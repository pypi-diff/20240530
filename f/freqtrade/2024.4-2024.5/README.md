# Comparing `tmp/freqtrade-2024.4.tar.gz` & `tmp/freqtrade-2024.5.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "freqtrade-2024.4.tar", last modified: Tue Apr 30 12:41:51 2024, max compression
+gzip compressed data, was "freqtrade-2024.5.tar", last modified: Thu May 30 16:45:41 2024, max compression
```

## Comparing `freqtrade-2024.4.tar` & `freqtrade-2024.5.tar`

### file list

```diff
@@ -1,370 +1,371 @@
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.534379 freqtrade-2024.4/
--rw-r--r--   0 runner    (1001) docker     (127)    35141 2024-04-30 12:41:47.000000 freqtrade-2024.4/LICENSE
--rw-r--r--   0 runner    (1001) docker     (127)      290 2024-04-30 12:41:47.000000 freqtrade-2024.4/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (127)    18224 2024-04-30 12:41:51.534379 freqtrade-2024.4/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)    11493 2024-04-30 12:41:47.000000 freqtrade-2024.4/README.md
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.470379 freqtrade-2024.4/freqtrade/
--rw-r--r--   0 runner    (1001) docker     (127)      810 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (127)      206 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/__main__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.474379 freqtrade-2024.4/freqtrade/commands/
--rw-r--r--   0 runner    (1001) docker     (127)     1912 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2187 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/analyze_commands.py
--rwxr-xr-x   0 runner    (1001) docker     (127)    22632 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/arguments.py
--rw-r--r--   0 runner    (1001) docker     (127)     9504 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/build_config_commands.py
--rwxr-xr-x   0 runner    (1001) docker     (127)    23376 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/cli_options.py
--rw-r--r--   0 runner    (1001) docker     (127)     5541 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/data_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)     1672 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/db_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)     6953 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/deploy_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)     3634 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/hyperopt_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)    10329 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/list_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)     5298 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/optimize_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)     1458 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/pairlist_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)     1158 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/plot_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)     1852 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/strategy_utils_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)      750 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/trade_commands.py
--rw-r--r--   0 runner    (1001) docker     (127)      428 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/commands/webserver_commands.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.478379 freqtrade-2024.4/freqtrade/configuration/
--rw-r--r--   0 runner    (1001) docker     (127)      439 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1022 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/config_secrets.py
--rw-r--r--   0 runner    (1001) docker     (127)      777 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/config_setup.py
--rw-r--r--   0 runner    (1001) docker     (127)    17535 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/config_validation.py
--rw-r--r--   0 runner    (1001) docker     (127)    21740 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/configuration.py
--rw-r--r--   0 runner    (1001) docker     (127)     7049 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/deprecated_settings.py
--rw-r--r--   0 runner    (1001) docker     (127)      163 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/detect_environment.py
--rw-r--r--   0 runner    (1001) docker     (127)     3630 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/directory_operations.py
--rw-r--r--   0 runner    (1001) docker     (127)     1826 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/environment_vars.py
--rw-r--r--   0 runner    (1001) docker     (127)     3887 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/load_config.py
--rw-r--r--   0 runner    (1001) docker     (127)     6278 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/configuration/timerange.py
--rw-r--r--   0 runner    (1001) docker     (127)    30148 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/constants.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.478379 freqtrade-2024.4/freqtrade/data/
--rw-r--r--   0 runner    (1001) docker     (127)      152 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    18339 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/btanalysis.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.478379 freqtrade-2024.4/freqtrade/data/converter/
--rw-r--r--   0 runner    (1001) docker     (127)     1238 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/converter/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    10906 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/converter/converter.py
--rw-r--r--   0 runner    (1001) docker     (127)     5886 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/converter/trade_converter.py
--rw-r--r--   0 runner    (1001) docker     (127)     3225 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/converter/trade_converter_kraken.py
--rw-r--r--   0 runner    (1001) docker     (127)    21785 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/dataprovider.py
--rw-r--r--   0 runner    (1001) docker     (127)    13192 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/entryexitanalysis.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.482379 freqtrade-2024.4/freqtrade/data/history/
--rw-r--r--   0 runner    (1001) docker     (127)      485 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.482379 freqtrade-2024.4/freqtrade/data/history/datahandlers/
--rw-r--r--   0 runner    (1001) docker     (127)       77 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/datahandlers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5135 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/datahandlers/featherdatahandler.py
--rw-r--r--   0 runner    (1001) docker     (127)     6349 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/datahandlers/hdf5datahandler.py
--rw-r--r--   0 runner    (1001) docker     (127)    20160 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/datahandlers/idatahandler.py
--rw-r--r--   0 runner    (1001) docker     (127)     5996 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/datahandlers/jsondatahandler.py
--rw-r--r--   0 runner    (1001) docker     (127)     5025 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/datahandlers/parquetdatahandler.py
--rw-r--r--   0 runner    (1001) docker     (127)    25505 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/history/history_utils.py
--rw-r--r--   0 runner    (1001) docker     (127)    14256 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/data/metrics.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.482379 freqtrade-2024.4/freqtrade/edge/
--rw-r--r--   0 runner    (1001) docker     (127)       59 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/edge/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    20653 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/edge/edge_positioning.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.486379 freqtrade-2024.4/freqtrade/enums/
--rw-r--r--   0 runner    (1001) docker     (127)      859 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      238 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/backteststate.py
--rw-r--r--   0 runner    (1001) docker     (127)      798 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/candletype.py
--rw-r--r--   0 runner    (1001) docker     (127)      640 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/exitchecktuple.py
--rw-r--r--   0 runner    (1001) docker     (127)      619 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/exittype.py
--rw-r--r--   0 runner    (1001) docker     (127)      210 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/hyperoptstate.py
--rw-r--r--   0 runner    (1001) docker     (127)      242 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/marginmode.py
--rw-r--r--   0 runner    (1001) docker     (127)      261 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/marketstatetype.py
--rw-r--r--   0 runner    (1001) docker     (127)      100 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/ordertypevalue.py
--rw-r--r--   0 runner    (1001) docker     (127)      177 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/pricetype.py
--rw-r--r--   0 runner    (1001) docker     (127)      976 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/rpcmessagetype.py
--rw-r--r--   0 runner    (1001) docker     (127)      588 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/runmode.py
--rw-r--r--   0 runner    (1001) docker     (127)      626 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/signaltype.py
--rw-r--r--   0 runner    (1001) docker     (127)      202 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/state.py
--rw-r--r--   0 runner    (1001) docker     (127)      220 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/enums/tradingmode.py
--rw-r--r--   0 runner    (1001) docker     (127)     2200 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exceptions.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.490379 freqtrade-2024.4/freqtrade/exchange/
--rw-r--r--   0 runner    (1001) docker     (127)     1845 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     9889 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/binance.py
--rw-r--r--   0 runner    (1001) docker     (127)   902770 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/binance_leverage_tiers.json
--rw-r--r--   0 runner    (1001) docker     (127)      357 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/bingx.py
--rw-r--r--   0 runner    (1001) docker     (127)      449 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/bitmart.py
--rw-r--r--   0 runner    (1001) docker     (127)     1621 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/bitpanda.py
--rw-r--r--   0 runner    (1001) docker     (127)      547 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/bitvavo.py
--rw-r--r--   0 runner    (1001) docker     (127)     9886 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/bybit.py
--rw-r--r--   0 runner    (1001) docker     (127)     2971 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/check_exchange.py
--rw-r--r--   0 runner    (1001) docker     (127)      564 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/coinbasepro.py
--rw-r--r--   0 runner    (1001) docker     (127)     6356 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/common.py
--rw-r--r--   0 runner    (1001) docker     (127)   139830 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/exchange.py
--rw-r--r--   0 runner    (1001) docker     (127)    11767 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/exchange_utils.py
--rw-r--r--   0 runner    (1001) docker     (127)     2804 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/exchange_utils_timeframe.py
--rw-r--r--   0 runner    (1001) docker     (127)     4965 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/gate.py
--rw-r--r--   0 runner    (1001) docker     (127)      517 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/hitbtc.py
--rw-r--r--   0 runner    (1001) docker     (127)      902 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/htx.py
--rw-r--r--   0 runner    (1001) docker     (127)      354 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/idex.py
--rw-r--r--   0 runner    (1001) docker     (127)     7130 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/kraken.py
--rw-r--r--   0 runner    (1001) docker     (127)     2201 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/kucoin.py
--rw-r--r--   0 runner    (1001) docker     (127)    10248 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/okx.py
--rw-r--r--   0 runner    (1001) docker     (127)      725 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/exchange/types.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.490379 freqtrade-2024.4/freqtrade/freqai/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.490379 freqtrade-2024.4/freqtrade/freqai/RL/
--rw-r--r--   0 runner    (1001) docker     (127)     4496 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/RL/Base3ActionRLEnv.py
--rw-r--r--   0 runner    (1001) docker     (127)     5021 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/RL/Base4ActionRLEnv.py
--rw-r--r--   0 runner    (1001) docker     (127)     5644 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/RL/Base5ActionRLEnv.py
--rw-r--r--   0 runner    (1001) docker     (127)    15447 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/RL/BaseEnvironment.py
--rw-r--r--   0 runner    (1001) docker     (127)    21145 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/RL/BaseReinforcementLearningModel.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/RL/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.494379 freqtrade-2024.4/freqtrade/freqai/base_models/
--rw-r--r--   0 runner    (1001) docker     (127)     5137 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/base_models/BaseClassifierModel.py
--rw-r--r--   0 runner    (1001) docker     (127)     8283 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/base_models/BasePyTorchClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     1144 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/base_models/BasePyTorchModel.py
--rw-r--r--   0 runner    (1001) docker     (127)     4774 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/base_models/BasePyTorchRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)     5039 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/base_models/BaseRegressionModel.py
--rw-r--r--   0 runner    (1001) docker     (127)     3451 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/base_models/FreqaiMultiOutputClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     2487 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/base_models/FreqaiMultiOutputRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)    33102 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/data_drawer.py
--rw-r--r--   0 runner    (1001) docker     (127)    43694 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/data_kitchen.py
--rw-r--r--   0 runner    (1001) docker     (127)    45701 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/freqai_interface.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.494379 freqtrade-2024.4/freqtrade/freqai/prediction_models/
--rw-r--r--   0 runner    (1001) docker     (127)     2083 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     2866 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostClassifierMultiTarget.py
--rw-r--r--   0 runner    (1001) docker     (127)     2048 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)     2834 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostRegressorMultiTarget.py
--rw-r--r--   0 runner    (1001) docker     (127)     1921 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     2698 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMClassifierMultiTarget.py
--rw-r--r--   0 runner    (1001) docker     (127)     1839 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)     2694 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMRegressorMultiTarget.py
--rw-r--r--   0 runner    (1001) docker     (127)     3622 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/PyTorchMLPClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     3308 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/PyTorchMLPRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)     6158 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/PyTorchTransformerRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)     7160 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/ReinforcementLearner.py
--rw-r--r--   0 runner    (1001) docker     (127)     3284 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/ReinforcementLearner_multiproc.py
--rw-r--r--   0 runner    (1001) docker     (127)     3241 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/SKLearnRandomForestClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     3338 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     3345 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRFClassifier.py
--rw-r--r--   0 runner    (1001) docker     (127)     2074 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRFRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)     2219 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRegressor.py
--rw-r--r--   0 runner    (1001) docker     (127)     2596 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRegressorMultiTarget.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/prediction_models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.498379 freqtrade-2024.4/freqtrade/freqai/tensorboard/
--rw-r--r--   0 runner    (1001) docker     (127)     2152 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/tensorboard/TensorboardCallback.py
--rw-r--r--   0 runner    (1001) docker     (127)      587 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/tensorboard/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      690 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/tensorboard/base_tensorboard.py
--rw-r--r--   0 runner    (1001) docker     (127)     1859 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/tensorboard/tensorboard.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.498379 freqtrade-2024.4/freqtrade/freqai/torch/
--rw-r--r--   0 runner    (1001) docker     (127)     1886 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/torch/PyTorchDataConvertor.py
--rw-r--r--   0 runner    (1001) docker     (127)     3762 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/torch/PyTorchMLPModel.py
--rw-r--r--   0 runner    (1001) docker     (127)     8740 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/torch/PyTorchModelTrainer.py
--rw-r--r--   0 runner    (1001) docker     (127)     2026 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/torch/PyTorchTrainerInterface.py
--rw-r--r--   0 runner    (1001) docker     (127)     3613 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/torch/PyTorchTransformerModel.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/torch/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      666 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/torch/datasets.py
--rw-r--r--   0 runner    (1001) docker     (127)     7457 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqai/utils.py
--rw-r--r--   0 runner    (1001) docker     (127)   102237 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/freqtradebot.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.498379 freqtrade-2024.4/freqtrade/leverage/
--rw-r--r--   0 runner    (1001) docker     (127)       63 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/leverage/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1257 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/leverage/interest.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.498379 freqtrade-2024.4/freqtrade/loggers/
--rw-r--r--   0 runner    (1001) docker     (127)     4271 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/loggers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      460 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/loggers/buffering_handler.py
--rw-r--r--   0 runner    (1001) docker     (127)     1598 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/loggers/set_log_levels.py
--rw-r--r--   0 runner    (1001) docker     (127)      714 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/loggers/std_err_stream_handler.py
--rwxr-xr-x   0 runner    (1001) docker     (127)     2328 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/main.py
--rw-r--r--   0 runner    (1001) docker     (127)     7610 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/misc.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.498379 freqtrade-2024.4/freqtrade/mixins/
--rw-r--r--   0 runner    (1001) docker     (127)       70 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/mixins/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1263 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/mixins/logging_mixin.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.502379 freqtrade-2024.4/freqtrade/optimize/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.502379 freqtrade-2024.4/freqtrade/optimize/analysis/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/analysis/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (127)    12380 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/analysis/lookahead.py
--rw-r--r--   0 runner    (1001) docker     (127)    10417 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/analysis/lookahead_helpers.py
--rw-r--r--   0 runner    (1001) docker     (127)     7448 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/analysis/recursive.py
--rw-r--r--   0 runner    (1001) docker     (127)     4230 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/analysis/recursive_helpers.py
--rw-r--r--   0 runner    (1001) docker     (127)     1519 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/backtest_caching.py
--rw-r--r--   0 runner    (1001) docker     (127)    67874 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/backtesting.py
--rw-r--r--   0 runner    (1001) docker     (127)     1902 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/base_analysis.py
--rw-r--r--   0 runner    (1001) docker     (127)      856 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/bt_progress.py
--rw-r--r--   0 runner    (1001) docker     (127)     1823 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/edge_cli.py
--rw-r--r--   0 runner    (1001) docker     (127)    29040 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt.py
--rw-r--r--   0 runner    (1001) docker     (127)     3672 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_auto.py
--rw-r--r--   0 runner    (1001) docker     (127)     4525 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_epoch_filters.py
--rw-r--r--   0 runner    (1001) docker     (127)     8554 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_interface.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.502379 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/
--rw-r--r--   0 runner    (1001) docker     (127)     1102 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_calmar.py
--rw-r--r--   0 runner    (1001) docker     (127)     1237 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown.py
--rw-r--r--   0 runner    (1001) docker     (127)     1470 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown_relative.py
--rw-r--r--   0 runner    (1001) docker     (127)      746 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_onlyprofit.py
--rw-r--r--   0 runner    (1001) docker     (127)      931 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_profit_drawdown.py
--rw-r--r--   0 runner    (1001) docker     (127)     1095 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe.py
--rw-r--r--   0 runner    (1001) docker     (127)     2108 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe_daily.py
--rw-r--r--   0 runner    (1001) docker     (127)     1965 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_short_trade_dur.py
--rw-r--r--   0 runner    (1001) docker     (127)     1109 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino.py
--rw-r--r--   0 runner    (1001) docker     (127)     2568 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino_daily.py
--rw-r--r--   0 runner    (1001) docker     (127)      951 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_loss_interface.py
--rw-r--r--   0 runner    (1001) docker     (127)    23157 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/hyperopt_tools.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.506379 freqtrade-2024.4/freqtrade/optimize/optimize_reports/
--rw-r--r--   0 runner    (1001) docker     (127)     1345 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/optimize_reports/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    18515 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/optimize_reports/bt_output.py
--rw-r--r--   0 runner    (1001) docker     (127)     3649 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/optimize_reports/bt_storage.py
--rw-r--r--   0 runner    (1001) docker     (127)    23477 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/optimize_reports/optimize_reports.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.506379 freqtrade-2024.4/freqtrade/optimize/space/
--rw-r--r--   0 runner    (1001) docker     (127)      127 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1402 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/optimize/space/decimalspace.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.506379 freqtrade-2024.4/freqtrade/persistence/
--rw-r--r--   0 runner    (1001) docker     (127)      504 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      154 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/base.py
--rw-r--r--   0 runner    (1001) docker     (127)     6569 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/custom_data.py
--rw-r--r--   0 runner    (1001) docker     (127)     6439 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/key_value_store.py
--rw-r--r--   0 runner    (1001) docker     (127)    16084 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/migrations.py
--rw-r--r--   0 runner    (1001) docker     (127)     3145 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/models.py
--rw-r--r--   0 runner    (1001) docker     (127)     3103 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/pairlock.py
--rw-r--r--   0 runner    (1001) docker     (127)     6364 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/pairlock_middleware.py
--rw-r--r--   0 runner    (1001) docker     (127)    80124 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/trade_model.py
--rw-r--r--   0 runner    (1001) docker     (127)      968 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/persistence/usedb_context.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.506379 freqtrade-2024.4/freqtrade/plot/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plot/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    26350 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plot/plotting.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.506379 freqtrade-2024.4/freqtrade/plugins/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.510379 freqtrade-2024.4/freqtrade/plugins/pairlist/
--rw-r--r--   0 runner    (1001) docker     (127)     6497 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/AgeFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     1875 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/FullTradesFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     9088 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/IPairList.py
--rw-r--r--   0 runner    (1001) docker     (127)     5888 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/MarketCapPairList.py
--rw-r--r--   0 runner    (1001) docker     (127)     2926 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/OffsetFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     3990 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/PerformanceFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     3089 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/PrecisionFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     6627 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/PriceFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     3987 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/ProducerPairList.py
--rw-r--r--   0 runner    (1001) docker     (127)    12344 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/RemotePairList.py
--rw-r--r--   0 runner    (1001) docker     (127)     3639 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/ShuffleFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     2971 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/SpreadFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     2879 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/StaticPairList.py
--rw-r--r--   0 runner    (1001) docker     (127)     7157 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/VolatilityFilter.py
--rw-r--r--   0 runner    (1001) docker     (127)    12988 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/VolumePairList.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2311 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/pairlist_helpers.py
--rw-r--r--   0 runner    (1001) docker     (127)     7312 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlist/rangestabilityfilter.py
--rw-r--r--   0 runner    (1001) docker     (127)     6881 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/pairlistmanager.py
--rw-r--r--   0 runner    (1001) docker     (127)     2870 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/protectionmanager.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.510379 freqtrade-2024.4/freqtrade/plugins/protections/
--rw-r--r--   0 runner    (1001) docker     (127)      105 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/protections/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2707 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/protections/cooldown_period.py
--rw-r--r--   0 runner    (1001) docker     (127)     4272 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/protections/iprotection.py
--rw-r--r--   0 runner    (1001) docker     (127)     3607 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/protections/low_profit_pairs.py
--rw-r--r--   0 runner    (1001) docker     (127)     3544 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/protections/max_drawdown_protection.py
--rw-r--r--   0 runner    (1001) docker     (127)     3691 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/plugins/protections/stoploss_guard.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.514379 freqtrade-2024.4/freqtrade/resolvers/
--rw-r--r--   0 runner    (1001) docker     (127)      512 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3699 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/exchange_resolver.py
--rw-r--r--   0 runner    (1001) docker     (127)     1776 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/freqaimodel_resolver.py
--rw-r--r--   0 runner    (1001) docker     (127)     1727 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/hyperopt_resolver.py
--rw-r--r--   0 runner    (1001) docker     (127)    10538 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/iresolver.py
--rw-r--r--   0 runner    (1001) docker     (127)     1794 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/pairlist_resolver.py
--rw-r--r--   0 runner    (1001) docker     (127)     1377 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/protection_resolver.py
--rw-r--r--   0 runner    (1001) docker     (127)    13871 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/resolvers/strategy_resolver.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.514379 freqtrade-2024.4/freqtrade/rpc/
--rw-r--r--   0 runner    (1001) docker     (127)      111 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.514379 freqtrade-2024.4/freqtrade/rpc/api_server/
--rw-r--r--   0 runner    (1001) docker     (127)       47 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5445 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/api_auth.py
--rw-r--r--   0 runner    (1001) docker     (127)     5234 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/api_background_tasks.py
--rw-r--r--   0 runner    (1001) docker     (127)    12785 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/api_backtest.py
--rw-r--r--   0 runner    (1001) docker     (127)    14070 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/api_schemas.py
--rw-r--r--   0 runner    (1001) docker     (127)    18152 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/api_v1.py
--rw-r--r--   0 runner    (1001) docker     (127)     4601 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/api_ws.py
--rw-r--r--   0 runner    (1001) docker     (127)     2033 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/deps.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.518379 freqtrade-2024.4/freqtrade/rpc/api_server/ui/
--rw-r--r--   0 runner    (1001) docker     (127)      753 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ui/fallback_file.html
--rw-r--r--   0 runner    (1001) docker     (127)   126794 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ui/favicon.ico
--rw-r--r--   0 runner    (1001) docker     (127)     2100 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/uvicorn_threaded.py
--rw-r--r--   0 runner    (1001) docker     (127)     2175 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/web_ui.py
--rw-r--r--   0 runner    (1001) docker     (127)     8230 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/webserver.py
--rw-r--r--   0 runner    (1001) docker     (127)      889 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/webserver_bgwork.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.518379 freqtrade-2024.4/freqtrade/rpc/api_server/ws/
--rw-r--r--   0 runner    (1001) docker     (127)      419 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ws/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     7565 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ws/channel.py
--rw-r--r--   0 runner    (1001) docker     (127)      898 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ws/message_stream.py
--rw-r--r--   0 runner    (1001) docker     (127)     2292 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ws/proxy.py
--rw-r--r--   0 runner    (1001) docker     (127)     1678 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ws/serializer.py
--rw-r--r--   0 runner    (1001) docker     (127)      257 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ws/types.py
--rw-r--r--   0 runner    (1001) docker     (127)     1884 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/api_server/ws_schemas.py
--rw-r--r--   0 runner    (1001) docker     (127)     2052 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/discord.py
--rw-r--r--   0 runner    (1001) docker     (127)    14701 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/external_message_consumer.py
--rw-r--r--   0 runner    (1001) docker     (127)     7312 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/fiat_convert.py
--rw-r--r--   0 runner    (1001) docker     (127)    62215 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/rpc.py
--rw-r--r--   0 runner    (1001) docker     (127)     5294 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/rpc_manager.py
--rw-r--r--   0 runner    (1001) docker     (127)     3206 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/rpc_types.py
--rw-r--r--   0 runner    (1001) docker     (127)    84100 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/telegram.py
--rw-r--r--   0 runner    (1001) docker     (127)     4911 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/rpc/webhook.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.518379 freqtrade-2024.4/freqtrade/strategy/
--rw-r--r--   0 runner    (1001) docker     (127)      650 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     8240 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/hyper.py
--rw-r--r--   0 runner    (1001) docker     (127)     6128 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/informative_decorator.py
--rw-r--r--   0 runner    (1001) docker     (127)    69757 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/interface.py
--rw-r--r--   0 runner    (1001) docker     (127)    12586 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/parameters.py
--rw-r--r--   0 runner    (1001) docker     (127)     7269 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/strategy_helper.py
--rw-r--r--   0 runner    (1001) docker     (127)     1568 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/strategy_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (127)     9774 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/strategy/strategyupdater.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.522379 freqtrade-2024.4/freqtrade/templates/
--rw-r--r--   0 runner    (1001) docker     (127)    12782 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/FreqaiExampleHybridStrategy.py
--rw-r--r--   0 runner    (1001) docker     (127)    11706 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/FreqaiExampleStrategy.py
--rw-r--r--   0 runner    (1001) docker     (127)     2100 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/base_config.json.j2
--rw-r--r--   0 runner    (1001) docker     (127)     5903 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/base_strategy.py.j2
--rw-r--r--   0 runner    (1001) docker     (127)     1917 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/sample_hyperopt_loss.py
--rw-r--r--   0 runner    (1001) docker     (127)    16720 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/sample_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)    14243 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_analysis_example.ipynb
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.522379 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/
--rw-r--r--   0 runner    (1001) docker     (127)      261 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/buy_trend_full.j2
--rw-r--r--   0 runner    (1001) docker     (127)      101 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/buy_trend_minimal.j2
--rw-r--r--   0 runner    (1001) docker     (127)     7747 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/indicators_full.j2
--rw-r--r--   0 runner    (1001) docker     (127)      464 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/indicators_minimal.j2
--rw-r--r--   0 runner    (1001) docker     (127)      506 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/plot_config_full.j2
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/plot_config_minimal.j2
--rw-r--r--   0 runner    (1001) docker     (127)      262 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/sell_trend_full.j2
--rw-r--r--   0 runner    (1001) docker     (127)      103 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/sell_trend_minimal.j2
--rw-r--r--   0 runner    (1001) docker     (127)      249 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/strategy_attributes_full.j2
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/strategy_attributes_minimal.j2
--rw-r--r--   0 runner    (1001) docker     (127)    16125 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/strategy_methods_advanced.j2
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/strategy_methods_empty.j2
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.522379 freqtrade-2024.4/freqtrade/templates/subtemplates/
--rw-r--r--   0 runner    (1001) docker     (127)      261 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_binance.j2
--rw-r--r--   0 runner    (1001) docker     (127)      397 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_bittrex.j2
--rw-r--r--   0 runner    (1001) docker     (127)      271 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_gateio.j2
--rw-r--r--   0 runner    (1001) docker     (127)      244 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_generic.j2
--rw-r--r--   0 runner    (1001) docker     (127)      260 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_huobi.j2
--rw-r--r--   0 runner    (1001) docker     (127)      249 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_kraken.j2
--rw-r--r--   0 runner    (1001) docker     (127)      291 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_kucoin.j2
--rw-r--r--   0 runner    (1001) docker     (127)      291 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/templates/subtemplates/exchange_okex.j2
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.522379 freqtrade-2024.4/freqtrade/types/
--rw-r--r--   0 runner    (1001) docker     (127)      339 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/types/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      736 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/types/backtest_result_type.py
--rw-r--r--   0 runner    (1001) docker     (127)      311 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/types/valid_exchanges_type.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.526379 freqtrade-2024.4/freqtrade/util/
--rw-r--r--   0 runner    (1001) docker     (127)      937 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2740 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/datetime_helpers.py
--rw-r--r--   0 runner    (1001) docker     (127)     1656 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/formatters.py
--rw-r--r--   0 runner    (1001) docker     (127)      337 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/ft_precise.py
--rw-r--r--   0 runner    (1001) docker     (127)      458 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/gc_setup.py
--rw-r--r--   0 runner    (1001) docker     (127)     1312 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/measure_time.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.526379 freqtrade-2024.4/freqtrade/util/migrations/
--rw-r--r--   0 runner    (1001) docker     (127)      485 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/migrations/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2670 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/migrations/binance_mig.py
--rw-r--r--   0 runner    (1001) docker     (127)      813 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/migrations/funding_rate_mig.py
--rw-r--r--   0 runner    (1001) docker     (127)      580 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/periodic_cache.py
--rw-r--r--   0 runner    (1001) docker     (127)      990 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/util/template_renderer.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.526379 freqtrade-2024.4/freqtrade/vendor/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/vendor/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.526379 freqtrade-2024.4/freqtrade/vendor/qtpylib/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/vendor/qtpylib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    19869 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/vendor/qtpylib/indicators.py
--rw-r--r--   0 runner    (1001) docker     (127)    15005 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/wallets.py
--rw-r--r--   0 runner    (1001) docker     (127)     8486 2024-04-30 12:41:47.000000 freqtrade-2024.4/freqtrade/worker.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-30 12:41:51.526379 freqtrade-2024.4/freqtrade.egg-info/
--rw-r--r--   0 runner    (1001) docker     (127)    18224 2024-04-30 12:41:51.000000 freqtrade-2024.4/freqtrade.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)    13216 2024-04-30 12:41:51.000000 freqtrade-2024.4/freqtrade.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2024-04-30 12:41:51.000000 freqtrade-2024.4/freqtrade.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (127)       50 2024-04-30 12:41:51.000000 freqtrade-2024.4/freqtrade.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2024-04-30 12:41:51.000000 freqtrade-2024.4/freqtrade.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (127)     1801 2024-04-30 12:41:51.000000 freqtrade-2024.4/freqtrade.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (127)       10 2024-04-30 12:41:51.000000 freqtrade-2024.4/freqtrade.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (127)     4088 2024-04-30 12:41:47.000000 freqtrade-2024.4/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (127)       38 2024-04-30 12:41:51.534379 freqtrade-2024.4/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (127)     2436 2024-04-30 12:41:47.000000 freqtrade-2024.4/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.579097 freqtrade-2024.5/
+-rw-r--r--   0 runner    (1001) docker     (127)    35141 2024-05-30 16:45:37.000000 freqtrade-2024.5/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (127)      290 2024-05-30 16:45:37.000000 freqtrade-2024.5/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (127)    18271 2024-05-30 16:45:41.579097 freqtrade-2024.5/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)    11540 2024-05-30 16:45:37.000000 freqtrade-2024.5/README.md
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.519096 freqtrade-2024.5/freqtrade/
+-rw-r--r--   0 runner    (1001) docker     (127)      936 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (127)      206 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/__main__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.523096 freqtrade-2024.5/freqtrade/commands/
+-rw-r--r--   0 runner    (1001) docker     (127)     1665 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2185 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/analyze_commands.py
+-rwxr-xr-x   0 runner    (1001) docker     (127)    21828 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/arguments.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9600 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/build_config_commands.py
+-rwxr-xr-x   0 runner    (1001) docker     (127)    24120 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/cli_options.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5870 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/data_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1648 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/db_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6689 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/deploy_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3722 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/hyperopt_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10694 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/list_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5326 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/optimize_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1459 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/pairlist_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1169 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/plot_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1869 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/strategy_utils_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)      750 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/trade_commands.py
+-rw-r--r--   0 runner    (1001) docker     (127)      428 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/commands/webserver_commands.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.523096 freqtrade-2024.5/freqtrade/configuration/
+-rw-r--r--   0 runner    (1001) docker     (127)      439 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1022 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/config_secrets.py
+-rw-r--r--   0 runner    (1001) docker     (127)      774 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/config_setup.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17647 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/config_validation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    21995 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6932 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/deprecated_settings.py
+-rw-r--r--   0 runner    (1001) docker     (127)      163 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/detect_environment.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3683 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/directory_operations.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1937 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/environment_vars.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3905 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/load_config.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6438 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/configuration/timerange.py
+-rw-r--r--   0 runner    (1001) docker     (127)    30693 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/constants.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.527096 freqtrade-2024.5/freqtrade/data/
+-rw-r--r--   0 runner    (1001) docker     (127)      146 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18274 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/btanalysis.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.527096 freqtrade-2024.5/freqtrade/data/converter/
+-rw-r--r--   0 runner    (1001) docker     (127)      944 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/converter/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10775 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/converter/converter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5887 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/converter/trade_converter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3196 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/converter/trade_converter_kraken.py
+-rw-r--r--   0 runner    (1001) docker     (127)    21713 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/dataprovider.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12937 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/entryexitanalysis.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.527096 freqtrade-2024.5/freqtrade/data/history/
+-rw-r--r--   0 runner    (1001) docker     (127)      469 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.527096 freqtrade-2024.5/freqtrade/data/history/datahandlers/
+-rw-r--r--   0 runner    (1001) docker     (127)       77 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/datahandlers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5156 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/datahandlers/featherdatahandler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6430 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/datahandlers/hdf5datahandler.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20129 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/datahandlers/idatahandler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6008 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/datahandlers/jsondatahandler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5041 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/datahandlers/parquetdatahandler.py
+-rw-r--r--   0 runner    (1001) docker     (127)    24296 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/history/history_utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14278 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/data/metrics.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.527096 freqtrade-2024.5/freqtrade/edge/
+-rw-r--r--   0 runner    (1001) docker     (127)       59 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/edge/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20930 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/edge/edge_positioning.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.531096 freqtrade-2024.5/freqtrade/enums/
+-rw-r--r--   0 runner    (1001) docker     (127)      859 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      239 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/backteststate.py
+-rw-r--r--   0 runner    (1001) docker     (127)      799 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/candletype.py
+-rw-r--r--   0 runner    (1001) docker     (127)      641 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/exitchecktuple.py
+-rw-r--r--   0 runner    (1001) docker     (127)      620 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/exittype.py
+-rw-r--r--   0 runner    (1001) docker     (127)      209 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/hyperoptstate.py
+-rw-r--r--   0 runner    (1001) docker     (127)      243 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/marginmode.py
+-rw-r--r--   0 runner    (1001) docker     (127)      262 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/marketstatetype.py
+-rw-r--r--   0 runner    (1001) docker     (127)      100 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/ordertypevalue.py
+-rw-r--r--   0 runner    (1001) docker     (127)      178 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/pricetype.py
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/rpcmessagetype.py
+-rw-r--r--   0 runner    (1001) docker     (127)      589 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/runmode.py
+-rw-r--r--   0 runner    (1001) docker     (127)      628 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/signaltype.py
+-rw-r--r--   0 runner    (1001) docker     (127)      203 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/state.py
+-rw-r--r--   0 runner    (1001) docker     (127)      221 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/enums/tradingmode.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2200 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exceptions.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.535096 freqtrade-2024.5/freqtrade/exchange/
+-rw-r--r--   0 runner    (1001) docker     (127)     1422 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9254 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/binance.py
+-rw-r--r--   0 runner    (1001) docker     (127)   899719 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/binance_leverage_tiers.json
+-rw-r--r--   0 runner    (1001) docker     (127)      519 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/bingx.py
+-rw-r--r--   0 runner    (1001) docker     (127)      448 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/bitmart.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1605 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/bitpanda.py
+-rw-r--r--   0 runner    (1001) docker     (127)      548 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/bitvavo.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10410 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/bybit.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2964 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/check_exchange.py
+-rw-r--r--   0 runner    (1001) docker     (127)      563 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/coinbasepro.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6429 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/common.py
+-rw-r--r--   0 runner    (1001) docker     (127)   140380 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/exchange.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11745 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/exchange_utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2786 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/exchange_utils_timeframe.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4826 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/gate.py
+-rw-r--r--   0 runner    (1001) docker     (127)      517 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/hitbtc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1037 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/htx.py
+-rw-r--r--   0 runner    (1001) docker     (127)      353 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/idex.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7125 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/kraken.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2114 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/kucoin.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10240 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/okx.py
+-rw-r--r--   0 runner    (1001) docker     (127)      725 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/exchange/types.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.535096 freqtrade-2024.5/freqtrade/freqai/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.539096 freqtrade-2024.5/freqtrade/freqai/RL/
+-rw-r--r--   0 runner    (1001) docker     (127)     4691 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/RL/Base3ActionRLEnv.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5121 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/RL/Base4ActionRLEnv.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5720 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/RL/Base5ActionRLEnv.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15419 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/RL/BaseEnvironment.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20722 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/RL/BaseReinforcementLearningModel.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/RL/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.539096 freqtrade-2024.5/freqtrade/freqai/base_models/
+-rw-r--r--   0 runner    (1001) docker     (127)     4978 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/base_models/BaseClassifierModel.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8019 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/base_models/BasePyTorchClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1144 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/base_models/BasePyTorchModel.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4589 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/base_models/BasePyTorchRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4880 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/base_models/BaseRegressionModel.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3385 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/base_models/FreqaiMultiOutputClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2434 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/base_models/FreqaiMultiOutputRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)    32814 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/data_drawer.py
+-rw-r--r--   0 runner    (1001) docker     (127)    43423 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/data_kitchen.py
+-rw-r--r--   0 runner    (1001) docker     (127)    45627 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/freqai_interface.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.543096 freqtrade-2024.5/freqtrade/freqai/prediction_models/
+-rw-r--r--   0 runner    (1001) docker     (127)     2061 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2849 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostClassifierMultiTarget.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2024 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2803 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostRegressorMultiTarget.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2051 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2774 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMClassifierMultiTarget.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1904 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2820 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMRegressorMultiTarget.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3537 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/PyTorchMLPClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3213 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/PyTorchMLPRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6103 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/PyTorchTransformerRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7104 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/ReinforcementLearner.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3048 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/ReinforcementLearner_multiproc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3269 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/SKLearnRandomForestClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3329 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3336 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRFClassifier.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2139 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRFRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2175 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRegressor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2722 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRegressorMultiTarget.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/prediction_models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.543096 freqtrade-2024.5/freqtrade/freqai/tensorboard/
+-rw-r--r--   0 runner    (1001) docker     (127)     2152 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/tensorboard/TensorboardCallback.py
+-rw-r--r--   0 runner    (1001) docker     (127)      539 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/tensorboard/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      675 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/tensorboard/base_tensorboard.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1810 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/tensorboard/tensorboard.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.543096 freqtrade-2024.5/freqtrade/freqai/torch/
+-rw-r--r--   0 runner    (1001) docker     (127)     1874 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/torch/PyTorchDataConvertor.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3762 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/torch/PyTorchMLPModel.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8689 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/torch/PyTorchModelTrainer.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2025 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/torch/PyTorchTrainerInterface.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3677 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/torch/PyTorchTransformerModel.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/torch/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      668 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/torch/datasets.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7478 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqai/utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)   104717 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/freqtradebot.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.543096 freqtrade-2024.5/freqtrade/leverage/
+-rw-r--r--   0 runner    (1001) docker     (127)       63 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/leverage/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1245 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/leverage/interest.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.543096 freqtrade-2024.5/freqtrade/loggers/
+-rw-r--r--   0 runner    (1001) docker     (127)     4243 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/loggers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      506 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/loggers/buffering_handler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1575 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/loggers/set_log_levels.py
+-rw-r--r--   0 runner    (1001) docker     (127)      714 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/loggers/std_err_stream_handler.py
+-rwxr-xr-x   0 runner    (1001) docker     (127)     2342 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/main.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7612 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/misc.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.543096 freqtrade-2024.5/freqtrade/mixins/
+-rw-r--r--   0 runner    (1001) docker     (127)       70 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/mixins/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1265 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/mixins/logging_mixin.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.547096 freqtrade-2024.5/freqtrade/optimize/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.547096 freqtrade-2024.5/freqtrade/optimize/analysis/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/analysis/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (127)    12344 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/analysis/lookahead.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10574 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/analysis/lookahead_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7411 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/analysis/recursive.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4317 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/analysis/recursive_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1526 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/backtest_caching.py
+-rw-r--r--   0 runner    (1001) docker     (127)    70046 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/backtesting.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1900 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/base_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (127)      855 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/bt_progress.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1833 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/edge_cli.py
+-rw-r--r--   0 runner    (1001) docker     (127)    29210 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3678 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_auto.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4488 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_epoch_filters.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8561 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_interface.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.547096 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/
+-rw-r--r--   0 runner    (1001) docker     (127)     1104 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_calmar.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1239 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1406 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown_relative.py
+-rw-r--r--   0 runner    (1001) docker     (127)      716 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_onlyprofit.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1164 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_profit_drawdown.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1097 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2106 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe_daily.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1935 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_short_trade_dur.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1111 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2566 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino_daily.py
+-rw-r--r--   0 runner    (1001) docker     (127)      907 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_loss_interface.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23552 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/hyperopt_tools.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.551097 freqtrade-2024.5/freqtrade/optimize/optimize_reports/
+-rw-r--r--   0 runner    (1001) docker     (127)      897 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/optimize_reports/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19825 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/optimize_reports/bt_output.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3642 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/optimize_reports/bt_storage.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22932 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/optimize_reports/optimize_reports.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.551097 freqtrade-2024.5/freqtrade/optimize/space/
+-rw-r--r--   0 runner    (1001) docker     (127)      127 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1463 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/optimize/space/decimalspace.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.551097 freqtrade-2024.5/freqtrade/persistence/
+-rw-r--r--   0 runner    (1001) docker     (127)      470 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      153 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/base.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6626 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/custom_data.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6823 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/key_value_store.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16335 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/migrations.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3192 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/models.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3085 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/pairlock.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6455 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/pairlock_middleware.py
+-rw-r--r--   0 runner    (1001) docker     (127)    81409 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/trade_model.py
+-rw-r--r--   0 runner    (1001) docker     (127)      967 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/persistence/usedb_context.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.551097 freqtrade-2024.5/freqtrade/plot/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plot/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    25612 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plot/plotting.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.551097 freqtrade-2024.5/freqtrade/plugins/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.555096 freqtrade-2024.5/freqtrade/plugins/pairlist/
+-rw-r--r--   0 runner    (1001) docker     (127)     6771 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/AgeFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1896 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/FullTradesFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9172 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/IPairList.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6154 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/MarketCapPairList.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2970 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/OffsetFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4050 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/PerformanceFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3134 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/PrecisionFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6800 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/PriceFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4067 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/ProducerPairList.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12343 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/RemotePairList.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3665 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/ShuffleFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3029 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/SpreadFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2913 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/StaticPairList.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7178 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/VolatilityFilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13326 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/VolumePairList.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2194 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/pairlist_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7370 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlist/rangestabilityfilter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6886 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/pairlistmanager.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2885 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/protectionmanager.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.555096 freqtrade-2024.5/freqtrade/plugins/protections/
+-rw-r--r--   0 runner    (1001) docker     (127)      105 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/protections/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2702 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/protections/cooldown_period.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4269 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/protections/iprotection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3682 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/protections/low_profit_pairs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3647 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/protections/max_drawdown_protection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3924 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/plugins/protections/stoploss_guard.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.559097 freqtrade-2024.5/freqtrade/resolvers/
+-rw-r--r--   0 runner    (1001) docker     (127)      513 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3865 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/exchange_resolver.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1777 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/freqaimodel_resolver.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1639 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/hyperopt_resolver.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10435 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/iresolver.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1673 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/pairlist_resolver.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1259 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/protection_resolver.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13255 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/resolvers/strategy_resolver.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.559097 freqtrade-2024.5/freqtrade/rpc/
+-rw-r--r--   0 runner    (1001) docker     (127)      111 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.559097 freqtrade-2024.5/freqtrade/rpc/api_server/
+-rw-r--r--   0 runner    (1001) docker     (127)       47 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5366 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/api_auth.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5679 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/api_background_tasks.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12577 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/api_backtest.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14102 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/api_schemas.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17621 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/api_v1.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4502 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/api_ws.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1992 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/deps.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.563097 freqtrade-2024.5/freqtrade/rpc/api_server/ui/
+-rw-r--r--   0 runner    (1001) docker     (127)      753 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ui/fallback_file.html
+-rw-r--r--   0 runner    (1001) docker     (127)   126794 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ui/favicon.ico
+-rw-r--r--   0 runner    (1001) docker     (127)     2100 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/uvicorn_threaded.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2176 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/web_ui.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7902 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/webserver.py
+-rw-r--r--   0 runner    (1001) docker     (127)      888 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/webserver_bgwork.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.563097 freqtrade-2024.5/freqtrade/rpc/api_server/ws/
+-rw-r--r--   0 runner    (1001) docker     (127)      419 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ws/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7485 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ws/channel.py
+-rw-r--r--   0 runner    (1001) docker     (127)      899 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ws/message_stream.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2292 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ws/proxy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1644 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ws/serializer.py
+-rw-r--r--   0 runner    (1001) docker     (127)      257 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ws/types.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1886 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/api_server/ws_schemas.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2067 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/discord.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14224 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/external_message_consumer.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7211 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/fiat_convert.py
+-rw-r--r--   0 runner    (1001) docker     (127)    62873 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/rpc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5408 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/rpc_manager.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3207 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/rpc_types.py
+-rw-r--r--   0 runner    (1001) docker     (127)    85613 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/telegram.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4945 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/rpc/webhook.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.563097 freqtrade-2024.5/freqtrade/strategy/
+-rw-r--r--   0 runner    (1001) docker     (127)      588 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8341 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/hyper.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5958 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/informative_decorator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    70032 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/interface.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12960 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/parameters.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7209 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/strategy_helper.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1449 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/strategy_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9754 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/strategy/strategyupdater.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.567097 freqtrade-2024.5/freqtrade/templates/
+-rw-r--r--   0 runner    (1001) docker     (127)    12832 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/FreqaiExampleHybridStrategy.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11556 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/FreqaiExampleStrategy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2149 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/base_config.json.j2
+-rw-r--r--   0 runner    (1001) docker     (127)     5903 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/base_strategy.py.j2
+-rw-r--r--   0 runner    (1001) docker     (127)     1895 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/sample_hyperopt_loss.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16795 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/sample_strategy.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14243 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_analysis_example.ipynb
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.567097 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/
+-rw-r--r--   0 runner    (1001) docker     (127)      261 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/buy_trend_full.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      101 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/buy_trend_minimal.j2
+-rw-r--r--   0 runner    (1001) docker     (127)     7747 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/indicators_full.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      464 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/indicators_minimal.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      506 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/plot_config_full.j2
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/plot_config_minimal.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      262 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/sell_trend_full.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      103 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/sell_trend_minimal.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      249 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/strategy_attributes_full.j2
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/strategy_attributes_minimal.j2
+-rw-r--r--   0 runner    (1001) docker     (127)    16125 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/strategy_methods_advanced.j2
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/strategy_methods_empty.j2
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.567097 freqtrade-2024.5/freqtrade/templates/subtemplates/
+-rw-r--r--   0 runner    (1001) docker     (127)      261 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_binance.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      397 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_bittrex.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      271 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_gateio.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      244 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_generic.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      260 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_huobi.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      249 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_kraken.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      291 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_kucoin.j2
+-rw-r--r--   0 runner    (1001) docker     (127)      291 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/templates/subtemplates/exchange_okex.j2
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.567097 freqtrade-2024.5/freqtrade/types/
+-rw-r--r--   0 runner    (1001) docker     (127)      258 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/types/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      736 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/types/backtest_result_type.py
+-rw-r--r--   0 runner    (1001) docker     (127)      311 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/types/valid_exchanges_type.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.571097 freqtrade-2024.5/freqtrade/util/
+-rw-r--r--   0 runner    (1001) docker     (127)      894 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      901 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/coin_gecko.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2760 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/datetime_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1647 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/formatters.py
+-rw-r--r--   0 runner    (1001) docker     (127)      338 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/ft_precise.py
+-rw-r--r--   0 runner    (1001) docker     (127)      458 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/gc_setup.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1314 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/measure_time.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.571097 freqtrade-2024.5/freqtrade/util/migrations/
+-rw-r--r--   0 runner    (1001) docker     (127)      392 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/migrations/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2653 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/migrations/binance_mig.py
+-rw-r--r--   0 runner    (1001) docker     (127)      798 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/migrations/funding_rate_mig.py
+-rw-r--r--   0 runner    (1001) docker     (127)      578 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/periodic_cache.py
+-rw-r--r--   0 runner    (1001) docker     (127)      962 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/util/template_renderer.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.571097 freqtrade-2024.5/freqtrade/vendor/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/vendor/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.571097 freqtrade-2024.5/freqtrade/vendor/qtpylib/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/vendor/qtpylib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19687 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/vendor/qtpylib/indicators.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14951 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/wallets.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8504 2024-05-30 16:45:37.000000 freqtrade-2024.5/freqtrade/worker.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-30 16:45:41.571097 freqtrade-2024.5/freqtrade.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (127)    18271 2024-05-30 16:45:41.000000 freqtrade-2024.5/freqtrade.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)    13245 2024-05-30 16:45:41.000000 freqtrade-2024.5/freqtrade.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-30 16:45:41.000000 freqtrade-2024.5/freqtrade.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       50 2024-05-30 16:45:41.000000 freqtrade-2024.5/freqtrade.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-30 16:45:41.000000 freqtrade-2024.5/freqtrade.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (127)     1801 2024-05-30 16:45:41.000000 freqtrade-2024.5/freqtrade.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       10 2024-05-30 16:45:41.000000 freqtrade-2024.5/freqtrade.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (127)     4311 2024-05-30 16:45:37.000000 freqtrade-2024.5/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (127)       38 2024-05-30 16:45:41.579097 freqtrade-2024.5/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (127)     2434 2024-05-30 16:45:37.000000 freqtrade-2024.5/setup.py
```

### Comparing `freqtrade-2024.4/LICENSE` & `freqtrade-2024.5/LICENSE`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/PKG-INFO` & `freqtrade-2024.5/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: freqtrade
-Version: 2024.4
+Version: 2024.5
 Summary: Freqtrade - Crypto Trading Bot
 Home-page: https://github.com/freqtrade/freqtrade
 Author: Freqtrade Team
 Author-email: Freqtrade Team <freqtrade@protonmail.com>
 License: GPLv3
 Project-URL: Homepage, https://github.com/freqtrade/freqtrade
 Project-URL: Documentation, https://freqtrade.io
@@ -18,15 +18,15 @@
 Classifier: Programming Language :: Python :: 3.12
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: Unix
 Classifier: Topic :: Office/Business :: Financial :: Investment
 Requires-Python: >=3.9
 Description-Content-Type: text/markdown
 License-File: LICENSE
-Requires-Dist: ccxt>=4.2.47
+Requires-Dist: ccxt>=4.3.24
 Requires-Dist: SQLAlchemy>=2.0.6
 Requires-Dist: python-telegram-bot>=20.1
 Requires-Dist: humanize>=4.0.0
 Requires-Dist: cachetools
 Requires-Dist: requests
 Requires-Dist: httpx>=0.24.1
 Requires-Dist: urllib3
@@ -200,14 +200,15 @@
 
 ## Supported Exchange marketplaces
 
 Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.
 
 - [X] [Binance](https://www.binance.com/)
 - [X] [Bitmart](https://bitmart.com/)
+- [X] [BingX](https://bingx.com/invite/0EM9RX)
 - [X] [Gate.io](https://www.gate.io/ref/6266643)
 - [X] [HTX](https://www.htx.com/) (Former Huobi)
 - [X] [Kraken](https://kraken.com/)
 - [X] [OKX](https://okx.com/) (Former OKEX)
 - [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_
 
 ### Supported Futures Exchanges (experimental)
```

### Comparing `freqtrade-2024.4/README.md` & `freqtrade-2024.5/README.md`

 * *Files 1% similar despite different names*

```diff
@@ -25,14 +25,15 @@
 
 ## Supported Exchange marketplaces
 
 Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.
 
 - [X] [Binance](https://www.binance.com/)
 - [X] [Bitmart](https://bitmart.com/)
+- [X] [BingX](https://bingx.com/invite/0EM9RX)
 - [X] [Gate.io](https://www.gate.io/ref/6266643)
 - [X] [HTX](https://www.htx.com/) (Former Huobi)
 - [X] [Kraken](https://kraken.com/)
 - [X] [OKX](https://okx.com/) (Former OKEX)
 - [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_
 
 ### Supported Futures Exchanges (experimental)
```

### Comparing `freqtrade-2024.4/freqtrade/__init__.py` & `freqtrade-2024.5/freqtrade/__init__.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,22 +1,34 @@
-""" Freqtrade bot """
-__version__ = '2024.4'
+"""Freqtrade bot"""
 
-if 'dev' in __version__:
+__version__ = "2024.5"
+
+if "dev" in __version__:
     from pathlib import Path
+
     try:
         import subprocess
+
         freqtrade_basedir = Path(__file__).parent
 
-        __version__ = __version__ + '-' + subprocess.check_output(
-            ['git', 'log', '--format="%h"', '-n 1'],
-            stderr=subprocess.DEVNULL, cwd=freqtrade_basedir).decode("utf-8").rstrip().strip('"')
+        __version__ = (
+            __version__
+            + "-"
+            + subprocess.check_output(
+                ["git", "log", '--format="%h"', "-n 1"],
+                stderr=subprocess.DEVNULL,
+                cwd=freqtrade_basedir,
+            )
+            .decode("utf-8")
+            .rstrip()
+            .strip('"')
+        )
 
     except Exception:  # pragma: no cover
         # git not available, ignore
         try:
             # Try Fallback to freqtrade_commit file (created by CI while building docker image)
-            versionfile = Path('./freqtrade_commit')
+            versionfile = Path("./freqtrade_commit")
             if versionfile.is_file():
                 __version__ = f"docker-{__version__}-{versionfile.read_text()[:8]}"
         except Exception:
             pass
```

### Comparing `freqtrade-2024.4/freqtrade/commands/analyze_commands.py` & `freqtrade-2024.5/freqtrade/commands/analyze_commands.py`

 * *Files 9% similar despite different names*

```diff
@@ -16,33 +16,33 @@
     :param args: Cli args from Arguments()
     :param method: Bot running mode
     :return: Configuration
     """
     config = setup_utils_configuration(args, method)
 
     no_unlimited_runmodes = {
-        RunMode.BACKTEST: 'backtesting',
+        RunMode.BACKTEST: "backtesting",
     }
     if method in no_unlimited_runmodes.keys():
         from freqtrade.data.btanalysis import get_latest_backtest_filename
 
-        if 'exportfilename' in config:
-            if config['exportfilename'].is_dir():
-                btfile = Path(get_latest_backtest_filename(config['exportfilename']))
+        if "exportfilename" in config:
+            if config["exportfilename"].is_dir():
+                btfile = Path(get_latest_backtest_filename(config["exportfilename"]))
                 signals_file = f"{config['exportfilename']}/{btfile.stem}_signals.pkl"
             else:
-                if config['exportfilename'].exists():
-                    btfile = Path(config['exportfilename'])
+                if config["exportfilename"].exists():
+                    btfile = Path(config["exportfilename"])
                     signals_file = f"{btfile.parent}/{btfile.stem}_signals.pkl"
                 else:
                     raise ConfigurationError(f"{config['exportfilename']} does not exist.")
         else:
-            raise ConfigurationError('exportfilename not in config.')
+            raise ConfigurationError("exportfilename not in config.")
 
-        if (not Path(signals_file).exists()):
+        if not Path(signals_file).exists():
             raise OperationalException(
                 f"Cannot find latest backtest signals file: {signals_file}."
                 "Run backtesting with `--export signals`."
             )
 
     return config
 
@@ -54,10 +54,10 @@
     :return: None
     """
     from freqtrade.data.entryexitanalysis import process_entry_exit_reasons
 
     # Initialize configuration
     config = setup_analyze_configuration(args, RunMode.BACKTEST)
 
-    logger.info('Starting freqtrade in analysis mode')
+    logger.info("Starting freqtrade in analysis mode")
 
     process_entry_exit_reasons(config)
```

### Comparing `freqtrade-2024.4/freqtrade/commands/arguments.py` & `freqtrade-2024.5/freqtrade/commands/arguments.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,132 +1,262 @@
 """
 This module contains the argument manager class
 """
+
 import argparse
 from functools import partial
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 from freqtrade.commands.cli_options import AVAILABLE_CLI_OPTIONS
 from freqtrade.constants import DEFAULT_CONFIG
 
 
 ARGS_COMMON = ["verbosity", "logfile", "version", "config", "datadir", "user_data_dir"]
 
-ARGS_STRATEGY = ["strategy", "strategy_path", "recursive_strategy_search", "freqaimodel",
-                 "freqaimodel_path"]
+ARGS_STRATEGY = [
+    "strategy",
+    "strategy_path",
+    "recursive_strategy_search",
+    "freqaimodel",
+    "freqaimodel_path",
+]
 
 ARGS_TRADE = ["db_url", "sd_notify", "dry_run", "dry_run_wallet", "fee"]
 
 ARGS_WEBSERVER: List[str] = []
 
-ARGS_COMMON_OPTIMIZE = ["timeframe", "timerange", "dataformat_ohlcv",
-                        "max_open_trades", "stake_amount", "fee", "pairs"]
-
-ARGS_BACKTEST = ARGS_COMMON_OPTIMIZE + ["position_stacking", "use_max_market_positions",
-                                        "enable_protections", "dry_run_wallet", "timeframe_detail",
-                                        "strategy_list", "export", "exportfilename",
-                                        "backtest_breakdown", "backtest_cache",
-                                        "freqai_backtest_live_models"]
-
-ARGS_HYPEROPT = ARGS_COMMON_OPTIMIZE + ["hyperopt", "hyperopt_path",
-                                        "position_stacking", "use_max_market_positions",
-                                        "enable_protections", "dry_run_wallet", "timeframe_detail",
-                                        "epochs", "spaces", "print_all",
-                                        "print_colorized", "print_json", "hyperopt_jobs",
-                                        "hyperopt_random_state", "hyperopt_min_trades",
-                                        "hyperopt_loss", "disableparamexport",
-                                        "hyperopt_ignore_missing_space", "analyze_per_epoch"]
+ARGS_COMMON_OPTIMIZE = [
+    "timeframe",
+    "timerange",
+    "dataformat_ohlcv",
+    "max_open_trades",
+    "stake_amount",
+    "fee",
+    "pairs",
+]
+
+ARGS_BACKTEST = ARGS_COMMON_OPTIMIZE + [
+    "position_stacking",
+    "use_max_market_positions",
+    "enable_protections",
+    "dry_run_wallet",
+    "timeframe_detail",
+    "strategy_list",
+    "export",
+    "exportfilename",
+    "backtest_breakdown",
+    "backtest_cache",
+    "freqai_backtest_live_models",
+]
+
+ARGS_HYPEROPT = ARGS_COMMON_OPTIMIZE + [
+    "hyperopt",
+    "hyperopt_path",
+    "position_stacking",
+    "use_max_market_positions",
+    "enable_protections",
+    "dry_run_wallet",
+    "timeframe_detail",
+    "epochs",
+    "spaces",
+    "print_all",
+    "print_colorized",
+    "print_json",
+    "hyperopt_jobs",
+    "hyperopt_random_state",
+    "hyperopt_min_trades",
+    "hyperopt_loss",
+    "disableparamexport",
+    "hyperopt_ignore_missing_space",
+    "analyze_per_epoch",
+]
 
 ARGS_EDGE = ARGS_COMMON_OPTIMIZE + ["stoploss_range"]
 
-ARGS_LIST_STRATEGIES = ["strategy_path", "print_one_column", "print_colorized",
-                        "recursive_strategy_search"]
+ARGS_LIST_STRATEGIES = [
+    "strategy_path",
+    "print_one_column",
+    "print_colorized",
+    "recursive_strategy_search",
+]
 
 ARGS_LIST_FREQAIMODELS = ["freqaimodel_path", "print_one_column", "print_colorized"]
 
 ARGS_LIST_HYPEROPTS = ["hyperopt_path", "print_one_column", "print_colorized"]
 
 ARGS_BACKTEST_SHOW = ["exportfilename", "backtest_show_pair_list", "backtest_breakdown"]
 
 ARGS_LIST_EXCHANGES = ["print_one_column", "list_exchanges_all"]
 
 ARGS_LIST_TIMEFRAMES = ["exchange", "print_one_column"]
 
-ARGS_LIST_PAIRS = ["exchange", "print_list", "list_pairs_print_json", "print_one_column",
-                   "print_csv", "base_currencies", "quote_currencies", "list_pairs_all",
-                   "trading_mode"]
-
-ARGS_TEST_PAIRLIST = ["user_data_dir", "verbosity", "config", "quote_currencies",
-                      "print_one_column", "list_pairs_print_json", "exchange"]
+ARGS_LIST_PAIRS = [
+    "exchange",
+    "print_list",
+    "list_pairs_print_json",
+    "print_one_column",
+    "print_csv",
+    "base_currencies",
+    "quote_currencies",
+    "list_pairs_all",
+    "trading_mode",
+]
+
+ARGS_TEST_PAIRLIST = [
+    "user_data_dir",
+    "verbosity",
+    "config",
+    "quote_currencies",
+    "print_one_column",
+    "list_pairs_print_json",
+    "exchange",
+]
 
 ARGS_CREATE_USERDIR = ["user_data_dir", "reset"]
 
 ARGS_BUILD_CONFIG = ["config"]
 ARGS_SHOW_CONFIG = ["user_data_dir", "config", "show_sensitive"]
 
 ARGS_BUILD_STRATEGY = ["user_data_dir", "strategy", "template"]
 
 ARGS_CONVERT_DATA_TRADES = ["pairs", "format_from_trades", "format_to", "erase", "exchange"]
 ARGS_CONVERT_DATA = ["pairs", "format_from", "format_to", "erase", "exchange"]
 ARGS_CONVERT_DATA_OHLCV = ARGS_CONVERT_DATA + ["timeframes", "trading_mode", "candle_types"]
 
-ARGS_CONVERT_TRADES = ["pairs", "timeframes", "exchange", "dataformat_ohlcv", "dataformat_trades",
-                       "trading_mode"]
+ARGS_CONVERT_TRADES = [
+    "pairs",
+    "timeframes",
+    "exchange",
+    "dataformat_ohlcv",
+    "dataformat_trades",
+    "trading_mode",
+]
 
 ARGS_LIST_DATA = ["exchange", "dataformat_ohlcv", "pairs", "trading_mode", "show_timerange"]
 
-ARGS_DOWNLOAD_DATA = ["pairs", "pairs_file", "days", "new_pairs_days", "include_inactive",
-                      "timerange", "download_trades", "exchange", "timeframes",
-                      "erase", "dataformat_ohlcv", "dataformat_trades", "trading_mode",
-                      "prepend_data"]
-
-ARGS_PLOT_DATAFRAME = ["pairs", "indicators1", "indicators2", "plot_limit",
-                       "db_url", "trade_source", "export", "exportfilename",
-                       "timerange", "timeframe", "no_trades"]
-
-ARGS_PLOT_PROFIT = ["pairs", "timerange", "export", "exportfilename", "db_url",
-                    "trade_source", "timeframe", "plot_auto_open", ]
+ARGS_DOWNLOAD_DATA = [
+    "pairs",
+    "pairs_file",
+    "days",
+    "new_pairs_days",
+    "include_inactive",
+    "timerange",
+    "download_trades",
+    "convert_trades",
+    "exchange",
+    "timeframes",
+    "erase",
+    "dataformat_ohlcv",
+    "dataformat_trades",
+    "trading_mode",
+    "prepend_data",
+]
+
+ARGS_PLOT_DATAFRAME = [
+    "pairs",
+    "indicators1",
+    "indicators2",
+    "plot_limit",
+    "db_url",
+    "trade_source",
+    "export",
+    "exportfilename",
+    "timerange",
+    "timeframe",
+    "no_trades",
+]
+
+ARGS_PLOT_PROFIT = [
+    "pairs",
+    "timerange",
+    "export",
+    "exportfilename",
+    "db_url",
+    "trade_source",
+    "timeframe",
+    "plot_auto_open",
+]
 
 ARGS_CONVERT_DB = ["db_url", "db_url_from"]
 
 ARGS_INSTALL_UI = ["erase_ui_only", "ui_version"]
 
 ARGS_SHOW_TRADES = ["db_url", "trade_ids", "print_json"]
 
-ARGS_HYPEROPT_LIST = ["hyperopt_list_best", "hyperopt_list_profitable",
-                      "hyperopt_list_min_trades", "hyperopt_list_max_trades",
-                      "hyperopt_list_min_avg_time", "hyperopt_list_max_avg_time",
-                      "hyperopt_list_min_avg_profit", "hyperopt_list_max_avg_profit",
-                      "hyperopt_list_min_total_profit", "hyperopt_list_max_total_profit",
-                      "hyperopt_list_min_objective", "hyperopt_list_max_objective",
-                      "print_colorized", "print_json", "hyperopt_list_no_details",
-                      "hyperoptexportfilename", "export_csv"]
-
-ARGS_HYPEROPT_SHOW = ["hyperopt_list_best", "hyperopt_list_profitable", "hyperopt_show_index",
-                      "print_json", "hyperoptexportfilename", "hyperopt_show_no_header",
-                      "disableparamexport", "backtest_breakdown"]
-
-ARGS_ANALYZE_ENTRIES_EXITS = ["exportfilename", "analysis_groups", "enter_reason_list",
-                              "exit_reason_list", "indicator_list", "timerange",
-                              "analysis_rejected", "analysis_to_csv", "analysis_csv_path"]
-
-NO_CONF_REQURIED = ["convert-data", "convert-trade-data", "download-data", "list-timeframes",
-                    "list-markets", "list-pairs", "list-strategies", "list-freqaimodels",
-                    "list-data", "hyperopt-list", "hyperopt-show", "backtest-filter",
-                    "plot-dataframe", "plot-profit", "show-trades", "trades-to-ohlcv",
-                    "strategy-updater"]
+ARGS_HYPEROPT_LIST = [
+    "hyperopt_list_best",
+    "hyperopt_list_profitable",
+    "hyperopt_list_min_trades",
+    "hyperopt_list_max_trades",
+    "hyperopt_list_min_avg_time",
+    "hyperopt_list_max_avg_time",
+    "hyperopt_list_min_avg_profit",
+    "hyperopt_list_max_avg_profit",
+    "hyperopt_list_min_total_profit",
+    "hyperopt_list_max_total_profit",
+    "hyperopt_list_min_objective",
+    "hyperopt_list_max_objective",
+    "print_colorized",
+    "print_json",
+    "hyperopt_list_no_details",
+    "hyperoptexportfilename",
+    "export_csv",
+]
+
+ARGS_HYPEROPT_SHOW = [
+    "hyperopt_list_best",
+    "hyperopt_list_profitable",
+    "hyperopt_show_index",
+    "print_json",
+    "hyperoptexportfilename",
+    "hyperopt_show_no_header",
+    "disableparamexport",
+    "backtest_breakdown",
+]
+
+ARGS_ANALYZE_ENTRIES_EXITS = [
+    "exportfilename",
+    "analysis_groups",
+    "enter_reason_list",
+    "exit_reason_list",
+    "indicator_list",
+    "timerange",
+    "analysis_rejected",
+    "analysis_to_csv",
+    "analysis_csv_path",
+]
+
+NO_CONF_REQURIED = [
+    "convert-data",
+    "convert-trade-data",
+    "download-data",
+    "list-timeframes",
+    "list-markets",
+    "list-pairs",
+    "list-strategies",
+    "list-freqaimodels",
+    "list-data",
+    "hyperopt-list",
+    "hyperopt-show",
+    "backtest-filter",
+    "plot-dataframe",
+    "plot-profit",
+    "show-trades",
+    "trades-to-ohlcv",
+    "strategy-updater",
+]
 
 NO_CONF_ALLOWED = ["create-userdir", "list-exchanges", "new-strategy"]
 
 ARGS_STRATEGY_UPDATER = ["strategy_list", "strategy_path", "recursive_strategy_search"]
 
 ARGS_LOOKAHEAD_ANALYSIS = [
-    a for a in ARGS_BACKTEST if a not in ("position_stacking", "use_max_market_positions", 'cache')
-    ] + ["minimum_trade_amount", "targeted_trade_amount", "lookahead_analysis_exportfilename"]
+    a for a in ARGS_BACKTEST if a not in ("position_stacking", "use_max_market_positions", "cache")
+] + ["minimum_trade_amount", "targeted_trade_amount", "lookahead_analysis_exportfilename"]
 
 ARGS_RECURSIVE_ANALYSIS = ["timeframe", "timerange", "dataformat_ohlcv", "pairs", "startup_candle"]
 
 
 class Arguments:
     """
     Arguments Class. Manage the arguments received by the cli
@@ -152,36 +282,35 @@
         Parses given arguments and returns an argparse Namespace instance.
         """
         parsed_arg = self.parser.parse_args(self.args)
 
         # Workaround issue in argparse with action='append' and default value
         # (see https://bugs.python.org/issue16399)
         # Allow no-config for certain commands (like downloading / plotting)
-        if ('config' in parsed_arg and parsed_arg.config is None):
-            conf_required = ('command' in parsed_arg and parsed_arg.command in NO_CONF_REQURIED)
+        if "config" in parsed_arg and parsed_arg.config is None:
+            conf_required = "command" in parsed_arg and parsed_arg.command in NO_CONF_REQURIED
 
-            if 'user_data_dir' in parsed_arg and parsed_arg.user_data_dir is not None:
+            if "user_data_dir" in parsed_arg and parsed_arg.user_data_dir is not None:
                 user_dir = parsed_arg.user_data_dir
             else:
                 # Default case
-                user_dir = 'user_data'
+                user_dir = "user_data"
                 # Try loading from "user_data/config.json"
             cfgfile = Path(user_dir) / DEFAULT_CONFIG
             if cfgfile.is_file():
                 parsed_arg.config = [str(cfgfile)]
             else:
                 # Else use "config.json".
                 cfgfile = Path.cwd() / DEFAULT_CONFIG
                 if cfgfile.is_file() or not conf_required:
                     parsed_arg.config = [DEFAULT_CONFIG]
 
         return parsed_arg
 
     def _build_args(self, optionlist, parser):
-
         for val in optionlist:
             opt = AVAILABLE_CLI_OPTIONS[val]
             parser.add_argument(*opt.cli, dest=val, **opt.kwargs)
 
     def _build_subcommands(self) -> None:
         """
         Builds and attaches all subcommands.
@@ -194,325 +323,333 @@
 
         _strategy_parser = argparse.ArgumentParser(add_help=False)
         strategy_group = _strategy_parser.add_argument_group("Strategy arguments")
         self._build_args(optionlist=ARGS_STRATEGY, parser=strategy_group)
 
         # Build main command
         self.parser = argparse.ArgumentParser(
-            prog="freqtrade",
-            description='Free, open source crypto trading bot'
+            prog="freqtrade", description="Free, open source crypto trading bot"
         )
-        self._build_args(optionlist=['version'], parser=self.parser)
+        self._build_args(optionlist=["version"], parser=self.parser)
 
-        from freqtrade.commands import (start_analysis_entries_exits, start_backtesting,
-                                        start_backtesting_show, start_convert_data,
-                                        start_convert_db, start_convert_trades,
-                                        start_create_userdir, start_download_data, start_edge,
-                                        start_hyperopt, start_hyperopt_list, start_hyperopt_show,
-                                        start_install_ui, start_list_data, start_list_exchanges,
-                                        start_list_freqAI_models, start_list_markets,
-                                        start_list_strategies, start_list_timeframes,
-                                        start_lookahead_analysis, start_new_config,
-                                        start_new_strategy, start_plot_dataframe, start_plot_profit,
-                                        start_recursive_analysis, start_show_config,
-                                        start_show_trades, start_strategy_update,
-                                        start_test_pairlist, start_trading, start_webserver)
-
-        subparsers = self.parser.add_subparsers(dest='command',
-                                                # Use custom message when no subhandler is added
-                                                # shown from `main.py`
-                                                # required=True
-                                                )
+        from freqtrade.commands import (
+            start_analysis_entries_exits,
+            start_backtesting,
+            start_backtesting_show,
+            start_convert_data,
+            start_convert_db,
+            start_convert_trades,
+            start_create_userdir,
+            start_download_data,
+            start_edge,
+            start_hyperopt,
+            start_hyperopt_list,
+            start_hyperopt_show,
+            start_install_ui,
+            start_list_data,
+            start_list_exchanges,
+            start_list_freqAI_models,
+            start_list_markets,
+            start_list_strategies,
+            start_list_timeframes,
+            start_lookahead_analysis,
+            start_new_config,
+            start_new_strategy,
+            start_plot_dataframe,
+            start_plot_profit,
+            start_recursive_analysis,
+            start_show_config,
+            start_show_trades,
+            start_strategy_update,
+            start_test_pairlist,
+            start_trading,
+            start_webserver,
+        )
+
+        subparsers = self.parser.add_subparsers(
+            dest="command",
+            # Use custom message when no subhandler is added
+            # shown from `main.py`
+            # required=True
+        )
 
         # Add trade subcommand
         trade_cmd = subparsers.add_parser(
-            'trade',
-            help='Trade module.',
-            parents=[_common_parser, _strategy_parser]
+            "trade", help="Trade module.", parents=[_common_parser, _strategy_parser]
         )
         trade_cmd.set_defaults(func=start_trading)
         self._build_args(optionlist=ARGS_TRADE, parser=trade_cmd)
 
         # add create-userdir subcommand
         create_userdir_cmd = subparsers.add_parser(
-            'create-userdir',
+            "create-userdir",
             help="Create user-data directory.",
         )
         create_userdir_cmd.set_defaults(func=start_create_userdir)
         self._build_args(optionlist=ARGS_CREATE_USERDIR, parser=create_userdir_cmd)
 
         # add new-config subcommand
         build_config_cmd = subparsers.add_parser(
-            'new-config',
+            "new-config",
             help="Create new config",
         )
         build_config_cmd.set_defaults(func=start_new_config)
         self._build_args(optionlist=ARGS_BUILD_CONFIG, parser=build_config_cmd)
 
         # add show-config subcommand
         show_config_cmd = subparsers.add_parser(
-            'show-config',
+            "show-config",
             help="Show resolved config",
         )
         show_config_cmd.set_defaults(func=start_show_config)
         self._build_args(optionlist=ARGS_SHOW_CONFIG, parser=show_config_cmd)
 
         # add new-strategy subcommand
         build_strategy_cmd = subparsers.add_parser(
-            'new-strategy',
+            "new-strategy",
             help="Create new strategy",
         )
         build_strategy_cmd.set_defaults(func=start_new_strategy)
         self._build_args(optionlist=ARGS_BUILD_STRATEGY, parser=build_strategy_cmd)
 
         # Add download-data subcommand
         download_data_cmd = subparsers.add_parser(
-            'download-data',
-            help='Download backtesting data.',
+            "download-data",
+            help="Download backtesting data.",
             parents=[_common_parser],
         )
         download_data_cmd.set_defaults(func=start_download_data)
         self._build_args(optionlist=ARGS_DOWNLOAD_DATA, parser=download_data_cmd)
 
         # Add convert-data subcommand
         convert_data_cmd = subparsers.add_parser(
-            'convert-data',
-            help='Convert candle (OHLCV) data from one format to another.',
+            "convert-data",
+            help="Convert candle (OHLCV) data from one format to another.",
             parents=[_common_parser],
         )
         convert_data_cmd.set_defaults(func=partial(start_convert_data, ohlcv=True))
         self._build_args(optionlist=ARGS_CONVERT_DATA_OHLCV, parser=convert_data_cmd)
 
         # Add convert-trade-data subcommand
         convert_trade_data_cmd = subparsers.add_parser(
-            'convert-trade-data',
-            help='Convert trade data from one format to another.',
+            "convert-trade-data",
+            help="Convert trade data from one format to another.",
             parents=[_common_parser],
         )
         convert_trade_data_cmd.set_defaults(func=partial(start_convert_data, ohlcv=False))
         self._build_args(optionlist=ARGS_CONVERT_DATA_TRADES, parser=convert_trade_data_cmd)
 
         # Add trades-to-ohlcv subcommand
         convert_trade_data_cmd = subparsers.add_parser(
-            'trades-to-ohlcv',
-            help='Convert trade data to OHLCV data.',
+            "trades-to-ohlcv",
+            help="Convert trade data to OHLCV data.",
             parents=[_common_parser],
         )
         convert_trade_data_cmd.set_defaults(func=start_convert_trades)
         self._build_args(optionlist=ARGS_CONVERT_TRADES, parser=convert_trade_data_cmd)
 
         # Add list-data subcommand
         list_data_cmd = subparsers.add_parser(
-            'list-data',
-            help='List downloaded data.',
+            "list-data",
+            help="List downloaded data.",
             parents=[_common_parser],
         )
         list_data_cmd.set_defaults(func=start_list_data)
         self._build_args(optionlist=ARGS_LIST_DATA, parser=list_data_cmd)
 
         # Add backtesting subcommand
         backtesting_cmd = subparsers.add_parser(
-            'backtesting',
-            help='Backtesting module.',
-            parents=[_common_parser, _strategy_parser]
+            "backtesting", help="Backtesting module.", parents=[_common_parser, _strategy_parser]
         )
         backtesting_cmd.set_defaults(func=start_backtesting)
         self._build_args(optionlist=ARGS_BACKTEST, parser=backtesting_cmd)
 
         # Add backtesting-show subcommand
         backtesting_show_cmd = subparsers.add_parser(
-            'backtesting-show',
-            help='Show past Backtest results',
+            "backtesting-show",
+            help="Show past Backtest results",
             parents=[_common_parser],
         )
         backtesting_show_cmd.set_defaults(func=start_backtesting_show)
         self._build_args(optionlist=ARGS_BACKTEST_SHOW, parser=backtesting_show_cmd)
 
         # Add backtesting analysis subcommand
         analysis_cmd = subparsers.add_parser(
-            'backtesting-analysis',
-            help='Backtest Analysis module.',
-            parents=[_common_parser]
+            "backtesting-analysis", help="Backtest Analysis module.", parents=[_common_parser]
         )
         analysis_cmd.set_defaults(func=start_analysis_entries_exits)
         self._build_args(optionlist=ARGS_ANALYZE_ENTRIES_EXITS, parser=analysis_cmd)
 
         # Add edge subcommand
         edge_cmd = subparsers.add_parser(
-            'edge',
-            help='Edge module.',
-            parents=[_common_parser, _strategy_parser]
+            "edge", help="Edge module.", parents=[_common_parser, _strategy_parser]
         )
         edge_cmd.set_defaults(func=start_edge)
         self._build_args(optionlist=ARGS_EDGE, parser=edge_cmd)
 
         # Add hyperopt subcommand
         hyperopt_cmd = subparsers.add_parser(
-            'hyperopt',
-            help='Hyperopt module.',
+            "hyperopt",
+            help="Hyperopt module.",
             parents=[_common_parser, _strategy_parser],
         )
         hyperopt_cmd.set_defaults(func=start_hyperopt)
         self._build_args(optionlist=ARGS_HYPEROPT, parser=hyperopt_cmd)
 
         # Add hyperopt-list subcommand
         hyperopt_list_cmd = subparsers.add_parser(
-            'hyperopt-list',
-            help='List Hyperopt results',
+            "hyperopt-list",
+            help="List Hyperopt results",
             parents=[_common_parser],
         )
         hyperopt_list_cmd.set_defaults(func=start_hyperopt_list)
         self._build_args(optionlist=ARGS_HYPEROPT_LIST, parser=hyperopt_list_cmd)
 
         # Add hyperopt-show subcommand
         hyperopt_show_cmd = subparsers.add_parser(
-            'hyperopt-show',
-            help='Show details of Hyperopt results',
+            "hyperopt-show",
+            help="Show details of Hyperopt results",
             parents=[_common_parser],
         )
         hyperopt_show_cmd.set_defaults(func=start_hyperopt_show)
         self._build_args(optionlist=ARGS_HYPEROPT_SHOW, parser=hyperopt_show_cmd)
 
         # Add list-exchanges subcommand
         list_exchanges_cmd = subparsers.add_parser(
-            'list-exchanges',
-            help='Print available exchanges.',
+            "list-exchanges",
+            help="Print available exchanges.",
             parents=[_common_parser],
         )
         list_exchanges_cmd.set_defaults(func=start_list_exchanges)
         self._build_args(optionlist=ARGS_LIST_EXCHANGES, parser=list_exchanges_cmd)
 
         # Add list-markets subcommand
         list_markets_cmd = subparsers.add_parser(
-            'list-markets',
-            help='Print markets on exchange.',
+            "list-markets",
+            help="Print markets on exchange.",
             parents=[_common_parser],
         )
         list_markets_cmd.set_defaults(func=partial(start_list_markets, pairs_only=False))
         self._build_args(optionlist=ARGS_LIST_PAIRS, parser=list_markets_cmd)
 
         # Add list-pairs subcommand
         list_pairs_cmd = subparsers.add_parser(
-            'list-pairs',
-            help='Print pairs on exchange.',
+            "list-pairs",
+            help="Print pairs on exchange.",
             parents=[_common_parser],
         )
         list_pairs_cmd.set_defaults(func=partial(start_list_markets, pairs_only=True))
         self._build_args(optionlist=ARGS_LIST_PAIRS, parser=list_pairs_cmd)
 
         # Add list-strategies subcommand
         list_strategies_cmd = subparsers.add_parser(
-            'list-strategies',
-            help='Print available strategies.',
+            "list-strategies",
+            help="Print available strategies.",
             parents=[_common_parser],
         )
         list_strategies_cmd.set_defaults(func=start_list_strategies)
         self._build_args(optionlist=ARGS_LIST_STRATEGIES, parser=list_strategies_cmd)
 
         # Add list-freqAI Models subcommand
         list_freqaimodels_cmd = subparsers.add_parser(
-            'list-freqaimodels',
-            help='Print available freqAI models.',
+            "list-freqaimodels",
+            help="Print available freqAI models.",
             parents=[_common_parser],
         )
         list_freqaimodels_cmd.set_defaults(func=start_list_freqAI_models)
         self._build_args(optionlist=ARGS_LIST_FREQAIMODELS, parser=list_freqaimodels_cmd)
 
         # Add list-timeframes subcommand
         list_timeframes_cmd = subparsers.add_parser(
-            'list-timeframes',
-            help='Print available timeframes for the exchange.',
+            "list-timeframes",
+            help="Print available timeframes for the exchange.",
             parents=[_common_parser],
         )
         list_timeframes_cmd.set_defaults(func=start_list_timeframes)
         self._build_args(optionlist=ARGS_LIST_TIMEFRAMES, parser=list_timeframes_cmd)
 
         # Add show-trades subcommand
         show_trades = subparsers.add_parser(
-            'show-trades',
-            help='Show trades.',
+            "show-trades",
+            help="Show trades.",
             parents=[_common_parser],
         )
         show_trades.set_defaults(func=start_show_trades)
         self._build_args(optionlist=ARGS_SHOW_TRADES, parser=show_trades)
 
         # Add test-pairlist subcommand
         test_pairlist_cmd = subparsers.add_parser(
-            'test-pairlist',
-            help='Test your pairlist configuration.',
+            "test-pairlist",
+            help="Test your pairlist configuration.",
         )
         test_pairlist_cmd.set_defaults(func=start_test_pairlist)
         self._build_args(optionlist=ARGS_TEST_PAIRLIST, parser=test_pairlist_cmd)
 
         # Add db-convert subcommand
         convert_db = subparsers.add_parser(
             "convert-db",
             help="Migrate database to different system",
         )
         convert_db.set_defaults(func=start_convert_db)
         self._build_args(optionlist=ARGS_CONVERT_DB, parser=convert_db)
 
         # Add install-ui subcommand
         install_ui_cmd = subparsers.add_parser(
-            'install-ui',
-            help='Install FreqUI',
+            "install-ui",
+            help="Install FreqUI",
         )
         install_ui_cmd.set_defaults(func=start_install_ui)
         self._build_args(optionlist=ARGS_INSTALL_UI, parser=install_ui_cmd)
 
         # Add Plotting subcommand
         plot_dataframe_cmd = subparsers.add_parser(
-            'plot-dataframe',
-            help='Plot candles with indicators.',
+            "plot-dataframe",
+            help="Plot candles with indicators.",
             parents=[_common_parser, _strategy_parser],
         )
         plot_dataframe_cmd.set_defaults(func=start_plot_dataframe)
         self._build_args(optionlist=ARGS_PLOT_DATAFRAME, parser=plot_dataframe_cmd)
 
         # Plot profit
         plot_profit_cmd = subparsers.add_parser(
-            'plot-profit',
-            help='Generate plot showing profits.',
+            "plot-profit",
+            help="Generate plot showing profits.",
             parents=[_common_parser, _strategy_parser],
         )
         plot_profit_cmd.set_defaults(func=start_plot_profit)
         self._build_args(optionlist=ARGS_PLOT_PROFIT, parser=plot_profit_cmd)
 
         # Add webserver subcommand
         webserver_cmd = subparsers.add_parser(
-            'webserver',
-            help='Webserver module.',
-            parents=[_common_parser]
+            "webserver", help="Webserver module.", parents=[_common_parser]
         )
         webserver_cmd.set_defaults(func=start_webserver)
         self._build_args(optionlist=ARGS_WEBSERVER, parser=webserver_cmd)
 
         # Add strategy_updater subcommand
         strategy_updater_cmd = subparsers.add_parser(
-            'strategy-updater',
-            help='updates outdated strategy files to the current version',
-            parents=[_common_parser]
+            "strategy-updater",
+            help="updates outdated strategy files to the current version",
+            parents=[_common_parser],
         )
         strategy_updater_cmd.set_defaults(func=start_strategy_update)
         self._build_args(optionlist=ARGS_STRATEGY_UPDATER, parser=strategy_updater_cmd)
 
         # Add lookahead_analysis subcommand
         lookahead_analayis_cmd = subparsers.add_parser(
-            'lookahead-analysis',
+            "lookahead-analysis",
             help="Check for potential look ahead bias.",
-            parents=[_common_parser, _strategy_parser]
+            parents=[_common_parser, _strategy_parser],
         )
         lookahead_analayis_cmd.set_defaults(func=start_lookahead_analysis)
 
-        self._build_args(optionlist=ARGS_LOOKAHEAD_ANALYSIS,
-                         parser=lookahead_analayis_cmd)
+        self._build_args(optionlist=ARGS_LOOKAHEAD_ANALYSIS, parser=lookahead_analayis_cmd)
 
         # Add recursive_analysis subcommand
         recursive_analayis_cmd = subparsers.add_parser(
-            'recursive-analysis',
+            "recursive-analysis",
             help="Check for potential recursive formula issue.",
-            parents=[_common_parser, _strategy_parser]
+            parents=[_common_parser, _strategy_parser],
         )
         recursive_analayis_cmd.set_defaults(func=start_recursive_analysis)
 
-        self._build_args(optionlist=ARGS_RECURSIVE_ANALYSIS,
-                         parser=recursive_analayis_cmd)
+        self._build_args(optionlist=ARGS_RECURSIVE_ANALYSIS, parser=recursive_analayis_cmd)
```

### Comparing `freqtrade-2024.4/freqtrade/commands/build_config_commands.py` & `freqtrade-2024.5/freqtrade/commands/build_config_commands.py`

 * *Files 12% similar despite different names*

```diff
@@ -41,15 +41,15 @@
             "type": "confirm",
             "name": "overwrite",
             "message": f"File {config_path} already exists. Overwrite?",
             "default": False,
         },
     ]
     answers = prompt(questions)
-    return answers['overwrite']
+    return answers["overwrite"]
 
 
 def ask_user_config() -> Dict[str, Any]:
     """
     Ask user a few questions to build the configuration.
     Interactive questions built using https://github.com/tmbo/questionary
     :returns: Dict with keys to put into template
@@ -61,225 +61,226 @@
             "message": "Do you want to enable Dry-run (simulated trades)?",
             "default": True,
         },
         {
             "type": "text",
             "name": "stake_currency",
             "message": "Please insert your stake currency:",
-            "default": 'USDT',
+            "default": "USDT",
         },
         {
             "type": "text",
             "name": "stake_amount",
             "message": f"Please insert your stake amount (Number or '{UNLIMITED_STAKE_AMOUNT}'):",
             "default": "unlimited",
             "validate": lambda val: val == UNLIMITED_STAKE_AMOUNT or validate_is_float(val),
-            "filter": lambda val: '"' + UNLIMITED_STAKE_AMOUNT + '"'
-            if val == UNLIMITED_STAKE_AMOUNT
-            else val
+            "filter": lambda val: (
+                '"' + UNLIMITED_STAKE_AMOUNT + '"' if val == UNLIMITED_STAKE_AMOUNT else val
+            ),
         },
         {
             "type": "text",
             "name": "max_open_trades",
             "message": "Please insert max_open_trades (Integer or -1 for unlimited open trades):",
             "default": "3",
-            "validate": lambda val: validate_is_int(val)
+            "validate": lambda val: validate_is_int(val),
         },
         {
             "type": "select",
             "name": "timeframe_in_config",
             "message": "Time",
-            "choices": ["Have the strategy define timeframe.", "Override in configuration."]
+            "choices": ["Have the strategy define timeframe.", "Override in configuration."],
         },
         {
             "type": "text",
             "name": "timeframe",
             "message": "Please insert your desired timeframe (e.g. 5m):",
             "default": "5m",
-            "when": lambda x: x["timeframe_in_config"] == 'Override in configuration.'
-
+            "when": lambda x: x["timeframe_in_config"] == "Override in configuration.",
         },
         {
             "type": "text",
             "name": "fiat_display_currency",
-            "message": "Please insert your display Currency (for reporting):",
-            "default": 'USD',
+            "message": (
+                "Please insert your display Currency for reporting "
+                "(leave empty to disable FIAT conversion):"
+            ),
+            "default": "USD",
         },
         {
             "type": "select",
             "name": "exchange_name",
             "message": "Select exchange",
             "choices": [
                 "binance",
                 "binanceus",
+                "bingx",
                 "gate",
                 "htx",
                 "kraken",
                 "kucoin",
                 "okx",
                 Separator("------------------"),
                 "other",
             ],
         },
         {
             "type": "confirm",
             "name": "trading_mode",
             "message": "Do you want to trade Perpetual Swaps (perpetual futures)?",
             "default": False,
-            "filter": lambda val: 'futures' if val else 'spot',
-            "when": lambda x: x["exchange_name"] in ['binance', 'gate', 'okx'],
+            "filter": lambda val: "futures" if val else "spot",
+            "when": lambda x: x["exchange_name"] in ["binance", "gate", "okx", "bybit"],
         },
         {
             "type": "autocomplete",
             "name": "exchange_name",
             "message": "Type your exchange name (Must be supported by ccxt)",
             "choices": available_exchanges(),
-            "when": lambda x: x["exchange_name"] == 'other'
+            "when": lambda x: x["exchange_name"] == "other",
         },
         {
             "type": "password",
             "name": "exchange_key",
             "message": "Insert Exchange Key",
-            "when": lambda x: not x['dry_run']
+            "when": lambda x: not x["dry_run"],
         },
         {
             "type": "password",
             "name": "exchange_secret",
             "message": "Insert Exchange Secret",
-            "when": lambda x: not x['dry_run']
+            "when": lambda x: not x["dry_run"],
         },
         {
             "type": "password",
             "name": "exchange_key_password",
             "message": "Insert Exchange API Key password",
-            "when": lambda x: not x['dry_run'] and x['exchange_name'] in ('kucoin', 'okx')
+            "when": lambda x: not x["dry_run"] and x["exchange_name"] in ("kucoin", "okx"),
         },
         {
             "type": "confirm",
             "name": "telegram",
             "message": "Do you want to enable Telegram?",
             "default": False,
         },
         {
             "type": "password",
             "name": "telegram_token",
             "message": "Insert Telegram token",
-            "when": lambda x: x['telegram']
+            "when": lambda x: x["telegram"],
         },
         {
             "type": "password",
             "name": "telegram_chat_id",
             "message": "Insert Telegram chat id",
-            "when": lambda x: x['telegram']
+            "when": lambda x: x["telegram"],
         },
         {
             "type": "confirm",
             "name": "api_server",
             "message": "Do you want to enable the Rest API (includes FreqUI)?",
             "default": False,
         },
         {
             "type": "text",
             "name": "api_server_listen_addr",
-            "message": ("Insert Api server Listen Address (0.0.0.0 for docker, "
-                        "otherwise best left untouched)"),
+            "message": (
+                "Insert Api server Listen Address (0.0.0.0 for docker, "
+                "otherwise best left untouched)"
+            ),
             "default": "127.0.0.1" if not running_in_docker() else "0.0.0.0",
-            "when": lambda x: x['api_server']
+            "when": lambda x: x["api_server"],
         },
         {
             "type": "text",
             "name": "api_server_username",
             "message": "Insert api-server username",
             "default": "freqtrader",
-            "when": lambda x: x['api_server']
+            "when": lambda x: x["api_server"],
         },
         {
             "type": "password",
             "name": "api_server_password",
             "message": "Insert api-server password",
-            "when": lambda x: x['api_server']
+            "when": lambda x: x["api_server"],
         },
     ]
     answers = prompt(questions)
 
     if not answers:
         # Interrupted questionary sessions return an empty dict.
         raise OperationalException("User interrupted interactive questions.")
     # Ensure default is set for non-futures exchanges
-    answers['trading_mode'] = answers.get('trading_mode', "spot")
-    answers['margin_mode'] = (
-        'isolated'
-        if answers.get('trading_mode') == 'futures'
-        else ''
-    )
+    answers["trading_mode"] = answers.get("trading_mode", "spot")
+    answers["margin_mode"] = "isolated" if answers.get("trading_mode") == "futures" else ""
     # Force JWT token to be a random string
-    answers['api_server_jwt_key'] = secrets.token_hex()
-    answers['api_server_ws_token'] = secrets.token_urlsafe(25)
+    answers["api_server_jwt_key"] = secrets.token_hex()
+    answers["api_server_ws_token"] = secrets.token_urlsafe(25)
 
     return answers
 
 
 def deploy_new_config(config_path: Path, selections: Dict[str, Any]) -> None:
     """
     Applies selections to the template and writes the result to config_path
     :param config_path: Path object for new config file. Should not exist yet
     :param selections: Dict containing selections taken by the user.
     """
     from jinja2.exceptions import TemplateNotFound
+
     try:
         exchange_template = MAP_EXCHANGE_CHILDCLASS.get(
-            selections['exchange_name'], selections['exchange_name'])
+            selections["exchange_name"], selections["exchange_name"]
+        )
 
-        selections['exchange'] = render_template(
-            templatefile=f"subtemplates/exchange_{exchange_template}.j2",
-            arguments=selections
+        selections["exchange"] = render_template(
+            templatefile=f"subtemplates/exchange_{exchange_template}.j2", arguments=selections
         )
     except TemplateNotFound:
-        selections['exchange'] = render_template(
-            templatefile="subtemplates/exchange_generic.j2",
-            arguments=selections
+        selections["exchange"] = render_template(
+            templatefile="subtemplates/exchange_generic.j2", arguments=selections
         )
 
-    config_text = render_template(templatefile='base_config.json.j2',
-                                  arguments=selections)
+    config_text = render_template(templatefile="base_config.json.j2", arguments=selections)
 
     logger.info(f"Writing config to `{config_path}`.")
     logger.info(
-        "Please make sure to check the configuration contents and adjust settings to your needs.")
+        "Please make sure to check the configuration contents and adjust settings to your needs."
+    )
 
     config_path.write_text(config_text)
 
 
 def start_new_config(args: Dict[str, Any]) -> None:
     """
     Create a new strategy from a template
     Asking the user questions to fill out the template accordingly.
     """
 
-    config_path = Path(args['config'][0])
+    config_path = Path(args["config"][0])
     chown_user_directory(config_path.parent)
     if config_path.exists():
         overwrite = ask_user_overwrite(config_path)
         if overwrite:
             config_path.unlink()
         else:
             raise OperationalException(
                 f"Configuration file `{config_path}` already exists. "
-                "Please delete it or use a different configuration file name.")
+                "Please delete it or use a different configuration file name."
+            )
     selections = ask_user_config()
     deploy_new_config(config_path, selections)
 
 
 def start_show_config(args: Dict[str, Any]) -> None:
-
     config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE, set_dry=False)
 
     # TODO: Sanitize from sensitive info before printing
 
     print("Your combined configuration is:")
     config_sanitized = sanitize_config(
-        config['original_config'],
-        show_sensitive=args.get('show_sensitive', False)
+        config["original_config"], show_sensitive=args.get("show_sensitive", False)
     )
 
     from rich import print_json
+
     print_json(data=config_sanitized)
```

### Comparing `freqtrade-2024.4/freqtrade/commands/data_commands.py` & `freqtrade-2024.5/freqtrade/commands/data_commands.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,37 +1,43 @@
 import logging
 import sys
 from collections import defaultdict
 from typing import Any, Dict
 
 from freqtrade.configuration import TimeRange, setup_utils_configuration
 from freqtrade.constants import DATETIME_PRINT_FORMAT, DL_DATA_TIMEFRAMES, Config
-from freqtrade.data.converter import (convert_ohlcv_format, convert_trades_format,
-                                      convert_trades_to_ohlcv)
+from freqtrade.data.converter import (
+    convert_ohlcv_format,
+    convert_trades_format,
+    convert_trades_to_ohlcv,
+)
 from freqtrade.data.history import download_data_main
 from freqtrade.enums import CandleType, RunMode, TradingMode
 from freqtrade.exceptions import ConfigurationError
 from freqtrade.exchange import timeframe_to_minutes
 from freqtrade.plugins.pairlist.pairlist_helpers import dynamic_expand_pairlist
 from freqtrade.resolvers import ExchangeResolver
 from freqtrade.util.migrations import migrate_data
 
 
 logger = logging.getLogger(__name__)
 
 
 def _check_data_config_download_sanity(config: Config) -> None:
-    if 'days' in config and 'timerange' in config:
-        raise ConfigurationError("--days and --timerange are mutually exclusive. "
-                                 "You can only specify one or the other.")
+    if "days" in config and "timerange" in config:
+        raise ConfigurationError(
+            "--days and --timerange are mutually exclusive. "
+            "You can only specify one or the other."
+        )
 
-    if 'pairs' not in config:
+    if "pairs" not in config:
         raise ConfigurationError(
             "Downloading data requires a list of pairs. "
-            "Please check the documentation on how to configure this.")
+            "Please check the documentation on how to configure this."
+        )
 
 
 def start_download_data(args: Dict[str, Any]) -> None:
     """
     Download data (former download_backtest_data.py script)
     """
     config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE)
@@ -42,111 +48,133 @@
         download_data_main(config)
 
     except KeyboardInterrupt:
         sys.exit("SIGINT received, aborting ...")
 
 
 def start_convert_trades(args: Dict[str, Any]) -> None:
-
     config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE)
 
     timerange = TimeRange()
 
     # Remove stake-currency to skip checks which are not relevant for datadownload
-    config['stake_currency'] = ''
+    config["stake_currency"] = ""
 
-    if 'timeframes' not in config:
-        config['timeframes'] = DL_DATA_TIMEFRAMES
+    if "timeframes" not in config:
+        config["timeframes"] = DL_DATA_TIMEFRAMES
 
     # Init exchange
     exchange = ExchangeResolver.load_exchange(config, validate=False)
     # Manual validations of relevant settings
 
-    for timeframe in config['timeframes']:
+    for timeframe in config["timeframes"]:
         exchange.validate_timeframes(timeframe)
     available_pairs = [
-        p for p in exchange.get_markets(
-            tradable_only=True, active_only=not config.get('include_inactive')
-            ).keys()
+        p
+        for p in exchange.get_markets(
+            tradable_only=True, active_only=not config.get("include_inactive")
+        ).keys()
     ]
 
     expanded_pairs = dynamic_expand_pairlist(config, available_pairs)
 
     # Convert downloaded trade data to different timeframes
     convert_trades_to_ohlcv(
-        pairs=expanded_pairs, timeframes=config['timeframes'],
-        datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')),
-        data_format_ohlcv=config['dataformat_ohlcv'],
-        data_format_trades=config['dataformat_trades'],
-        candle_type=config.get('candle_type_def', CandleType.SPOT)
+        pairs=expanded_pairs,
+        timeframes=config["timeframes"],
+        datadir=config["datadir"],
+        timerange=timerange,
+        erase=bool(config.get("erase")),
+        data_format_ohlcv=config["dataformat_ohlcv"],
+        data_format_trades=config["dataformat_trades"],
+        candle_type=config.get("candle_type_def", CandleType.SPOT),
     )
 
 
 def start_convert_data(args: Dict[str, Any], ohlcv: bool = True) -> None:
     """
     Convert data from one format to another
     """
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
     if ohlcv:
         migrate_data(config)
-        convert_ohlcv_format(config,
-                             convert_from=args['format_from'],
-                             convert_to=args['format_to'],
-                             erase=args['erase'])
+        convert_ohlcv_format(
+            config,
+            convert_from=args["format_from"],
+            convert_to=args["format_to"],
+            erase=args["erase"],
+        )
     else:
-        convert_trades_format(config,
-                              convert_from=args['format_from_trades'], convert_to=args['format_to'],
-                              erase=args['erase'])
+        convert_trades_format(
+            config,
+            convert_from=args["format_from_trades"],
+            convert_to=args["format_to"],
+            erase=args["erase"],
+        )
 
 
 def start_list_data(args: Dict[str, Any]) -> None:
     """
     List available backtest data
     """
 
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
     from tabulate import tabulate
 
     from freqtrade.data.history import get_datahandler
-    dhc = get_datahandler(config['datadir'], config['dataformat_ohlcv'])
+
+    dhc = get_datahandler(config["datadir"], config["dataformat_ohlcv"])
 
     paircombs = dhc.ohlcv_get_available_data(
-        config['datadir'],
-        config.get('trading_mode', TradingMode.SPOT)
-        )
+        config["datadir"], config.get("trading_mode", TradingMode.SPOT)
+    )
 
-    if args['pairs']:
-        paircombs = [comb for comb in paircombs if comb[0] in args['pairs']]
+    if args["pairs"]:
+        paircombs = [comb for comb in paircombs if comb[0] in args["pairs"]]
 
     print(f"Found {len(paircombs)} pair / timeframe combinations.")
-    if not config.get('show_timerange'):
+    if not config.get("show_timerange"):
         groupedpair = defaultdict(list)
         for pair, timeframe, candle_type in sorted(
-            paircombs,
-            key=lambda x: (x[0], timeframe_to_minutes(x[1]), x[2])
+            paircombs, key=lambda x: (x[0], timeframe_to_minutes(x[1]), x[2])
         ):
             groupedpair[(pair, candle_type)].append(timeframe)
 
         if groupedpair:
-            print(tabulate([
-                (pair, ', '.join(timeframes), candle_type)
-                for (pair, candle_type), timeframes in groupedpair.items()
-            ],
-                headers=("Pair", "Timeframe", "Type"),
-                tablefmt='psql', stralign='right'))
+            print(
+                tabulate(
+                    [
+                        (pair, ", ".join(timeframes), candle_type)
+                        for (pair, candle_type), timeframes in groupedpair.items()
+                    ],
+                    headers=("Pair", "Timeframe", "Type"),
+                    tablefmt="psql",
+                    stralign="right",
+                )
+            )
     else:
-        paircombs1 = [(
-            pair, timeframe, candle_type,
-            *dhc.ohlcv_data_min_max(pair, timeframe, candle_type)
-        ) for pair, timeframe, candle_type in paircombs]
-
-        print(tabulate([
-            (pair, timeframe, candle_type,
-                start.strftime(DATETIME_PRINT_FORMAT),
-                end.strftime(DATETIME_PRINT_FORMAT), length)
-            for pair, timeframe, candle_type, start, end, length in sorted(
-                paircombs1,
-                key=lambda x: (x[0], timeframe_to_minutes(x[1]), x[2]))
-            ],
-            headers=("Pair", "Timeframe", "Type", 'From', 'To', 'Candles'),
-            tablefmt='psql', stralign='right'))
+        paircombs1 = [
+            (pair, timeframe, candle_type, *dhc.ohlcv_data_min_max(pair, timeframe, candle_type))
+            for pair, timeframe, candle_type in paircombs
+        ]
+
+        print(
+            tabulate(
+                [
+                    (
+                        pair,
+                        timeframe,
+                        candle_type,
+                        start.strftime(DATETIME_PRINT_FORMAT),
+                        end.strftime(DATETIME_PRINT_FORMAT),
+                        length,
+                    )
+                    for pair, timeframe, candle_type, start, end, length in sorted(
+                        paircombs1, key=lambda x: (x[0], timeframe_to_minutes(x[1]), x[2])
+                    )
+                ],
+                headers=("Pair", "Timeframe", "Type", "From", "To", "Candles"),
+                tablefmt="psql",
+                stralign="right",
+            )
+        )
```

### Comparing `freqtrade-2024.4/freqtrade/commands/db_commands.py` & `freqtrade-2024.5/freqtrade/commands/db_commands.py`

 * *Files 13% similar despite different names*

```diff
@@ -15,17 +15,17 @@
 
     from freqtrade.persistence import Order, Trade, init_db
     from freqtrade.persistence.migrations import set_sequence_ids
     from freqtrade.persistence.pairlock import PairLock
 
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
-    init_db(config['db_url'])
+    init_db(config["db_url"])
     session_target = Trade.session
-    init_db(config['db_url_from'])
+    init_db(config["db_url_from"])
     logger.info("Starting db migration.")
 
     trade_count = 0
     pairlock_count = 0
     for trade in Trade.get_trades():
         trade_count += 1
         make_transient(trade)
@@ -43,13 +43,15 @@
     session_target.commit()
 
     # Update sequences
     max_trade_id = session_target.scalar(select(func.max(Trade.id)))
     max_order_id = session_target.scalar(select(func.max(Order.id)))
     max_pairlock_id = session_target.scalar(select(func.max(PairLock.id)))
 
-    set_sequence_ids(session_target.get_bind(),
-                     trade_id=max_trade_id,
-                     order_id=max_order_id,
-                     pairlock_id=max_pairlock_id)
+    set_sequence_ids(
+        session_target.get_bind(),
+        trade_id=max_trade_id,
+        order_id=max_order_id,
+        pairlock_id=max_pairlock_id,
+    )
 
     logger.info(f"Migrated {trade_count} Trades, and {pairlock_count} Pairlocks.")
```

### Comparing `freqtrade-2024.4/freqtrade/commands/deploy_commands.py` & `freqtrade-2024.5/freqtrade/commands/deploy_commands.py`

 * *Files 9% similar despite different names*

```diff
@@ -34,15 +34,15 @@
         sys.exit(1)
 
 
 def deploy_new_strategy(strategy_name: str, strategy_path: Path, subtemplate: str) -> None:
     """
     Deploy new strategy from template to strategy_path
     """
-    fallback = 'full'
+    fallback = "full"
     attributes = render_template_with_fallback(
         templatefile=f"strategy_subtemplates/strategy_attributes_{subtemplate}.j2",
         templatefallbackfile=f"strategy_subtemplates/strategy_attributes_{fallback}.j2",
     )
     indicators = render_template_with_fallback(
         templatefile=f"strategy_subtemplates/indicators_{subtemplate}.j2",
         templatefallbackfile=f"strategy_subtemplates/indicators_{fallback}.j2",
@@ -60,65 +60,67 @@
         templatefallbackfile=f"strategy_subtemplates/plot_config_{fallback}.j2",
     )
     additional_methods = render_template_with_fallback(
         templatefile=f"strategy_subtemplates/strategy_methods_{subtemplate}.j2",
         templatefallbackfile="strategy_subtemplates/strategy_methods_empty.j2",
     )
 
-    strategy_text = render_template(templatefile='base_strategy.py.j2',
-                                    arguments={"strategy": strategy_name,
-                                               "attributes": attributes,
-                                               "indicators": indicators,
-                                               "buy_trend": buy_trend,
-                                               "sell_trend": sell_trend,
-                                               "plot_config": plot_config,
-                                               "additional_methods": additional_methods,
-                                               })
+    strategy_text = render_template(
+        templatefile="base_strategy.py.j2",
+        arguments={
+            "strategy": strategy_name,
+            "attributes": attributes,
+            "indicators": indicators,
+            "buy_trend": buy_trend,
+            "sell_trend": sell_trend,
+            "plot_config": plot_config,
+            "additional_methods": additional_methods,
+        },
+    )
 
     logger.info(f"Writing strategy to `{strategy_path}`.")
     strategy_path.write_text(strategy_text)
 
 
 def start_new_strategy(args: Dict[str, Any]) -> None:
-
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
     if "strategy" in args and args["strategy"]:
-
-        new_path = config['user_data_dir'] / USERPATH_STRATEGIES / (args['strategy'] + '.py')
+        new_path = config["user_data_dir"] / USERPATH_STRATEGIES / (args["strategy"] + ".py")
 
         if new_path.exists():
-            raise OperationalException(f"`{new_path}` already exists. "
-                                       "Please choose another Strategy Name.")
+            raise OperationalException(
+                f"`{new_path}` already exists. Please choose another Strategy Name."
+            )
 
-        deploy_new_strategy(args['strategy'], new_path, args['template'])
+        deploy_new_strategy(args["strategy"], new_path, args["template"])
 
     else:
         raise ConfigurationError("`new-strategy` requires --strategy to be set.")
 
 
 def clean_ui_subdir(directory: Path):
     if directory.is_dir():
         logger.info("Removing UI directory content.")
 
-        for p in reversed(list(directory.glob('**/*'))):  # iterate contents from leaves to root
-            if p.name in ('.gitkeep', 'fallback_file.html'):
+        for p in reversed(list(directory.glob("**/*"))):  # iterate contents from leaves to root
+            if p.name in (".gitkeep", "fallback_file.html"):
                 continue
             if p.is_file():
                 p.unlink()
             elif p.is_dir():
                 p.rmdir()
 
 
 def read_ui_version(dest_folder: Path) -> Optional[str]:
-    file = dest_folder / '.uiversion'
+    file = dest_folder / ".uiversion"
     if not file.is_file():
         return None
 
-    with file.open('r') as f:
+    with file.open("r") as f:
         return f.read()
 
 
 def download_and_install_ui(dest_folder: Path, dl_url: str, version: str):
     from io import BytesIO
     from zipfile import ZipFile
 
@@ -129,60 +131,59 @@
         for fn in zf.filelist:
             with zf.open(fn) as x:
                 destfile = dest_folder / fn.filename
                 if fn.is_dir():
                     destfile.mkdir(exist_ok=True)
                 else:
                     destfile.write_bytes(x.read())
-    with (dest_folder / '.uiversion').open('w') as f:
+    with (dest_folder / ".uiversion").open("w") as f:
         f.write(version)
 
 
 def get_ui_download_url(version: Optional[str] = None) -> Tuple[str, str]:
-    base_url = 'https://api.github.com/repos/freqtrade/frequi/'
+    base_url = "https://api.github.com/repos/freqtrade/frequi/"
     # Get base UI Repo path
 
     resp = requests.get(f"{base_url}releases", timeout=req_timeout)
     resp.raise_for_status()
     r = resp.json()
 
     if version:
-        tmp = [x for x in r if x['name'] == version]
+        tmp = [x for x in r if x["name"] == version]
         if tmp:
-            latest_version = tmp[0]['name']
-            assets = tmp[0].get('assets', [])
+            latest_version = tmp[0]["name"]
+            assets = tmp[0].get("assets", [])
         else:
             raise ValueError("UI-Version not found.")
     else:
-        latest_version = r[0]['name']
-        assets = r[0].get('assets', [])
-    dl_url = ''
+        latest_version = r[0]["name"]
+        assets = r[0].get("assets", [])
+    dl_url = ""
     if assets and len(assets) > 0:
-        dl_url = assets[0]['browser_download_url']
+        dl_url = assets[0]["browser_download_url"]
 
     # URL not found - try assets url
     if not dl_url:
-        assets = r[0]['assets_url']
+        assets = r[0]["assets_url"]
         resp = requests.get(assets, timeout=req_timeout)
         r = resp.json()
-        dl_url = r[0]['browser_download_url']
+        dl_url = r[0]["browser_download_url"]
 
     return dl_url, latest_version
 
 
 def start_install_ui(args: Dict[str, Any]) -> None:
-
-    dest_folder = Path(__file__).parents[1] / 'rpc/api_server/ui/installed/'
+    dest_folder = Path(__file__).parents[1] / "rpc/api_server/ui/installed/"
     # First make sure the assets are removed.
-    dl_url, latest_version = get_ui_download_url(args.get('ui_version'))
+    dl_url, latest_version = get_ui_download_url(args.get("ui_version"))
 
     curr_version = read_ui_version(dest_folder)
-    if curr_version == latest_version and not args.get('erase_ui_only'):
+    if curr_version == latest_version and not args.get("erase_ui_only"):
         logger.info(f"UI already up-to-date, FreqUI Version {curr_version}.")
         return
 
     clean_ui_subdir(dest_folder)
-    if args.get('erase_ui_only'):
+    if args.get("erase_ui_only"):
         logger.info("Erased UI directory content. Not downloading new version.")
     else:
         # Download a new version
         download_and_install_ui(dest_folder, dl_url, latest_version)
```

### Comparing `freqtrade-2024.4/freqtrade/commands/hyperopt_commands.py` & `freqtrade-2024.5/freqtrade/commands/hyperopt_commands.py`

 * *Files 12% similar despite different names*

```diff
@@ -18,87 +18,99 @@
     """
     List hyperopt epochs previously evaluated
     """
     from freqtrade.optimize.hyperopt_tools import HyperoptTools
 
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
-    print_colorized = config.get('print_colorized', False)
-    print_json = config.get('print_json', False)
-    export_csv = config.get('export_csv')
-    no_details = config.get('hyperopt_list_no_details', False)
+    print_colorized = config.get("print_colorized", False)
+    print_json = config.get("print_json", False)
+    export_csv = config.get("export_csv")
+    no_details = config.get("hyperopt_list_no_details", False)
     no_header = False
 
     results_file = get_latest_hyperopt_file(
-        config['user_data_dir'] / 'hyperopt_results',
-        config.get('hyperoptexportfilename'))
+        config["user_data_dir"] / "hyperopt_results", config.get("hyperoptexportfilename")
+    )
 
     # Previous evaluations
     epochs, total_epochs = HyperoptTools.load_filtered_results(results_file, config)
 
     if print_colorized:
         colorama_init(autoreset=True)
 
     if not export_csv:
         try:
-            print(HyperoptTools.get_result_table(config, epochs, total_epochs,
-                                                 not config.get('hyperopt_list_best', False),
-                                                 print_colorized, 0))
+            print(
+                HyperoptTools.get_result_table(
+                    config,
+                    epochs,
+                    total_epochs,
+                    not config.get("hyperopt_list_best", False),
+                    print_colorized,
+                    0,
+                )
+            )
         except KeyboardInterrupt:
-            print('User interrupted..')
+            print("User interrupted..")
 
     if epochs and not no_details:
-        sorted_epochs = sorted(epochs, key=itemgetter('loss'))
+        sorted_epochs = sorted(epochs, key=itemgetter("loss"))
         results = sorted_epochs[0]
         HyperoptTools.show_epoch_details(results, total_epochs, print_json, no_header)
 
     if epochs and export_csv:
-        HyperoptTools.export_csv_file(
-            config, epochs, export_csv
-        )
+        HyperoptTools.export_csv_file(config, epochs, export_csv)
 
 
 def start_hyperopt_show(args: Dict[str, Any]) -> None:
     """
     Show details of a hyperopt epoch previously evaluated
     """
     from freqtrade.optimize.hyperopt_tools import HyperoptTools
 
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
-    print_json = config.get('print_json', False)
-    no_header = config.get('hyperopt_show_no_header', False)
+    print_json = config.get("print_json", False)
+    no_header = config.get("hyperopt_show_no_header", False)
     results_file = get_latest_hyperopt_file(
-        config['user_data_dir'] / 'hyperopt_results',
-        config.get('hyperoptexportfilename'))
+        config["user_data_dir"] / "hyperopt_results", config.get("hyperoptexportfilename")
+    )
 
-    n = config.get('hyperopt_show_index', -1)
+    n = config.get("hyperopt_show_index", -1)
 
     # Previous evaluations
     epochs, total_epochs = HyperoptTools.load_filtered_results(results_file, config)
 
     filtered_epochs = len(epochs)
 
     if n > filtered_epochs:
         raise OperationalException(
-            f"The index of the epoch to show should be less than {filtered_epochs + 1}.")
+            f"The index of the epoch to show should be less than {filtered_epochs + 1}."
+        )
     if n < -filtered_epochs:
         raise OperationalException(
-            f"The index of the epoch to show should be greater than {-filtered_epochs - 1}.")
+            f"The index of the epoch to show should be greater than {-filtered_epochs - 1}."
+        )
 
     # Translate epoch index from human-readable format to pythonic
     if n > 0:
         n -= 1
 
     if epochs:
         val = epochs[n]
 
-        metrics = val['results_metrics']
-        if 'strategy_name' in metrics:
-            strategy_name = metrics['strategy_name']
-            show_backtest_result(strategy_name, metrics,
-                                 metrics['stake_currency'], config.get('backtest_breakdown', []))
+        metrics = val["results_metrics"]
+        if "strategy_name" in metrics:
+            strategy_name = metrics["strategy_name"]
+            show_backtest_result(
+                strategy_name,
+                metrics,
+                metrics["stake_currency"],
+                config.get("backtest_breakdown", []),
+            )
 
             HyperoptTools.try_export_params(config, strategy_name, val)
 
-        HyperoptTools.show_epoch_details(val, total_epochs, print_json, no_header,
-                                         header_str="Epoch details")
+        HyperoptTools.show_epoch_details(
+            val, total_epochs, print_json, no_header, header_str="Epoch details"
+        )
```

### Comparing `freqtrade-2024.4/freqtrade/commands/list_commands.py` & `freqtrade-2024.5/freqtrade/commands/list_commands.py`

 * *Files 13% similar despite different names*

```diff
@@ -22,134 +22,152 @@
 
 def start_list_exchanges(args: Dict[str, Any]) -> None:
     """
     Print available exchanges
     :param args: Cli args from Arguments()
     :return: None
     """
-    exchanges = list_available_exchanges(args['list_exchanges_all'])
+    exchanges = list_available_exchanges(args["list_exchanges_all"])
 
-    if args['print_one_column']:
-        print('\n'.join([e['name'] for e in exchanges]))
+    if args["print_one_column"]:
+        print("\n".join([e["name"] for e in exchanges]))
     else:
         headers = {
-            'name': 'Exchange name',
-            'supported': 'Supported',
-            'trade_modes': 'Markets',
-            'comment': 'Reason',
-            }
-        headers.update({'valid': 'Valid'} if args['list_exchanges_all'] else {})
+            "name": "Exchange name",
+            "supported": "Supported",
+            "trade_modes": "Markets",
+            "comment": "Reason",
+        }
+        headers.update({"valid": "Valid"} if args["list_exchanges_all"] else {})
 
         def build_entry(exchange: ValidExchangesType, valid: bool):
-            valid_entry = {'valid': exchange['valid']} if valid else {}
+            valid_entry = {"valid": exchange["valid"]} if valid else {}
             result: Dict[str, Union[str, bool]] = {
-                'name': exchange['name'],
+                "name": exchange["name"],
                 **valid_entry,
-                'supported': 'Official' if exchange['supported'] else '',
-                'trade_modes': ', '.join(
-                    (f"{a['margin_mode']} " if a['margin_mode'] else '') + a['trading_mode']
-                    for a in exchange['trade_modes']
+                "supported": "Official" if exchange["supported"] else "",
+                "trade_modes": ", ".join(
+                    (f"{a['margin_mode']} " if a["margin_mode"] else "") + a["trading_mode"]
+                    for a in exchange["trade_modes"]
                 ),
-                'comment': exchange['comment'],
+                "comment": exchange["comment"],
             }
 
             return result
 
-        if args['list_exchanges_all']:
+        if args["list_exchanges_all"]:
             print("All exchanges supported by the ccxt library:")
             exchanges = [build_entry(e, True) for e in exchanges]
         else:
             print("Exchanges available for Freqtrade:")
-            exchanges = [build_entry(e, False) for e in exchanges if e['valid'] is not False]
+            exchanges = [build_entry(e, False) for e in exchanges if e["valid"] is not False]
 
-        print(tabulate(exchanges, headers=headers, ))
+        print(
+            tabulate(
+                exchanges,
+                headers=headers,
+            )
+        )
 
 
 def _print_objs_tabular(objs: List, print_colorized: bool) -> None:
     if print_colorized:
         colorama_init(autoreset=True)
         red = Fore.RED
         yellow = Fore.YELLOW
         reset = Style.RESET_ALL
     else:
-        red = ''
-        yellow = ''
-        reset = ''
-
-    names = [s['name'] for s in objs]
-    objs_to_print = [{
-        'name': s['name'] if s['name'] else "--",
-        'location': s['location_rel'],
-        'status': (red + "LOAD FAILED" + reset if s['class'] is None
-                   else "OK" if names.count(s['name']) == 1
-                   else yellow + "DUPLICATE NAME" + reset)
-    } for s in objs]
+        red = ""
+        yellow = ""
+        reset = ""
+
+    names = [s["name"] for s in objs]
+    objs_to_print = [
+        {
+            "name": s["name"] if s["name"] else "--",
+            "location": s["location_rel"],
+            "status": (
+                red + "LOAD FAILED" + reset
+                if s["class"] is None
+                else "OK"
+                if names.count(s["name"]) == 1
+                else yellow + "DUPLICATE NAME" + reset
+            ),
+        }
+        for s in objs
+    ]
     for idx, s in enumerate(objs):
-        if 'hyperoptable' in s:
-            objs_to_print[idx].update({
-                'hyperoptable': "Yes" if s['hyperoptable']['count'] > 0 else "No",
-                'buy-Params': len(s['hyperoptable'].get('buy', [])),
-                'sell-Params': len(s['hyperoptable'].get('sell', [])),
-            })
-    print(tabulate(objs_to_print, headers='keys', tablefmt='psql', stralign='right'))
+        if "hyperoptable" in s:
+            objs_to_print[idx].update(
+                {
+                    "hyperoptable": "Yes" if s["hyperoptable"]["count"] > 0 else "No",
+                    "buy-Params": len(s["hyperoptable"].get("buy", [])),
+                    "sell-Params": len(s["hyperoptable"].get("sell", [])),
+                }
+            )
+    print(tabulate(objs_to_print, headers="keys", tablefmt="psql", stralign="right"))
 
 
 def start_list_strategies(args: Dict[str, Any]) -> None:
     """
     Print files with Strategy custom classes available in the directory
     """
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
     strategy_objs = StrategyResolver.search_all_objects(
-        config, not args['print_one_column'], config.get('recursive_strategy_search', False))
+        config, not args["print_one_column"], config.get("recursive_strategy_search", False)
+    )
     # Sort alphabetically
-    strategy_objs = sorted(strategy_objs, key=lambda x: x['name'])
+    strategy_objs = sorted(strategy_objs, key=lambda x: x["name"])
     for obj in strategy_objs:
-        if obj['class']:
-            obj['hyperoptable'] = obj['class'].detect_all_parameters()
+        if obj["class"]:
+            obj["hyperoptable"] = obj["class"].detect_all_parameters()
         else:
-            obj['hyperoptable'] = {'count': 0}
+            obj["hyperoptable"] = {"count": 0}
 
-    if args['print_one_column']:
-        print('\n'.join([s['name'] for s in strategy_objs]))
+    if args["print_one_column"]:
+        print("\n".join([s["name"] for s in strategy_objs]))
     else:
-        _print_objs_tabular(strategy_objs, config.get('print_colorized', False))
+        _print_objs_tabular(strategy_objs, config.get("print_colorized", False))
 
 
 def start_list_freqAI_models(args: Dict[str, Any]) -> None:
     """
     Print files with FreqAI models custom classes available in the directory
     """
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
     from freqtrade.resolvers.freqaimodel_resolver import FreqaiModelResolver
-    model_objs = FreqaiModelResolver.search_all_objects(config, not args['print_one_column'])
+
+    model_objs = FreqaiModelResolver.search_all_objects(config, not args["print_one_column"])
     # Sort alphabetically
-    model_objs = sorted(model_objs, key=lambda x: x['name'])
-    if args['print_one_column']:
-        print('\n'.join([s['name'] for s in model_objs]))
+    model_objs = sorted(model_objs, key=lambda x: x["name"])
+    if args["print_one_column"]:
+        print("\n".join([s["name"] for s in model_objs]))
     else:
-        _print_objs_tabular(model_objs, config.get('print_colorized', False))
+        _print_objs_tabular(model_objs, config.get("print_colorized", False))
 
 
 def start_list_timeframes(args: Dict[str, Any]) -> None:
     """
     Print timeframes available on Exchange
     """
     config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE)
     # Do not use timeframe set in the config
-    config['timeframe'] = None
+    config["timeframe"] = None
 
     # Init exchange
     exchange = ExchangeResolver.load_exchange(config, validate=False)
 
-    if args['print_one_column']:
-        print('\n'.join(exchange.timeframes))
+    if args["print_one_column"]:
+        print("\n".join(exchange.timeframes))
     else:
-        print(f"Timeframes available for the exchange `{exchange.name}`: "
-              f"{', '.join(exchange.timeframes)}")
+        print(
+            f"Timeframes available for the exchange `{exchange.name}`: "
+            f"{', '.join(exchange.timeframes)}"
+        )
 
 
 def start_list_markets(args: Dict[str, Any], pairs_only: bool = False) -> None:
     """
     Print pairs/markets on the exchange
     :param args: Cli args from Arguments()
     :param pairs_only: if True print only pairs, otherwise print all instruments (markets)
@@ -157,108 +175,135 @@
     """
     config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE)
 
     # Init exchange
     exchange = ExchangeResolver.load_exchange(config, validate=False)
 
     # By default only active pairs/markets are to be shown
-    active_only = not args.get('list_pairs_all', False)
+    active_only = not args.get("list_pairs_all", False)
 
-    base_currencies = args.get('base_currencies', [])
-    quote_currencies = args.get('quote_currencies', [])
+    base_currencies = args.get("base_currencies", [])
+    quote_currencies = args.get("quote_currencies", [])
 
     try:
-        pairs = exchange.get_markets(base_currencies=base_currencies,
-                                     quote_currencies=quote_currencies,
-                                     tradable_only=pairs_only,
-                                     active_only=active_only)
+        pairs = exchange.get_markets(
+            base_currencies=base_currencies,
+            quote_currencies=quote_currencies,
+            tradable_only=pairs_only,
+            active_only=active_only,
+        )
         # Sort the pairs/markets by symbol
         pairs = dict(sorted(pairs.items()))
     except Exception as e:
         raise OperationalException(f"Cannot get markets. Reason: {e}") from e
 
     else:
-        summary_str = ((f"Exchange {exchange.name} has {len(pairs)} ") +
-                       ("active " if active_only else "") +
-                       (plural(len(pairs), "pair" if pairs_only else "market")) +
-                       (f" with {', '.join(base_currencies)} as base "
-                        f"{plural(len(base_currencies), 'currency', 'currencies')}"
-                        if base_currencies else "") +
-                       (" and" if base_currencies and quote_currencies else "") +
-                       (f" with {', '.join(quote_currencies)} as quote "
-                        f"{plural(len(quote_currencies), 'currency', 'currencies')}"
-                        if quote_currencies else ""))
-
-        headers = ["Id", "Symbol", "Base", "Quote", "Active",
-                   "Spot", "Margin", "Future", "Leverage"]
-
-        tabular_data = [{
-                'Id': v['id'],
-                'Symbol': v['symbol'],
-                'Base': v['base'],
-                'Quote': v['quote'],
-                'Active': market_is_active(v),
-                'Spot': 'Spot' if exchange.market_is_spot(v) else '',
-                'Margin': 'Margin' if exchange.market_is_margin(v) else '',
-                'Future': 'Future' if exchange.market_is_future(v) else '',
-                'Leverage': exchange.get_max_leverage(v['symbol'], 20)
-            } for _, v in pairs.items()]
-
-        if (args.get('print_one_column', False) or
-                args.get('list_pairs_print_json', False) or
-                args.get('print_csv', False)):
+        summary_str = (
+            (f"Exchange {exchange.name} has {len(pairs)} ")
+            + ("active " if active_only else "")
+            + (plural(len(pairs), "pair" if pairs_only else "market"))
+            + (
+                f" with {', '.join(base_currencies)} as base "
+                f"{plural(len(base_currencies), 'currency', 'currencies')}"
+                if base_currencies
+                else ""
+            )
+            + (" and" if base_currencies and quote_currencies else "")
+            + (
+                f" with {', '.join(quote_currencies)} as quote "
+                f"{plural(len(quote_currencies), 'currency', 'currencies')}"
+                if quote_currencies
+                else ""
+            )
+        )
+
+        headers = [
+            "Id",
+            "Symbol",
+            "Base",
+            "Quote",
+            "Active",
+            "Spot",
+            "Margin",
+            "Future",
+            "Leverage",
+        ]
+
+        tabular_data = [
+            {
+                "Id": v["id"],
+                "Symbol": v["symbol"],
+                "Base": v["base"],
+                "Quote": v["quote"],
+                "Active": market_is_active(v),
+                "Spot": "Spot" if exchange.market_is_spot(v) else "",
+                "Margin": "Margin" if exchange.market_is_margin(v) else "",
+                "Future": "Future" if exchange.market_is_future(v) else "",
+                "Leverage": exchange.get_max_leverage(v["symbol"], 20),
+            }
+            for _, v in pairs.items()
+        ]
+
+        if (
+            args.get("print_one_column", False)
+            or args.get("list_pairs_print_json", False)
+            or args.get("print_csv", False)
+        ):
             # Print summary string in the log in case of machine-readable
             # regular formats.
             logger.info(f"{summary_str}.")
         else:
             # Print empty string separating leading logs and output in case of
             # human-readable formats.
             print()
 
         if pairs:
-            if args.get('print_list', False):
+            if args.get("print_list", False):
                 # print data as a list, with human-readable summary
                 print(f"{summary_str}: {', '.join(pairs.keys())}.")
-            elif args.get('print_one_column', False):
-                print('\n'.join(pairs.keys()))
-            elif args.get('list_pairs_print_json', False):
+            elif args.get("print_one_column", False):
+                print("\n".join(pairs.keys()))
+            elif args.get("list_pairs_print_json", False):
                 print(rapidjson.dumps(list(pairs.keys()), default=str))
-            elif args.get('print_csv', False):
+            elif args.get("print_csv", False):
                 writer = csv.DictWriter(sys.stdout, fieldnames=headers)
                 writer.writeheader()
                 writer.writerows(tabular_data)
             else:
                 # print data as a table, with the human-readable summary
                 print(f"{summary_str}:")
-                print(tabulate(tabular_data, headers='keys', tablefmt='psql', stralign='right'))
-        elif not (args.get('print_one_column', False) or
-                  args.get('list_pairs_print_json', False) or
-                  args.get('print_csv', False)):
+                print(tabulate(tabular_data, headers="keys", tablefmt="psql", stralign="right"))
+        elif not (
+            args.get("print_one_column", False)
+            or args.get("list_pairs_print_json", False)
+            or args.get("print_csv", False)
+        ):
             print(f"{summary_str}.")
 
 
 def start_show_trades(args: Dict[str, Any]) -> None:
     """
     Show trades
     """
     import json
 
     from freqtrade.persistence import Trade, init_db
+
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
-    if 'db_url' not in config:
+    if "db_url" not in config:
         raise ConfigurationError("--db-url is required for this command.")
 
     logger.info(f'Using DB: "{parse_db_uri_for_logging(config["db_url"])}"')
-    init_db(config['db_url'])
+    init_db(config["db_url"])
     tfilter = []
 
-    if config.get('trade_ids'):
-        tfilter.append(Trade.id.in_(config['trade_ids']))
+    if config.get("trade_ids"):
+        tfilter.append(Trade.id.in_(config["trade_ids"]))
 
     trades = Trade.get_trades(tfilter).all()
     logger.info(f"Printing {len(trades)} Trades: ")
-    if config.get('print_json', False):
+    if config.get("print_json", False):
         print(json.dumps([trade.to_json() for trade in trades], indent=4))
     else:
         for trade in trades:
             print(trade)
```

### Comparing `freqtrade-2024.4/freqtrade/commands/optimize_commands.py` & `freqtrade-2024.5/freqtrade/commands/optimize_commands.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,28 +17,30 @@
     :param args: Cli args from Arguments()
     :param method: Bot running mode
     :return: Configuration
     """
     config = setup_utils_configuration(args, method)
 
     no_unlimited_runmodes = {
-        RunMode.BACKTEST: 'backtesting',
-        RunMode.HYPEROPT: 'hyperoptimization',
+        RunMode.BACKTEST: "backtesting",
+        RunMode.HYPEROPT: "hyperoptimization",
     }
     if method in no_unlimited_runmodes.keys():
-        wallet_size = config['dry_run_wallet'] * config['tradable_balance_ratio']
+        wallet_size = config["dry_run_wallet"] * config["tradable_balance_ratio"]
         # tradable_balance_ratio
-        if (config['stake_amount'] != constants.UNLIMITED_STAKE_AMOUNT
-                and config['stake_amount'] > wallet_size):
-            wallet = fmt_coin(wallet_size, config['stake_currency'])
-            stake = fmt_coin(config['stake_amount'], config['stake_currency'])
+        if (
+            config["stake_amount"] != constants.UNLIMITED_STAKE_AMOUNT
+            and config["stake_amount"] > wallet_size
+        ):
+            wallet = fmt_coin(wallet_size, config["stake_currency"])
+            stake = fmt_coin(config["stake_amount"], config["stake_currency"])
             raise ConfigurationError(
                 f"Starting balance ({wallet}) is smaller than stake_amount {stake}. "
                 f"Wallet is calculated as `dry_run_wallet * tradable_balance_ratio`."
-                )
+            )
 
     return config
 
 
 def start_backtesting(args: Dict[str, Any]) -> None:
     """
     Start Backtesting script
@@ -47,15 +49,15 @@
     """
     # Import here to avoid loading backtesting module when it's not used
     from freqtrade.optimize.backtesting import Backtesting
 
     # Initialize configuration
     config = setup_optimize_configuration(args, RunMode.BACKTEST)
 
-    logger.info('Starting freqtrade in Backtesting mode')
+    logger.info("Starting freqtrade in Backtesting mode")
 
     # Initialize backtesting object
     backtesting = Backtesting(config)
     backtesting.start()
 
 
 def start_backtesting_show(args: Dict[str, Any]) -> None:
@@ -64,15 +66,15 @@
     """
 
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
     from freqtrade.data.btanalysis import load_backtest_stats
     from freqtrade.optimize.optimize_reports import show_backtest_results, show_sorted_pairlist
 
-    results = load_backtest_stats(config['exportfilename'])
+    results = load_backtest_stats(config["exportfilename"])
 
     show_backtest_results(config, results)
     show_sorted_pairlist(config, results)
 
 
 def start_hyperopt(args: Dict[str, Any]) -> None:
     """
@@ -83,38 +85,40 @@
     # Import here to avoid loading hyperopt module when it's not used
     try:
         from filelock import FileLock, Timeout
 
         from freqtrade.optimize.hyperopt import Hyperopt
     except ImportError as e:
         raise OperationalException(
-            f"{e}. Please ensure that the hyperopt dependencies are installed.") from e
+            f"{e}. Please ensure that the hyperopt dependencies are installed."
+        ) from e
     # Initialize configuration
     config = setup_optimize_configuration(args, RunMode.HYPEROPT)
 
-    logger.info('Starting freqtrade in Hyperopt mode')
+    logger.info("Starting freqtrade in Hyperopt mode")
 
     lock = FileLock(Hyperopt.get_lock_filename(config))
 
     try:
         with lock.acquire(timeout=1):
-
             # Remove noisy log messages
-            logging.getLogger('hyperopt.tpe').setLevel(logging.WARNING)
-            logging.getLogger('filelock').setLevel(logging.WARNING)
+            logging.getLogger("hyperopt.tpe").setLevel(logging.WARNING)
+            logging.getLogger("filelock").setLevel(logging.WARNING)
 
             # Initialize backtesting object
             hyperopt = Hyperopt(config)
             hyperopt.start()
 
     except Timeout:
         logger.info("Another running instance of freqtrade Hyperopt detected.")
-        logger.info("Simultaneous execution of multiple Hyperopt commands is not supported. "
-                    "Hyperopt module is resource hungry. Please run your Hyperopt sequentially "
-                    "or on separate machines.")
+        logger.info(
+            "Simultaneous execution of multiple Hyperopt commands is not supported. "
+            "Hyperopt module is resource hungry. Please run your Hyperopt sequentially "
+            "or on separate machines."
+        )
         logger.info("Quitting now.")
         # TODO: return False here in order to help freqtrade to exit
         # with non-zero exit code...
         # Same in Edge and Backtesting start() functions.
 
 
 def start_edge(args: Dict[str, Any]) -> None:
@@ -123,15 +127,15 @@
     :param args: Cli args from Arguments()
     :return: None
     """
     from freqtrade.optimize.edge_cli import EdgeCli
 
     # Initialize configuration
     config = setup_optimize_configuration(args, RunMode.EDGE)
-    logger.info('Starting freqtrade in Edge mode')
+    logger.info("Starting freqtrade in Edge mode")
 
     # Initialize Edge object
     edge_cli = EdgeCli(config)
     edge_cli.start()
 
 
 def start_lookahead_analysis(args: Dict[str, Any]) -> None:
```

### Comparing `freqtrade-2024.4/freqtrade/commands/pairlist_commands.py` & `freqtrade-2024.5/freqtrade/commands/pairlist_commands.py`

 * *Files 14% similar despite different names*

```diff
@@ -13,32 +13,33 @@
 
 def start_test_pairlist(args: Dict[str, Any]) -> None:
     """
     Test Pairlist configuration
     """
     from freqtrade.persistence import FtNoDBContext
     from freqtrade.plugins.pairlistmanager import PairListManager
+
     config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE)
 
     exchange = ExchangeResolver.load_exchange(config, validate=False)
 
-    quote_currencies = args.get('quote_currencies')
+    quote_currencies = args.get("quote_currencies")
     if not quote_currencies:
-        quote_currencies = [config.get('stake_currency')]
+        quote_currencies = [config.get("stake_currency")]
     results = {}
     with FtNoDBContext():
         for curr in quote_currencies:
-            config['stake_currency'] = curr
+            config["stake_currency"] = curr
             pairlists = PairListManager(exchange, config)
             pairlists.refresh_pairlist()
             results[curr] = pairlists.whitelist
 
     for curr, pairlist in results.items():
-        if not args.get('print_one_column', False) and not args.get('list_pairs_print_json', False):
+        if not args.get("print_one_column", False) and not args.get("list_pairs_print_json", False):
             print(f"Pairs for {curr}: ")
 
-        if args.get('print_one_column', False):
-            print('\n'.join(pairlist))
-        elif args.get('list_pairs_print_json', False):
+        if args.get("print_one_column", False):
+            print("\n".join(pairlist))
+        elif args.get("list_pairs_print_json", False):
             print(rapidjson.dumps(list(pairlist), default=str))
         else:
             print(pairlist)
```

### Comparing `freqtrade-2024.4/freqtrade/commands/plot_commands.py` & `freqtrade-2024.5/freqtrade/commands/plot_commands.py`

 * *Files 15% similar despite different names*

```diff
@@ -2,35 +2,38 @@
 
 from freqtrade.configuration import setup_utils_configuration
 from freqtrade.enums import RunMode
 from freqtrade.exceptions import ConfigurationError
 
 
 def validate_plot_args(args: Dict[str, Any]) -> None:
-    if not args.get('datadir') and not args.get('config'):
+    if not args.get("datadir") and not args.get("config"):
         raise ConfigurationError(
             "You need to specify either `--datadir` or `--config` "
-            "for plot-profit and plot-dataframe.")
+            "for plot-profit and plot-dataframe."
+        )
 
 
 def start_plot_dataframe(args: Dict[str, Any]) -> None:
     """
     Entrypoint for dataframe plotting
     """
     # Import here to avoid errors if plot-dependencies are not installed.
     from freqtrade.plot.plotting import load_and_plot_trades
+
     validate_plot_args(args)
     config = setup_utils_configuration(args, RunMode.PLOT)
 
     load_and_plot_trades(config)
 
 
 def start_plot_profit(args: Dict[str, Any]) -> None:
     """
     Entrypoint for plot_profit
     """
     # Import here to avoid errors if plot-dependencies are not installed.
     from freqtrade.plot.plotting import plot_profit
+
     validate_plot_args(args)
     config = setup_utils_configuration(args, RunMode.PLOT)
 
     plot_profit(config)
```

### Comparing `freqtrade-2024.4/freqtrade/commands/strategy_utils_commands.py` & `freqtrade-2024.5/freqtrade/commands/strategy_utils_commands.py`

 * *Files 3% similar despite different names*

```diff
@@ -22,31 +22,33 @@
 
     if sys.version_info == (3, 8):  # pragma: no cover
         sys.exit("Freqtrade strategy updater requires Python version >= 3.9")
 
     config = setup_utils_configuration(args, RunMode.UTIL_NO_EXCHANGE)
 
     strategy_objs = StrategyResolver.search_all_objects(
-        config, enum_failed=False, recursive=config.get('recursive_strategy_search', False))
+        config, enum_failed=False, recursive=config.get("recursive_strategy_search", False)
+    )
 
     filtered_strategy_objs = []
-    if args['strategy_list']:
+    if args["strategy_list"]:
         filtered_strategy_objs = [
-            strategy_obj for strategy_obj in strategy_objs
-            if strategy_obj['name'] in args['strategy_list']
+            strategy_obj
+            for strategy_obj in strategy_objs
+            if strategy_obj["name"] in args["strategy_list"]
         ]
 
     else:
         # Use all available entries.
         filtered_strategy_objs = strategy_objs
 
     processed_locations = set()
     for strategy_obj in filtered_strategy_objs:
-        if strategy_obj['location'] not in processed_locations:
-            processed_locations.add(strategy_obj['location'])
+        if strategy_obj["location"] not in processed_locations:
+            processed_locations.add(strategy_obj["location"])
             start_conversion(strategy_obj, config)
 
 
 def start_conversion(strategy_obj, config):
     print(f"Conversion of {Path(strategy_obj['location']).name} started.")
     instance_strategy_updater = StrategyUpdater()
     start = time.perf_counter()
```

### Comparing `freqtrade-2024.4/freqtrade/commands/trade_commands.py` & `freqtrade-2024.5/freqtrade/commands/trade_commands.py`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/configuration/config_secrets.py` & `freqtrade-2024.5/freqtrade/configuration/config_secrets.py`

 * *Files 13% similar despite different names*

```diff
@@ -20,17 +20,17 @@
         "telegram.token",
         "telegram.chat_id",
         "discord.webhook_url",
         "api_server.password",
     ]
     config = deepcopy(config)
     for key in keys_to_remove:
-        if '.' in key:
-            nested_keys = key.split('.')
+        if "." in key:
+            nested_keys = key.split(".")
             nested_config = config
             for nested_key in nested_keys[:-1]:
                 nested_config = nested_config.get(nested_key, {})
-            nested_config[nested_keys[-1]] = 'REDACTED'
+            nested_config[nested_keys[-1]] = "REDACTED"
         else:
-            config[key] = 'REDACTED'
+            config[key] = "REDACTED"
 
     return config
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/config_setup.py` & `freqtrade-2024.5/freqtrade/configuration/config_setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,23 +7,24 @@
 from .configuration import Configuration
 
 
 logger = logging.getLogger(__name__)
 
 
 def setup_utils_configuration(
-        args: Dict[str, Any], method: RunMode, *, set_dry: bool = True) -> Dict[str, Any]:
+    args: Dict[str, Any], method: RunMode, *, set_dry: bool = True
+) -> Dict[str, Any]:
     """
     Prepare the configuration for utils subcommands
     :param args: Cli args from Arguments()
     :param method: Bot running mode
     :return: Configuration
     """
     configuration = Configuration(args, method)
     config = configuration.get_config()
 
     # Ensure these modes are using Dry-run
     if set_dry:
-        config['dry_run'] = True
+        config["dry_run"] = True
     validate_config_consistency(config, preliminary=True)
 
     return config
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/config_validation.py` & `freqtrade-2024.5/freqtrade/configuration/config_validation.py`

 * *Files 12% similar despite different names*

```diff
@@ -16,59 +16,53 @@
 
 
 def _extend_validator(validator_class):
     """
     Extended validator for the Freqtrade configuration JSON Schema.
     Currently it only handles defaults for subschemas.
     """
-    validate_properties = validator_class.VALIDATORS['properties']
+    validate_properties = validator_class.VALIDATORS["properties"]
 
     def set_defaults(validator, properties, instance, schema):
         for prop, subschema in properties.items():
-            if 'default' in subschema:
-                instance.setdefault(prop, subschema['default'])
+            if "default" in subschema:
+                instance.setdefault(prop, subschema["default"])
 
         yield from validate_properties(validator, properties, instance, schema)
 
-    return validators.extend(
-        validator_class, {'properties': set_defaults}
-    )
+    return validators.extend(validator_class, {"properties": set_defaults})
 
 
 FreqtradeValidator = _extend_validator(Draft4Validator)
 
 
 def validate_config_schema(conf: Dict[str, Any], preliminary: bool = False) -> Dict[str, Any]:
     """
     Validate the configuration follow the Config Schema
     :param conf: Config in JSON format
     :return: Returns the config if valid, otherwise throw an exception
     """
     conf_schema = deepcopy(constants.CONF_SCHEMA)
-    if conf.get('runmode', RunMode.OTHER) in (RunMode.DRY_RUN, RunMode.LIVE):
-        conf_schema['required'] = constants.SCHEMA_TRADE_REQUIRED
-    elif conf.get('runmode', RunMode.OTHER) in (RunMode.BACKTEST, RunMode.HYPEROPT):
+    if conf.get("runmode", RunMode.OTHER) in (RunMode.DRY_RUN, RunMode.LIVE):
+        conf_schema["required"] = constants.SCHEMA_TRADE_REQUIRED
+    elif conf.get("runmode", RunMode.OTHER) in (RunMode.BACKTEST, RunMode.HYPEROPT):
         if preliminary:
-            conf_schema['required'] = constants.SCHEMA_BACKTEST_REQUIRED
+            conf_schema["required"] = constants.SCHEMA_BACKTEST_REQUIRED
         else:
-            conf_schema['required'] = constants.SCHEMA_BACKTEST_REQUIRED_FINAL
-    elif conf.get('runmode', RunMode.OTHER) == RunMode.WEBSERVER:
-        conf_schema['required'] = constants.SCHEMA_MINIMAL_WEBSERVER
+            conf_schema["required"] = constants.SCHEMA_BACKTEST_REQUIRED_FINAL
+    elif conf.get("runmode", RunMode.OTHER) == RunMode.WEBSERVER:
+        conf_schema["required"] = constants.SCHEMA_MINIMAL_WEBSERVER
     else:
-        conf_schema['required'] = constants.SCHEMA_MINIMAL_REQUIRED
+        conf_schema["required"] = constants.SCHEMA_MINIMAL_REQUIRED
     try:
         FreqtradeValidator(conf_schema).validate(conf)
         return conf
     except ValidationError as e:
-        logger.critical(
-            f"Invalid configuration. Reason: {e}"
-        )
-        raise ValidationError(
-            best_match(Draft4Validator(conf_schema).iter_errors(conf)).message
-        )
+        logger.critical(f"Invalid configuration. Reason: {e}")
+        raise ValidationError(best_match(Draft4Validator(conf_schema).iter_errors(conf)).message)
 
 
 def validate_config_consistency(conf: Dict[str, Any], *, preliminary: bool = False) -> None:
     """
     Validate the configuration consistency.
     Should be ran after loading both configuration and strategy,
     since strategies can set certain configuration settings too.
@@ -87,322 +81,350 @@
     _validate_freqai_hyperopt(conf)
     _validate_freqai_backtest(conf)
     _validate_freqai_include_timeframes(conf, preliminary=preliminary)
     _validate_consumers(conf)
     validate_migrated_strategy_settings(conf)
 
     # validate configuration before returning
-    logger.info('Validating configuration ...')
+    logger.info("Validating configuration ...")
     validate_config_schema(conf, preliminary=preliminary)
 
 
 def _validate_unlimited_amount(conf: Dict[str, Any]) -> None:
     """
     If edge is disabled, either max_open_trades or stake_amount need to be set.
     :raise: ConfigurationError if config validation failed
     """
-    if (not conf.get('edge', {}).get('enabled')
-        and conf.get('max_open_trades') == float('inf')
-            and conf.get('stake_amount') == constants.UNLIMITED_STAKE_AMOUNT):
+    if (
+        not conf.get("edge", {}).get("enabled")
+        and conf.get("max_open_trades") == float("inf")
+        and conf.get("stake_amount") == constants.UNLIMITED_STAKE_AMOUNT
+    ):
         raise ConfigurationError("`max_open_trades` and `stake_amount` cannot both be unlimited.")
 
 
 def _validate_price_config(conf: Dict[str, Any]) -> None:
     """
     When using market orders, price sides must be using the "other" side of the price
     """
     # TODO: The below could be an enforced setting when using market orders
-    if (conf.get('order_types', {}).get('entry') == 'market'
-            and conf.get('entry_pricing', {}).get('price_side') not in ('ask', 'other')):
-        raise ConfigurationError(
-            'Market entry orders require entry_pricing.price_side = "other".')
-
-    if (conf.get('order_types', {}).get('exit') == 'market'
-            and conf.get('exit_pricing', {}).get('price_side') not in ('bid', 'other')):
+    if conf.get("order_types", {}).get("entry") == "market" and conf.get("entry_pricing", {}).get(
+        "price_side"
+    ) not in ("ask", "other"):
+        raise ConfigurationError('Market entry orders require entry_pricing.price_side = "other".')
+
+    if conf.get("order_types", {}).get("exit") == "market" and conf.get("exit_pricing", {}).get(
+        "price_side"
+    ) not in ("bid", "other"):
         raise ConfigurationError('Market exit orders require exit_pricing.price_side = "other".')
 
 
 def _validate_trailing_stoploss(conf: Dict[str, Any]) -> None:
-
-    if conf.get('stoploss') == 0.0:
+    if conf.get("stoploss") == 0.0:
         raise ConfigurationError(
-            'The config stoploss needs to be different from 0 to avoid problems with sell orders.'
+            "The config stoploss needs to be different from 0 to avoid problems with sell orders."
         )
     # Skip if trailing stoploss is not activated
-    if not conf.get('trailing_stop', False):
+    if not conf.get("trailing_stop", False):
         return
 
-    tsl_positive = float(conf.get('trailing_stop_positive', 0))
-    tsl_offset = float(conf.get('trailing_stop_positive_offset', 0))
-    tsl_only_offset = conf.get('trailing_only_offset_is_reached', False)
+    tsl_positive = float(conf.get("trailing_stop_positive", 0))
+    tsl_offset = float(conf.get("trailing_stop_positive_offset", 0))
+    tsl_only_offset = conf.get("trailing_only_offset_is_reached", False)
 
     if tsl_only_offset:
         if tsl_positive == 0.0:
             raise ConfigurationError(
-                'The config trailing_only_offset_is_reached needs '
-                'trailing_stop_positive_offset to be more than 0 in your config.')
+                "The config trailing_only_offset_is_reached needs "
+                "trailing_stop_positive_offset to be more than 0 in your config."
+            )
     if tsl_positive > 0 and 0 < tsl_offset <= tsl_positive:
         raise ConfigurationError(
-            'The config trailing_stop_positive_offset needs '
-            'to be greater than trailing_stop_positive in your config.')
+            "The config trailing_stop_positive_offset needs "
+            "to be greater than trailing_stop_positive in your config."
+        )
 
     # Fetch again without default
-    if 'trailing_stop_positive' in conf and float(conf['trailing_stop_positive']) == 0.0:
+    if "trailing_stop_positive" in conf and float(conf["trailing_stop_positive"]) == 0.0:
         raise ConfigurationError(
-            'The config trailing_stop_positive needs to be different from 0 '
-            'to avoid problems with sell orders.'
+            "The config trailing_stop_positive needs to be different from 0 "
+            "to avoid problems with sell orders."
         )
 
 
 def _validate_edge(conf: Dict[str, Any]) -> None:
     """
     Edge and Dynamic whitelist should not both be enabled, since edge overrides dynamic whitelists.
     """
 
-    if not conf.get('edge', {}).get('enabled'):
+    if not conf.get("edge", {}).get("enabled"):
         return
 
-    if not conf.get('use_exit_signal', True):
+    if not conf.get("use_exit_signal", True):
         raise ConfigurationError(
             "Edge requires `use_exit_signal` to be True, otherwise no sells will happen."
         )
 
 
 def _validate_whitelist(conf: Dict[str, Any]) -> None:
     """
     Dynamic whitelist does not require pair_whitelist to be set - however StaticWhitelist does.
     """
-    if conf.get('runmode', RunMode.OTHER) in [RunMode.OTHER, RunMode.PLOT,
-                                              RunMode.UTIL_NO_EXCHANGE, RunMode.UTIL_EXCHANGE]:
+    if conf.get("runmode", RunMode.OTHER) in [
+        RunMode.OTHER,
+        RunMode.PLOT,
+        RunMode.UTIL_NO_EXCHANGE,
+        RunMode.UTIL_EXCHANGE,
+    ]:
         return
 
-    for pl in conf.get('pairlists', [{'method': 'StaticPairList'}]):
-        if (isinstance(pl, dict) and pl.get('method') == 'StaticPairList'
-                and not conf.get('exchange', {}).get('pair_whitelist')):
+    for pl in conf.get("pairlists", [{"method": "StaticPairList"}]):
+        if (
+            isinstance(pl, dict)
+            and pl.get("method") == "StaticPairList"
+            and not conf.get("exchange", {}).get("pair_whitelist")
+        ):
             raise ConfigurationError("StaticPairList requires pair_whitelist to be set.")
 
 
 def _validate_protections(conf: Dict[str, Any]) -> None:
     """
     Validate protection configuration validity
     """
 
-    for prot in conf.get('protections', []):
-        if ('stop_duration' in prot and 'stop_duration_candles' in prot):
+    for prot in conf.get("protections", []):
+        if "stop_duration" in prot and "stop_duration_candles" in prot:
             raise ConfigurationError(
                 "Protections must specify either `stop_duration` or `stop_duration_candles`.\n"
                 f"Please fix the protection {prot.get('method')}"
             )
 
-        if ('lookback_period' in prot and 'lookback_period_candles' in prot):
+        if "lookback_period" in prot and "lookback_period_candles" in prot:
             raise ConfigurationError(
                 "Protections must specify either `lookback_period` or `lookback_period_candles`.\n"
                 f"Please fix the protection {prot.get('method')}"
             )
 
 
 def _validate_ask_orderbook(conf: Dict[str, Any]) -> None:
-    ask_strategy = conf.get('exit_pricing', {})
-    ob_min = ask_strategy.get('order_book_min')
-    ob_max = ask_strategy.get('order_book_max')
-    if ob_min is not None and ob_max is not None and ask_strategy.get('use_order_book'):
+    ask_strategy = conf.get("exit_pricing", {})
+    ob_min = ask_strategy.get("order_book_min")
+    ob_max = ask_strategy.get("order_book_max")
+    if ob_min is not None and ob_max is not None and ask_strategy.get("use_order_book"):
         if ob_min != ob_max:
             raise ConfigurationError(
                 "Using order_book_max != order_book_min in exit_pricing is no longer supported."
                 "Please pick one value and use `order_book_top` in the future."
             )
         else:
             # Move value to order_book_top
-            ask_strategy['order_book_top'] = ob_min
+            ask_strategy["order_book_top"] = ob_min
             logger.warning(
                 "DEPRECATED: "
                 "Please use `order_book_top` instead of `order_book_min` and `order_book_max` "
                 "for your `exit_pricing` configuration."
             )
 
 
 def validate_migrated_strategy_settings(conf: Dict[str, Any]) -> None:
-
     _validate_time_in_force(conf)
     _validate_order_types(conf)
     _validate_unfilledtimeout(conf)
     _validate_pricing_rules(conf)
     _strategy_settings(conf)
 
 
 def _validate_time_in_force(conf: Dict[str, Any]) -> None:
-
-    time_in_force = conf.get('order_time_in_force', {})
-    if 'buy' in time_in_force or 'sell' in time_in_force:
-        if conf.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT:
+    time_in_force = conf.get("order_time_in_force", {})
+    if "buy" in time_in_force or "sell" in time_in_force:
+        if conf.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT:
             raise ConfigurationError(
-                "Please migrate your time_in_force settings to use 'entry' and 'exit'.")
+                "Please migrate your time_in_force settings to use 'entry' and 'exit'."
+            )
         else:
             logger.warning(
                 "DEPRECATED: Using 'buy' and 'sell' for time_in_force is deprecated."
                 "Please migrate your time_in_force settings to use 'entry' and 'exit'."
             )
             process_deprecated_setting(
-                conf, 'order_time_in_force', 'buy', 'order_time_in_force', 'entry')
+                conf, "order_time_in_force", "buy", "order_time_in_force", "entry"
+            )
 
             process_deprecated_setting(
-                conf, 'order_time_in_force', 'sell', 'order_time_in_force', 'exit')
+                conf, "order_time_in_force", "sell", "order_time_in_force", "exit"
+            )
 
 
 def _validate_order_types(conf: Dict[str, Any]) -> None:
-
-    order_types = conf.get('order_types', {})
-    old_order_types = ['buy', 'sell', 'emergencysell', 'forcebuy',
-                       'forcesell', 'emergencyexit', 'forceexit', 'forceentry']
+    order_types = conf.get("order_types", {})
+    old_order_types = [
+        "buy",
+        "sell",
+        "emergencysell",
+        "forcebuy",
+        "forcesell",
+        "emergencyexit",
+        "forceexit",
+        "forceentry",
+    ]
     if any(x in order_types for x in old_order_types):
-        if conf.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT:
+        if conf.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT:
             raise ConfigurationError(
-                "Please migrate your order_types settings to use the new wording.")
+                "Please migrate your order_types settings to use the new wording."
+            )
         else:
             logger.warning(
                 "DEPRECATED: Using 'buy' and 'sell' for order_types is deprecated."
                 "Please migrate your order_types settings to use 'entry' and 'exit' wording."
             )
             for o, n in [
-                ('buy', 'entry'),
-                ('sell', 'exit'),
-                ('emergencysell', 'emergency_exit'),
-                ('forcesell', 'force_exit'),
-                ('forcebuy', 'force_entry'),
-                ('emergencyexit', 'emergency_exit'),
-                ('forceexit', 'force_exit'),
-                ('forceentry', 'force_entry'),
+                ("buy", "entry"),
+                ("sell", "exit"),
+                ("emergencysell", "emergency_exit"),
+                ("forcesell", "force_exit"),
+                ("forcebuy", "force_entry"),
+                ("emergencyexit", "emergency_exit"),
+                ("forceexit", "force_exit"),
+                ("forceentry", "force_entry"),
             ]:
-
-                process_deprecated_setting(conf, 'order_types', o, 'order_types', n)
+                process_deprecated_setting(conf, "order_types", o, "order_types", n)
 
 
 def _validate_unfilledtimeout(conf: Dict[str, Any]) -> None:
-    unfilledtimeout = conf.get('unfilledtimeout', {})
-    if any(x in unfilledtimeout for x in ['buy', 'sell']):
-        if conf.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT:
+    unfilledtimeout = conf.get("unfilledtimeout", {})
+    if any(x in unfilledtimeout for x in ["buy", "sell"]):
+        if conf.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT:
             raise ConfigurationError(
-                "Please migrate your unfilledtimeout settings to use the new wording.")
+                "Please migrate your unfilledtimeout settings to use the new wording."
+            )
         else:
-
             logger.warning(
                 "DEPRECATED: Using 'buy' and 'sell' for unfilledtimeout is deprecated."
                 "Please migrate your unfilledtimeout settings to use 'entry' and 'exit' wording."
             )
             for o, n in [
-                ('buy', 'entry'),
-                ('sell', 'exit'),
+                ("buy", "entry"),
+                ("sell", "exit"),
             ]:
-
-                process_deprecated_setting(conf, 'unfilledtimeout', o, 'unfilledtimeout', n)
+                process_deprecated_setting(conf, "unfilledtimeout", o, "unfilledtimeout", n)
 
 
 def _validate_pricing_rules(conf: Dict[str, Any]) -> None:
-
-    if conf.get('ask_strategy') or conf.get('bid_strategy'):
-        if conf.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT:
-            raise ConfigurationError(
-                "Please migrate your pricing settings to use the new wording.")
+    if conf.get("ask_strategy") or conf.get("bid_strategy"):
+        if conf.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT:
+            raise ConfigurationError("Please migrate your pricing settings to use the new wording.")
         else:
-
             logger.warning(
                 "DEPRECATED: Using 'ask_strategy' and 'bid_strategy' is deprecated."
                 "Please migrate your settings to use 'entry_pricing' and 'exit_pricing'."
             )
-            conf['entry_pricing'] = {}
-            for obj in list(conf.get('bid_strategy', {}).keys()):
-                if obj == 'ask_last_balance':
-                    process_deprecated_setting(conf, 'bid_strategy', obj,
-                                               'entry_pricing', 'price_last_balance')
+            conf["entry_pricing"] = {}
+            for obj in list(conf.get("bid_strategy", {}).keys()):
+                if obj == "ask_last_balance":
+                    process_deprecated_setting(
+                        conf, "bid_strategy", obj, "entry_pricing", "price_last_balance"
+                    )
                 else:
-                    process_deprecated_setting(conf, 'bid_strategy', obj, 'entry_pricing', obj)
-            del conf['bid_strategy']
+                    process_deprecated_setting(conf, "bid_strategy", obj, "entry_pricing", obj)
+            del conf["bid_strategy"]
 
-            conf['exit_pricing'] = {}
-            for obj in list(conf.get('ask_strategy', {}).keys()):
-                if obj == 'bid_last_balance':
-                    process_deprecated_setting(conf, 'ask_strategy', obj,
-                                               'exit_pricing', 'price_last_balance')
+            conf["exit_pricing"] = {}
+            for obj in list(conf.get("ask_strategy", {}).keys()):
+                if obj == "bid_last_balance":
+                    process_deprecated_setting(
+                        conf, "ask_strategy", obj, "exit_pricing", "price_last_balance"
+                    )
                 else:
-                    process_deprecated_setting(conf, 'ask_strategy', obj, 'exit_pricing', obj)
-            del conf['ask_strategy']
+                    process_deprecated_setting(conf, "ask_strategy", obj, "exit_pricing", obj)
+            del conf["ask_strategy"]
 
 
 def _validate_freqai_hyperopt(conf: Dict[str, Any]) -> None:
-    freqai_enabled = conf.get('freqai', {}).get('enabled', False)
-    analyze_per_epoch = conf.get('analyze_per_epoch', False)
+    freqai_enabled = conf.get("freqai", {}).get("enabled", False)
+    analyze_per_epoch = conf.get("analyze_per_epoch", False)
     if analyze_per_epoch and freqai_enabled:
         raise ConfigurationError(
-            'Using analyze-per-epoch parameter is not supported with a FreqAI strategy.')
+            "Using analyze-per-epoch parameter is not supported with a FreqAI strategy."
+        )
 
 
 def _validate_freqai_include_timeframes(conf: Dict[str, Any], preliminary: bool) -> None:
-    freqai_enabled = conf.get('freqai', {}).get('enabled', False)
+    freqai_enabled = conf.get("freqai", {}).get("enabled", False)
     if freqai_enabled:
-        main_tf = conf.get('timeframe', '5m')
-        freqai_include_timeframes = conf.get('freqai', {}).get('feature_parameters', {}
-                                                               ).get('include_timeframes', [])
+        main_tf = conf.get("timeframe", "5m")
+        freqai_include_timeframes = (
+            conf.get("freqai", {}).get("feature_parameters", {}).get("include_timeframes", [])
+        )
 
         from freqtrade.exchange import timeframe_to_seconds
+
         main_tf_s = timeframe_to_seconds(main_tf)
         offending_lines = []
         for tf in freqai_include_timeframes:
             tf_s = timeframe_to_seconds(tf)
             if tf_s < main_tf_s:
                 offending_lines.append(tf)
         if offending_lines:
             raise ConfigurationError(
                 f"Main timeframe of {main_tf} must be smaller or equal to FreqAI "
-                f"`include_timeframes`.Offending include-timeframes: {', '.join(offending_lines)}")
+                f"`include_timeframes`.Offending include-timeframes: {', '.join(offending_lines)}"
+            )
 
         # Ensure that the base timeframe is included in the include_timeframes list
         if not preliminary and main_tf not in freqai_include_timeframes:
-            feature_parameters = conf.get('freqai', {}).get('feature_parameters', {})
+            feature_parameters = conf.get("freqai", {}).get("feature_parameters", {})
             include_timeframes = [main_tf] + freqai_include_timeframes
-            conf.get('freqai', {}).get('feature_parameters', {}) \
-                .update({**feature_parameters, 'include_timeframes': include_timeframes})
+            conf.get("freqai", {}).get("feature_parameters", {}).update(
+                {**feature_parameters, "include_timeframes": include_timeframes}
+            )
 
 
 def _validate_freqai_backtest(conf: Dict[str, Any]) -> None:
-    if conf.get('runmode', RunMode.OTHER) == RunMode.BACKTEST:
-        freqai_enabled = conf.get('freqai', {}).get('enabled', False)
-        timerange = conf.get('timerange')
-        freqai_backtest_live_models = conf.get('freqai_backtest_live_models', False)
+    if conf.get("runmode", RunMode.OTHER) == RunMode.BACKTEST:
+        freqai_enabled = conf.get("freqai", {}).get("enabled", False)
+        timerange = conf.get("timerange")
+        freqai_backtest_live_models = conf.get("freqai_backtest_live_models", False)
         if freqai_backtest_live_models and freqai_enabled and timerange:
             raise ConfigurationError(
-                'Using timerange parameter is not supported with '
-                '--freqai-backtest-live-models parameter.')
+                "Using timerange parameter is not supported with "
+                "--freqai-backtest-live-models parameter."
+            )
 
         if freqai_backtest_live_models and not freqai_enabled:
             raise ConfigurationError(
-                'Using --freqai-backtest-live-models parameter is only '
-                'supported with a FreqAI strategy.')
+                "Using --freqai-backtest-live-models parameter is only "
+                "supported with a FreqAI strategy."
+            )
 
         if freqai_enabled and not freqai_backtest_live_models and not timerange:
             raise ConfigurationError(
-                'Please pass --timerange if you intend to use FreqAI for backtesting.')
+                "Please pass --timerange if you intend to use FreqAI for backtesting."
+            )
 
 
 def _validate_consumers(conf: Dict[str, Any]) -> None:
-    emc_conf = conf.get('external_message_consumer', {})
-    if emc_conf.get('enabled', False):
-        if len(emc_conf.get('producers', [])) < 1:
+    emc_conf = conf.get("external_message_consumer", {})
+    if emc_conf.get("enabled", False):
+        if len(emc_conf.get("producers", [])) < 1:
             raise ConfigurationError("You must specify at least 1 Producer to connect to.")
 
-        producer_names = [p['name'] for p in emc_conf.get('producers', [])]
+        producer_names = [p["name"] for p in emc_conf.get("producers", [])]
         duplicates = [item for item, count in Counter(producer_names).items() if count > 1]
         if duplicates:
             raise ConfigurationError(
-                f"Producer names must be unique. Duplicate: {', '.join(duplicates)}")
-        if conf.get('process_only_new_candles', True):
+                f"Producer names must be unique. Duplicate: {', '.join(duplicates)}"
+            )
+        if conf.get("process_only_new_candles", True):
             # Warning here or require it?
-            logger.warning("To receive best performance with external data, "
-                           "please set `process_only_new_candles` to False")
+            logger.warning(
+                "To receive best performance with external data, "
+                "please set `process_only_new_candles` to False"
+            )
 
 
 def _strategy_settings(conf: Dict[str, Any]) -> None:
-
-    process_deprecated_setting(conf, None, 'use_sell_signal', None, 'use_exit_signal')
-    process_deprecated_setting(conf, None, 'sell_profit_only', None, 'exit_profit_only')
-    process_deprecated_setting(conf, None, 'sell_profit_offset', None, 'exit_profit_offset')
-    process_deprecated_setting(conf, None, 'ignore_roi_if_buy_signal',
-                               None, 'ignore_roi_if_entry_signal')
+    process_deprecated_setting(conf, None, "use_sell_signal", None, "use_exit_signal")
+    process_deprecated_setting(conf, None, "sell_profit_only", None, "exit_profit_only")
+    process_deprecated_setting(conf, None, "sell_profit_offset", None, "exit_profit_offset")
+    process_deprecated_setting(
+        conf, None, "ignore_roi_if_buy_signal", None, "ignore_roi_if_entry_signal"
+    )
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/configuration.py` & `freqtrade-2024.5/freqtrade/configuration/configuration.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 This module contains the configuration class
 """
+
 import logging
 import warnings
 from copy import deepcopy
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Tuple
 
 from freqtrade import constants
@@ -52,40 +53,41 @@
         override the same parameter from an earlier file (last definition wins).
         Runs through the whole Configuration initialization, so all expected config entries
         are available to interactive environments.
         :param files: List of file paths
         :return: configuration dictionary
         """
         # Keep this method as staticmethod, so it can be used from interactive environments
-        c = Configuration({'config': files}, RunMode.OTHER)
+        c = Configuration({"config": files}, RunMode.OTHER)
         return c.get_config()
 
     def load_config(self) -> Dict[str, Any]:
         """
         Extract information for sys.argv and load the bot configuration
         :return: Configuration dictionary
         """
         # Load all configs
         config: Config = load_from_files(self.args.get("config", []))
 
         # Load environment variables
         from freqtrade.commands.arguments import NO_CONF_ALLOWED
-        if self.args.get('command') not in NO_CONF_ALLOWED:
+
+        if self.args.get("command") not in NO_CONF_ALLOWED:
             env_data = enironment_vars_to_dict()
             config = deep_merge_dicts(env_data, config)
 
         # Normalize config
-        if 'internals' not in config:
-            config['internals'] = {}
+        if "internals" not in config:
+            config["internals"] = {}
 
-        if 'pairlists' not in config:
-            config['pairlists'] = []
+        if "pairlists" not in config:
+            config["pairlists"] = []
 
         # Keep a copy of the original configuration file
-        config['original_config'] = deepcopy(config)
+        config["original_config"] = deepcopy(config)
 
         self._process_logging_options(config)
 
         self._process_runmode(config)
 
         self._process_common_options(config)
 
@@ -101,332 +103,368 @@
 
         self._process_freqai_options(config)
 
         # Import check_exchange here to avoid import cycle problems
         from freqtrade.exchange.check_exchange import check_exchange
 
         # Check if the exchange set by the user is supported
-        check_exchange(config, config.get('experimental', {}).get('block_bad_exchanges', True))
+        check_exchange(config, config.get("experimental", {}).get("block_bad_exchanges", True))
 
         self._resolve_pairs_list(config)
 
         process_temporary_deprecated_settings(config)
 
         return config
 
     def _process_logging_options(self, config: Config) -> None:
         """
         Extract information for sys.argv and load logging configuration:
         the -v/--verbose, --logfile options
         """
         # Log level
-        config.update({'verbosity': self.args.get('verbosity', 0)})
+        config.update({"verbosity": self.args.get("verbosity", 0)})
 
-        if 'logfile' in self.args and self.args['logfile']:
-            config.update({'logfile': self.args['logfile']})
+        if "logfile" in self.args and self.args["logfile"]:
+            config.update({"logfile": self.args["logfile"]})
 
         setup_logging(config)
 
     def _process_trading_options(self, config: Config) -> None:
-        if config['runmode'] not in TRADE_MODES:
+        if config["runmode"] not in TRADE_MODES:
             return
 
-        if config.get('dry_run', False):
-            logger.info('Dry run is enabled')
-            if config.get('db_url') in [None, constants.DEFAULT_DB_PROD_URL]:
+        if config.get("dry_run", False):
+            logger.info("Dry run is enabled")
+            if config.get("db_url") in [None, constants.DEFAULT_DB_PROD_URL]:
                 # Default to in-memory db for dry_run if not specified
-                config['db_url'] = constants.DEFAULT_DB_DRYRUN_URL
+                config["db_url"] = constants.DEFAULT_DB_DRYRUN_URL
         else:
-            if not config.get('db_url'):
-                config['db_url'] = constants.DEFAULT_DB_PROD_URL
-            logger.info('Dry run is disabled')
+            if not config.get("db_url"):
+                config["db_url"] = constants.DEFAULT_DB_PROD_URL
+            logger.info("Dry run is disabled")
 
         logger.info(f'Using DB: "{parse_db_uri_for_logging(config["db_url"])}"')
 
     def _process_common_options(self, config: Config) -> None:
-
         # Set strategy if not specified in config and or if it's non default
-        if self.args.get('strategy') or not config.get('strategy'):
-            config.update({'strategy': self.args.get('strategy')})
+        if self.args.get("strategy") or not config.get("strategy"):
+            config.update({"strategy": self.args.get("strategy")})
 
-        self._args_to_config(config, argname='strategy_path',
-                             logstring='Using additional Strategy lookup path: {}')
+        self._args_to_config(
+            config, argname="strategy_path", logstring="Using additional Strategy lookup path: {}"
+        )
 
-        if ('db_url' in self.args and self.args['db_url'] and
-                self.args['db_url'] != constants.DEFAULT_DB_PROD_URL):
-            config.update({'db_url': self.args['db_url']})
-            logger.info('Parameter --db-url detected ...')
+        if (
+            "db_url" in self.args
+            and self.args["db_url"]
+            and self.args["db_url"] != constants.DEFAULT_DB_PROD_URL
+        ):
+            config.update({"db_url": self.args["db_url"]})
+            logger.info("Parameter --db-url detected ...")
 
-        self._args_to_config(config, argname='db_url_from',
-                             logstring='Parameter --db-url-from detected ...')
+        self._args_to_config(
+            config, argname="db_url_from", logstring="Parameter --db-url-from detected ..."
+        )
 
-        if config.get('force_entry_enable', False):
-            logger.warning('`force_entry_enable` RPC message enabled.')
+        if config.get("force_entry_enable", False):
+            logger.warning("`force_entry_enable` RPC message enabled.")
 
         # Support for sd_notify
-        if 'sd_notify' in self.args and self.args['sd_notify']:
-            config['internals'].update({'sd_notify': True})
+        if "sd_notify" in self.args and self.args["sd_notify"]:
+            config["internals"].update({"sd_notify": True})
 
     def _process_datadir_options(self, config: Config) -> None:
         """
         Extract information for sys.argv and load directory configurations
         --user-data, --datadir
         """
         # Check exchange parameter here - otherwise `datadir` might be wrong.
-        if 'exchange' in self.args and self.args['exchange']:
-            config['exchange']['name'] = self.args['exchange']
+        if "exchange" in self.args and self.args["exchange"]:
+            config["exchange"]["name"] = self.args["exchange"]
             logger.info(f"Using exchange {config['exchange']['name']}")
 
-        if 'pair_whitelist' not in config['exchange']:
-            config['exchange']['pair_whitelist'] = []
+        if "pair_whitelist" not in config["exchange"]:
+            config["exchange"]["pair_whitelist"] = []
 
-        if 'user_data_dir' in self.args and self.args['user_data_dir']:
-            config.update({'user_data_dir': self.args['user_data_dir']})
-        elif 'user_data_dir' not in config:
+        if "user_data_dir" in self.args and self.args["user_data_dir"]:
+            config.update({"user_data_dir": self.args["user_data_dir"]})
+        elif "user_data_dir" not in config:
             # Default to cwd/user_data (legacy option ...)
-            config.update({'user_data_dir': str(Path.cwd() / 'user_data')})
+            config.update({"user_data_dir": str(Path.cwd() / "user_data")})
 
         # reset to user_data_dir so this contains the absolute path.
-        config['user_data_dir'] = create_userdata_dir(config['user_data_dir'], create_dir=False)
-        logger.info('Using user-data directory: %s ...', config['user_data_dir'])
+        config["user_data_dir"] = create_userdata_dir(config["user_data_dir"], create_dir=False)
+        logger.info("Using user-data directory: %s ...", config["user_data_dir"])
 
-        config.update({'datadir': create_datadir(config, self.args.get('datadir'))})
-        logger.info('Using data directory: %s ...', config.get('datadir'))
+        config.update({"datadir": create_datadir(config, self.args.get("datadir"))})
+        logger.info("Using data directory: %s ...", config.get("datadir"))
 
-        if self.args.get('exportfilename'):
-            self._args_to_config(config, argname='exportfilename',
-                                 logstring='Storing backtest results to {} ...')
-            config['exportfilename'] = Path(config['exportfilename'])
+        if self.args.get("exportfilename"):
+            self._args_to_config(
+                config, argname="exportfilename", logstring="Storing backtest results to {} ..."
+            )
+            config["exportfilename"] = Path(config["exportfilename"])
         else:
-            config['exportfilename'] = (config['user_data_dir']
-                                        / 'backtest_results')
+            config["exportfilename"] = config["user_data_dir"] / "backtest_results"
 
-        if self.args.get('show_sensitive'):
+        if self.args.get("show_sensitive"):
             logger.warning(
                 "Sensitive information will be shown in the upcoming output. "
                 "Please make sure to never share this output without redacting "
-                "the information yourself.")
+                "the information yourself."
+            )
 
     def _process_optimize_options(self, config: Config) -> None:
-
         # This will override the strategy configuration
-        self._args_to_config(config, argname='timeframe',
-                             logstring='Parameter -i/--timeframe detected ... '
-                                       'Using timeframe: {} ...')
-
-        self._args_to_config(config, argname='position_stacking',
-                             logstring='Parameter --enable-position-stacking detected ...')
-
-        self._args_to_config(
-            config, argname='enable_protections',
-            logstring='Parameter --enable-protections detected, enabling Protections. ...')
-
-        if 'use_max_market_positions' in self.args and not self.args["use_max_market_positions"]:
-            config.update({'use_max_market_positions': False})
-            logger.info('Parameter --disable-max-market-positions detected ...')
-            logger.info('max_open_trades set to unlimited ...')
-        elif 'max_open_trades' in self.args and self.args['max_open_trades']:
-            config.update({'max_open_trades': self.args['max_open_trades']})
-            logger.info('Parameter --max-open-trades detected, '
-                        'overriding max_open_trades to: %s ...', config.get('max_open_trades'))
-        elif config['runmode'] in NON_UTIL_MODES:
-            logger.info('Using max_open_trades: %s ...', config.get('max_open_trades'))
+        self._args_to_config(
+            config,
+            argname="timeframe",
+            logstring="Parameter -i/--timeframe detected ... Using timeframe: {} ...",
+        )
+
+        self._args_to_config(
+            config,
+            argname="position_stacking",
+            logstring="Parameter --enable-position-stacking detected ...",
+        )
+
+        self._args_to_config(
+            config,
+            argname="enable_protections",
+            logstring="Parameter --enable-protections detected, enabling Protections. ...",
+        )
+
+        if "use_max_market_positions" in self.args and not self.args["use_max_market_positions"]:
+            config.update({"use_max_market_positions": False})
+            logger.info("Parameter --disable-max-market-positions detected ...")
+            logger.info("max_open_trades set to unlimited ...")
+        elif "max_open_trades" in self.args and self.args["max_open_trades"]:
+            config.update({"max_open_trades": self.args["max_open_trades"]})
+            logger.info(
+                "Parameter --max-open-trades detected, overriding max_open_trades to: %s ...",
+                config.get("max_open_trades"),
+            )
+        elif config["runmode"] in NON_UTIL_MODES:
+            logger.info("Using max_open_trades: %s ...", config.get("max_open_trades"))
         # Setting max_open_trades to infinite if -1
-        if config.get('max_open_trades') == -1:
-            config['max_open_trades'] = float('inf')
+        if config.get("max_open_trades") == -1:
+            config["max_open_trades"] = float("inf")
 
-        if self.args.get('stake_amount'):
+        if self.args.get("stake_amount"):
             # Convert explicitly to float to support CLI argument for both unlimited and value
             try:
-                self.args['stake_amount'] = float(self.args['stake_amount'])
+                self.args["stake_amount"] = float(self.args["stake_amount"])
             except ValueError:
                 pass
 
         configurations = [
-            ('timeframe_detail',
-             'Parameter --timeframe-detail detected, using {} for intra-candle backtesting ...'),
-            ('backtest_show_pair_list', 'Parameter --show-pair-list detected.'),
-            ('stake_amount',
-             'Parameter --stake-amount detected, overriding stake_amount to: {} ...'),
-            ('dry_run_wallet',
-             'Parameter --dry-run-wallet detected, overriding dry_run_wallet to: {} ...'),
-            ('fee', 'Parameter --fee detected, setting fee to: {} ...'),
-            ('timerange', 'Parameter --timerange detected: {} ...'),
-            ]
+            (
+                "timeframe_detail",
+                "Parameter --timeframe-detail detected, using {} for intra-candle backtesting ...",
+            ),
+            ("backtest_show_pair_list", "Parameter --show-pair-list detected."),
+            (
+                "stake_amount",
+                "Parameter --stake-amount detected, overriding stake_amount to: {} ...",
+            ),
+            (
+                "dry_run_wallet",
+                "Parameter --dry-run-wallet detected, overriding dry_run_wallet to: {} ...",
+            ),
+            ("fee", "Parameter --fee detected, setting fee to: {} ..."),
+            ("timerange", "Parameter --timerange detected: {} ..."),
+        ]
 
         self._args_to_config_loop(config, configurations)
 
         self._process_datadir_options(config)
 
-        self._args_to_config(config, argname='strategy_list',
-                             logstring='Using strategy list of {} strategies', logfun=len)
+        self._args_to_config(
+            config,
+            argname="strategy_list",
+            logstring="Using strategy list of {} strategies",
+            logfun=len,
+        )
 
         configurations = [
-            ('recursive_strategy_search',
-             'Recursively searching for a strategy in the strategies folder.'),
-            ('timeframe', 'Overriding timeframe with Command line argument'),
-            ('export', 'Parameter --export detected: {} ...'),
-            ('backtest_breakdown', 'Parameter --breakdown detected ...'),
-            ('backtest_cache', 'Parameter --cache={} detected ...'),
-            ('disableparamexport', 'Parameter --disableparamexport detected: {} ...'),
-            ('freqai_backtest_live_models',
-             'Parameter --freqai-backtest-live-models detected ...'),
+            (
+                "recursive_strategy_search",
+                "Recursively searching for a strategy in the strategies folder.",
+            ),
+            ("timeframe", "Overriding timeframe with Command line argument"),
+            ("export", "Parameter --export detected: {} ..."),
+            ("backtest_breakdown", "Parameter --breakdown detected ..."),
+            ("backtest_cache", "Parameter --cache={} detected ..."),
+            ("disableparamexport", "Parameter --disableparamexport detected: {} ..."),
+            ("freqai_backtest_live_models", "Parameter --freqai-backtest-live-models detected ..."),
         ]
         self._args_to_config_loop(config, configurations)
 
         # Edge section:
-        if 'stoploss_range' in self.args and self.args["stoploss_range"]:
+        if "stoploss_range" in self.args and self.args["stoploss_range"]:
             txt_range = eval(self.args["stoploss_range"])
-            config['edge'].update({'stoploss_range_min': txt_range[0]})
-            config['edge'].update({'stoploss_range_max': txt_range[1]})
-            config['edge'].update({'stoploss_range_step': txt_range[2]})
-            logger.info('Parameter --stoplosses detected: %s ...', self.args["stoploss_range"])
+            config["edge"].update({"stoploss_range_min": txt_range[0]})
+            config["edge"].update({"stoploss_range_max": txt_range[1]})
+            config["edge"].update({"stoploss_range_step": txt_range[2]})
+            logger.info("Parameter --stoplosses detected: %s ...", self.args["stoploss_range"])
 
         # Hyperopt section
 
         configurations = [
-            ('hyperopt', 'Using Hyperopt class name: {}'),
-            ('hyperopt_path', 'Using additional Hyperopt lookup path: {}'),
-            ('hyperoptexportfilename', 'Using hyperopt file: {}'),
-            ('lookahead_analysis_exportfilename', 'Saving lookahead analysis results into {} ...'),
-            ('epochs', 'Parameter --epochs detected ... Will run Hyperopt with for {} epochs ...'),
-            ('spaces', 'Parameter -s/--spaces detected: {}'),
-            ('analyze_per_epoch', 'Parameter --analyze-per-epoch detected.'),
-            ('print_all', 'Parameter --print-all detected ...'),
+            ("hyperopt", "Using Hyperopt class name: {}"),
+            ("hyperopt_path", "Using additional Hyperopt lookup path: {}"),
+            ("hyperoptexportfilename", "Using hyperopt file: {}"),
+            ("lookahead_analysis_exportfilename", "Saving lookahead analysis results into {} ..."),
+            ("epochs", "Parameter --epochs detected ... Will run Hyperopt with for {} epochs ..."),
+            ("spaces", "Parameter -s/--spaces detected: {}"),
+            ("analyze_per_epoch", "Parameter --analyze-per-epoch detected."),
+            ("print_all", "Parameter --print-all detected ..."),
         ]
         self._args_to_config_loop(config, configurations)
 
-        if 'print_colorized' in self.args and not self.args["print_colorized"]:
-            logger.info('Parameter --no-color detected ...')
-            config.update({'print_colorized': False})
+        if "print_colorized" in self.args and not self.args["print_colorized"]:
+            logger.info("Parameter --no-color detected ...")
+            config.update({"print_colorized": False})
         else:
-            config.update({'print_colorized': True})
+            config.update({"print_colorized": True})
 
         configurations = [
-            ('print_json', 'Parameter --print-json detected ...'),
-            ('export_csv', 'Parameter --export-csv detected: {}'),
-            ('hyperopt_jobs', 'Parameter -j/--job-workers detected: {}'),
-            ('hyperopt_random_state', 'Parameter --random-state detected: {}'),
-            ('hyperopt_min_trades', 'Parameter --min-trades detected: {}'),
-            ('hyperopt_loss', 'Using Hyperopt loss class name: {}'),
-            ('hyperopt_show_index', 'Parameter -n/--index detected: {}'),
-            ('hyperopt_list_best', 'Parameter --best detected: {}'),
-            ('hyperopt_list_profitable', 'Parameter --profitable detected: {}'),
-            ('hyperopt_list_min_trades', 'Parameter --min-trades detected: {}'),
-            ('hyperopt_list_max_trades', 'Parameter --max-trades detected: {}'),
-            ('hyperopt_list_min_avg_time', 'Parameter --min-avg-time detected: {}'),
-            ('hyperopt_list_max_avg_time', 'Parameter --max-avg-time detected: {}'),
-            ('hyperopt_list_min_avg_profit', 'Parameter --min-avg-profit detected: {}'),
-            ('hyperopt_list_max_avg_profit', 'Parameter --max-avg-profit detected: {}'),
-            ('hyperopt_list_min_total_profit', 'Parameter --min-total-profit detected: {}'),
-            ('hyperopt_list_max_total_profit', 'Parameter --max-total-profit detected: {}'),
-            ('hyperopt_list_min_objective', 'Parameter --min-objective detected: {}'),
-            ('hyperopt_list_max_objective', 'Parameter --max-objective detected: {}'),
-            ('hyperopt_list_no_details', 'Parameter --no-details detected: {}'),
-            ('hyperopt_show_no_header', 'Parameter --no-header detected: {}'),
-            ('hyperopt_ignore_missing_space', 'Paramter --ignore-missing-space detected: {}'),
+            ("print_json", "Parameter --print-json detected ..."),
+            ("export_csv", "Parameter --export-csv detected: {}"),
+            ("hyperopt_jobs", "Parameter -j/--job-workers detected: {}"),
+            ("hyperopt_random_state", "Parameter --random-state detected: {}"),
+            ("hyperopt_min_trades", "Parameter --min-trades detected: {}"),
+            ("hyperopt_loss", "Using Hyperopt loss class name: {}"),
+            ("hyperopt_show_index", "Parameter -n/--index detected: {}"),
+            ("hyperopt_list_best", "Parameter --best detected: {}"),
+            ("hyperopt_list_profitable", "Parameter --profitable detected: {}"),
+            ("hyperopt_list_min_trades", "Parameter --min-trades detected: {}"),
+            ("hyperopt_list_max_trades", "Parameter --max-trades detected: {}"),
+            ("hyperopt_list_min_avg_time", "Parameter --min-avg-time detected: {}"),
+            ("hyperopt_list_max_avg_time", "Parameter --max-avg-time detected: {}"),
+            ("hyperopt_list_min_avg_profit", "Parameter --min-avg-profit detected: {}"),
+            ("hyperopt_list_max_avg_profit", "Parameter --max-avg-profit detected: {}"),
+            ("hyperopt_list_min_total_profit", "Parameter --min-total-profit detected: {}"),
+            ("hyperopt_list_max_total_profit", "Parameter --max-total-profit detected: {}"),
+            ("hyperopt_list_min_objective", "Parameter --min-objective detected: {}"),
+            ("hyperopt_list_max_objective", "Parameter --max-objective detected: {}"),
+            ("hyperopt_list_no_details", "Parameter --no-details detected: {}"),
+            ("hyperopt_show_no_header", "Parameter --no-header detected: {}"),
+            ("hyperopt_ignore_missing_space", "Parameter --ignore-missing-space detected: {}"),
         ]
 
         self._args_to_config_loop(config, configurations)
 
     def _process_plot_options(self, config: Config) -> None:
-
         configurations = [
-            ('pairs', 'Using pairs {}'),
-            ('indicators1', 'Using indicators1: {}'),
-            ('indicators2', 'Using indicators2: {}'),
-            ('trade_ids', 'Filtering on trade_ids: {}'),
-            ('plot_limit', 'Limiting plot to: {}'),
-            ('plot_auto_open', 'Parameter --auto-open detected.'),
-            ('trade_source', 'Using trades from: {}'),
-            ('prepend_data', 'Prepend detected. Allowing data prepending.'),
-            ('erase', 'Erase detected. Deleting existing data.'),
-            ('no_trades', 'Parameter --no-trades detected.'),
-            ('timeframes', 'timeframes --timeframes: {}'),
-            ('days', 'Detected --days: {}'),
-            ('include_inactive', 'Detected --include-inactive-pairs: {}'),
-            ('download_trades', 'Detected --dl-trades: {}'),
-            ('dataformat_ohlcv', 'Using "{}" to store OHLCV data.'),
-            ('dataformat_trades', 'Using "{}" to store trades data.'),
-            ('show_timerange', 'Detected --show-timerange'),
+            ("pairs", "Using pairs {}"),
+            ("indicators1", "Using indicators1: {}"),
+            ("indicators2", "Using indicators2: {}"),
+            ("trade_ids", "Filtering on trade_ids: {}"),
+            ("plot_limit", "Limiting plot to: {}"),
+            ("plot_auto_open", "Parameter --auto-open detected."),
+            ("trade_source", "Using trades from: {}"),
+            ("prepend_data", "Prepend detected. Allowing data prepending."),
+            ("erase", "Erase detected. Deleting existing data."),
+            ("no_trades", "Parameter --no-trades detected."),
+            ("timeframes", "timeframes --timeframes: {}"),
+            ("days", "Detected --days: {}"),
+            ("include_inactive", "Detected --include-inactive-pairs: {}"),
+            ("download_trades", "Detected --dl-trades: {}"),
+            ("convert_trades", "Detected --convert: {} - Converting Trade data to OHCV {}"),
+            ("dataformat_ohlcv", 'Using "{}" to store OHLCV data.'),
+            ("dataformat_trades", 'Using "{}" to store trades data.'),
+            ("show_timerange", "Detected --show-timerange"),
         ]
         self._args_to_config_loop(config, configurations)
 
     def _process_data_options(self, config: Config) -> None:
-        self._args_to_config(config, argname='new_pairs_days',
-                             logstring='Detected --new-pairs-days: {}')
-        self._args_to_config(config, argname='trading_mode',
-                             logstring='Detected --trading-mode: {}')
-        config['candle_type_def'] = CandleType.get_default(
-            config.get('trading_mode', 'spot') or 'spot')
-        config['trading_mode'] = TradingMode(config.get('trading_mode', 'spot') or 'spot')
-        self._args_to_config(config, argname='candle_types',
-                             logstring='Detected --candle-types: {}')
+        self._args_to_config(
+            config, argname="new_pairs_days", logstring="Detected --new-pairs-days: {}"
+        )
+        self._args_to_config(
+            config, argname="trading_mode", logstring="Detected --trading-mode: {}"
+        )
+        config["candle_type_def"] = CandleType.get_default(
+            config.get("trading_mode", "spot") or "spot"
+        )
+        config["trading_mode"] = TradingMode(config.get("trading_mode", "spot") or "spot")
+        self._args_to_config(
+            config, argname="candle_types", logstring="Detected --candle-types: {}"
+        )
 
     def _process_analyze_options(self, config: Config) -> None:
         configurations = [
-            ('analysis_groups', 'Analysis reason groups: {}'),
-            ('enter_reason_list', 'Analysis enter tag list: {}'),
-            ('exit_reason_list', 'Analysis exit tag list: {}'),
-            ('indicator_list', 'Analysis indicator list: {}'),
-            ('timerange', 'Filter trades by timerange: {}'),
-            ('analysis_rejected', 'Analyse rejected signals: {}'),
-            ('analysis_to_csv', 'Store analysis tables to CSV: {}'),
-            ('analysis_csv_path', 'Path to store analysis CSVs: {}'),
+            ("analysis_groups", "Analysis reason groups: {}"),
+            ("enter_reason_list", "Analysis enter tag list: {}"),
+            ("exit_reason_list", "Analysis exit tag list: {}"),
+            ("indicator_list", "Analysis indicator list: {}"),
+            ("timerange", "Filter trades by timerange: {}"),
+            ("analysis_rejected", "Analyse rejected signals: {}"),
+            ("analysis_to_csv", "Store analysis tables to CSV: {}"),
+            ("analysis_csv_path", "Path to store analysis CSVs: {}"),
             # Lookahead analysis results
-            ('targeted_trade_amount', 'Targeted Trade amount: {}'),
-            ('minimum_trade_amount', 'Minimum Trade amount: {}'),
-            ('lookahead_analysis_exportfilename', 'Path to store lookahead-analysis-results: {}'),
-            ('startup_candle', 'Startup candle to be used on recursive analysis: {}'),
+            ("targeted_trade_amount", "Targeted Trade amount: {}"),
+            ("minimum_trade_amount", "Minimum Trade amount: {}"),
+            ("lookahead_analysis_exportfilename", "Path to store lookahead-analysis-results: {}"),
+            ("startup_candle", "Startup candle to be used on recursive analysis: {}"),
         ]
         self._args_to_config_loop(config, configurations)
 
     def _args_to_config_loop(self, config, configurations: List[Tuple[str, str]]) -> None:
-
         for argname, logstring in configurations:
             self._args_to_config(config, argname=argname, logstring=logstring)
 
     def _process_runmode(self, config: Config) -> None:
-
-        self._args_to_config(config, argname='dry_run',
-                             logstring='Parameter --dry-run detected, '
-                             'overriding dry_run to: {} ...')
+        self._args_to_config(
+            config,
+            argname="dry_run",
+            logstring="Parameter --dry-run detected, overriding dry_run to: {} ...",
+        )
 
         if not self.runmode:
             # Handle real mode, infer dry/live from config
-            self.runmode = RunMode.DRY_RUN if config.get('dry_run', True) else RunMode.LIVE
+            self.runmode = RunMode.DRY_RUN if config.get("dry_run", True) else RunMode.LIVE
             logger.info(f"Runmode set to {self.runmode.value}.")
 
-        config.update({'runmode': self.runmode})
+        config.update({"runmode": self.runmode})
 
     def _process_freqai_options(self, config: Config) -> None:
+        self._args_to_config(
+            config, argname="freqaimodel", logstring="Using freqaimodel class name: {}"
+        )
 
-        self._args_to_config(config, argname='freqaimodel',
-                             logstring='Using freqaimodel class name: {}')
-
-        self._args_to_config(config, argname='freqaimodel_path',
-                             logstring='Using freqaimodel path: {}')
+        self._args_to_config(
+            config, argname="freqaimodel_path", logstring="Using freqaimodel path: {}"
+        )
 
         return
 
-    def _args_to_config(self, config: Config, argname: str,
-                        logstring: str, logfun: Optional[Callable] = None,
-                        deprecated_msg: Optional[str] = None) -> None:
+    def _args_to_config(
+        self,
+        config: Config,
+        argname: str,
+        logstring: str,
+        logfun: Optional[Callable] = None,
+        deprecated_msg: Optional[str] = None,
+    ) -> None:
         """
         :param config: Configuration dictionary
         :param argname: Argumentname in self.args - will be copied to config dict.
         :param logstring: Logging String
         :param logfun: logfun is applied to the configuration entry before passing
                         that entry to the log string using .format().
                         sample: logfun=len (prints the length of the found
                         configuration instead of the content)
         """
-        if (argname in self.args and self.args[argname] is not None
-                and self.args[argname] is not False):
-
+        if (
+            argname in self.args
+            and self.args[argname] is not None
+            and self.args[argname] is not False
+        ):
             config.update({argname: self.args[argname]})
             if logfun:
                 logger.info(logstring.format(logfun(config[argname])))
             else:
                 logger.info(logstring.format(config[argname]))
             if deprecated_msg:
                 warnings.warn(f"DEPRECATED: {deprecated_msg}", DeprecationWarning)
@@ -437,33 +475,33 @@
         Takes first found:
         * -p (pairs argument)
         * --pairs-file
         * whitelist from config
         """
 
         if "pairs" in config:
-            config['exchange']['pair_whitelist'] = config['pairs']
+            config["exchange"]["pair_whitelist"] = config["pairs"]
             return
 
         if "pairs_file" in self.args and self.args["pairs_file"]:
             pairs_file = Path(self.args["pairs_file"])
             logger.info(f'Reading pairs file "{pairs_file}".')
             # Download pairs from the pairs file if no config is specified
             # or if pairs file is specified explicitly
             if not pairs_file.exists():
                 raise OperationalException(f'No pairs file found with path "{pairs_file}".')
-            config['pairs'] = load_file(pairs_file)
-            if isinstance(config['pairs'], list):
-                config['pairs'].sort()
+            config["pairs"] = load_file(pairs_file)
+            if isinstance(config["pairs"], list):
+                config["pairs"].sort()
             return
 
-        if 'config' in self.args and self.args['config']:
+        if "config" in self.args and self.args["config"]:
             logger.info("Using pairlist from configuration.")
-            config['pairs'] = config.get('exchange', {}).get('pair_whitelist')
+            config["pairs"] = config.get("exchange", {}).get("pair_whitelist")
         else:
             # Fall back to /dl_path/pairs.json
-            pairs_file = config['datadir'] / 'pairs.json'
+            pairs_file = config["datadir"] / "pairs.json"
             if pairs_file.exists():
                 logger.info(f'Reading pairs file "{pairs_file}".')
-                config['pairs'] = load_file(pairs_file)
-                if 'pairs' in config and isinstance(config['pairs'], list):
-                    config['pairs'].sort()
+                config["pairs"] = load_file(pairs_file)
+                if "pairs" in config and isinstance(config["pairs"], list):
+                    config["pairs"].sort()
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/deprecated_settings.py` & `freqtrade-2024.5/freqtrade/configuration/deprecated_settings.py`

 * *Files 25% similar despite different names*

```diff
@@ -8,34 +8,38 @@
 from freqtrade.constants import Config
 from freqtrade.exceptions import ConfigurationError, OperationalException
 
 
 logger = logging.getLogger(__name__)
 
 
-def check_conflicting_settings(config: Config,
-                               section_old: Optional[str], name_old: str,
-                               section_new: Optional[str], name_new: str) -> None:
+def check_conflicting_settings(
+    config: Config,
+    section_old: Optional[str],
+    name_old: str,
+    section_new: Optional[str],
+    name_new: str,
+) -> None:
     section_new_config = config.get(section_new, {}) if section_new else config
     section_old_config = config.get(section_old, {}) if section_old else config
     if name_new in section_new_config and name_old in section_old_config:
         new_name = f"{section_new}.{name_new}" if section_new else f"{name_new}"
         old_name = f"{section_old}.{name_old}" if section_old else f"{name_old}"
         raise OperationalException(
             f"Conflicting settings `{new_name}` and `{old_name}` "
             "(DEPRECATED) detected in the configuration file. "
             "This deprecated setting will be removed in the next versions of Freqtrade. "
             f"Please delete it from your configuration and use the `{new_name}` "
             "setting instead."
         )
 
 
-def process_removed_setting(config: Config,
-                            section1: str, name1: str,
-                            section2: Optional[str], name2: str) -> None:
+def process_removed_setting(
+    config: Config, section1: str, name1: str, section2: Optional[str], name2: str
+) -> None:
     """
     :param section1: Removed section
     :param name1: Removed setting name
     :param section2: new section for this key
     :param name2: new setting name
     """
     section1_config = config.get(section1, {})
@@ -44,18 +48,21 @@
         raise ConfigurationError(
             f"Setting `{section1}.{name1}` has been moved to `{section_2}. "
             f"Please delete it from your configuration and use the `{section_2}` "
             "setting instead."
         )
 
 
-def process_deprecated_setting(config: Config,
-                               section_old: Optional[str], name_old: str,
-                               section_new: Optional[str], name_new: str
-                               ) -> None:
+def process_deprecated_setting(
+    config: Config,
+    section_old: Optional[str],
+    name_old: str,
+    section_new: Optional[str],
+    name_new: str,
+) -> None:
     check_conflicting_settings(config, section_old, name_old, section_new, name_new)
     section_old_config = config.get(section_old, {}) if section_old else config
 
     if name_old in section_old_config:
         section_1 = f"{section_old}.{name_old}" if section_old else f"{name_old}"
         section_2 = f"{section_new}.{name_new}" if section_new else f"{name_new}"
         logger.warning(
@@ -67,74 +74,107 @@
 
         section_new_config = config.get(section_new, {}) if section_new else config
         section_new_config[name_new] = section_old_config[name_old]
         del section_old_config[name_old]
 
 
 def process_temporary_deprecated_settings(config: Config) -> None:
-
     # Kept for future deprecated / moved settings
     # check_conflicting_settings(config, 'ask_strategy', 'use_sell_signal',
     #                            'experimental', 'use_sell_signal')
 
-    process_deprecated_setting(config, 'ask_strategy', 'ignore_buying_expired_candle_after',
-                               None, 'ignore_buying_expired_candle_after')
+    process_deprecated_setting(
+        config,
+        "ask_strategy",
+        "ignore_buying_expired_candle_after",
+        None,
+        "ignore_buying_expired_candle_after",
+    )
 
-    process_deprecated_setting(config, None, 'forcebuy_enable', None, 'force_entry_enable')
+    process_deprecated_setting(config, None, "forcebuy_enable", None, "force_entry_enable")
 
     # New settings
-    if config.get('telegram'):
-        process_deprecated_setting(config['telegram'], 'notification_settings', 'sell',
-                                   'notification_settings', 'exit')
-        process_deprecated_setting(config['telegram'], 'notification_settings', 'sell_fill',
-                                   'notification_settings', 'exit_fill')
-        process_deprecated_setting(config['telegram'], 'notification_settings', 'sell_cancel',
-                                   'notification_settings', 'exit_cancel')
-        process_deprecated_setting(config['telegram'], 'notification_settings', 'buy',
-                                   'notification_settings', 'entry')
-        process_deprecated_setting(config['telegram'], 'notification_settings', 'buy_fill',
-                                   'notification_settings', 'entry_fill')
-        process_deprecated_setting(config['telegram'], 'notification_settings', 'buy_cancel',
-                                   'notification_settings', 'entry_cancel')
-    if config.get('webhook'):
-        process_deprecated_setting(config, 'webhook', 'webhookbuy', 'webhook', 'webhookentry')
-        process_deprecated_setting(config, 'webhook', 'webhookbuycancel',
-                                   'webhook', 'webhookentrycancel')
-        process_deprecated_setting(config, 'webhook', 'webhookbuyfill',
-                                   'webhook', 'webhookentryfill')
-        process_deprecated_setting(config, 'webhook', 'webhooksell', 'webhook', 'webhookexit')
-        process_deprecated_setting(config, 'webhook', 'webhooksellcancel',
-                                   'webhook', 'webhookexitcancel')
-        process_deprecated_setting(config, 'webhook', 'webhooksellfill',
-                                   'webhook', 'webhookexitfill')
+    if config.get("telegram"):
+        process_deprecated_setting(
+            config["telegram"], "notification_settings", "sell", "notification_settings", "exit"
+        )
+        process_deprecated_setting(
+            config["telegram"],
+            "notification_settings",
+            "sell_fill",
+            "notification_settings",
+            "exit_fill",
+        )
+        process_deprecated_setting(
+            config["telegram"],
+            "notification_settings",
+            "sell_cancel",
+            "notification_settings",
+            "exit_cancel",
+        )
+        process_deprecated_setting(
+            config["telegram"], "notification_settings", "buy", "notification_settings", "entry"
+        )
+        process_deprecated_setting(
+            config["telegram"],
+            "notification_settings",
+            "buy_fill",
+            "notification_settings",
+            "entry_fill",
+        )
+        process_deprecated_setting(
+            config["telegram"],
+            "notification_settings",
+            "buy_cancel",
+            "notification_settings",
+            "entry_cancel",
+        )
+    if config.get("webhook"):
+        process_deprecated_setting(config, "webhook", "webhookbuy", "webhook", "webhookentry")
+        process_deprecated_setting(
+            config, "webhook", "webhookbuycancel", "webhook", "webhookentrycancel"
+        )
+        process_deprecated_setting(
+            config, "webhook", "webhookbuyfill", "webhook", "webhookentryfill"
+        )
+        process_deprecated_setting(config, "webhook", "webhooksell", "webhook", "webhookexit")
+        process_deprecated_setting(
+            config, "webhook", "webhooksellcancel", "webhook", "webhookexitcancel"
+        )
+        process_deprecated_setting(
+            config, "webhook", "webhooksellfill", "webhook", "webhookexitfill"
+        )
 
     # Legacy way - having them in experimental ...
 
-    process_removed_setting(config, 'experimental', 'use_sell_signal', None, 'use_exit_signal')
-    process_removed_setting(config, 'experimental', 'sell_profit_only', None, 'exit_profit_only')
-    process_removed_setting(config, 'experimental', 'ignore_roi_if_buy_signal',
-                            None, 'ignore_roi_if_entry_signal')
-
-    process_removed_setting(config, 'ask_strategy', 'use_sell_signal', None, 'use_exit_signal')
-    process_removed_setting(config, 'ask_strategy', 'sell_profit_only', None, 'exit_profit_only')
-    process_removed_setting(config, 'ask_strategy', 'sell_profit_offset',
-                            None, 'exit_profit_offset')
-    process_removed_setting(config, 'ask_strategy', 'ignore_roi_if_buy_signal',
-                            None, 'ignore_roi_if_entry_signal')
-    if (config.get('edge', {}).get('enabled', False)
-       and 'capital_available_percentage' in config.get('edge', {})):
+    process_removed_setting(config, "experimental", "use_sell_signal", None, "use_exit_signal")
+    process_removed_setting(config, "experimental", "sell_profit_only", None, "exit_profit_only")
+    process_removed_setting(
+        config, "experimental", "ignore_roi_if_buy_signal", None, "ignore_roi_if_entry_signal"
+    )
+
+    process_removed_setting(config, "ask_strategy", "use_sell_signal", None, "use_exit_signal")
+    process_removed_setting(config, "ask_strategy", "sell_profit_only", None, "exit_profit_only")
+    process_removed_setting(
+        config, "ask_strategy", "sell_profit_offset", None, "exit_profit_offset"
+    )
+    process_removed_setting(
+        config, "ask_strategy", "ignore_roi_if_buy_signal", None, "ignore_roi_if_entry_signal"
+    )
+    if config.get("edge", {}).get(
+        "enabled", False
+    ) and "capital_available_percentage" in config.get("edge", {}):
         raise ConfigurationError(
             "DEPRECATED: "
             "Using 'edge.capital_available_percentage' has been deprecated in favor of "
             "'tradable_balance_ratio'. Please migrate your configuration to "
             "'tradable_balance_ratio' and remove 'capital_available_percentage' "
             "from the edge configuration."
         )
-    if 'ticker_interval' in config:
-
+    if "ticker_interval" in config:
         raise ConfigurationError(
             "DEPRECATED: 'ticker_interval' detected. "
             "Please use 'timeframe' instead of 'ticker_interval."
         )
 
-    if 'protections' in config:
+    if "protections" in config:
         logger.warning("DEPRECATED: Setting 'protections' in the configuration is deprecated.")
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/directory_operations.py` & `freqtrade-2024.5/freqtrade/configuration/directory_operations.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,71 +1,86 @@
 import logging
 import shutil
 from pathlib import Path
 from typing import Optional
 
 from freqtrade.configuration.detect_environment import running_in_docker
-from freqtrade.constants import (USER_DATA_FILES, USERPATH_FREQAIMODELS, USERPATH_HYPEROPTS,
-                                 USERPATH_NOTEBOOKS, USERPATH_STRATEGIES, Config)
+from freqtrade.constants import (
+    USER_DATA_FILES,
+    USERPATH_FREQAIMODELS,
+    USERPATH_HYPEROPTS,
+    USERPATH_NOTEBOOKS,
+    USERPATH_STRATEGIES,
+    Config,
+)
 from freqtrade.exceptions import OperationalException
 
 
 logger = logging.getLogger(__name__)
 
 
 def create_datadir(config: Config, datadir: Optional[str] = None) -> Path:
-
     folder = Path(datadir) if datadir else Path(f"{config['user_data_dir']}/data")
     if not datadir:
         # set datadir
-        exchange_name = config.get('exchange', {}).get('name', '').lower()
+        exchange_name = config.get("exchange", {}).get("name", "").lower()
         folder = folder.joinpath(exchange_name)
 
     if not folder.is_dir():
         folder.mkdir(parents=True)
-        logger.info(f'Created data directory: {datadir}')
+        logger.info(f"Created data directory: {datadir}")
     return folder
 
 
 def chown_user_directory(directory: Path) -> None:
     """
     Use Sudo to change permissions of the home-directory if necessary
     Only applies when running in docker!
     """
     if running_in_docker():
         try:
             import subprocess
-            subprocess.check_output(
-                ['sudo', 'chown', '-R', 'ftuser:', str(directory.resolve())])
+
+            subprocess.check_output(["sudo", "chown", "-R", "ftuser:", str(directory.resolve())])
         except Exception:
             logger.warning(f"Could not chown {directory}")
 
 
 def create_userdata_dir(directory: str, create_dir: bool = False) -> Path:
     """
     Create userdata directory structure.
     if create_dir is True, then the parent-directory will be created if it does not exist.
     Sub-directories will always be created if the parent directory exists.
     Raises OperationalException if given a non-existing directory.
     :param directory: Directory to check
     :param create_dir: Create directory if it does not exist.
     :return: Path object containing the directory
     """
-    sub_dirs = ["backtest_results", "data", USERPATH_HYPEROPTS, "hyperopt_results", "logs",
-                USERPATH_NOTEBOOKS, "plot", USERPATH_STRATEGIES, USERPATH_FREQAIMODELS]
+    sub_dirs = [
+        "backtest_results",
+        "data",
+        USERPATH_HYPEROPTS,
+        "hyperopt_results",
+        "logs",
+        USERPATH_NOTEBOOKS,
+        "plot",
+        USERPATH_STRATEGIES,
+        USERPATH_FREQAIMODELS,
+    ]
     folder = Path(directory)
     chown_user_directory(folder)
     if not folder.is_dir():
         if create_dir:
             folder.mkdir(parents=True)
-            logger.info(f'Created user-data directory: {folder}')
+            logger.info(f"Created user-data directory: {folder}")
         else:
             raise OperationalException(
                 f"Directory `{folder}` does not exist. "
-                "Please use `freqtrade create-userdir` to create a user directory")
+                "Please use `freqtrade create-userdir` to create a user directory"
+            )
 
     # Create required subdirectories
     for f in sub_dirs:
         subfolder = folder / f
         if not subfolder.is_dir():
             subfolder.mkdir(parents=False)
     return folder
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/environment_vars.py` & `freqtrade-2024.5/freqtrade/configuration/environment_vars.py`

 * *Files 5% similar despite different names*

```diff
@@ -12,40 +12,45 @@
 def _get_var_typed(val):
     try:
         return int(val)
     except ValueError:
         try:
             return float(val)
         except ValueError:
-            if val.lower() in ('t', 'true'):
+            if val.lower() in ("t", "true"):
                 return True
-            elif val.lower() in ('f', 'false'):
+            elif val.lower() in ("f", "false"):
                 return False
     # keep as string
     return val
 
 
 def _flat_vars_to_nested_dict(env_dict: Dict[str, Any], prefix: str) -> Dict[str, Any]:
     """
     Environment variables must be prefixed with FREQTRADE.
     FREQTRADE__{section}__{key}
     :param env_dict: Dictionary to validate - usually os.environ
     :param prefix: Prefix to consider (usually FREQTRADE__)
     :return: Nested dict based on available and relevant variables.
     """
-    no_convert = ['CHAT_ID', 'PASSWORD']
+    no_convert = ["CHAT_ID", "PASSWORD"]
     relevant_vars: Dict[str, Any] = {}
 
     for env_var, val in sorted(env_dict.items()):
         if env_var.startswith(prefix):
             logger.info(f"Loading variable '{env_var}'")
-            key = env_var.replace(prefix, '')
-            for k in reversed(key.split('__')):
-                val = {k.lower(): _get_var_typed(val)
-                       if not isinstance(val, dict) and k not in no_convert else val}
+            key = env_var.replace(prefix, "")
+            for k in reversed(key.split("__")):
+                val = {
+                    k.lower(): (
+                        _get_var_typed(val)
+                        if not isinstance(val, dict) and k not in no_convert
+                        else val
+                    )
+                }
             relevant_vars = deep_merge_dicts(val, relevant_vars)
     return relevant_vars
 
 
 def enironment_vars_to_dict() -> Dict[str, Any]:
     """
     Read environment variables and return a nested dict for relevant variables
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/load_config.py` & `freqtrade-2024.5/freqtrade/configuration/load_config.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,243 +1,245 @@
 00000000: 2222 220a 5468 6973 206d 6f64 756c 6520  """.This module 
 00000010: 636f 6e74 6169 6e20 6675 6e63 7469 6f6e  contain function
 00000020: 7320 746f 206c 6f61 6420 7468 6520 636f  s to load the co
 00000030: 6e66 6967 7572 6174 696f 6e20 6669 6c65  nfiguration file
-00000040: 0a22 2222 0a69 6d70 6f72 7420 6c6f 6767  .""".import logg
-00000050: 696e 670a 696d 706f 7274 2072 650a 696d  ing.import re.im
-00000060: 706f 7274 2073 7973 0a66 726f 6d20 636f  port sys.from co
-00000070: 7079 2069 6d70 6f72 7420 6465 6570 636f  py import deepco
-00000080: 7079 0a66 726f 6d20 7061 7468 6c69 6220  py.from pathlib 
-00000090: 696d 706f 7274 2050 6174 680a 6672 6f6d  import Path.from
-000000a0: 2074 7970 696e 6720 696d 706f 7274 2041   typing import A
-000000b0: 6e79 2c20 4469 6374 2c20 4c69 7374 2c20  ny, Dict, List, 
-000000c0: 4f70 7469 6f6e 616c 0a0a 696d 706f 7274  Optional..import
-000000d0: 2072 6170 6964 6a73 6f6e 0a0a 6672 6f6d   rapidjson..from
-000000e0: 2066 7265 7174 7261 6465 2e63 6f6e 7374   freqtrade.const
-000000f0: 616e 7473 2069 6d70 6f72 7420 4d49 4e49  ants import MINI
-00000100: 4d41 4c5f 434f 4e46 4947 2c20 436f 6e66  MAL_CONFIG, Conf
-00000110: 6967 0a66 726f 6d20 6672 6571 7472 6164  ig.from freqtrad
-00000120: 652e 6578 6365 7074 696f 6e73 2069 6d70  e.exceptions imp
-00000130: 6f72 7420 436f 6e66 6967 7572 6174 696f  ort Configuratio
-00000140: 6e45 7272 6f72 2c20 4f70 6572 6174 696f  nError, Operatio
-00000150: 6e61 6c45 7863 6570 7469 6f6e 0a66 726f  nalException.fro
-00000160: 6d20 6672 6571 7472 6164 652e 6d69 7363  m freqtrade.misc
-00000170: 2069 6d70 6f72 7420 6465 6570 5f6d 6572   import deep_mer
-00000180: 6765 5f64 6963 7473 0a0a 0a6c 6f67 6765  ge_dicts...logge
-00000190: 7220 3d20 6c6f 6767 696e 672e 6765 744c  r = logging.getL
-000001a0: 6f67 6765 7228 5f5f 6e61 6d65 5f5f 290a  ogger(__name__).
-000001b0: 0a0a 434f 4e46 4947 5f50 4152 5345 5f4d  ..CONFIG_PARSE_M
-000001c0: 4f44 4520 3d20 7261 7069 646a 736f 6e2e  ODE = rapidjson.
-000001d0: 504d 5f43 4f4d 4d45 4e54 5320 7c20 7261  PM_COMMENTS | ra
-000001e0: 7069 646a 736f 6e2e 504d 5f54 5241 494c  pidjson.PM_TRAIL
-000001f0: 494e 475f 434f 4d4d 4153 0a0a 0a64 6566  ING_COMMAS...def
-00000200: 206c 6f67 5f63 6f6e 6669 675f 6572 726f   log_config_erro
-00000210: 725f 7261 6e67 6528 7061 7468 3a20 7374  r_range(path: st
-00000220: 722c 2065 7272 6d73 673a 2073 7472 2920  r, errmsg: str) 
-00000230: 2d3e 2073 7472 3a0a 2020 2020 2222 220a  -> str:.    """.
-00000240: 2020 2020 5061 7273 6573 2063 6f6e 6669      Parses confi
-00000250: 6775 7261 7469 6f6e 2066 696c 6520 616e  guration file an
-00000260: 6420 7072 696e 7473 2072 616e 6765 2061  d prints range a
-00000270: 726f 756e 6420 6572 726f 720a 2020 2020  round error.    
-00000280: 2222 220a 2020 2020 6966 2070 6174 6820  """.    if path 
-00000290: 213d 2027 2d27 3a0a 2020 2020 2020 2020  != '-':.        
-000002a0: 6f66 6673 6574 6c69 7374 203d 2072 652e  offsetlist = re.
-000002b0: 6669 6e64 616c 6c28 7227 283f 3c3d 5061  findall(r'(?<=Pa
-000002c0: 7273 655c 7365 7272 6f72 5c73 6174 5c73  rse\serror\sat\s
-000002d0: 6f66 6673 6574 5c73 295c 642b 272c 2065  offset\s)\d+', e
-000002e0: 7272 6d73 6729 0a20 2020 2020 2020 2069  rrmsg).        i
-000002f0: 6620 6f66 6673 6574 6c69 7374 3a0a 2020  f offsetlist:.  
-00000300: 2020 2020 2020 2020 2020 6f66 6673 6574            offset
-00000310: 203d 2069 6e74 286f 6666 7365 746c 6973   = int(offsetlis
-00000320: 745b 305d 290a 2020 2020 2020 2020 2020  t[0]).          
-00000330: 2020 7465 7874 203d 2050 6174 6828 7061    text = Path(pa
-00000340: 7468 292e 7265 6164 5f74 6578 7428 290a  th).read_text().
-00000350: 2020 2020 2020 2020 2020 2020 2320 4665              # Fe
-00000360: 7463 6820 616e 206f 6666 7365 7420 6f66  tch an offset of
-00000370: 2038 3020 6368 6172 6163 7465 7273 2061   80 characters a
-00000380: 726f 756e 6420 7468 6520 6572 726f 7220  round the error 
-00000390: 6c69 6e65 0a20 2020 2020 2020 2020 2020  line.           
-000003a0: 2073 7562 7465 7874 203d 2074 6578 745b   subtext = text[
-000003b0: 6f66 6673 6574 202d 206d 696e 2838 302c  offset - min(80,
-000003c0: 206f 6666 7365 7429 3a6f 6666 7365 7420   offset):offset 
-000003d0: 2b20 3830 5d0a 2020 2020 2020 2020 2020  + 80].          
-000003e0: 2020 7365 676d 656e 7473 203d 2073 7562    segments = sub
-000003f0: 7465 7874 2e73 706c 6974 2827 5c6e 2729  text.split('\n')
-00000400: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00000410: 6c65 6e28 7365 676d 656e 7473 2920 3e20  len(segments) > 
-00000420: 333a 0a20 2020 2020 2020 2020 2020 2020  3:.             
-00000430: 2020 2023 2052 656d 6f76 6520 6669 7273     # Remove firs
-00000440: 7420 616e 6420 6c61 7374 206c 696e 6573  t and last lines
-00000450: 2c20 746f 2061 766f 6964 206f 6464 2074  , to avoid odd t
-00000460: 7275 6e63 6174 696f 6e73 0a20 2020 2020  runcations.     
-00000470: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00000480: 6e20 275c 6e27 2e6a 6f69 6e28 7365 676d  n '\n'.join(segm
-00000490: 656e 7473 5b31 3a2d 315d 290a 2020 2020  ents[1:-1]).    
-000004a0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000004b0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-000004c0: 7475 726e 2073 7562 7465 7874 0a20 2020  turn subtext.   
-000004d0: 2072 6574 7572 6e20 2727 0a0a 0a64 6566   return ''...def
-000004e0: 206c 6f61 645f 6669 6c65 2870 6174 683a   load_file(path:
-000004f0: 2050 6174 6829 202d 3e20 4469 6374 5b73   Path) -> Dict[s
-00000500: 7472 2c20 416e 795d 3a0a 2020 2020 7472  tr, Any]:.    tr
-00000510: 793a 0a20 2020 2020 2020 2077 6974 6820  y:.        with 
-00000520: 7061 7468 2e6f 7065 6e28 2772 2729 2061  path.open('r') a
-00000530: 7320 6669 6c65 3a0a 2020 2020 2020 2020  s file:.        
-00000540: 2020 2020 636f 6e66 6967 203d 2072 6170      config = rap
-00000550: 6964 6a73 6f6e 2e6c 6f61 6428 6669 6c65  idjson.load(file
-00000560: 2c20 7061 7273 655f 6d6f 6465 3d43 4f4e  , parse_mode=CON
-00000570: 4649 475f 5041 5253 455f 4d4f 4445 290a  FIG_PARSE_MODE).
-00000580: 2020 2020 6578 6365 7074 2046 696c 654e      except FileN
-00000590: 6f74 466f 756e 6445 7272 6f72 3a0a 2020  otFoundError:.  
-000005a0: 2020 2020 2020 7261 6973 6520 4f70 6572        raise Oper
-000005b0: 6174 696f 6e61 6c45 7863 6570 7469 6f6e  ationalException
-000005c0: 2866 2746 696c 6520 227b 7061 7468 7d22  (f'File "{path}"
-000005d0: 206e 6f74 2066 6f75 6e64 2127 2920 6672   not found!') fr
-000005e0: 6f6d 204e 6f6e 650a 2020 2020 7265 7475  om None.    retu
-000005f0: 726e 2063 6f6e 6669 670a 0a0a 6465 6620  rn config...def 
-00000600: 6c6f 6164 5f63 6f6e 6669 675f 6669 6c65  load_config_file
-00000610: 2870 6174 683a 2073 7472 2920 2d3e 2044  (path: str) -> D
-00000620: 6963 745b 7374 722c 2041 6e79 5d3a 0a20  ict[str, Any]:. 
-00000630: 2020 2022 2222 0a20 2020 204c 6f61 6473     """.    Loads
-00000640: 2061 2063 6f6e 6669 6720 6669 6c65 2066   a config file f
-00000650: 726f 6d20 7468 6520 6769 7665 6e20 7061  rom the given pa
-00000660: 7468 0a20 2020 203a 7061 7261 6d20 7061  th.    :param pa
-00000670: 7468 3a20 7061 7468 2061 7320 7374 720a  th: path as str.
-00000680: 2020 2020 3a72 6574 7572 6e3a 2063 6f6e      :return: con
-00000690: 6669 6775 7261 7469 6f6e 2061 7320 6469  figuration as di
-000006a0: 6374 696f 6e61 7279 0a20 2020 2022 2222  ctionary.    """
-000006b0: 0a20 2020 2074 7279 3a0a 2020 2020 2020  .    try:.      
-000006c0: 2020 2320 5265 6164 2063 6f6e 6669 6720    # Read config 
-000006d0: 6672 6f6d 2073 7464 696e 2069 6620 7265  from stdin if re
-000006e0: 7175 6573 7465 6420 696e 2074 6865 206f  quested in the o
-000006f0: 7074 696f 6e73 0a20 2020 2020 2020 2077  ptions.        w
-00000700: 6974 6820 5061 7468 2870 6174 6829 2e6f  ith Path(path).o
-00000710: 7065 6e28 2920 6966 2070 6174 6820 213d  pen() if path !=
-00000720: 2027 2d27 2065 6c73 6520 7379 732e 7374   '-' else sys.st
-00000730: 6469 6e20 6173 2066 696c 653a 0a20 2020  din as file:.   
-00000740: 2020 2020 2020 2020 2063 6f6e 6669 6720           config 
-00000750: 3d20 7261 7069 646a 736f 6e2e 6c6f 6164  = rapidjson.load
-00000760: 2866 696c 652c 2070 6172 7365 5f6d 6f64  (file, parse_mod
-00000770: 653d 434f 4e46 4947 5f50 4152 5345 5f4d  e=CONFIG_PARSE_M
-00000780: 4f44 4529 0a20 2020 2065 7863 6570 7420  ODE).    except 
-00000790: 4669 6c65 4e6f 7446 6f75 6e64 4572 726f  FileNotFoundErro
-000007a0: 723a 0a20 2020 2020 2020 2072 6169 7365  r:.        raise
-000007b0: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
-000007c0: 7074 696f 6e28 0a20 2020 2020 2020 2020  ption(.         
-000007d0: 2020 2066 2743 6f6e 6669 6720 6669 6c65     f'Config file
-000007e0: 2022 7b70 6174 687d 2220 6e6f 7420 666f   "{path}" not fo
-000007f0: 756e 6421 270a 2020 2020 2020 2020 2020  und!'.          
-00000800: 2020 2720 506c 6561 7365 2063 7265 6174    ' Please creat
-00000810: 6520 6120 636f 6e66 6967 2066 696c 6520  e a config file 
-00000820: 6f72 2063 6865 636b 2077 6865 7468 6572  or check whether
-00000830: 2069 7420 6578 6973 7473 2e27 2920 6672   it exists.') fr
-00000840: 6f6d 204e 6f6e 650a 2020 2020 6578 6365  om None.    exce
-00000850: 7074 2072 6170 6964 6a73 6f6e 2e4a 534f  pt rapidjson.JSO
-00000860: 4e44 6563 6f64 6545 7272 6f72 2061 7320  NDecodeError as 
-00000870: 653a 0a20 2020 2020 2020 2065 7272 5f72  e:.        err_r
-00000880: 616e 6765 203d 206c 6f67 5f63 6f6e 6669  ange = log_confi
-00000890: 675f 6572 726f 725f 7261 6e67 6528 7061  g_error_range(pa
-000008a0: 7468 2c20 7374 7228 6529 290a 2020 2020  th, str(e)).    
-000008b0: 2020 2020 7261 6973 6520 436f 6e66 6967      raise Config
-000008c0: 7572 6174 696f 6e45 7272 6f72 280a 2020  urationError(.  
-000008d0: 2020 2020 2020 2020 2020 6627 7b65 7d5c            f'{e}\
-000008e0: 6e27 0a20 2020 2020 2020 2020 2020 2066  n'.            f
-000008f0: 2750 6c65 6173 6520 7665 7269 6679 2074  'Please verify t
-00000900: 6865 2066 6f6c 6c6f 7769 6e67 2073 6567  he following seg
-00000910: 6d65 6e74 206f 6620 796f 7572 2063 6f6e  ment of your con
-00000920: 6669 6775 7261 7469 6f6e 3a5c 6e7b 6572  figuration:\n{er
-00000930: 725f 7261 6e67 657d 270a 2020 2020 2020  r_range}'.      
-00000940: 2020 2020 2020 6966 2065 7272 5f72 616e        if err_ran
-00000950: 6765 2065 6c73 6520 2750 6c65 6173 6520  ge else 'Please 
-00000960: 7665 7269 6679 2079 6f75 7220 636f 6e66  verify your conf
-00000970: 6967 7572 6174 696f 6e20 6669 6c65 2066  iguration file f
-00000980: 6f72 2073 796e 7461 7820 6572 726f 7273  or syntax errors
-00000990: 2e27 0a20 2020 2020 2020 2029 0a0a 2020  .'.        )..  
-000009a0: 2020 7265 7475 726e 2063 6f6e 6669 670a    return config.
-000009b0: 0a0a 6465 6620 6c6f 6164 5f66 726f 6d5f  ..def load_from_
-000009c0: 6669 6c65 7328 0a20 2020 2020 2020 2066  files(.        f
-000009d0: 696c 6573 3a20 4c69 7374 5b73 7472 5d2c  iles: List[str],
-000009e0: 2062 6173 655f 7061 7468 3a20 4f70 7469   base_path: Opti
-000009f0: 6f6e 616c 5b50 6174 685d 203d 204e 6f6e  onal[Path] = Non
-00000a00: 652c 206c 6576 656c 3a20 696e 7420 3d20  e, level: int = 
-00000a10: 3029 202d 3e20 4469 6374 5b73 7472 2c20  0) -> Dict[str, 
-00000a20: 416e 795d 3a0a 2020 2020 2222 220a 2020  Any]:.    """.  
-00000a30: 2020 5265 6375 7273 6976 656c 7920 6c6f    Recursively lo
-00000a40: 6164 2063 6f6e 6669 6775 7261 7469 6f6e  ad configuration
-00000a50: 2066 696c 6573 2069 6620 7370 6563 6966   files if specif
-00000a60: 6965 642e 0a20 2020 2053 7562 2d66 696c  ied..    Sub-fil
-00000a70: 6573 2061 7265 2061 7373 756d 6564 2074  es are assumed t
-00000a80: 6f20 6265 2072 656c 6174 6976 6520 746f  o be relative to
-00000a90: 2074 6865 2069 6e69 7469 616c 2063 6f6e   the initial con
-00000aa0: 6669 672e 0a20 2020 2022 2222 0a20 2020  fig..    """.   
-00000ab0: 2063 6f6e 6669 673a 2043 6f6e 6669 6720   config: Config 
-00000ac0: 3d20 7b7d 0a20 2020 2069 6620 6c65 7665  = {}.    if leve
-00000ad0: 6c20 3e20 353a 0a20 2020 2020 2020 2072  l > 5:.        r
-00000ae0: 6169 7365 2043 6f6e 6669 6775 7261 7469  aise Configurati
-00000af0: 6f6e 4572 726f 7228 2243 6f6e 6669 6720  onError("Config 
-00000b00: 6c6f 6f70 2064 6574 6563 7465 642e 2229  loop detected.")
-00000b10: 0a0a 2020 2020 6966 206e 6f74 2066 696c  ..    if not fil
-00000b20: 6573 3a0a 2020 2020 2020 2020 7265 7475  es:.        retu
-00000b30: 726e 2064 6565 7063 6f70 7928 4d49 4e49  rn deepcopy(MINI
-00000b40: 4d41 4c5f 434f 4e46 4947 290a 2020 2020  MAL_CONFIG).    
-00000b50: 6669 6c65 735f 6c6f 6164 6564 203d 205b  files_loaded = [
-00000b60: 5d0a 2020 2020 2320 5765 2065 7870 6563  ].    # We expec
-00000b70: 7420 6865 7265 2061 206c 6973 7420 6f66  t here a list of
-00000b80: 2063 6f6e 6669 6720 6669 6c65 6e61 6d65   config filename
-00000b90: 730a 2020 2020 666f 7220 6669 6c65 6e61  s.    for filena
-00000ba0: 6d65 2069 6e20 6669 6c65 733a 0a20 2020  me in files:.   
-00000bb0: 2020 2020 206c 6f67 6765 722e 696e 666f       logger.info
-00000bc0: 2866 2755 7369 6e67 2063 6f6e 6669 673a  (f'Using config:
-00000bd0: 207b 6669 6c65 6e61 6d65 7d20 2e2e 2e27   {filename} ...'
-00000be0: 290a 2020 2020 2020 2020 6966 2066 696c  ).        if fil
-00000bf0: 656e 616d 6520 3d3d 2027 2d27 3a0a 2020  ename == '-':.  
-00000c00: 2020 2020 2020 2020 2020 2320 496d 6d65            # Imme
-00000c10: 6469 6174 656c 7920 6c6f 6164 2073 7464  diately load std
-00000c20: 696e 2061 6e64 2072 6574 7572 6e0a 2020  in and return.  
-00000c30: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00000c40: 206c 6f61 645f 636f 6e66 6967 5f66 696c   load_config_fil
-00000c50: 6528 6669 6c65 6e61 6d65 290a 2020 2020  e(filename).    
-00000c60: 2020 2020 6669 6c65 203d 2050 6174 6828      file = Path(
-00000c70: 6669 6c65 6e61 6d65 290a 2020 2020 2020  filename).      
-00000c80: 2020 6966 2062 6173 655f 7061 7468 3a0a    if base_path:.
-00000c90: 2020 2020 2020 2020 2020 2020 2320 5072              # Pr
-00000ca0: 6570 656e 6420 6261 7365 7061 7468 2074  epend basepath t
-00000cb0: 6f20 616c 6c6f 7720 666f 7220 7265 6c61  o allow for rela
-00000cc0: 7469 7665 2061 7373 6967 6e6d 656e 7473  tive assignments
-00000cd0: 0a20 2020 2020 2020 2020 2020 2066 696c  .            fil
-00000ce0: 6520 3d20 6261 7365 5f70 6174 6820 2f20  e = base_path / 
-00000cf0: 6669 6c65 0a0a 2020 2020 2020 2020 636f  file..        co
-00000d00: 6e66 6967 5f74 6d70 203d 206c 6f61 645f  nfig_tmp = load_
-00000d10: 636f 6e66 6967 5f66 696c 6528 7374 7228  config_file(str(
-00000d20: 6669 6c65 2929 0a20 2020 2020 2020 2069  file)).        i
-00000d30: 6620 2761 6464 5f63 6f6e 6669 675f 6669  f 'add_config_fi
-00000d40: 6c65 7327 2069 6e20 636f 6e66 6967 5f74  les' in config_t
-00000d50: 6d70 3a0a 2020 2020 2020 2020 2020 2020  mp:.            
-00000d60: 636f 6e66 6967 5f73 7562 203d 206c 6f61  config_sub = loa
-00000d70: 645f 6672 6f6d 5f66 696c 6573 280a 2020  d_from_files(.  
-00000d80: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00000d90: 6e66 6967 5f74 6d70 5b27 6164 645f 636f  nfig_tmp['add_co
-00000da0: 6e66 6967 5f66 696c 6573 275d 2c20 6669  nfig_files'], fi
-00000db0: 6c65 2e72 6573 6f6c 7665 2829 2e70 6172  le.resolve().par
-00000dc0: 656e 742c 206c 6576 656c 202b 2031 290a  ent, level + 1).
-00000dd0: 2020 2020 2020 2020 2020 2020 6669 6c65              file
-00000de0: 735f 6c6f 6164 6564 2e65 7874 656e 6428  s_loaded.extend(
-00000df0: 636f 6e66 6967 5f73 7562 2e67 6574 2827  config_sub.get('
-00000e00: 636f 6e66 6967 5f66 696c 6573 272c 205b  config_files', [
-00000e10: 5d29 290a 2020 2020 2020 2020 2020 2020  ])).            
-00000e20: 636f 6e66 6967 5f74 6d70 203d 2064 6565  config_tmp = dee
-00000e30: 705f 6d65 7267 655f 6469 6374 7328 636f  p_merge_dicts(co
-00000e40: 6e66 6967 5f74 6d70 2c20 636f 6e66 6967  nfig_tmp, config
-00000e50: 5f73 7562 290a 0a20 2020 2020 2020 2066  _sub)..        f
-00000e60: 696c 6573 5f6c 6f61 6465 642e 696e 7365  iles_loaded.inse
-00000e70: 7274 2830 2c20 7374 7228 6669 6c65 2929  rt(0, str(file))
-00000e80: 0a0a 2020 2020 2020 2020 2320 4d65 7267  ..        # Merg
-00000e90: 6520 636f 6e66 6967 206f 7074 696f 6e73  e config options
-00000ea0: 2c20 6f76 6572 7772 6974 696e 6720 7072  , overwriting pr
-00000eb0: 696f 7220 7661 6c75 6573 0a20 2020 2020  ior values.     
-00000ec0: 2020 2063 6f6e 6669 6720 3d20 6465 6570     config = deep
-00000ed0: 5f6d 6572 6765 5f64 6963 7473 2863 6f6e  _merge_dicts(con
-00000ee0: 6669 675f 746d 702c 2063 6f6e 6669 6729  fig_tmp, config)
-00000ef0: 0a0a 2020 2020 636f 6e66 6967 5b27 636f  ..    config['co
-00000f00: 6e66 6967 5f66 696c 6573 275d 203d 2066  nfig_files'] = f
-00000f10: 696c 6573 5f6c 6f61 6465 640a 0a20 2020  iles_loaded..   
-00000f20: 2072 6574 7572 6e20 636f 6e66 6967 0a     return config.
+00000040: 0a22 2222 0a0a 696d 706f 7274 206c 6f67  ."""..import log
+00000050: 6769 6e67 0a69 6d70 6f72 7420 7265 0a69  ging.import re.i
+00000060: 6d70 6f72 7420 7379 730a 6672 6f6d 2063  mport sys.from c
+00000070: 6f70 7920 696d 706f 7274 2064 6565 7063  opy import deepc
+00000080: 6f70 790a 6672 6f6d 2070 6174 686c 6962  opy.from pathlib
+00000090: 2069 6d70 6f72 7420 5061 7468 0a66 726f   import Path.fro
+000000a0: 6d20 7479 7069 6e67 2069 6d70 6f72 7420  m typing import 
+000000b0: 416e 792c 2044 6963 742c 204c 6973 742c  Any, Dict, List,
+000000c0: 204f 7074 696f 6e61 6c0a 0a69 6d70 6f72   Optional..impor
+000000d0: 7420 7261 7069 646a 736f 6e0a 0a66 726f  t rapidjson..fro
+000000e0: 6d20 6672 6571 7472 6164 652e 636f 6e73  m freqtrade.cons
+000000f0: 7461 6e74 7320 696d 706f 7274 204d 494e  tants import MIN
+00000100: 494d 414c 5f43 4f4e 4649 472c 2043 6f6e  IMAL_CONFIG, Con
+00000110: 6669 670a 6672 6f6d 2066 7265 7174 7261  fig.from freqtra
+00000120: 6465 2e65 7863 6570 7469 6f6e 7320 696d  de.exceptions im
+00000130: 706f 7274 2043 6f6e 6669 6775 7261 7469  port Configurati
+00000140: 6f6e 4572 726f 722c 204f 7065 7261 7469  onError, Operati
+00000150: 6f6e 616c 4578 6365 7074 696f 6e0a 6672  onalException.fr
+00000160: 6f6d 2066 7265 7174 7261 6465 2e6d 6973  om freqtrade.mis
+00000170: 6320 696d 706f 7274 2064 6565 705f 6d65  c import deep_me
+00000180: 7267 655f 6469 6374 730a 0a0a 6c6f 6767  rge_dicts...logg
+00000190: 6572 203d 206c 6f67 6769 6e67 2e67 6574  er = logging.get
+000001a0: 4c6f 6767 6572 285f 5f6e 616d 655f 5f29  Logger(__name__)
+000001b0: 0a0a 0a43 4f4e 4649 475f 5041 5253 455f  ...CONFIG_PARSE_
+000001c0: 4d4f 4445 203d 2072 6170 6964 6a73 6f6e  MODE = rapidjson
+000001d0: 2e50 4d5f 434f 4d4d 454e 5453 207c 2072  .PM_COMMENTS | r
+000001e0: 6170 6964 6a73 6f6e 2e50 4d5f 5452 4149  apidjson.PM_TRAI
+000001f0: 4c49 4e47 5f43 4f4d 4d41 530a 0a0a 6465  LING_COMMAS...de
+00000200: 6620 6c6f 675f 636f 6e66 6967 5f65 7272  f log_config_err
+00000210: 6f72 5f72 616e 6765 2870 6174 683a 2073  or_range(path: s
+00000220: 7472 2c20 6572 726d 7367 3a20 7374 7229  tr, errmsg: str)
+00000230: 202d 3e20 7374 723a 0a20 2020 2022 2222   -> str:.    """
+00000240: 0a20 2020 2050 6172 7365 7320 636f 6e66  .    Parses conf
+00000250: 6967 7572 6174 696f 6e20 6669 6c65 2061  iguration file a
+00000260: 6e64 2070 7269 6e74 7320 7261 6e67 6520  nd prints range 
+00000270: 6172 6f75 6e64 2065 7272 6f72 0a20 2020  around error.   
+00000280: 2022 2222 0a20 2020 2069 6620 7061 7468   """.    if path
+00000290: 2021 3d20 222d 223a 0a20 2020 2020 2020   != "-":.       
+000002a0: 206f 6666 7365 746c 6973 7420 3d20 7265   offsetlist = re
+000002b0: 2e66 696e 6461 6c6c 2872 2228 3f3c 3d50  .findall(r"(?<=P
+000002c0: 6172 7365 5c73 6572 726f 725c 7361 745c  arse\serror\sat\
+000002d0: 736f 6666 7365 745c 7329 5c64 2b22 2c20  soffset\s)\d+", 
+000002e0: 6572 726d 7367 290a 2020 2020 2020 2020  errmsg).        
+000002f0: 6966 206f 6666 7365 746c 6973 743a 0a20  if offsetlist:. 
+00000300: 2020 2020 2020 2020 2020 206f 6666 7365             offse
+00000310: 7420 3d20 696e 7428 6f66 6673 6574 6c69  t = int(offsetli
+00000320: 7374 5b30 5d29 0a20 2020 2020 2020 2020  st[0]).         
+00000330: 2020 2074 6578 7420 3d20 5061 7468 2870     text = Path(p
+00000340: 6174 6829 2e72 6561 645f 7465 7874 2829  ath).read_text()
+00000350: 0a20 2020 2020 2020 2020 2020 2023 2046  .            # F
+00000360: 6574 6368 2061 6e20 6f66 6673 6574 206f  etch an offset o
+00000370: 6620 3830 2063 6861 7261 6374 6572 7320  f 80 characters 
+00000380: 6172 6f75 6e64 2074 6865 2065 7272 6f72  around the error
+00000390: 206c 696e 650a 2020 2020 2020 2020 2020   line.          
+000003a0: 2020 7375 6274 6578 7420 3d20 7465 7874    subtext = text
+000003b0: 5b6f 6666 7365 7420 2d20 6d69 6e28 3830  [offset - min(80
+000003c0: 2c20 6f66 6673 6574 2920 3a20 6f66 6673  , offset) : offs
+000003d0: 6574 202b 2038 305d 0a20 2020 2020 2020  et + 80].       
+000003e0: 2020 2020 2073 6567 6d65 6e74 7320 3d20       segments = 
+000003f0: 7375 6274 6578 742e 7370 6c69 7428 225c  subtext.split("\
+00000400: 6e22 290a 2020 2020 2020 2020 2020 2020  n").            
+00000410: 6966 206c 656e 2873 6567 6d65 6e74 7329  if len(segments)
+00000420: 203e 2033 3a0a 2020 2020 2020 2020 2020   > 3:.          
+00000430: 2020 2020 2020 2320 5265 6d6f 7665 2066        # Remove f
+00000440: 6972 7374 2061 6e64 206c 6173 7420 6c69  irst and last li
+00000450: 6e65 732c 2074 6f20 6176 6f69 6420 6f64  nes, to avoid od
+00000460: 6420 7472 756e 6361 7469 6f6e 730a 2020  d truncations.  
+00000470: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00000480: 7475 726e 2022 5c6e 222e 6a6f 696e 2873  turn "\n".join(s
+00000490: 6567 6d65 6e74 735b 313a 2d31 5d29 0a20  egments[1:-1]). 
+000004a0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+000004b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000004c0: 2072 6574 7572 6e20 7375 6274 6578 740a   return subtext.
+000004d0: 2020 2020 7265 7475 726e 2022 220a 0a0a      return ""...
+000004e0: 6465 6620 6c6f 6164 5f66 696c 6528 7061  def load_file(pa
+000004f0: 7468 3a20 5061 7468 2920 2d3e 2044 6963  th: Path) -> Dic
+00000500: 745b 7374 722c 2041 6e79 5d3a 0a20 2020  t[str, Any]:.   
+00000510: 2074 7279 3a0a 2020 2020 2020 2020 7769   try:.        wi
+00000520: 7468 2070 6174 682e 6f70 656e 2822 7222  th path.open("r"
+00000530: 2920 6173 2066 696c 653a 0a20 2020 2020  ) as file:.     
+00000540: 2020 2020 2020 2063 6f6e 6669 6720 3d20         config = 
+00000550: 7261 7069 646a 736f 6e2e 6c6f 6164 2866  rapidjson.load(f
+00000560: 696c 652c 2070 6172 7365 5f6d 6f64 653d  ile, parse_mode=
+00000570: 434f 4e46 4947 5f50 4152 5345 5f4d 4f44  CONFIG_PARSE_MOD
+00000580: 4529 0a20 2020 2065 7863 6570 7420 4669  E).    except Fi
+00000590: 6c65 4e6f 7446 6f75 6e64 4572 726f 723a  leNotFoundError:
+000005a0: 0a20 2020 2020 2020 2072 6169 7365 204f  .        raise O
+000005b0: 7065 7261 7469 6f6e 616c 4578 6365 7074  perationalExcept
+000005c0: 696f 6e28 6627 4669 6c65 2022 7b70 6174  ion(f'File "{pat
+000005d0: 687d 2220 6e6f 7420 666f 756e 6421 2729  h}" not found!')
+000005e0: 2066 726f 6d20 4e6f 6e65 0a20 2020 2072   from None.    r
+000005f0: 6574 7572 6e20 636f 6e66 6967 0a0a 0a64  eturn config...d
+00000600: 6566 206c 6f61 645f 636f 6e66 6967 5f66  ef load_config_f
+00000610: 696c 6528 7061 7468 3a20 7374 7229 202d  ile(path: str) -
+00000620: 3e20 4469 6374 5b73 7472 2c20 416e 795d  > Dict[str, Any]
+00000630: 3a0a 2020 2020 2222 220a 2020 2020 4c6f  :.    """.    Lo
+00000640: 6164 7320 6120 636f 6e66 6967 2066 696c  ads a config fil
+00000650: 6520 6672 6f6d 2074 6865 2067 6976 656e  e from the given
+00000660: 2070 6174 680a 2020 2020 3a70 6172 616d   path.    :param
+00000670: 2070 6174 683a 2070 6174 6820 6173 2073   path: path as s
+00000680: 7472 0a20 2020 203a 7265 7475 726e 3a20  tr.    :return: 
+00000690: 636f 6e66 6967 7572 6174 696f 6e20 6173  configuration as
+000006a0: 2064 6963 7469 6f6e 6172 790a 2020 2020   dictionary.    
+000006b0: 2222 220a 2020 2020 7472 793a 0a20 2020  """.    try:.   
+000006c0: 2020 2020 2023 2052 6561 6420 636f 6e66       # Read conf
+000006d0: 6967 2066 726f 6d20 7374 6469 6e20 6966  ig from stdin if
+000006e0: 2072 6571 7565 7374 6564 2069 6e20 7468   requested in th
+000006f0: 6520 6f70 7469 6f6e 730a 2020 2020 2020  e options.      
+00000700: 2020 7769 7468 2050 6174 6828 7061 7468    with Path(path
+00000710: 292e 6f70 656e 2829 2069 6620 7061 7468  ).open() if path
+00000720: 2021 3d20 222d 2220 656c 7365 2073 7973   != "-" else sys
+00000730: 2e73 7464 696e 2061 7320 6669 6c65 3a0a  .stdin as file:.
+00000740: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00000750: 6967 203d 2072 6170 6964 6a73 6f6e 2e6c  ig = rapidjson.l
+00000760: 6f61 6428 6669 6c65 2c20 7061 7273 655f  oad(file, parse_
+00000770: 6d6f 6465 3d43 4f4e 4649 475f 5041 5253  mode=CONFIG_PARS
+00000780: 455f 4d4f 4445 290a 2020 2020 6578 6365  E_MODE).    exce
+00000790: 7074 2046 696c 654e 6f74 466f 756e 6445  pt FileNotFoundE
+000007a0: 7272 6f72 3a0a 2020 2020 2020 2020 7261  rror:.        ra
+000007b0: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
+000007c0: 7863 6570 7469 6f6e 280a 2020 2020 2020  xception(.      
+000007d0: 2020 2020 2020 6627 436f 6e66 6967 2066        f'Config f
+000007e0: 696c 6520 227b 7061 7468 7d22 206e 6f74  ile "{path}" not
+000007f0: 2066 6f75 6e64 2127 0a20 2020 2020 2020   found!'.       
+00000800: 2020 2020 2022 2050 6c65 6173 6520 6372       " Please cr
+00000810: 6561 7465 2061 2063 6f6e 6669 6720 6669  eate a config fi
+00000820: 6c65 206f 7220 6368 6563 6b20 7768 6574  le or check whet
+00000830: 6865 7220 6974 2065 7869 7374 732e 220a  her it exists.".
+00000840: 2020 2020 2020 2020 2920 6672 6f6d 204e          ) from N
+00000850: 6f6e 650a 2020 2020 6578 6365 7074 2072  one.    except r
+00000860: 6170 6964 6a73 6f6e 2e4a 534f 4e44 6563  apidjson.JSONDec
+00000870: 6f64 6545 7272 6f72 2061 7320 653a 0a20  odeError as e:. 
+00000880: 2020 2020 2020 2065 7272 5f72 616e 6765         err_range
+00000890: 203d 206c 6f67 5f63 6f6e 6669 675f 6572   = log_config_er
+000008a0: 726f 725f 7261 6e67 6528 7061 7468 2c20  ror_range(path, 
+000008b0: 7374 7228 6529 290a 2020 2020 2020 2020  str(e)).        
+000008c0: 7261 6973 6520 436f 6e66 6967 7572 6174  raise Configurat
+000008d0: 696f 6e45 7272 6f72 280a 2020 2020 2020  ionError(.      
+000008e0: 2020 2020 2020 6622 7b65 7d5c 6e50 6c65        f"{e}\nPle
+000008f0: 6173 6520 7665 7269 6679 2074 6865 2066  ase verify the f
+00000900: 6f6c 6c6f 7769 6e67 2073 6567 6d65 6e74  ollowing segment
+00000910: 206f 6620 796f 7572 2063 6f6e 6669 6775   of your configu
+00000920: 7261 7469 6f6e 3a5c 6e7b 6572 725f 7261  ration:\n{err_ra
+00000930: 6e67 657d 220a 2020 2020 2020 2020 2020  nge}".          
+00000940: 2020 6966 2065 7272 5f72 616e 6765 0a20    if err_range. 
+00000950: 2020 2020 2020 2020 2020 2065 6c73 6520             else 
+00000960: 2250 6c65 6173 6520 7665 7269 6679 2079  "Please verify y
+00000970: 6f75 7220 636f 6e66 6967 7572 6174 696f  our configuratio
+00000980: 6e20 6669 6c65 2066 6f72 2073 796e 7461  n file for synta
+00000990: 7820 6572 726f 7273 2e22 0a20 2020 2020  x errors.".     
+000009a0: 2020 2029 0a0a 2020 2020 7265 7475 726e     )..    return
+000009b0: 2063 6f6e 6669 670a 0a0a 6465 6620 6c6f   config...def lo
+000009c0: 6164 5f66 726f 6d5f 6669 6c65 7328 0a20  ad_from_files(. 
+000009d0: 2020 2066 696c 6573 3a20 4c69 7374 5b73     files: List[s
+000009e0: 7472 5d2c 2062 6173 655f 7061 7468 3a20  tr], base_path: 
+000009f0: 4f70 7469 6f6e 616c 5b50 6174 685d 203d  Optional[Path] =
+00000a00: 204e 6f6e 652c 206c 6576 656c 3a20 696e   None, level: in
+00000a10: 7420 3d20 300a 2920 2d3e 2044 6963 745b  t = 0.) -> Dict[
+00000a20: 7374 722c 2041 6e79 5d3a 0a20 2020 2022  str, Any]:.    "
+00000a30: 2222 0a20 2020 2052 6563 7572 7369 7665  "".    Recursive
+00000a40: 6c79 206c 6f61 6420 636f 6e66 6967 7572  ly load configur
+00000a50: 6174 696f 6e20 6669 6c65 7320 6966 2073  ation files if s
+00000a60: 7065 6369 6669 6564 2e0a 2020 2020 5375  pecified..    Su
+00000a70: 622d 6669 6c65 7320 6172 6520 6173 7375  b-files are assu
+00000a80: 6d65 6420 746f 2062 6520 7265 6c61 7469  med to be relati
+00000a90: 7665 2074 6f20 7468 6520 696e 6974 6961  ve to the initia
+00000aa0: 6c20 636f 6e66 6967 2e0a 2020 2020 2222  l config..    ""
+00000ab0: 220a 2020 2020 636f 6e66 6967 3a20 436f  ".    config: Co
+00000ac0: 6e66 6967 203d 207b 7d0a 2020 2020 6966  nfig = {}.    if
+00000ad0: 206c 6576 656c 203e 2035 3a0a 2020 2020   level > 5:.    
+00000ae0: 2020 2020 7261 6973 6520 436f 6e66 6967      raise Config
+00000af0: 7572 6174 696f 6e45 7272 6f72 2822 436f  urationError("Co
+00000b00: 6e66 6967 206c 6f6f 7020 6465 7465 6374  nfig loop detect
+00000b10: 6564 2e22 290a 0a20 2020 2069 6620 6e6f  ed.")..    if no
+00000b20: 7420 6669 6c65 733a 0a20 2020 2020 2020  t files:.       
+00000b30: 2072 6574 7572 6e20 6465 6570 636f 7079   return deepcopy
+00000b40: 284d 494e 494d 414c 5f43 4f4e 4649 4729  (MINIMAL_CONFIG)
+00000b50: 0a20 2020 2066 696c 6573 5f6c 6f61 6465  .    files_loade
+00000b60: 6420 3d20 5b5d 0a20 2020 2023 2057 6520  d = [].    # We 
+00000b70: 6578 7065 6374 2068 6572 6520 6120 6c69  expect here a li
+00000b80: 7374 206f 6620 636f 6e66 6967 2066 696c  st of config fil
+00000b90: 656e 616d 6573 0a20 2020 2066 6f72 2066  enames.    for f
+00000ba0: 696c 656e 616d 6520 696e 2066 696c 6573  ilename in files
+00000bb0: 3a0a 2020 2020 2020 2020 6c6f 6767 6572  :.        logger
+00000bc0: 2e69 6e66 6f28 6622 5573 696e 6720 636f  .info(f"Using co
+00000bd0: 6e66 6967 3a20 7b66 696c 656e 616d 657d  nfig: {filename}
+00000be0: 202e 2e2e 2229 0a20 2020 2020 2020 2069   ...").        i
+00000bf0: 6620 6669 6c65 6e61 6d65 203d 3d20 222d  f filename == "-
+00000c00: 223a 0a20 2020 2020 2020 2020 2020 2023  ":.            #
+00000c10: 2049 6d6d 6564 6961 7465 6c79 206c 6f61   Immediately loa
+00000c20: 6420 7374 6469 6e20 616e 6420 7265 7475  d stdin and retu
+00000c30: 726e 0a20 2020 2020 2020 2020 2020 2072  rn.            r
+00000c40: 6574 7572 6e20 6c6f 6164 5f63 6f6e 6669  eturn load_confi
+00000c50: 675f 6669 6c65 2866 696c 656e 616d 6529  g_file(filename)
+00000c60: 0a20 2020 2020 2020 2066 696c 6520 3d20  .        file = 
+00000c70: 5061 7468 2866 696c 656e 616d 6529 0a20  Path(filename). 
+00000c80: 2020 2020 2020 2069 6620 6261 7365 5f70         if base_p
+00000c90: 6174 683a 0a20 2020 2020 2020 2020 2020  ath:.           
+00000ca0: 2023 2050 7265 7065 6e64 2062 6173 6570   # Prepend basep
+00000cb0: 6174 6820 746f 2061 6c6c 6f77 2066 6f72  ath to allow for
+00000cc0: 2072 656c 6174 6976 6520 6173 7369 676e   relative assign
+00000cd0: 6d65 6e74 730a 2020 2020 2020 2020 2020  ments.          
+00000ce0: 2020 6669 6c65 203d 2062 6173 655f 7061    file = base_pa
+00000cf0: 7468 202f 2066 696c 650a 0a20 2020 2020  th / file..     
+00000d00: 2020 2063 6f6e 6669 675f 746d 7020 3d20     config_tmp = 
+00000d10: 6c6f 6164 5f63 6f6e 6669 675f 6669 6c65  load_config_file
+00000d20: 2873 7472 2866 696c 6529 290a 2020 2020  (str(file)).    
+00000d30: 2020 2020 6966 2022 6164 645f 636f 6e66      if "add_conf
+00000d40: 6967 5f66 696c 6573 2220 696e 2063 6f6e  ig_files" in con
+00000d50: 6669 675f 746d 703a 0a20 2020 2020 2020  fig_tmp:.       
+00000d60: 2020 2020 2063 6f6e 6669 675f 7375 6220       config_sub 
+00000d70: 3d20 6c6f 6164 5f66 726f 6d5f 6669 6c65  = load_from_file
+00000d80: 7328 0a20 2020 2020 2020 2020 2020 2020  s(.             
+00000d90: 2020 2063 6f6e 6669 675f 746d 705b 2261     config_tmp["a
+00000da0: 6464 5f63 6f6e 6669 675f 6669 6c65 7322  dd_config_files"
+00000db0: 5d2c 2066 696c 652e 7265 736f 6c76 6528  ], file.resolve(
+00000dc0: 292e 7061 7265 6e74 2c20 6c65 7665 6c20  ).parent, level 
+00000dd0: 2b20 310a 2020 2020 2020 2020 2020 2020  + 1.            
+00000de0: 290a 2020 2020 2020 2020 2020 2020 6669  ).            fi
+00000df0: 6c65 735f 6c6f 6164 6564 2e65 7874 656e  les_loaded.exten
+00000e00: 6428 636f 6e66 6967 5f73 7562 2e67 6574  d(config_sub.get
+00000e10: 2822 636f 6e66 6967 5f66 696c 6573 222c  ("config_files",
+00000e20: 205b 5d29 290a 2020 2020 2020 2020 2020   [])).          
+00000e30: 2020 636f 6e66 6967 5f74 6d70 203d 2064    config_tmp = d
+00000e40: 6565 705f 6d65 7267 655f 6469 6374 7328  eep_merge_dicts(
+00000e50: 636f 6e66 6967 5f74 6d70 2c20 636f 6e66  config_tmp, conf
+00000e60: 6967 5f73 7562 290a 0a20 2020 2020 2020  ig_sub)..       
+00000e70: 2066 696c 6573 5f6c 6f61 6465 642e 696e   files_loaded.in
+00000e80: 7365 7274 2830 2c20 7374 7228 6669 6c65  sert(0, str(file
+00000e90: 2929 0a0a 2020 2020 2020 2020 2320 4d65  ))..        # Me
+00000ea0: 7267 6520 636f 6e66 6967 206f 7074 696f  rge config optio
+00000eb0: 6e73 2c20 6f76 6572 7772 6974 696e 6720  ns, overwriting 
+00000ec0: 7072 696f 7220 7661 6c75 6573 0a20 2020  prior values.   
+00000ed0: 2020 2020 2063 6f6e 6669 6720 3d20 6465       config = de
+00000ee0: 6570 5f6d 6572 6765 5f64 6963 7473 2863  ep_merge_dicts(c
+00000ef0: 6f6e 6669 675f 746d 702c 2063 6f6e 6669  onfig_tmp, confi
+00000f00: 6729 0a0a 2020 2020 636f 6e66 6967 5b22  g)..    config["
+00000f10: 636f 6e66 6967 5f66 696c 6573 225d 203d  config_files"] =
+00000f20: 2066 696c 6573 5f6c 6f61 6465 640a 0a20   files_loaded.. 
+00000f30: 2020 2072 6574 7572 6e20 636f 6e66 6967     return config
+00000f40: 0a                                       .
```

### Comparing `freqtrade-2024.4/freqtrade/configuration/timerange.py` & `freqtrade-2024.5/freqtrade/configuration/timerange.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 This module contains the argument manager class
 """
+
 import logging
 import re
 from datetime import datetime, timezone
 from typing import Optional
 
 from typing_extensions import Self
 
@@ -18,17 +19,21 @@
 class TimeRange:
     """
     object defining timerange inputs.
     [start/stop]type defines if [start/stop]ts shall be used.
     if *type is None, don't use corresponding startvalue.
     """
 
-    def __init__(self, starttype: Optional[str] = None, stoptype: Optional[str] = None,
-                 startts: int = 0, stopts: int = 0):
-
+    def __init__(
+        self,
+        starttype: Optional[str] = None,
+        stoptype: Optional[str] = None,
+        startts: int = 0,
+        stopts: int = 0,
+    ):
         self.starttype: Optional[str] = starttype
         self.stoptype: Optional[str] = stoptype
         self.startts: int = startts
         self.stopts: int = stopts
 
     @property
     def startdt(self) -> Optional[datetime]:
@@ -44,119 +49,132 @@
 
     @property
     def timerange_str(self) -> str:
         """
         Returns a string representation of the timerange as used by parse_timerange.
         Follows the format yyyymmdd-yyyymmdd - leaving out the parts that are not set.
         """
-        start = ''
-        stop = ''
+        start = ""
+        stop = ""
         if startdt := self.startdt:
-            start = startdt.strftime('%Y%m%d')
+            start = startdt.strftime("%Y%m%d")
         if stopdt := self.stopdt:
-            stop = stopdt.strftime('%Y%m%d')
+            stop = stopdt.strftime("%Y%m%d")
         return f"{start}-{stop}"
 
     @property
     def start_fmt(self) -> str:
         """
         Returns a string representation of the start date
         """
-        val = 'unbounded'
+        val = "unbounded"
         if (startdt := self.startdt) is not None:
             val = startdt.strftime(DATETIME_PRINT_FORMAT)
         return val
 
     @property
     def stop_fmt(self) -> str:
         """
         Returns a string representation of the stop date
         """
-        val = 'unbounded'
+        val = "unbounded"
         if (stopdt := self.stopdt) is not None:
             val = stopdt.strftime(DATETIME_PRINT_FORMAT)
         return val
 
     def __eq__(self, other):
         """Override the default Equals behavior"""
-        return (self.starttype == other.starttype and self.stoptype == other.stoptype
-                and self.startts == other.startts and self.stopts == other.stopts)
+        return (
+            self.starttype == other.starttype
+            and self.stoptype == other.stoptype
+            and self.startts == other.startts
+            and self.stopts == other.stopts
+        )
 
     def subtract_start(self, seconds: int) -> None:
         """
         Subtracts <seconds> from startts if startts is set.
         :param seconds: Seconds to subtract from starttime
         :return: None (Modifies the object in place)
         """
         if self.startts:
             self.startts = self.startts - seconds
 
-    def adjust_start_if_necessary(self, timeframe_secs: int, startup_candles: int,
-                                  min_date: datetime) -> None:
+    def adjust_start_if_necessary(
+        self, timeframe_secs: int, startup_candles: int, min_date: datetime
+    ) -> None:
         """
         Adjust startts by <startup_candles> candles.
         Applies only if no startup-candles have been available.
         :param timeframe_secs: Timeframe in seconds e.g. `timeframe_to_seconds('5m')`
         :param startup_candles: Number of candles to move start-date forward
         :param min_date: Minimum data date loaded. Key kriterium to decide if start-time
                          has to be moved
         :return: None (Modifies the object in place)
         """
-        if (not self.starttype or (startup_candles
-                                   and min_date.timestamp() >= self.startts)):
+        if not self.starttype or (startup_candles and min_date.timestamp() >= self.startts):
             # If no startts was defined, or backtest-data starts at the defined backtest-date
-            logger.warning("Moving start-date by %s candles to account for startup time.",
-                           startup_candles)
+            logger.warning(
+                "Moving start-date by %s candles to account for startup time.", startup_candles
+            )
             self.startts = int(min_date.timestamp() + timeframe_secs * startup_candles)
-            self.starttype = 'date'
+            self.starttype = "date"
 
     @classmethod
     def parse_timerange(cls, text: Optional[str]) -> Self:
         """
         Parse the value of the argument --timerange to determine what is the range desired
         :param text: value from --timerange
         :return: Start and End range period
         """
         if not text:
             return cls(None, None, 0, 0)
-        syntax = [(r'^-(\d{8})$', (None, 'date')),
-                  (r'^(\d{8})-$', ('date', None)),
-                  (r'^(\d{8})-(\d{8})$', ('date', 'date')),
-                  (r'^-(\d{10})$', (None, 'date')),
-                  (r'^(\d{10})-$', ('date', None)),
-                  (r'^(\d{10})-(\d{10})$', ('date', 'date')),
-                  (r'^-(\d{13})$', (None, 'date')),
-                  (r'^(\d{13})-$', ('date', None)),
-                  (r'^(\d{13})-(\d{13})$', ('date', 'date')),
-                  ]
+        syntax = [
+            (r"^-(\d{8})$", (None, "date")),
+            (r"^(\d{8})-$", ("date", None)),
+            (r"^(\d{8})-(\d{8})$", ("date", "date")),
+            (r"^-(\d{10})$", (None, "date")),
+            (r"^(\d{10})-$", ("date", None)),
+            (r"^(\d{10})-(\d{10})$", ("date", "date")),
+            (r"^-(\d{13})$", (None, "date")),
+            (r"^(\d{13})-$", ("date", None)),
+            (r"^(\d{13})-(\d{13})$", ("date", "date")),
+        ]
         for rex, stype in syntax:
             # Apply the regular expression to text
             match = re.match(rex, text)
             if match:  # Regex has matched
                 rvals = match.groups()
                 index = 0
                 start: int = 0
                 stop: int = 0
                 if stype[0]:
                     starts = rvals[index]
-                    if stype[0] == 'date' and len(starts) == 8:
-                        start = int(datetime.strptime(starts, '%Y%m%d').replace(
-                            tzinfo=timezone.utc).timestamp())
+                    if stype[0] == "date" and len(starts) == 8:
+                        start = int(
+                            datetime.strptime(starts, "%Y%m%d")
+                            .replace(tzinfo=timezone.utc)
+                            .timestamp()
+                        )
                     elif len(starts) == 13:
                         start = int(starts) // 1000
                     else:
                         start = int(starts)
                     index += 1
                 if stype[1]:
                     stops = rvals[index]
-                    if stype[1] == 'date' and len(stops) == 8:
-                        stop = int(datetime.strptime(stops, '%Y%m%d').replace(
-                            tzinfo=timezone.utc).timestamp())
+                    if stype[1] == "date" and len(stops) == 8:
+                        stop = int(
+                            datetime.strptime(stops, "%Y%m%d")
+                            .replace(tzinfo=timezone.utc)
+                            .timestamp()
+                        )
                     elif len(stops) == 13:
                         stop = int(stops) // 1000
                     else:
                         stop = int(stops)
                 if start > stop > 0:
                     raise ConfigurationError(
-                        f'Start date is after stop date for timerange "{text}"')
+                        f'Start date is after stop date for timerange "{text}"'
+                    )
                 return cls(stype[0], stype[1], start, stop)
         raise ConfigurationError(f'Incorrect syntax for timerange "{text}"')
```

### Comparing `freqtrade-2024.4/freqtrade/data/btanalysis.py` & `freqtrade-2024.5/freqtrade/data/btanalysis.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Helpers when analyzing backtest data
 """
+
 import logging
 from copy import copy
 from datetime import datetime, timezone
 from pathlib import Path
 from typing import Any, Dict, List, Literal, Optional, Union
 
 import numpy as np
@@ -17,22 +18,43 @@
 from freqtrade.persistence import LocalTrade, Trade, init_db
 from freqtrade.types import BacktestHistoryEntryType, BacktestResultType
 
 
 logger = logging.getLogger(__name__)
 
 # Newest format
-BT_DATA_COLUMNS = ['pair', 'stake_amount', 'max_stake_amount', 'amount',
-                   'open_date', 'close_date', 'open_rate', 'close_rate',
-                   'fee_open', 'fee_close', 'trade_duration',
-                   'profit_ratio', 'profit_abs', 'exit_reason',
-                   'initial_stop_loss_abs', 'initial_stop_loss_ratio', 'stop_loss_abs',
-                   'stop_loss_ratio', 'min_rate', 'max_rate', 'is_open', 'enter_tag',
-                   'leverage', 'is_short', 'open_timestamp', 'close_timestamp', 'orders'
-                   ]
+BT_DATA_COLUMNS = [
+    "pair",
+    "stake_amount",
+    "max_stake_amount",
+    "amount",
+    "open_date",
+    "close_date",
+    "open_rate",
+    "close_rate",
+    "fee_open",
+    "fee_close",
+    "trade_duration",
+    "profit_ratio",
+    "profit_abs",
+    "exit_reason",
+    "initial_stop_loss_abs",
+    "initial_stop_loss_ratio",
+    "stop_loss_abs",
+    "stop_loss_ratio",
+    "min_rate",
+    "max_rate",
+    "is_open",
+    "enter_tag",
+    "leverage",
+    "is_short",
+    "open_timestamp",
+    "close_timestamp",
+    "orders",
+]
 
 
 def get_latest_optimize_filename(directory: Union[Path, str], variant: str) -> str:
     """
     Get latest backtest export based on '.last_result.json'.
     :param directory: Directory to search for last result
     :param variant: 'backtest' or 'hyperopt' - the method to return
@@ -46,72 +68,75 @@
         directory = Path(directory)
     if not directory.is_dir():
         raise ValueError(f"Directory '{directory}' does not exist.")
     filename = directory / LAST_BT_RESULT_FN
 
     if not filename.is_file():
         raise ValueError(
-            f"Directory '{directory}' does not seem to contain backtest statistics yet.")
+            f"Directory '{directory}' does not seem to contain backtest statistics yet."
+        )
 
     with filename.open() as file:
         data = json_load(file)
 
-    if f'latest_{variant}' not in data:
+    if f"latest_{variant}" not in data:
         raise ValueError(f"Invalid '{LAST_BT_RESULT_FN}' format.")
 
-    return data[f'latest_{variant}']
+    return data[f"latest_{variant}"]
 
 
 def get_latest_backtest_filename(directory: Union[Path, str]) -> str:
     """
     Get latest backtest export based on '.last_result.json'.
     :param directory: Directory to search for last result
     :return: string containing the filename of the latest backtest result
     :raises: ValueError in the following cases:
         * Directory does not exist
         * `directory/.last_result.json` does not exist
         * `directory/.last_result.json` has the wrong content
     """
-    return get_latest_optimize_filename(directory, 'backtest')
+    return get_latest_optimize_filename(directory, "backtest")
 
 
 def get_latest_hyperopt_filename(directory: Union[Path, str]) -> str:
     """
     Get latest hyperopt export based on '.last_result.json'.
     :param directory: Directory to search for last result
     :return: string containing the filename of the latest hyperopt result
     :raises: ValueError in the following cases:
         * Directory does not exist
         * `directory/.last_result.json` does not exist
         * `directory/.last_result.json` has the wrong content
     """
     try:
-        return get_latest_optimize_filename(directory, 'hyperopt')
+        return get_latest_optimize_filename(directory, "hyperopt")
     except ValueError:
         # Return default (legacy) pickle filename
-        return 'hyperopt_results.pickle'
+        return "hyperopt_results.pickle"
 
 
 def get_latest_hyperopt_file(
-        directory: Union[Path, str], predef_filename: Optional[str] = None) -> Path:
+    directory: Union[Path, str], predef_filename: Optional[str] = None
+) -> Path:
     """
     Get latest hyperopt export based on '.last_result.json'.
     :param directory: Directory to search for last result
     :return: string containing the filename of the latest hyperopt result
     :raises: ValueError in the following cases:
         * Directory does not exist
         * `directory/.last_result.json` does not exist
         * `directory/.last_result.json` has the wrong content
     """
     if isinstance(directory, str):
         directory = Path(directory)
     if predef_filename:
         if Path(predef_filename).is_absolute():
             raise ConfigurationError(
-                "--hyperopt-filename expects only the filename, not an absolute path.")
+                "--hyperopt-filename expects only the filename, not an absolute path."
+            )
         return directory / predef_filename
     return directory / get_latest_hyperopt_filename(directory)
 
 
 def load_backtest_metadata(filename: Union[Path, str]) -> Dict[str, Any]:
     """
     Read metadata dictionary from backtest results file without reading and deserializing entire
@@ -122,15 +147,15 @@
     filename = get_backtest_metadata_filename(filename)
     try:
         with filename.open() as fp:
             return json_load(fp)
     except FileNotFoundError:
         return {}
     except Exception as e:
-        raise OperationalException('Unexpected error while loading backtest metadata.') from e
+        raise OperationalException("Unexpected error while loading backtest metadata.") from e
 
 
 def load_backtest_stats(filename: Union[Path, str]) -> BacktestResultType:
     """
     Load backtest statistics file.
     :param filename: pathlib.Path object, or string pointing to the file.
     :return: a dictionary containing the resulting file.
@@ -143,58 +168,59 @@
         raise ValueError(f"File {filename} does not exist.")
     logger.info(f"Loading backtest result from {filename}")
     with filename.open() as file:
         data = json_load(file)
 
     # Legacy list format does not contain metadata.
     if isinstance(data, dict):
-        data['metadata'] = load_backtest_metadata(filename)
+        data["metadata"] = load_backtest_metadata(filename)
     return data
 
 
 def load_and_merge_backtest_result(strategy_name: str, filename: Path, results: Dict[str, Any]):
     """
     Load one strategy from multi-strategy result and merge it with results
     :param strategy_name: Name of the strategy contained in the result
     :param filename: Backtest-result-filename to load
     :param results: dict to merge the result to.
     """
     bt_data = load_backtest_stats(filename)
-    k: Literal['metadata', 'strategy']
-    for k in ('metadata', 'strategy'):  # type: ignore
+    k: Literal["metadata", "strategy"]
+    for k in ("metadata", "strategy"):  # type: ignore
         results[k][strategy_name] = bt_data[k][strategy_name]
-    results['metadata'][strategy_name]['filename'] = filename.stem
-    comparison = bt_data['strategy_comparison']
+    results["metadata"][strategy_name]["filename"] = filename.stem
+    comparison = bt_data["strategy_comparison"]
     for i in range(len(comparison)):
-        if comparison[i]['key'] == strategy_name:
-            results['strategy_comparison'].append(comparison[i])
+        if comparison[i]["key"] == strategy_name:
+            results["strategy_comparison"].append(comparison[i])
             break
 
 
 def _get_backtest_files(dirname: Path) -> List[Path]:
     # Weird glob expression here avoids including .meta.json files.
-    return list(reversed(sorted(dirname.glob('backtest-result-*-[0-9][0-9].json'))))
+    return list(reversed(sorted(dirname.glob("backtest-result-*-[0-9][0-9].json"))))
 
 
 def _extract_backtest_result(filename: Path) -> List[BacktestHistoryEntryType]:
     metadata = load_backtest_metadata(filename)
     return [
         {
-            'filename': filename.stem,
-            'strategy': s,
-            'run_id': v['run_id'],
-            'notes': v.get('notes', ''),
+            "filename": filename.stem,
+            "strategy": s,
+            "run_id": v["run_id"],
+            "notes": v.get("notes", ""),
             # Backtest "run" time
-            'backtest_start_time': v['backtest_start_time'],
+            "backtest_start_time": v["backtest_start_time"],
             # Backtest timerange
-            'backtest_start_ts': v.get('backtest_start_ts', None),
-            'backtest_end_ts': v.get('backtest_end_ts', None),
-            'timeframe': v.get('timeframe', None),
-            'timeframe_detail': v.get('timeframe_detail', None),
-        } for s, v in metadata.items()
+            "backtest_start_ts": v.get("backtest_start_ts", None),
+            "backtest_end_ts": v.get("backtest_end_ts", None),
+            "timeframe": v.get("timeframe", None),
+            "timeframe_detail": v.get("timeframe_detail", None),
+        }
+        for s, v in metadata.items()
     ]
 
 
 def get_backtest_result(filename: Path) -> List[BacktestHistoryEntryType]:
     """
     Get backtest result read from metadata file
     """
@@ -214,15 +240,15 @@
 
 def delete_backtest_result(file_abs: Path):
     """
     Delete backtest result file and corresponding metadata file.
     """
     # *.meta.json
     logger.info(f"Deleting backtest result file: {file_abs.name}")
-    file_abs_meta = file_abs.with_suffix('.meta.json')
+    file_abs_meta = file_abs.with_suffix(".meta.json")
     file_abs.unlink()
     file_abs_meta.unlink()
 
 
 def update_backtest_metadata(filename: Path, strategy: str, content: Dict[str, Any]):
     """
     Updates backtest metadata file with new content.
@@ -240,34 +266,35 @@
 
 def get_backtest_market_change(filename: Path, include_ts: bool = True) -> pd.DataFrame:
     """
     Read backtest market change file.
     """
     df = pd.read_feather(filename)
     if include_ts:
-        df.loc[:, '__date_ts'] = df.loc[:, 'date'].astype(np.int64) // 1000 // 1000
+        df.loc[:, "__date_ts"] = df.loc[:, "date"].astype(np.int64) // 1000 // 1000
     return df
 
 
-def find_existing_backtest_stats(dirname: Union[Path, str], run_ids: Dict[str, str],
-                                 min_backtest_date: Optional[datetime] = None) -> Dict[str, Any]:
+def find_existing_backtest_stats(
+    dirname: Union[Path, str], run_ids: Dict[str, str], min_backtest_date: Optional[datetime] = None
+) -> Dict[str, Any]:
     """
     Find existing backtest stats that match specified run IDs and load them.
     :param dirname: pathlib.Path object, or string pointing to the file.
     :param run_ids: {strategy_name: id_string} dictionary.
     :param min_backtest_date: do not load a backtest older than specified date.
     :return: results dict.
     """
     # Copy so we can modify this dict without affecting parent scope.
     run_ids = copy(run_ids)
     dirname = Path(dirname)
     results: Dict[str, Any] = {
-        'metadata': {},
-        'strategy': {},
-        'strategy_comparison': [],
+        "metadata": {},
+        "strategy": {},
+        "strategy_comparison": [],
     }
 
     for filename in _get_backtest_files(dirname):
         metadata = load_backtest_metadata(filename)
         if not metadata:
             # Files are sorted from newest to oldest. When file without metadata is encountered it
             # is safe to assume older files will also not have any metadata.
@@ -276,48 +303,48 @@
         for strategy_name, run_id in list(run_ids.items()):
             strategy_metadata = metadata.get(strategy_name, None)
             if not strategy_metadata:
                 # This strategy is not present in analyzed backtest.
                 continue
 
             if min_backtest_date is not None:
-                backtest_date = strategy_metadata['backtest_start_time']
+                backtest_date = strategy_metadata["backtest_start_time"]
                 backtest_date = datetime.fromtimestamp(backtest_date, tz=timezone.utc)
                 if backtest_date < min_backtest_date:
                     # Do not use a cached result for this strategy as first result is too old.
                     del run_ids[strategy_name]
                     continue
 
-            if strategy_metadata['run_id'] == run_id:
+            if strategy_metadata["run_id"] == run_id:
                 del run_ids[strategy_name]
                 load_and_merge_backtest_result(strategy_name, filename, results)
 
         if len(run_ids) == 0:
             break
     return results
 
 
 def _load_backtest_data_df_compatibility(df: pd.DataFrame) -> pd.DataFrame:
     """
     Compatibility support for older backtest data.
     """
-    df['open_date'] = pd.to_datetime(df['open_date'], utc=True)
-    df['close_date'] = pd.to_datetime(df['close_date'], utc=True)
+    df["open_date"] = pd.to_datetime(df["open_date"], utc=True)
+    df["close_date"] = pd.to_datetime(df["close_date"], utc=True)
     # Compatibility support for pre short Columns
-    if 'is_short' not in df.columns:
-        df['is_short'] = False
-    if 'leverage' not in df.columns:
-        df['leverage'] = 1.0
-    if 'enter_tag' not in df.columns:
-        df['enter_tag'] = df['buy_tag']
-        df = df.drop(['buy_tag'], axis=1)
-    if 'max_stake_amount' not in df.columns:
-        df['max_stake_amount'] = df['stake_amount']
-    if 'orders' not in df.columns:
-        df['orders'] = None
+    if "is_short" not in df.columns:
+        df["is_short"] = False
+    if "leverage" not in df.columns:
+        df["leverage"] = 1.0
+    if "enter_tag" not in df.columns:
+        df["enter_tag"] = df["buy_tag"]
+        df = df.drop(["buy_tag"], axis=1)
+    if "max_stake_amount" not in df.columns:
+        df["max_stake_amount"] = df["stake_amount"]
+    if "orders" not in df.columns:
+        df["orders"] = None
     return df
 
 
 def load_backtest_data(filename: Union[Path, str], strategy: Optional[str] = None) -> pd.DataFrame:
     """
     Load backtest data file.
     :param filename: pathlib.Path object, or string pointing to a file or directory
@@ -325,93 +352,99 @@
                      Can also serve as protection to load the correct result.
     :return: a dataframe with the analysis results
     :raise: ValueError if loading goes wrong.
     """
     data = load_backtest_stats(filename)
     if not isinstance(data, list):
         # new, nested format
-        if 'strategy' not in data:
+        if "strategy" not in data:
             raise ValueError("Unknown dataformat.")
 
         if not strategy:
-            if len(data['strategy']) == 1:
-                strategy = list(data['strategy'].keys())[0]
+            if len(data["strategy"]) == 1:
+                strategy = list(data["strategy"].keys())[0]
             else:
-                raise ValueError("Detected backtest result with more than one strategy. "
-                                 "Please specify a strategy.")
+                raise ValueError(
+                    "Detected backtest result with more than one strategy. "
+                    "Please specify a strategy."
+                )
 
-        if strategy not in data['strategy']:
+        if strategy not in data["strategy"]:
             raise ValueError(
                 f"Strategy {strategy} not available in the backtest result. "
                 f"Available strategies are '{','.join(data['strategy'].keys())}'"
-                )
+            )
 
-        data = data['strategy'][strategy]['trades']
+        data = data["strategy"][strategy]["trades"]
         df = pd.DataFrame(data)
         if not df.empty:
             df = _load_backtest_data_df_compatibility(df)
 
     else:
         # old format - only with lists.
         raise OperationalException(
-            "Backtest-results with only trades data are no longer supported.")
+            "Backtest-results with only trades data are no longer supported."
+        )
     if not df.empty:
         df = df.sort_values("open_date").reset_index(drop=True)
     return df
 
 
 def analyze_trade_parallelism(results: pd.DataFrame, timeframe: str) -> pd.DataFrame:
     """
     Find overlapping trades by expanding each trade once per period it was open
     and then counting overlaps.
     :param results: Results Dataframe - can be loaded
     :param timeframe: Timeframe used for backtest
     :return: dataframe with open-counts per time-period in timeframe
     """
     from freqtrade.exchange import timeframe_to_resample_freq
+
     timeframe_freq = timeframe_to_resample_freq(timeframe)
-    dates = [pd.Series(pd.date_range(row[1]['open_date'], row[1]['close_date'],
-                                     freq=timeframe_freq))
-             for row in results[['open_date', 'close_date']].iterrows()]
+    dates = [
+        pd.Series(pd.date_range(row[1]["open_date"], row[1]["close_date"], freq=timeframe_freq))
+        for row in results[["open_date", "close_date"]].iterrows()
+    ]
     deltas = [len(x) for x in dates]
-    dates = pd.Series(pd.concat(dates).values, name='date')
+    dates = pd.Series(pd.concat(dates).values, name="date")
     df2 = pd.DataFrame(np.repeat(results.values, deltas, axis=0), columns=results.columns)
 
     df2 = pd.concat([dates, df2], axis=1)
-    df2 = df2.set_index('date')
-    df_final = df2.resample(timeframe_freq)[['pair']].count()
-    df_final = df_final.rename({'pair': 'open_trades'}, axis=1)
+    df2 = df2.set_index("date")
+    df_final = df2.resample(timeframe_freq)[["pair"]].count()
+    df_final = df_final.rename({"pair": "open_trades"}, axis=1)
     return df_final
 
 
-def evaluate_result_multi(results: pd.DataFrame, timeframe: str,
-                          max_open_trades: IntOrInf) -> pd.DataFrame:
+def evaluate_result_multi(
+    results: pd.DataFrame, timeframe: str, max_open_trades: IntOrInf
+) -> pd.DataFrame:
     """
     Find overlapping trades by expanding each trade once per period it was open
     and then counting overlaps
     :param results: Results Dataframe - can be loaded
     :param timeframe: Frequency used for the backtest
     :param max_open_trades: parameter max_open_trades used during backtest run
     :return: dataframe with open-counts per time-period in freq
     """
     df_final = analyze_trade_parallelism(results, timeframe)
-    return df_final[df_final['open_trades'] > max_open_trades]
+    return df_final[df_final["open_trades"] > max_open_trades]
 
 
 def trade_list_to_dataframe(trades: Union[List[Trade], List[LocalTrade]]) -> pd.DataFrame:
     """
     Convert list of Trade objects to pandas Dataframe
     :param trades: List of trade objects
     :return: Dataframe with BT_DATA_COLUMNS
     """
     df = pd.DataFrame.from_records([t.to_json(True) for t in trades], columns=BT_DATA_COLUMNS)
     if len(df) > 0:
-        df['close_date'] = pd.to_datetime(df['close_date'], utc=True)
-        df['open_date'] = pd.to_datetime(df['open_date'], utc=True)
-        df['close_rate'] = df['close_rate'].astype('float64')
+        df["close_date"] = pd.to_datetime(df["close_date"], utc=True)
+        df["open_date"] = pd.to_datetime(df["open_date"], utc=True)
+        df["close_rate"] = df["close_rate"].astype("float64")
     return df
 
 
 def load_trades_from_db(db_url: str, strategy: Optional[str] = None) -> pd.DataFrame:
     """
     Load trades from a DB (using dburl)
     :param db_url: Sqlite url (default format sqlite:///tradesv3.dry-run.sqlite)
@@ -425,16 +458,21 @@
     if strategy:
         filters.append(Trade.strategy == strategy)
     trades = trade_list_to_dataframe(list(Trade.get_trades(filters).all()))
 
     return trades
 
 
-def load_trades(source: str, db_url: str, exportfilename: Path,
-                no_trades: bool = False, strategy: Optional[str] = None) -> pd.DataFrame:
+def load_trades(
+    source: str,
+    db_url: str,
+    exportfilename: Path,
+    no_trades: bool = False,
+    strategy: Optional[str] = None,
+) -> pd.DataFrame:
     """
     Based on configuration option 'trade_source':
     * loads data from DB (using `db_url`)
     * loads data from backtestfile (using `exportfilename`)
     :param source: "DB" or "file" - specify source to load from
     :param db_url: sqlalchemy formatted url to a database
     :param exportfilename: Json file generated by backtesting
@@ -447,22 +485,24 @@
 
     if source == "DB":
         return load_trades_from_db(db_url)
     elif source == "file":
         return load_backtest_data(exportfilename, strategy)
 
 
-def extract_trades_of_period(dataframe: pd.DataFrame, trades: pd.DataFrame,
-                             date_index=False) -> pd.DataFrame:
+def extract_trades_of_period(
+    dataframe: pd.DataFrame, trades: pd.DataFrame, date_index=False
+) -> pd.DataFrame:
     """
     Compare trades and backtested pair DataFrames to get trades performed on backtested period
     :return: the DataFrame of a trades of period
     """
     if date_index:
         trades_start = dataframe.index[0]
         trades_stop = dataframe.index[-1]
     else:
-        trades_start = dataframe.iloc[0]['date']
-        trades_stop = dataframe.iloc[-1]['date']
-    trades = trades.loc[(trades['open_date'] >= trades_start) &
-                        (trades['close_date'] <= trades_stop)]
+        trades_start = dataframe.iloc[0]["date"]
+        trades_stop = dataframe.iloc[-1]["date"]
+    trades = trades.loc[
+        (trades["open_date"] >= trades_start) & (trades["close_date"] <= trades_stop)
+    ]
     return trades
```

### Comparing `freqtrade-2024.4/freqtrade/data/converter/__init__.py` & `freqtrade-2024.5/freqtrade/data/converter/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,28 +1,38 @@
-from freqtrade.data.converter.converter import (clean_ohlcv_dataframe, convert_ohlcv_format,
-                                                ohlcv_fill_up_missing_data, ohlcv_to_dataframe,
-                                                order_book_to_dataframe, reduce_dataframe_footprint,
-                                                trim_dataframe, trim_dataframes)
-from freqtrade.data.converter.trade_converter import (convert_trades_format,
-                                                      convert_trades_to_ohlcv, trades_convert_types,
-                                                      trades_df_remove_duplicates,
-                                                      trades_dict_to_list, trades_list_to_df,
-                                                      trades_to_ohlcv)
+from freqtrade.data.converter.converter import (
+    clean_ohlcv_dataframe,
+    convert_ohlcv_format,
+    ohlcv_fill_up_missing_data,
+    ohlcv_to_dataframe,
+    order_book_to_dataframe,
+    reduce_dataframe_footprint,
+    trim_dataframe,
+    trim_dataframes,
+)
+from freqtrade.data.converter.trade_converter import (
+    convert_trades_format,
+    convert_trades_to_ohlcv,
+    trades_convert_types,
+    trades_df_remove_duplicates,
+    trades_dict_to_list,
+    trades_list_to_df,
+    trades_to_ohlcv,
+)
 
 
 __all__ = [
-    'clean_ohlcv_dataframe',
-    'convert_ohlcv_format',
-    'ohlcv_fill_up_missing_data',
-    'ohlcv_to_dataframe',
-    'order_book_to_dataframe',
-    'reduce_dataframe_footprint',
-    'trim_dataframe',
-    'trim_dataframes',
-    'convert_trades_format',
-    'convert_trades_to_ohlcv',
-    'trades_convert_types',
-    'trades_df_remove_duplicates',
-    'trades_dict_to_list',
-    'trades_list_to_df',
-    'trades_to_ohlcv',
+    "clean_ohlcv_dataframe",
+    "convert_ohlcv_format",
+    "ohlcv_fill_up_missing_data",
+    "ohlcv_to_dataframe",
+    "order_book_to_dataframe",
+    "reduce_dataframe_footprint",
+    "trim_dataframe",
+    "trim_dataframes",
+    "convert_trades_format",
+    "convert_trades_to_ohlcv",
+    "trades_convert_types",
+    "trades_df_remove_duplicates",
+    "trades_dict_to_list",
+    "trades_list_to_df",
+    "trades_to_ohlcv",
 ]
```

### Comparing `freqtrade-2024.4/freqtrade/data/converter/converter.py` & `freqtrade-2024.5/freqtrade/data/converter/converter.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,26 +1,33 @@
 """
 Functions to convert data from one format to another
 """
+
 import logging
 from typing import Dict
 
 import numpy as np
 import pandas as pd
 from pandas import DataFrame, to_datetime
 
 from freqtrade.constants import DEFAULT_DATAFRAME_COLUMNS, Config
 from freqtrade.enums import CandleType, TradingMode
 
 
 logger = logging.getLogger(__name__)
 
 
-def ohlcv_to_dataframe(ohlcv: list, timeframe: str, pair: str, *,
-                       fill_missing: bool = True, drop_incomplete: bool = True) -> DataFrame:
+def ohlcv_to_dataframe(
+    ohlcv: list,
+    timeframe: str,
+    pair: str,
+    *,
+    fill_missing: bool = True,
+    drop_incomplete: bool = True,
+) -> DataFrame:
     """
     Converts a list with candle (OHLCV) data (in format returned by ccxt.fetch_ohlcv)
     to a Dataframe
     :param ohlcv: list with candle (OHLCV) data, as returned by exchange.async_get_candle_history
     :param timeframe: timeframe (e.g. 5m). Used to fill up eventual missing data
     :param pair: Pair this data is for (used to warn if fillup was necessary)
     :param fill_missing: fill up missing candles with 0 candles
@@ -28,165 +35,185 @@
     :param drop_incomplete: Drop the last candle of the dataframe, assuming it's incomplete
     :return: DataFrame
     """
     logger.debug(f"Converting candle (OHLCV) data to dataframe for pair {pair}.")
     cols = DEFAULT_DATAFRAME_COLUMNS
     df = DataFrame(ohlcv, columns=cols)
 
-    df['date'] = to_datetime(df['date'], unit='ms', utc=True)
+    df["date"] = to_datetime(df["date"], unit="ms", utc=True)
 
     # Some exchanges return int values for Volume and even for OHLC.
     # Convert them since TA-LIB indicators used in the strategy assume floats
     # and fail with exception...
-    df = df.astype(dtype={'open': 'float', 'high': 'float', 'low': 'float', 'close': 'float',
-                          'volume': 'float'})
-    return clean_ohlcv_dataframe(df, timeframe, pair,
-                                 fill_missing=fill_missing,
-                                 drop_incomplete=drop_incomplete)
-
-
-def clean_ohlcv_dataframe(data: DataFrame, timeframe: str, pair: str, *,
-                          fill_missing: bool, drop_incomplete: bool) -> DataFrame:
+    df = df.astype(
+        dtype={
+            "open": "float",
+            "high": "float",
+            "low": "float",
+            "close": "float",
+            "volume": "float",
+        }
+    )
+    return clean_ohlcv_dataframe(
+        df, timeframe, pair, fill_missing=fill_missing, drop_incomplete=drop_incomplete
+    )
+
+
+def clean_ohlcv_dataframe(
+    data: DataFrame, timeframe: str, pair: str, *, fill_missing: bool, drop_incomplete: bool
+) -> DataFrame:
     """
     Cleanse a OHLCV dataframe by
       * Grouping it by date (removes duplicate tics)
       * dropping last candles if requested
       * Filling up missing data (if requested)
     :param data: DataFrame containing candle (OHLCV) data.
     :param timeframe: timeframe (e.g. 5m). Used to fill up eventual missing data
     :param pair: Pair this data is for (used to warn if fillup was necessary)
     :param fill_missing: fill up missing candles with 0 candles
                          (see ohlcv_fill_up_missing_data for details)
     :param drop_incomplete: Drop the last candle of the dataframe, assuming it's incomplete
     :return: DataFrame
     """
     # group by index and aggregate results to eliminate duplicate ticks
-    data = data.groupby(by='date', as_index=False, sort=True).agg({
-        'open': 'first',
-        'high': 'max',
-        'low': 'min',
-        'close': 'last',
-        'volume': 'max',
-    })
+    data = data.groupby(by="date", as_index=False, sort=True).agg(
+        {
+            "open": "first",
+            "high": "max",
+            "low": "min",
+            "close": "last",
+            "volume": "max",
+        }
+    )
     # eliminate partial candle
     if drop_incomplete:
         data.drop(data.tail(1).index, inplace=True)
-        logger.debug('Dropping last candle')
+        logger.debug("Dropping last candle")
 
     if fill_missing:
         return ohlcv_fill_up_missing_data(data, timeframe, pair)
     else:
         return data
 
 
 def ohlcv_fill_up_missing_data(dataframe: DataFrame, timeframe: str, pair: str) -> DataFrame:
     """
     Fills up missing data with 0 volume rows,
-    using the previous close as price for "open", "high" "low" and "close", volume is set to 0
+    using the previous close as price for "open", "high", "low" and "close", volume is set to 0
 
     """
     from freqtrade.exchange import timeframe_to_resample_freq
 
-    ohlcv_dict = {
-        'open': 'first',
-        'high': 'max',
-        'low': 'min',
-        'close': 'last',
-        'volume': 'sum'
-    }
+    ohlcv_dict = {"open": "first", "high": "max", "low": "min", "close": "last", "volume": "sum"}
     resample_interval = timeframe_to_resample_freq(timeframe)
     # Resample to create "NAN" values
-    df = dataframe.resample(resample_interval, on='date').agg(ohlcv_dict)
+    df = dataframe.resample(resample_interval, on="date").agg(ohlcv_dict)
 
     # Forwardfill close for missing columns
-    df['close'] = df['close'].ffill()
+    df["close"] = df["close"].ffill()
     # Use close for "open, high, low"
-    df.loc[:, ['open', 'high', 'low']] = df[['open', 'high', 'low']].fillna(
-        value={'open': df['close'],
-               'high': df['close'],
-               'low': df['close'],
-               })
+    df.loc[:, ["open", "high", "low"]] = df[["open", "high", "low"]].fillna(
+        value={
+            "open": df["close"],
+            "high": df["close"],
+            "low": df["close"],
+        }
+    )
     df.reset_index(inplace=True)
     len_before = len(dataframe)
     len_after = len(df)
     pct_missing = (len_after - len_before) / len_before if len_before > 0 else 0
     if len_before != len_after:
-        message = (f"Missing data fillup for {pair}, {timeframe}: "
-                   f"before: {len_before} - after: {len_after} - {pct_missing:.2%}")
+        message = (
+            f"Missing data fillup for {pair}, {timeframe}: "
+            f"before: {len_before} - after: {len_after} - {pct_missing:.2%}"
+        )
         if pct_missing > 0.01:
             logger.info(message)
         else:
             # Don't be verbose if only a small amount is missing
             logger.debug(message)
     return df
 
 
-def trim_dataframe(df: DataFrame, timerange, *, df_date_col: str = 'date',
-                   startup_candles: int = 0) -> DataFrame:
+def trim_dataframe(
+    df: DataFrame, timerange, *, df_date_col: str = "date", startup_candles: int = 0
+) -> DataFrame:
     """
     Trim dataframe based on given timerange
     :param df: Dataframe to trim
     :param timerange: timerange (use start and end date if available)
     :param df_date_col: Column in the dataframe to use as Date column
     :param startup_candles: When not 0, is used instead the timerange start date
     :return: trimmed dataframe
     """
     if startup_candles:
         # Trim candles instead of timeframe in case of given startup_candle count
         df = df.iloc[startup_candles:, :]
     else:
-        if timerange.starttype == 'date':
+        if timerange.starttype == "date":
             df = df.loc[df[df_date_col] >= timerange.startdt, :]
-    if timerange.stoptype == 'date':
+    if timerange.stoptype == "date":
         df = df.loc[df[df_date_col] <= timerange.stopdt, :]
     return df
 
 
-def trim_dataframes(preprocessed: Dict[str, DataFrame], timerange,
-                    startup_candles: int) -> Dict[str, DataFrame]:
+def trim_dataframes(
+    preprocessed: Dict[str, DataFrame], timerange, startup_candles: int
+) -> Dict[str, DataFrame]:
     """
     Trim startup period from analyzed dataframes
     :param preprocessed: Dict of pair: dataframe
     :param timerange: timerange (use start and end date if available)
     :param startup_candles: Startup-candles that should be removed
     :return: Dict of trimmed dataframes
     """
     processed: Dict[str, DataFrame] = {}
 
     for pair, df in preprocessed.items():
         trimed_df = trim_dataframe(df, timerange, startup_candles=startup_candles)
         if not trimed_df.empty:
             processed[pair] = trimed_df
         else:
-            logger.warning(f'{pair} has no data left after adjusting for startup candles, '
-                           f'skipping.')
+            logger.warning(
+                f"{pair} has no data left after adjusting for startup candles, skipping."
+            )
     return processed
 
 
 def order_book_to_dataframe(bids: list, asks: list) -> DataFrame:
     """
     TODO: This should get a dedicated test
     Gets order book list, returns dataframe with below format per suggested by creslin
     -------------------------------------------------------------------
      b_sum       b_size       bids       asks       a_size       a_sum
     -------------------------------------------------------------------
     """
-    cols = ['bids', 'b_size']
+    cols = ["bids", "b_size"]
 
     bids_frame = DataFrame(bids, columns=cols)
     # add cumulative sum column
-    bids_frame['b_sum'] = bids_frame['b_size'].cumsum()
-    cols2 = ['asks', 'a_size']
+    bids_frame["b_sum"] = bids_frame["b_size"].cumsum()
+    cols2 = ["asks", "a_size"]
     asks_frame = DataFrame(asks, columns=cols2)
     # add cumulative sum column
-    asks_frame['a_sum'] = asks_frame['a_size'].cumsum()
+    asks_frame["a_sum"] = asks_frame["a_size"].cumsum()
 
-    frame = pd.concat([bids_frame['b_sum'], bids_frame['b_size'], bids_frame['bids'],
-                       asks_frame['asks'], asks_frame['a_size'], asks_frame['a_sum']], axis=1,
-                      keys=['b_sum', 'b_size', 'bids', 'asks', 'a_size', 'a_sum'])
+    frame = pd.concat(
+        [
+            bids_frame["b_sum"],
+            bids_frame["b_size"],
+            bids_frame["bids"],
+            asks_frame["asks"],
+            asks_frame["a_size"],
+            asks_frame["a_sum"],
+        ],
+        axis=1,
+        keys=["b_sum", "b_size", "bids", "asks", "a_size", "a_sum"],
+    )
     # logger.info('order book %s', frame )
     return frame
 
 
 def convert_ohlcv_format(
     config: Config,
     convert_from: str,
@@ -197,77 +224,79 @@
     Convert OHLCV from one format to another
     :param config: Config dictionary
     :param convert_from: Source format
     :param convert_to: Target format
     :param erase: Erase source data (does not apply if source and target format are identical)
     """
     from freqtrade.data.history import get_datahandler
-    src = get_datahandler(config['datadir'], convert_from)
-    trg = get_datahandler(config['datadir'], convert_to)
-    timeframes = config.get('timeframes', [config.get('timeframe')])
+
+    src = get_datahandler(config["datadir"], convert_from)
+    trg = get_datahandler(config["datadir"], convert_to)
+    timeframes = config.get("timeframes", [config.get("timeframe")])
     logger.info(f"Converting candle (OHLCV) for timeframe {timeframes}")
 
-    candle_types = [CandleType.from_string(ct) for ct in config.get('candle_types', [
-        c.value for c in CandleType])]
+    candle_types = [
+        CandleType.from_string(ct)
+        for ct in config.get("candle_types", [c.value for c in CandleType])
+    ]
     logger.info(candle_types)
-    paircombs = src.ohlcv_get_available_data(config['datadir'], TradingMode.SPOT)
-    paircombs.extend(src.ohlcv_get_available_data(config['datadir'], TradingMode.FUTURES))
+    paircombs = src.ohlcv_get_available_data(config["datadir"], TradingMode.SPOT)
+    paircombs.extend(src.ohlcv_get_available_data(config["datadir"], TradingMode.FUTURES))
 
-    if 'pairs' in config:
+    if "pairs" in config:
         # Filter pairs
-        paircombs = [comb for comb in paircombs if comb[0] in config['pairs']]
+        paircombs = [comb for comb in paircombs if comb[0] in config["pairs"]]
 
-    if 'timeframes' in config:
-        paircombs = [comb for comb in paircombs if comb[1] in config['timeframes']]
+    if "timeframes" in config:
+        paircombs = [comb for comb in paircombs if comb[1] in config["timeframes"]]
     paircombs = [comb for comb in paircombs if comb[2] in candle_types]
 
     paircombs = sorted(paircombs, key=lambda x: (x[0], x[1], x[2].value))
 
-    formatted_paircombs = '\n'.join([f"{pair}, {timeframe}, {candle_type}"
-                                    for pair, timeframe, candle_type in paircombs])
-
-    logger.info(f"Converting candle (OHLCV) data for the following pair combinations:\n"
-                f"{formatted_paircombs}")
+    formatted_paircombs = "\n".join(
+        [f"{pair}, {timeframe}, {candle_type}" for pair, timeframe, candle_type in paircombs]
+    )
+
+    logger.info(
+        f"Converting candle (OHLCV) data for the following pair combinations:\n"
+        f"{formatted_paircombs}"
+    )
     for pair, timeframe, candle_type in paircombs:
-        data = src.ohlcv_load(pair=pair, timeframe=timeframe,
-                              timerange=None,
-                              fill_missing=False,
-                              drop_incomplete=False,
-                              startup_candles=0,
-                              candle_type=candle_type)
+        data = src.ohlcv_load(
+            pair=pair,
+            timeframe=timeframe,
+            timerange=None,
+            fill_missing=False,
+            drop_incomplete=False,
+            startup_candles=0,
+            candle_type=candle_type,
+        )
         logger.info(f"Converting {len(data)} {timeframe} {candle_type} candles for {pair}")
         if len(data) > 0:
-            trg.ohlcv_store(
-                pair=pair,
-                timeframe=timeframe,
-                data=data,
-                candle_type=candle_type
-            )
+            trg.ohlcv_store(pair=pair, timeframe=timeframe, data=data, candle_type=candle_type)
             if erase and convert_from != convert_to:
                 logger.info(f"Deleting source data for {pair} / {timeframe}")
                 src.ohlcv_purge(pair=pair, timeframe=timeframe, candle_type=candle_type)
 
 
 def reduce_dataframe_footprint(df: DataFrame) -> DataFrame:
     """
     Ensure all values are float32 in the incoming dataframe.
     :param df: Dataframe to be converted to float/int 32s
     :return: Dataframe converted to float/int 32s
     """
 
-    logger.debug(f"Memory usage of dataframe is "
-                 f"{df.memory_usage().sum() / 1024**2:.2f} MB")
+    logger.debug(f"Memory usage of dataframe is {df.memory_usage().sum() / 1024**2:.2f} MB")
 
     df_dtypes = df.dtypes
     for column, dtype in df_dtypes.items():
-        if column in ['open', 'high', 'low', 'close', 'volume']:
+        if column in ["open", "high", "low", "close", "volume"]:
             continue
         if dtype == np.float64:
             df_dtypes[column] = np.float32
         elif dtype == np.int64:
             df_dtypes[column] = np.int32
     df = df.astype(df_dtypes)
 
-    logger.debug(f"Memory usage after optimization is: "
-                 f"{df.memory_usage().sum() / 1024**2:.2f} MB")
+    logger.debug(f"Memory usage after optimization is: {df.memory_usage().sum() / 1024**2:.2f} MB")
 
     return df
```

### Comparing `freqtrade-2024.4/freqtrade/data/converter/trade_converter.py` & `freqtrade-2024.5/freqtrade/data/converter/trade_converter.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,35 +1,41 @@
 """
 Functions to convert data from one format to another
 """
+
 import logging
 from pathlib import Path
 from typing import Dict, List
 
 import pandas as pd
 from pandas import DataFrame, to_datetime
 
 from freqtrade.configuration import TimeRange
-from freqtrade.constants import (DEFAULT_DATAFRAME_COLUMNS, DEFAULT_TRADES_COLUMNS, TRADES_DTYPES,
-                                 Config, TradeList)
+from freqtrade.constants import (
+    DEFAULT_DATAFRAME_COLUMNS,
+    DEFAULT_TRADES_COLUMNS,
+    TRADES_DTYPES,
+    Config,
+    TradeList,
+)
 from freqtrade.enums import CandleType, TradingMode
 from freqtrade.exceptions import OperationalException
 
 
 logger = logging.getLogger(__name__)
 
 
 def trades_df_remove_duplicates(trades: pd.DataFrame) -> pd.DataFrame:
     """
     Removes duplicates from the trades DataFrame.
     Uses pandas.DataFrame.drop_duplicates to remove duplicates based on the 'timestamp' column.
     :param trades: DataFrame with the columns constants.DEFAULT_TRADES_COLUMNS
     :return: DataFrame with duplicates removed based on the 'timestamp' column
     """
-    return trades.drop_duplicates(subset=['timestamp', 'id'])
+    return trades.drop_duplicates(subset=["timestamp", "id"])
 
 
 def trades_dict_to_list(trades: List[Dict]) -> TradeList:
     """
     Convert fetch_trades result into a List (to be more memory efficient).
     :param trades: List of trades, as returned by ccxt.fetch_trades.
     :return: List of Lists, with constants.DEFAULT_TRADES_COLUMNS as columns
@@ -38,15 +44,15 @@
 
 
 def trades_convert_types(trades: DataFrame) -> DataFrame:
     """
     Convert Trades dtypes and add 'date' column
     """
     trades = trades.astype(TRADES_DTYPES)
-    trades['date'] = to_datetime(trades['timestamp'], unit='ms', utc=True)
+    trades["date"] = to_datetime(trades["timestamp"], unit="ms", utc=True)
     return trades
 
 
 def trades_list_to_df(trades: TradeList, convert: bool = True):
     """
     convert trades list to dataframe
     :param trades: List of Lists with constants.DEFAULT_TRADES_COLUMNS as columns
@@ -67,21 +73,22 @@
     Converts trades list to OHLCV list
     :param trades: List of trades, as returned by ccxt.fetch_trades.
     :param timeframe: Timeframe to resample data to
     :return: OHLCV Dataframe.
     :raises: ValueError if no trades are provided
     """
     from freqtrade.exchange import timeframe_to_resample_freq
+
     if trades.empty:
-        raise ValueError('Trade-list empty.')
-    df = trades.set_index('date', drop=True)
+        raise ValueError("Trade-list empty.")
+    df = trades.set_index("date", drop=True)
     resample_interval = timeframe_to_resample_freq(timeframe)
-    df_new = df['price'].resample(resample_interval).ohlc()
-    df_new['volume'] = df['amount'].resample(resample_interval).sum()
-    df_new['date'] = df_new.index
+    df_new = df["price"].resample(resample_interval).ohlc()
+    df_new["volume"] = df["amount"].resample(resample_interval).sum()
+    df_new["date"] = df_new.index
     # Drop 0 volume rows
     df_new = df_new.dropna()
     return df_new.loc[:, DEFAULT_DATAFRAME_COLUMNS]
 
 
 def convert_trades_to_ohlcv(
     pairs: List[str],
@@ -93,61 +100,66 @@
     data_format_trades: str,
     candle_type: CandleType,
 ) -> None:
     """
     Convert stored trades data to ohlcv data
     """
     from freqtrade.data.history import get_datahandler
+
     data_handler_trades = get_datahandler(datadir, data_format=data_format_trades)
     data_handler_ohlcv = get_datahandler(datadir, data_format=data_format_ohlcv)
 
-    logger.info(f"About to convert pairs: '{', '.join(pairs)}', "
-                f"intervals: '{', '.join(timeframes)}' to {datadir}")
+    logger.info(
+        f"About to convert pairs: '{', '.join(pairs)}', "
+        f"intervals: '{', '.join(timeframes)}' to {datadir}"
+    )
     trading_mode = TradingMode.FUTURES if candle_type != CandleType.SPOT else TradingMode.SPOT
     for pair in pairs:
         trades = data_handler_trades.trades_load(pair, trading_mode)
         for timeframe in timeframes:
             if erase:
                 if data_handler_ohlcv.ohlcv_purge(pair, timeframe, candle_type=candle_type):
-                    logger.info(f'Deleting existing data for pair {pair}, interval {timeframe}.')
+                    logger.info(f"Deleting existing data for pair {pair}, interval {timeframe}.")
             try:
                 ohlcv = trades_to_ohlcv(trades, timeframe)
                 # Store ohlcv
                 data_handler_ohlcv.ohlcv_store(pair, timeframe, data=ohlcv, candle_type=candle_type)
             except ValueError:
-                logger.warning(f'Could not convert {pair} to OHLCV.')
+                logger.warning(f"Could not convert {pair} to OHLCV.")
 
 
 def convert_trades_format(config: Config, convert_from: str, convert_to: str, erase: bool):
     """
     Convert trades from one format to another format.
     :param config: Config dictionary
     :param convert_from: Source format
     :param convert_to: Target format
     :param erase: Erase source data (does not apply if source and target format are identical)
     """
-    if convert_from == 'kraken_csv':
-        if config['exchange']['name'] != 'kraken':
+    if convert_from == "kraken_csv":
+        if config["exchange"]["name"] != "kraken":
             raise OperationalException(
-                'Converting from csv is only supported for kraken.'
-                'Please refer to the documentation for details about this special mode.'
+                "Converting from csv is only supported for kraken."
+                "Please refer to the documentation for details about this special mode."
             )
         from freqtrade.data.converter.trade_converter_kraken import import_kraken_trades_from_csv
+
         import_kraken_trades_from_csv(config, convert_to)
         return
 
     from freqtrade.data.history import get_datahandler
-    src = get_datahandler(config['datadir'], convert_from)
-    trg = get_datahandler(config['datadir'], convert_to)
 
-    if 'pairs' not in config:
-        config['pairs'] = src.trades_get_pairs(config['datadir'])
+    src = get_datahandler(config["datadir"], convert_from)
+    trg = get_datahandler(config["datadir"], convert_to)
+
+    if "pairs" not in config:
+        config["pairs"] = src.trades_get_pairs(config["datadir"])
     logger.info(f"Converting trades for {config['pairs']}")
-    trading_mode: TradingMode = config.get('trading_mode', TradingMode.SPOT)
-    for pair in config['pairs']:
+    trading_mode: TradingMode = config.get("trading_mode", TradingMode.SPOT)
+    for pair in config["pairs"]:
         data = src.trades_load(pair, trading_mode)
         logger.info(f"Converting {len(data)} trades for {pair}")
         trg.trades_store(pair, data, trading_mode)
 
         if erase and convert_from != convert_to:
             logger.info(f"Deleting source Trade data for {pair}.")
             src.trades_purge(pair, trading_mode)
```

### Comparing `freqtrade-2024.4/freqtrade/data/converter/trade_converter_kraken.py` & `freqtrade-2024.5/freqtrade/data/converter/trade_converter_kraken.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,50 +1,53 @@
 import logging
 from pathlib import Path
 
 import pandas as pd
 
 from freqtrade.constants import DATETIME_PRINT_FORMAT, DEFAULT_TRADES_COLUMNS, Config
-from freqtrade.data.converter.trade_converter import (trades_convert_types,
-                                                      trades_df_remove_duplicates)
+from freqtrade.data.converter.trade_converter import (
+    trades_convert_types,
+    trades_df_remove_duplicates,
+)
 from freqtrade.data.history import get_datahandler
 from freqtrade.enums import TradingMode
 from freqtrade.exceptions import OperationalException
 from freqtrade.plugins.pairlist.pairlist_helpers import expand_pairlist
 from freqtrade.resolvers import ExchangeResolver
 
 
 logger = logging.getLogger(__name__)
 
-KRAKEN_CSV_TRADE_COLUMNS = ['timestamp', 'price', 'amount']
+KRAKEN_CSV_TRADE_COLUMNS = ["timestamp", "price", "amount"]
 
 
 def import_kraken_trades_from_csv(config: Config, convert_to: str):
     """
     Import kraken trades from csv
     """
-    if config['exchange']['name'] != 'kraken':
-        raise OperationalException('This function is only for the kraken exchange.')
+    if config["exchange"]["name"] != "kraken":
+        raise OperationalException("This function is only for the kraken exchange.")
 
-    datadir: Path = config['datadir']
+    datadir: Path = config["datadir"]
     data_handler = get_datahandler(datadir, data_format=convert_to)
 
-    tradesdir: Path = config['datadir'] / 'trades_csv'
+    tradesdir: Path = config["datadir"] / "trades_csv"
     exchange = ExchangeResolver.load_exchange(config, validate=False)
     # iterate through directories in this directory
-    data_symbols = {p.stem for p in tradesdir.rglob('*.csv')}
+    data_symbols = {p.stem for p in tradesdir.rglob("*.csv")}
 
     # create pair/filename mapping
     markets = {
-        (m['symbol'], m['altname']) for m in exchange.markets.values()
-        if m.get('altname') in data_symbols
+        (m["symbol"], m["altname"])
+        for m in exchange.markets.values()
+        if m.get("altname") in data_symbols
     }
     logger.info(f"Found csv files for {', '.join(data_symbols)}.")
 
-    if pairs_raw := config.get('pairs'):
+    if pairs_raw := config.get("pairs"):
         pairs = expand_pairlist(pairs_raw, [m[0] for m in markets])
         markets = {m for m in markets if m[0] in pairs}
         if not markets:
             logger.info(f"No data found for pairs {', '.join(pairs_raw)}.")
             return
     logger.info(f"Converting pairs: {', '.join(m[0] for m in markets)}.")
 
@@ -62,22 +65,24 @@
             # edgecase, can only happen if the file was deleted between the above glob and here
             logger.info(f"No data found for pair {pair}")
             continue
 
         trades = pd.concat(dfs, ignore_index=True)
         del dfs
 
-        trades.loc[:, 'timestamp'] = trades['timestamp'] * 1e3
-        trades.loc[:, 'cost'] = trades['price'] * trades['amount']
+        trades.loc[:, "timestamp"] = trades["timestamp"] * 1e3
+        trades.loc[:, "cost"] = trades["price"] * trades["amount"]
         for col in DEFAULT_TRADES_COLUMNS:
             if col not in trades.columns:
-                trades.loc[:, col] = ''
+                trades.loc[:, col] = ""
         trades = trades[DEFAULT_TRADES_COLUMNS]
         trades = trades_convert_types(trades)
 
         trades_df = trades_df_remove_duplicates(trades)
         del trades
-        logger.info(f"{pair}: {len(trades_df)} trades, from "
-                    f"{trades_df['date'].min():{DATETIME_PRINT_FORMAT}} to "
-                    f"{trades_df['date'].max():{DATETIME_PRINT_FORMAT}}")
+        logger.info(
+            f"{pair}: {len(trades_df)} trades, from "
+            f"{trades_df['date'].min():{DATETIME_PRINT_FORMAT}} to "
+            f"{trades_df['date'].max():{DATETIME_PRINT_FORMAT}}"
+        )
 
         data_handler.trades_store(pair, trades_df, TradingMode.SPOT)
```

### Comparing `freqtrade-2024.4/freqtrade/data/dataprovider.py` & `freqtrade-2024.5/freqtrade/data/dataprovider.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,70 +1,76 @@
 """
 Dataprovider
 Responsible to provide data to the bot
 including ticker and orderbook data, live and historical candle (OHLCV) data
 Common Interface for bot and strategy to access data.
 """
+
 import logging
 from collections import deque
 from datetime import datetime, timezone
 from typing import Any, Dict, List, Optional, Tuple
 
 from pandas import DataFrame, Timedelta, Timestamp, to_timedelta
 
 from freqtrade.configuration import TimeRange
-from freqtrade.constants import (FULL_DATAFRAME_THRESHOLD, Config, ListPairsWithTimeframes,
-                                 PairWithTimeframe)
+from freqtrade.constants import (
+    FULL_DATAFRAME_THRESHOLD,
+    Config,
+    ListPairsWithTimeframes,
+    PairWithTimeframe,
+)
 from freqtrade.data.history import load_pair_history
 from freqtrade.enums import CandleType, RPCMessageType, RunMode
 from freqtrade.exceptions import ExchangeError, OperationalException
 from freqtrade.exchange import Exchange, timeframe_to_prev_date, timeframe_to_seconds
 from freqtrade.exchange.types import OrderBook
 from freqtrade.misc import append_candles_to_dataframe
 from freqtrade.rpc import RPCManager
 from freqtrade.rpc.rpc_types import RPCAnalyzedDFMsg
 from freqtrade.util import PeriodicCache
 
 
 logger = logging.getLogger(__name__)
 
-NO_EXCHANGE_EXCEPTION = 'Exchange is not available to DataProvider.'
+NO_EXCHANGE_EXCEPTION = "Exchange is not available to DataProvider."
 MAX_DATAFRAME_CANDLES = 1000
 
 
 class DataProvider:
-
     def __init__(
         self,
         config: Config,
         exchange: Optional[Exchange],
         pairlists=None,
-        rpc: Optional[RPCManager] = None
+        rpc: Optional[RPCManager] = None,
     ) -> None:
         self._config = config
         self._exchange = exchange
         self._pairlists = pairlists
         self.__rpc = rpc
         self.__cached_pairs: Dict[PairWithTimeframe, Tuple[DataFrame, datetime]] = {}
         self.__slice_index: Optional[int] = None
         self.__slice_date: Optional[datetime] = None
 
         self.__cached_pairs_backtesting: Dict[PairWithTimeframe, DataFrame] = {}
-        self.__producer_pairs_df: Dict[str,
-                                       Dict[PairWithTimeframe, Tuple[DataFrame, datetime]]] = {}
+        self.__producer_pairs_df: Dict[
+            str, Dict[PairWithTimeframe, Tuple[DataFrame, datetime]]
+        ] = {}
         self.__producer_pairs: Dict[str, List[str]] = {}
         self._msg_queue: deque = deque()
 
-        self._default_candle_type = self._config.get('candle_type_def', CandleType.SPOT)
-        self._default_timeframe = self._config.get('timeframe', '1h')
+        self._default_candle_type = self._config.get("candle_type_def", CandleType.SPOT)
+        self._default_timeframe = self._config.get("timeframe", "1h")
 
         self.__msg_cache = PeriodicCache(
-            maxsize=1000, ttl=timeframe_to_seconds(self._default_timeframe))
+            maxsize=1000, ttl=timeframe_to_seconds(self._default_timeframe)
+        )
 
-        self.producers = self._config.get('external_message_consumer', {}).get('producers', [])
+        self.producers = self._config.get("external_message_consumer", {}).get("producers", [])
         self.external_data_enabled = len(self.producers) > 0
 
     def _set_dataframe_max_index(self, limit_index: int):
         """
         Limit analyzed dataframe to max specified index.
         Only relevant in backtesting.
         :param limit_index: dataframe index.
@@ -76,32 +82,27 @@
         Limit infomrative dataframe to max specified index.
         Only relevant in backtesting.
         :param limit_date: "current date"
         """
         self.__slice_date = limit_date
 
     def _set_cached_df(
-        self,
-        pair: str,
-        timeframe: str,
-        dataframe: DataFrame,
-        candle_type: CandleType
+        self, pair: str, timeframe: str, dataframe: DataFrame, candle_type: CandleType
     ) -> None:
         """
         Store cached Dataframe.
         Using private method as this should never be used by a user
         (but the class is exposed via `self.dp` to the strategy)
         :param pair: pair to get the data for
         :param timeframe: Timeframe to get data for
         :param dataframe: analyzed dataframe
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         """
         pair_key = (pair, timeframe, candle_type)
-        self.__cached_pairs[pair_key] = (
-            dataframe, datetime.now(timezone.utc))
+        self.__cached_pairs[pair_key] = (dataframe, datetime.now(timezone.utc))
 
     # For multiple producers we will want to merge the pairlists instead of overwriting
     def _set_producer_pairs(self, pairlist: List[str], producer_name: str = "default"):
         """
         Set the pairs received to later be used.
 
         :param pairlist: List of pairs
@@ -112,51 +113,48 @@
         """
         Get the pairs cached from the producer
 
         :returns: List of pairs
         """
         return self.__producer_pairs.get(producer_name, []).copy()
 
-    def _emit_df(
-        self,
-        pair_key: PairWithTimeframe,
-        dataframe: DataFrame,
-        new_candle: bool
-    ) -> None:
+    def _emit_df(self, pair_key: PairWithTimeframe, dataframe: DataFrame, new_candle: bool) -> None:
         """
         Send this dataframe as an ANALYZED_DF message to RPC
 
         :param pair_key: PairWithTimeframe tuple
         :param dataframe: Dataframe to emit
         :param new_candle: This is a new candle
         """
         if self.__rpc:
             msg: RPCAnalyzedDFMsg = {
-                    'type': RPCMessageType.ANALYZED_DF,
-                    'data': {
-                        'key': pair_key,
-                        'df': dataframe.tail(1),
-                        'la': datetime.now(timezone.utc)
-                    }
-                }
+                "type": RPCMessageType.ANALYZED_DF,
+                "data": {
+                    "key": pair_key,
+                    "df": dataframe.tail(1),
+                    "la": datetime.now(timezone.utc),
+                },
+            }
             self.__rpc.send_msg(msg)
             if new_candle:
-                self.__rpc.send_msg({
-                        'type': RPCMessageType.NEW_CANDLE,
-                        'data': pair_key,
-                    })
+                self.__rpc.send_msg(
+                    {
+                        "type": RPCMessageType.NEW_CANDLE,
+                        "data": pair_key,
+                    }
+                )
 
     def _replace_external_df(
         self,
         pair: str,
         dataframe: DataFrame,
         last_analyzed: datetime,
         timeframe: str,
         candle_type: CandleType,
-        producer_name: str = "default"
+        producer_name: str = "default",
     ) -> None:
         """
         Add the pair data to this class from an external source.
 
         :param pair: pair to get the data for
         :param timeframe: Timeframe to get data for
         :param candle_type: Any of the enum CandleType (must match trading mode!)
@@ -174,15 +172,15 @@
     def _add_external_df(
         self,
         pair: str,
         dataframe: DataFrame,
         last_analyzed: datetime,
         timeframe: str,
         candle_type: CandleType,
-        producer_name: str = "default"
+        producer_name: str = "default",
     ) -> Tuple[bool, int]:
         """
         Append a candle to the existing external dataframe. The incoming dataframe
         must have at least 1 candle.
 
         :param pair: pair to get the data for
         :param timeframe: Timeframe to get data for
@@ -200,36 +198,38 @@
             # Add the dataframe to the dataprovider
             self._replace_external_df(
                 pair,
                 dataframe,
                 last_analyzed=last_analyzed,
                 timeframe=timeframe,
                 candle_type=candle_type,
-                producer_name=producer_name
+                producer_name=producer_name,
             )
             return (True, 0)
 
-        if (producer_name not in self.__producer_pairs_df
-           or pair_key not in self.__producer_pairs_df[producer_name]):
+        if (
+            producer_name not in self.__producer_pairs_df
+            or pair_key not in self.__producer_pairs_df[producer_name]
+        ):
             # We don't have data from this producer yet,
             # or we don't have data for this pair_key
             # return False and 1000 for the full df
             return (False, 1000)
 
         existing_df, _ = self.__producer_pairs_df[producer_name][pair_key]
 
         # CHECK FOR MISSING CANDLES
         # Convert the timeframe to a timedelta for pandas
         timeframe_delta: Timedelta = to_timedelta(timeframe)
-        local_last: Timestamp = existing_df.iloc[-1]['date']  # We want the last date from our copy
+        local_last: Timestamp = existing_df.iloc[-1]["date"]  # We want the last date from our copy
         # We want the first date from the incoming
-        incoming_first: Timestamp = dataframe.iloc[0]['date']
+        incoming_first: Timestamp = dataframe.iloc[0]["date"]
 
         # Remove existing candles that are newer than the incoming first candle
-        existing_df1 = existing_df[existing_df['date'] < incoming_first]
+        existing_df1 = existing_df[existing_df["date"] < incoming_first]
 
         candle_difference = (incoming_first - local_last) / timeframe_delta
 
         # If the difference divided by the timeframe is 1, then this
         # is the candle we want and the incoming data isn't missing any.
         # If the candle_difference is more than 1, that means
         # we missed some candles between our data and the incoming
@@ -239,29 +239,29 @@
         if existing_df1.empty:
             appended_df = dataframe
         else:
             appended_df = append_candles_to_dataframe(existing_df1, dataframe)
 
         # Everything is good, we appended
         self._replace_external_df(
-                    pair,
-                    appended_df,
-                    last_analyzed=last_analyzed,
-                    timeframe=timeframe,
-                    candle_type=candle_type,
-                    producer_name=producer_name
-                    )
+            pair,
+            appended_df,
+            last_analyzed=last_analyzed,
+            timeframe=timeframe,
+            candle_type=candle_type,
+            producer_name=producer_name,
+        )
         return (True, 0)
 
     def get_producer_df(
         self,
         pair: str,
         timeframe: Optional[str] = None,
         candle_type: Optional[CandleType] = None,
-        producer_name: str = "default"
+        producer_name: str = "default",
     ) -> Tuple[DataFrame, datetime]:
         """
         Get the pair data from producers.
 
         :param pair: pair to get the data for
         :param timeframe: Timeframe to get data for
         :param candle_type: Any of the enum CandleType (must match trading mode!)
@@ -288,72 +288,72 @@
 
     def add_pairlisthandler(self, pairlists) -> None:
         """
         Allow adding pairlisthandler after initialization
         """
         self._pairlists = pairlists
 
-    def historic_ohlcv(
-        self,
-        pair: str,
-        timeframe: str,
-        candle_type: str = ''
-    ) -> DataFrame:
+    def historic_ohlcv(self, pair: str, timeframe: str, candle_type: str = "") -> DataFrame:
         """
         Get stored historical candle (OHLCV) data
         :param pair: pair to get the data for
         :param timeframe: timeframe to get data for
         :param candle_type: '', mark, index, premiumIndex, or funding_rate
         """
-        _candle_type = CandleType.from_string(
-            candle_type) if candle_type != '' else self._config['candle_type_def']
+        _candle_type = (
+            CandleType.from_string(candle_type)
+            if candle_type != ""
+            else self._config["candle_type_def"]
+        )
         saved_pair: PairWithTimeframe = (pair, str(timeframe), _candle_type)
         if saved_pair not in self.__cached_pairs_backtesting:
-            timerange = TimeRange.parse_timerange(None if self._config.get(
-                'timerange') is None else str(self._config.get('timerange')))
+            timerange = TimeRange.parse_timerange(
+                None
+                if self._config.get("timerange") is None
+                else str(self._config.get("timerange"))
+            )
 
             startup_candles = self.get_required_startup(str(timeframe))
             tf_seconds = timeframe_to_seconds(str(timeframe))
             timerange.subtract_start(tf_seconds * startup_candles)
 
-            logger.info(f"Loading data for {pair} {timeframe} "
-                        f"from {timerange.start_fmt} to {timerange.stop_fmt}")
+            logger.info(
+                f"Loading data for {pair} {timeframe} "
+                f"from {timerange.start_fmt} to {timerange.stop_fmt}"
+            )
 
             self.__cached_pairs_backtesting[saved_pair] = load_pair_history(
                 pair=pair,
                 timeframe=timeframe,
-                datadir=self._config['datadir'],
+                datadir=self._config["datadir"],
                 timerange=timerange,
-                data_format=self._config['dataformat_ohlcv'],
+                data_format=self._config["dataformat_ohlcv"],
                 candle_type=_candle_type,
-
             )
         return self.__cached_pairs_backtesting[saved_pair].copy()
 
     def get_required_startup(self, timeframe: str) -> int:
-        freqai_config = self._config.get('freqai', {})
-        if not freqai_config.get('enabled', False):
-            return self._config.get('startup_candle_count', 0)
+        freqai_config = self._config.get("freqai", {})
+        if not freqai_config.get("enabled", False):
+            return self._config.get("startup_candle_count", 0)
         else:
-            startup_candles = self._config.get('startup_candle_count', 0)
-            indicator_periods = freqai_config['feature_parameters']['indicator_periods_candles']
+            startup_candles = self._config.get("startup_candle_count", 0)
+            indicator_periods = freqai_config["feature_parameters"]["indicator_periods_candles"]
             # make sure the startupcandles is at least the set maximum indicator periods
-            self._config['startup_candle_count'] = max(startup_candles, max(indicator_periods))
+            self._config["startup_candle_count"] = max(startup_candles, max(indicator_periods))
             tf_seconds = timeframe_to_seconds(timeframe)
-            train_candles = freqai_config['train_period_days'] * 86400 / tf_seconds
-            total_candles = int(self._config['startup_candle_count'] + train_candles)
+            train_candles = freqai_config["train_period_days"] * 86400 / tf_seconds
+            total_candles = int(self._config["startup_candle_count"] + train_candles)
             logger.info(
-                f'Increasing startup_candle_count for freqai on {timeframe} to {total_candles}')
+                f"Increasing startup_candle_count for freqai on {timeframe} to {total_candles}"
+            )
         return total_candles
 
     def get_pair_dataframe(
-        self,
-        pair: str,
-        timeframe: Optional[str] = None,
-        candle_type: str = ''
+        self, pair: str, timeframe: Optional[str] = None, candle_type: str = ""
     ) -> DataFrame:
         """
         Return pair candle (OHLCV) data, either live or cached historical -- depending
         on the runmode.
         Only combinations in the pairlist or which have been specified as informative pairs
         will be available.
         :param pair: pair to get the data for
@@ -362,55 +362,55 @@
         :param candle_type: '', mark, index, premiumIndex, or funding_rate
         """
         if self.runmode in (RunMode.DRY_RUN, RunMode.LIVE):
             # Get live OHLCV data.
             data = self.ohlcv(pair=pair, timeframe=timeframe, candle_type=candle_type)
         else:
             # Get historical OHLCV data (cached on disk).
-            timeframe = timeframe or self._config['timeframe']
+            timeframe = timeframe or self._config["timeframe"]
             data = self.historic_ohlcv(pair=pair, timeframe=timeframe, candle_type=candle_type)
             # Cut date to timeframe-specific date.
             # This is necessary to prevent lookahead bias in callbacks through informative pairs.
             if self.__slice_date:
                 cutoff_date = timeframe_to_prev_date(timeframe, self.__slice_date)
-                data = data.loc[data['date'] < cutoff_date]
+                data = data.loc[data["date"] < cutoff_date]
         if len(data) == 0:
             logger.warning(f"No data found for ({pair}, {timeframe}, {candle_type}).")
         return data
 
     def get_analyzed_dataframe(self, pair: str, timeframe: str) -> Tuple[DataFrame, datetime]:
         """
         Retrieve the analyzed dataframe. Returns the full dataframe in trade mode (live / dry),
         and the last 1000 candles (up to the time evaluated at this moment) in all other modes.
         :param pair: pair to get the data for
         :param timeframe: timeframe to get data for
         :return: Tuple of (Analyzed Dataframe, lastrefreshed) for the requested pair / timeframe
             combination.
             Returns empty dataframe and Epoch 0 (1970-01-01) if no dataframe was cached.
         """
-        pair_key = (pair, timeframe, self._config.get('candle_type_def', CandleType.SPOT))
+        pair_key = (pair, timeframe, self._config.get("candle_type_def", CandleType.SPOT))
         if pair_key in self.__cached_pairs:
             if self.runmode in (RunMode.DRY_RUN, RunMode.LIVE):
                 df, date = self.__cached_pairs[pair_key]
             else:
                 df, date = self.__cached_pairs[pair_key]
                 if self.__slice_index is not None:
                     max_index = self.__slice_index
-                    df = df.iloc[max(0, max_index - MAX_DATAFRAME_CANDLES):max_index]
+                    df = df.iloc[max(0, max_index - MAX_DATAFRAME_CANDLES) : max_index]
             return df, date
         else:
             return (DataFrame(), datetime.fromtimestamp(0, tz=timezone.utc))
 
     @property
     def runmode(self) -> RunMode:
         """
         Get runmode of the bot
         can be "live", "dry-run", "backtest", "edgecli", "hyperopt" or "other".
         """
-        return RunMode(self._config.get('runmode', RunMode.OTHER))
+        return RunMode(self._config.get("runmode", RunMode.OTHER))
 
     def current_whitelist(self) -> List[str]:
         """
         fetch latest available whitelist.
 
         Useful when you have a large whitelist and need to call each pair as an informative pair.
         As available pairs does not show whitelist until after informative pairs have been cached.
@@ -430,17 +430,19 @@
         # Don't reset backtesting pairs -
         # otherwise they're reloaded each time during hyperopt due to with analyze_per_epoch
         # self.__cached_pairs_backtesting = {}
         self.__slice_index = 0
 
     # Exchange functions
 
-    def refresh(self,
-                pairlist: ListPairsWithTimeframes,
-                helping_pairs: Optional[ListPairsWithTimeframes] = None) -> None:
+    def refresh(
+        self,
+        pairlist: ListPairsWithTimeframes,
+        helping_pairs: Optional[ListPairsWithTimeframes] = None,
+    ) -> None:
         """
         Refresh data, called with each cycle
         """
         if self._exchange is None:
             raise OperationalException(NO_EXCHANGE_EXCEPTION)
         final_pairs = (pairlist + helping_pairs) if helping_pairs else pairlist
         self._exchange.refresh_latest_ohlcv(final_pairs)
@@ -452,37 +454,35 @@
         Should be whitelist + open trades.
         """
         if self._exchange is None:
             raise OperationalException(NO_EXCHANGE_EXCEPTION)
         return list(self._exchange._klines.keys())
 
     def ohlcv(
-        self,
-        pair: str,
-        timeframe: Optional[str] = None,
-        copy: bool = True,
-        candle_type: str = ''
+        self, pair: str, timeframe: Optional[str] = None, copy: bool = True, candle_type: str = ""
     ) -> DataFrame:
         """
         Get candle (OHLCV) data for the given pair as DataFrame
         Please use the `available_pairs` method to verify which pairs are currently cached.
         :param pair: pair to get the data for
         :param timeframe: Timeframe to get data for
         :param candle_type: '', mark, index, premiumIndex, or funding_rate
         :param copy: copy dataframe before returning if True.
                      Use False only for read-only operations (where the dataframe is not modified)
         """
         if self._exchange is None:
             raise OperationalException(NO_EXCHANGE_EXCEPTION)
         if self.runmode in (RunMode.DRY_RUN, RunMode.LIVE):
-            _candle_type = CandleType.from_string(
-                candle_type) if candle_type != '' else self._config['candle_type_def']
+            _candle_type = (
+                CandleType.from_string(candle_type)
+                if candle_type != ""
+                else self._config["candle_type_def"]
+            )
             return self._exchange.klines(
-                (pair, timeframe or self._config['timeframe'], _candle_type),
-                copy=copy
+                (pair, timeframe or self._config["timeframe"], _candle_type), copy=copy
             )
         else:
             return DataFrame()
 
     def market(self, pair: str) -> Optional[Dict[str, Any]]:
         """
         Return market data for the pair
```

### Comparing `freqtrade-2024.4/freqtrade/data/entryexitanalysis.py` & `freqtrade-2024.5/freqtrade/data/entryexitanalysis.py`

 * *Files 11% similar despite different names*

```diff
@@ -4,27 +4,31 @@
 
 import joblib
 import pandas as pd
 from tabulate import tabulate
 
 from freqtrade.configuration import TimeRange
 from freqtrade.constants import Config
-from freqtrade.data.btanalysis import (get_latest_backtest_filename, load_backtest_data,
-                                       load_backtest_stats)
+from freqtrade.data.btanalysis import (
+    get_latest_backtest_filename,
+    load_backtest_data,
+    load_backtest_stats,
+)
 from freqtrade.exceptions import OperationalException
 
 
 logger = logging.getLogger(__name__)
 
 
 def _load_backtest_analysis_data(backtest_dir: Path, name: str):
     if backtest_dir.is_dir():
-        scpf = Path(backtest_dir,
-                    Path(get_latest_backtest_filename(backtest_dir)).stem + "_" + name + ".pkl"
-                    )
+        scpf = Path(
+            backtest_dir,
+            Path(get_latest_backtest_filename(backtest_dir)).stem + "_" + name + ".pkl",
+        )
     else:
         scpf = Path(backtest_dir.parent / f"{backtest_dir.stem}_{name}.pkl")
 
     try:
         with scpf.open("rb") as scp:
             loaded_data = joblib.load(scp)
             logger.info(f"Loaded {name} candles: {str(scpf)}")
@@ -49,284 +53,318 @@
 
     try:
         logger.info(f"Processing {strategy_name} : {len(pairlist)} pairs")
 
         for pair in pairlist:
             if pair in signal_candles[strategy_name]:
                 analysed_trades_dict[strategy_name][pair] = _analyze_candles_and_indicators(
-                    pair, trades, signal_candles[strategy_name][pair])
+                    pair, trades, signal_candles[strategy_name][pair]
+                )
     except Exception as e:
         print(f"Cannot process entry/exit reasons for {strategy_name}: ", e)
 
     return analysed_trades_dict
 
 
 def _analyze_candles_and_indicators(pair, trades: pd.DataFrame, signal_candles: pd.DataFrame):
     buyf = signal_candles
 
     if len(buyf) > 0:
-        buyf = buyf.set_index('date', drop=False)
-        trades_red = trades.loc[trades['pair'] == pair].copy()
+        buyf = buyf.set_index("date", drop=False)
+        trades_red = trades.loc[trades["pair"] == pair].copy()
 
         trades_inds = pd.DataFrame()
 
         if trades_red.shape[0] > 0 and buyf.shape[0] > 0:
             for t, v in trades_red.open_date.items():
-                allinds = buyf.loc[(buyf['date'] < v)]
+                allinds = buyf.loc[(buyf["date"] < v)]
                 if allinds.shape[0] > 0:
                     tmp_inds = allinds.iloc[[-1]]
 
-                    trades_red.loc[t, 'signal_date'] = tmp_inds['date'].values[0]
-                    trades_red.loc[t, 'enter_reason'] = trades_red.loc[t, 'enter_tag']
-                    tmp_inds.index.rename('signal_date', inplace=True)
+                    trades_red.loc[t, "signal_date"] = tmp_inds["date"].values[0]
+                    trades_red.loc[t, "enter_reason"] = trades_red.loc[t, "enter_tag"]
+                    tmp_inds.index.rename("signal_date", inplace=True)
                     trades_inds = pd.concat([trades_inds, tmp_inds])
 
-            if 'signal_date' in trades_red:
-                trades_red['signal_date'] = pd.to_datetime(trades_red['signal_date'], utc=True)
-                trades_red.set_index('signal_date', inplace=True)
+            if "signal_date" in trades_red:
+                trades_red["signal_date"] = pd.to_datetime(trades_red["signal_date"], utc=True)
+                trades_red.set_index("signal_date", inplace=True)
 
                 try:
-                    trades_red = pd.merge(trades_red, trades_inds, on='signal_date', how='outer')
+                    trades_red = pd.merge(trades_red, trades_inds, on="signal_date", how="outer")
                 except Exception as e:
                     raise e
         return trades_red
     else:
         return pd.DataFrame()
 
 
-def _do_group_table_output(bigdf, glist, csv_path: Path, to_csv=False, ):
+def _do_group_table_output(
+    bigdf,
+    glist,
+    csv_path: Path,
+    to_csv=False,
+):
     for g in glist:
         # 0: summary wins/losses grouped by enter tag
         if g == "0":
-            group_mask = ['enter_reason']
-            wins = bigdf.loc[bigdf['profit_abs'] >= 0] \
-                        .groupby(group_mask) \
-                        .agg({'profit_abs': ['sum']})
-
-            wins.columns = ['profit_abs_wins']
-            loss = bigdf.loc[bigdf['profit_abs'] < 0] \
-                        .groupby(group_mask) \
-                        .agg({'profit_abs': ['sum']})
-            loss.columns = ['profit_abs_loss']
-
-            new = bigdf.groupby(group_mask).agg({'profit_abs': [
-                                                    'count',
-                                                    lambda x: sum(x > 0),
-                                                    lambda x: sum(x <= 0)]})
+            group_mask = ["enter_reason"]
+            wins = (
+                bigdf.loc[bigdf["profit_abs"] >= 0].groupby(group_mask).agg({"profit_abs": ["sum"]})
+            )
+
+            wins.columns = ["profit_abs_wins"]
+            loss = (
+                bigdf.loc[bigdf["profit_abs"] < 0].groupby(group_mask).agg({"profit_abs": ["sum"]})
+            )
+            loss.columns = ["profit_abs_loss"]
+
+            new = bigdf.groupby(group_mask).agg(
+                {"profit_abs": ["count", lambda x: sum(x > 0), lambda x: sum(x <= 0)]}
+            )
             new = pd.concat([new, wins, loss], axis=1).fillna(0)
 
-            new['profit_tot'] = new['profit_abs_wins'] - abs(new['profit_abs_loss'])
-            new['wl_ratio_pct'] = (new.iloc[:, 1] / new.iloc[:, 0] * 100).fillna(0)
-            new['avg_win'] = (new['profit_abs_wins'] / new.iloc[:, 1]).fillna(0)
-            new['avg_loss'] = (new['profit_abs_loss'] / new.iloc[:, 2]).fillna(0)
-
-            new['exp_ratio'] = (
-                (
-                    (1 + (new['avg_win'] / abs(new['avg_loss']))) * (new['wl_ratio_pct'] / 100)
-                ) - 1).fillna(0)
-
-            new.columns = ['total_num_buys', 'wins', 'losses',
-                           'profit_abs_wins', 'profit_abs_loss',
-                           'profit_tot', 'wl_ratio_pct',
-                           'avg_win', 'avg_loss', 'exp_ratio']
+            new["profit_tot"] = new["profit_abs_wins"] - abs(new["profit_abs_loss"])
+            new["wl_ratio_pct"] = (new.iloc[:, 1] / new.iloc[:, 0] * 100).fillna(0)
+            new["avg_win"] = (new["profit_abs_wins"] / new.iloc[:, 1]).fillna(0)
+            new["avg_loss"] = (new["profit_abs_loss"] / new.iloc[:, 2]).fillna(0)
+
+            new["exp_ratio"] = (
+                ((1 + (new["avg_win"] / abs(new["avg_loss"]))) * (new["wl_ratio_pct"] / 100)) - 1
+            ).fillna(0)
+
+            new.columns = [
+                "total_num_buys",
+                "wins",
+                "losses",
+                "profit_abs_wins",
+                "profit_abs_loss",
+                "profit_tot",
+                "wl_ratio_pct",
+                "avg_win",
+                "avg_loss",
+                "exp_ratio",
+            ]
 
-            sortcols = ['total_num_buys']
+            sortcols = ["total_num_buys"]
 
-            _print_table(new, sortcols, show_index=True, name="Group 0:",
-                         to_csv=to_csv, csv_path=csv_path)
+            _print_table(
+                new, sortcols, show_index=True, name="Group 0:", to_csv=to_csv, csv_path=csv_path
+            )
 
         else:
-            agg_mask = {'profit_abs': ['count', 'sum', 'median', 'mean'],
-                        'profit_ratio': ['median', 'mean', 'sum']}
-            agg_cols = ['num_buys', 'profit_abs_sum', 'profit_abs_median',
-                        'profit_abs_mean', 'median_profit_pct', 'mean_profit_pct',
-                        'total_profit_pct']
-            sortcols = ['profit_abs_sum', 'enter_reason']
+            agg_mask = {
+                "profit_abs": ["count", "sum", "median", "mean"],
+                "profit_ratio": ["median", "mean", "sum"],
+            }
+            agg_cols = [
+                "num_buys",
+                "profit_abs_sum",
+                "profit_abs_median",
+                "profit_abs_mean",
+                "median_profit_pct",
+                "mean_profit_pct",
+                "total_profit_pct",
+            ]
+            sortcols = ["profit_abs_sum", "enter_reason"]
 
             # 1: profit summaries grouped by enter_tag
             if g == "1":
-                group_mask = ['enter_reason']
+                group_mask = ["enter_reason"]
 
             # 2: profit summaries grouped by enter_tag and exit_tag
             if g == "2":
-                group_mask = ['enter_reason', 'exit_reason']
+                group_mask = ["enter_reason", "exit_reason"]
 
             # 3: profit summaries grouped by pair and enter_tag
             if g == "3":
-                group_mask = ['pair', 'enter_reason']
+                group_mask = ["pair", "enter_reason"]
 
             # 4: profit summaries grouped by pair, enter_ and exit_tag (this can get quite large)
             if g == "4":
-                group_mask = ['pair', 'enter_reason', 'exit_reason']
+                group_mask = ["pair", "enter_reason", "exit_reason"]
 
             # 5: profit summaries grouped by exit_tag
             if g == "5":
-                group_mask = ['exit_reason']
-                sortcols = ['exit_reason']
+                group_mask = ["exit_reason"]
+                sortcols = ["exit_reason"]
 
             if group_mask:
                 new = bigdf.groupby(group_mask).agg(agg_mask).reset_index()
                 new.columns = group_mask + agg_cols
-                new['median_profit_pct'] = new['median_profit_pct'] * 100
-                new['mean_profit_pct'] = new['mean_profit_pct'] * 100
-                new['total_profit_pct'] = new['total_profit_pct'] * 100
+                new["median_profit_pct"] = new["median_profit_pct"] * 100
+                new["mean_profit_pct"] = new["mean_profit_pct"] * 100
+                new["total_profit_pct"] = new["total_profit_pct"] * 100
 
-                _print_table(new, sortcols, name=f"Group {g}:",
-                             to_csv=to_csv, csv_path=csv_path)
+                _print_table(new, sortcols, name=f"Group {g}:", to_csv=to_csv, csv_path=csv_path)
             else:
                 logger.warning("Invalid group mask specified.")
 
 
-def _do_rejected_signals_output(rejected_signals_df: pd.DataFrame,
-                                to_csv: bool = False, csv_path=None) -> None:
-    cols = ['pair', 'date', 'enter_tag']
-    sortcols = ['date', 'pair', 'enter_tag']
-    _print_table(rejected_signals_df[cols],
-                 sortcols,
-                 show_index=False,
-                 name="Rejected Signals:",
-                 to_csv=to_csv,
-                 csv_path=csv_path)
+def _do_rejected_signals_output(
+    rejected_signals_df: pd.DataFrame, to_csv: bool = False, csv_path=None
+) -> None:
+    cols = ["pair", "date", "enter_tag"]
+    sortcols = ["date", "pair", "enter_tag"]
+    _print_table(
+        rejected_signals_df[cols],
+        sortcols,
+        show_index=False,
+        name="Rejected Signals:",
+        to_csv=to_csv,
+        csv_path=csv_path,
+    )
 
 
-def _select_rows_within_dates(df, timerange=None, df_date_col: str = 'date'):
+def _select_rows_within_dates(df, timerange=None, df_date_col: str = "date"):
     if timerange:
-        if timerange.starttype == 'date':
+        if timerange.starttype == "date":
             df = df.loc[(df[df_date_col] >= timerange.startdt)]
-        if timerange.stoptype == 'date':
+        if timerange.stoptype == "date":
             df = df.loc[(df[df_date_col] < timerange.stopdt)]
     return df
 
 
 def _select_rows_by_tags(df, enter_reason_list, exit_reason_list):
     if enter_reason_list and "all" not in enter_reason_list:
-        df = df.loc[(df['enter_reason'].isin(enter_reason_list))]
+        df = df.loc[(df["enter_reason"].isin(enter_reason_list))]
 
     if exit_reason_list and "all" not in exit_reason_list:
-        df = df.loc[(df['exit_reason'].isin(exit_reason_list))]
+        df = df.loc[(df["exit_reason"].isin(exit_reason_list))]
     return df
 
 
-def prepare_results(analysed_trades, stratname,
-                    enter_reason_list, exit_reason_list,
-                    timerange=None):
+def prepare_results(
+    analysed_trades, stratname, enter_reason_list, exit_reason_list, timerange=None
+):
     res_df = pd.DataFrame()
     for pair, trades in analysed_trades[stratname].items():
-        if (trades.shape[0] > 0):
-            trades.dropna(subset=['close_date'], inplace=True)
+        if trades.shape[0] > 0:
+            trades.dropna(subset=["close_date"], inplace=True)
             res_df = pd.concat([res_df, trades], ignore_index=True)
 
     res_df = _select_rows_within_dates(res_df, timerange)
 
-    if res_df is not None and res_df.shape[0] > 0 and ('enter_reason' in res_df.columns):
+    if res_df is not None and res_df.shape[0] > 0 and ("enter_reason" in res_df.columns):
         res_df = _select_rows_by_tags(res_df, enter_reason_list, exit_reason_list)
 
     return res_df
 
 
-def print_results(res_df: pd.DataFrame, analysis_groups: List[str], indicator_list: List[str],
-                  csv_path: Path, rejected_signals=None, to_csv=False):
+def print_results(
+    res_df: pd.DataFrame,
+    analysis_groups: List[str],
+    indicator_list: List[str],
+    csv_path: Path,
+    rejected_signals=None,
+    to_csv=False,
+):
     if res_df.shape[0] > 0:
         if analysis_groups:
             _do_group_table_output(res_df, analysis_groups, to_csv=to_csv, csv_path=csv_path)
 
         if rejected_signals is not None:
             if rejected_signals.empty:
                 print("There were no rejected signals.")
             else:
                 _do_rejected_signals_output(rejected_signals, to_csv=to_csv, csv_path=csv_path)
 
         # NB this can be large for big dataframes!
         if "all" in indicator_list:
-            _print_table(res_df,
-                         show_index=False,
-                         name="Indicators:",
-                         to_csv=to_csv,
-                         csv_path=csv_path)
+            _print_table(
+                res_df, show_index=False, name="Indicators:", to_csv=to_csv, csv_path=csv_path
+            )
         elif indicator_list is not None and indicator_list:
             available_inds = []
             for ind in indicator_list:
                 if ind in res_df:
                     available_inds.append(ind)
             ilist = ["pair", "enter_reason", "exit_reason"] + available_inds
-            _print_table(res_df[ilist],
-                         sortcols=['exit_reason'],
-                         show_index=False,
-                         name="Indicators:",
-                         to_csv=to_csv,
-                         csv_path=csv_path)
+            _print_table(
+                res_df[ilist],
+                sortcols=["exit_reason"],
+                show_index=False,
+                name="Indicators:",
+                to_csv=to_csv,
+                csv_path=csv_path,
+            )
     else:
         print("\\No trades to show")
 
 
-def _print_table(df: pd.DataFrame, sortcols=None, *, show_index=False, name=None,
-                 to_csv=False, csv_path: Path):
-    if (sortcols is not None):
+def _print_table(
+    df: pd.DataFrame, sortcols=None, *, show_index=False, name=None, to_csv=False, csv_path: Path
+):
+    if sortcols is not None:
         data = df.sort_values(sortcols)
     else:
         data = df
 
     if to_csv:
         safe_name = Path(csv_path, name.lower().replace(" ", "_").replace(":", "") + ".csv")
         data.to_csv(safe_name)
         print(f"Saved {name} to {safe_name}")
     else:
         if name is not None:
             print(name)
 
-        print(
-            tabulate(
-                data,
-                headers='keys',
-                tablefmt='psql',
-                showindex=show_index
-            )
-        )
+        print(tabulate(data, headers="keys", tablefmt="psql", showindex=show_index))
 
 
 def process_entry_exit_reasons(config: Config):
     try:
-        analysis_groups = config.get('analysis_groups', [])
-        enter_reason_list = config.get('enter_reason_list', ["all"])
-        exit_reason_list = config.get('exit_reason_list', ["all"])
-        indicator_list = config.get('indicator_list', [])
-        do_rejected = config.get('analysis_rejected', False)
-        to_csv = config.get('analysis_to_csv', False)
-        csv_path = Path(config.get('analysis_csv_path', config['exportfilename']))
+        analysis_groups = config.get("analysis_groups", [])
+        enter_reason_list = config.get("enter_reason_list", ["all"])
+        exit_reason_list = config.get("exit_reason_list", ["all"])
+        indicator_list = config.get("indicator_list", [])
+        do_rejected = config.get("analysis_rejected", False)
+        to_csv = config.get("analysis_to_csv", False)
+        csv_path = Path(config.get("analysis_csv_path", config["exportfilename"]))
         if to_csv and not csv_path.is_dir():
             raise OperationalException(f"Specified directory {csv_path} does not exist.")
 
-        timerange = TimeRange.parse_timerange(None if config.get(
-            'timerange') is None else str(config.get('timerange')))
+        timerange = TimeRange.parse_timerange(
+            None if config.get("timerange") is None else str(config.get("timerange"))
+        )
 
-        backtest_stats = load_backtest_stats(config['exportfilename'])
+        backtest_stats = load_backtest_stats(config["exportfilename"])
 
-        for strategy_name, results in backtest_stats['strategy'].items():
-            trades = load_backtest_data(config['exportfilename'], strategy_name)
+        for strategy_name, results in backtest_stats["strategy"].items():
+            trades = load_backtest_data(config["exportfilename"], strategy_name)
 
             if trades is not None and not trades.empty:
-                signal_candles = _load_signal_candles(config['exportfilename'])
+                signal_candles = _load_signal_candles(config["exportfilename"])
 
                 rej_df = None
                 if do_rejected:
-                    rejected_signals_dict = _load_rejected_signals(config['exportfilename'])
-                    rej_df = prepare_results(rejected_signals_dict, strategy_name,
-                                             enter_reason_list, exit_reason_list,
-                                             timerange=timerange)
+                    rejected_signals_dict = _load_rejected_signals(config["exportfilename"])
+                    rej_df = prepare_results(
+                        rejected_signals_dict,
+                        strategy_name,
+                        enter_reason_list,
+                        exit_reason_list,
+                        timerange=timerange,
+                    )
 
                 analysed_trades_dict = _process_candles_and_indicators(
-                                        config['exchange']['pair_whitelist'], strategy_name,
-                                        trades, signal_candles)
+                    config["exchange"]["pair_whitelist"], strategy_name, trades, signal_candles
+                )
 
-                res_df = prepare_results(analysed_trades_dict, strategy_name,
-                                         enter_reason_list, exit_reason_list,
-                                         timerange=timerange)
-
-                print_results(res_df,
-                              analysis_groups,
-                              indicator_list,
-                              rejected_signals=rej_df,
-                              to_csv=to_csv,
-                              csv_path=csv_path)
+                res_df = prepare_results(
+                    analysed_trades_dict,
+                    strategy_name,
+                    enter_reason_list,
+                    exit_reason_list,
+                    timerange=timerange,
+                )
+
+                print_results(
+                    res_df,
+                    analysis_groups,
+                    indicator_list,
+                    rejected_signals=rej_df,
+                    to_csv=to_csv,
+                    csv_path=csv_path,
+                )
 
     except ValueError as e:
         raise OperationalException(e) from e
```

### Comparing `freqtrade-2024.4/freqtrade/data/history/datahandlers/featherdatahandler.py` & `freqtrade-2024.5/freqtrade/data/history/datahandlers/featherdatahandler.py`

 * *Files 7% similar despite different names*

```diff
@@ -10,72 +10,76 @@
 from .idatahandler import IDataHandler
 
 
 logger = logging.getLogger(__name__)
 
 
 class FeatherDataHandler(IDataHandler):
-
     _columns = DEFAULT_DATAFRAME_COLUMNS
 
     def ohlcv_store(
-            self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType) -> None:
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
+    ) -> None:
         """
         Store data in json format "values".
             format looks as follows:
             [[<date>,<open>,<high>,<low>,<close>]]
         :param pair: Pair - used to generate filename
         :param timeframe: Timeframe - used to generate filename
         :param data: Dataframe containing OHLCV data
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: None
         """
         filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type)
         self.create_dir_if_needed(filename)
 
         data.reset_index(drop=True).loc[:, self._columns].to_feather(
-            filename, compression_level=9, compression='lz4')
+            filename, compression_level=9, compression="lz4"
+        )
 
-    def _ohlcv_load(self, pair: str, timeframe: str,
-                    timerange: Optional[TimeRange], candle_type: CandleType
-                    ) -> DataFrame:
+    def _ohlcv_load(
+        self, pair: str, timeframe: str, timerange: Optional[TimeRange], candle_type: CandleType
+    ) -> DataFrame:
         """
         Internal method used to load data for one pair from disk.
         Implements the loading and conversion to a Pandas dataframe.
         Timerange trimming and dataframe validation happens outside of this method.
         :param pair: Pair to load data
         :param timeframe: Timeframe (e.g. "5m")
         :param timerange: Limit data to be loaded to this timerange.
                         Optionally implemented by subclasses to avoid loading
                         all data where possible.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: DataFrame with ohlcv data, or empty DataFrame
         """
-        filename = self._pair_data_filename(
-            self._datadir, pair, timeframe, candle_type=candle_type)
+        filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type=candle_type)
         if not filename.exists():
             # Fallback mode for 1M files
             filename = self._pair_data_filename(
-                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True)
+                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True
+            )
             if not filename.exists():
                 return DataFrame(columns=self._columns)
 
         pairdata = read_feather(filename)
         pairdata.columns = self._columns
-        pairdata = pairdata.astype(dtype={'open': 'float', 'high': 'float',
-                                          'low': 'float', 'close': 'float', 'volume': 'float'})
-        pairdata['date'] = to_datetime(pairdata['date'], unit='ms', utc=True)
+        pairdata = pairdata.astype(
+            dtype={
+                "open": "float",
+                "high": "float",
+                "low": "float",
+                "close": "float",
+                "volume": "float",
+            }
+        )
+        pairdata["date"] = to_datetime(pairdata["date"], unit="ms", utc=True)
         return pairdata
 
     def ohlcv_append(
-        self,
-        pair: str,
-        timeframe: str,
-        data: DataFrame,
-        candle_type: CandleType
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
     ) -> None:
         """
         Append data to existing data structures
         :param pair: Pair
         :param timeframe: Timeframe this ohlcv data is for
         :param data: Data to append.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
@@ -88,27 +92,27 @@
         :param pair: Pair - used for filename
         :param data: Dataframe containing trades
                      column sequence as in DEFAULT_TRADES_COLUMNS
         :param trading_mode: Trading mode to use (used to determine the filename)
         """
         filename = self._pair_trades_filename(self._datadir, pair, trading_mode)
         self.create_dir_if_needed(filename)
-        data.reset_index(drop=True).to_feather(filename, compression_level=9, compression='lz4')
+        data.reset_index(drop=True).to_feather(filename, compression_level=9, compression="lz4")
 
     def trades_append(self, pair: str, data: DataFrame):
         """
         Append data to existing files
         :param pair: Pair - used for filename
         :param data: Dataframe containing trades
                      column sequence as in DEFAULT_TRADES_COLUMNS
         """
         raise NotImplementedError()
 
     def _trades_load(
-            self, pair: str, trading_mode: TradingMode, timerange: Optional[TimeRange] = None
+        self, pair: str, trading_mode: TradingMode, timerange: Optional[TimeRange] = None
     ) -> DataFrame:
         """
         Load a pair from file, either .json.gz or .json
         # TODO: respect timerange ...
         :param pair: Load trades for this pair
         :param trading_mode: Trading mode to use (used to determine the filename)
         :param timerange: Timerange to load trades for - currently not implemented
```

### Comparing `freqtrade-2024.4/freqtrade/data/history/datahandlers/hdf5datahandler.py` & `freqtrade-2024.5/freqtrade/data/history/datahandlers/hdf5datahandler.py`

 * *Files 5% similar despite different names*

```diff
@@ -11,19 +11,19 @@
 from .idatahandler import IDataHandler
 
 
 logger = logging.getLogger(__name__)
 
 
 class HDF5DataHandler(IDataHandler):
-
     _columns = DEFAULT_DATAFRAME_COLUMNS
 
     def ohlcv_store(
-            self, pair: str, timeframe: str, data: pd.DataFrame, candle_type: CandleType) -> None:
+        self, pair: str, timeframe: str, data: pd.DataFrame, candle_type: CandleType
+    ) -> None:
         """
         Store data in hdf5 file.
         :param pair: Pair - used to generate filename
         :param timeframe: Timeframe - used to generate filename
         :param data: Dataframe containing OHLCV data
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: None
@@ -31,69 +31,73 @@
         key = self._pair_ohlcv_key(pair, timeframe)
         _data = data.copy()
 
         filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type)
         self.create_dir_if_needed(filename)
 
         _data.loc[:, self._columns].to_hdf(
-            filename, key=key, mode='a', complevel=9, complib='blosc',
-            format='table', data_columns=['date']
+            filename,
+            key=key,
+            mode="a",
+            complevel=9,
+            complib="blosc",
+            format="table",
+            data_columns=["date"],
         )
 
-    def _ohlcv_load(self, pair: str, timeframe: str,
-                    timerange: Optional[TimeRange], candle_type: CandleType
-                    ) -> pd.DataFrame:
+    def _ohlcv_load(
+        self, pair: str, timeframe: str, timerange: Optional[TimeRange], candle_type: CandleType
+    ) -> pd.DataFrame:
         """
         Internal method used to load data for one pair from disk.
         Implements the loading and conversion to a Pandas dataframe.
         Timerange trimming and dataframe validation happens outside of this method.
         :param pair: Pair to load data
         :param timeframe: Timeframe (e.g. "5m")
         :param timerange: Limit data to be loaded to this timerange.
                         Optionally implemented by subclasses to avoid loading
                         all data where possible.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: DataFrame with ohlcv data, or empty DataFrame
         """
         key = self._pair_ohlcv_key(pair, timeframe)
-        filename = self._pair_data_filename(
-            self._datadir,
-            pair,
-            timeframe,
-            candle_type=candle_type
-        )
+        filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type=candle_type)
 
         if not filename.exists():
             # Fallback mode for 1M files
             filename = self._pair_data_filename(
-                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True)
+                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True
+            )
             if not filename.exists():
                 return pd.DataFrame(columns=self._columns)
         where = []
         if timerange:
-            if timerange.starttype == 'date':
+            if timerange.starttype == "date":
                 where.append(f"date >= Timestamp({timerange.startts * 1e9})")
-            if timerange.stoptype == 'date':
+            if timerange.stoptype == "date":
                 where.append(f"date <= Timestamp({timerange.stopts * 1e9})")
 
         pairdata = pd.read_hdf(filename, key=key, mode="r", where=where)
 
         if list(pairdata.columns) != self._columns:
             raise ValueError("Wrong dataframe format")
-        pairdata = pairdata.astype(dtype={'open': 'float', 'high': 'float',
-                                          'low': 'float', 'close': 'float', 'volume': 'float'})
+        pairdata = pairdata.astype(
+            dtype={
+                "open": "float",
+                "high": "float",
+                "low": "float",
+                "close": "float",
+                "volume": "float",
+            }
+        )
         pairdata = pairdata.reset_index(drop=True)
         return pairdata
 
     def ohlcv_append(
-        self,
-        pair: str,
-        timeframe: str,
-        data: pd.DataFrame,
-        candle_type: CandleType
+        self, pair: str, timeframe: str, data: pd.DataFrame, candle_type: CandleType
     ) -> None:
         """
         Append data to existing data structures
         :param pair: Pair
         :param timeframe: Timeframe this ohlcv data is for
         :param data: Data to append.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
@@ -107,17 +111,21 @@
         :param data: Dataframe containing trades
                      column sequence as in DEFAULT_TRADES_COLUMNS
         :param trading_mode: Trading mode to use (used to determine the filename)
         """
         key = self._pair_trades_key(pair)
 
         data.to_hdf(
-            self._pair_trades_filename(self._datadir, pair, trading_mode), key=key,
-            mode='a', complevel=9, complib='blosc',
-            format='table', data_columns=['timestamp']
+            self._pair_trades_filename(self._datadir, pair, trading_mode),
+            key=key,
+            mode="a",
+            complevel=9,
+            complib="blosc",
+            format="table",
+            data_columns=["timestamp"],
         )
 
     def trades_append(self, pair: str, data: pd.DataFrame):
         """
         Append data to existing files
         :param pair: Pair - used for filename
         :param data: Dataframe containing trades
@@ -138,29 +146,29 @@
         key = self._pair_trades_key(pair)
         filename = self._pair_trades_filename(self._datadir, pair, trading_mode)
 
         if not filename.exists():
             return pd.DataFrame(columns=DEFAULT_TRADES_COLUMNS)
         where = []
         if timerange:
-            if timerange.starttype == 'date':
+            if timerange.starttype == "date":
                 where.append(f"timestamp >= {timerange.startts * 1e3}")
-            if timerange.stoptype == 'date':
+            if timerange.stoptype == "date":
                 where.append(f"timestamp < {timerange.stopts * 1e3}")
 
         trades: pd.DataFrame = pd.read_hdf(filename, key=key, mode="r", where=where)
-        trades[['id', 'type']] = trades[['id', 'type']].replace({np.nan: None})
+        trades[["id", "type"]] = trades[["id", "type"]].replace({np.nan: None})
         return trades
 
     @classmethod
     def _get_file_extension(cls):
         return "h5"
 
     @classmethod
     def _pair_ohlcv_key(cls, pair: str, timeframe: str) -> str:
         # Escape futures pairs to avoid warnings
-        pair_esc = pair.replace(':', '_')
+        pair_esc = pair.replace(":", "_")
         return f"{pair_esc}/ohlcv/tf_{timeframe}"
 
     @classmethod
     def _pair_trades_key(cls, pair: str) -> str:
         return f"{pair}/trades"
```

### Comparing `freqtrade-2024.4/freqtrade/data/history/datahandlers/idatahandler.py` & `freqtrade-2024.5/freqtrade/data/history/datahandlers/idatahandler.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,124 +1,136 @@
 """
 Abstract datahandler interface.
 It's subclasses handle and storing data from disk.
 
 """
+
 import logging
 import re
 from abc import ABC, abstractmethod
 from copy import deepcopy
 from datetime import datetime, timezone
 from pathlib import Path
 from typing import List, Optional, Tuple, Type
 
 from pandas import DataFrame
 
 from freqtrade import misc
 from freqtrade.configuration import TimeRange
 from freqtrade.constants import DEFAULT_TRADES_COLUMNS, ListPairsWithTimeframes
-from freqtrade.data.converter import (clean_ohlcv_dataframe, trades_convert_types,
-                                      trades_df_remove_duplicates, trim_dataframe)
+from freqtrade.data.converter import (
+    clean_ohlcv_dataframe,
+    trades_convert_types,
+    trades_df_remove_duplicates,
+    trim_dataframe,
+)
 from freqtrade.enums import CandleType, TradingMode
 from freqtrade.exchange import timeframe_to_seconds
 
 
 logger = logging.getLogger(__name__)
 
 
 class IDataHandler(ABC):
-
-    _OHLCV_REGEX = r'^([a-zA-Z_\d-]+)\-(\d+[a-zA-Z]{1,2})\-?([a-zA-Z_]*)?(?=\.)'
+    _OHLCV_REGEX = r"^([a-zA-Z_\d-]+)\-(\d+[a-zA-Z]{1,2})\-?([a-zA-Z_]*)?(?=\.)"
 
     def __init__(self, datadir: Path) -> None:
         self._datadir = datadir
 
     @classmethod
     def _get_file_extension(cls) -> str:
         """
         Get file extension for this particular datahandler
         """
         raise NotImplementedError()
 
     @classmethod
     def ohlcv_get_available_data(
-            cls, datadir: Path, trading_mode: TradingMode) -> ListPairsWithTimeframes:
+        cls, datadir: Path, trading_mode: TradingMode
+    ) -> ListPairsWithTimeframes:
         """
         Returns a list of all pairs with ohlcv data available in this datadir
         :param datadir: Directory to search for ohlcv files
         :param trading_mode: trading-mode to be used
         :return: List of Tuples of (pair, timeframe, CandleType)
         """
         if trading_mode == TradingMode.FUTURES:
-            datadir = datadir.joinpath('futures')
+            datadir = datadir.joinpath("futures")
         _tmp = [
-            re.search(
-                cls._OHLCV_REGEX, p.name
-            ) for p in datadir.glob(f"*.{cls._get_file_extension()}")]
+            re.search(cls._OHLCV_REGEX, p.name)
+            for p in datadir.glob(f"*.{cls._get_file_extension()}")
+        ]
         return [
             (
                 cls.rebuild_pair_from_filename(match[1]),
                 cls.rebuild_timeframe_from_filename(match[2]),
-                CandleType.from_string(match[3])
-            ) for match in _tmp if match and len(match.groups()) > 1]
+                CandleType.from_string(match[3]),
+            )
+            for match in _tmp
+            if match and len(match.groups()) > 1
+        ]
 
     @classmethod
     def ohlcv_get_pairs(cls, datadir: Path, timeframe: str, candle_type: CandleType) -> List[str]:
         """
         Returns a list of all pairs with ohlcv data available in this datadir
         for the specified timeframe
         :param datadir: Directory to search for ohlcv files
         :param timeframe: Timeframe to search pairs for
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: List of Pairs
         """
         candle = ""
         if candle_type != CandleType.SPOT:
-            datadir = datadir.joinpath('futures')
+            datadir = datadir.joinpath("futures")
             candle = f"-{candle_type}"
         ext = cls._get_file_extension()
-        _tmp = [re.search(r'^(\S+)(?=\-' + timeframe + candle + f'.{ext})', p.name)
-                for p in datadir.glob(f"*{timeframe}{candle}.{ext}")]
+        _tmp = [
+            re.search(r"^(\S+)(?=\-" + timeframe + candle + f".{ext})", p.name)
+            for p in datadir.glob(f"*{timeframe}{candle}.{ext}")
+        ]
         # Check if regex found something and only return these results
         return [cls.rebuild_pair_from_filename(match[0]) for match in _tmp if match]
 
     @abstractmethod
     def ohlcv_store(
-            self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType) -> None:
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
+    ) -> None:
         """
         Store ohlcv data.
         :param pair: Pair - used to generate filename
         :param timeframe: Timeframe - used to generate filename
         :param data: Dataframe containing OHLCV data
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: None
         """
 
-    def ohlcv_data_min_max(self, pair: str, timeframe: str,
-                           candle_type: CandleType) -> Tuple[datetime, datetime, int]:
+    def ohlcv_data_min_max(
+        self, pair: str, timeframe: str, candle_type: CandleType
+    ) -> Tuple[datetime, datetime, int]:
         """
         Returns the min and max timestamp for the given pair and timeframe.
         :param pair: Pair to get min/max for
         :param timeframe: Timeframe to get min/max for
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: (min, max, len)
         """
         df = self._ohlcv_load(pair, timeframe, None, candle_type)
         if df.empty:
             return (
                 datetime.fromtimestamp(0, tz=timezone.utc),
                 datetime.fromtimestamp(0, tz=timezone.utc),
                 0,
             )
-        return df.iloc[0]['date'].to_pydatetime(), df.iloc[-1]['date'].to_pydatetime(), len(df)
+        return df.iloc[0]["date"].to_pydatetime(), df.iloc[-1]["date"].to_pydatetime(), len(df)
 
     @abstractmethod
-    def _ohlcv_load(self, pair: str, timeframe: str, timerange: Optional[TimeRange],
-                    candle_type: CandleType
-                    ) -> DataFrame:
+    def _ohlcv_load(
+        self, pair: str, timeframe: str, timerange: Optional[TimeRange], candle_type: CandleType
+    ) -> DataFrame:
         """
         Internal method used to load data for one pair from disk.
         Implements the loading and conversion to a Pandas dataframe.
         Timerange trimming and dataframe validation happens outside of this method.
         :param pair: Pair to load data
         :param timeframe: Timeframe (e.g. "5m")
         :param timerange: Limit data to be loaded to this timerange.
@@ -140,19 +152,15 @@
         if filename.exists():
             filename.unlink()
             return True
         return False
 
     @abstractmethod
     def ohlcv_append(
-        self,
-        pair: str,
-        timeframe: str,
-        data: DataFrame,
-        candle_type: CandleType
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
     ) -> None:
         """
         Append data to existing data structures
         :param pair: Pair
         :param timeframe: Timeframe this ohlcv data is for
         :param data: Data to append.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
@@ -162,16 +170,18 @@
     def trades_get_pairs(cls, datadir: Path) -> List[str]:
         """
         Returns a list of all pairs for which trade data is available in this
         :param datadir: Directory to search for ohlcv files
         :return: List of Pairs
         """
         _ext = cls._get_file_extension()
-        _tmp = [re.search(r'^(\S+)(?=\-trades.' + _ext + ')', p.name)
-                for p in datadir.glob(f"*trades.{_ext}")]
+        _tmp = [
+            re.search(r"^(\S+)(?=\-trades." + _ext + ")", p.name)
+            for p in datadir.glob(f"*trades.{_ext}")
+        ]
         # Check if regex found something and only return these results to avoid exceptions.
         return [cls.rebuild_pair_from_filename(match[0]) for match in _tmp if match]
 
     @abstractmethod
     def _trades_store(self, pair: str, data: DataFrame, trading_mode: TradingMode) -> None:
         """
         Store trades data (list of Dicts) to file
@@ -223,15 +233,15 @@
         filename = self._pair_trades_filename(self._datadir, pair, trading_mode)
         if filename.exists():
             filename.unlink()
             return True
         return False
 
     def trades_load(
-            self, pair: str, trading_mode: TradingMode, timerange: Optional[TimeRange] = None
+        self, pair: str, trading_mode: TradingMode, timerange: Optional[TimeRange] = None
     ) -> DataFrame:
         """
         Load a pair from file, either .json.gz or .json
         Removes duplicates in the process.
         :param pair: Load trades for this pair
         :param trading_mode: Trading mode to use (used to determine the filename)
         :param timerange: Timerange to load trades for - currently not implemented
@@ -256,68 +266,71 @@
     @classmethod
     def _pair_data_filename(
         cls,
         datadir: Path,
         pair: str,
         timeframe: str,
         candle_type: CandleType,
-        no_timeframe_modify: bool = False
+        no_timeframe_modify: bool = False,
     ) -> Path:
         pair_s = misc.pair_to_filename(pair)
         candle = ""
         if not no_timeframe_modify:
             timeframe = cls.timeframe_to_file(timeframe)
 
         if candle_type != CandleType.SPOT:
-            datadir = datadir.joinpath('futures')
+            datadir = datadir.joinpath("futures")
             candle = f"-{candle_type}"
-        filename = datadir.joinpath(
-            f'{pair_s}-{timeframe}{candle}.{cls._get_file_extension()}')
+        filename = datadir.joinpath(f"{pair_s}-{timeframe}{candle}.{cls._get_file_extension()}")
         return filename
 
     @classmethod
     def _pair_trades_filename(cls, datadir: Path, pair: str, trading_mode: TradingMode) -> Path:
         pair_s = misc.pair_to_filename(pair)
         if trading_mode == TradingMode.FUTURES:
             # Futures pair ...
-            datadir = datadir.joinpath('futures')
+            datadir = datadir.joinpath("futures")
 
-        filename = datadir.joinpath(f'{pair_s}-trades.{cls._get_file_extension()}')
+        filename = datadir.joinpath(f"{pair_s}-trades.{cls._get_file_extension()}")
         return filename
 
     @staticmethod
     def timeframe_to_file(timeframe: str):
-        return timeframe.replace('M', 'Mo')
+        return timeframe.replace("M", "Mo")
 
     @staticmethod
     def rebuild_timeframe_from_filename(timeframe: str) -> str:
         """
         converts timeframe from disk to file
         Replaces mo with M (to avoid problems on case-insensitive filesystems)
         """
-        return re.sub('1mo', '1M', timeframe, flags=re.IGNORECASE)
+        return re.sub("1mo", "1M", timeframe, flags=re.IGNORECASE)
 
     @staticmethod
     def rebuild_pair_from_filename(pair: str) -> str:
         """
         Rebuild pair name from filename
         Assumes a asset name of max. 7 length to also support BTC-PERP and BTC-PERP:USD names.
         """
-        res = re.sub(r'^(([A-Za-z\d]{1,10})|^([A-Za-z\-]{1,6}))(_)', r'\g<1>/', pair, count=1)
-        res = re.sub('_', ':', res, count=1)
+        res = re.sub(r"^(([A-Za-z\d]{1,10})|^([A-Za-z\-]{1,6}))(_)", r"\g<1>/", pair, count=1)
+        res = re.sub("_", ":", res, count=1)
         return res
 
-    def ohlcv_load(self, pair, timeframe: str,
-                   candle_type: CandleType, *,
-                   timerange: Optional[TimeRange] = None,
-                   fill_missing: bool = True,
-                   drop_incomplete: bool = False,
-                   startup_candles: int = 0,
-                   warn_no_data: bool = True,
-                   ) -> DataFrame:
+    def ohlcv_load(
+        self,
+        pair,
+        timeframe: str,
+        candle_type: CandleType,
+        *,
+        timerange: Optional[TimeRange] = None,
+        fill_missing: bool = True,
+        drop_incomplete: bool = False,
+        startup_candles: int = 0,
+        warn_no_data: bool = True,
+    ) -> DataFrame:
         """
         Load cached candle (OHLCV) data for the given pair.
 
         :param pair: Pair to load data for
         :param timeframe: Timeframe (e.g. "5m")
         :param timerange: Limit data to be loaded to this timerange
         :param fill_missing: Fill missing values with "No action"-candles
@@ -329,87 +342,108 @@
         """
         # Fix startup period
         timerange_startup = deepcopy(timerange)
         if startup_candles > 0 and timerange_startup:
             timerange_startup.subtract_start(timeframe_to_seconds(timeframe) * startup_candles)
 
         pairdf = self._ohlcv_load(
-            pair,
-            timeframe,
-            timerange=timerange_startup,
-            candle_type=candle_type
+            pair, timeframe, timerange=timerange_startup, candle_type=candle_type
         )
         if self._check_empty_df(pairdf, pair, timeframe, candle_type, warn_no_data):
             return pairdf
         else:
-            enddate = pairdf.iloc[-1]['date']
+            enddate = pairdf.iloc[-1]["date"]
 
             if timerange_startup:
                 self._validate_pairdata(pair, pairdf, timeframe, candle_type, timerange_startup)
                 pairdf = trim_dataframe(pairdf, timerange_startup)
                 if self._check_empty_df(pairdf, pair, timeframe, candle_type, warn_no_data, True):
                     return pairdf
 
             # incomplete candles should only be dropped if we didn't trim the end beforehand.
-            pairdf = clean_ohlcv_dataframe(pairdf, timeframe,
-                                           pair=pair,
-                                           fill_missing=fill_missing,
-                                           drop_incomplete=(drop_incomplete and
-                                                            enddate == pairdf.iloc[-1]['date']))
+            pairdf = clean_ohlcv_dataframe(
+                pairdf,
+                timeframe,
+                pair=pair,
+                fill_missing=fill_missing,
+                drop_incomplete=(drop_incomplete and enddate == pairdf.iloc[-1]["date"]),
+            )
             self._check_empty_df(pairdf, pair, timeframe, candle_type, warn_no_data)
             return pairdf
 
     def _check_empty_df(
-            self, pairdf: DataFrame, pair: str, timeframe: str, candle_type: CandleType,
-            warn_no_data: bool, warn_price: bool = False) -> bool:
+        self,
+        pairdf: DataFrame,
+        pair: str,
+        timeframe: str,
+        candle_type: CandleType,
+        warn_no_data: bool,
+        warn_price: bool = False,
+    ) -> bool:
         """
         Warn on empty dataframe
         """
         if pairdf.empty:
             if warn_no_data:
                 logger.warning(
                     f"No history for {pair}, {candle_type}, {timeframe} found. "
                     "Use `freqtrade download-data` to download the data"
                 )
             return True
         elif warn_price:
             candle_price_gap = 0
-            if (candle_type in (CandleType.SPOT, CandleType.FUTURES) and
-                    not pairdf.empty
-                    and 'close' in pairdf.columns and 'open' in pairdf.columns):
+            if (
+                candle_type in (CandleType.SPOT, CandleType.FUTURES)
+                and not pairdf.empty
+                and "close" in pairdf.columns
+                and "open" in pairdf.columns
+            ):
                 # Detect gaps between prior close and open
-                gaps = ((pairdf['open'] - pairdf['close'].shift(1)) / pairdf['close'].shift(1))
+                gaps = (pairdf["open"] - pairdf["close"].shift(1)) / pairdf["close"].shift(1)
                 gaps = gaps.dropna()
                 if len(gaps):
                     candle_price_gap = max(abs(gaps))
             if candle_price_gap > 0.1:
-                logger.info(f"Price jump in {pair}, {timeframe}, {candle_type} between two candles "
-                            f"of {candle_price_gap:.2%} detected.")
+                logger.info(
+                    f"Price jump in {pair}, {timeframe}, {candle_type} between two candles "
+                    f"of {candle_price_gap:.2%} detected."
+                )
 
         return False
 
-    def _validate_pairdata(self, pair, pairdata: DataFrame, timeframe: str,
-                           candle_type: CandleType, timerange: TimeRange):
+    def _validate_pairdata(
+        self,
+        pair,
+        pairdata: DataFrame,
+        timeframe: str,
+        candle_type: CandleType,
+        timerange: TimeRange,
+    ):
         """
         Validates pairdata for missing data at start end end and logs warnings.
         :param pairdata: Dataframe to validate
         :param timerange: Timerange specified for start and end dates
         """
 
-        if timerange.starttype == 'date':
-            if pairdata.iloc[0]['date'] > timerange.startdt:
-                logger.warning(f"{pair}, {candle_type}, {timeframe}, "
-                               f"data starts at {pairdata.iloc[0]['date']:%Y-%m-%d %H:%M:%S}")
-        if timerange.stoptype == 'date':
-            if pairdata.iloc[-1]['date'] < timerange.stopdt:
-                logger.warning(f"{pair}, {candle_type}, {timeframe}, "
-                               f"data ends at {pairdata.iloc[-1]['date']:%Y-%m-%d %H:%M:%S}")
+        if timerange.starttype == "date":
+            if pairdata.iloc[0]["date"] > timerange.startdt:
+                logger.warning(
+                    f"{pair}, {candle_type}, {timeframe}, "
+                    f"data starts at {pairdata.iloc[0]['date']:%Y-%m-%d %H:%M:%S}"
+                )
+        if timerange.stoptype == "date":
+            if pairdata.iloc[-1]["date"] < timerange.stopdt:
+                logger.warning(
+                    f"{pair}, {candle_type}, {timeframe}, "
+                    f"data ends at {pairdata.iloc[-1]['date']:%Y-%m-%d %H:%M:%S}"
+                )
 
     def rename_futures_data(
-            self, pair: str, new_pair: str, timeframe: str, candle_type: CandleType):
+        self, pair: str, new_pair: str, timeframe: str, candle_type: CandleType
+    ):
         """
         Temporary method to migrate data from old naming to new naming (BTC/USDT -> BTC/USDT:USDT)
         Only used for binance to support the binance futures naming unification.
         """
 
         file_old = self._pair_data_filename(self._datadir, pair, timeframe, candle_type)
         file_new = self._pair_data_filename(self._datadir, new_pair, timeframe, candle_type)
@@ -427,64 +461,71 @@
         paircombs = self.ohlcv_get_available_data(self._datadir, TradingMode.FUTURES)
         funding_rate_combs = [
             f for f in paircombs if f[2] == CandleType.FUNDING_RATE and f[1] != ff_timeframe
         ]
 
         if funding_rate_combs:
             logger.warning(
-                f'Migrating {len(funding_rate_combs)} funding fees to correct timeframe.')
+                f"Migrating {len(funding_rate_combs)} funding fees to correct timeframe."
+            )
 
         for pair, timeframe, candletype in funding_rate_combs:
             old_name = self._pair_data_filename(self._datadir, pair, timeframe, candletype)
             new_name = self._pair_data_filename(self._datadir, pair, ff_timeframe, candletype)
 
             if not Path(old_name).exists():
-                logger.warning(f'{old_name} does not exist, skipping.')
+                logger.warning(f"{old_name} does not exist, skipping.")
                 continue
 
             if Path(new_name).exists():
-                logger.warning(f'{new_name} already exists, Removing.')
+                logger.warning(f"{new_name} already exists, Removing.")
                 Path(new_name).unlink()
 
             Path(old_name).rename(new_name)
 
 
 def get_datahandlerclass(datatype: str) -> Type[IDataHandler]:
     """
     Get datahandler class.
     Could be done using Resolvers, but since this may be called often and resolvers
     are rather expensive, doing this directly should improve performance.
     :param datatype: datatype to use.
     :return: Datahandler class
     """
 
-    if datatype == 'json':
+    if datatype == "json":
         from .jsondatahandler import JsonDataHandler
+
         return JsonDataHandler
-    elif datatype == 'jsongz':
+    elif datatype == "jsongz":
         from .jsondatahandler import JsonGzDataHandler
+
         return JsonGzDataHandler
-    elif datatype == 'hdf5':
+    elif datatype == "hdf5":
         from .hdf5datahandler import HDF5DataHandler
+
         return HDF5DataHandler
-    elif datatype == 'feather':
+    elif datatype == "feather":
         from .featherdatahandler import FeatherDataHandler
+
         return FeatherDataHandler
-    elif datatype == 'parquet':
+    elif datatype == "parquet":
         from .parquetdatahandler import ParquetDataHandler
+
         return ParquetDataHandler
     else:
         raise ValueError(f"No datahandler for datatype {datatype} available.")
 
 
-def get_datahandler(datadir: Path, data_format: Optional[str] = None,
-                    data_handler: Optional[IDataHandler] = None) -> IDataHandler:
+def get_datahandler(
+    datadir: Path, data_format: Optional[str] = None, data_handler: Optional[IDataHandler] = None
+) -> IDataHandler:
     """
     :param datadir: Folder to save data
     :param data_format: dataformat to use
     :param data_handler: returns this datahandler if it exists or initializes a new one
     """
 
     if not data_handler:
-        HandlerClass = get_datahandlerclass(data_format or 'feather')
+        HandlerClass = get_datahandlerclass(data_format or "feather")
         data_handler = HandlerClass(datadir)
     return data_handler
```

### Comparing `freqtrade-2024.4/freqtrade/data/history/datahandlers/jsondatahandler.py` & `freqtrade-2024.5/freqtrade/data/history/datahandlers/jsondatahandler.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,81 +13,84 @@
 from .idatahandler import IDataHandler
 
 
 logger = logging.getLogger(__name__)
 
 
 class JsonDataHandler(IDataHandler):
-
     _use_zip = False
     _columns = DEFAULT_DATAFRAME_COLUMNS
 
     def ohlcv_store(
-            self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType) -> None:
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
+    ) -> None:
         """
         Store data in json format "values".
             format looks as follows:
             [[<date>,<open>,<high>,<low>,<close>]]
         :param pair: Pair - used to generate filename
         :param timeframe: Timeframe - used to generate filename
         :param data: Dataframe containing OHLCV data
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: None
         """
         filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type)
         self.create_dir_if_needed(filename)
         _data = data.copy()
         # Convert date to int
-        _data['date'] = _data['date'].astype(np.int64) // 1000 // 1000
+        _data["date"] = _data["date"].astype(np.int64) // 1000 // 1000
 
         # Reset index, select only appropriate columns and save as json
         _data.reset_index(drop=True).loc[:, self._columns].to_json(
-            filename, orient="values",
-            compression='gzip' if self._use_zip else None)
+            filename, orient="values", compression="gzip" if self._use_zip else None
+        )
 
-    def _ohlcv_load(self, pair: str, timeframe: str,
-                    timerange: Optional[TimeRange], candle_type: CandleType
-                    ) -> DataFrame:
+    def _ohlcv_load(
+        self, pair: str, timeframe: str, timerange: Optional[TimeRange], candle_type: CandleType
+    ) -> DataFrame:
         """
         Internal method used to load data for one pair from disk.
         Implements the loading and conversion to a Pandas dataframe.
         Timerange trimming and dataframe validation happens outside of this method.
         :param pair: Pair to load data
         :param timeframe: Timeframe (e.g. "5m")
         :param timerange: Limit data to be loaded to this timerange.
                         Optionally implemented by subclasses to avoid loading
                         all data where possible.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: DataFrame with ohlcv data, or empty DataFrame
         """
-        filename = self._pair_data_filename(
-            self._datadir, pair, timeframe, candle_type=candle_type)
+        filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type=candle_type)
         if not filename.exists():
             # Fallback mode for 1M files
             filename = self._pair_data_filename(
-                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True)
+                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True
+            )
             if not filename.exists():
                 return DataFrame(columns=self._columns)
         try:
-            pairdata = read_json(filename, orient='values')
+            pairdata = read_json(filename, orient="values")
             pairdata.columns = self._columns
         except ValueError:
             logger.error(f"Could not load data for {pair}.")
             return DataFrame(columns=self._columns)
-        pairdata = pairdata.astype(dtype={'open': 'float', 'high': 'float',
-                                          'low': 'float', 'close': 'float', 'volume': 'float'})
-        pairdata['date'] = to_datetime(pairdata['date'], unit='ms', utc=True)
+        pairdata = pairdata.astype(
+            dtype={
+                "open": "float",
+                "high": "float",
+                "low": "float",
+                "close": "float",
+                "volume": "float",
+            }
+        )
+        pairdata["date"] = to_datetime(pairdata["date"], unit="ms", utc=True)
         return pairdata
 
     def ohlcv_append(
-        self,
-        pair: str,
-        timeframe: str,
-        data: DataFrame,
-        candle_type: CandleType
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
     ) -> None:
         """
         Append data to existing data structures
         :param pair: Pair
         :param timeframe: Timeframe this ohlcv data is for
         :param data: Data to append.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
@@ -141,9 +144,8 @@
 
     @classmethod
     def _get_file_extension(cls):
         return "json.gz" if cls._use_zip else "json"
 
 
 class JsonGzDataHandler(JsonDataHandler):
-
     _use_zip = True
```

### Comparing `freqtrade-2024.4/freqtrade/data/history/datahandlers/parquetdatahandler.py` & `freqtrade-2024.5/freqtrade/data/history/datahandlers/parquetdatahandler.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,19 +10,19 @@
 from .idatahandler import IDataHandler
 
 
 logger = logging.getLogger(__name__)
 
 
 class ParquetDataHandler(IDataHandler):
-
     _columns = DEFAULT_DATAFRAME_COLUMNS
 
     def ohlcv_store(
-            self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType) -> None:
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
+    ) -> None:
         """
         Store data in json format "values".
             format looks as follows:
             [[<date>,<open>,<high>,<low>,<close>]]
         :param pair: Pair - used to generate filename
         :param timeframe: Timeframe - used to generate filename
         :param data: Dataframe containing OHLCV data
@@ -30,51 +30,54 @@
         :return: None
         """
         filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type)
         self.create_dir_if_needed(filename)
 
         data.reset_index(drop=True).loc[:, self._columns].to_parquet(filename)
 
-    def _ohlcv_load(self, pair: str, timeframe: str,
-                    timerange: Optional[TimeRange], candle_type: CandleType
-                    ) -> DataFrame:
+    def _ohlcv_load(
+        self, pair: str, timeframe: str, timerange: Optional[TimeRange], candle_type: CandleType
+    ) -> DataFrame:
         """
         Internal method used to load data for one pair from disk.
         Implements the loading and conversion to a Pandas dataframe.
         Timerange trimming and dataframe validation happens outside of this method.
         :param pair: Pair to load data
         :param timeframe: Timeframe (e.g. "5m")
         :param timerange: Limit data to be loaded to this timerange.
                         Optionally implemented by subclasses to avoid loading
                         all data where possible.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         :return: DataFrame with ohlcv data, or empty DataFrame
         """
-        filename = self._pair_data_filename(
-            self._datadir, pair, timeframe, candle_type=candle_type)
+        filename = self._pair_data_filename(self._datadir, pair, timeframe, candle_type=candle_type)
         if not filename.exists():
             # Fallback mode for 1M files
             filename = self._pair_data_filename(
-                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True)
+                self._datadir, pair, timeframe, candle_type=candle_type, no_timeframe_modify=True
+            )
             if not filename.exists():
                 return DataFrame(columns=self._columns)
 
         pairdata = read_parquet(filename)
         pairdata.columns = self._columns
-        pairdata = pairdata.astype(dtype={'open': 'float', 'high': 'float',
-                                          'low': 'float', 'close': 'float', 'volume': 'float'})
-        pairdata['date'] = to_datetime(pairdata['date'], unit='ms', utc=True)
+        pairdata = pairdata.astype(
+            dtype={
+                "open": "float",
+                "high": "float",
+                "low": "float",
+                "close": "float",
+                "volume": "float",
+            }
+        )
+        pairdata["date"] = to_datetime(pairdata["date"], unit="ms", utc=True)
         return pairdata
 
     def ohlcv_append(
-        self,
-        pair: str,
-        timeframe: str,
-        data: DataFrame,
-        candle_type: CandleType
+        self, pair: str, timeframe: str, data: DataFrame, candle_type: CandleType
     ) -> None:
         """
         Append data to existing data structures
         :param pair: Pair
         :param timeframe: Timeframe this ohlcv data is for
         :param data: Data to append.
         :param candle_type: Any of the enum CandleType (must match trading mode!)
```

### Comparing `freqtrade-2024.4/freqtrade/data/history/history_utils.py` & `freqtrade-2024.5/freqtrade/data/history/history_utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -3,43 +3,54 @@
 from datetime import datetime, timedelta
 from pathlib import Path
 from typing import Dict, List, Optional, Tuple
 
 from pandas import DataFrame, concat
 
 from freqtrade.configuration import TimeRange
-from freqtrade.constants import (DATETIME_PRINT_FORMAT, DEFAULT_DATAFRAME_COLUMNS,
-                                 DL_DATA_TIMEFRAMES, DOCS_LINK, Config)
-from freqtrade.data.converter import (clean_ohlcv_dataframe, convert_trades_to_ohlcv,
-                                      ohlcv_to_dataframe, trades_df_remove_duplicates,
-                                      trades_list_to_df)
+from freqtrade.constants import (
+    DATETIME_PRINT_FORMAT,
+    DEFAULT_DATAFRAME_COLUMNS,
+    DL_DATA_TIMEFRAMES,
+    DOCS_LINK,
+    Config,
+)
+from freqtrade.data.converter import (
+    clean_ohlcv_dataframe,
+    convert_trades_to_ohlcv,
+    ohlcv_to_dataframe,
+    trades_df_remove_duplicates,
+    trades_list_to_df,
+)
 from freqtrade.data.history.datahandlers import IDataHandler, get_datahandler
 from freqtrade.enums import CandleType, TradingMode
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange import Exchange
 from freqtrade.plugins.pairlist.pairlist_helpers import dynamic_expand_pairlist
 from freqtrade.util import dt_ts, format_ms_time
 from freqtrade.util.datetime_helpers import dt_now
 from freqtrade.util.migrations import migrate_data
 
 
 logger = logging.getLogger(__name__)
 
 
-def load_pair_history(pair: str,
-                      timeframe: str,
-                      datadir: Path, *,
-                      timerange: Optional[TimeRange] = None,
-                      fill_up_missing: bool = True,
-                      drop_incomplete: bool = False,
-                      startup_candles: int = 0,
-                      data_format: Optional[str] = None,
-                      data_handler: Optional[IDataHandler] = None,
-                      candle_type: CandleType = CandleType.SPOT
-                      ) -> DataFrame:
+def load_pair_history(
+    pair: str,
+    timeframe: str,
+    datadir: Path,
+    *,
+    timerange: Optional[TimeRange] = None,
+    fill_up_missing: bool = True,
+    drop_incomplete: bool = False,
+    startup_candles: int = 0,
+    data_format: Optional[str] = None,
+    data_handler: Optional[IDataHandler] = None,
+    candle_type: CandleType = CandleType.SPOT,
+) -> DataFrame:
     """
     Load cached ohlcv history for the given pair.
 
     :param pair: Pair to load data for
     :param timeframe: Timeframe (e.g. "5m")
     :param datadir: Path to the data storage location.
     :param data_format: Format of the data. Ignored if data_handler is set.
@@ -50,35 +61,38 @@
     :param data_handler: Initialized data-handler to use.
                          Will be initialized from data_format if not set
     :param candle_type: Any of the enum CandleType (must match trading mode!)
     :return: DataFrame with ohlcv data, or empty DataFrame
     """
     data_handler = get_datahandler(datadir, data_format, data_handler)
 
-    return data_handler.ohlcv_load(pair=pair,
-                                   timeframe=timeframe,
-                                   timerange=timerange,
-                                   fill_missing=fill_up_missing,
-                                   drop_incomplete=drop_incomplete,
-                                   startup_candles=startup_candles,
-                                   candle_type=candle_type,
-                                   )
-
-
-def load_data(datadir: Path,
-              timeframe: str,
-              pairs: List[str], *,
-              timerange: Optional[TimeRange] = None,
-              fill_up_missing: bool = True,
-              startup_candles: int = 0,
-              fail_without_data: bool = False,
-              data_format: str = 'feather',
-              candle_type: CandleType = CandleType.SPOT,
-              user_futures_funding_rate: Optional[int] = None,
-              ) -> Dict[str, DataFrame]:
+    return data_handler.ohlcv_load(
+        pair=pair,
+        timeframe=timeframe,
+        timerange=timerange,
+        fill_missing=fill_up_missing,
+        drop_incomplete=drop_incomplete,
+        startup_candles=startup_candles,
+        candle_type=candle_type,
+    )
+
+
+def load_data(
+    datadir: Path,
+    timeframe: str,
+    pairs: List[str],
+    *,
+    timerange: Optional[TimeRange] = None,
+    fill_up_missing: bool = True,
+    startup_candles: int = 0,
+    fail_without_data: bool = False,
+    data_format: str = "feather",
+    candle_type: CandleType = CandleType.SPOT,
+    user_futures_funding_rate: Optional[int] = None,
+) -> Dict[str, DataFrame]:
     """
     Load ohlcv history data for a list of pairs.
 
     :param datadir: Path to the data storage location.
     :param timeframe: Timeframe (e.g. "5m")
     :param pairs: List of pairs to load
     :param timerange: Limit data to be loaded to this timerange
@@ -87,65 +101,76 @@
     :param fail_without_data: Raise OperationalException if no data is found.
     :param data_format: Data format which should be used. Defaults to json
     :param candle_type: Any of the enum CandleType (must match trading mode!)
     :return: dict(<pair>:<Dataframe>)
     """
     result: Dict[str, DataFrame] = {}
     if startup_candles > 0 and timerange:
-        logger.info(f'Using indicator startup period: {startup_candles} ...')
+        logger.info(f"Using indicator startup period: {startup_candles} ...")
 
     data_handler = get_datahandler(datadir, data_format)
 
     for pair in pairs:
-        hist = load_pair_history(pair=pair, timeframe=timeframe,
-                                 datadir=datadir, timerange=timerange,
-                                 fill_up_missing=fill_up_missing,
-                                 startup_candles=startup_candles,
-                                 data_handler=data_handler,
-                                 candle_type=candle_type,
-                                 )
+        hist = load_pair_history(
+            pair=pair,
+            timeframe=timeframe,
+            datadir=datadir,
+            timerange=timerange,
+            fill_up_missing=fill_up_missing,
+            startup_candles=startup_candles,
+            data_handler=data_handler,
+            candle_type=candle_type,
+        )
         if not hist.empty:
             result[pair] = hist
         else:
             if candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:
                 logger.warn(f"{pair} using user specified [{user_futures_funding_rate}]")
             elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):
                 result[pair] = DataFrame(columns=["date", "open", "close", "high", "low", "volume"])
 
     if fail_without_data and not result:
         raise OperationalException("No data found. Terminating.")
     return result
 
 
-def refresh_data(*, datadir: Path,
-                 timeframe: str,
-                 pairs: List[str],
-                 exchange: Exchange,
-                 data_format: Optional[str] = None,
-                 timerange: Optional[TimeRange] = None,
-                 candle_type: CandleType,
-                 ) -> None:
+def refresh_data(
+    *,
+    datadir: Path,
+    timeframe: str,
+    pairs: List[str],
+    exchange: Exchange,
+    data_format: Optional[str] = None,
+    timerange: Optional[TimeRange] = None,
+    candle_type: CandleType,
+) -> None:
     """
     Refresh ohlcv history data for a list of pairs.
 
     :param datadir: Path to the data storage location.
     :param timeframe: Timeframe (e.g. "5m")
     :param pairs: List of pairs to load
     :param exchange: Exchange object
     :param data_format: dataformat to use
     :param timerange: Limit data to be loaded to this timerange
     :param candle_type: Any of the enum CandleType (must match trading mode!)
     """
     data_handler = get_datahandler(datadir, data_format)
     for idx, pair in enumerate(pairs):
-        process = f'{idx}/{len(pairs)}'
-        _download_pair_history(pair=pair, process=process,
-                               timeframe=timeframe, datadir=datadir,
-                               timerange=timerange, exchange=exchange, data_handler=data_handler,
-                               candle_type=candle_type)
+        process = f"{idx}/{len(pairs)}"
+        _download_pair_history(
+            pair=pair,
+            process=process,
+            timeframe=timeframe,
+            datadir=datadir,
+            timerange=timerange,
+            exchange=exchange,
+            data_handler=data_handler,
+            candle_type=candle_type,
+        )
 
 
 def _load_cached_data_for_updating(
     pair: str,
     timeframe: str,
     timerange: Optional[TimeRange],
     data_handler: IDataHandler,
@@ -159,50 +184,57 @@
     If that's the case then what's available should be completely overwritten.
     Otherwise downloads always start at the end of the available data to avoid data gaps.
     Note: Only used by download_pair_history().
     """
     start = None
     end = None
     if timerange:
-        if timerange.starttype == 'date':
+        if timerange.starttype == "date":
             start = timerange.startdt
-        if timerange.stoptype == 'date':
+        if timerange.stoptype == "date":
             end = timerange.stopdt
 
     # Intentionally don't pass timerange in - since we need to load the full dataset.
-    data = data_handler.ohlcv_load(pair, timeframe=timeframe,
-                                   timerange=None, fill_missing=False,
-                                   drop_incomplete=True, warn_no_data=False,
-                                   candle_type=candle_type)
+    data = data_handler.ohlcv_load(
+        pair,
+        timeframe=timeframe,
+        timerange=None,
+        fill_missing=False,
+        drop_incomplete=True,
+        warn_no_data=False,
+        candle_type=candle_type,
+    )
     if not data.empty:
-        if not prepend and start and start < data.iloc[0]['date']:
+        if not prepend and start and start < data.iloc[0]["date"]:
             # Earlier data than existing data requested, redownload all
             data = DataFrame(columns=DEFAULT_DATAFRAME_COLUMNS)
         else:
             if prepend:
-                end = data.iloc[0]['date']
+                end = data.iloc[0]["date"]
             else:
-                start = data.iloc[-1]['date']
+                start = data.iloc[-1]["date"]
     start_ms = int(start.timestamp() * 1000) if start else None
     end_ms = int(end.timestamp() * 1000) if end else None
     return data, start_ms, end_ms
 
 
-def _download_pair_history(pair: str, *,
-                           datadir: Path,
-                           exchange: Exchange,
-                           timeframe: str = '5m',
-                           process: str = '',
-                           new_pairs_days: int = 30,
-                           data_handler: Optional[IDataHandler] = None,
-                           timerange: Optional[TimeRange] = None,
-                           candle_type: CandleType,
-                           erase: bool = False,
-                           prepend: bool = False,
-                           ) -> bool:
+def _download_pair_history(
+    pair: str,
+    *,
+    datadir: Path,
+    exchange: Exchange,
+    timeframe: str = "5m",
+    process: str = "",
+    new_pairs_days: int = 30,
+    data_handler: Optional[IDataHandler] = None,
+    timerange: Optional[TimeRange] = None,
+    candle_type: CandleType,
+    erase: bool = False,
+    prepend: bool = False,
+) -> bool:
     """
     Download latest candles from the exchange for the pair and timeframe passed in parameters
     The data is downloaded starting from the last correct data that
     exists in a cache. If timerange starts earlier than the data in the cache,
     the full data will be redownloaded
 
     :param pair: pair to download
@@ -213,207 +245,259 @@
     :return: bool with success state
     """
     data_handler = get_datahandler(datadir, data_handler=data_handler)
 
     try:
         if erase:
             if data_handler.ohlcv_purge(pair, timeframe, candle_type=candle_type):
-                logger.info(f'Deleting existing data for pair {pair}, {timeframe}, {candle_type}.')
+                logger.info(f"Deleting existing data for pair {pair}, {timeframe}, {candle_type}.")
 
         data, since_ms, until_ms = _load_cached_data_for_updating(
-            pair, timeframe, timerange,
+            pair,
+            timeframe,
+            timerange,
             data_handler=data_handler,
             candle_type=candle_type,
-            prepend=prepend)
+            prepend=prepend,
+        )
 
-        logger.info(f'({process}) - Download history data for "{pair}", {timeframe}, '
-                    f'{candle_type} and store in {datadir}. '
-                    f'From {format_ms_time(since_ms) if since_ms else "start"} to '
-                    f'{format_ms_time(until_ms) if until_ms else "now"}'
-                    )
-
-        logger.debug("Current Start: %s",
-                     f"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}"
-                     if not data.empty else 'None')
-        logger.debug("Current End: %s",
-                     f"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}"
-                     if not data.empty else 'None')
+        logger.info(
+            f'({process}) - Download history data for "{pair}", {timeframe}, '
+            f"{candle_type} and store in {datadir}. "
+            f'From {format_ms_time(since_ms) if since_ms else "start"} to '
+            f'{format_ms_time(until_ms) if until_ms else "now"}'
+        )
+
+        logger.debug(
+            "Current Start: %s",
+            f"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}" if not data.empty else "None",
+        )
+        logger.debug(
+            "Current End: %s",
+            f"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}" if not data.empty else "None",
+        )
 
         # Default since_ms to 30 days if nothing is given
-        new_data = exchange.get_historic_ohlcv(pair=pair,
-                                               timeframe=timeframe,
-                                               since_ms=since_ms if since_ms else
-                                               int((datetime.now() - timedelta(days=new_pairs_days)
-                                                    ).timestamp()) * 1000,
-                                               is_new_pair=data.empty,
-                                               candle_type=candle_type,
-                                               until_ms=until_ms if until_ms else None
-                                               )
+        new_data = exchange.get_historic_ohlcv(
+            pair=pair,
+            timeframe=timeframe,
+            since_ms=(
+                since_ms
+                if since_ms
+                else int((datetime.now() - timedelta(days=new_pairs_days)).timestamp()) * 1000
+            ),
+            is_new_pair=data.empty,
+            candle_type=candle_type,
+            until_ms=until_ms if until_ms else None,
+        )
         # TODO: Maybe move parsing to exchange class (?)
-        new_dataframe = ohlcv_to_dataframe(new_data, timeframe, pair,
-                                           fill_missing=False, drop_incomplete=True)
+        new_dataframe = ohlcv_to_dataframe(
+            new_data, timeframe, pair, fill_missing=False, drop_incomplete=True
+        )
         if data.empty:
             data = new_dataframe
         else:
             # Run cleaning again to ensure there were no duplicate candles
             # Especially between existing and new data.
-            data = clean_ohlcv_dataframe(concat([data, new_dataframe], axis=0), timeframe, pair,
-                                         fill_missing=False, drop_incomplete=False)
+            data = clean_ohlcv_dataframe(
+                concat([data, new_dataframe], axis=0),
+                timeframe,
+                pair,
+                fill_missing=False,
+                drop_incomplete=False,
+            )
 
-        logger.debug("New Start: %s",
-                     f"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}"
-                     if not data.empty else 'None')
-        logger.debug("New End: %s",
-                     f"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}"
-                     if not data.empty else 'None')
+        logger.debug(
+            "New Start: %s",
+            f"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}" if not data.empty else "None",
+        )
+        logger.debug(
+            "New End: %s",
+            f"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}" if not data.empty else "None",
+        )
 
         data_handler.ohlcv_store(pair, timeframe, data=data, candle_type=candle_type)
         return True
 
     except Exception:
         logger.exception(
             f'Failed to download history data for pair: "{pair}", timeframe: {timeframe}.'
         )
         return False
 
 
-def refresh_backtest_ohlcv_data(exchange: Exchange, pairs: List[str], timeframes: List[str],
-                                datadir: Path, trading_mode: str,
-                                timerange: Optional[TimeRange] = None,
-                                new_pairs_days: int = 30, erase: bool = False,
-                                data_format: Optional[str] = None,
-                                prepend: bool = False,
-                                ) -> List[str]:
+def refresh_backtest_ohlcv_data(
+    exchange: Exchange,
+    pairs: List[str],
+    timeframes: List[str],
+    datadir: Path,
+    trading_mode: str,
+    timerange: Optional[TimeRange] = None,
+    new_pairs_days: int = 30,
+    erase: bool = False,
+    data_format: Optional[str] = None,
+    prepend: bool = False,
+) -> List[str]:
     """
     Refresh stored ohlcv data for backtesting and hyperopt operations.
     Used by freqtrade download-data subcommand.
     :return: List of pairs that are not available.
     """
     pairs_not_available = []
     data_handler = get_datahandler(datadir, data_format)
     candle_type = CandleType.get_default(trading_mode)
-    process = ''
+    process = ""
     for idx, pair in enumerate(pairs, start=1):
         if pair not in exchange.markets:
             pairs_not_available.append(pair)
             logger.info(f"Skipping pair {pair}...")
             continue
         for timeframe in timeframes:
-
-            logger.debug(f'Downloading pair {pair}, {candle_type}, interval {timeframe}.')
-            process = f'{idx}/{len(pairs)}'
-            _download_pair_history(pair=pair, process=process,
-                                   datadir=datadir, exchange=exchange,
-                                   timerange=timerange, data_handler=data_handler,
-                                   timeframe=str(timeframe), new_pairs_days=new_pairs_days,
-                                   candle_type=candle_type,
-                                   erase=erase, prepend=prepend)
-        if trading_mode == 'futures':
+            logger.debug(f"Downloading pair {pair}, {candle_type}, interval {timeframe}.")
+            process = f"{idx}/{len(pairs)}"
+            _download_pair_history(
+                pair=pair,
+                process=process,
+                datadir=datadir,
+                exchange=exchange,
+                timerange=timerange,
+                data_handler=data_handler,
+                timeframe=str(timeframe),
+                new_pairs_days=new_pairs_days,
+                candle_type=candle_type,
+                erase=erase,
+                prepend=prepend,
+            )
+        if trading_mode == "futures":
             # Predefined candletype (and timeframe) depending on exchange
             # Downloads what is necessary to backtest based on futures data.
-            tf_mark = exchange.get_option('mark_ohlcv_timeframe')
-            tf_funding_rate = exchange.get_option('funding_fee_timeframe')
+            tf_mark = exchange.get_option("mark_ohlcv_timeframe")
+            tf_funding_rate = exchange.get_option("funding_fee_timeframe")
 
-            fr_candle_type = CandleType.from_string(exchange.get_option('mark_ohlcv_price'))
+            fr_candle_type = CandleType.from_string(exchange.get_option("mark_ohlcv_price"))
             # All exchanges need FundingRate for futures trading.
             # The timeframe is aligned to the mark-price timeframe.
             combs = ((CandleType.FUNDING_RATE, tf_funding_rate), (fr_candle_type, tf_mark))
             for candle_type_f, tf in combs:
-                logger.debug(f'Downloading pair {pair}, {candle_type_f}, interval {tf}.')
-                _download_pair_history(pair=pair, process=process,
-                                       datadir=datadir, exchange=exchange,
-                                       timerange=timerange, data_handler=data_handler,
-                                       timeframe=str(tf), new_pairs_days=new_pairs_days,
-                                       candle_type=candle_type_f,
-                                       erase=erase, prepend=prepend)
+                logger.debug(f"Downloading pair {pair}, {candle_type_f}, interval {tf}.")
+                _download_pair_history(
+                    pair=pair,
+                    process=process,
+                    datadir=datadir,
+                    exchange=exchange,
+                    timerange=timerange,
+                    data_handler=data_handler,
+                    timeframe=str(tf),
+                    new_pairs_days=new_pairs_days,
+                    candle_type=candle_type_f,
+                    erase=erase,
+                    prepend=prepend,
+                )
 
     return pairs_not_available
 
 
-def _download_trades_history(exchange: Exchange,
-                             pair: str, *,
-                             new_pairs_days: int = 30,
-                             timerange: Optional[TimeRange] = None,
-                             data_handler: IDataHandler,
-                             trading_mode: TradingMode,
-                             ) -> bool:
+def _download_trades_history(
+    exchange: Exchange,
+    pair: str,
+    *,
+    new_pairs_days: int = 30,
+    timerange: Optional[TimeRange] = None,
+    data_handler: IDataHandler,
+    trading_mode: TradingMode,
+) -> bool:
     """
     Download trade history from the exchange.
     Appends to previously downloaded trades data.
     """
     try:
-
         until = None
         since = 0
         if timerange:
-            if timerange.starttype == 'date':
+            if timerange.starttype == "date":
                 since = timerange.startts * 1000
-            if timerange.stoptype == 'date':
+            if timerange.stoptype == "date":
                 until = timerange.stopts * 1000
 
         trades = data_handler.trades_load(pair, trading_mode)
 
         # TradesList columns are defined in constants.DEFAULT_TRADES_COLUMNS
         # DEFAULT_TRADES_COLUMNS: 0 -> timestamp
         # DEFAULT_TRADES_COLUMNS: 1 -> id
 
-        if not trades.empty and since > 0 and since < trades.iloc[0]['timestamp']:
+        if not trades.empty and since > 0 and since < trades.iloc[0]["timestamp"]:
             # since is before the first trade
-            logger.info(f"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than "
-                        f"available data. Redownloading trades for {pair}...")
+            logger.info(
+                f"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than "
+                f"available data. Redownloading trades for {pair}..."
+            )
             trades = trades_list_to_df([])
 
-        from_id = trades.iloc[-1]['id'] if not trades.empty else None
-        if not trades.empty and since < trades.iloc[-1]['timestamp']:
+        from_id = trades.iloc[-1]["id"] if not trades.empty else None
+        if not trades.empty and since < trades.iloc[-1]["timestamp"]:
             # Reset since to the last available point
             # - 5 seconds (to ensure we're getting all trades)
-            since = trades.iloc[-1]['timestamp'] - (5 * 1000)
-            logger.info(f"Using last trade date -5s - Downloading trades for {pair} "
-                        f"since: {format_ms_time(since)}.")
+            since = trades.iloc[-1]["timestamp"] - (5 * 1000)
+            logger.info(
+                f"Using last trade date -5s - Downloading trades for {pair} "
+                f"since: {format_ms_time(since)}."
+            )
 
         if not since:
             since = dt_ts(dt_now() - timedelta(days=new_pairs_days))
 
-        logger.debug("Current Start: %s", 'None' if trades.empty else
-                     f"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}")
-        logger.debug("Current End: %s", 'None' if trades.empty else
-                     f"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}")
+        logger.debug(
+            "Current Start: %s",
+            "None" if trades.empty else f"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}",
+        )
+        logger.debug(
+            "Current End: %s",
+            "None" if trades.empty else f"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}",
+        )
         logger.info(f"Current Amount of trades: {len(trades)}")
 
         # Default since_ms to 30 days if nothing is given
-        new_trades = exchange.get_historic_trades(pair=pair,
-                                                  since=since,
-                                                  until=until,
-                                                  from_id=from_id,
-                                                  )
+        new_trades = exchange.get_historic_trades(
+            pair=pair,
+            since=since,
+            until=until,
+            from_id=from_id,
+        )
         new_trades_df = trades_list_to_df(new_trades[1])
         trades = concat([trades, new_trades_df], axis=0)
         # Remove duplicates to make sure we're not storing data we don't need
         trades = trades_df_remove_duplicates(trades)
         data_handler.trades_store(pair, trades, trading_mode)
 
-        logger.debug("New Start: %s", 'None' if trades.empty else
-                     f"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}")
-        logger.debug("New End: %s", 'None' if trades.empty else
-                     f"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}")
+        logger.debug(
+            "New Start: %s",
+            "None" if trades.empty else f"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}",
+        )
+        logger.debug(
+            "New End: %s",
+            "None" if trades.empty else f"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}",
+        )
         logger.info(f"New Amount of trades: {len(trades)}")
         return True
 
     except Exception:
-        logger.exception(
-            f'Failed to download historic trades for pair: "{pair}". '
-        )
+        logger.exception(f'Failed to download historic trades for pair: "{pair}". ')
         return False
 
 
-def refresh_backtest_trades_data(exchange: Exchange, pairs: List[str], datadir: Path,
-                                 timerange: TimeRange, trading_mode: TradingMode,
-                                 new_pairs_days: int = 30,
-                                 erase: bool = False, data_format: str = 'feather',
-                                 ) -> List[str]:
+def refresh_backtest_trades_data(
+    exchange: Exchange,
+    pairs: List[str],
+    datadir: Path,
+    timerange: TimeRange,
+    trading_mode: TradingMode,
+    new_pairs_days: int = 30,
+    erase: bool = False,
+    data_format: str = "feather",
+) -> List[str]:
     """
     Refresh stored trades data for backtesting and hyperopt operations.
     Used by freqtrade download-data subcommand.
     :return: List of pairs that are not available.
     """
     pairs_not_available = []
     data_handler = get_datahandler(datadir, data_format=data_format)
@@ -421,43 +505,48 @@
         if pair not in exchange.markets:
             pairs_not_available.append(pair)
             logger.info(f"Skipping pair {pair}...")
             continue
 
         if erase:
             if data_handler.trades_purge(pair, trading_mode):
-                logger.info(f'Deleting existing data for pair {pair}.')
+                logger.info(f"Deleting existing data for pair {pair}.")
 
-        logger.info(f'Downloading trades for pair {pair}.')
-        _download_trades_history(exchange=exchange,
-                                 pair=pair,
-                                 new_pairs_days=new_pairs_days,
-                                 timerange=timerange,
-                                 data_handler=data_handler,
-                                 trading_mode=trading_mode)
+        logger.info(f"Downloading trades for pair {pair}.")
+        _download_trades_history(
+            exchange=exchange,
+            pair=pair,
+            new_pairs_days=new_pairs_days,
+            timerange=timerange,
+            data_handler=data_handler,
+            trading_mode=trading_mode,
+        )
     return pairs_not_available
 
 
 def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:
     """
     Get the maximum common timerange for the given backtest data.
 
     :param data: dictionary with preprocessed backtesting data
     :return: tuple containing min_date, max_date
     """
     timeranges = [
-        (frame['date'].min().to_pydatetime(), frame['date'].max().to_pydatetime())
+        (frame["date"].min().to_pydatetime(), frame["date"].max().to_pydatetime())
         for frame in data.values()
     ]
-    return (min(timeranges, key=operator.itemgetter(0))[0],
-            max(timeranges, key=operator.itemgetter(1))[1])
+    return (
+        min(timeranges, key=operator.itemgetter(0))[0],
+        max(timeranges, key=operator.itemgetter(1))[1],
+    )
 
 
-def validate_backtest_data(data: DataFrame, pair: str, min_date: datetime,
-                           max_date: datetime, timeframe_min: int) -> bool:
+def validate_backtest_data(
+    data: DataFrame, pair: str, min_date: datetime, max_date: datetime, timeframe_min: int
+) -> bool:
     """
     Validates preprocessed backtesting data for missing values and shows warnings about it that.
 
     :param data: preprocessed backtesting data (as DataFrame)
     :param pair: pair used for log output.
     :param min_date: start-date of the data
     :param max_date: end-date of the data
@@ -465,93 +554,118 @@
     """
     # total difference in minutes / timeframe-minutes
     expected_frames = int((max_date - min_date).total_seconds() // 60 // timeframe_min)
     found_missing = False
     dflen = len(data)
     if dflen < expected_frames:
         found_missing = True
-        logger.warning("%s has missing frames: expected %s, got %s, that's %s missing values",
-                       pair, expected_frames, dflen, expected_frames - dflen)
+        logger.warning(
+            "%s has missing frames: expected %s, got %s, that's %s missing values",
+            pair,
+            expected_frames,
+            dflen,
+            expected_frames - dflen,
+        )
     return found_missing
 
 
 def download_data_main(config: Config) -> None:
-
     timerange = TimeRange()
-    if 'days' in config:
-        time_since = (datetime.now() - timedelta(days=config['days'])).strftime("%Y%m%d")
-        timerange = TimeRange.parse_timerange(f'{time_since}-')
+    if "days" in config:
+        time_since = (datetime.now() - timedelta(days=config["days"])).strftime("%Y%m%d")
+        timerange = TimeRange.parse_timerange(f"{time_since}-")
 
-    if 'timerange' in config:
-        timerange = timerange.parse_timerange(config['timerange'])
+    if "timerange" in config:
+        timerange = timerange.parse_timerange(config["timerange"])
 
     # Remove stake-currency to skip checks which are not relevant for datadownload
-    config['stake_currency'] = ''
+    config["stake_currency"] = ""
 
     pairs_not_available: List[str] = []
 
     # Init exchange
     from freqtrade.resolvers.exchange_resolver import ExchangeResolver
+
     exchange = ExchangeResolver.load_exchange(config, validate=False)
     available_pairs = [
-        p for p in exchange.get_markets(
-            tradable_only=True, active_only=not config.get('include_inactive')
-            ).keys()
+        p
+        for p in exchange.get_markets(
+            tradable_only=True, active_only=not config.get("include_inactive")
+        ).keys()
     ]
 
     expanded_pairs = dynamic_expand_pairlist(config, available_pairs)
-    if 'timeframes' not in config:
-        config['timeframes'] = DL_DATA_TIMEFRAMES
+    if "timeframes" not in config:
+        config["timeframes"] = DL_DATA_TIMEFRAMES
 
     # Manual validations of relevant settings
-    if not config['exchange'].get('skip_pair_validation', False):
+    if not config["exchange"].get("skip_pair_validation", False):
         exchange.validate_pairs(expanded_pairs)
-    logger.info(f"About to download pairs: {expanded_pairs}, "
-                f"intervals: {config['timeframes']} to {config['datadir']}")
+    logger.info(
+        f"About to download pairs: {expanded_pairs}, "
+        f"intervals: {config['timeframes']} to {config['datadir']}"
+    )
 
     if len(expanded_pairs) == 0:
         logger.warning(
             "No pairs available for download. "
             "Please make sure you're using the correct Pair naming for your selected trade mode. \n"
-            f"More info: {DOCS_LINK}/bot-basics/#pair-naming")
+            f"More info: {DOCS_LINK}/bot-basics/#pair-naming"
+        )
 
-    for timeframe in config['timeframes']:
+    for timeframe in config["timeframes"]:
         exchange.validate_timeframes(timeframe)
 
     # Start downloading
     try:
-        if config.get('download_trades'):
+        if config.get("download_trades"):
             pairs_not_available = refresh_backtest_trades_data(
-                exchange, pairs=expanded_pairs, datadir=config['datadir'],
-                timerange=timerange, new_pairs_days=config['new_pairs_days'],
-                erase=bool(config.get('erase')), data_format=config['dataformat_trades'],
-                trading_mode=config.get('trading_mode', TradingMode.SPOT),
-                )
-
-            # Convert downloaded trade data to different timeframes
-            convert_trades_to_ohlcv(
-                pairs=expanded_pairs, timeframes=config['timeframes'],
-                datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')),
-                data_format_ohlcv=config['dataformat_ohlcv'],
-                data_format_trades=config['dataformat_trades'],
-                candle_type=config.get('candle_type_def', CandleType.SPOT),
+                exchange,
+                pairs=expanded_pairs,
+                datadir=config["datadir"],
+                timerange=timerange,
+                new_pairs_days=config["new_pairs_days"],
+                erase=bool(config.get("erase")),
+                data_format=config["dataformat_trades"],
+                trading_mode=config.get("trading_mode", TradingMode.SPOT),
             )
+
+            if config.get("convert_trades") or not exchange.get_option("ohlcv_has_history", True):
+                # Convert downloaded trade data to different timeframes
+                # Only auto-convert for exchanges without historic klines
+
+                convert_trades_to_ohlcv(
+                    pairs=expanded_pairs,
+                    timeframes=config["timeframes"],
+                    datadir=config["datadir"],
+                    timerange=timerange,
+                    erase=bool(config.get("erase")),
+                    data_format_ohlcv=config["dataformat_ohlcv"],
+                    data_format_trades=config["dataformat_trades"],
+                    candle_type=config.get("candle_type_def", CandleType.SPOT),
+                )
         else:
-            if not exchange.get_option('ohlcv_has_history', True):
+            if not exchange.get_option("ohlcv_has_history", True):
                 raise OperationalException(
                     f"Historic klines not available for {exchange.name}. "
                     "Please use `--dl-trades` instead for this exchange "
                     "(will unfortunately take a long time)."
-                    )
+                )
             migrate_data(config, exchange)
             pairs_not_available = refresh_backtest_ohlcv_data(
-                exchange, pairs=expanded_pairs, timeframes=config['timeframes'],
-                datadir=config['datadir'], timerange=timerange,
-                new_pairs_days=config['new_pairs_days'],
-                erase=bool(config.get('erase')), data_format=config['dataformat_ohlcv'],
-                trading_mode=config.get('trading_mode', 'spot'),
-                prepend=config.get('prepend_data', False)
+                exchange,
+                pairs=expanded_pairs,
+                timeframes=config["timeframes"],
+                datadir=config["datadir"],
+                timerange=timerange,
+                new_pairs_days=config["new_pairs_days"],
+                erase=bool(config.get("erase")),
+                data_format=config["dataformat_ohlcv"],
+                trading_mode=config.get("trading_mode", "spot"),
+                prepend=config.get("prepend_data", False),
             )
     finally:
         if pairs_not_available:
-            logger.info(f"Pairs [{','.join(pairs_not_available)}] not available "
-                        f"on exchange {exchange.name}.")
+            logger.info(
+                f"Pairs [{','.join(pairs_not_available)}] not available "
+                f"on exchange {exchange.name}."
+            )
```

### Comparing `freqtrade-2024.4/freqtrade/data/metrics.py` & `freqtrade-2024.5/freqtrade/data/metrics.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 import logging
 import math
+from dataclasses import dataclass
 from datetime import datetime
 from typing import Dict, Tuple
 
 import numpy as np
 import pandas as pd
 
 
@@ -27,181 +28,201 @@
         end = df[column].dropna().iloc[-1]
         tmp_means.append((end - start) / start)
 
     return float(np.mean(tmp_means))
 
 
 def combine_dataframes_by_column(
-        data: Dict[str, pd.DataFrame], column: str = "close") -> pd.DataFrame:
+    data: Dict[str, pd.DataFrame], column: str = "close"
+) -> pd.DataFrame:
     """
     Combine multiple dataframes "column"
     :param data: Dict of Dataframes, dict key should be pair.
     :param column: Column in the original dataframes to use
     :return: DataFrame with the column renamed to the dict key.
     :raise: ValueError if no data is provided.
     """
     if not data:
         raise ValueError("No data provided.")
-    df_comb = pd.concat([data[pair].set_index('date').rename(
-        {column: pair}, axis=1)[pair] for pair in data], axis=1)
+    df_comb = pd.concat(
+        [data[pair].set_index("date").rename({column: pair}, axis=1)[pair] for pair in data], axis=1
+    )
     return df_comb
 
 
 def combined_dataframes_with_rel_mean(
-        data: Dict[str, pd.DataFrame], fromdt: datetime, todt: datetime,
-        column: str = "close") -> pd.DataFrame:
+    data: Dict[str, pd.DataFrame], fromdt: datetime, todt: datetime, column: str = "close"
+) -> pd.DataFrame:
     """
     Combine multiple dataframes "column"
     :param data: Dict of Dataframes, dict key should be pair.
     :param column: Column in the original dataframes to use
     :return: DataFrame with the column renamed to the dict key, and a column
         named mean, containing the mean of all pairs.
     :raise: ValueError if no data is provided.
     """
     df_comb = combine_dataframes_by_column(data, column)
     # Trim dataframes to the given timeframe
     df_comb = df_comb.iloc[(df_comb.index >= fromdt) & (df_comb.index < todt)]
-    df_comb['count'] = df_comb.count(axis=1)
-    df_comb['mean'] = df_comb.mean(axis=1)
-    df_comb['rel_mean'] = df_comb['mean'].pct_change().fillna(0).cumsum()
-    return df_comb[['mean', 'rel_mean', 'count']]
+    df_comb["count"] = df_comb.count(axis=1)
+    df_comb["mean"] = df_comb.mean(axis=1)
+    df_comb["rel_mean"] = df_comb["mean"].pct_change().fillna(0).cumsum()
+    return df_comb[["mean", "rel_mean", "count"]]
 
 
 def combine_dataframes_with_mean(
-        data: Dict[str, pd.DataFrame], column: str = "close") -> pd.DataFrame:
+    data: Dict[str, pd.DataFrame], column: str = "close"
+) -> pd.DataFrame:
     """
     Combine multiple dataframes "column"
     :param data: Dict of Dataframes, dict key should be pair.
     :param column: Column in the original dataframes to use
     :return: DataFrame with the column renamed to the dict key, and a column
         named mean, containing the mean of all pairs.
     :raise: ValueError if no data is provided.
     """
     df_comb = combine_dataframes_by_column(data, column)
 
-    df_comb['mean'] = df_comb.mean(axis=1)
+    df_comb["mean"] = df_comb.mean(axis=1)
 
     return df_comb
 
 
-def create_cum_profit(df: pd.DataFrame, trades: pd.DataFrame, col_name: str,
-                      timeframe: str) -> pd.DataFrame:
+def create_cum_profit(
+    df: pd.DataFrame, trades: pd.DataFrame, col_name: str, timeframe: str
+) -> pd.DataFrame:
     """
     Adds a column `col_name` with the cumulative profit for the given trades array.
     :param df: DataFrame with date index
     :param trades: DataFrame containing trades (requires columns close_date and profit_abs)
     :param col_name: Column name that will be assigned the results
     :param timeframe: Timeframe used during the operations
     :return: Returns df with one additional column, col_name, containing the cumulative profit.
     :raise: ValueError if trade-dataframe was found empty.
     """
     if len(trades) == 0:
         raise ValueError("Trade dataframe empty.")
     from freqtrade.exchange import timeframe_to_resample_freq
+
     timeframe_freq = timeframe_to_resample_freq(timeframe)
     # Resample to timeframe to make sure trades match candles
-    _trades_sum = trades.resample(timeframe_freq, on='close_date'
-                                  )[['profit_abs']].sum()
-    df.loc[:, col_name] = _trades_sum['profit_abs'].cumsum()
+    _trades_sum = trades.resample(timeframe_freq, on="close_date")[["profit_abs"]].sum()
+    df.loc[:, col_name] = _trades_sum["profit_abs"].cumsum()
     # Set first value to 0
     df.loc[df.iloc[0].name, col_name] = 0
     # FFill to get continuous
     df[col_name] = df[col_name].ffill()
     return df
 
 
-def _calc_drawdown_series(profit_results: pd.DataFrame, *, date_col: str, value_col: str,
-                          starting_balance: float) -> pd.DataFrame:
+def _calc_drawdown_series(
+    profit_results: pd.DataFrame, *, date_col: str, value_col: str, starting_balance: float
+) -> pd.DataFrame:
     max_drawdown_df = pd.DataFrame()
-    max_drawdown_df['cumulative'] = profit_results[value_col].cumsum()
-    max_drawdown_df['high_value'] = max_drawdown_df['cumulative'].cummax()
-    max_drawdown_df['drawdown'] = max_drawdown_df['cumulative'] - max_drawdown_df['high_value']
-    max_drawdown_df['date'] = profit_results.loc[:, date_col]
+    max_drawdown_df["cumulative"] = profit_results[value_col].cumsum()
+    max_drawdown_df["high_value"] = max_drawdown_df["cumulative"].cummax()
+    max_drawdown_df["drawdown"] = max_drawdown_df["cumulative"] - max_drawdown_df["high_value"]
+    max_drawdown_df["date"] = profit_results.loc[:, date_col]
     if starting_balance:
-        cumulative_balance = starting_balance + max_drawdown_df['cumulative']
-        max_balance = starting_balance + max_drawdown_df['high_value']
-        max_drawdown_df['drawdown_relative'] = ((max_balance - cumulative_balance) / max_balance)
+        cumulative_balance = starting_balance + max_drawdown_df["cumulative"]
+        max_balance = starting_balance + max_drawdown_df["high_value"]
+        max_drawdown_df["drawdown_relative"] = (max_balance - cumulative_balance) / max_balance
     else:
         # NOTE: This is not completely accurate,
         # but might good enough if starting_balance is not available
-        max_drawdown_df['drawdown_relative'] = (
-            (max_drawdown_df['high_value'] - max_drawdown_df['cumulative'])
-            / max_drawdown_df['high_value'])
+        max_drawdown_df["drawdown_relative"] = (
+            max_drawdown_df["high_value"] - max_drawdown_df["cumulative"]
+        ) / max_drawdown_df["high_value"]
     return max_drawdown_df
 
 
-def calculate_underwater(trades: pd.DataFrame, *, date_col: str = 'close_date',
-                         value_col: str = 'profit_ratio', starting_balance: float = 0.0
-                         ):
+def calculate_underwater(
+    trades: pd.DataFrame,
+    *,
+    date_col: str = "close_date",
+    value_col: str = "profit_ratio",
+    starting_balance: float = 0.0,
+):
     """
     Calculate max drawdown and the corresponding close dates
     :param trades: DataFrame containing trades (requires columns close_date and profit_ratio)
     :param date_col: Column in DataFrame to use for dates (defaults to 'close_date')
     :param value_col: Column in DataFrame to use for values (defaults to 'profit_ratio')
     :return: Tuple (float, highdate, lowdate, highvalue, lowvalue) with absolute max drawdown,
              high and low time and high and low value.
     :raise: ValueError if trade-dataframe was found empty.
     """
     if len(trades) == 0:
         raise ValueError("Trade dataframe empty.")
     profit_results = trades.sort_values(date_col).reset_index(drop=True)
     max_drawdown_df = _calc_drawdown_series(
-        profit_results,
-        date_col=date_col,
-        value_col=value_col,
-        starting_balance=starting_balance)
+        profit_results, date_col=date_col, value_col=value_col, starting_balance=starting_balance
+    )
 
     return max_drawdown_df
 
 
-def calculate_max_drawdown(trades: pd.DataFrame, *, date_col: str = 'close_date',
-                           value_col: str = 'profit_abs', starting_balance: float = 0,
-                           relative: bool = False
-                           ) -> Tuple[float, pd.Timestamp, pd.Timestamp, float, float, float]:
+@dataclass()
+class DrawDownResult:
+    drawdown_abs: float = 0.0
+    high_date: pd.Timestamp = None
+    low_date: pd.Timestamp = None
+    high_value: float = 0.0
+    low_value: float = 0.0
+    relative_account_drawdown: float = 0.0
+
+
+def calculate_max_drawdown(
+    trades: pd.DataFrame,
+    *,
+    date_col: str = "close_date",
+    value_col: str = "profit_abs",
+    starting_balance: float = 0,
+    relative: bool = False,
+) -> DrawDownResult:
     """
     Calculate max drawdown and the corresponding close dates
     :param trades: DataFrame containing trades (requires columns close_date and profit_ratio)
     :param date_col: Column in DataFrame to use for dates (defaults to 'close_date')
     :param value_col: Column in DataFrame to use for values (defaults to 'profit_abs')
     :param starting_balance: Portfolio starting balance - properly calculate relative drawdown.
-    :return: Tuple (float, highdate, lowdate, highvalue, lowvalue, relative_drawdown)
+    :return: DrawDownResult object
              with absolute max drawdown, high and low time and high and low value,
              and the relative account drawdown
     :raise: ValueError if trade-dataframe was found empty.
     """
     if len(trades) == 0:
         raise ValueError("Trade dataframe empty.")
     profit_results = trades.sort_values(date_col).reset_index(drop=True)
     max_drawdown_df = _calc_drawdown_series(
-        profit_results,
-        date_col=date_col,
-        value_col=value_col,
-        starting_balance=starting_balance
+        profit_results, date_col=date_col, value_col=value_col, starting_balance=starting_balance
     )
 
     idxmin = (
-        max_drawdown_df['drawdown_relative'].idxmax()
-        if relative else max_drawdown_df['drawdown'].idxmin()
+        max_drawdown_df["drawdown_relative"].idxmax()
+        if relative
+        else max_drawdown_df["drawdown"].idxmin()
     )
     if idxmin == 0:
         raise ValueError("No losing trade, therefore no drawdown.")
-    high_date = profit_results.loc[max_drawdown_df.iloc[:idxmin]['high_value'].idxmax(), date_col]
+    high_date = profit_results.loc[max_drawdown_df.iloc[:idxmin]["high_value"].idxmax(), date_col]
     low_date = profit_results.loc[idxmin, date_col]
-    high_val = max_drawdown_df.loc[max_drawdown_df.iloc[:idxmin]
-                                   ['high_value'].idxmax(), 'cumulative']
-    low_val = max_drawdown_df.loc[idxmin, 'cumulative']
-    max_drawdown_rel = max_drawdown_df.loc[idxmin, 'drawdown_relative']
-
-    return (
-        abs(max_drawdown_df.loc[idxmin, 'drawdown']),
-        high_date,
-        low_date,
-        high_val,
-        low_val,
-        max_drawdown_rel
+    high_val = max_drawdown_df.loc[
+        max_drawdown_df.iloc[:idxmin]["high_value"].idxmax(), "cumulative"
+    ]
+    low_val = max_drawdown_df.loc[idxmin, "cumulative"]
+    max_drawdown_rel = max_drawdown_df.loc[idxmin, "drawdown_relative"]
+
+    return DrawDownResult(
+        drawdown_abs=abs(max_drawdown_df.loc[idxmin, "drawdown"]),
+        high_date=high_date,
+        low_date=low_date,
+        high_value=high_val,
+        low_value=low_val,
+        relative_account_drawdown=max_drawdown_rel,
     )
 
 
 def calculate_csum(trades: pd.DataFrame, starting_balance: float = 0) -> Tuple[float, float]:
     """
     Calculate min/max cumsum of trades, to show if the wallet/stake amount ratio is sane
     :param trades: DataFrame containing trades (requires columns close_date and profit_percent)
@@ -209,17 +230,17 @@
     :return: Tuple (float, float) with cumsum of profit_abs
     :raise: ValueError if trade-dataframe was found empty.
     """
     if len(trades) == 0:
         raise ValueError("Trade dataframe empty.")
 
     csum_df = pd.DataFrame()
-    csum_df['sum'] = trades['profit_abs'].cumsum()
-    csum_min = csum_df['sum'].min() + starting_balance
-    csum_max = csum_df['sum'].max() + starting_balance
+    csum_df["sum"] = trades["profit_abs"].cumsum()
+    csum_min = csum_df["sum"].min() + starting_balance
+    csum_max = csum_df["sum"].max() + starting_balance
 
     return csum_min, csum_max
 
 
 def calculate_cagr(days_passed: int, starting_balance: float, final_balance: float) -> float:
     """
     Calculate CAGR
@@ -241,72 +262,74 @@
     :return: expectancy, expectancy_ratio
     """
 
     expectancy = 0
     expectancy_ratio = 100
 
     if len(trades) > 0:
-        winning_trades = trades.loc[trades['profit_abs'] > 0]
-        losing_trades = trades.loc[trades['profit_abs'] < 0]
-        profit_sum = winning_trades['profit_abs'].sum()
-        loss_sum = abs(losing_trades['profit_abs'].sum())
+        winning_trades = trades.loc[trades["profit_abs"] > 0]
+        losing_trades = trades.loc[trades["profit_abs"] < 0]
+        profit_sum = winning_trades["profit_abs"].sum()
+        loss_sum = abs(losing_trades["profit_abs"].sum())
         nb_win_trades = len(winning_trades)
         nb_loss_trades = len(losing_trades)
 
         average_win = (profit_sum / nb_win_trades) if nb_win_trades > 0 else 0
         average_loss = (loss_sum / nb_loss_trades) if nb_loss_trades > 0 else 0
-        winrate = (nb_win_trades / len(trades))
-        loserate = (nb_loss_trades / len(trades))
+        winrate = nb_win_trades / len(trades)
+        loserate = nb_loss_trades / len(trades)
 
         expectancy = (winrate * average_win) - (loserate * average_loss)
-        if (average_loss > 0):
+        if average_loss > 0:
             risk_reward_ratio = average_win / average_loss
             expectancy_ratio = ((1 + risk_reward_ratio) * winrate) - 1
 
     return expectancy, expectancy_ratio
 
 
-def calculate_sortino(trades: pd.DataFrame, min_date: datetime, max_date: datetime,
-                      starting_balance: float) -> float:
+def calculate_sortino(
+    trades: pd.DataFrame, min_date: datetime, max_date: datetime, starting_balance: float
+) -> float:
     """
     Calculate sortino
     :param trades: DataFrame containing trades (requires columns profit_abs)
     :return: sortino
     """
     if (len(trades) == 0) or (min_date is None) or (max_date is None) or (min_date == max_date):
         return 0
 
-    total_profit = trades['profit_abs'] / starting_balance
+    total_profit = trades["profit_abs"] / starting_balance
     days_period = max(1, (max_date - min_date).days)
 
     expected_returns_mean = total_profit.sum() / days_period
 
-    down_stdev = np.std(trades.loc[trades['profit_abs'] < 0, 'profit_abs'] / starting_balance)
+    down_stdev = np.std(trades.loc[trades["profit_abs"] < 0, "profit_abs"] / starting_balance)
 
     if down_stdev != 0 and not np.isnan(down_stdev):
         sortino_ratio = expected_returns_mean / down_stdev * np.sqrt(365)
     else:
         # Define high (negative) sortino ratio to be clear that this is NOT optimal.
         sortino_ratio = -100
 
     # print(expected_returns_mean, down_stdev, sortino_ratio)
     return sortino_ratio
 
 
-def calculate_sharpe(trades: pd.DataFrame, min_date: datetime, max_date: datetime,
-                     starting_balance: float) -> float:
+def calculate_sharpe(
+    trades: pd.DataFrame, min_date: datetime, max_date: datetime, starting_balance: float
+) -> float:
     """
     Calculate sharpe
     :param trades: DataFrame containing trades (requires column profit_abs)
     :return: sharpe
     """
     if (len(trades) == 0) or (min_date is None) or (max_date is None) or (min_date == max_date):
         return 0
 
-    total_profit = trades['profit_abs'] / starting_balance
+    total_profit = trades["profit_abs"] / starting_balance
     days_period = max(1, (max_date - min_date).days)
 
     expected_returns_mean = total_profit.sum() / days_period
     up_stdev = np.std(total_profit)
 
     if up_stdev != 0:
         sharp_ratio = expected_returns_mean / up_stdev * np.sqrt(365)
@@ -314,36 +337,38 @@
         # Define high (negative) sharpe ratio to be clear that this is NOT optimal.
         sharp_ratio = -100
 
     # print(expected_returns_mean, up_stdev, sharp_ratio)
     return sharp_ratio
 
 
-def calculate_calmar(trades: pd.DataFrame, min_date: datetime, max_date: datetime,
-                     starting_balance: float) -> float:
+def calculate_calmar(
+    trades: pd.DataFrame, min_date: datetime, max_date: datetime, starting_balance: float
+) -> float:
     """
     Calculate calmar
     :param trades: DataFrame containing trades (requires columns close_date and profit_abs)
     :return: calmar
     """
     if (len(trades) == 0) or (min_date is None) or (max_date is None) or (min_date == max_date):
         return 0
 
-    total_profit = trades['profit_abs'].sum() / starting_balance
+    total_profit = trades["profit_abs"].sum() / starting_balance
     days_period = max(1, (max_date - min_date).days)
 
     # adding slippage of 0.1% per trade
     # total_profit = total_profit - 0.0005
     expected_returns_mean = total_profit / days_period * 100
 
     # calculate max drawdown
     try:
-        _, _, _, _, _, max_drawdown = calculate_max_drawdown(
+        drawdown = calculate_max_drawdown(
             trades, value_col="profit_abs", starting_balance=starting_balance
         )
+        max_drawdown = drawdown.relative_account_drawdown
     except ValueError:
         max_drawdown = 0
 
     if max_drawdown != 0:
         calmar_ratio = expected_returns_mean / max_drawdown * math.sqrt(365)
     else:
         # Define high (negative) calmar ratio to be clear that this is NOT optimal.
```

### Comparing `freqtrade-2024.4/freqtrade/edge/edge_positioning.py` & `freqtrade-2024.5/freqtrade/edge/edge_positioning.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 # pragma pylint: disable=W0603
-""" Edge positioning package """
+"""Edge positioning package"""
+
 import logging
 from collections import defaultdict
 from copy import deepcopy
 from datetime import timedelta
 from typing import Any, Dict, List, NamedTuple
 
 import numpy as np
@@ -42,141 +43,147 @@
     and force it into the strategy
     Author: https://github.com/mishaker
     """
 
     _cached_pairs: Dict[str, Any] = {}  # Keeps a list of pairs
 
     def __init__(self, config: Config, exchange, strategy) -> None:
-
         self.config = config
         self.exchange = exchange
         self.strategy: IStrategy = strategy
 
-        self.edge_config = self.config.get('edge', {})
+        self.edge_config = self.config.get("edge", {})
         self._cached_pairs: Dict[str, Any] = {}  # Keeps a list of pairs
         self._final_pairs: list = []
 
         # checking max_open_trades. it should be -1 as with Edge
         # the number of trades is determined by position size
-        if self.config['max_open_trades'] != float('inf'):
-            logger.critical('max_open_trades should be -1 in config !')
+        if self.config["max_open_trades"] != float("inf"):
+            logger.critical("max_open_trades should be -1 in config !")
 
-        if self.config['stake_amount'] != UNLIMITED_STAKE_AMOUNT:
-            raise OperationalException('Edge works only with unlimited stake amount')
+        if self.config["stake_amount"] != UNLIMITED_STAKE_AMOUNT:
+            raise OperationalException("Edge works only with unlimited stake amount")
 
-        self._capital_ratio: float = self.config['tradable_balance_ratio']
-        self._allowed_risk: float = self.edge_config.get('allowed_risk')
-        self._since_number_of_days: int = self.edge_config.get('calculate_since_number_of_days', 14)
+        self._capital_ratio: float = self.config["tradable_balance_ratio"]
+        self._allowed_risk: float = self.edge_config.get("allowed_risk")
+        self._since_number_of_days: int = self.edge_config.get("calculate_since_number_of_days", 14)
         self._last_updated: int = 0  # Timestamp of pairs last updated time
         self._refresh_pairs = True
 
-        self._stoploss_range_min = float(self.edge_config.get('stoploss_range_min', -0.01))
-        self._stoploss_range_max = float(self.edge_config.get('stoploss_range_max', -0.05))
-        self._stoploss_range_step = float(self.edge_config.get('stoploss_range_step', -0.001))
+        self._stoploss_range_min = float(self.edge_config.get("stoploss_range_min", -0.01))
+        self._stoploss_range_max = float(self.edge_config.get("stoploss_range_max", -0.05))
+        self._stoploss_range_step = float(self.edge_config.get("stoploss_range_step", -0.001))
 
         # calculating stoploss range
         self._stoploss_range = np.arange(
-            self._stoploss_range_min,
-            self._stoploss_range_max,
-            self._stoploss_range_step
+            self._stoploss_range_min, self._stoploss_range_max, self._stoploss_range_step
         )
 
         self._timerange: TimeRange = TimeRange.parse_timerange(
-            f"{(dt_now() - timedelta(days=self._since_number_of_days)).strftime('%Y%m%d')}-")
-        if config.get('fee'):
-            self.fee = config['fee']
+            f"{(dt_now() - timedelta(days=self._since_number_of_days)).strftime('%Y%m%d')}-"
+        )
+        if config.get("fee"):
+            self.fee = config["fee"]
         else:
             try:
-                self.fee = self.exchange.get_fee(symbol=expand_pairlist(
-                    self.config['exchange']['pair_whitelist'], list(self.exchange.markets))[0])
+                self.fee = self.exchange.get_fee(
+                    symbol=expand_pairlist(
+                        self.config["exchange"]["pair_whitelist"], list(self.exchange.markets)
+                    )[0]
+                )
             except IndexError:
                 self.fee = None
 
     def calculate(self, pairs: List[str]) -> bool:
         if self.fee is None and pairs:
             self.fee = self.exchange.get_fee(pairs[0])
 
-        heartbeat = self.edge_config.get('process_throttle_secs')
+        heartbeat = self.edge_config.get("process_throttle_secs")
 
         if (self._last_updated > 0) and (
-                self._last_updated + heartbeat > int(dt_now().timestamp())):
+            self._last_updated + heartbeat > int(dt_now().timestamp())
+        ):
             return False
 
         data: Dict[str, Any] = {}
-        logger.info('Using stake_currency: %s ...', self.config['stake_currency'])
-        logger.info('Using local backtesting data (using whitelist in given config) ...')
+        logger.info("Using stake_currency: %s ...", self.config["stake_currency"])
+        logger.info("Using local backtesting data (using whitelist in given config) ...")
 
         if self._refresh_pairs:
             timerange_startup = deepcopy(self._timerange)
-            timerange_startup.subtract_start(timeframe_to_seconds(
-                self.strategy.timeframe) * self.strategy.startup_candle_count)
+            timerange_startup.subtract_start(
+                timeframe_to_seconds(self.strategy.timeframe) * self.strategy.startup_candle_count
+            )
             refresh_data(
-                datadir=self.config['datadir'],
+                datadir=self.config["datadir"],
                 pairs=pairs,
                 exchange=self.exchange,
                 timeframe=self.strategy.timeframe,
                 timerange=timerange_startup,
-                data_format=self.config['dataformat_ohlcv'],
-                candle_type=self.config.get('candle_type_def', CandleType.SPOT),
+                data_format=self.config["dataformat_ohlcv"],
+                candle_type=self.config.get("candle_type_def", CandleType.SPOT),
             )
             # Download informative pairs too
             res = defaultdict(list)
             for pair, timeframe, _ in self.strategy.gather_informative_pairs():
                 res[timeframe].append(pair)
             for timeframe, inf_pairs in res.items():
                 timerange_startup = deepcopy(self._timerange)
-                timerange_startup.subtract_start(timeframe_to_seconds(
-                    timeframe) * self.strategy.startup_candle_count)
+                timerange_startup.subtract_start(
+                    timeframe_to_seconds(timeframe) * self.strategy.startup_candle_count
+                )
                 refresh_data(
-                    datadir=self.config['datadir'],
+                    datadir=self.config["datadir"],
                     pairs=inf_pairs,
                     exchange=self.exchange,
                     timeframe=timeframe,
                     timerange=timerange_startup,
-                    data_format=self.config['dataformat_ohlcv'],
-                    candle_type=self.config.get('candle_type_def', CandleType.SPOT),
+                    data_format=self.config["dataformat_ohlcv"],
+                    candle_type=self.config.get("candle_type_def", CandleType.SPOT),
                 )
 
         data = load_data(
-            datadir=self.config['datadir'],
+            datadir=self.config["datadir"],
             pairs=pairs,
             timeframe=self.strategy.timeframe,
             timerange=self._timerange,
             startup_candles=self.strategy.startup_candle_count,
-            data_format=self.config['dataformat_ohlcv'],
-            candle_type=self.config.get('candle_type_def', CandleType.SPOT),
+            data_format=self.config["dataformat_ohlcv"],
+            candle_type=self.config.get("candle_type_def", CandleType.SPOT),
         )
 
         if not data:
             # Reinitializing cached pairs
             self._cached_pairs = {}
             logger.critical("No data found. Edge is stopped ...")
             return False
         # Fake run-mode to Edge
-        prior_rm = self.config['runmode']
-        self.config['runmode'] = RunMode.EDGE
+        prior_rm = self.config["runmode"]
+        self.config["runmode"] = RunMode.EDGE
         preprocessed = self.strategy.advise_all_indicators(data)
-        self.config['runmode'] = prior_rm
+        self.config["runmode"] = prior_rm
 
         # Print timeframe
         min_date, max_date = get_timerange(preprocessed)
-        logger.info(f'Measuring data from {min_date.strftime(DATETIME_PRINT_FORMAT)} '
-                    f'up to {max_date.strftime(DATETIME_PRINT_FORMAT)} '
-                    f'({(max_date - min_date).days} days)..')
+        logger.info(
+            f"Measuring data from {min_date.strftime(DATETIME_PRINT_FORMAT)} "
+            f"up to {max_date.strftime(DATETIME_PRINT_FORMAT)} "
+            f"({(max_date - min_date).days} days).."
+        )
         # TODO: Should edge support shorts? needs to be investigated further
         # * (add enter_short exit_short)
-        headers = ['date', 'open', 'high', 'low', 'close', 'enter_long', 'exit_long']
+        headers = ["date", "open", "high", "low", "close", "enter_long", "exit_long"]
 
         trades: list = []
         for pair, pair_data in preprocessed.items():
             # Sorting dataframe by date and reset index
-            pair_data = pair_data.sort_values(by=['date'])
+            pair_data = pair_data.sort_values(by=["date"])
             pair_data = pair_data.reset_index(drop=True)
 
-            df_analyzed = self.strategy.ft_advise_signals(pair_data, {'pair': pair})[headers].copy()
+            df_analyzed = self.strategy.ft_advise_signals(pair_data, {"pair": pair})[headers].copy()
 
             trades += self._find_trades_for_stoploss_range(df_analyzed, pair, self._stoploss_range)
 
         # If no trade found then exit
         if len(trades) == 0:
             logger.info("No trades found.")
             return False
@@ -184,86 +191,96 @@
         # Fill missing, calculable columns, profit, duration , abs etc.
         trades_df = self._fill_calculable_fields(DataFrame(trades))
         self._cached_pairs = self._process_expectancy(trades_df)
         self._last_updated = int(dt_now().timestamp())
 
         return True
 
-    def stake_amount(self, pair: str, free_capital: float,
-                     total_capital: float, capital_in_trade: float) -> float:
+    def stake_amount(
+        self, pair: str, free_capital: float, total_capital: float, capital_in_trade: float
+    ) -> float:
         stoploss = self.get_stoploss(pair)
         available_capital = (total_capital + capital_in_trade) * self._capital_ratio
         allowed_capital_at_risk = available_capital * self._allowed_risk
         max_position_size = abs(allowed_capital_at_risk / stoploss)
         # Position size must be below available capital.
         position_size = min(min(max_position_size, free_capital), available_capital)
         if pair in self._cached_pairs:
             logger.info(
-                'winrate: %s, expectancy: %s, position size: %s, pair: %s,'
-                ' capital in trade: %s, free capital: %s, total capital: %s,'
-                ' stoploss: %s, available capital: %s.',
+                "winrate: %s, expectancy: %s, position size: %s, pair: %s,"
+                " capital in trade: %s, free capital: %s, total capital: %s,"
+                " stoploss: %s, available capital: %s.",
                 self._cached_pairs[pair].winrate,
                 self._cached_pairs[pair].expectancy,
-                position_size, pair,
-                capital_in_trade, free_capital, total_capital,
-                stoploss, available_capital
+                position_size,
+                pair,
+                capital_in_trade,
+                free_capital,
+                total_capital,
+                stoploss,
+                available_capital,
             )
         return round(position_size, 15)
 
     def get_stoploss(self, pair: str) -> float:
         if pair in self._cached_pairs:
             return self._cached_pairs[pair].stoploss
         else:
-            logger.warning(f'Tried to access stoploss of non-existing pair {pair}, '
-                           'strategy stoploss is returned instead.')
+            logger.warning(
+                f"Tried to access stoploss of non-existing pair {pair}, "
+                "strategy stoploss is returned instead."
+            )
             return self.strategy.stoploss
 
     def adjust(self, pairs: List[str]) -> list:
         """
         Filters out and sorts "pairs" according to Edge calculated pairs
         """
         final = []
         for pair, info in self._cached_pairs.items():
             if (
-                info.expectancy > float(self.edge_config.get('minimum_expectancy', 0.2))
-                and info.winrate > float(self.edge_config.get('minimum_winrate', 0.60))
+                info.expectancy > float(self.edge_config.get("minimum_expectancy", 0.2))
+                and info.winrate > float(self.edge_config.get("minimum_winrate", 0.60))
                 and pair in pairs
             ):
                 final.append(pair)
 
         if self._final_pairs != final:
             self._final_pairs = final
             if self._final_pairs:
                 logger.info(
-                    'Minimum expectancy and minimum winrate are met only for %s,'
-                    ' so other pairs are filtered out.',
-                    self._final_pairs
+                    "Minimum expectancy and minimum winrate are met only for %s,"
+                    " so other pairs are filtered out.",
+                    self._final_pairs,
                 )
             else:
                 logger.info(
-                    'Edge removed all pairs as no pair with minimum expectancy '
-                    'and minimum winrate was found !'
+                    "Edge removed all pairs as no pair with minimum expectancy "
+                    "and minimum winrate was found !"
                 )
 
         return self._final_pairs
 
     def accepted_pairs(self) -> List[Dict[str, Any]]:
         """
         return a list of accepted pairs along with their winrate, expectancy and stoploss
         """
         final = []
         for pair, info in self._cached_pairs.items():
-            if (info.expectancy > float(self.edge_config.get('minimum_expectancy', 0.2)) and
-                    info.winrate > float(self.edge_config.get('minimum_winrate', 0.60))):
-                final.append({
-                    'Pair': pair,
-                    'Winrate': info.winrate,
-                    'Expectancy': info.expectancy,
-                    'Stoploss': info.stoploss,
-                })
+            if info.expectancy > float(
+                self.edge_config.get("minimum_expectancy", 0.2)
+            ) and info.winrate > float(self.edge_config.get("minimum_winrate", 0.60)):
+                final.append(
+                    {
+                        "Pair": pair,
+                        "Winrate": info.winrate,
+                        "Expectancy": info.expectancy,
+                        "Stoploss": info.stoploss,
+                    }
+                )
         return final
 
     def _fill_calculable_fields(self, result: DataFrame) -> DataFrame:
         """
         The result frame contains a number of columns that are calculable
         from other columns. These are left blank till all rows are added,
         to be populated in single vector calls.
@@ -275,138 +292,152 @@
         :param result Dataframe
         :return: result Dataframe
         """
         # We set stake amount to an arbitrary amount, as it doesn't change the calculation.
         # All returned values are relative, they are defined as ratios.
         stake = 0.015
 
-        result['trade_duration'] = result['close_date'] - result['open_date']
+        result["trade_duration"] = result["close_date"] - result["open_date"]
 
-        result['trade_duration'] = result['trade_duration'].map(
-            lambda x: int(x.total_seconds() / 60))
+        result["trade_duration"] = result["trade_duration"].map(
+            lambda x: int(x.total_seconds() / 60)
+        )
 
         # Spends, Takes, Profit, Absolute Profit
 
         # Buy Price
-        result['buy_vol'] = stake / result['open_rate']  # How many target are we buying
-        result['buy_fee'] = stake * self.fee
-        result['buy_spend'] = stake + result['buy_fee']  # How much we're spending
+        result["buy_vol"] = stake / result["open_rate"]  # How many target are we buying
+        result["buy_fee"] = stake * self.fee
+        result["buy_spend"] = stake + result["buy_fee"]  # How much we're spending
 
         # Sell price
-        result['sell_sum'] = result['buy_vol'] * result['close_rate']
-        result['sell_fee'] = result['sell_sum'] * self.fee
-        result['sell_take'] = result['sell_sum'] - result['sell_fee']
+        result["sell_sum"] = result["buy_vol"] * result["close_rate"]
+        result["sell_fee"] = result["sell_sum"] * self.fee
+        result["sell_take"] = result["sell_sum"] - result["sell_fee"]
 
         # profit_ratio
-        result['profit_ratio'] = (result['sell_take'] - result['buy_spend']) / result['buy_spend']
+        result["profit_ratio"] = (result["sell_take"] - result["buy_spend"]) / result["buy_spend"]
 
         # Absolute profit
-        result['profit_abs'] = result['sell_take'] - result['buy_spend']
+        result["profit_abs"] = result["sell_take"] - result["buy_spend"]
 
         return result
 
     def _process_expectancy(self, results: DataFrame) -> Dict[str, Any]:
         """
         This calculates WinRate, Required Risk Reward, Risk Reward and Expectancy of all pairs
         The calculation will be done per pair and per strategy.
         """
         # Removing pairs having less than min_trades_number
-        min_trades_number = self.edge_config.get('min_trade_number', 10)
-        results = results.groupby(['pair', 'stoploss']).filter(lambda x: len(x) > min_trades_number)
+        min_trades_number = self.edge_config.get("min_trade_number", 10)
+        results = results.groupby(["pair", "stoploss"]).filter(lambda x: len(x) > min_trades_number)
         ###################################
 
         # Removing outliers (Only Pumps) from the dataset
         # The method to detect outliers is to calculate standard deviation
         # Then every value more than (standard deviation + 2*average) is out (pump)
         #
         # Removing Pumps
-        if self.edge_config.get('remove_pumps', False):
-            results = results[results['profit_abs'] < 2 * results['profit_abs'].std()
-                              + results['profit_abs'].mean()]
+        if self.edge_config.get("remove_pumps", False):
+            results = results[
+                results["profit_abs"]
+                < 2 * results["profit_abs"].std() + results["profit_abs"].mean()
+            ]
         ##########################################################################
 
         # Removing trades having a duration more than X minutes (set in config)
-        max_trade_duration = self.edge_config.get('max_trade_duration_minute', 1440)
+        max_trade_duration = self.edge_config.get("max_trade_duration_minute", 1440)
         results = results[results.trade_duration < max_trade_duration]
         #######################################################################
 
         if results.empty:
             return {}
 
         groupby_aggregator = {
-            'profit_abs': [
-                ('nb_trades', 'count'),  # number of all trades
-                ('profit_sum', lambda x: x[x > 0].sum()),  # cumulative profit of all winning trades
-                ('loss_sum', lambda x: abs(x[x < 0].sum())),  # cumulative loss of all losing trades
-                ('nb_win_trades', lambda x: x[x > 0].count())  # number of winning trades
+            "profit_abs": [
+                ("nb_trades", "count"),  # number of all trades
+                ("profit_sum", lambda x: x[x > 0].sum()),  # cumulative profit of all winning trades
+                ("loss_sum", lambda x: abs(x[x < 0].sum())),  # cumulative loss of all losing trades
+                ("nb_win_trades", lambda x: x[x > 0].count()),  # number of winning trades
             ],
-            'trade_duration': [('avg_trade_duration', 'mean')]
+            "trade_duration": [("avg_trade_duration", "mean")],
         }
 
         # Group by (pair and stoploss) by applying above aggregator
-        df = results.groupby(['pair', 'stoploss'])[['profit_abs', 'trade_duration']].agg(
-            groupby_aggregator).reset_index(col_level=1)
+        df = (
+            results.groupby(["pair", "stoploss"])[["profit_abs", "trade_duration"]]
+            .agg(groupby_aggregator)
+            .reset_index(col_level=1)
+        )
 
         # Dropping level 0 as we don't need it
         df.columns = df.columns.droplevel(0)
 
         # Calculating number of losing trades, average win and average loss
-        df['nb_loss_trades'] = df['nb_trades'] - df['nb_win_trades']
-        df['average_win'] = np.where(df['nb_win_trades'] == 0, 0.0,
-                                     df['profit_sum'] / df['nb_win_trades'])
-        df['average_loss'] = np.where(df['nb_loss_trades'] == 0, 0.0,
-                                      df['loss_sum'] / df['nb_loss_trades'])
+        df["nb_loss_trades"] = df["nb_trades"] - df["nb_win_trades"]
+        df["average_win"] = np.where(
+            df["nb_win_trades"] == 0, 0.0, df["profit_sum"] / df["nb_win_trades"]
+        )
+        df["average_loss"] = np.where(
+            df["nb_loss_trades"] == 0, 0.0, df["loss_sum"] / df["nb_loss_trades"]
+        )
 
         # Win rate = number of profitable trades / number of trades
-        df['winrate'] = df['nb_win_trades'] / df['nb_trades']
+        df["winrate"] = df["nb_win_trades"] / df["nb_trades"]
 
         # risk_reward_ratio = average win / average loss
-        df['risk_reward_ratio'] = df['average_win'] / df['average_loss']
+        df["risk_reward_ratio"] = df["average_win"] / df["average_loss"]
 
         # required_risk_reward = (1 / winrate) - 1
-        df['required_risk_reward'] = (1 / df['winrate']) - 1
+        df["required_risk_reward"] = (1 / df["winrate"]) - 1
 
         # expectancy = (risk_reward_ratio * winrate) - (lossrate)
-        df['expectancy'] = (df['risk_reward_ratio'] * df['winrate']) - (1 - df['winrate'])
+        df["expectancy"] = (df["risk_reward_ratio"] * df["winrate"]) - (1 - df["winrate"])
 
         # sort by expectancy and stoploss
-        df = df.sort_values(by=['expectancy', 'stoploss'], ascending=False).groupby(
-            'pair').first().sort_values(by=['expectancy'], ascending=False).reset_index()
+        df = (
+            df.sort_values(by=["expectancy", "stoploss"], ascending=False)
+            .groupby("pair")
+            .first()
+            .sort_values(by=["expectancy"], ascending=False)
+            .reset_index()
+        )
 
         final = {}
         for x in df.itertuples():
             final[x.pair] = PairInfo(
                 x.stoploss,
                 x.winrate,
                 x.risk_reward_ratio,
                 x.required_risk_reward,
                 x.expectancy,
                 x.nb_trades,
-                x.avg_trade_duration
+                x.avg_trade_duration,
             )
 
         # Returning a list of pairs in order of "expectancy"
         return final
 
     def _find_trades_for_stoploss_range(self, df, pair: str, stoploss_range) -> list:
-        buy_column = df['enter_long'].values
-        sell_column = df['exit_long'].values
-        date_column = df['date'].values
-        ohlc_columns = df[['open', 'high', 'low', 'close']].values
+        buy_column = df["enter_long"].values
+        sell_column = df["exit_long"].values
+        date_column = df["date"].values
+        ohlc_columns = df[["open", "high", "low", "close"]].values
 
         result: list = []
         for stoploss in stoploss_range:
             result += self._detect_next_stop_or_sell_point(
                 buy_column, sell_column, date_column, ohlc_columns, round(stoploss, 6), pair
             )
 
         return result
 
-    def _detect_next_stop_or_sell_point(self, buy_column, sell_column, date_column,
-                                        ohlc_columns, stoploss, pair: str):
+    def _detect_next_stop_or_sell_point(
+        self, buy_column, sell_column, date_column, ohlc_columns, stoploss, pair: str
+    ):
         """
         Iterate through ohlc_columns in order to find the next trade
         Next trade opens from the first buy signal noticed to
         The sell or stoploss signal after it.
         It then cuts OHLC, buy_column, sell_column and date_column.
         Cut from (the exit trade index) + 1.
 
@@ -425,35 +456,36 @@
                 break
             else:
                 # When a buy signal is seen,
                 # trade opens in reality on the next candle
                 open_trade_index += 1
 
             open_price = ohlc_columns[open_trade_index, 0]
-            stop_price = (open_price * (stoploss + 1))
+            stop_price = open_price * (stoploss + 1)
 
             # Searching for the index where stoploss is hit
             stop_index = utf1st.find_1st(
-                ohlc_columns[open_trade_index:, 2], stop_price, utf1st.cmp_smaller)
+                ohlc_columns[open_trade_index:, 2], stop_price, utf1st.cmp_smaller
+            )
 
             # If we don't find it then we assume stop_index will be far in future (infinite number)
             if stop_index == -1:
-                stop_index = float('inf')
+                stop_index = float("inf")
 
             # Searching for the index where sell is hit
             sell_index = utf1st.find_1st(sell_column[open_trade_index:], 1, utf1st.cmp_equal)
 
             # If we don't find it then we assume sell_index will be far in future (infinite number)
             if sell_index == -1:
-                sell_index = float('inf')
+                sell_index = float("inf")
 
             # Check if we don't find any stop or sell point (in that case trade remains open)
             # It is not interesting for Edge to consider it so we simply ignore the trade
             # And stop iterating there is no more entry
-            if stop_index == sell_index == float('inf'):
+            if stop_index == sell_index == float("inf"):
                 break
 
             if stop_index <= sell_index:
                 exit_index = open_trade_index + stop_index
                 exit_type = ExitType.STOP_LOSS
                 exit_price = stop_price
             elif stop_index > sell_index:
@@ -463,25 +495,26 @@
                 # Check if we have the next candle
                 if len(ohlc_columns) - 1 < exit_index:
                     break
 
                 exit_type = ExitType.EXIT_SIGNAL
                 exit_price = ohlc_columns[exit_index, 0]
 
-            trade = {'pair': pair,
-                     'stoploss': stoploss,
-                     'profit_ratio': '',
-                     'profit_abs': '',
-                     'open_date': date_column[open_trade_index],
-                     'close_date': date_column[exit_index],
-                     'trade_duration': '',
-                     'open_rate': round(open_price, 15),
-                     'close_rate': round(exit_price, 15),
-                     'exit_type': exit_type
-                     }
+            trade = {
+                "pair": pair,
+                "stoploss": stoploss,
+                "profit_ratio": "",
+                "profit_abs": "",
+                "open_date": date_column[open_trade_index],
+                "close_date": date_column[exit_index],
+                "trade_duration": "",
+                "open_rate": round(open_price, 15),
+                "close_rate": round(exit_price, 15),
+                "exit_type": exit_type,
+            }
 
             result.append(trade)
 
             # Giving a view of exit_index till the end of array
             buy_column = buy_column[exit_index:]
             sell_column = sell_column[exit_index:]
             date_column = date_column[exit_index:]
```

### Comparing `freqtrade-2024.4/freqtrade/enums/__init__.py` & `freqtrade-2024.5/freqtrade/enums/__init__.py`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/enums/candletype.py` & `freqtrade-2024.5/freqtrade/enums/candletype.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,30 +1,31 @@
 from enum import Enum
 
 
 class CandleType(str, Enum):
     """Enum to distinguish candle types"""
+
     SPOT = "spot"
     FUTURES = "futures"
     MARK = "mark"
     INDEX = "index"
     PREMIUMINDEX = "premiumIndex"
 
     # TODO: Could take up less memory if these weren't a CandleType
     FUNDING_RATE = "funding_rate"
     # BORROW_RATE = "borrow_rate"  # * unimplemented
 
     def __str__(self):
         return f"{self.name.lower()}"
 
     @staticmethod
-    def from_string(value: str) -> 'CandleType':
+    def from_string(value: str) -> "CandleType":
         if not value:
             # Default to spot
             return CandleType.SPOT
         return CandleType(value)
 
     @staticmethod
-    def get_default(trading_mode: str) -> 'CandleType':
-        if trading_mode == 'futures':
+    def get_default(trading_mode: str) -> "CandleType":
+        if trading_mode == "futures":
             return CandleType.FUTURES
         return CandleType.SPOT
```

### Comparing `freqtrade-2024.4/freqtrade/enums/exitchecktuple.py` & `freqtrade-2024.5/freqtrade/enums/exitchecktuple.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,19 @@
 from freqtrade.enums.exittype import ExitType
 
 
 class ExitCheckTuple:
     """
     NamedTuple for Exit type + reason
     """
+
     exit_type: ExitType
-    exit_reason: str = ''
+    exit_reason: str = ""
 
-    def __init__(self, exit_type: ExitType, exit_reason: str = ''):
+    def __init__(self, exit_type: ExitType, exit_reason: str = ""):
         self.exit_type = exit_type
         self.exit_reason = exit_reason or exit_type.value
 
     @property
     def exit_flag(self):
         return self.exit_type != ExitType.NONE
```

### Comparing `freqtrade-2024.4/freqtrade/enums/exittype.py` & `freqtrade-2024.5/freqtrade/enums/exittype.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 from enum import Enum
 
 
 class ExitType(Enum):
     """
     Enum to distinguish between exit reasons
     """
+
     ROI = "roi"
     STOP_LOSS = "stop_loss"
     STOPLOSS_ON_EXCHANGE = "stoploss_on_exchange"
     TRAILING_STOP_LOSS = "trailing_stop_loss"
     LIQUIDATION = "liquidation"
     EXIT_SIGNAL = "exit_signal"
     FORCE_EXIT = "force_exit"
```

### Comparing `freqtrade-2024.4/freqtrade/enums/rpcmessagetype.py` & `freqtrade-2024.5/freqtrade/enums/rpcmessagetype.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,45 +1,45 @@
 from enum import Enum
 
 
 class RPCMessageType(str, Enum):
-    STATUS = 'status'
-    WARNING = 'warning'
-    EXCEPTION = 'exception'
-    STARTUP = 'startup'
-
-    ENTRY = 'entry'
-    ENTRY_FILL = 'entry_fill'
-    ENTRY_CANCEL = 'entry_cancel'
-
-    EXIT = 'exit'
-    EXIT_FILL = 'exit_fill'
-    EXIT_CANCEL = 'exit_cancel'
-
-    PROTECTION_TRIGGER = 'protection_trigger'
-    PROTECTION_TRIGGER_GLOBAL = 'protection_trigger_global'
-
-    STRATEGY_MSG = 'strategy_msg'
-
-    WHITELIST = 'whitelist'
-    ANALYZED_DF = 'analyzed_df'
-    NEW_CANDLE = 'new_candle'
+    STATUS = "status"
+    WARNING = "warning"
+    EXCEPTION = "exception"
+    STARTUP = "startup"
+
+    ENTRY = "entry"
+    ENTRY_FILL = "entry_fill"
+    ENTRY_CANCEL = "entry_cancel"
+
+    EXIT = "exit"
+    EXIT_FILL = "exit_fill"
+    EXIT_CANCEL = "exit_cancel"
+
+    PROTECTION_TRIGGER = "protection_trigger"
+    PROTECTION_TRIGGER_GLOBAL = "protection_trigger_global"
+
+    STRATEGY_MSG = "strategy_msg"
+
+    WHITELIST = "whitelist"
+    ANALYZED_DF = "analyzed_df"
+    NEW_CANDLE = "new_candle"
 
     def __repr__(self):
         return self.value
 
     def __str__(self):
         return self.value
 
 
 # Enum for parsing requests from ws consumers
 class RPCRequestType(str, Enum):
-    SUBSCRIBE = 'subscribe'
+    SUBSCRIBE = "subscribe"
 
-    WHITELIST = 'whitelist'
-    ANALYZED_DF = 'analyzed_df'
+    WHITELIST = "whitelist"
+    ANALYZED_DF = "analyzed_df"
 
     def __str__(self):
         return self.value
 
 
 NO_ECHO_MESSAGES = (RPCMessageType.ANALYZED_DF, RPCMessageType.WHITELIST, RPCMessageType.NEW_CANDLE)
```

### Comparing `freqtrade-2024.4/freqtrade/enums/runmode.py` & `freqtrade-2024.5/freqtrade/enums/runmode.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 
 class RunMode(Enum):
     """
     Bot running mode (backtest, hyperopt, ...)
     can be "live", "dry-run", "backtest", "edge", "hyperopt".
     """
+
     LIVE = "live"
     DRY_RUN = "dry_run"
     BACKTEST = "backtest"
     EDGE = "edge"
     HYPEROPT = "hyperopt"
     UTIL_EXCHANGE = "util_exchange"
     UTIL_NO_EXCHANGE = "util_no_exchange"
```

### Comparing `freqtrade-2024.4/freqtrade/enums/signaltype.py` & `freqtrade-2024.5/freqtrade/enums/signaltype.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,33 +1,35 @@
 from enum import Enum
 
 
 class SignalType(Enum):
     """
     Enum to distinguish between enter and exit signals
     """
+
     ENTER_LONG = "enter_long"
     EXIT_LONG = "exit_long"
     ENTER_SHORT = "enter_short"
     EXIT_SHORT = "exit_short"
 
     def __str__(self):
         return f"{self.name.lower()}"
 
 
 class SignalTagType(Enum):
     """
     Enum for signal columns
     """
+
     ENTER_TAG = "enter_tag"
     EXIT_TAG = "exit_tag"
 
     def __str__(self):
         return f"{self.name.lower()}"
 
 
 class SignalDirection(str, Enum):
-    LONG = 'long'
-    SHORT = 'short'
+    LONG = "long"
+    SHORT = "short"
 
     def __str__(self):
         return f"{self.name.lower()}"
```

### Comparing `freqtrade-2024.4/freqtrade/exceptions.py` & `freqtrade-2024.5/freqtrade/exceptions.py`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/exchange/__init__.py` & `freqtrade-2024.5/freqtrade/exchange/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,31 +1,44 @@
 # flake8: noqa: F401
 # isort: off
 from freqtrade.exchange.common import remove_exchange_credentials, MAP_EXCHANGE_CHILDCLASS
 from freqtrade.exchange.exchange import Exchange
+
 # isort: on
 from freqtrade.exchange.binance import Binance
 from freqtrade.exchange.bingx import Bingx
 from freqtrade.exchange.bitmart import Bitmart
 from freqtrade.exchange.bitpanda import Bitpanda
 from freqtrade.exchange.bitvavo import Bitvavo
 from freqtrade.exchange.bybit import Bybit
 from freqtrade.exchange.coinbasepro import Coinbasepro
-from freqtrade.exchange.exchange_utils import (ROUND_DOWN, ROUND_UP, amount_to_contract_precision,
-                                               amount_to_contracts, amount_to_precision,
-                                               available_exchanges, ccxt_exchanges,
-                                               contracts_to_amount, date_minus_candles,
-                                               is_exchange_known_ccxt, list_available_exchanges,
-                                               market_is_active, price_to_precision,
-                                               validate_exchange)
-from freqtrade.exchange.exchange_utils_timeframe import (timeframe_to_minutes, timeframe_to_msecs,
-                                                         timeframe_to_next_date,
-                                                         timeframe_to_prev_date,
-                                                         timeframe_to_resample_freq,
-                                                         timeframe_to_seconds)
+from freqtrade.exchange.exchange_utils import (
+    ROUND_DOWN,
+    ROUND_UP,
+    amount_to_contract_precision,
+    amount_to_contracts,
+    amount_to_precision,
+    available_exchanges,
+    ccxt_exchanges,
+    contracts_to_amount,
+    date_minus_candles,
+    is_exchange_known_ccxt,
+    list_available_exchanges,
+    market_is_active,
+    price_to_precision,
+    validate_exchange,
+)
+from freqtrade.exchange.exchange_utils_timeframe import (
+    timeframe_to_minutes,
+    timeframe_to_msecs,
+    timeframe_to_next_date,
+    timeframe_to_prev_date,
+    timeframe_to_resample_freq,
+    timeframe_to_seconds,
+)
 from freqtrade.exchange.gate import Gate
 from freqtrade.exchange.hitbtc import Hitbtc
 from freqtrade.exchange.htx import Htx
 from freqtrade.exchange.idex import Idex
 from freqtrade.exchange.kraken import Kraken
 from freqtrade.exchange.kucoin import Kucoin
 from freqtrade.exchange.okx import Okx
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/binance.py` & `freqtrade-2024.5/freqtrade/exchange/binance.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-""" Binance exchange subclass """
+"""Binance exchange subclass"""
+
 import logging
 from datetime import datetime, timezone
 from pathlib import Path
 from typing import Dict, List, Optional, Tuple
 
 import ccxt
 
@@ -14,15 +15,14 @@
 from freqtrade.misc import deep_merge_dicts, json_load
 
 
 logger = logging.getLogger(__name__)
 
 
 class Binance(Exchange):
-
     _ft_has: Dict = {
         "stoploss_on_exchange": True,
         "stop_price_param": "stopPrice",
         "stop_price_prop": "stopPrice",
         "stoploss_order_types": {"limit": "stop_loss_limit"},
         "order_time_in_force": ["GTC", "FOK", "IOC", "PO"],
         "ohlcv_candle_limit": 1000,
@@ -32,15 +32,15 @@
     }
     _ft_has_futures: Dict = {
         "stoploss_order_types": {"limit": "stop", "market": "stop_market"},
         "order_time_in_force": ["GTC", "FOK", "IOC"],
         "tickers_have_price": False,
         "floor_leverage": True,
         "stop_price_type_field": "workingType",
-        "order_props_in_contracts": ['amount', 'cost', 'filled', 'remaining'],
+        "order_props_in_contracts": ["amount", "cost", "filled", "remaining"],
         "stop_price_type_value_mapping": {
             PriceType.LAST: "CONTRACT_PRICE",
             PriceType.MARK: "MARK_PRICE",
         },
     }
 
     _supported_trading_mode_margin_pairs: List[Tuple[TradingMode, MarginMode]] = [
@@ -63,57 +63,66 @@
     def additional_exchange_init(self) -> None:
         """
         Additional exchange initialization logic.
         .api will be available at this point.
         Must be overridden in child methods if required.
         """
         try:
-            if self.trading_mode == TradingMode.FUTURES and not self._config['dry_run']:
+            if self.trading_mode == TradingMode.FUTURES and not self._config["dry_run"]:
                 position_side = self._api.fapiPrivateGetPositionSideDual()
-                self._log_exchange_response('position_side_setting', position_side)
+                self._log_exchange_response("position_side_setting", position_side)
                 assets_margin = self._api.fapiPrivateGetMultiAssetsMargin()
-                self._log_exchange_response('multi_asset_margin', assets_margin)
+                self._log_exchange_response("multi_asset_margin", assets_margin)
                 msg = ""
-                if position_side.get('dualSidePosition') is True:
+                if position_side.get("dualSidePosition") is True:
                     msg += (
                         "\nHedge Mode is not supported by freqtrade. "
-                        "Please change 'Position Mode' on your binance futures account.")
-                if assets_margin.get('multiAssetsMargin') is True:
-                    msg += ("\nMulti-Asset Mode is not supported by freqtrade. "
-                            "Please change 'Asset Mode' on your binance futures account.")
+                        "Please change 'Position Mode' on your binance futures account."
+                    )
+                if assets_margin.get("multiAssetsMargin") is True:
+                    msg += (
+                        "\nMulti-Asset Mode is not supported by freqtrade. "
+                        "Please change 'Asset Mode' on your binance futures account."
+                    )
                 if msg:
                     raise OperationalException(msg)
         except ccxt.DDoSProtection as e:
             raise DDosProtection(e) from e
         except (ccxt.OperationFailed, ccxt.ExchangeError) as e:
             raise TemporaryError(
-                f'Error in additional_exchange_init due to {e.__class__.__name__}. Message: {e}'
-                ) from e
+                f"Error in additional_exchange_init due to {e.__class__.__name__}. Message: {e}"
+            ) from e
 
         except ccxt.BaseError as e:
             raise OperationalException(e) from e
 
-    async def _async_get_historic_ohlcv(self, pair: str, timeframe: str,
-                                        since_ms: int, candle_type: CandleType,
-                                        is_new_pair: bool = False, raise_: bool = False,
-                                        until_ms: Optional[int] = None
-                                        ) -> OHLCVResponse:
+    async def _async_get_historic_ohlcv(
+        self,
+        pair: str,
+        timeframe: str,
+        since_ms: int,
+        candle_type: CandleType,
+        is_new_pair: bool = False,
+        raise_: bool = False,
+        until_ms: Optional[int] = None,
+    ) -> OHLCVResponse:
         """
         Overwrite to introduce "fast new pair" functionality by detecting the pair's listing date
         Does not work for other exchanges, which don't return the earliest data when called with "0"
         :param candle_type: Any of the enum CandleType (must match trading mode!)
         """
         if is_new_pair:
             x = await self._async_get_candle_history(pair, timeframe, candle_type, 0)
             if x and x[3] and x[3][0] and x[3][0][0] > since_ms:
                 # Set starting date to first available candle.
                 since_ms = x[3][0][0]
                 logger.info(
                     f"Candle-data for {pair} available starting with "
-                    f"{datetime.fromtimestamp(since_ms // 1000, tz=timezone.utc).isoformat()}.")
+                    f"{datetime.fromtimestamp(since_ms // 1000, tz=timezone.utc).isoformat()}."
+                )
 
         return await super()._async_get_historic_ohlcv(
             pair=pair,
             timeframe=timeframe,
             since_ms=since_ms,
             is_new_pair=is_new_pair,
             raise_=raise_,
@@ -131,15 +140,15 @@
         :return: True if the date falls on a full hour, False otherwise
         """
         return open_date.minute == 0 and open_date.second < 15
 
     def dry_run_liquidation_price(
         self,
         pair: str,
-        open_rate: float,   # Entry price of position
+        open_rate: float,  # Entry price of position
         is_short: bool,
         amount: float,
         stake_amount: float,
         leverage: float,
         wallet_balance: float,  # Or margin balance
         mm_ex_1: float = 0.0,  # (Binance) Cross only
         upnl_ex_1: float = 0.0,  # (Binance) Cross only
@@ -173,47 +182,32 @@
         side_1 = -1 if is_short else 1
         cross_vars = upnl_ex_1 - mm_ex_1 if self.margin_mode == MarginMode.CROSS else 0.0
 
         # mm_ratio: Binance's formula specifies maintenance margin rate which is mm_ratio * 100%
         # maintenance_amt: (CUM) Maintenance Amount of position
         mm_ratio, maintenance_amt = self.get_maintenance_ratio_and_amt(pair, stake_amount)
 
-        if (maintenance_amt is None):
+        if maintenance_amt is None:
             raise OperationalException(
                 "Parameter maintenance_amt is required by Binance.liquidation_price"
                 f"for {self.trading_mode.value}"
             )
 
         if self.trading_mode == TradingMode.FUTURES:
             return (
-                (
-                    (wallet_balance + cross_vars + maintenance_amt) -
-                    (side_1 * amount * open_rate)
-                ) / (
-                    (amount * mm_ratio) - (side_1 * amount)
-                )
-            )
+                (wallet_balance + cross_vars + maintenance_amt) - (side_1 * amount * open_rate)
+            ) / ((amount * mm_ratio) - (side_1 * amount))
         else:
             raise OperationalException(
-                "Freqtrade only supports isolated futures for leverage trading")
+                "Freqtrade only supports isolated futures for leverage trading"
+            )
 
-    @retrier
     def load_leverage_tiers(self) -> Dict[str, List[Dict]]:
         if self.trading_mode == TradingMode.FUTURES:
-            if self._config['dry_run']:
-                leverage_tiers_path = (
-                    Path(__file__).parent / 'binance_leverage_tiers.json'
-                )
+            if self._config["dry_run"]:
+                leverage_tiers_path = Path(__file__).parent / "binance_leverage_tiers.json"
                 with leverage_tiers_path.open() as json_file:
                     return json_load(json_file)
             else:
-                try:
-                    return self._api.fetch_leverage_tiers()
-                except ccxt.DDoSProtection as e:
-                    raise DDosProtection(e) from e
-                except (ccxt.OperationFailed, ccxt.ExchangeError) as e:
-                    raise TemporaryError(f'Could not fetch leverage amounts due to'
-                                         f'{e.__class__.__name__}. Message: {e}') from e
-                except ccxt.BaseError as e:
-                    raise OperationalException(e) from e
+                return self.get_leverage_tiers()
         else:
             return {}
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/binance_leverage_tiers.json` & `freqtrade-2024.5/freqtrade/exchange/binance_leverage_tiers.json`

 * *Files 0% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9464504204459561%*

 * *Differences: {"'1000BONK/USDC:USDC'": "[OrderedDict([('tier', 1.0), ('currency', 'USDC'), ('minNotional', 0.0), "*

 * *                         "('maxNotional', 5000.0), ('maintenanceMarginRate', 0.01), "*

 * *                         "('maxLeverage', 50.0), ('info', OrderedDict([('bracket', '1'), "*

 * *                         "('initialLeverage', '50'), ('notionalCap', '5000'), ('notionalFloor', "*

 * *                         "'0'), ('maintMarginRatio', '0.01'), ('cum', '0.0')]))]), "*

 * *                         "OrderedDict([('tier', 2.0 []*

```diff
@@ -1,8 +1,138 @@
 {
+    "1000BONK/USDC:USDC": [
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "1",
+                "cum": "0.0",
+                "initialLeverage": "50",
+                "maintMarginRatio": "0.01",
+                "notionalCap": "5000",
+                "notionalFloor": "0"
+            },
+            "maintenanceMarginRate": 0.01,
+            "maxLeverage": 50.0,
+            "maxNotional": 5000.0,
+            "minNotional": 0.0,
+            "tier": 1.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "2",
+                "cum": "50.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "50000",
+                "notionalFloor": "5000"
+            },
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 50000.0,
+            "minNotional": 5000.0,
+            "tier": 2.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "3",
+                "cum": "300.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "600000",
+                "notionalFloor": "50000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 600000.0,
+            "minNotional": 50000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "4",
+                "cum": "15300.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
+                "notionalCap": "1200000",
+                "notionalFloor": "600000"
+            },
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
+            "maxNotional": 1200000.0,
+            "minNotional": 600000.0,
+            "tier": 4.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "5",
+                "cum": "75300.0",
+                "initialLeverage": "5",
+                "maintMarginRatio": "0.1",
+                "notionalCap": "3000000",
+                "notionalFloor": "1200000"
+            },
+            "maintenanceMarginRate": 0.1,
+            "maxLeverage": 5.0,
+            "maxNotional": 3000000.0,
+            "minNotional": 1200000.0,
+            "tier": 5.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "6",
+                "cum": "150300.0",
+                "initialLeverage": "4",
+                "maintMarginRatio": "0.125",
+                "notionalCap": "4000000",
+                "notionalFloor": "3000000"
+            },
+            "maintenanceMarginRate": 0.125,
+            "maxLeverage": 4.0,
+            "maxNotional": 4000000.0,
+            "minNotional": 3000000.0,
+            "tier": 6.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "7",
+                "cum": "650300.0",
+                "initialLeverage": "2",
+                "maintMarginRatio": "0.25",
+                "notionalCap": "6000000",
+                "notionalFloor": "4000000"
+            },
+            "maintenanceMarginRate": 0.25,
+            "maxLeverage": 2.0,
+            "maxNotional": 6000000.0,
+            "minNotional": 4000000.0,
+            "tier": 7.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "8",
+                "cum": "2150300.0",
+                "initialLeverage": "1",
+                "maintMarginRatio": "0.5",
+                "notionalCap": "10000000",
+                "notionalFloor": "6000000"
+            },
+            "maintenanceMarginRate": 0.5,
+            "maxLeverage": 1.0,
+            "maxNotional": 10000000.0,
+            "minNotional": 6000000.0,
+            "tier": 8.0
+        }
+    ],
     "1000BONK/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -507,117 +637,117 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "2",
                 "cum": "25.0",
                 "initialLeverage": "25",
                 "maintMarginRatio": "0.02",
-                "notionalCap": "10000",
+                "notionalCap": "50000",
                 "notionalFloor": "5000"
             },
             "maintenanceMarginRate": 0.02,
             "maxLeverage": 25.0,
-            "maxNotional": 10000.0,
+            "maxNotional": 50000.0,
             "minNotional": 5000.0,
             "tier": 2.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "3",
-                "cum": "75.0",
+                "cum": "275.0",
                 "initialLeverage": "20",
                 "maintMarginRatio": "0.025",
-                "notionalCap": "50000",
-                "notionalFloor": "10000"
+                "notionalCap": "200000",
+                "notionalFloor": "50000"
             },
             "maintenanceMarginRate": 0.025,
             "maxLeverage": 20.0,
-            "maxNotional": 50000.0,
-            "minNotional": 10000.0,
+            "maxNotional": 200000.0,
+            "minNotional": 50000.0,
             "tier": 3.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "4",
-                "cum": "1325.0",
+                "cum": "5275.0",
                 "initialLeverage": "10",
                 "maintMarginRatio": "0.05",
-                "notionalCap": "1200000",
-                "notionalFloor": "50000"
+                "notionalCap": "2000000",
+                "notionalFloor": "200000"
             },
             "maintenanceMarginRate": 0.05,
             "maxLeverage": 10.0,
-            "maxNotional": 1200000.0,
-            "minNotional": 50000.0,
+            "maxNotional": 2000000.0,
+            "minNotional": 200000.0,
             "tier": 4.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "5",
-                "cum": "61325.0",
+                "cum": "105275.0",
                 "initialLeverage": "5",
                 "maintMarginRatio": "0.1",
-                "notionalCap": "3000000",
-                "notionalFloor": "1200000"
+                "notionalCap": "4000000",
+                "notionalFloor": "2000000"
             },
             "maintenanceMarginRate": 0.1,
             "maxLeverage": 5.0,
-            "maxNotional": 3000000.0,
-            "minNotional": 1200000.0,
+            "maxNotional": 4000000.0,
+            "minNotional": 2000000.0,
             "tier": 5.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "6",
-                "cum": "136325.0",
+                "cum": "205275.0",
                 "initialLeverage": "4",
                 "maintMarginRatio": "0.125",
-                "notionalCap": "3600000",
-                "notionalFloor": "3000000"
+                "notionalCap": "5000000",
+                "notionalFloor": "4000000"
             },
             "maintenanceMarginRate": 0.125,
             "maxLeverage": 4.0,
-            "maxNotional": 3600000.0,
-            "minNotional": 3000000.0,
+            "maxNotional": 5000000.0,
+            "minNotional": 4000000.0,
             "tier": 6.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "7",
-                "cum": "586325.0",
+                "cum": "830275.0",
                 "initialLeverage": "2",
                 "maintMarginRatio": "0.25",
-                "notionalCap": "9000000",
-                "notionalFloor": "3600000"
+                "notionalCap": "10000000",
+                "notionalFloor": "5000000"
             },
             "maintenanceMarginRate": 0.25,
             "maxLeverage": 2.0,
-            "maxNotional": 9000000.0,
-            "minNotional": 3600000.0,
+            "maxNotional": 10000000.0,
+            "minNotional": 5000000.0,
             "tier": 7.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "8",
-                "cum": "2836325.0",
+                "cum": "3330275.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "15000000",
-                "notionalFloor": "9000000"
+                "notionalCap": "20000000",
+                "notionalFloor": "10000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 15000000.0,
-            "minNotional": 9000000.0,
+            "maxNotional": 20000000.0,
+            "minNotional": 10000000.0,
             "tier": 8.0
         }
     ],
     "1000RATS/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
@@ -3037,112 +3167,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 10000000.0,
             "minNotional": 6000000.0,
             "tier": 7.0
         }
     ],
-    "ANT/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "21",
-                "maintMarginRatio": "0.015",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.015,
-            "maxLeverage": 21.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "50.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 20.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "675.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 10.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "5675.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "250000",
-                "notionalFloor": "100000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 250000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "11925.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "250000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 250000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "386925.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "1500000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 1500000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
-        }
-    ],
     "APE/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -4697,112 +4729,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 3000000.0,
             "minNotional": 1500000.0,
             "tier": 8.0
         }
     ],
-    "AUDIO/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.02",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.02,
-            "maxLeverage": 20.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "25.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 10.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "650.0",
-                "initialLeverage": "8",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 8.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "5650.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "250000",
-                "notionalFloor": "100000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 250000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "11900.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "250000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 250000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "386900.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "3000000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 3000000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
-        }
-    ],
     "AVAX/USDC:USDC": [
         {
             "currency": "USDC",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "75",
@@ -5917,14 +5851,128 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 5000000.0,
             "minNotional": 1000000.0,
             "tier": 6.0
         }
     ],
+    "BB/USDT:USDT": [
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "1",
+                "cum": "0.0",
+                "initialLeverage": "50",
+                "maintMarginRatio": "0.015",
+                "notionalCap": "5000",
+                "notionalFloor": "0"
+            },
+            "maintenanceMarginRate": 0.015,
+            "maxLeverage": 50.0,
+            "maxNotional": 5000.0,
+            "minNotional": 0.0,
+            "tier": 1.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "2",
+                "cum": "50.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "25000",
+                "notionalFloor": "5000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 25000.0,
+            "minNotional": 5000.0,
+            "tier": 2.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "3",
+                "cum": "675.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
+                "notionalCap": "100000",
+                "notionalFloor": "25000"
+            },
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
+            "maxNotional": 100000.0,
+            "minNotional": 25000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "4",
+                "cum": "5675.0",
+                "initialLeverage": "5",
+                "maintMarginRatio": "0.1",
+                "notionalCap": "200000",
+                "notionalFloor": "100000"
+            },
+            "maintenanceMarginRate": 0.1,
+            "maxLeverage": 5.0,
+            "maxNotional": 200000.0,
+            "minNotional": 100000.0,
+            "tier": 4.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "5",
+                "cum": "10675.0",
+                "initialLeverage": "4",
+                "maintMarginRatio": "0.125",
+                "notionalCap": "500000",
+                "notionalFloor": "200000"
+            },
+            "maintenanceMarginRate": 0.125,
+            "maxLeverage": 4.0,
+            "maxNotional": 500000.0,
+            "minNotional": 200000.0,
+            "tier": 5.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "6",
+                "cum": "73175.0",
+                "initialLeverage": "2",
+                "maintMarginRatio": "0.25",
+                "notionalCap": "1000000",
+                "notionalFloor": "500000"
+            },
+            "maintenanceMarginRate": 0.25,
+            "maxLeverage": 2.0,
+            "maxNotional": 1000000.0,
+            "minNotional": 500000.0,
+            "tier": 6.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "7",
+                "cum": "323175.0",
+                "initialLeverage": "1",
+                "maintMarginRatio": "0.5",
+                "notionalCap": "2000000",
+                "notionalFloor": "1000000"
+            },
+            "maintenanceMarginRate": 0.5,
+            "maxLeverage": 1.0,
+            "maxNotional": 2000000.0,
+            "minNotional": 1000000.0,
+            "tier": 7.0
+        }
+    ],
     "BCH/USDC:USDC": [
         {
             "currency": "USDC",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "75",
@@ -6681,112 +6729,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 3000000.0,
             "minNotional": 1500000.0,
             "tier": 7.0
         }
     ],
-    "BLUEBIRD/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "11",
-                "maintMarginRatio": "0.01",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.01,
-            "maxLeverage": 11.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "75.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 10.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "700.0",
-                "initialLeverage": "8",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 8.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "5700.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "250000",
-                "notionalFloor": "100000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 250000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "11950.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "250000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 250000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "386950.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "1500000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 1500000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
-        }
-    ],
     "BLUR/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -8217,150 +8167,182 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "2",
                 "cum": "50.0",
                 "initialLeverage": "100",
                 "maintMarginRatio": "0.005",
-                "notionalCap": "500000",
+                "notionalCap": "600000",
                 "notionalFloor": "50000"
             },
             "maintenanceMarginRate": 0.005,
             "maxLeverage": 100.0,
-            "maxNotional": 500000.0,
+            "maxNotional": 600000.0,
             "minNotional": 50000.0,
             "tier": 2.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "3",
-                "cum": "2550.0",
+                "cum": "950.0",
+                "initialLeverage": "75",
+                "maintMarginRatio": "0.0065",
+                "notionalCap": "3000000",
+                "notionalFloor": "600000"
+            },
+            "maintenanceMarginRate": 0.0065,
+            "maxLeverage": 75.0,
+            "maxNotional": 3000000.0,
+            "minNotional": 600000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "4",
+                "cum": "11450.0",
                 "initialLeverage": "50",
                 "maintMarginRatio": "0.01",
-                "notionalCap": "10000000",
-                "notionalFloor": "500000"
+                "notionalCap": "12000000",
+                "notionalFloor": "3000000"
             },
             "maintenanceMarginRate": 0.01,
             "maxLeverage": 50.0,
-            "maxNotional": 10000000.0,
-            "minNotional": 500000.0,
-            "tier": 3.0
+            "maxNotional": 12000000.0,
+            "minNotional": 3000000.0,
+            "tier": 4.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "4",
-                "cum": "152550.0",
+                "bracket": "5",
+                "cum": "131450.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "70000000",
+                "notionalFloor": "12000000"
+            },
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 70000000.0,
+            "minNotional": 12000000.0,
+            "tier": 5.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "6",
+                "cum": "481450.0",
                 "initialLeverage": "20",
                 "maintMarginRatio": "0.025",
-                "notionalCap": "80000000",
-                "notionalFloor": "10000000"
+                "notionalCap": "100000000",
+                "notionalFloor": "70000000"
             },
             "maintenanceMarginRate": 0.025,
             "maxLeverage": 20.0,
-            "maxNotional": 80000000.0,
-            "minNotional": 10000000.0,
-            "tier": 4.0
+            "maxNotional": 100000000.0,
+            "minNotional": 70000000.0,
+            "tier": 6.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "5",
-                "cum": "2152550.0",
+                "bracket": "7",
+                "cum": "2981450.0",
                 "initialLeverage": "10",
                 "maintMarginRatio": "0.05",
-                "notionalCap": "150000000",
-                "notionalFloor": "80000000"
+                "notionalCap": "230000000",
+                "notionalFloor": "100000000"
             },
             "maintenanceMarginRate": 0.05,
             "maxLeverage": 10.0,
-            "maxNotional": 150000000.0,
-            "minNotional": 80000000.0,
-            "tier": 5.0
+            "maxNotional": 230000000.0,
+            "minNotional": 100000000.0,
+            "tier": 7.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "6",
-                "cum": "9652550.0",
+                "bracket": "8",
+                "cum": "14481450.0",
                 "initialLeverage": "5",
                 "maintMarginRatio": "0.1",
-                "notionalCap": "300000000",
-                "notionalFloor": "150000000"
+                "notionalCap": "480000000",
+                "notionalFloor": "230000000"
             },
             "maintenanceMarginRate": 0.1,
             "maxLeverage": 5.0,
-            "maxNotional": 300000000.0,
-            "minNotional": 150000000.0,
-            "tier": 6.0
+            "maxNotional": 480000000.0,
+            "minNotional": 230000000.0,
+            "tier": 8.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "7",
-                "cum": "17152550.0",
+                "bracket": "9",
+                "cum": "26481450.0",
                 "initialLeverage": "4",
                 "maintMarginRatio": "0.125",
-                "notionalCap": "450000000",
-                "notionalFloor": "300000000"
+                "notionalCap": "600000000",
+                "notionalFloor": "480000000"
             },
             "maintenanceMarginRate": 0.125,
             "maxLeverage": 4.0,
-            "maxNotional": 450000000.0,
-            "minNotional": 300000000.0,
-            "tier": 7.0
+            "maxNotional": 600000000.0,
+            "minNotional": 480000000.0,
+            "tier": 9.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "8",
-                "cum": "28402550.0",
+                "bracket": "10",
+                "cum": "41481450.0",
                 "initialLeverage": "3",
                 "maintMarginRatio": "0.15",
-                "notionalCap": "600000000",
-                "notionalFloor": "450000000"
+                "notionalCap": "800000000",
+                "notionalFloor": "600000000"
             },
             "maintenanceMarginRate": 0.15,
             "maxLeverage": 3.0,
-            "maxNotional": 600000000.0,
-            "minNotional": 450000000.0,
-            "tier": 8.0
+            "maxNotional": 800000000.0,
+            "minNotional": 600000000.0,
+            "tier": 10.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "9",
-                "cum": "88402550.0",
+                "bracket": "11",
+                "cum": "121481450.0",
                 "initialLeverage": "2",
                 "maintMarginRatio": "0.25",
-                "notionalCap": "800000000",
-                "notionalFloor": "600000000"
+                "notionalCap": "1200000000",
+                "notionalFloor": "800000000"
             },
             "maintenanceMarginRate": 0.25,
             "maxLeverage": 2.0,
-            "maxNotional": 800000000.0,
-            "minNotional": 600000000.0,
-            "tier": 9.0
+            "maxNotional": 1200000000.0,
+            "minNotional": 800000000.0,
+            "tier": 11.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "10",
-                "cum": "288402550.0",
+                "bracket": "12",
+                "cum": "421481450.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "1000000000",
-                "notionalFloor": "800000000"
+                "notionalCap": "1800000000",
+                "notionalFloor": "1200000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 1000000000.0,
-            "minNotional": 800000000.0,
-            "tier": 10.0
+            "maxNotional": 1800000000.0,
+            "minNotional": 1200000000.0,
+            "tier": 12.0
         }
     ],
     "BTC/USDT:USDT-240628": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
@@ -8811,112 +8793,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 9.223372036854776e+18,
             "minNotional": 1000000.0,
             "tier": 6.0
         }
     ],
-    "BTS/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "50",
-                "maintMarginRatio": "0.01",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.01,
-            "maxLeverage": 50.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "75.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 20.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "700.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 10.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "5700.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "250000",
-                "notionalFloor": "100000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 250000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "11950.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "250000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 250000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "386950.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "5000000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 5000000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
-        }
-    ],
     "C98/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "25",
@@ -9805,112 +9689,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 5000000.0,
             "minNotional": 3000000.0,
             "tier": 7.0
         }
     ],
-    "COCOS/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "8",
-                "maintMarginRatio": "0.02",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.02,
-            "maxLeverage": 8.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "25.0",
-                "initialLeverage": "7",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 7.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "650.0",
-                "initialLeverage": "6",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 6.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "5650.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "250000",
-                "notionalFloor": "100000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 250000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "11900.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "250000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 250000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "386900.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "1500000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 1500000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
-        }
-    ],
     "COMBO/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "20",
@@ -10709,20 +10495,20 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "5",
                 "cum": "386875.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "5000000",
+                "notionalCap": "2000000",
                 "notionalFloor": "1000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 5000000.0,
+            "maxNotional": 2000000.0,
             "minNotional": 1000000.0,
             "tier": 5.0
         }
     ],
     "CYBER/USDT:USDT": [
         {
             "currency": "USDT",
@@ -12541,14 +12327,144 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 10000000.0,
             "minNotional": 6000000.0,
             "tier": 7.0
         }
     ],
+    "ENA/USDC:USDC": [
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "1",
+                "cum": "0.0",
+                "initialLeverage": "50",
+                "maintMarginRatio": "0.01",
+                "notionalCap": "5000",
+                "notionalFloor": "0"
+            },
+            "maintenanceMarginRate": 0.01,
+            "maxLeverage": 50.0,
+            "maxNotional": 5000.0,
+            "minNotional": 0.0,
+            "tier": 1.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "2",
+                "cum": "50.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "50000",
+                "notionalFloor": "5000"
+            },
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 50000.0,
+            "minNotional": 5000.0,
+            "tier": 2.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "3",
+                "cum": "300.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "600000",
+                "notionalFloor": "50000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 600000.0,
+            "minNotional": 50000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "4",
+                "cum": "15300.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
+                "notionalCap": "1200000",
+                "notionalFloor": "600000"
+            },
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
+            "maxNotional": 1200000.0,
+            "minNotional": 600000.0,
+            "tier": 4.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "5",
+                "cum": "75300.0",
+                "initialLeverage": "5",
+                "maintMarginRatio": "0.1",
+                "notionalCap": "3000000",
+                "notionalFloor": "1200000"
+            },
+            "maintenanceMarginRate": 0.1,
+            "maxLeverage": 5.0,
+            "maxNotional": 3000000.0,
+            "minNotional": 1200000.0,
+            "tier": 5.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "6",
+                "cum": "150300.0",
+                "initialLeverage": "4",
+                "maintMarginRatio": "0.125",
+                "notionalCap": "4000000",
+                "notionalFloor": "3000000"
+            },
+            "maintenanceMarginRate": 0.125,
+            "maxLeverage": 4.0,
+            "maxNotional": 4000000.0,
+            "minNotional": 3000000.0,
+            "tier": 6.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "7",
+                "cum": "650300.0",
+                "initialLeverage": "2",
+                "maintMarginRatio": "0.25",
+                "notionalCap": "6000000",
+                "notionalFloor": "4000000"
+            },
+            "maintenanceMarginRate": 0.25,
+            "maxLeverage": 2.0,
+            "maxNotional": 6000000.0,
+            "minNotional": 4000000.0,
+            "tier": 7.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "8",
+                "cum": "2150300.0",
+                "initialLeverage": "1",
+                "maintMarginRatio": "0.5",
+                "notionalCap": "10000000",
+                "notionalFloor": "6000000"
+            },
+            "maintenanceMarginRate": 0.5,
+            "maxLeverage": 1.0,
+            "maxNotional": 10000000.0,
+            "minNotional": 6000000.0,
+            "tier": 8.0
+        }
+    ],
     "ENA/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -13587,166 +13503,182 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "2",
                 "cum": "50.0",
                 "initialLeverage": "100",
                 "maintMarginRatio": "0.005",
-                "notionalCap": "500000",
+                "notionalCap": "600000",
                 "notionalFloor": "50000"
             },
             "maintenanceMarginRate": 0.005,
             "maxLeverage": 100.0,
-            "maxNotional": 500000.0,
+            "maxNotional": 600000.0,
             "minNotional": 50000.0,
             "tier": 2.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "3",
-                "cum": "800.0",
+                "cum": "950.0",
                 "initialLeverage": "75",
                 "maintMarginRatio": "0.0065",
-                "notionalCap": "1000000",
-                "notionalFloor": "500000"
+                "notionalCap": "3000000",
+                "notionalFloor": "600000"
             },
             "maintenanceMarginRate": 0.0065,
             "maxLeverage": 75.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 500000.0,
+            "maxNotional": 3000000.0,
+            "minNotional": 600000.0,
             "tier": 3.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "4",
-                "cum": "4300.0",
+                "cum": "11450.0",
                 "initialLeverage": "50",
                 "maintMarginRatio": "0.01",
-                "notionalCap": "5000000",
-                "notionalFloor": "1000000"
+                "notionalCap": "12000000",
+                "notionalFloor": "3000000"
             },
             "maintenanceMarginRate": 0.01,
             "maxLeverage": 50.0,
-            "maxNotional": 5000000.0,
-            "minNotional": 1000000.0,
+            "maxNotional": 12000000.0,
+            "minNotional": 3000000.0,
             "tier": 4.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "5",
-                "cum": "54300.0",
-                "initialLeverage": "20",
+                "cum": "131450.0",
+                "initialLeverage": "25",
                 "maintMarginRatio": "0.02",
                 "notionalCap": "50000000",
-                "notionalFloor": "5000000"
+                "notionalFloor": "12000000"
             },
             "maintenanceMarginRate": 0.02,
-            "maxLeverage": 20.0,
+            "maxLeverage": 25.0,
             "maxNotional": 50000000.0,
-            "minNotional": 5000000.0,
+            "minNotional": 12000000.0,
             "tier": 5.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "6",
-                "cum": "1554300.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000000",
+                "cum": "381450.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "65000000",
                 "notionalFloor": "50000000"
             },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 10.0,
-            "maxNotional": 100000000.0,
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 65000000.0,
             "minNotional": 50000000.0,
             "tier": 6.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "7",
-                "cum": "6554300.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
+                "cum": "2006450.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
                 "notionalCap": "150000000",
-                "notionalFloor": "100000000"
+                "notionalFloor": "65000000"
             },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
             "maxNotional": 150000000.0,
-            "minNotional": 100000000.0,
+            "minNotional": 65000000.0,
             "tier": 7.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "8",
-                "cum": "10304300.0",
-                "initialLeverage": "4",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "300000000",
+                "cum": "9506450.0",
+                "initialLeverage": "5",
+                "maintMarginRatio": "0.1",
+                "notionalCap": "320000000",
                 "notionalFloor": "150000000"
             },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 4.0,
-            "maxNotional": 300000000.0,
+            "maintenanceMarginRate": 0.1,
+            "maxLeverage": 5.0,
+            "maxNotional": 320000000.0,
             "minNotional": 150000000.0,
             "tier": 8.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "9",
-                "cum": "17804300.0",
-                "initialLeverage": "3",
-                "maintMarginRatio": "0.15",
+                "cum": "17506450.0",
+                "initialLeverage": "4",
+                "maintMarginRatio": "0.125",
                 "notionalCap": "400000000",
-                "notionalFloor": "300000000"
+                "notionalFloor": "320000000"
             },
-            "maintenanceMarginRate": 0.15,
-            "maxLeverage": 3.0,
+            "maintenanceMarginRate": 0.125,
+            "maxLeverage": 4.0,
             "maxNotional": 400000000.0,
-            "minNotional": 300000000.0,
+            "minNotional": 320000000.0,
             "tier": 9.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "10",
-                "cum": "57804300.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.25",
-                "notionalCap": "500000000",
+                "cum": "27506450.0",
+                "initialLeverage": "3",
+                "maintMarginRatio": "0.15",
+                "notionalCap": "530000000",
                 "notionalFloor": "400000000"
             },
-            "maintenanceMarginRate": 0.25,
-            "maxLeverage": 2.0,
-            "maxNotional": 500000000.0,
+            "maintenanceMarginRate": 0.15,
+            "maxLeverage": 3.0,
+            "maxNotional": 530000000.0,
             "minNotional": 400000000.0,
             "tier": 10.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "11",
-                "cum": "182804300.0",
+                "cum": "80506450.0",
+                "initialLeverage": "2",
+                "maintMarginRatio": "0.25",
+                "notionalCap": "800000000",
+                "notionalFloor": "530000000"
+            },
+            "maintenanceMarginRate": 0.25,
+            "maxLeverage": 2.0,
+            "maxNotional": 800000000.0,
+            "minNotional": 530000000.0,
+            "tier": 11.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "12",
+                "cum": "280506450.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "800000000",
-                "notionalFloor": "500000000"
+                "notionalCap": "1200000000",
+                "notionalFloor": "800000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 800000000.0,
-            "minNotional": 500000000.0,
-            "tier": 11.0
+            "maxNotional": 1200000000.0,
+            "minNotional": 800000000.0,
+            "tier": 12.0
         }
     ],
     "ETH/USDT:USDT-240628": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
@@ -14001,14 +13933,144 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 120000000.0,
             "minNotional": 40000000.0,
             "tier": 8.0
         }
     ],
+    "ETHFI/USDC:USDC": [
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "1",
+                "cum": "0.0",
+                "initialLeverage": "50",
+                "maintMarginRatio": "0.01",
+                "notionalCap": "5000",
+                "notionalFloor": "0"
+            },
+            "maintenanceMarginRate": 0.01,
+            "maxLeverage": 50.0,
+            "maxNotional": 5000.0,
+            "minNotional": 0.0,
+            "tier": 1.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "2",
+                "cum": "50.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "50000",
+                "notionalFloor": "5000"
+            },
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 50000.0,
+            "minNotional": 5000.0,
+            "tier": 2.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "3",
+                "cum": "300.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "600000",
+                "notionalFloor": "50000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 600000.0,
+            "minNotional": 50000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "4",
+                "cum": "15300.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
+                "notionalCap": "1200000",
+                "notionalFloor": "600000"
+            },
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
+            "maxNotional": 1200000.0,
+            "minNotional": 600000.0,
+            "tier": 4.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "5",
+                "cum": "75300.0",
+                "initialLeverage": "5",
+                "maintMarginRatio": "0.1",
+                "notionalCap": "3000000",
+                "notionalFloor": "1200000"
+            },
+            "maintenanceMarginRate": 0.1,
+            "maxLeverage": 5.0,
+            "maxNotional": 3000000.0,
+            "minNotional": 1200000.0,
+            "tier": 5.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "6",
+                "cum": "150300.0",
+                "initialLeverage": "4",
+                "maintMarginRatio": "0.125",
+                "notionalCap": "4000000",
+                "notionalFloor": "3000000"
+            },
+            "maintenanceMarginRate": 0.125,
+            "maxLeverage": 4.0,
+            "maxNotional": 4000000.0,
+            "minNotional": 3000000.0,
+            "tier": 6.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "7",
+                "cum": "650300.0",
+                "initialLeverage": "2",
+                "maintMarginRatio": "0.25",
+                "notionalCap": "6000000",
+                "notionalFloor": "4000000"
+            },
+            "maintenanceMarginRate": 0.25,
+            "maxLeverage": 2.0,
+            "maxNotional": 6000000.0,
+            "minNotional": 4000000.0,
+            "tier": 7.0
+        },
+        {
+            "currency": "USDC",
+            "info": {
+                "bracket": "8",
+                "cum": "2150300.0",
+                "initialLeverage": "1",
+                "maintMarginRatio": "0.5",
+                "notionalCap": "10000000",
+                "notionalFloor": "6000000"
+            },
+            "maintenanceMarginRate": 0.5,
+            "maxLeverage": 1.0,
+            "maxNotional": 10000000.0,
+            "minNotional": 6000000.0,
+            "tier": 8.0
+        }
+    ],
     "ETHFI/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -14251,120 +14313,136 @@
     ],
     "FET/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
-                "initialLeverage": "25",
-                "maintMarginRatio": "0.02",
+                "initialLeverage": "50",
+                "maintMarginRatio": "0.015",
                 "notionalCap": "5000",
                 "notionalFloor": "0"
             },
-            "maintenanceMarginRate": 0.02,
-            "maxLeverage": 25.0,
+            "maintenanceMarginRate": 0.015,
+            "maxLeverage": 50.0,
             "maxNotional": 5000.0,
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "2",
                 "cum": "25.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.025",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
                 "notionalCap": "25000",
                 "notionalFloor": "5000"
             },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 20.0,
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
             "maxNotional": 25000.0,
             "minNotional": 5000.0,
             "tier": 2.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "3",
-                "cum": "650.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "200000",
+                "cum": "150.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "80000",
                 "notionalFloor": "25000"
             },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 10.0,
-            "maxNotional": 200000.0,
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 80000.0,
             "minNotional": 25000.0,
             "tier": 3.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "4",
-                "cum": "10650.0",
+                "cum": "2150.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
+                "notionalCap": "800000",
+                "notionalFloor": "80000"
+            },
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
+            "maxNotional": 800000.0,
+            "minNotional": 80000.0,
+            "tier": 4.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "5",
+                "cum": "42150.0",
                 "initialLeverage": "5",
                 "maintMarginRatio": "0.1",
-                "notionalCap": "500000",
-                "notionalFloor": "200000"
+                "notionalCap": "1600000",
+                "notionalFloor": "800000"
             },
             "maintenanceMarginRate": 0.1,
             "maxLeverage": 5.0,
-            "maxNotional": 500000.0,
-            "minNotional": 200000.0,
-            "tier": 4.0
+            "maxNotional": 1600000.0,
+            "minNotional": 800000.0,
+            "tier": 5.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "5",
-                "cum": "23150.0",
+                "bracket": "6",
+                "cum": "82150.0",
                 "initialLeverage": "4",
                 "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "500000"
+                "notionalCap": "2000000",
+                "notionalFloor": "1600000"
             },
             "maintenanceMarginRate": 0.125,
             "maxLeverage": 4.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 500000.0,
-            "tier": 5.0
+            "maxNotional": 2000000.0,
+            "minNotional": 1600000.0,
+            "tier": 6.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "6",
-                "cum": "148150.0",
+                "bracket": "7",
+                "cum": "332150.0",
                 "initialLeverage": "2",
                 "maintMarginRatio": "0.25",
-                "notionalCap": "3000000",
-                "notionalFloor": "1000000"
+                "notionalCap": "4000000",
+                "notionalFloor": "2000000"
             },
             "maintenanceMarginRate": 0.25,
             "maxLeverage": 2.0,
-            "maxNotional": 3000000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
+            "maxNotional": 4000000.0,
+            "minNotional": 2000000.0,
+            "tier": 7.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "7",
-                "cum": "898150.0",
+                "bracket": "8",
+                "cum": "1332150.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "5000000",
-                "notionalFloor": "3000000"
+                "notionalCap": "8000000",
+                "notionalFloor": "4000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 5000000.0,
-            "minNotional": 3000000.0,
-            "tier": 7.0
+            "maxNotional": 8000000.0,
+            "minNotional": 4000000.0,
+            "tier": 8.0
         }
     ],
     "FIL/USDC:USDC": [
         {
             "currency": "USDC",
             "info": {
                 "bracket": "1",
@@ -14847,112 +14925,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 5000000.0,
             "minNotional": 1000000.0,
             "tier": 6.0
         }
     ],
-    "FOOTBALL/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "11",
-                "maintMarginRatio": "0.02",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.02,
-            "maxLeverage": 11.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "25.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 10.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "650.0",
-                "initialLeverage": "8",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 8.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "5650.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "250000",
-                "notionalFloor": "100000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 250000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "11900.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "250000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 250000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "386900.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "1500000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 1500000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
-        }
-    ],
     "FRONT/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -15732,105 +15712,121 @@
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "2",
-                "cum": "50.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
+                "cum": "25.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "20000",
                 "notionalFloor": "5000"
             },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 20.0,
-            "maxNotional": 25000.0,
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 20000.0,
             "minNotional": 5000.0,
             "tier": 2.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "3",
-                "cum": "675.0",
+                "cum": "125.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "30000",
+                "notionalFloor": "20000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 30000.0,
+            "minNotional": 20000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "4",
+                "cum": "875.0",
                 "initialLeverage": "10",
                 "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
+                "notionalCap": "300000",
+                "notionalFloor": "30000"
             },
             "maintenanceMarginRate": 0.05,
             "maxLeverage": 10.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
+            "maxNotional": 300000.0,
+            "minNotional": 30000.0,
+            "tier": 4.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "4",
-                "cum": "5675.0",
+                "bracket": "5",
+                "cum": "15875.0",
                 "initialLeverage": "5",
                 "maintMarginRatio": "0.1",
-                "notionalCap": "200000",
-                "notionalFloor": "100000"
+                "notionalCap": "600000",
+                "notionalFloor": "300000"
             },
             "maintenanceMarginRate": 0.1,
             "maxLeverage": 5.0,
-            "maxNotional": 200000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
+            "maxNotional": 600000.0,
+            "minNotional": 300000.0,
+            "tier": 5.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "5",
-                "cum": "10675.0",
+                "bracket": "6",
+                "cum": "30875.0",
                 "initialLeverage": "4",
                 "maintMarginRatio": "0.125",
-                "notionalCap": "500000",
-                "notionalFloor": "200000"
+                "notionalCap": "750000",
+                "notionalFloor": "600000"
             },
             "maintenanceMarginRate": 0.125,
             "maxLeverage": 4.0,
-            "maxNotional": 500000.0,
-            "minNotional": 200000.0,
-            "tier": 5.0
+            "maxNotional": 750000.0,
+            "minNotional": 600000.0,
+            "tier": 6.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "6",
-                "cum": "73175.0",
+                "bracket": "7",
+                "cum": "124625.0",
                 "initialLeverage": "2",
                 "maintMarginRatio": "0.25",
-                "notionalCap": "1000000",
-                "notionalFloor": "500000"
+                "notionalCap": "1500000",
+                "notionalFloor": "750000"
             },
             "maintenanceMarginRate": 0.25,
             "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 500000.0,
-            "tier": 6.0
+            "maxNotional": 1500000.0,
+            "minNotional": 750000.0,
+            "tier": 7.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "7",
-                "cum": "323175.0",
+                "bracket": "8",
+                "cum": "499625.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "2000000",
-                "notionalFloor": "1000000"
+                "notionalCap": "3000000",
+                "notionalFloor": "1500000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 2000000.0,
-            "minNotional": 1000000.0,
-            "tier": 7.0
+            "maxNotional": 3000000.0,
+            "minNotional": 1500000.0,
+            "tier": 8.0
         }
     ],
     "GLMR/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
@@ -16819,128 +16815,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 10000000.0,
             "minNotional": 6000000.0,
             "tier": 7.0
         }
     ],
-    "HNT/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.02",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.02,
-            "maxLeverage": 10.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "25.0",
-                "initialLeverage": "8",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 8.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "650.0",
-                "initialLeverage": "6",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "300000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 6.0,
-            "maxNotional": 300000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "15650.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "800000",
-                "notionalFloor": "300000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 800000.0,
-            "minNotional": 300000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "35650.0",
-                "initialLeverage": "4",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "800000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 4.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 800000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "160650.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.25",
-                "notionalCap": "1500000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.25,
-            "maxLeverage": 2.0,
-            "maxNotional": 1500000.0,
-            "minNotional": 1000000.0,
-            "tier": 6.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "7",
-                "cum": "535650.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "2000000",
-                "notionalFloor": "1500000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 2000000.0,
-            "minNotional": 1500000.0,
-            "tier": 7.0
-        }
-    ],
     "HOOK/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "20",
@@ -17559,20 +17441,20 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "7",
                 "cum": "898150.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "5000000",
+                "notionalCap": "3500000",
                 "notionalFloor": "3000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 5000000.0,
+            "maxNotional": 3500000.0,
             "minNotional": 3000000.0,
             "tier": 7.0
         }
     ],
     "ILV/USDT:USDT": [
         {
             "currency": "USDT",
@@ -22109,128 +21991,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 2000000.0,
             "minNotional": 1000000.0,
             "tier": 7.0
         }
     ],
-    "MBL/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "50",
-                "maintMarginRatio": "0.015",
-                "notionalCap": "5000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.015,
-            "maxLeverage": 50.0,
-            "maxNotional": 5000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "50.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
-                "notionalFloor": "5000"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 20.0,
-            "maxNotional": 25000.0,
-            "minNotional": 5000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "675.0",
-                "initialLeverage": "10",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 10.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "5675.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "200000",
-                "notionalFloor": "100000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 200000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "10675.0",
-                "initialLeverage": "4",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "500000",
-                "notionalFloor": "200000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 4.0,
-            "maxNotional": 500000.0,
-            "minNotional": 200000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "73175.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.25",
-                "notionalCap": "1000000",
-                "notionalFloor": "500000"
-            },
-            "maintenanceMarginRate": 0.25,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 500000.0,
-            "tier": 6.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "7",
-                "cum": "323175.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "2000000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 2000000.0,
-            "minNotional": 1000000.0,
-            "tier": 7.0
-        }
-    ],
     "MDT/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "20",
@@ -22327,20 +22095,20 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "7",
                 "cum": "898150.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "5000000",
+                "notionalCap": "3500000",
                 "notionalFloor": "3000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 5000000.0,
+            "maxNotional": 3500000.0,
             "minNotional": 3000000.0,
             "tier": 7.0
         }
     ],
     "MEME/USDT:USDT": [
         {
             "currency": "USDT",
@@ -24029,14 +23797,128 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 5000000.0,
             "minNotional": 3000000.0,
             "tier": 7.0
         }
     ],
+    "NOT/USDT:USDT": [
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "1",
+                "cum": "0.0",
+                "initialLeverage": "50",
+                "maintMarginRatio": "0.015",
+                "notionalCap": "5000",
+                "notionalFloor": "0"
+            },
+            "maintenanceMarginRate": 0.015,
+            "maxLeverage": 50.0,
+            "maxNotional": 5000.0,
+            "minNotional": 0.0,
+            "tier": 1.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "2",
+                "cum": "50.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "25000",
+                "notionalFloor": "5000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 25000.0,
+            "minNotional": 5000.0,
+            "tier": 2.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "3",
+                "cum": "675.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
+                "notionalCap": "100000",
+                "notionalFloor": "25000"
+            },
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
+            "maxNotional": 100000.0,
+            "minNotional": 25000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "4",
+                "cum": "5675.0",
+                "initialLeverage": "5",
+                "maintMarginRatio": "0.1",
+                "notionalCap": "200000",
+                "notionalFloor": "100000"
+            },
+            "maintenanceMarginRate": 0.1,
+            "maxLeverage": 5.0,
+            "maxNotional": 200000.0,
+            "minNotional": 100000.0,
+            "tier": 4.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "5",
+                "cum": "10675.0",
+                "initialLeverage": "4",
+                "maintMarginRatio": "0.125",
+                "notionalCap": "500000",
+                "notionalFloor": "200000"
+            },
+            "maintenanceMarginRate": 0.125,
+            "maxLeverage": 4.0,
+            "maxNotional": 500000.0,
+            "minNotional": 200000.0,
+            "tier": 5.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "6",
+                "cum": "73175.0",
+                "initialLeverage": "2",
+                "maintMarginRatio": "0.25",
+                "notionalCap": "1000000",
+                "notionalFloor": "500000"
+            },
+            "maintenanceMarginRate": 0.25,
+            "maxLeverage": 2.0,
+            "maxNotional": 1000000.0,
+            "minNotional": 500000.0,
+            "tier": 6.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "7",
+                "cum": "323175.0",
+                "initialLeverage": "1",
+                "maintMarginRatio": "0.5",
+                "notionalCap": "2000000",
+                "notionalFloor": "1000000"
+            },
+            "maintenanceMarginRate": 0.5,
+            "maxLeverage": 1.0,
+            "maxNotional": 2000000.0,
+            "minNotional": 1000000.0,
+            "tier": 7.0
+        }
+    ],
     "NTRN/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -24588,105 +24470,121 @@
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "2",
-                "cum": "50.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
+                "cum": "25.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "20000",
                 "notionalFloor": "5000"
             },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 20.0,
-            "maxNotional": 25000.0,
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 20000.0,
             "minNotional": 5000.0,
             "tier": 2.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "3",
-                "cum": "675.0",
+                "cum": "125.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "30000",
+                "notionalFloor": "20000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 30000.0,
+            "minNotional": 20000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "4",
+                "cum": "875.0",
                 "initialLeverage": "10",
                 "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
+                "notionalCap": "300000",
+                "notionalFloor": "30000"
             },
             "maintenanceMarginRate": 0.05,
             "maxLeverage": 10.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
+            "maxNotional": 300000.0,
+            "minNotional": 30000.0,
+            "tier": 4.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "4",
-                "cum": "5675.0",
+                "bracket": "5",
+                "cum": "15875.0",
                 "initialLeverage": "5",
                 "maintMarginRatio": "0.1",
-                "notionalCap": "200000",
-                "notionalFloor": "100000"
+                "notionalCap": "600000",
+                "notionalFloor": "300000"
             },
             "maintenanceMarginRate": 0.1,
             "maxLeverage": 5.0,
-            "maxNotional": 200000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
+            "maxNotional": 600000.0,
+            "minNotional": 300000.0,
+            "tier": 5.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "5",
-                "cum": "10675.0",
+                "bracket": "6",
+                "cum": "30875.0",
                 "initialLeverage": "4",
                 "maintMarginRatio": "0.125",
-                "notionalCap": "500000",
-                "notionalFloor": "200000"
+                "notionalCap": "750000",
+                "notionalFloor": "600000"
             },
             "maintenanceMarginRate": 0.125,
             "maxLeverage": 4.0,
-            "maxNotional": 500000.0,
-            "minNotional": 200000.0,
-            "tier": 5.0
+            "maxNotional": 750000.0,
+            "minNotional": 600000.0,
+            "tier": 6.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "6",
-                "cum": "73175.0",
+                "bracket": "7",
+                "cum": "124625.0",
                 "initialLeverage": "2",
                 "maintMarginRatio": "0.25",
-                "notionalCap": "1000000",
-                "notionalFloor": "500000"
+                "notionalCap": "1500000",
+                "notionalFloor": "750000"
             },
             "maintenanceMarginRate": 0.25,
             "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 500000.0,
-            "tier": 6.0
+            "maxNotional": 1500000.0,
+            "minNotional": 750000.0,
+            "tier": 7.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "7",
-                "cum": "323175.0",
+                "bracket": "8",
+                "cum": "499625.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "2000000",
-                "notionalFloor": "1000000"
+                "notionalCap": "3000000",
+                "notionalFloor": "1500000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 2000000.0,
-            "minNotional": 1000000.0,
-            "tier": 7.0
+            "maxNotional": 3000000.0,
+            "minNotional": 1500000.0,
+            "tier": 8.0
         }
     ],
     "ONDO/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
@@ -27209,20 +27107,20 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "7",
                 "cum": "898150.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "5000000",
+                "notionalCap": "3500000",
                 "notionalFloor": "3000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 5000000.0,
+            "maxNotional": 3500000.0,
             "minNotional": 3000000.0,
             "tier": 7.0
         }
     ],
     "RAY/USDT:USDT": [
         {
             "currency": "USDT",
@@ -27643,14 +27541,144 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 10000000.0,
             "minNotional": 6000000.0,
             "tier": 7.0
         }
     ],
+    "REZ/USDT:USDT": [
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "1",
+                "cum": "0.0",
+                "initialLeverage": "50",
+                "maintMarginRatio": "0.015",
+                "notionalCap": "5000",
+                "notionalFloor": "0"
+            },
+            "maintenanceMarginRate": 0.015,
+            "maxLeverage": 50.0,
+            "maxNotional": 5000.0,
+            "minNotional": 0.0,
+            "tier": 1.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "2",
+                "cum": "25.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "20000",
+                "notionalFloor": "5000"
+            },
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 20000.0,
+            "minNotional": 5000.0,
+            "tier": 2.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "3",
+                "cum": "125.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "30000",
+                "notionalFloor": "20000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 30000.0,
+            "minNotional": 20000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "4",
+                "cum": "875.0",
+                "initialLeverage": "10",
+                "maintMarginRatio": "0.05",
+                "notionalCap": "300000",
+                "notionalFloor": "30000"
+            },
+            "maintenanceMarginRate": 0.05,
+            "maxLeverage": 10.0,
+            "maxNotional": 300000.0,
+            "minNotional": 30000.0,
+            "tier": 4.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "5",
+                "cum": "15875.0",
+                "initialLeverage": "5",
+                "maintMarginRatio": "0.1",
+                "notionalCap": "600000",
+                "notionalFloor": "300000"
+            },
+            "maintenanceMarginRate": 0.1,
+            "maxLeverage": 5.0,
+            "maxNotional": 600000.0,
+            "minNotional": 300000.0,
+            "tier": 5.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "6",
+                "cum": "30875.0",
+                "initialLeverage": "4",
+                "maintMarginRatio": "0.125",
+                "notionalCap": "750000",
+                "notionalFloor": "600000"
+            },
+            "maintenanceMarginRate": 0.125,
+            "maxLeverage": 4.0,
+            "maxNotional": 750000.0,
+            "minNotional": 600000.0,
+            "tier": 6.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "7",
+                "cum": "124625.0",
+                "initialLeverage": "2",
+                "maintMarginRatio": "0.25",
+                "notionalCap": "1500000",
+                "notionalFloor": "750000"
+            },
+            "maintenanceMarginRate": 0.25,
+            "maxLeverage": 2.0,
+            "maxNotional": 1500000.0,
+            "minNotional": 750000.0,
+            "tier": 7.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "8",
+                "cum": "499625.0",
+                "initialLeverage": "1",
+                "maintMarginRatio": "0.5",
+                "notionalCap": "3000000",
+                "notionalFloor": "1500000"
+            },
+            "maintenanceMarginRate": 0.5,
+            "maxLeverage": 1.0,
+            "maxNotional": 3000000.0,
+            "minNotional": 1500000.0,
+            "tier": 8.0
+        }
+    ],
     "RIF/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -29245,21 +29273,21 @@
     ],
     "SLP/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
-                "initialLeverage": "50",
+                "initialLeverage": "21",
                 "maintMarginRatio": "0.015",
                 "notionalCap": "5000",
                 "notionalFloor": "0"
             },
             "maintenanceMarginRate": 0.015,
-            "maxLeverage": 50.0,
+            "maxLeverage": 21.0,
             "maxNotional": 5000.0,
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
@@ -29343,37 +29371,37 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "7",
                 "cum": "323175.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "2000000",
+                "notionalCap": "1500000",
                 "notionalFloor": "1000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 2000000.0,
+            "maxNotional": 1500000.0,
             "minNotional": 1000000.0,
             "tier": 7.0
         }
     ],
     "SNT/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
-                "initialLeverage": "50",
+                "initialLeverage": "21",
                 "maintMarginRatio": "0.015",
                 "notionalCap": "5000",
                 "notionalFloor": "0"
             },
             "maintenanceMarginRate": 0.015,
-            "maxLeverage": 50.0,
+            "maxLeverage": 21.0,
             "maxNotional": 5000.0,
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
@@ -30035,96 +30063,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 3000000.0,
             "minNotional": 1000000.0,
             "tier": 6.0
         }
     ],
-    "SRM/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "8",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "15000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 8.0,
-            "maxNotional": 15000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "375.0",
-                "initialLeverage": "6",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "50000",
-                "notionalFloor": "15000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 6.0,
-            "maxNotional": 50000.0,
-            "minNotional": 15000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "2875.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "200000",
-                "notionalFloor": "50000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 200000.0,
-            "minNotional": 50000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "7875.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1000000",
-                "notionalFloor": "200000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 200000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "382875.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "1500000",
-                "notionalFloor": "1000000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 1500000.0,
-            "minNotional": 1000000.0,
-            "tier": 5.0
-        }
-    ],
     "SSV/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "20",
@@ -30677,21 +30623,21 @@
     ],
     "STPT/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
-                "initialLeverage": "50",
+                "initialLeverage": "21",
                 "maintMarginRatio": "0.015",
                 "notionalCap": "5000",
                 "notionalFloor": "0"
             },
             "maintenanceMarginRate": 0.015,
-            "maxLeverage": 50.0,
+            "maxLeverage": 21.0,
             "maxNotional": 5000.0,
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
@@ -30775,20 +30721,20 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "7",
                 "cum": "484425.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "3000000",
+                "notionalCap": "2000000",
                 "notionalFloor": "1500000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 3000000.0,
+            "maxNotional": 2000000.0,
             "minNotional": 1500000.0,
             "tier": 7.0
         }
     ],
     "STRAX/USDT:USDT": [
         {
             "currency": "USDT",
@@ -32466,105 +32412,121 @@
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "2",
-                "cum": "50.0",
-                "initialLeverage": "20",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "25000",
+                "cum": "25.0",
+                "initialLeverage": "25",
+                "maintMarginRatio": "0.02",
+                "notionalCap": "20000",
                 "notionalFloor": "5000"
             },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 20.0,
-            "maxNotional": 25000.0,
+            "maintenanceMarginRate": 0.02,
+            "maxLeverage": 25.0,
+            "maxNotional": 20000.0,
             "minNotional": 5000.0,
             "tier": 2.0
         },
         {
             "currency": "USDT",
             "info": {
                 "bracket": "3",
-                "cum": "675.0",
+                "cum": "125.0",
+                "initialLeverage": "20",
+                "maintMarginRatio": "0.025",
+                "notionalCap": "30000",
+                "notionalFloor": "20000"
+            },
+            "maintenanceMarginRate": 0.025,
+            "maxLeverage": 20.0,
+            "maxNotional": 30000.0,
+            "minNotional": 20000.0,
+            "tier": 3.0
+        },
+        {
+            "currency": "USDT",
+            "info": {
+                "bracket": "4",
+                "cum": "875.0",
                 "initialLeverage": "10",
                 "maintMarginRatio": "0.05",
-                "notionalCap": "100000",
-                "notionalFloor": "25000"
+                "notionalCap": "300000",
+                "notionalFloor": "30000"
             },
             "maintenanceMarginRate": 0.05,
             "maxLeverage": 10.0,
-            "maxNotional": 100000.0,
-            "minNotional": 25000.0,
-            "tier": 3.0
+            "maxNotional": 300000.0,
+            "minNotional": 30000.0,
+            "tier": 4.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "4",
-                "cum": "5675.0",
+                "bracket": "5",
+                "cum": "15875.0",
                 "initialLeverage": "5",
                 "maintMarginRatio": "0.1",
-                "notionalCap": "200000",
-                "notionalFloor": "100000"
+                "notionalCap": "600000",
+                "notionalFloor": "300000"
             },
             "maintenanceMarginRate": 0.1,
             "maxLeverage": 5.0,
-            "maxNotional": 200000.0,
-            "minNotional": 100000.0,
-            "tier": 4.0
+            "maxNotional": 600000.0,
+            "minNotional": 300000.0,
+            "tier": 5.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "5",
-                "cum": "10675.0",
+                "bracket": "6",
+                "cum": "30875.0",
                 "initialLeverage": "4",
                 "maintMarginRatio": "0.125",
-                "notionalCap": "500000",
-                "notionalFloor": "200000"
+                "notionalCap": "750000",
+                "notionalFloor": "600000"
             },
             "maintenanceMarginRate": 0.125,
             "maxLeverage": 4.0,
-            "maxNotional": 500000.0,
-            "minNotional": 200000.0,
-            "tier": 5.0
+            "maxNotional": 750000.0,
+            "minNotional": 600000.0,
+            "tier": 6.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "6",
-                "cum": "73175.0",
+                "bracket": "7",
+                "cum": "124625.0",
                 "initialLeverage": "2",
                 "maintMarginRatio": "0.25",
-                "notionalCap": "1000000",
-                "notionalFloor": "500000"
+                "notionalCap": "1500000",
+                "notionalFloor": "750000"
             },
             "maintenanceMarginRate": 0.25,
             "maxLeverage": 2.0,
-            "maxNotional": 1000000.0,
-            "minNotional": 500000.0,
-            "tier": 6.0
+            "maxNotional": 1500000.0,
+            "minNotional": 750000.0,
+            "tier": 7.0
         },
         {
             "currency": "USDT",
             "info": {
-                "bracket": "7",
-                "cum": "323175.0",
+                "bracket": "8",
+                "cum": "499625.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "2000000",
-                "notionalFloor": "1000000"
+                "notionalCap": "3000000",
+                "notionalFloor": "1500000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 2000000.0,
-            "minNotional": 1000000.0,
-            "tier": 7.0
+            "maxNotional": 3000000.0,
+            "minNotional": 1500000.0,
+            "tier": 8.0
         }
     ],
     "TOKEN/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
@@ -32673,112 +32635,14 @@
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
             "maxNotional": 2000000.0,
             "minNotional": 1000000.0,
             "tier": 7.0
         }
     ],
-    "TOMO/USDT:USDT": [
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "1",
-                "cum": "0.0",
-                "initialLeverage": "8",
-                "maintMarginRatio": "0.025",
-                "notionalCap": "50000",
-                "notionalFloor": "0"
-            },
-            "maintenanceMarginRate": 0.025,
-            "maxLeverage": 8.0,
-            "maxNotional": 50000.0,
-            "minNotional": 0.0,
-            "tier": 1.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "2",
-                "cum": "1250.0",
-                "initialLeverage": "6",
-                "maintMarginRatio": "0.05",
-                "notionalCap": "600000",
-                "notionalFloor": "50000"
-            },
-            "maintenanceMarginRate": 0.05,
-            "maxLeverage": 6.0,
-            "maxNotional": 600000.0,
-            "minNotional": 50000.0,
-            "tier": 2.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "3",
-                "cum": "31250.0",
-                "initialLeverage": "5",
-                "maintMarginRatio": "0.1",
-                "notionalCap": "1280000",
-                "notionalFloor": "600000"
-            },
-            "maintenanceMarginRate": 0.1,
-            "maxLeverage": 5.0,
-            "maxNotional": 1280000.0,
-            "minNotional": 600000.0,
-            "tier": 3.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "4",
-                "cum": "63250.0",
-                "initialLeverage": "4",
-                "maintMarginRatio": "0.125",
-                "notionalCap": "1600000",
-                "notionalFloor": "1280000"
-            },
-            "maintenanceMarginRate": 0.125,
-            "maxLeverage": 4.0,
-            "maxNotional": 1600000.0,
-            "minNotional": 1280000.0,
-            "tier": 4.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "5",
-                "cum": "263250.0",
-                "initialLeverage": "2",
-                "maintMarginRatio": "0.25",
-                "notionalCap": "4800000",
-                "notionalFloor": "1600000"
-            },
-            "maintenanceMarginRate": 0.25,
-            "maxLeverage": 2.0,
-            "maxNotional": 4800000.0,
-            "minNotional": 1600000.0,
-            "tier": 5.0
-        },
-        {
-            "currency": "USDT",
-            "info": {
-                "bracket": "6",
-                "cum": "1463250.0",
-                "initialLeverage": "1",
-                "maintMarginRatio": "0.5",
-                "notionalCap": "5000000",
-                "notionalFloor": "4800000"
-            },
-            "maintenanceMarginRate": 0.5,
-            "maxLeverage": 1.0,
-            "maxNotional": 5000000.0,
-            "minNotional": 4800000.0,
-            "tier": 6.0
-        }
-    ],
     "TON/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
                 "initialLeverage": "50",
@@ -32907,21 +32771,21 @@
     ],
     "TRB/USDT:USDT": [
         {
             "currency": "USDT",
             "info": {
                 "bracket": "1",
                 "cum": "0.0",
-                "initialLeverage": "50",
+                "initialLeverage": "26",
                 "maintMarginRatio": "0.015",
                 "notionalCap": "5000",
                 "notionalFloor": "0"
             },
             "maintenanceMarginRate": 0.015,
-            "maxLeverage": 50.0,
+            "maxLeverage": 26.0,
             "maxNotional": 5000.0,
             "minNotional": 0.0,
             "tier": 1.0
         },
         {
             "currency": "USDT",
             "info": {
@@ -33021,20 +32885,20 @@
         {
             "currency": "USDT",
             "info": {
                 "bracket": "8",
                 "cum": "1297775.0",
                 "initialLeverage": "1",
                 "maintMarginRatio": "0.5",
-                "notionalCap": "8000000",
+                "notionalCap": "4500000",
                 "notionalFloor": "4000000"
             },
             "maintenanceMarginRate": 0.5,
             "maxLeverage": 1.0,
-            "maxNotional": 8000000.0,
+            "maxNotional": 4500000.0,
             "minNotional": 4000000.0,
             "tier": 8.0
         }
     ],
     "TRU/USDT:USDT": [
         {
             "currency": "USDT",
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/bitpanda.py` & `freqtrade-2024.5/freqtrade/exchange/bitpanda.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-""" Bitpanda exchange subclass """
+"""Bitpanda exchange subclass"""
+
 import logging
 from datetime import datetime, timezone
 from typing import Dict, List, Optional
 
 from freqtrade.exchange import Exchange
 
 
@@ -11,16 +12,17 @@
 
 class Bitpanda(Exchange):
     """
     Bitpanda exchange class. Contains adjustments needed for Freqtrade to work
     with this exchange.
     """
 
-    def get_trades_for_order(self, order_id: str, pair: str, since: datetime,
-                             params: Optional[Dict] = None) -> List:
+    def get_trades_for_order(
+        self, order_id: str, pair: str, since: datetime, params: Optional[Dict] = None
+    ) -> List:
         """
         Fetch Orders using the "fetch_my_trades" endpoint and filter them by order-id.
         The "since" argument passed in is coming from the database and is in UTC,
         as timezone-native datetime object.
         From the python documentation:
             > Naive datetime instances are assumed to represent local time
         Therefore, calling "since.timestamp()" will get the UTC timestamp, after applying the
@@ -29,9 +31,9 @@
         instead of from the last 5 seconds, however fails for UTC- timezones,
         since we're then asking for trades with a "since" argument in the future.
 
         :param order_id order_id: Order-id as given when creating the order
         :param pair: Pair the order is for
         :param since: datetime object of the order creation time. Assumes object is in UTC.
         """
-        params = {'to': int(datetime.now(timezone.utc).timestamp() * 1000)}
+        params = {"to": int(datetime.now(timezone.utc).timestamp() * 1000)}
         return super().get_trades_for_order(order_id, pair, since, params)
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/bitvavo.py` & `freqtrade-2024.5/freqtrade/exchange/bitvavo.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 """Kucoin exchange subclass."""
+
 import logging
 from typing import Dict
 
 from freqtrade.exchange import Exchange
 
 
 logger = logging.getLogger(__name__)
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/bybit.py` & `freqtrade-2024.5/freqtrade/exchange/bybit.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-""" Bybit exchange subclass """
+"""Bybit exchange subclass"""
+
 import logging
 from datetime import datetime, timedelta
 from typing import Any, Dict, List, Optional, Tuple
 
 import ccxt
 
 from freqtrade.constants import BuySell
@@ -21,14 +22,15 @@
     Bybit exchange class. Contains adjustments needed for Freqtrade to work
     with this exchange.
 
     Please note that this exchange is not included in the list of exchanges
     officially supported by the Freqtrade development team. So some features
     may still not work as expected.
     """
+
     unified_account = False
 
     _ft_has: Dict = {
         "ohlcv_candle_limit": 1000,
         "ohlcv_has_history": True,
         "order_time_in_force": ["GTC", "FOK", "IOC", "PO"],
     }
@@ -56,97 +58,93 @@
 
     @property
     def _ccxt_config(self) -> Dict:
         # Parameters to add directly to ccxt sync/async initialization.
         # ccxt defaults to swap mode.
         config = {}
         if self.trading_mode == TradingMode.SPOT:
-            config.update({
-                "options": {
-                    "defaultType": "spot"
-                }
-            })
+            config.update({"options": {"defaultType": "spot"}})
         config.update(super()._ccxt_config)
         return config
 
     def market_is_future(self, market: Dict[str, Any]) -> bool:
         main = super().market_is_future(market)
         # For ByBit, we'll only support USDT markets for now.
-        return (
-            main and market['settle'] == 'USDT'
-        )
+        return main and market["settle"] == "USDT"
 
     @retrier
     def additional_exchange_init(self) -> None:
         """
         Additional exchange initialization logic.
         .api will be available at this point.
         Must be overridden in child methods if required.
         """
         try:
-            if not self._config['dry_run']:
+            if not self._config["dry_run"]:
                 if self.trading_mode == TradingMode.FUTURES:
                     position_mode = self._api.set_position_mode(False)
-                    self._log_exchange_response('set_position_mode', position_mode)
+                    self._log_exchange_response("set_position_mode", position_mode)
                 is_unified = self._api.is_unified_enabled()
                 # Returns a tuple of bools, first for margin, second for Account
                 if is_unified and len(is_unified) > 1 and is_unified[1]:
                     self.unified_account = True
                     logger.info("Bybit: Unified account.")
-                    raise OperationalException("Bybit: Unified account is not supported. "
-                                               "Please use a standard (sub)account.")
+                    raise OperationalException(
+                        "Bybit: Unified account is not supported. "
+                        "Please use a standard (sub)account."
+                    )
                 else:
                     self.unified_account = False
                     logger.info("Bybit: Standard account.")
         except ccxt.DDoSProtection as e:
             raise DDosProtection(e) from e
         except (ccxt.OperationFailed, ccxt.ExchangeError) as e:
             raise TemporaryError(
-                f'Error in additional_exchange_init due to {e.__class__.__name__}. Message: {e}'
-                ) from e
+                f"Error in additional_exchange_init due to {e.__class__.__name__}. Message: {e}"
+            ) from e
         except ccxt.BaseError as e:
             raise OperationalException(e) from e
 
     def ohlcv_candle_limit(
-            self, timeframe: str, candle_type: CandleType, since_ms: Optional[int] = None) -> int:
-
+        self, timeframe: str, candle_type: CandleType, since_ms: Optional[int] = None
+    ) -> int:
         if candle_type in (CandleType.FUNDING_RATE):
             return 200
 
         return super().ohlcv_candle_limit(timeframe, candle_type, since_ms)
 
     def _lev_prep(self, pair: str, leverage: float, side: BuySell, accept_fail: bool = False):
         if self.trading_mode != TradingMode.SPOT:
-            params = {'leverage': leverage}
+            params = {"leverage": leverage}
             self.set_margin_mode(pair, self.margin_mode, accept_fail=True, params=params)
             self._set_leverage(leverage, pair, accept_fail=True)
 
     def _get_params(
         self,
         side: BuySell,
         ordertype: str,
         leverage: float,
         reduceOnly: bool,
-        time_in_force: str = 'GTC',
+        time_in_force: str = "GTC",
     ) -> Dict:
         params = super()._get_params(
             side=side,
             ordertype=ordertype,
             leverage=leverage,
             reduceOnly=reduceOnly,
             time_in_force=time_in_force,
         )
         if self.trading_mode == TradingMode.FUTURES and self.margin_mode:
-            params['position_idx'] = 0
+            params["position_idx"] = 0
         return params
 
     def dry_run_liquidation_price(
         self,
         pair: str,
-        open_rate: float,   # Entry price of position
+        open_rate: float,  # Entry price of position
         is_short: bool,
         amount: float,
         stake_amount: float,
         leverage: float,
         wallet_balance: float,  # Or margin balance
         mm_ex_1: float = 0.0,  # (Binance) Cross only
         upnl_ex_1: float = 0.0,  # (Binance) Cross only
@@ -181,47 +179,46 @@
             Isolated-Margin Mode: isolatedWalletBalance
         """
 
         market = self.markets[pair]
         mm_ratio, _ = self.get_maintenance_ratio_and_amt(pair, stake_amount)
 
         if self.trading_mode == TradingMode.FUTURES and self.margin_mode == MarginMode.ISOLATED:
-
-            if market['inverse']:
-                raise OperationalException(
-                    "Freqtrade does not yet support inverse contracts")
+            if market["inverse"]:
+                raise OperationalException("Freqtrade does not yet support inverse contracts")
             initial_margin_rate = 1 / leverage
 
             # See docstring - ignores extra margin!
             if is_short:
                 return open_rate * (1 + initial_margin_rate - mm_ratio)
             else:
                 return open_rate * (1 - initial_margin_rate + mm_ratio)
 
         else:
             raise OperationalException(
-                "Freqtrade only supports isolated futures for leverage trading")
+                "Freqtrade only supports isolated futures for leverage trading"
+            )
 
     def get_funding_fees(
-            self, pair: str, amount: float, is_short: bool, open_date: datetime) -> float:
+        self, pair: str, amount: float, is_short: bool, open_date: datetime
+    ) -> float:
         """
         Fetch funding fees, either from the exchange (live) or calculates them
         based on funding rate/mark price history
         :param pair: The quote/base pair of the trade
         :param is_short: trade direction
         :param amount: Trade amount
         :param open_date: Open date of the trade
         :return: funding fee since open_date
         :raises: ExchangeError if something goes wrong.
         """
         # Bybit does not provide "applied" funding fees per position.
         if self.trading_mode == TradingMode.FUTURES:
             try:
-                return self._fetch_and_calculate_funding_fees(
-                        pair, amount, is_short, open_date)
+                return self._fetch_and_calculate_funding_fees(pair, amount, is_short, open_date)
             except ExchangeError:
                 logger.warning(f"Could not update funding fees for {pair}.")
         return 0.0
 
     def fetch_orders(self, pair: str, since: datetime, params: Optional[Dict] = None) -> List[Dict]:
         """
         Fetch all orders for a pair "since"
@@ -230,22 +227,42 @@
         """
         # On bybit, the distance between since and "until" can't exceed 7 days.
         # we therefore need to split the query into multiple queries.
         orders = []
 
         while since < dt_now():
             until = since + timedelta(days=7, minutes=-1)
-            orders += super().fetch_orders(pair, since, params={'until': dt_ts(until)})
+            orders += super().fetch_orders(pair, since, params={"until": dt_ts(until)})
             since = until
 
         return orders
 
     def fetch_order(self, order_id: str, pair: str, params: Optional[Dict] = None) -> Dict:
         order = super().fetch_order(order_id, pair, params)
         if (
-            order.get('status') == 'canceled'
-            and order.get('filled') == 0.0
-            and order.get('remaining') == 0.0
+            order.get("status") == "canceled"
+            and order.get("filled") == 0.0
+            and order.get("remaining") == 0.0
         ):
             # Canceled orders will have "remaining=0" on bybit.
-            order['remaining'] = None
+            order["remaining"] = None
         return order
+
+    @retrier
+    def get_leverage_tiers(self) -> Dict[str, List[Dict]]:
+        """
+        Cache leverage tiers for 1 day, since they are not expected to change often, and
+        bybit requires pagination to fetch all tiers.
+        """
+
+        # Load cached tiers
+        tiers_cached = self.load_cached_leverage_tiers(
+            self._config["stake_currency"], timedelta(days=1)
+        )
+        if tiers_cached:
+            return tiers_cached
+
+        # Fetch tiers from exchange
+        tiers = super().get_leverage_tiers()
+
+        self.cache_leverage_tiers(tiers, self._config["stake_currency"])
+        return tiers
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/check_exchange.py` & `freqtrade-2024.5/freqtrade/exchange/check_exchange.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,49 +17,56 @@
                           exchanges
     :return: False if exchange is 'bad', i.e. is known to work with the bot with
              critical issues or does not work at all, crashes, etc. True otherwise.
              raises an exception if the exchange if not supported by ccxt
              and thus is not known for the Freqtrade at all.
     """
 
-    if (config['runmode'] in [RunMode.PLOT, RunMode.UTIL_NO_EXCHANGE, RunMode.OTHER]
-       and not config.get('exchange', {}).get('name')):
+    if config["runmode"] in [
+        RunMode.PLOT,
+        RunMode.UTIL_NO_EXCHANGE,
+        RunMode.OTHER,
+    ] and not config.get("exchange", {}).get("name"):
         # Skip checking exchange in plot mode, since it requires no exchange
         return True
     logger.info("Checking exchange...")
 
-    exchange = config.get('exchange', {}).get('name', '').lower()
+    exchange = config.get("exchange", {}).get("name", "").lower()
     if not exchange:
         raise OperationalException(
-            f'This command requires a configured exchange. You should either use '
-            f'`--exchange <exchange_name>` or specify a configuration file via `--config`.\n'
-            f'The following exchanges are available for Freqtrade: '
+            f"This command requires a configured exchange. You should either use "
+            f"`--exchange <exchange_name>` or specify a configuration file via `--config`.\n"
+            f"The following exchanges are available for Freqtrade: "
             f'{", ".join(available_exchanges())}'
         )
 
     if not is_exchange_known_ccxt(exchange):
         raise OperationalException(
             f'Exchange "{exchange}" is not known to the ccxt library '
-            f'and therefore not available for the bot.\n'
-            f'The following exchanges are available for Freqtrade: '
+            f"and therefore not available for the bot.\n"
+            f"The following exchanges are available for Freqtrade: "
             f'{", ".join(available_exchanges())}'
         )
 
     valid, reason = validate_exchange(exchange)
     if not valid:
         if check_for_bad:
-            raise OperationalException(f'Exchange "{exchange}"  will not work with Freqtrade. '
-                                       f'Reason: {reason}')
+            raise OperationalException(
+                f'Exchange "{exchange}"  will not work with Freqtrade. ' f"Reason: {reason}"
+            )
         else:
             logger.warning(f'Exchange "{exchange}"  will not work with Freqtrade. Reason: {reason}')
 
     if MAP_EXCHANGE_CHILDCLASS.get(exchange, exchange) in SUPPORTED_EXCHANGES:
-        logger.info(f'Exchange "{exchange}" is officially supported '
-                    f'by the Freqtrade development team.')
+        logger.info(
+            f'Exchange "{exchange}" is officially supported ' f"by the Freqtrade development team."
+        )
     else:
-        logger.warning(f'Exchange "{exchange}" is known to the ccxt library, '
-                       f'available for the bot, but not officially supported '
-                       f'by the Freqtrade development team. '
-                       f'It may work flawlessly (please report back) or have serious issues. '
-                       f'Use it at your own discretion.')
+        logger.warning(
+            f'Exchange "{exchange}" is known to the ccxt library, '
+            f"available for the bot, but not officially supported "
+            f"by the Freqtrade development team. "
+            f"It may work flawlessly (please report back) or have serious issues. "
+            f"Use it at your own discretion."
+        )
 
     return True
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/coinbasepro.py` & `freqtrade-2024.5/freqtrade/exchange/coinbasepro.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-""" CoinbasePro exchange subclass """
+"""CoinbasePro exchange subclass"""
+
 import logging
 from typing import Dict
 
 from freqtrade.exchange import Exchange
 
 
 logger = logging.getLogger(__name__)
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/common.py` & `freqtrade-2024.5/freqtrade/exchange/common.py`

 * *Files 10% similar despite different names*

```diff
@@ -39,54 +39,57 @@
     "bitmex": "Various reasons.",
     "phemex": "Does not provide history.",
     "probit": "Requires additional, regular calls to `signIn()`.",
     "poloniex": "Does not provide fetch_order endpoint to fetch both open and closed orders.",
 }
 
 MAP_EXCHANGE_CHILDCLASS = {
-    'binanceus': 'binance',
-    'binanceje': 'binance',
-    'binanceusdm': 'binance',
-    'okex': 'okx',
-    'gateio': 'gate',
-    'huboi': 'htx',
+    "binanceus": "binance",
+    "binanceje": "binance",
+    "binanceusdm": "binance",
+    "okex": "okx",
+    "gateio": "gate",
+    "huboi": "htx",
 }
 
 SUPPORTED_EXCHANGES = [
-    'binance',
-    'bitmart',
-    'gate',
-    'htx',
-    'kraken',
-    'okx',
+    "binance",
+    "bingx",
+    "bitmart",
+    "gate",
+    "htx",
+    "kraken",
+    "okx",
 ]
 
 # either the main, or replacement methods (array) is required
 EXCHANGE_HAS_REQUIRED: Dict[str, List[str]] = {
     # Required / private
-    'fetchOrder': ['fetchOpenOrder', 'fetchClosedOrder'],
-    'cancelOrder': [],
-    'createOrder': [],
-    'fetchBalance': [],
-
+    "fetchOrder": ["fetchOpenOrder", "fetchClosedOrder"],
+    "cancelOrder": [],
+    "createOrder": [],
+    "fetchBalance": [],
     # Public endpoints
-    'fetchOHLCV': [],
+    "fetchOHLCV": [],
 }
 
 EXCHANGE_HAS_OPTIONAL = [
     # Private
-    'fetchMyTrades',  # Trades for order - fee detection
-    'createLimitOrder', 'createMarketOrder',  # Either OR for orders
+    "fetchMyTrades",  # Trades for order - fee detection
+    "createLimitOrder",
+    "createMarketOrder",  # Either OR for orders
     # 'setLeverage',  # Margin/Futures trading
     # 'setMarginMode',  # Margin/Futures trading
     # 'fetchFundingHistory', # Futures trading
     # Public
-    'fetchOrderBook', 'fetchL2OrderBook', 'fetchTicker',  # OR for pricing
-    'fetchTickers',  # For volumepairlist?
-    'fetchTrades',  # Downloading trades data
+    "fetchOrderBook",
+    "fetchL2OrderBook",
+    "fetchTicker",  # OR for pricing
+    "fetchTickers",  # For volumepairlist?
+    "fetchTrades",  # Downloading trades data
     # 'fetchFundingRateHistory',  # Futures trading
     # 'fetchPositions',  # Futures trading
     # 'fetchLeverageTiers',  # Futures initialization
     # 'fetchMarketLeverageTiers',  # Futures initialization
     # 'fetchOpenOrder', 'fetchClosedOrder',  # replacement for fetchOrder
     # 'fetchOpenOrders', 'fetchClosedOrders',  # 'fetchOrders',  # Refinding balance...
 ]
@@ -95,97 +98,100 @@
 def remove_exchange_credentials(exchange_config: ExchangeConfig, dry_run: bool) -> None:
     """
     Removes exchange keys from the configuration and specifies dry-run
     Used for backtesting / hyperopt / edge and utils.
     Modifies the input dict!
     """
     if dry_run:
-        exchange_config['key'] = ''
-        exchange_config['apiKey'] = ''
-        exchange_config['secret'] = ''
-        exchange_config['password'] = ''
-        exchange_config['uid'] = ''
+        exchange_config["key"] = ""
+        exchange_config["apiKey"] = ""
+        exchange_config["secret"] = ""
+        exchange_config["password"] = ""
+        exchange_config["uid"] = ""
 
 
 def calculate_backoff(retrycount, max_retries):
     """
     Calculate backoff
     """
     return (max_retries - retrycount) ** 2 + 1
 
 
 def retrier_async(f):
     async def wrapper(*args, **kwargs):
-        count = kwargs.pop('count', API_RETRY_COUNT)
+        count = kwargs.pop("count", API_RETRY_COUNT)
         kucoin = args[0].name == "KuCoin"  # Check if the exchange is KuCoin.
         try:
             return await f(*args, **kwargs)
         except TemporaryError as ex:
             msg = f'{f.__name__}() returned exception: "{ex}". '
             if count > 0:
-                msg += f'Retrying still for {count} times.'
+                msg += f"Retrying still for {count} times."
                 count -= 1
-                kwargs['count'] = count
+                kwargs["count"] = count
                 if isinstance(ex, DDosProtection):
                     if kucoin and "429000" in str(ex):
                         # Temporary fix for 429000 error on kucoin
                         # see https://github.com/freqtrade/freqtrade/issues/5700 for details.
                         _get_logging_mixin().log_once(
                             f"Kucoin 429 error, avoid triggering DDosProtection backoff delay. "
-                            f"{count} tries left before giving up", logmethod=logger.warning)
+                            f"{count} tries left before giving up",
+                            logmethod=logger.warning,
+                        )
                         # Reset msg to avoid logging too many times.
-                        msg = ''
+                        msg = ""
                     else:
                         backoff_delay = calculate_backoff(count + 1, API_RETRY_COUNT)
                         logger.info(f"Applying DDosProtection backoff delay: {backoff_delay}")
                         await asyncio.sleep(backoff_delay)
                 if msg:
                     logger.warning(msg)
                 return await wrapper(*args, **kwargs)
             else:
-                logger.warning(msg + 'Giving up.')
+                logger.warning(msg + "Giving up.")
                 raise ex
+
     return wrapper
 
 
-F = TypeVar('F', bound=Callable[..., Any])
+F = TypeVar("F", bound=Callable[..., Any])
 
 
 # Type shenanigans
 @overload
-def retrier(_func: F) -> F:
-    ...
+def retrier(_func: F) -> F: ...
 
 
 @overload
-def retrier(*, retries=API_RETRY_COUNT) -> Callable[[F], F]:
-    ...
+def retrier(*, retries=API_RETRY_COUNT) -> Callable[[F], F]: ...
 
 
 def retrier(_func: Optional[F] = None, *, retries=API_RETRY_COUNT):
     def decorator(f: F) -> F:
         @wraps(f)
         def wrapper(*args, **kwargs):
-            count = kwargs.pop('count', retries)
+            count = kwargs.pop("count", retries)
             try:
                 return f(*args, **kwargs)
             except (TemporaryError, RetryableOrderError) as ex:
                 msg = f'{f.__name__}() returned exception: "{ex}". '
                 if count > 0:
-                    logger.warning(msg + f'Retrying still for {count} times.')
+                    logger.warning(msg + f"Retrying still for {count} times.")
                     count -= 1
-                    kwargs.update({'count': count})
+                    kwargs.update({"count": count})
                     if isinstance(ex, (DDosProtection, RetryableOrderError)):
                         # increasing backoff
                         backoff_delay = calculate_backoff(count + 1, retries)
                         logger.info(f"Applying DDosProtection backoff delay: {backoff_delay}")
                         time.sleep(backoff_delay)
                     return wrapper(*args, **kwargs)
                 else:
-                    logger.warning(msg + 'Giving up.')
+                    logger.warning(msg + "Giving up.")
                     raise ex
+
         return cast(F, wrapper)
+
     # Support both @retrier and @retrier(retries=2) syntax
     if _func is None:
         return decorator
     else:
         return decorator(_func)
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/exchange.py` & `freqtrade-2024.5/freqtrade/exchange/exchange.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8740 +1,8774 @@
 00000000: 2320 7072 6167 6d61 2070 796c 696e 743a  # pragma pylint:
 00000010: 2064 6973 6162 6c65 3d57 3036 3033 0a22   disable=W0603."
 00000020: 2222 0a43 7279 7074 6f63 7572 7265 6e63  "".Cryptocurrenc
 00000030: 7920 4578 6368 616e 6765 7320 7375 7070  y Exchanges supp
-00000040: 6f72 740a 2222 220a 696d 706f 7274 2061  ort.""".import a
-00000050: 7379 6e63 696f 0a69 6d70 6f72 7420 696e  syncio.import in
-00000060: 7370 6563 740a 696d 706f 7274 206c 6f67  spect.import log
-00000070: 6769 6e67 0a69 6d70 6f72 7420 7369 676e  ging.import sign
-00000080: 616c 0a66 726f 6d20 636f 7079 2069 6d70  al.from copy imp
-00000090: 6f72 7420 6465 6570 636f 7079 0a66 726f  ort deepcopy.fro
-000000a0: 6d20 6461 7465 7469 6d65 2069 6d70 6f72  m datetime impor
-000000b0: 7420 6461 7465 7469 6d65 2c20 7469 6d65  t datetime, time
-000000c0: 6465 6c74 612c 2074 696d 657a 6f6e 650a  delta, timezone.
-000000d0: 6672 6f6d 206d 6174 6820 696d 706f 7274  from math import
-000000e0: 2066 6c6f 6f72 2c20 6973 6e61 6e0a 6672   floor, isnan.fr
-000000f0: 6f6d 2074 6872 6561 6469 6e67 2069 6d70  om threading imp
-00000100: 6f72 7420 4c6f 636b 0a66 726f 6d20 7479  ort Lock.from ty
-00000110: 7069 6e67 2069 6d70 6f72 7420 416e 792c  ping import Any,
-00000120: 2043 6f72 6f75 7469 6e65 2c20 4469 6374   Coroutine, Dict
-00000130: 2c20 4c69 7374 2c20 4c69 7465 7261 6c2c  , List, Literal,
-00000140: 204f 7074 696f 6e61 6c2c 2054 7570 6c65   Optional, Tuple
-00000150: 2c20 556e 696f 6e0a 0a69 6d70 6f72 7420  , Union..import 
-00000160: 6363 7874 0a69 6d70 6f72 7420 6363 7874  ccxt.import ccxt
-00000170: 2e61 7379 6e63 5f73 7570 706f 7274 2061  .async_support a
-00000180: 7320 6363 7874 5f61 7379 6e63 0a66 726f  s ccxt_async.fro
-00000190: 6d20 6361 6368 6574 6f6f 6c73 2069 6d70  m cachetools imp
-000001a0: 6f72 7420 5454 4c43 6163 6865 0a66 726f  ort TTLCache.fro
-000001b0: 6d20 6363 7874 2069 6d70 6f72 7420 5449  m ccxt import TI
-000001c0: 434b 5f53 495a 450a 6672 6f6d 2064 6174  CK_SIZE.from dat
-000001d0: 6575 7469 6c20 696d 706f 7274 2070 6172  eutil import par
-000001e0: 7365 720a 6672 6f6d 2070 616e 6461 7320  ser.from pandas 
-000001f0: 696d 706f 7274 2044 6174 6146 7261 6d65  import DataFrame
-00000200: 2c20 636f 6e63 6174 0a0a 6672 6f6d 2066  , concat..from f
-00000210: 7265 7174 7261 6465 2e63 6f6e 7374 616e  reqtrade.constan
-00000220: 7473 2069 6d70 6f72 7420 2844 4546 4155  ts import (DEFAU
-00000230: 4c54 5f41 4d4f 554e 545f 5245 5345 5256  LT_AMOUNT_RESERV
-00000240: 455f 5045 5243 454e 542c 204e 4f4e 5f4f  E_PERCENT, NON_O
-00000250: 5045 4e5f 4558 4348 414e 4745 5f53 5441  PEN_EXCHANGE_STA
-00000260: 5445 532c 2042 6964 4173 6b2c 0a20 2020  TES, BidAsk,.   
-00000270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000280: 2020 2020 2020 2020 2020 2020 2020 4275                Bu
-00000290: 7953 656c 6c2c 2043 6f6e 6669 672c 2045  ySell, Config, E
-000002a0: 6e74 7279 4578 6974 2c20 4578 6368 616e  ntryExit, Exchan
-000002b0: 6765 436f 6e66 6967 2c0a 2020 2020 2020  geConfig,.      
-000002c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000002d0: 2020 2020 2020 2020 2020 204c 6973 7450             ListP
-000002e0: 6169 7273 5769 7468 5469 6d65 6672 616d  airsWithTimefram
-000002f0: 6573 2c20 4d61 6b65 7254 616b 6572 2c20  es, MakerTaker, 
-00000300: 4f42 4c69 7465 7261 6c2c 2050 6169 7257  OBLiteral, PairW
-00000310: 6974 6854 696d 6566 7261 6d65 290a 6672  ithTimeframe).fr
-00000320: 6f6d 2066 7265 7174 7261 6465 2e64 6174  om freqtrade.dat
-00000330: 612e 636f 6e76 6572 7465 7220 696d 706f  a.converter impo
-00000340: 7274 2063 6c65 616e 5f6f 686c 6376 5f64  rt clean_ohlcv_d
-00000350: 6174 6166 7261 6d65 2c20 6f68 6c63 765f  ataframe, ohlcv_
-00000360: 746f 5f64 6174 6166 7261 6d65 2c20 7472  to_dataframe, tr
-00000370: 6164 6573 5f64 6963 745f 746f 5f6c 6973  ades_dict_to_lis
-00000380: 740a 6672 6f6d 2066 7265 7174 7261 6465  t.from freqtrade
-00000390: 2e65 6e75 6d73 2069 6d70 6f72 7420 4f50  .enums import OP
-000003a0: 5449 4d49 5a45 5f4d 4f44 4553 2c20 4361  TIMIZE_MODES, Ca
-000003b0: 6e64 6c65 5479 7065 2c20 4d61 7267 696e  ndleType, Margin
-000003c0: 4d6f 6465 2c20 5072 6963 6554 7970 652c  Mode, PriceType,
-000003d0: 2052 756e 4d6f 6465 2c20 5472 6164 696e   RunMode, Tradin
-000003e0: 674d 6f64 650a 6672 6f6d 2066 7265 7174  gMode.from freqt
-000003f0: 7261 6465 2e65 7863 6570 7469 6f6e 7320  rade.exceptions 
-00000400: 696d 706f 7274 2028 436f 6e66 6967 7572  import (Configur
-00000410: 6174 696f 6e45 7272 6f72 2c20 4444 6f73  ationError, DDos
-00000420: 5072 6f74 6563 7469 6f6e 2c20 4578 6368  Protection, Exch
-00000430: 616e 6765 4572 726f 722c 0a20 2020 2020  angeError,.     
-00000440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000450: 2020 2020 2020 2020 2020 2020 2049 6e73               Ins
-00000460: 7566 6669 6369 656e 7446 756e 6473 4572  ufficientFundsEr
-00000470: 726f 722c 2049 6e76 616c 6964 4f72 6465  ror, InvalidOrde
-00000480: 7245 7863 6570 7469 6f6e 2c0a 2020 2020  rException,.    
-00000490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000004a0: 2020 2020 2020 2020 2020 2020 2020 4f70                Op
-000004b0: 6572 6174 696f 6e61 6c45 7863 6570 7469  erationalExcepti
-000004c0: 6f6e 2c20 5072 6963 696e 6745 7272 6f72  on, PricingError
-000004d0: 2c20 5265 7472 7961 626c 654f 7264 6572  , RetryableOrder
-000004e0: 4572 726f 722c 0a20 2020 2020 2020 2020  Error,.         
-000004f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000500: 2020 2020 2020 2020 2054 656d 706f 7261           Tempora
-00000510: 7279 4572 726f 7229 0a66 726f 6d20 6672  ryError).from fr
-00000520: 6571 7472 6164 652e 6578 6368 616e 6765  eqtrade.exchange
-00000530: 2e63 6f6d 6d6f 6e20 696d 706f 7274 2028  .common import (
-00000540: 4150 495f 4645 5443 485f 4f52 4445 525f  API_FETCH_ORDER_
-00000550: 5245 5452 595f 434f 554e 542c 2072 656d  RETRY_COUNT, rem
-00000560: 6f76 655f 6578 6368 616e 6765 5f63 7265  ove_exchange_cre
-00000570: 6465 6e74 6961 6c73 2c0a 2020 2020 2020  dentials,.      
-00000580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000005a0: 2072 6574 7269 6572 2c20 7265 7472 6965   retrier, retrie
-000005b0: 725f 6173 796e 6329 0a66 726f 6d20 6672  r_async).from fr
-000005c0: 6571 7472 6164 652e 6578 6368 616e 6765  eqtrade.exchange
-000005d0: 2e65 7863 6861 6e67 655f 7574 696c 7320  .exchange_utils 
-000005e0: 696d 706f 7274 2028 524f 554e 442c 2052  import (ROUND, R
-000005f0: 4f55 4e44 5f44 4f57 4e2c 2052 4f55 4e44  OUND_DOWN, ROUND
-00000600: 5f55 502c 2043 6378 744d 6f64 756c 6554  _UP, CcxtModuleT
-00000610: 7970 652c 0a20 2020 2020 2020 2020 2020  ype,.           
-00000620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000640: 2020 2020 616d 6f75 6e74 5f74 6f5f 636f      amount_to_co
-00000650: 6e74 7261 6374 5f70 7265 6369 7369 6f6e  ntract_precision
-00000660: 2c20 616d 6f75 6e74 5f74 6f5f 636f 6e74  , amount_to_cont
-00000670: 7261 6374 732c 0a20 2020 2020 2020 2020  racts,.         
-00000680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000006a0: 2020 2020 2020 616d 6f75 6e74 5f74 6f5f        amount_to_
-000006b0: 7072 6563 6973 696f 6e2c 2063 6f6e 7472  precision, contr
-000006c0: 6163 7473 5f74 6f5f 616d 6f75 6e74 2c0a  acts_to_amount,.
-000006d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000006e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000006f0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00000700: 6174 655f 6d69 6e75 735f 6361 6e64 6c65  ate_minus_candle
-00000710: 732c 2069 735f 6578 6368 616e 6765 5f6b  s, is_exchange_k
-00000720: 6e6f 776e 5f63 6378 742c 0a20 2020 2020  nown_ccxt,.     
-00000730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000750: 2020 2020 2020 2020 2020 6d61 726b 6574            market
-00000760: 5f69 735f 6163 7469 7665 2c20 7072 6963  _is_active, pric
-00000770: 655f 746f 5f70 7265 6369 7369 6f6e 290a  e_to_precision).
-00000780: 6672 6f6d 2066 7265 7174 7261 6465 2e65  from freqtrade.e
-00000790: 7863 6861 6e67 652e 6578 6368 616e 6765  xchange.exchange
-000007a0: 5f75 7469 6c73 5f74 696d 6566 7261 6d65  _utils_timeframe
-000007b0: 2069 6d70 6f72 7420 2874 696d 6566 7261   import (timefra
-000007c0: 6d65 5f74 6f5f 6d69 6e75 7465 732c 2074  me_to_minutes, t
-000007d0: 696d 6566 7261 6d65 5f74 6f5f 6d73 6563  imeframe_to_msec
-000007e0: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
-000007f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000810: 2020 2020 2020 2020 2020 2020 7469 6d65              time
-00000820: 6672 616d 655f 746f 5f6e 6578 745f 6461  frame_to_next_da
-00000830: 7465 2c0a 2020 2020 2020 2020 2020 2020  te,.            
-00000840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000860: 2020 2020 2020 2020 2020 2020 2074 696d               tim
-00000870: 6566 7261 6d65 5f74 6f5f 7072 6576 5f64  eframe_to_prev_d
-00000880: 6174 652c 0a20 2020 2020 2020 2020 2020  ate,.           
-00000890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000008a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000008b0: 2020 2020 2020 2020 2020 2020 2020 7469                ti
-000008c0: 6d65 6672 616d 655f 746f 5f73 6563 6f6e  meframe_to_secon
-000008d0: 6473 290a 6672 6f6d 2066 7265 7174 7261  ds).from freqtra
-000008e0: 6465 2e65 7863 6861 6e67 652e 7479 7065  de.exchange.type
-000008f0: 7320 696d 706f 7274 204f 484c 4356 5265  s import OHLCVRe
-00000900: 7370 6f6e 7365 2c20 4f72 6465 7242 6f6f  sponse, OrderBoo
-00000910: 6b2c 2054 6963 6b65 722c 2054 6963 6b65  k, Ticker, Ticke
-00000920: 7273 0a66 726f 6d20 6672 6571 7472 6164  rs.from freqtrad
-00000930: 652e 6d69 7363 2069 6d70 6f72 7420 2863  e.misc import (c
-00000940: 6875 6e6b 732c 2064 6565 705f 6d65 7267  hunks, deep_merg
-00000950: 655f 6469 6374 732c 2066 696c 655f 6475  e_dicts, file_du
-00000960: 6d70 5f6a 736f 6e2c 2066 696c 655f 6c6f  mp_json, file_lo
-00000970: 6164 5f6a 736f 6e2c 0a20 2020 2020 2020  ad_json,.       
-00000980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000990: 2020 2020 2073 6166 655f 7661 6c75 655f       safe_value_
-000009a0: 6661 6c6c 6261 636b 3229 0a66 726f 6d20  fallback2).from 
-000009b0: 6672 6571 7472 6164 652e 706c 7567 696e  freqtrade.plugin
-000009c0: 732e 7061 6972 6c69 7374 2e70 6169 726c  s.pairlist.pairl
-000009d0: 6973 745f 6865 6c70 6572 7320 696d 706f  ist_helpers impo
-000009e0: 7274 2065 7870 616e 645f 7061 6972 6c69  rt expand_pairli
-000009f0: 7374 0a66 726f 6d20 6672 6571 7472 6164  st.from freqtrad
-00000a00: 652e 7574 696c 2069 6d70 6f72 7420 6474  e.util import dt
-00000a10: 5f66 726f 6d5f 7473 2c20 6474 5f6e 6f77  _from_ts, dt_now
-00000a20: 0a66 726f 6d20 6672 6571 7472 6164 652e  .from freqtrade.
-00000a30: 7574 696c 2e64 6174 6574 696d 655f 6865  util.datetime_he
-00000a40: 6c70 6572 7320 696d 706f 7274 2064 745f  lpers import dt_
-00000a50: 6875 6d61 6e69 7a65 5f64 656c 7461 2c20  humanize_delta, 
-00000a60: 6474 5f74 730a 6672 6f6d 2066 7265 7174  dt_ts.from freqt
-00000a70: 7261 6465 2e75 7469 6c2e 7065 7269 6f64  rade.util.period
-00000a80: 6963 5f63 6163 6865 2069 6d70 6f72 7420  ic_cache import 
-00000a90: 5065 7269 6f64 6963 4361 6368 650a 0a0a  PeriodicCache...
-00000aa0: 6c6f 6767 6572 203d 206c 6f67 6769 6e67  logger = logging
-00000ab0: 2e67 6574 4c6f 6767 6572 285f 5f6e 616d  .getLogger(__nam
-00000ac0: 655f 5f29 0a0a 0a63 6c61 7373 2045 7863  e__)...class Exc
-00000ad0: 6861 6e67 653a 0a0a 2020 2020 2320 5061  hange:..    # Pa
-00000ae0: 7261 6d65 7465 7273 2074 6f20 6164 6420  rameters to add 
-00000af0: 6469 7265 6374 6c79 2074 6f20 6275 792f  directly to buy/
-00000b00: 7365 6c6c 2063 616c 6c73 2028 6c69 6b65  sell calls (like
-00000b10: 2061 6772 6565 696e 6720 746f 2074 7261   agreeing to tra
-00000b20: 6469 6e67 2061 6772 6565 6d65 6e74 290a  ding agreement).
-00000b30: 2020 2020 5f70 6172 616d 733a 2044 6963      _params: Dic
-00000b40: 7420 3d20 7b7d 0a0a 2020 2020 2320 4164  t = {}..    # Ad
-00000b50: 6469 7469 6f6e 616c 2070 6172 616d 6574  ditional paramet
-00000b60: 6572 7320 2d20 6164 6465 6420 746f 2074  ers - added to t
-00000b70: 6865 2063 6378 7420 6f62 6a65 6374 0a20  he ccxt object. 
-00000b80: 2020 205f 6363 7874 5f70 6172 616d 733a     _ccxt_params:
-00000b90: 2044 6963 7420 3d20 7b7d 0a0a 2020 2020   Dict = {}..    
-00000ba0: 2320 4469 6374 2074 6f20 7370 6563 6966  # Dict to specif
-00000bb0: 7920 7768 6963 6820 6f70 7469 6f6e 7320  y which options 
-00000bc0: 6561 6368 2065 7863 6861 6e67 6520 696d  each exchange im
-00000bd0: 706c 656d 656e 7473 0a20 2020 2023 2054  plements.    # T
-00000be0: 6869 7320 6465 6669 6e65 7320 6465 6661  his defines defa
-00000bf0: 756c 7473 2c20 7768 6963 6820 6361 6e20  ults, which can 
-00000c00: 6265 2073 656c 6563 7469 7665 6c79 206f  be selectively o
-00000c10: 7665 7272 6964 6465 6e20 6279 2073 7562  verridden by sub
-00000c20: 636c 6173 7365 7320 7573 696e 6720 5f66  classes using _f
-00000c30: 745f 6861 730a 2020 2020 2320 6f72 2062  t_has.    # or b
-00000c40: 7920 7370 6563 6966 7969 6e67 2074 6865  y specifying the
-00000c50: 6d20 696e 2074 6865 2063 6f6e 6669 6775  m in the configu
-00000c60: 7261 7469 6f6e 2e0a 2020 2020 5f66 745f  ration..    _ft_
-00000c70: 6861 735f 6465 6661 756c 743a 2044 6963  has_default: Dic
-00000c80: 7420 3d20 7b0a 2020 2020 2020 2020 2273  t = {.        "s
-00000c90: 746f 706c 6f73 735f 6f6e 5f65 7863 6861  toploss_on_excha
-00000ca0: 6e67 6522 3a20 4661 6c73 652c 0a20 2020  nge": False,.   
-00000cb0: 2020 2020 2022 7374 6f70 5f70 7269 6365       "stop_price
-00000cc0: 5f70 6172 616d 223a 2022 7374 6f70 4c6f  _param": "stopLo
-00000cd0: 7373 5072 6963 6522 2c20 2023 2055 7365  ssPrice",  # Use
-00000ce0: 6420 666f 7220 7374 6f70 6c6f 7373 5f6f  d for stoploss_o
-00000cf0: 6e5f 6578 6368 616e 6765 2072 6571 7565  n_exchange reque
-00000d00: 7374 0a20 2020 2020 2020 2022 7374 6f70  st.        "stop
-00000d10: 5f70 7269 6365 5f70 726f 7022 3a20 2273  _price_prop": "s
-00000d20: 746f 704c 6f73 7350 7269 6365 222c 2020  topLossPrice",  
-00000d30: 2320 5573 6564 2066 6f72 2073 746f 706c  # Used for stopl
-00000d40: 6f73 735f 6f6e 5f65 7863 6861 6e67 6520  oss_on_exchange 
-00000d50: 7265 7370 6f6e 7365 2070 6172 7369 6e67  response parsing
-00000d60: 0a20 2020 2020 2020 2022 6f72 6465 725f  .        "order_
-00000d70: 7469 6d65 5f69 6e5f 666f 7263 6522 3a20  time_in_force": 
-00000d80: 5b22 4754 4322 5d2c 0a20 2020 2020 2020  ["GTC"],.       
-00000d90: 2022 6f68 6c63 765f 7061 7261 6d73 223a   "ohlcv_params":
-00000da0: 207b 7d2c 0a20 2020 2020 2020 2022 6f68   {},.        "oh
-00000db0: 6c63 765f 6361 6e64 6c65 5f6c 696d 6974  lcv_candle_limit
-00000dc0: 223a 2035 3030 2c0a 2020 2020 2020 2020  ": 500,.        
-00000dd0: 226f 686c 6376 5f68 6173 5f68 6973 746f  "ohlcv_has_histo
-00000de0: 7279 223a 2054 7275 652c 2020 2320 536f  ry": True,  # So
-00000df0: 6d65 2065 7863 6861 6e67 6573 2028 4b72  me exchanges (Kr
-00000e00: 616b 656e 2920 646f 6e27 7420 7072 6f76  aken) don't prov
-00000e10: 6964 6520 6869 7374 6f72 7920 7669 6120  ide history via 
-00000e20: 6f68 6c63 760a 2020 2020 2020 2020 226f  ohlcv.        "o
-00000e30: 686c 6376 5f70 6172 7469 616c 5f63 616e  hlcv_partial_can
-00000e40: 646c 6522 3a20 5472 7565 2c0a 2020 2020  dle": True,.    
-00000e50: 2020 2020 226f 686c 6376 5f72 6571 7569      "ohlcv_requi
-00000e60: 7265 5f73 696e 6365 223a 2046 616c 7365  re_since": False
-00000e70: 2c0a 2020 2020 2020 2020 2320 4368 6563  ,.        # Chec
-00000e80: 6b20 6874 7470 733a 2f2f 6769 7468 7562  k https://github
-00000e90: 2e63 6f6d 2f63 6378 742f 6363 7874 2f69  .com/ccxt/ccxt/i
-00000ea0: 7373 7565 732f 3130 3736 3720 666f 7220  ssues/10767 for 
-00000eb0: 7265 6d6f 7661 6c20 6f66 206f 686c 6376  removal of ohlcv
-00000ec0: 5f76 6f6c 756d 655f 6375 7272 656e 6379  _volume_currency
-00000ed0: 0a20 2020 2020 2020 2022 6f68 6c63 765f  .        "ohlcv_
-00000ee0: 766f 6c75 6d65 5f63 7572 7265 6e63 7922  volume_currency"
-00000ef0: 3a20 2262 6173 6522 2c20 2023 2022 6261  : "base",  # "ba
-00000f00: 7365 2220 6f72 2022 7175 6f74 6522 0a20  se" or "quote". 
-00000f10: 2020 2020 2020 2022 7469 636b 6572 735f         "tickers_
-00000f20: 6861 7665 5f71 756f 7465 566f 6c75 6d65  have_quoteVolume
-00000f30: 223a 2054 7275 652c 0a20 2020 2020 2020  ": True,.       
-00000f40: 2022 7469 636b 6572 735f 6861 7665 5f62   "tickers_have_b
-00000f50: 6964 5f61 736b 223a 2054 7275 652c 2020  id_ask": True,  
-00000f60: 2320 6269 6420 2f20 6173 6b20 656d 7074  # bid / ask empt
-00000f70: 7920 666f 7220 6665 7463 685f 7469 636b  y for fetch_tick
-00000f80: 6572 730a 2020 2020 2020 2020 2274 6963  ers.        "tic
-00000f90: 6b65 7273 5f68 6176 655f 7072 6963 6522  kers_have_price"
-00000fa0: 3a20 5472 7565 2c0a 2020 2020 2020 2020  : True,.        
-00000fb0: 2274 7261 6465 735f 7061 6769 6e61 7469  "trades_paginati
-00000fc0: 6f6e 223a 2022 7469 6d65 222c 2020 2320  on": "time",  # 
-00000fd0: 506f 7373 6962 6c65 2061 7265 2022 7469  Possible are "ti
-00000fe0: 6d65 2220 6f72 2022 6964 220a 2020 2020  me" or "id".    
-00000ff0: 2020 2020 2274 7261 6465 735f 7061 6769      "trades_pagi
-00001000: 6e61 7469 6f6e 5f61 7267 223a 2022 7369  nation_arg": "si
-00001010: 6e63 6522 2c0a 2020 2020 2020 2020 226c  nce",.        "l
-00001020: 325f 6c69 6d69 745f 7261 6e67 6522 3a20  2_limit_range": 
-00001030: 4e6f 6e65 2c0a 2020 2020 2020 2020 226c  None,.        "l
-00001040: 325f 6c69 6d69 745f 7261 6e67 655f 7265  2_limit_range_re
-00001050: 7175 6972 6564 223a 2054 7275 652c 2020  quired": True,  
-00001060: 2320 416c 6c6f 7720 456d 7074 7920 4c32  # Allow Empty L2
-00001070: 206c 696d 6974 2028 6b75 636f 696e 290a   limit (kucoin).
-00001080: 2020 2020 2020 2020 226d 6172 6b5f 6f68          "mark_oh
-00001090: 6c63 765f 7072 6963 6522 3a20 226d 6172  lcv_price": "mar
-000010a0: 6b22 2c0a 2020 2020 2020 2020 226d 6172  k",.        "mar
-000010b0: 6b5f 6f68 6c63 765f 7469 6d65 6672 616d  k_ohlcv_timefram
-000010c0: 6522 3a20 2238 6822 2c0a 2020 2020 2020  e": "8h",.      
-000010d0: 2020 2266 756e 6469 6e67 5f66 6565 5f74    "funding_fee_t
-000010e0: 696d 6566 7261 6d65 223a 2022 3868 222c  imeframe": "8h",
-000010f0: 0a20 2020 2020 2020 2022 6363 7874 5f66  .        "ccxt_f
-00001100: 7574 7572 6573 5f6e 616d 6522 3a20 2273  utures_name": "s
-00001110: 7761 7022 2c0a 2020 2020 2020 2020 226e  wap",.        "n
-00001120: 6565 6473 5f74 7261 6469 6e67 5f66 6565  eeds_trading_fee
-00001130: 7322 3a20 4661 6c73 652c 2020 2320 7573  s": False,  # us
-00001140: 6520 6665 7463 685f 7472 6164 696e 675f  e fetch_trading_
-00001150: 6665 6573 2074 6f20 6361 6368 6520 6665  fees to cache fe
-00001160: 6573 0a20 2020 2020 2020 2022 6f72 6465  es.        "orde
-00001170: 725f 7072 6f70 735f 696e 5f63 6f6e 7472  r_props_in_contr
-00001180: 6163 7473 223a 205b 2761 6d6f 756e 7427  acts": ['amount'
-00001190: 2c20 2766 696c 6c65 6427 2c20 2772 656d  , 'filled', 'rem
-000011a0: 6169 6e69 6e67 275d 2c0a 2020 2020 2020  aining'],.      
-000011b0: 2020 2320 4f76 6572 7269 6465 2063 7265    # Override cre
-000011c0: 6174 654d 6172 6b65 7442 7579 4f72 6465  ateMarketBuyOrde
-000011d0: 7252 6571 7569 7265 7350 7269 6365 2077  rRequiresPrice w
-000011e0: 6865 7265 2063 6378 7420 6861 7320 6974  here ccxt has it
-000011f0: 2077 726f 6e67 0a20 2020 2020 2020 2022   wrong.        "
-00001200: 6d61 726b 6574 4f72 6465 7252 6571 7569  marketOrderRequi
-00001210: 7265 7350 7269 6365 223a 2046 616c 7365  resPrice": False
-00001220: 2c0a 2020 2020 2020 2020 2265 7863 6861  ,.        "excha
-00001230: 6e67 655f 6861 735f 6f76 6572 7269 6465  nge_has_override
-00001240: 7322 3a20 7b7d 2c20 2023 2044 6963 7469  s": {},  # Dicti
-00001250: 6f6e 6172 7920 6f76 6572 7269 6469 6e67  onary overriding
-00001260: 2063 6378 7427 7320 2268 6173 222e 0a20   ccxt's "has".. 
-00001270: 2020 2020 2020 2023 2045 7870 6563 7465         # Expecte
-00001280: 6420 746f 2062 6520 696e 2074 6865 2066  d to be in the f
-00001290: 6f72 6d61 7420 7b22 6665 7463 684f 484c  ormat {"fetchOHL
-000012a0: 4356 223a 2054 7275 657d 206f 7220 7b22  CV": True} or {"
-000012b0: 6665 7463 684f 484c 4356 223a 2046 616c  fetchOHLCV": Fal
-000012c0: 7365 7d0a 2020 2020 7d0a 2020 2020 5f66  se}.    }.    _f
-000012d0: 745f 6861 733a 2044 6963 7420 3d20 7b7d  t_has: Dict = {}
-000012e0: 0a20 2020 205f 6674 5f68 6173 5f66 7574  .    _ft_has_fut
-000012f0: 7572 6573 3a20 4469 6374 203d 207b 7d0a  ures: Dict = {}.
-00001300: 0a20 2020 205f 7375 7070 6f72 7465 645f  .    _supported_
-00001310: 7472 6164 696e 675f 6d6f 6465 5f6d 6172  trading_mode_mar
-00001320: 6769 6e5f 7061 6972 733a 204c 6973 745b  gin_pairs: List[
-00001330: 5475 706c 655b 5472 6164 696e 674d 6f64  Tuple[TradingMod
-00001340: 652c 204d 6172 6769 6e4d 6f64 655d 5d20  e, MarginMode]] 
-00001350: 3d20 5b0a 2020 2020 2020 2020 2320 5472  = [.        # Tr
-00001360: 6164 696e 674d 6f64 652e 5350 4f54 2061  adingMode.SPOT a
-00001370: 6c77 6179 7320 7375 7070 6f72 7465 6420  lways supported 
-00001380: 616e 6420 6e6f 7420 7265 7175 6972 6564  and not required
-00001390: 2069 6e20 7468 6973 206c 6973 740a 2020   in this list.  
-000013a0: 2020 5d0a 0a20 2020 2064 6566 205f 5f69    ]..    def __i
-000013b0: 6e69 745f 5f28 7365 6c66 2c20 636f 6e66  nit__(self, conf
-000013c0: 6967 3a20 436f 6e66 6967 2c20 2a2c 2065  ig: Config, *, e
-000013d0: 7863 6861 6e67 655f 636f 6e66 6967 3a20  xchange_config: 
-000013e0: 4f70 7469 6f6e 616c 5b45 7863 6861 6e67  Optional[Exchang
-000013f0: 6543 6f6e 6669 675d 203d 204e 6f6e 652c  eConfig] = None,
-00001400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001410: 2020 7661 6c69 6461 7465 3a20 626f 6f6c    validate: bool
-00001420: 203d 2054 7275 652c 206c 6f61 645f 6c65   = True, load_le
-00001430: 7665 7261 6765 5f74 6965 7273 3a20 626f  verage_tiers: bo
-00001440: 6f6c 203d 2046 616c 7365 2920 2d3e 204e  ol = False) -> N
-00001450: 6f6e 653a 0a20 2020 2020 2020 2022 2222  one:.        """
-00001460: 0a20 2020 2020 2020 2049 6e69 7469 616c  .        Initial
-00001470: 697a 6573 2074 6869 7320 6d6f 6475 6c65  izes this module
-00001480: 2077 6974 6820 7468 6520 6769 7665 6e20   with the given 
-00001490: 636f 6e66 6967 2c0a 2020 2020 2020 2020  config,.        
-000014a0: 6974 2064 6f65 7320 6261 7369 6320 7661  it does basic va
-000014b0: 6c69 6461 7469 6f6e 2077 6865 7468 6572  lidation whether
-000014c0: 2074 6865 2073 7065 6369 6669 6564 2065   the specified e
-000014d0: 7863 6861 6e67 6520 616e 6420 7061 6972  xchange and pair
-000014e0: 7320 6172 6520 7661 6c69 642e 0a20 2020  s are valid..   
-000014f0: 2020 2020 203a 7265 7475 726e 3a20 4e6f       :return: No
-00001500: 6e65 0a20 2020 2020 2020 2022 2222 0a20  ne.        """. 
-00001510: 2020 2020 2020 2073 656c 662e 5f61 7069         self._api
-00001520: 3a20 6363 7874 2e45 7863 6861 6e67 650a  : ccxt.Exchange.
-00001530: 2020 2020 2020 2020 7365 6c66 2e5f 6170          self._ap
-00001540: 695f 6173 796e 633a 2063 6378 745f 6173  i_async: ccxt_as
-00001550: 796e 632e 4578 6368 616e 6765 203d 204e  ync.Exchange = N
-00001560: 6f6e 650a 2020 2020 2020 2020 7365 6c66  one.        self
-00001570: 2e5f 6d61 726b 6574 733a 2044 6963 7420  ._markets: Dict 
-00001580: 3d20 7b7d 0a20 2020 2020 2020 2073 656c  = {}.        sel
-00001590: 662e 5f74 7261 6469 6e67 5f66 6565 733a  f._trading_fees:
-000015a0: 2044 6963 745b 7374 722c 2041 6e79 5d20   Dict[str, Any] 
-000015b0: 3d20 7b7d 0a20 2020 2020 2020 2073 656c  = {}.        sel
-000015c0: 662e 5f6c 6576 6572 6167 655f 7469 6572  f._leverage_tier
-000015d0: 733a 2044 6963 745b 7374 722c 204c 6973  s: Dict[str, Lis
-000015e0: 745b 4469 6374 5d5d 203d 207b 7d0a 2020  t[Dict]] = {}.  
-000015f0: 2020 2020 2020 2320 4c6f 636b 2065 7665        # Lock eve
-00001600: 6e74 206c 6f6f 702e 2054 6869 7320 6973  nt loop. This is
-00001610: 206e 6563 6573 7361 7279 2074 6f20 6176   necessary to av
-00001620: 6f69 6420 7261 6365 2d63 6f6e 6469 7469  oid race-conditi
-00001630: 6f6e 7320 7768 656e 2075 7369 6e67 2066  ons when using f
-00001640: 6f72 6365 2a20 636f 6d6d 616e 6473 0a20  orce* commands. 
-00001650: 2020 2020 2020 2023 2044 7565 2074 6f20         # Due to 
-00001660: 6675 6e64 696e 6720 6665 6520 6665 7463  funding fee fetc
-00001670: 6869 6e67 2e0a 2020 2020 2020 2020 7365  hing..        se
-00001680: 6c66 2e5f 6c6f 6f70 5f6c 6f63 6b20 3d20  lf._loop_lock = 
-00001690: 4c6f 636b 2829 0a20 2020 2020 2020 2073  Lock().        s
-000016a0: 656c 662e 6c6f 6f70 203d 2073 656c 662e  elf.loop = self.
-000016b0: 5f69 6e69 745f 6173 796e 635f 6c6f 6f70  _init_async_loop
-000016c0: 2829 0a20 2020 2020 2020 2073 656c 662e  ().        self.
-000016d0: 5f63 6f6e 6669 673a 2043 6f6e 6669 6720  _config: Config 
-000016e0: 3d20 7b7d 0a0a 2020 2020 2020 2020 7365  = {}..        se
-000016f0: 6c66 2e5f 636f 6e66 6967 2e75 7064 6174  lf._config.updat
-00001700: 6528 636f 6e66 6967 290a 0a20 2020 2020  e(config)..     
-00001710: 2020 2023 2048 6f6c 6473 206c 6173 7420     # Holds last 
-00001720: 6361 6e64 6c65 2072 6566 7265 7368 6564  candle refreshed
-00001730: 2074 696d 6520 6f66 2065 6163 6820 7061   time of each pa
-00001740: 6972 0a20 2020 2020 2020 2073 656c 662e  ir.        self.
-00001750: 5f70 6169 7273 5f6c 6173 745f 7265 6672  _pairs_last_refr
-00001760: 6573 685f 7469 6d65 3a20 4469 6374 5b50  esh_time: Dict[P
-00001770: 6169 7257 6974 6854 696d 6566 7261 6d65  airWithTimeframe
-00001780: 2c20 696e 745d 203d 207b 7d0a 2020 2020  , int] = {}.    
-00001790: 2020 2020 2320 5469 6d65 7374 616d 7020      # Timestamp 
-000017a0: 6f66 206c 6173 7420 6d61 726b 6574 7320  of last markets 
-000017b0: 7265 6672 6573 680a 2020 2020 2020 2020  refresh.        
-000017c0: 7365 6c66 2e5f 6c61 7374 5f6d 6172 6b65  self._last_marke
-000017d0: 7473 5f72 6566 7265 7368 3a20 696e 7420  ts_refresh: int 
-000017e0: 3d20 300a 0a20 2020 2020 2020 2023 2043  = 0..        # C
-000017f0: 6163 6865 2066 6f72 2031 3020 6d69 6e75  ache for 10 minu
-00001800: 7465 7320 2e2e 2e0a 2020 2020 2020 2020  tes ....        
-00001810: 7365 6c66 2e5f 6361 6368 655f 6c6f 636b  self._cache_lock
-00001820: 203d 204c 6f63 6b28 290a 2020 2020 2020   = Lock().      
-00001830: 2020 7365 6c66 2e5f 6665 7463 685f 7469    self._fetch_ti
-00001840: 636b 6572 735f 6361 6368 653a 2054 544c  ckers_cache: TTL
-00001850: 4361 6368 6520 3d20 5454 4c43 6163 6865  Cache = TTLCache
-00001860: 286d 6178 7369 7a65 3d32 2c20 7474 6c3d  (maxsize=2, ttl=
-00001870: 3630 202a 2031 3029 0a20 2020 2020 2020  60 * 10).       
-00001880: 2023 2043 6163 6865 2076 616c 7565 7320   # Cache values 
-00001890: 666f 7220 3330 3020 746f 2061 766f 6964  for 300 to avoid
-000018a0: 2066 7265 7175 656e 7420 706f 6c6c 696e   frequent pollin
-000018b0: 6720 6f66 2074 6865 2065 7863 6861 6e67  g of the exchang
-000018c0: 6520 666f 7220 7072 6963 6573 0a20 2020  e for prices.   
-000018d0: 2020 2020 2023 2043 6163 6869 6e67 206f       # Caching o
-000018e0: 6e6c 7920 6170 706c 6965 7320 746f 2052  nly applies to R
-000018f0: 5043 206d 6574 686f 6473 2c20 736f 2070  PC methods, so p
-00001900: 7269 6365 7320 666f 7220 6f70 656e 2074  rices for open t
-00001910: 7261 6465 7320 6172 6520 7374 696c 6c0a  rades are still.
-00001920: 2020 2020 2020 2020 2320 7265 6672 6573          # refres
-00001930: 6865 6420 6f6e 6365 2065 7665 7279 2069  hed once every i
-00001940: 7465 7261 7469 6f6e 2e0a 2020 2020 2020  teration..      
-00001950: 2020 2320 5368 6f75 6c64 6e27 7420 6265    # Shouldn't be
-00001960: 2074 6f6f 2068 6967 6820 6569 7468 6572   too high either
-00001970: 2c20 6173 2069 7427 6c6c 2066 7265 657a  , as it'll freez
-00001980: 6520 5549 2075 7064 6174 6573 2069 6e20  e UI updates in 
-00001990: 6361 7365 206f 6620 6f70 656e 206f 7264  case of open ord
-000019a0: 6572 732e 0a20 2020 2020 2020 2073 656c  ers..        sel
-000019b0: 662e 5f65 7869 745f 7261 7465 5f63 6163  f._exit_rate_cac
-000019c0: 6865 3a20 5454 4c43 6163 6865 203d 2054  he: TTLCache = T
-000019d0: 544c 4361 6368 6528 6d61 7873 697a 653d  TLCache(maxsize=
-000019e0: 3130 302c 2074 746c 3d33 3030 290a 2020  100, ttl=300).  
-000019f0: 2020 2020 2020 7365 6c66 2e5f 656e 7472        self._entr
-00001a00: 795f 7261 7465 5f63 6163 6865 3a20 5454  y_rate_cache: TT
-00001a10: 4c43 6163 6865 203d 2054 544c 4361 6368  LCache = TTLCach
-00001a20: 6528 6d61 7873 697a 653d 3130 302c 2074  e(maxsize=100, t
-00001a30: 746c 3d33 3030 290a 0a20 2020 2020 2020  tl=300)..       
-00001a40: 2023 2048 6f6c 6473 2063 616e 646c 6573   # Holds candles
-00001a50: 0a20 2020 2020 2020 2073 656c 662e 5f6b  .        self._k
-00001a60: 6c69 6e65 733a 2044 6963 745b 5061 6972  lines: Dict[Pair
-00001a70: 5769 7468 5469 6d65 6672 616d 652c 2044  WithTimeframe, D
-00001a80: 6174 6146 7261 6d65 5d20 3d20 7b7d 0a20  ataFrame] = {}. 
-00001a90: 2020 2020 2020 2073 656c 662e 5f65 7870         self._exp
-00001aa0: 6972 696e 675f 6361 6e64 6c65 5f63 6163  iring_candle_cac
-00001ab0: 6865 3a20 4469 6374 5b54 7570 6c65 5b73  he: Dict[Tuple[s
-00001ac0: 7472 2c20 696e 745d 2c20 5065 7269 6f64  tr, int], Period
-00001ad0: 6963 4361 6368 655d 203d 207b 7d0a 0a20  icCache] = {}.. 
-00001ae0: 2020 2020 2020 2023 2048 6f6c 6473 2061         # Holds a
-00001af0: 6c6c 206f 7065 6e20 7365 6c6c 206f 7264  ll open sell ord
-00001b00: 6572 7320 666f 7220 6472 795f 7275 6e0a  ers for dry_run.
-00001b10: 2020 2020 2020 2020 7365 6c66 2e5f 6472          self._dr
-00001b20: 795f 7275 6e5f 6f70 656e 5f6f 7264 6572  y_run_open_order
-00001b30: 733a 2044 6963 745b 7374 722c 2041 6e79  s: Dict[str, Any
-00001b40: 5d20 3d20 7b7d 0a0a 2020 2020 2020 2020  ] = {}..        
-00001b50: 6966 2063 6f6e 6669 675b 2764 7279 5f72  if config['dry_r
-00001b60: 756e 275d 3a0a 2020 2020 2020 2020 2020  un']:.          
-00001b70: 2020 6c6f 6767 6572 2e69 6e66 6f28 2749    logger.info('I
-00001b80: 6e73 7461 6e63 6520 6973 2072 756e 6e69  nstance is runni
-00001b90: 6e67 2077 6974 6820 6472 795f 7275 6e20  ng with dry_run 
-00001ba0: 656e 6162 6c65 6427 290a 2020 2020 2020  enabled').      
-00001bb0: 2020 6c6f 6767 6572 2e69 6e66 6f28 6622    logger.info(f"
-00001bc0: 5573 696e 6720 4343 5854 207b 6363 7874  Using CCXT {ccxt
-00001bd0: 2e5f 5f76 6572 7369 6f6e 5f5f 7d22 290a  .__version__}").
-00001be0: 2020 2020 2020 2020 6578 6368 616e 6765          exchange
-00001bf0: 5f63 6f6e 663a 2044 6963 745b 7374 722c  _conf: Dict[str,
-00001c00: 2041 6e79 5d20 3d20 6578 6368 616e 6765   Any] = exchange
-00001c10: 5f63 6f6e 6669 6720 6966 2065 7863 6861  _config if excha
-00001c20: 6e67 655f 636f 6e66 6967 2065 6c73 6520  nge_config else 
-00001c30: 636f 6e66 6967 5b27 6578 6368 616e 6765  config['exchange
-00001c40: 275d 0a20 2020 2020 2020 2072 656d 6f76  '].        remov
-00001c50: 655f 6578 6368 616e 6765 5f63 7265 6465  e_exchange_crede
-00001c60: 6e74 6961 6c73 2865 7863 6861 6e67 655f  ntials(exchange_
-00001c70: 636f 6e66 2c20 636f 6e66 6967 2e67 6574  conf, config.get
-00001c80: 2827 6472 795f 7275 6e27 2c20 4661 6c73  ('dry_run', Fals
-00001c90: 6529 290a 2020 2020 2020 2020 7365 6c66  e)).        self
-00001ca0: 2e6c 6f67 5f72 6573 706f 6e73 6573 203d  .log_responses =
-00001cb0: 2065 7863 6861 6e67 655f 636f 6e66 2e67   exchange_conf.g
-00001cc0: 6574 2827 6c6f 675f 7265 7370 6f6e 7365  et('log_response
-00001cd0: 7327 2c20 4661 6c73 6529 0a0a 2020 2020  s', False)..    
-00001ce0: 2020 2020 2320 4c65 7665 7261 6765 2070      # Leverage p
-00001cf0: 726f 7065 7274 6965 730a 2020 2020 2020  roperties.      
-00001d00: 2020 7365 6c66 2e74 7261 6469 6e67 5f6d    self.trading_m
-00001d10: 6f64 653a 2054 7261 6469 6e67 4d6f 6465  ode: TradingMode
-00001d20: 203d 2063 6f6e 6669 672e 6765 7428 2774   = config.get('t
-00001d30: 7261 6469 6e67 5f6d 6f64 6527 2c20 5472  rading_mode', Tr
-00001d40: 6164 696e 674d 6f64 652e 5350 4f54 290a  adingMode.SPOT).
-00001d50: 2020 2020 2020 2020 7365 6c66 2e6d 6172          self.mar
-00001d60: 6769 6e5f 6d6f 6465 3a20 4d61 7267 696e  gin_mode: Margin
-00001d70: 4d6f 6465 203d 2028 0a20 2020 2020 2020  Mode = (.       
-00001d80: 2020 2020 204d 6172 6769 6e4d 6f64 6528       MarginMode(
-00001d90: 636f 6e66 6967 2e67 6574 2827 6d61 7267  config.get('marg
-00001da0: 696e 5f6d 6f64 6527 2929 0a20 2020 2020  in_mode')).     
-00001db0: 2020 2020 2020 2069 6620 636f 6e66 6967         if config
-00001dc0: 2e67 6574 2827 6d61 7267 696e 5f6d 6f64  .get('margin_mod
-00001dd0: 6527 290a 2020 2020 2020 2020 2020 2020  e').            
-00001de0: 656c 7365 204d 6172 6769 6e4d 6f64 652e  else MarginMode.
-00001df0: 4e4f 4e45 0a20 2020 2020 2020 2029 0a20  NONE.        ). 
-00001e00: 2020 2020 2020 2073 656c 662e 6c69 7175         self.liqu
-00001e10: 6964 6174 696f 6e5f 6275 6666 6572 203d  idation_buffer =
-00001e20: 2063 6f6e 6669 672e 6765 7428 276c 6971   config.get('liq
-00001e30: 7569 6461 7469 6f6e 5f62 7566 6665 7227  uidation_buffer'
-00001e40: 2c20 302e 3035 290a 0a20 2020 2020 2020  , 0.05)..       
-00001e50: 2023 2044 6565 7020 6d65 7267 6520 6674   # Deep merge ft
-00001e60: 5f68 6173 2077 6974 6820 6465 6661 756c  _has with defaul
-00001e70: 7420 6674 5f68 6173 206f 7074 696f 6e73  t ft_has options
-00001e80: 0a20 2020 2020 2020 2073 656c 662e 5f66  .        self._f
-00001e90: 745f 6861 7320 3d20 6465 6570 5f6d 6572  t_has = deep_mer
-00001ea0: 6765 5f64 6963 7473 2873 656c 662e 5f66  ge_dicts(self._f
-00001eb0: 745f 6861 732c 2064 6565 7063 6f70 7928  t_has, deepcopy(
-00001ec0: 7365 6c66 2e5f 6674 5f68 6173 5f64 6566  self._ft_has_def
-00001ed0: 6175 6c74 2929 0a20 2020 2020 2020 2069  ault)).        i
-00001ee0: 6620 7365 6c66 2e74 7261 6469 6e67 5f6d  f self.trading_m
-00001ef0: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
-00001f00: 6465 2e46 5554 5552 4553 3a0a 2020 2020  de.FUTURES:.    
-00001f10: 2020 2020 2020 2020 7365 6c66 2e5f 6674          self._ft
-00001f20: 5f68 6173 203d 2064 6565 705f 6d65 7267  _has = deep_merg
-00001f30: 655f 6469 6374 7328 7365 6c66 2e5f 6674  e_dicts(self._ft
-00001f40: 5f68 6173 5f66 7574 7572 6573 2c20 7365  _has_futures, se
-00001f50: 6c66 2e5f 6674 5f68 6173 290a 2020 2020  lf._ft_has).    
-00001f60: 2020 2020 6966 2065 7863 6861 6e67 655f      if exchange_
-00001f70: 636f 6e66 2e67 6574 2827 5f66 745f 6861  conf.get('_ft_ha
-00001f80: 735f 7061 7261 6d73 2729 3a0a 2020 2020  s_params'):.    
-00001f90: 2020 2020 2020 2020 7365 6c66 2e5f 6674          self._ft
-00001fa0: 5f68 6173 203d 2064 6565 705f 6d65 7267  _has = deep_merg
-00001fb0: 655f 6469 6374 7328 6578 6368 616e 6765  e_dicts(exchange
-00001fc0: 5f63 6f6e 662e 6765 7428 275f 6674 5f68  _conf.get('_ft_h
-00001fd0: 6173 5f70 6172 616d 7327 292c 0a20 2020  as_params'),.   
-00001fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002000: 2020 2020 2020 2020 2073 656c 662e 5f66           self._f
-00002010: 745f 6861 7329 0a20 2020 2020 2020 2020  t_has).         
-00002020: 2020 206c 6f67 6765 722e 696e 666f 2822     logger.info("
-00002030: 4f76 6572 7269 6469 6e67 2065 7863 6861  Overriding excha
-00002040: 6e67 652e 5f66 745f 6861 7320 7769 7468  nge._ft_has with
-00002050: 2063 6f6e 6669 6720 7061 7261 6d73 2c20   config params, 
-00002060: 7265 7375 6c74 3a20 2573 222c 2073 656c  result: %s", sel
-00002070: 662e 5f66 745f 6861 7329 0a0a 2020 2020  f._ft_has)..    
-00002080: 2020 2020 2320 4173 7369 676e 2074 6869      # Assign thi
-00002090: 7320 6469 7265 6374 6c79 2066 6f72 2065  s directly for e
-000020a0: 6173 7920 6163 6365 7373 0a20 2020 2020  asy access.     
-000020b0: 2020 2073 656c 662e 5f6f 686c 6376 5f70     self._ohlcv_p
-000020c0: 6172 7469 616c 5f63 616e 646c 6520 3d20  artial_candle = 
-000020d0: 7365 6c66 2e5f 6674 5f68 6173 5b27 6f68  self._ft_has['oh
-000020e0: 6c63 765f 7061 7274 6961 6c5f 6361 6e64  lcv_partial_cand
-000020f0: 6c65 275d 0a0a 2020 2020 2020 2020 7365  le']..        se
-00002100: 6c66 2e5f 7472 6164 6573 5f70 6167 696e  lf._trades_pagin
-00002110: 6174 696f 6e20 3d20 7365 6c66 2e5f 6674  ation = self._ft
-00002120: 5f68 6173 5b27 7472 6164 6573 5f70 6167  _has['trades_pag
-00002130: 696e 6174 696f 6e27 5d0a 2020 2020 2020  ination'].      
-00002140: 2020 7365 6c66 2e5f 7472 6164 6573 5f70    self._trades_p
-00002150: 6167 696e 6174 696f 6e5f 6172 6720 3d20  agination_arg = 
-00002160: 7365 6c66 2e5f 6674 5f68 6173 5b27 7472  self._ft_has['tr
-00002170: 6164 6573 5f70 6167 696e 6174 696f 6e5f  ades_pagination_
-00002180: 6172 6727 5d0a 0a20 2020 2020 2020 2023  arg']..        #
-00002190: 2049 6e69 7469 616c 697a 6520 6363 7874   Initialize ccxt
-000021a0: 206f 626a 6563 7473 0a20 2020 2020 2020   objects.       
-000021b0: 2063 6378 745f 636f 6e66 6967 203d 2073   ccxt_config = s
-000021c0: 656c 662e 5f63 6378 745f 636f 6e66 6967  elf._ccxt_config
-000021d0: 0a20 2020 2020 2020 2063 6378 745f 636f  .        ccxt_co
-000021e0: 6e66 6967 203d 2064 6565 705f 6d65 7267  nfig = deep_merg
-000021f0: 655f 6469 6374 7328 6578 6368 616e 6765  e_dicts(exchange
-00002200: 5f63 6f6e 662e 6765 7428 2763 6378 745f  _conf.get('ccxt_
-00002210: 636f 6e66 6967 272c 207b 7d29 2c20 6363  config', {}), cc
-00002220: 7874 5f63 6f6e 6669 6729 0a20 2020 2020  xt_config).     
-00002230: 2020 2063 6378 745f 636f 6e66 6967 203d     ccxt_config =
-00002240: 2064 6565 705f 6d65 7267 655f 6469 6374   deep_merge_dict
-00002250: 7328 6578 6368 616e 6765 5f63 6f6e 662e  s(exchange_conf.
-00002260: 6765 7428 2763 6378 745f 7379 6e63 5f63  get('ccxt_sync_c
-00002270: 6f6e 6669 6727 2c20 7b7d 292c 2063 6378  onfig', {}), ccx
-00002280: 745f 636f 6e66 6967 290a 0a20 2020 2020  t_config)..     
-00002290: 2020 2073 656c 662e 5f61 7069 203d 2073     self._api = s
-000022a0: 656c 662e 5f69 6e69 745f 6363 7874 2865  elf._init_ccxt(e
-000022b0: 7863 6861 6e67 655f 636f 6e66 2c20 6363  xchange_conf, cc
-000022c0: 7874 5f6b 7761 7267 733d 6363 7874 5f63  xt_kwargs=ccxt_c
-000022d0: 6f6e 6669 6729 0a0a 2020 2020 2020 2020  onfig)..        
-000022e0: 6363 7874 5f61 7379 6e63 5f63 6f6e 6669  ccxt_async_confi
-000022f0: 6720 3d20 7365 6c66 2e5f 6363 7874 5f63  g = self._ccxt_c
-00002300: 6f6e 6669 670a 2020 2020 2020 2020 6363  onfig.        cc
-00002310: 7874 5f61 7379 6e63 5f63 6f6e 6669 6720  xt_async_config 
-00002320: 3d20 6465 6570 5f6d 6572 6765 5f64 6963  = deep_merge_dic
-00002330: 7473 2865 7863 6861 6e67 655f 636f 6e66  ts(exchange_conf
-00002340: 2e67 6574 2827 6363 7874 5f63 6f6e 6669  .get('ccxt_confi
-00002350: 6727 2c20 7b7d 292c 0a20 2020 2020 2020  g', {}),.       
-00002360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002380: 2020 2020 2020 6363 7874 5f61 7379 6e63        ccxt_async
-00002390: 5f63 6f6e 6669 6729 0a20 2020 2020 2020  _config).       
-000023a0: 2063 6378 745f 6173 796e 635f 636f 6e66   ccxt_async_conf
-000023b0: 6967 203d 2064 6565 705f 6d65 7267 655f  ig = deep_merge_
-000023c0: 6469 6374 7328 6578 6368 616e 6765 5f63  dicts(exchange_c
-000023d0: 6f6e 662e 6765 7428 2763 6378 745f 6173  onf.get('ccxt_as
-000023e0: 796e 635f 636f 6e66 6967 272c 207b 7d29  ync_config', {})
-000023f0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00002400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002410: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00002420: 6378 745f 6173 796e 635f 636f 6e66 6967  cxt_async_config
-00002430: 290a 2020 2020 2020 2020 7365 6c66 2e5f  ).        self._
-00002440: 6170 695f 6173 796e 6320 3d20 7365 6c66  api_async = self
-00002450: 2e5f 696e 6974 5f63 6378 7428 0a20 2020  ._init_ccxt(.   
-00002460: 2020 2020 2020 2020 2065 7863 6861 6e67           exchang
-00002470: 655f 636f 6e66 2c20 6363 7874 5f61 7379  e_conf, ccxt_asy
-00002480: 6e63 2c20 6363 7874 5f6b 7761 7267 733d  nc, ccxt_kwargs=
-00002490: 6363 7874 5f61 7379 6e63 5f63 6f6e 6669  ccxt_async_confi
-000024a0: 6729 0a0a 2020 2020 2020 2020 6c6f 6767  g)..        logg
-000024b0: 6572 2e69 6e66 6f28 6627 5573 696e 6720  er.info(f'Using 
-000024c0: 4578 6368 616e 6765 2022 7b73 656c 662e  Exchange "{self.
-000024d0: 6e61 6d65 7d22 2729 0a20 2020 2020 2020  name}"').       
-000024e0: 2073 656c 662e 7265 7175 6972 6564 5f63   self.required_c
-000024f0: 616e 646c 655f 6361 6c6c 5f63 6f75 6e74  andle_call_count
-00002500: 203d 2031 0a20 2020 2020 2020 2069 6620   = 1.        if 
-00002510: 7661 6c69 6461 7465 3a0a 2020 2020 2020  validate:.      
-00002520: 2020 2020 2020 2320 496e 6974 6961 6c20        # Initial 
-00002530: 6d61 726b 6574 7320 6c6f 6164 0a20 2020  markets load.   
-00002540: 2020 2020 2020 2020 2073 656c 662e 5f6c           self._l
-00002550: 6f61 645f 6d61 726b 6574 7328 290a 2020  oad_markets().  
-00002560: 2020 2020 2020 2020 2020 7365 6c66 2e76            self.v
-00002570: 616c 6964 6174 655f 636f 6e66 6967 2863  alidate_config(c
-00002580: 6f6e 6669 6729 0a20 2020 2020 2020 2020  onfig).         
-00002590: 2020 2073 656c 662e 5f73 7461 7274 7570     self._startup
-000025a0: 5f63 616e 646c 655f 636f 756e 743a 2069  _candle_count: i
-000025b0: 6e74 203d 2063 6f6e 6669 672e 6765 7428  nt = config.get(
-000025c0: 2773 7461 7274 7570 5f63 616e 646c 655f  'startup_candle_
-000025d0: 636f 756e 7427 2c20 3029 0a20 2020 2020  count', 0).     
-000025e0: 2020 2020 2020 2073 656c 662e 7265 7175         self.requ
-000025f0: 6972 6564 5f63 616e 646c 655f 6361 6c6c  ired_candle_call
-00002600: 5f63 6f75 6e74 203d 2073 656c 662e 7661  _count = self.va
-00002610: 6c69 6461 7465 5f72 6571 7569 7265 645f  lidate_required_
-00002620: 7374 6172 7475 705f 6361 6e64 6c65 7328  startup_candles(
-00002630: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002640: 2073 656c 662e 5f73 7461 7274 7570 5f63   self._startup_c
-00002650: 616e 646c 655f 636f 756e 742c 2063 6f6e  andle_count, con
-00002660: 6669 672e 6765 7428 2774 696d 6566 7261  fig.get('timefra
-00002670: 6d65 272c 2027 2729 290a 0a20 2020 2020  me', ''))..     
-00002680: 2020 2023 2043 6f6e 7665 7274 7320 7468     # Converts th
-00002690: 6520 696e 7465 7276 616c 2070 726f 7669  e interval provi
-000026a0: 6465 6420 696e 206d 696e 7574 6573 2069  ded in minutes i
-000026b0: 6e20 636f 6e66 6967 2074 6f20 7365 636f  n config to seco
-000026c0: 6e64 730a 2020 2020 2020 2020 7365 6c66  nds.        self
-000026d0: 2e6d 6172 6b65 7473 5f72 6566 7265 7368  .markets_refresh
-000026e0: 5f69 6e74 6572 7661 6c3a 2069 6e74 203d  _interval: int =
-000026f0: 2065 7863 6861 6e67 655f 636f 6e66 2e67   exchange_conf.g
-00002700: 6574 280a 2020 2020 2020 2020 2020 2020  et(.            
-00002710: 226d 6172 6b65 7473 5f72 6566 7265 7368  "markets_refresh
-00002720: 5f69 6e74 6572 7661 6c22 2c20 3630 2920  _interval", 60) 
-00002730: 2a20 3630 202a 2031 3030 300a 0a20 2020  * 60 * 1000..   
-00002740: 2020 2020 2069 6620 7365 6c66 2e74 7261       if self.tra
-00002750: 6469 6e67 5f6d 6f64 6520 213d 2054 7261  ding_mode != Tra
-00002760: 6469 6e67 4d6f 6465 2e53 504f 5420 616e  dingMode.SPOT an
-00002770: 6420 6c6f 6164 5f6c 6576 6572 6167 655f  d load_leverage_
-00002780: 7469 6572 733a 0a20 2020 2020 2020 2020  tiers:.         
-00002790: 2020 2073 656c 662e 6669 6c6c 5f6c 6576     self.fill_lev
-000027a0: 6572 6167 655f 7469 6572 7328 290a 2020  erage_tiers().  
-000027b0: 2020 2020 2020 7365 6c66 2e61 6464 6974        self.addit
-000027c0: 696f 6e61 6c5f 6578 6368 616e 6765 5f69  ional_exchange_i
-000027d0: 6e69 7428 290a 0a20 2020 2064 6566 205f  nit()..    def _
-000027e0: 5f64 656c 5f5f 2873 656c 6629 3a0a 2020  _del__(self):.  
-000027f0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-00002800: 2020 4465 7374 7275 6374 6f72 202d 2063    Destructor - c
-00002810: 6c65 616e 2075 7020 6173 796e 6320 7374  lean up async st
-00002820: 7566 660a 2020 2020 2020 2020 2222 220a  uff.        """.
-00002830: 2020 2020 2020 2020 7365 6c66 2e63 6c6f          self.clo
-00002840: 7365 2829 0a0a 2020 2020 6465 6620 636c  se()..    def cl
-00002850: 6f73 6528 7365 6c66 293a 0a20 2020 2020  ose(self):.     
-00002860: 2020 206c 6f67 6765 722e 6465 6275 6728     logger.debug(
-00002870: 2245 7863 6861 6e67 6520 6f62 6a65 6374  "Exchange object
-00002880: 2064 6573 7472 6f79 6564 2c20 636c 6f73   destroyed, clos
-00002890: 696e 6720 6173 796e 6320 6c6f 6f70 2229  ing async loop")
-000028a0: 0a20 2020 2020 2020 2069 6620 2873 656c  .        if (sel
-000028b0: 662e 5f61 7069 5f61 7379 6e63 2061 6e64  f._api_async and
-000028c0: 2069 6e73 7065 6374 2e69 7363 6f72 6f75   inspect.iscorou
-000028d0: 7469 6e65 6675 6e63 7469 6f6e 2873 656c  tinefunction(sel
-000028e0: 662e 5f61 7069 5f61 7379 6e63 2e63 6c6f  f._api_async.clo
-000028f0: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
-00002900: 2020 2020 616e 6420 7365 6c66 2e5f 6170      and self._ap
-00002910: 695f 6173 796e 632e 7365 7373 696f 6e29  i_async.session)
-00002920: 3a0a 2020 2020 2020 2020 2020 2020 6c6f  :.            lo
-00002930: 6767 6572 2e64 6562 7567 2822 436c 6f73  gger.debug("Clos
-00002940: 696e 6720 6173 796e 6320 6363 7874 2073  ing async ccxt s
-00002950: 6573 7369 6f6e 2e22 290a 2020 2020 2020  ession.").      
-00002960: 2020 2020 2020 7365 6c66 2e6c 6f6f 702e        self.loop.
-00002970: 7275 6e5f 756e 7469 6c5f 636f 6d70 6c65  run_until_comple
-00002980: 7465 2873 656c 662e 5f61 7069 5f61 7379  te(self._api_asy
-00002990: 6e63 2e63 6c6f 7365 2829 290a 2020 2020  nc.close()).    
-000029a0: 2020 2020 6966 2073 656c 662e 6c6f 6f70      if self.loop
-000029b0: 2061 6e64 206e 6f74 2073 656c 662e 6c6f   and not self.lo
-000029c0: 6f70 2e69 735f 636c 6f73 6564 2829 3a0a  op.is_closed():.
-000029d0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000029e0: 2e6c 6f6f 702e 636c 6f73 6528 290a 0a20  .loop.close().. 
-000029f0: 2020 2064 6566 205f 696e 6974 5f61 7379     def _init_asy
-00002a00: 6e63 5f6c 6f6f 7028 7365 6c66 2920 2d3e  nc_loop(self) ->
-00002a10: 2061 7379 6e63 696f 2e41 6273 7472 6163   asyncio.Abstrac
-00002a20: 7445 7665 6e74 4c6f 6f70 3a0a 2020 2020  tEventLoop:.    
-00002a30: 2020 2020 6c6f 6f70 203d 2061 7379 6e63      loop = async
-00002a40: 696f 2e6e 6577 5f65 7665 6e74 5f6c 6f6f  io.new_event_loo
-00002a50: 7028 290a 2020 2020 2020 2020 6173 796e  p().        asyn
-00002a60: 6369 6f2e 7365 745f 6576 656e 745f 6c6f  cio.set_event_lo
-00002a70: 6f70 286c 6f6f 7029 0a20 2020 2020 2020  op(loop).       
-00002a80: 2072 6574 7572 6e20 6c6f 6f70 0a0a 2020   return loop..  
-00002a90: 2020 6465 6620 7661 6c69 6461 7465 5f63    def validate_c
-00002aa0: 6f6e 6669 6728 7365 6c66 2c20 636f 6e66  onfig(self, conf
-00002ab0: 6967 293a 0a20 2020 2020 2020 2023 2043  ig):.        # C
-00002ac0: 6865 636b 2069 6620 7469 6d65 6672 616d  heck if timefram
-00002ad0: 6520 6973 2061 7661 696c 6162 6c65 0a20  e is available. 
-00002ae0: 2020 2020 2020 2073 656c 662e 7661 6c69         self.vali
-00002af0: 6461 7465 5f74 696d 6566 7261 6d65 7328  date_timeframes(
-00002b00: 636f 6e66 6967 2e67 6574 2827 7469 6d65  config.get('time
-00002b10: 6672 616d 6527 2929 0a0a 2020 2020 2020  frame'))..      
-00002b20: 2020 2320 4368 6563 6b20 6966 2061 6c6c    # Check if all
-00002b30: 2070 6169 7273 2061 7265 2061 7661 696c   pairs are avail
-00002b40: 6162 6c65 0a20 2020 2020 2020 2073 656c  able.        sel
-00002b50: 662e 7661 6c69 6461 7465 5f73 7461 6b65  f.validate_stake
-00002b60: 6375 7272 656e 6379 2863 6f6e 6669 675b  currency(config[
-00002b70: 2773 7461 6b65 5f63 7572 7265 6e63 7927  'stake_currency'
-00002b80: 5d29 0a20 2020 2020 2020 2069 6620 6e6f  ]).        if no
-00002b90: 7420 636f 6e66 6967 5b27 6578 6368 616e  t config['exchan
-00002ba0: 6765 275d 2e67 6574 2827 736b 6970 5f70  ge'].get('skip_p
-00002bb0: 6169 725f 7661 6c69 6461 7469 6f6e 2729  air_validation')
-00002bc0: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
-00002bd0: 6c66 2e76 616c 6964 6174 655f 7061 6972  lf.validate_pair
-00002be0: 7328 636f 6e66 6967 5b27 6578 6368 616e  s(config['exchan
-00002bf0: 6765 275d 5b27 7061 6972 5f77 6869 7465  ge']['pair_white
-00002c00: 6c69 7374 275d 290a 2020 2020 2020 2020  list']).        
-00002c10: 7365 6c66 2e76 616c 6964 6174 655f 6f72  self.validate_or
-00002c20: 6465 7274 7970 6573 2863 6f6e 6669 672e  dertypes(config.
-00002c30: 6765 7428 276f 7264 6572 5f74 7970 6573  get('order_types
-00002c40: 272c 207b 7d29 290a 2020 2020 2020 2020  ', {})).        
-00002c50: 7365 6c66 2e76 616c 6964 6174 655f 6f72  self.validate_or
-00002c60: 6465 725f 7469 6d65 5f69 6e5f 666f 7263  der_time_in_forc
-00002c70: 6528 636f 6e66 6967 2e67 6574 2827 6f72  e(config.get('or
-00002c80: 6465 725f 7469 6d65 5f69 6e5f 666f 7263  der_time_in_forc
-00002c90: 6527 2c20 7b7d 2929 0a20 2020 2020 2020  e', {})).       
-00002ca0: 2073 656c 662e 7661 6c69 6461 7465 5f74   self.validate_t
-00002cb0: 7261 6469 6e67 5f6d 6f64 655f 616e 645f  rading_mode_and_
-00002cc0: 6d61 7267 696e 5f6d 6f64 6528 7365 6c66  margin_mode(self
-00002cd0: 2e74 7261 6469 6e67 5f6d 6f64 652c 2073  .trading_mode, s
-00002ce0: 656c 662e 6d61 7267 696e 5f6d 6f64 6529  elf.margin_mode)
-00002cf0: 0a20 2020 2020 2020 2073 656c 662e 7661  .        self.va
-00002d00: 6c69 6461 7465 5f70 7269 6369 6e67 2863  lidate_pricing(c
-00002d10: 6f6e 6669 675b 2765 7869 745f 7072 6963  onfig['exit_pric
-00002d20: 696e 6727 5d29 0a20 2020 2020 2020 2073  ing']).        s
-00002d30: 656c 662e 7661 6c69 6461 7465 5f70 7269  elf.validate_pri
-00002d40: 6369 6e67 2863 6f6e 6669 675b 2765 6e74  cing(config['ent
-00002d50: 7279 5f70 7269 6369 6e67 275d 290a 0a20  ry_pricing']).. 
-00002d60: 2020 2064 6566 205f 696e 6974 5f63 6378     def _init_ccx
-00002d70: 7428 7365 6c66 2c20 6578 6368 616e 6765  t(self, exchange
-00002d80: 5f63 6f6e 6669 673a 2044 6963 745b 7374  _config: Dict[st
-00002d90: 722c 2041 6e79 5d2c 2063 6378 745f 6d6f  r, Any], ccxt_mo
-00002da0: 6475 6c65 3a20 4363 7874 4d6f 6475 6c65  dule: CcxtModule
-00002db0: 5479 7065 203d 2063 6378 742c 202a 2c0a  Type = ccxt, *,.
-00002dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002dd0: 2020 2063 6378 745f 6b77 6172 6773 3a20     ccxt_kwargs: 
-00002de0: 4469 6374 2920 2d3e 2063 6378 742e 4578  Dict) -> ccxt.Ex
-00002df0: 6368 616e 6765 3a0a 2020 2020 2020 2020  change:.        
-00002e00: 2222 220a 2020 2020 2020 2020 496e 6974  """.        Init
-00002e10: 6961 6c69 7a65 2063 6378 7420 7769 7468  ialize ccxt with
-00002e20: 2067 6976 656e 2063 6f6e 6669 6720 616e   given config an
-00002e30: 6420 7265 7475 726e 2076 616c 6964 0a20  d return valid. 
-00002e40: 2020 2020 2020 2063 6378 7420 696e 7374         ccxt inst
-00002e50: 616e 6365 2e0a 2020 2020 2020 2020 2222  ance..        ""
-00002e60: 220a 2020 2020 2020 2020 2320 4669 6e64  ".        # Find
-00002e70: 206d 6174 6368 696e 6720 636c 6173 7320   matching class 
-00002e80: 666f 7220 7468 6520 6769 7665 6e20 6578  for the given ex
-00002e90: 6368 616e 6765 206e 616d 650a 2020 2020  change name.    
-00002ea0: 2020 2020 6e61 6d65 203d 2065 7863 6861      name = excha
-00002eb0: 6e67 655f 636f 6e66 6967 5b27 6e61 6d65  nge_config['name
-00002ec0: 275d 0a0a 2020 2020 2020 2020 6966 206e  ']..        if n
-00002ed0: 6f74 2069 735f 6578 6368 616e 6765 5f6b  ot is_exchange_k
-00002ee0: 6e6f 776e 5f63 6378 7428 6e61 6d65 2c20  nown_ccxt(name, 
-00002ef0: 6363 7874 5f6d 6f64 756c 6529 3a0a 2020  ccxt_module):.  
-00002f00: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00002f10: 4f70 6572 6174 696f 6e61 6c45 7863 6570  OperationalExcep
-00002f20: 7469 6f6e 2866 2745 7863 6861 6e67 6520  tion(f'Exchange 
-00002f30: 7b6e 616d 657d 2069 7320 6e6f 7420 7375  {name} is not su
-00002f40: 7070 6f72 7465 6420 6279 2063 6378 7427  pported by ccxt'
-00002f50: 290a 0a20 2020 2020 2020 2065 785f 636f  )..        ex_co
-00002f60: 6e66 6967 203d 207b 0a20 2020 2020 2020  nfig = {.       
-00002f70: 2020 2020 2027 6170 694b 6579 273a 2065       'apiKey': e
-00002f80: 7863 6861 6e67 655f 636f 6e66 6967 2e67  xchange_config.g
-00002f90: 6574 2827 6b65 7927 292c 0a20 2020 2020  et('key'),.     
-00002fa0: 2020 2020 2020 2027 7365 6372 6574 273a         'secret':
-00002fb0: 2065 7863 6861 6e67 655f 636f 6e66 6967   exchange_config
-00002fc0: 2e67 6574 2827 7365 6372 6574 2729 2c0a  .get('secret'),.
-00002fd0: 2020 2020 2020 2020 2020 2020 2770 6173              'pas
-00002fe0: 7377 6f72 6427 3a20 6578 6368 616e 6765  sword': exchange
-00002ff0: 5f63 6f6e 6669 672e 6765 7428 2770 6173  _config.get('pas
-00003000: 7377 6f72 6427 292c 0a20 2020 2020 2020  sword'),.       
-00003010: 2020 2020 2027 7569 6427 3a20 6578 6368       'uid': exch
-00003020: 616e 6765 5f63 6f6e 6669 672e 6765 7428  ange_config.get(
-00003030: 2775 6964 272c 2027 2729 2c0a 2020 2020  'uid', ''),.    
-00003040: 2020 2020 7d0a 2020 2020 2020 2020 6966      }.        if
-00003050: 2063 6378 745f 6b77 6172 6773 3a0a 2020   ccxt_kwargs:.  
-00003060: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
-00003070: 2e69 6e66 6f28 2741 7070 6c79 696e 6720  .info('Applying 
-00003080: 6164 6469 7469 6f6e 616c 2063 6378 7420  additional ccxt 
-00003090: 636f 6e66 6967 3a20 2573 272c 2063 6378  config: %s', ccx
-000030a0: 745f 6b77 6172 6773 290a 2020 2020 2020  t_kwargs).      
-000030b0: 2020 6966 2073 656c 662e 5f63 6378 745f    if self._ccxt_
-000030c0: 7061 7261 6d73 3a0a 2020 2020 2020 2020  params:.        
-000030d0: 2020 2020 2320 496e 6a65 6374 2073 7461      # Inject sta
-000030e0: 7469 6320 6f70 7469 6f6e 7320 6166 7465  tic options afte
-000030f0: 7220 7468 6520 6162 6f76 6520 6f75 7470  r the above outp
-00003100: 7574 2074 6f20 6e6f 7420 636f 6e66 7573  ut to not confus
-00003110: 6520 7573 6572 732e 0a20 2020 2020 2020  e users..       
-00003120: 2020 2020 2063 6378 745f 6b77 6172 6773       ccxt_kwargs
-00003130: 203d 2064 6565 705f 6d65 7267 655f 6469   = deep_merge_di
-00003140: 6374 7328 7365 6c66 2e5f 6363 7874 5f70  cts(self._ccxt_p
-00003150: 6172 616d 732c 2063 6378 745f 6b77 6172  arams, ccxt_kwar
-00003160: 6773 290a 2020 2020 2020 2020 6966 2063  gs).        if c
-00003170: 6378 745f 6b77 6172 6773 3a0a 2020 2020  cxt_kwargs:.    
-00003180: 2020 2020 2020 2020 6578 5f63 6f6e 6669          ex_confi
-00003190: 672e 7570 6461 7465 2863 6378 745f 6b77  g.update(ccxt_kw
-000031a0: 6172 6773 290a 2020 2020 2020 2020 7472  args).        tr
-000031b0: 793a 0a0a 2020 2020 2020 2020 2020 2020  y:..            
-000031c0: 6170 6920 3d20 6765 7461 7474 7228 6363  api = getattr(cc
-000031d0: 7874 5f6d 6f64 756c 652c 206e 616d 652e  xt_module, name.
-000031e0: 6c6f 7765 7228 2929 2865 785f 636f 6e66  lower())(ex_conf
-000031f0: 6967 290a 2020 2020 2020 2020 6578 6365  ig).        exce
-00003200: 7074 2028 4b65 7945 7272 6f72 2c20 4174  pt (KeyError, At
-00003210: 7472 6962 7574 6545 7272 6f72 2920 6173  tributeError) as
-00003220: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-00003230: 7261 6973 6520 4f70 6572 6174 696f 6e61  raise Operationa
-00003240: 6c45 7863 6570 7469 6f6e 2866 2745 7863  lException(f'Exc
-00003250: 6861 6e67 6520 7b6e 616d 657d 2069 7320  hange {name} is 
-00003260: 6e6f 7420 7375 7070 6f72 7465 6427 2920  not supported') 
-00003270: 6672 6f6d 2065 0a20 2020 2020 2020 2065  from e.        e
-00003280: 7863 6570 7420 6363 7874 2e42 6173 6545  xcept ccxt.BaseE
-00003290: 7272 6f72 2061 7320 653a 0a20 2020 2020  rror as e:.     
-000032a0: 2020 2020 2020 2072 6169 7365 204f 7065         raise Ope
-000032b0: 7261 7469 6f6e 616c 4578 6365 7074 696f  rationalExceptio
-000032c0: 6e28 6622 496e 6974 6961 6c69 7a61 7469  n(f"Initializati
-000032d0: 6f6e 206f 6620 6363 7874 2066 6169 6c65  on of ccxt faile
-000032e0: 642e 2052 6561 736f 6e3a 207b 657d 2229  d. Reason: {e}")
-000032f0: 2066 726f 6d20 650a 0a20 2020 2020 2020   from e..       
-00003300: 2072 6574 7572 6e20 6170 690a 0a20 2020   return api..   
-00003310: 2040 7072 6f70 6572 7479 0a20 2020 2064   @property.    d
-00003320: 6566 205f 6363 7874 5f63 6f6e 6669 6728  ef _ccxt_config(
-00003330: 7365 6c66 2920 2d3e 2044 6963 743a 0a20  self) -> Dict:. 
-00003340: 2020 2020 2020 2023 2050 6172 616d 6574         # Paramet
-00003350: 6572 7320 746f 2061 6464 2064 6972 6563  ers to add direc
-00003360: 746c 7920 746f 2063 6378 7420 7379 6e63  tly to ccxt sync
-00003370: 2f61 7379 6e63 2069 6e69 7469 616c 697a  /async initializ
-00003380: 6174 696f 6e2e 0a20 2020 2020 2020 2069  ation..        i
-00003390: 6620 7365 6c66 2e74 7261 6469 6e67 5f6d  f self.trading_m
-000033a0: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
-000033b0: 6465 2e4d 4152 4749 4e3a 0a20 2020 2020  de.MARGIN:.     
-000033c0: 2020 2020 2020 2072 6574 7572 6e20 7b0a         return {.
-000033d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000033e0: 226f 7074 696f 6e73 223a 207b 0a20 2020  "options": {.   
-000033f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003400: 2022 6465 6661 756c 7454 7970 6522 3a20   "defaultType": 
-00003410: 226d 6172 6769 6e22 0a20 2020 2020 2020  "margin".       
-00003420: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
-00003430: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
-00003440: 2065 6c69 6620 7365 6c66 2e74 7261 6469   elif self.tradi
-00003450: 6e67 5f6d 6f64 6520 3d3d 2054 7261 6469  ng_mode == Tradi
-00003460: 6e67 4d6f 6465 2e46 5554 5552 4553 3a0a  ngMode.FUTURES:.
-00003470: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00003480: 726e 207b 0a20 2020 2020 2020 2020 2020  rn {.           
-00003490: 2020 2020 2022 6f70 7469 6f6e 7322 3a20       "options": 
-000034a0: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
-000034b0: 2020 2020 2020 2264 6566 6175 6c74 5479        "defaultTy
-000034c0: 7065 223a 2073 656c 662e 5f66 745f 6861  pe": self._ft_ha
-000034d0: 735b 2263 6378 745f 6675 7475 7265 735f  s["ccxt_futures_
-000034e0: 6e61 6d65 225d 0a20 2020 2020 2020 2020  name"].         
-000034f0: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
-00003500: 2020 2020 207d 0a20 2020 2020 2020 2065       }.        e
-00003510: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00003520: 2072 6574 7572 6e20 7b7d 0a0a 2020 2020   return {}..    
-00003530: 4070 726f 7065 7274 790a 2020 2020 6465  @property.    de
-00003540: 6620 6e61 6d65 2873 656c 6629 202d 3e20  f name(self) -> 
-00003550: 7374 723a 0a20 2020 2020 2020 2022 2222  str:.        """
-00003560: 6578 6368 616e 6765 204e 616d 6520 2866  exchange Name (f
-00003570: 726f 6d20 6363 7874 2922 2222 0a20 2020  rom ccxt)""".   
-00003580: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00003590: 2e5f 6170 692e 6e61 6d65 0a0a 2020 2020  ._api.name..    
-000035a0: 4070 726f 7065 7274 790a 2020 2020 6465  @property.    de
-000035b0: 6620 6964 2873 656c 6629 202d 3e20 7374  f id(self) -> st
-000035c0: 723a 0a20 2020 2020 2020 2022 2222 6578  r:.        """ex
-000035d0: 6368 616e 6765 2063 6378 7420 6964 2222  change ccxt id""
-000035e0: 220a 2020 2020 2020 2020 7265 7475 726e  ".        return
-000035f0: 2073 656c 662e 5f61 7069 2e69 640a 0a20   self._api.id.. 
-00003600: 2020 2040 7072 6f70 6572 7479 0a20 2020     @property.   
-00003610: 2064 6566 2074 696d 6566 7261 6d65 7328   def timeframes(
-00003620: 7365 6c66 2920 2d3e 204c 6973 745b 7374  self) -> List[st
-00003630: 725d 3a0a 2020 2020 2020 2020 7265 7475  r]:.        retu
-00003640: 726e 206c 6973 7428 2873 656c 662e 5f61  rn list((self._a
-00003650: 7069 2e74 696d 6566 7261 6d65 7320 6f72  pi.timeframes or
-00003660: 207b 7d29 2e6b 6579 7328 2929 0a0a 2020   {}).keys())..  
-00003670: 2020 4070 726f 7065 7274 790a 2020 2020    @property.    
-00003680: 6465 6620 6d61 726b 6574 7328 7365 6c66  def markets(self
-00003690: 2920 2d3e 2044 6963 745b 7374 722c 2041  ) -> Dict[str, A
-000036a0: 6e79 5d3a 0a20 2020 2020 2020 2022 2222  ny]:.        """
-000036b0: 6578 6368 616e 6765 2063 6378 7420 6d61  exchange ccxt ma
-000036c0: 726b 6574 7322 2222 0a20 2020 2020 2020  rkets""".       
-000036d0: 2069 6620 6e6f 7420 7365 6c66 2e5f 6d61   if not self._ma
-000036e0: 726b 6574 733a 0a20 2020 2020 2020 2020  rkets:.         
-000036f0: 2020 206c 6f67 6765 722e 696e 666f 2822     logger.info("
-00003700: 4d61 726b 6574 7320 7765 7265 206e 6f74  Markets were not
-00003710: 206c 6f61 6465 642e 204c 6f61 6469 6e67   loaded. Loading
-00003720: 2074 6865 6d20 6e6f 772e 2e22 290a 2020   them now..").  
-00003730: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-00003740: 6c6f 6164 5f6d 6172 6b65 7473 2829 0a20  load_markets(). 
-00003750: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-00003760: 6c66 2e5f 6d61 726b 6574 730a 0a20 2020  lf._markets..   
-00003770: 2040 7072 6f70 6572 7479 0a20 2020 2064   @property.    d
-00003780: 6566 2070 7265 6369 7369 6f6e 4d6f 6465  ef precisionMode
-00003790: 2873 656c 6629 202d 3e20 696e 743a 0a20  (self) -> int:. 
-000037a0: 2020 2020 2020 2022 2222 6578 6368 616e         """exchan
-000037b0: 6765 2063 6378 7420 7072 6563 6973 696f  ge ccxt precisio
-000037c0: 6e4d 6f64 6522 2222 0a20 2020 2020 2020  nMode""".       
-000037d0: 2072 6574 7572 6e20 7365 6c66 2e5f 6170   return self._ap
-000037e0: 692e 7072 6563 6973 696f 6e4d 6f64 650a  i.precisionMode.
-000037f0: 0a20 2020 2064 6566 2061 6464 6974 696f  .    def additio
-00003800: 6e61 6c5f 6578 6368 616e 6765 5f69 6e69  nal_exchange_ini
-00003810: 7428 7365 6c66 2920 2d3e 204e 6f6e 653a  t(self) -> None:
-00003820: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00003830: 2020 2020 2041 6464 6974 696f 6e61 6c20       Additional 
-00003840: 6578 6368 616e 6765 2069 6e69 7469 616c  exchange initial
-00003850: 697a 6174 696f 6e20 6c6f 6769 632e 0a20  ization logic.. 
-00003860: 2020 2020 2020 202e 6170 6920 7769 6c6c         .api will
-00003870: 2062 6520 6176 6169 6c61 626c 6520 6174   be available at
-00003880: 2074 6869 7320 706f 696e 742e 0a20 2020   this point..   
-00003890: 2020 2020 204d 7573 7420 6265 206f 7665       Must be ove
-000038a0: 7272 6964 6465 6e20 696e 2063 6869 6c64  rridden in child
-000038b0: 206d 6574 686f 6473 2069 6620 7265 7175   methods if requ
-000038c0: 6972 6564 2e0a 2020 2020 2020 2020 2222  ired..        ""
-000038d0: 220a 2020 2020 2020 2020 7061 7373 0a0a  ".        pass..
-000038e0: 2020 2020 6465 6620 5f6c 6f67 5f65 7863      def _log_exc
-000038f0: 6861 6e67 655f 7265 7370 6f6e 7365 2873  hange_response(s
-00003900: 656c 662c 2065 6e64 706f 696e 743a 2073  elf, endpoint: s
-00003910: 7472 2c20 7265 7370 6f6e 7365 2c20 2a2c  tr, response, *,
-00003920: 2061 6464 5f69 6e66 6f3d 4e6f 6e65 2920   add_info=None) 
-00003930: 2d3e 204e 6f6e 653a 0a20 2020 2020 2020  -> None:.       
-00003940: 2022 2222 204c 6f67 2065 7863 6861 6e67   """ Log exchang
-00003950: 6520 7265 7370 6f6e 7365 7320 2222 220a  e responses """.
-00003960: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00003970: 6c6f 675f 7265 7370 6f6e 7365 733a 0a20  log_responses:. 
-00003980: 2020 2020 2020 2020 2020 2061 6464 5f69             add_i
-00003990: 6e66 6f5f 7374 7220 3d20 2222 2069 6620  nfo_str = "" if 
-000039a0: 6164 645f 696e 666f 2069 7320 4e6f 6e65  add_info is None
-000039b0: 2065 6c73 6520 6622 207b 6164 645f 696e   else f" {add_in
-000039c0: 666f 7d3a 2022 0a20 2020 2020 2020 2020  fo}: ".         
-000039d0: 2020 206c 6f67 6765 722e 696e 666f 2866     logger.info(f
-000039e0: 2241 5049 207b 656e 6470 6f69 6e74 7d3a  "API {endpoint}:
-000039f0: 207b 6164 645f 696e 666f 5f73 7472 7d7b   {add_info_str}{
-00003a00: 7265 7370 6f6e 7365 7d22 290a 0a20 2020  response}")..   
-00003a10: 2064 6566 206f 686c 6376 5f63 616e 646c   def ohlcv_candl
-00003a20: 655f 6c69 6d69 7428 0a20 2020 2020 2020  e_limit(.       
-00003a30: 2020 2020 2073 656c 662c 2074 696d 6566       self, timef
-00003a40: 7261 6d65 3a20 7374 722c 2063 616e 646c  rame: str, candl
-00003a50: 655f 7479 7065 3a20 4361 6e64 6c65 5479  e_type: CandleTy
-00003a60: 7065 2c20 7369 6e63 655f 6d73 3a20 4f70  pe, since_ms: Op
-00003a70: 7469 6f6e 616c 5b69 6e74 5d20 3d20 4e6f  tional[int] = No
-00003a80: 6e65 2920 2d3e 2069 6e74 3a0a 2020 2020  ne) -> int:.    
-00003a90: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-00003aa0: 4578 6368 616e 6765 206f 686c 6376 2063  Exchange ohlcv c
-00003ab0: 616e 646c 6520 6c69 6d69 740a 2020 2020  andle limit.    
-00003ac0: 2020 2020 5573 6573 206f 686c 6376 5f63      Uses ohlcv_c
-00003ad0: 616e 646c 655f 6c69 6d69 745f 7065 725f  andle_limit_per_
-00003ae0: 7469 6d65 6672 616d 6520 6966 2074 6865  timeframe if the
-00003af0: 2065 7863 6861 6e67 6520 6861 7320 6469   exchange has di
-00003b00: 6666 6572 656e 7420 6c69 6d69 7473 0a20  fferent limits. 
-00003b10: 2020 2020 2020 2070 6572 2074 696d 6566         per timef
-00003b20: 7261 6d65 2028 652e 672e 2062 6974 7472  rame (e.g. bittr
-00003b30: 6578 292c 206f 7468 6572 7769 7365 2066  ex), otherwise f
-00003b40: 616c 6c73 2062 6163 6b20 746f 206f 686c  alls back to ohl
-00003b50: 6376 5f63 616e 646c 655f 6c69 6d69 740a  cv_candle_limit.
-00003b60: 2020 2020 2020 2020 544f 444f 3a20 7468          TODO: th
-00003b70: 6973 2069 7320 6d6f 7374 206c 696b 656c  is is most likel
-00003b80: 7920 6e6f 206c 6f6e 6765 7220 6e65 6564  y no longer need
-00003b90: 6564 2073 696e 6365 206f 6e6c 7920 6269  ed since only bi
-00003ba0: 7474 7265 7820 6e65 6564 6564 2074 6869  ttrex needed thi
-00003bb0: 732e 0a20 2020 2020 2020 203a 7061 7261  s..        :para
-00003bc0: 6d20 7469 6d65 6672 616d 653a 2054 696d  m timeframe: Tim
-00003bd0: 6566 7261 6d65 2074 6f20 6368 6563 6b0a  eframe to check.
-00003be0: 2020 2020 2020 2020 3a70 6172 616d 2063          :param c
-00003bf0: 616e 646c 655f 7479 7065 3a20 4361 6e64  andle_type: Cand
-00003c00: 6c65 2d74 7970 650a 2020 2020 2020 2020  le-type.        
-00003c10: 3a70 6172 616d 2073 696e 6365 5f6d 733a  :param since_ms:
-00003c20: 2053 7461 7274 696e 6720 7469 6d65 7374   Starting timest
-00003c30: 616d 700a 2020 2020 2020 2020 3a72 6574  amp.        :ret
-00003c40: 7572 6e3a 2043 616e 646c 6520 6c69 6d69  urn: Candle limi
-00003c50: 7420 6173 2069 6e74 6567 6572 0a20 2020  t as integer.   
-00003c60: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00003c70: 2072 6574 7572 6e20 696e 7428 7365 6c66   return int(self
-00003c80: 2e5f 6674 5f68 6173 2e67 6574 2827 6f68  ._ft_has.get('oh
-00003c90: 6c63 765f 6361 6e64 6c65 5f6c 696d 6974  lcv_candle_limit
-00003ca0: 5f70 6572 5f74 696d 6566 7261 6d65 272c  _per_timeframe',
-00003cb0: 207b 7d29 2e67 6574 280a 2020 2020 2020   {}).get(.      
-00003cc0: 2020 2020 2020 7469 6d65 6672 616d 652c        timeframe,
-00003cd0: 2073 656c 662e 5f66 745f 6861 732e 6765   self._ft_has.ge
-00003ce0: 7428 276f 686c 6376 5f63 616e 646c 655f  t('ohlcv_candle_
-00003cf0: 6c69 6d69 7427 2929 290a 0a20 2020 2064  limit')))..    d
-00003d00: 6566 2067 6574 5f6d 6172 6b65 7473 280a  ef get_markets(.
-00003d10: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00003d20: 2c0a 2020 2020 2020 2020 2020 2020 6261  ,.            ba
-00003d30: 7365 5f63 7572 7265 6e63 6965 733a 204f  se_currencies: O
-00003d40: 7074 696f 6e61 6c5b 4c69 7374 5b73 7472  ptional[List[str
-00003d50: 5d5d 203d 204e 6f6e 652c 0a20 2020 2020  ]] = None,.     
-00003d60: 2020 2020 2020 2071 756f 7465 5f63 7572         quote_cur
-00003d70: 7265 6e63 6965 733a 204f 7074 696f 6e61  rencies: Optiona
-00003d80: 6c5b 4c69 7374 5b73 7472 5d5d 203d 204e  l[List[str]] = N
-00003d90: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
-00003da0: 2073 706f 745f 6f6e 6c79 3a20 626f 6f6c   spot_only: bool
-00003db0: 203d 2046 616c 7365 2c20 6d61 7267 696e   = False, margin
-00003dc0: 5f6f 6e6c 793a 2062 6f6f 6c20 3d20 4661  _only: bool = Fa
-00003dd0: 6c73 652c 2066 7574 7572 6573 5f6f 6e6c  lse, futures_onl
-00003de0: 793a 2062 6f6f 6c20 3d20 4661 6c73 652c  y: bool = False,
-00003df0: 0a20 2020 2020 2020 2020 2020 2074 7261  .            tra
-00003e00: 6461 626c 655f 6f6e 6c79 3a20 626f 6f6c  dable_only: bool
-00003e10: 203d 2054 7275 652c 0a20 2020 2020 2020   = True,.       
-00003e20: 2020 2020 2061 6374 6976 655f 6f6e 6c79       active_only
-00003e30: 3a20 626f 6f6c 203d 2046 616c 7365 2920  : bool = False) 
-00003e40: 2d3e 2044 6963 745b 7374 722c 2041 6e79  -> Dict[str, Any
-00003e50: 5d3a 0a20 2020 2020 2020 2022 2222 0a20  ]:.        """. 
-00003e60: 2020 2020 2020 2052 6574 7572 6e20 6578         Return ex
-00003e70: 6368 616e 6765 2063 6378 7420 6d61 726b  change ccxt mark
-00003e80: 6574 732c 2066 696c 7465 7265 6420 6f75  ets, filtered ou
-00003e90: 7420 6279 2062 6173 6520 6375 7272 656e  t by base curren
-00003ea0: 6379 2061 6e64 2071 756f 7465 2063 7572  cy and quote cur
-00003eb0: 7265 6e63 790a 2020 2020 2020 2020 6966  rency.        if
-00003ec0: 2074 6869 7320 7761 7320 7265 7175 6573   this was reques
-00003ed0: 7465 6420 696e 2070 6172 616d 6574 6572  ted in parameter
-00003ee0: 732e 0a20 2020 2020 2020 2022 2222 0a20  s..        """. 
-00003ef0: 2020 2020 2020 206d 6172 6b65 7473 203d         markets =
-00003f00: 2073 656c 662e 6d61 726b 6574 730a 2020   self.markets.  
-00003f10: 2020 2020 2020 6966 206e 6f74 206d 6172        if not mar
-00003f20: 6b65 7473 3a0a 2020 2020 2020 2020 2020  kets:.          
-00003f30: 2020 7261 6973 6520 4f70 6572 6174 696f    raise Operatio
-00003f40: 6e61 6c45 7863 6570 7469 6f6e 2822 4d61  nalException("Ma
-00003f50: 726b 6574 7320 7765 7265 206e 6f74 206c  rkets were not l
-00003f60: 6f61 6465 642e 2229 0a0a 2020 2020 2020  oaded.")..      
-00003f70: 2020 6966 2062 6173 655f 6375 7272 656e    if base_curren
-00003f80: 6369 6573 3a0a 2020 2020 2020 2020 2020  cies:.          
-00003f90: 2020 6d61 726b 6574 7320 3d20 7b6b 3a20    markets = {k: 
-00003fa0: 7620 666f 7220 6b2c 2076 2069 6e20 6d61  v for k, v in ma
-00003fb0: 726b 6574 732e 6974 656d 7328 2920 6966  rkets.items() if
-00003fc0: 2076 5b27 6261 7365 275d 2069 6e20 6261   v['base'] in ba
-00003fd0: 7365 5f63 7572 7265 6e63 6965 737d 0a20  se_currencies}. 
-00003fe0: 2020 2020 2020 2069 6620 7175 6f74 655f         if quote_
-00003ff0: 6375 7272 656e 6369 6573 3a0a 2020 2020  currencies:.    
-00004000: 2020 2020 2020 2020 6d61 726b 6574 7320          markets 
-00004010: 3d20 7b6b 3a20 7620 666f 7220 6b2c 2076  = {k: v for k, v
-00004020: 2069 6e20 6d61 726b 6574 732e 6974 656d   in markets.item
-00004030: 7328 2920 6966 2076 5b27 7175 6f74 6527  s() if v['quote'
-00004040: 5d20 696e 2071 756f 7465 5f63 7572 7265  ] in quote_curre
-00004050: 6e63 6965 737d 0a20 2020 2020 2020 2069  ncies}.        i
-00004060: 6620 7472 6164 6162 6c65 5f6f 6e6c 793a  f tradable_only:
-00004070: 0a20 2020 2020 2020 2020 2020 206d 6172  .            mar
-00004080: 6b65 7473 203d 207b 6b3a 2076 2066 6f72  kets = {k: v for
-00004090: 206b 2c20 7620 696e 206d 6172 6b65 7473   k, v in markets
-000040a0: 2e69 7465 6d73 2829 2069 6620 7365 6c66  .items() if self
-000040b0: 2e6d 6172 6b65 745f 6973 5f74 7261 6461  .market_is_trada
-000040c0: 626c 6528 7629 7d0a 2020 2020 2020 2020  ble(v)}.        
-000040d0: 6966 2073 706f 745f 6f6e 6c79 3a0a 2020  if spot_only:.  
-000040e0: 2020 2020 2020 2020 2020 6d61 726b 6574            market
-000040f0: 7320 3d20 7b6b 3a20 7620 666f 7220 6b2c  s = {k: v for k,
-00004100: 2076 2069 6e20 6d61 726b 6574 732e 6974   v in markets.it
-00004110: 656d 7328 2920 6966 2073 656c 662e 6d61  ems() if self.ma
-00004120: 726b 6574 5f69 735f 7370 6f74 2876 297d  rket_is_spot(v)}
-00004130: 0a20 2020 2020 2020 2069 6620 6d61 7267  .        if marg
-00004140: 696e 5f6f 6e6c 793a 0a20 2020 2020 2020  in_only:.       
-00004150: 2020 2020 206d 6172 6b65 7473 203d 207b       markets = {
-00004160: 6b3a 2076 2066 6f72 206b 2c20 7620 696e  k: v for k, v in
-00004170: 206d 6172 6b65 7473 2e69 7465 6d73 2829   markets.items()
-00004180: 2069 6620 7365 6c66 2e6d 6172 6b65 745f   if self.market_
-00004190: 6973 5f6d 6172 6769 6e28 7629 7d0a 2020  is_margin(v)}.  
-000041a0: 2020 2020 2020 6966 2066 7574 7572 6573        if futures
-000041b0: 5f6f 6e6c 793a 0a20 2020 2020 2020 2020  _only:.         
-000041c0: 2020 206d 6172 6b65 7473 203d 207b 6b3a     markets = {k:
-000041d0: 2076 2066 6f72 206b 2c20 7620 696e 206d   v for k, v in m
-000041e0: 6172 6b65 7473 2e69 7465 6d73 2829 2069  arkets.items() i
-000041f0: 6620 7365 6c66 2e6d 6172 6b65 745f 6973  f self.market_is
-00004200: 5f66 7574 7572 6528 7629 7d0a 2020 2020  _future(v)}.    
-00004210: 2020 2020 6966 2061 6374 6976 655f 6f6e      if active_on
-00004220: 6c79 3a0a 2020 2020 2020 2020 2020 2020  ly:.            
-00004230: 6d61 726b 6574 7320 3d20 7b6b 3a20 7620  markets = {k: v 
-00004240: 666f 7220 6b2c 2076 2069 6e20 6d61 726b  for k, v in mark
-00004250: 6574 732e 6974 656d 7328 2920 6966 206d  ets.items() if m
-00004260: 6172 6b65 745f 6973 5f61 6374 6976 6528  arket_is_active(
-00004270: 7629 7d0a 2020 2020 2020 2020 7265 7475  v)}.        retu
-00004280: 726e 206d 6172 6b65 7473 0a0a 2020 2020  rn markets..    
-00004290: 6465 6620 6765 745f 7175 6f74 655f 6375  def get_quote_cu
-000042a0: 7272 656e 6369 6573 2873 656c 6629 202d  rrencies(self) -
-000042b0: 3e20 4c69 7374 5b73 7472 5d3a 0a20 2020  > List[str]:.   
-000042c0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-000042d0: 2052 6574 7572 6e20 6120 6c69 7374 206f   Return a list o
-000042e0: 6620 7375 7070 6f72 7465 6420 7175 6f74  f supported quot
-000042f0: 6520 6375 7272 656e 6369 6573 0a20 2020  e currencies.   
-00004300: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00004310: 206d 6172 6b65 7473 203d 2073 656c 662e   markets = self.
-00004320: 6d61 726b 6574 730a 2020 2020 2020 2020  markets.        
-00004330: 7265 7475 726e 2073 6f72 7465 6428 7365  return sorted(se
-00004340: 7428 5b78 5b27 7175 6f74 6527 5d20 666f  t([x['quote'] fo
-00004350: 7220 5f2c 2078 2069 6e20 6d61 726b 6574  r _, x in market
-00004360: 732e 6974 656d 7328 295d 2929 0a0a 2020  s.items()]))..  
-00004370: 2020 6465 6620 6765 745f 7061 6972 5f71    def get_pair_q
-00004380: 756f 7465 5f63 7572 7265 6e63 7928 7365  uote_currency(se
-00004390: 6c66 2c20 7061 6972 3a20 7374 7229 202d  lf, pair: str) -
-000043a0: 3e20 7374 723a 0a20 2020 2020 2020 2022  > str:.        "
-000043b0: 2222 2052 6574 7572 6e20 6120 7061 6972  "" Return a pair
-000043c0: 2773 2071 756f 7465 2063 7572 7265 6e63  's quote currenc
-000043d0: 7920 2862 6173 652f 7175 6f74 653a 7365  y (base/quote:se
-000043e0: 7474 6c65 6d65 6e74 2920 2222 220a 2020  ttlement) """.  
-000043f0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-00004400: 662e 6d61 726b 6574 732e 6765 7428 7061  f.markets.get(pa
-00004410: 6972 2c20 7b7d 292e 6765 7428 2771 756f  ir, {}).get('quo
-00004420: 7465 272c 2027 2729 0a0a 2020 2020 6465  te', '')..    de
-00004430: 6620 6765 745f 7061 6972 5f62 6173 655f  f get_pair_base_
-00004440: 6375 7272 656e 6379 2873 656c 662c 2070  currency(self, p
-00004450: 6169 723a 2073 7472 2920 2d3e 2073 7472  air: str) -> str
-00004460: 3a0a 2020 2020 2020 2020 2222 2220 5265  :.        """ Re
-00004470: 7475 726e 2061 2070 6169 7227 7320 6261  turn a pair's ba
-00004480: 7365 2063 7572 7265 6e63 7920 2862 6173  se currency (bas
-00004490: 652f 7175 6f74 653a 7365 7474 6c65 6d65  e/quote:settleme
-000044a0: 6e74 2920 2222 220a 2020 2020 2020 2020  nt) """.        
-000044b0: 7265 7475 726e 2073 656c 662e 6d61 726b  return self.mark
-000044c0: 6574 732e 6765 7428 7061 6972 2c20 7b7d  ets.get(pair, {}
-000044d0: 292e 6765 7428 2762 6173 6527 2c20 2727  ).get('base', ''
-000044e0: 290a 0a20 2020 2064 6566 206d 6172 6b65  )..    def marke
-000044f0: 745f 6973 5f66 7574 7572 6528 7365 6c66  t_is_future(self
-00004500: 2c20 6d61 726b 6574 3a20 4469 6374 5b73  , market: Dict[s
-00004510: 7472 2c20 416e 795d 2920 2d3e 2062 6f6f  tr, Any]) -> boo
-00004520: 6c3a 0a20 2020 2020 2020 2072 6574 7572  l:.        retur
-00004530: 6e20 280a 2020 2020 2020 2020 2020 2020  n (.            
-00004540: 6d61 726b 6574 2e67 6574 2873 656c 662e  market.get(self.
-00004550: 5f66 745f 6861 735b 2263 6378 745f 6675  _ft_has["ccxt_fu
-00004560: 7475 7265 735f 6e61 6d65 225d 2c20 4661  tures_name"], Fa
-00004570: 6c73 6529 2069 7320 5472 7565 2061 6e64  lse) is True and
-00004580: 0a20 2020 2020 2020 2020 2020 206d 6172  .            mar
-00004590: 6b65 742e 6765 7428 276c 696e 6561 7227  ket.get('linear'
-000045a0: 2c20 4661 6c73 6529 2069 7320 5472 7565  , False) is True
-000045b0: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
-000045c0: 6465 6620 6d61 726b 6574 5f69 735f 7370  def market_is_sp
-000045d0: 6f74 2873 656c 662c 206d 6172 6b65 743a  ot(self, market:
-000045e0: 2044 6963 745b 7374 722c 2041 6e79 5d29   Dict[str, Any])
-000045f0: 202d 3e20 626f 6f6c 3a0a 2020 2020 2020   -> bool:.      
-00004600: 2020 7265 7475 726e 206d 6172 6b65 742e    return market.
-00004610: 6765 7428 2773 706f 7427 2c20 4661 6c73  get('spot', Fals
-00004620: 6529 2069 7320 5472 7565 0a0a 2020 2020  e) is True..    
-00004630: 6465 6620 6d61 726b 6574 5f69 735f 6d61  def market_is_ma
-00004640: 7267 696e 2873 656c 662c 206d 6172 6b65  rgin(self, marke
-00004650: 743a 2044 6963 745b 7374 722c 2041 6e79  t: Dict[str, Any
-00004660: 5d29 202d 3e20 626f 6f6c 3a0a 2020 2020  ]) -> bool:.    
-00004670: 2020 2020 7265 7475 726e 206d 6172 6b65      return marke
-00004680: 742e 6765 7428 276d 6172 6769 6e27 2c20  t.get('margin', 
-00004690: 4661 6c73 6529 2069 7320 5472 7565 0a0a  False) is True..
-000046a0: 2020 2020 6465 6620 6d61 726b 6574 5f69      def market_i
-000046b0: 735f 7472 6164 6162 6c65 2873 656c 662c  s_tradable(self,
-000046c0: 206d 6172 6b65 743a 2044 6963 745b 7374   market: Dict[st
-000046d0: 722c 2041 6e79 5d29 202d 3e20 626f 6f6c  r, Any]) -> bool
-000046e0: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-000046f0: 2020 2020 2020 4368 6563 6b20 6966 2074        Check if t
-00004700: 6865 206d 6172 6b65 7420 7379 6d62 6f6c  he market symbol
-00004710: 2069 7320 7472 6164 6162 6c65 2062 7920   is tradable by 
-00004720: 4672 6571 7472 6164 652e 0a20 2020 2020  Freqtrade..     
-00004730: 2020 2045 6e73 7572 6573 2074 6861 7420     Ensures that 
-00004740: 436f 6e66 6967 7572 6564 206d 6f64 6520  Configured mode 
-00004750: 616c 6967 6e73 2074 6f0a 2020 2020 2020  aligns to.      
-00004760: 2020 2222 220a 2020 2020 2020 2020 7265    """.        re
-00004770: 7475 726e 2028 0a20 2020 2020 2020 2020  turn (.         
-00004780: 2020 206d 6172 6b65 742e 6765 7428 2771     market.get('q
-00004790: 756f 7465 272c 204e 6f6e 6529 2069 7320  uote', None) is 
-000047a0: 6e6f 7420 4e6f 6e65 0a20 2020 2020 2020  not None.       
-000047b0: 2020 2020 2061 6e64 206d 6172 6b65 742e       and market.
-000047c0: 6765 7428 2762 6173 6527 2c20 4e6f 6e65  get('base', None
-000047d0: 2920 6973 206e 6f74 204e 6f6e 650a 2020  ) is not None.  
-000047e0: 2020 2020 2020 2020 2020 616e 6420 2873            and (s
-000047f0: 656c 662e 7072 6563 6973 696f 6e4d 6f64  elf.precisionMod
-00004800: 6520 213d 2054 4943 4b5f 5349 5a45 0a20  e != TICK_SIZE. 
-00004810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004820: 2320 546f 6f20 6c6f 7720 7072 6563 6973  # Too low precis
-00004830: 696f 6e20 7769 6c6c 2066 616c 7369 6679  ion will falsify
-00004840: 2063 616c 6375 6c61 7469 6f6e 730a 2020   calculations.  
-00004850: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00004860: 7220 6d61 726b 6574 2e67 6574 2827 7072  r market.get('pr
-00004870: 6563 6973 696f 6e27 2c20 7b7d 292e 6765  ecision', {}).ge
-00004880: 7428 2770 7269 6365 2729 203e 2031 652d  t('price') > 1e-
-00004890: 3131 290a 2020 2020 2020 2020 2020 2020  11).            
-000048a0: 616e 6420 2828 7365 6c66 2e74 7261 6469  and ((self.tradi
-000048b0: 6e67 5f6d 6f64 6520 3d3d 2054 7261 6469  ng_mode == Tradi
-000048c0: 6e67 4d6f 6465 2e53 504f 5420 616e 6420  ngMode.SPOT and 
-000048d0: 7365 6c66 2e6d 6172 6b65 745f 6973 5f73  self.market_is_s
-000048e0: 706f 7428 6d61 726b 6574 2929 0a20 2020  pot(market)).   
-000048f0: 2020 2020 2020 2020 2020 2020 2020 6f72                or
-00004900: 2028 7365 6c66 2e74 7261 6469 6e67 5f6d   (self.trading_m
-00004910: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
-00004920: 6465 2e4d 4152 4749 4e20 616e 6420 7365  de.MARGIN and se
-00004930: 6c66 2e6d 6172 6b65 745f 6973 5f6d 6172  lf.market_is_mar
-00004940: 6769 6e28 6d61 726b 6574 2929 0a20 2020  gin(market)).   
-00004950: 2020 2020 2020 2020 2020 2020 2020 6f72                or
-00004960: 2028 7365 6c66 2e74 7261 6469 6e67 5f6d   (self.trading_m
-00004970: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
-00004980: 6465 2e46 5554 5552 4553 2061 6e64 2073  de.FUTURES and s
-00004990: 656c 662e 6d61 726b 6574 5f69 735f 6675  elf.market_is_fu
-000049a0: 7475 7265 286d 6172 6b65 7429 2929 0a20  ture(market))). 
-000049b0: 2020 2020 2020 2029 0a0a 2020 2020 6465         )..    de
-000049c0: 6620 6b6c 696e 6573 2873 656c 662c 2070  f klines(self, p
-000049d0: 6169 725f 696e 7465 7276 616c 3a20 5061  air_interval: Pa
-000049e0: 6972 5769 7468 5469 6d65 6672 616d 652c  irWithTimeframe,
-000049f0: 2063 6f70 793a 2062 6f6f 6c20 3d20 5472   copy: bool = Tr
-00004a00: 7565 2920 2d3e 2044 6174 6146 7261 6d65  ue) -> DataFrame
-00004a10: 3a0a 2020 2020 2020 2020 6966 2070 6169  :.        if pai
-00004a20: 725f 696e 7465 7276 616c 2069 6e20 7365  r_interval in se
-00004a30: 6c66 2e5f 6b6c 696e 6573 3a0a 2020 2020  lf._klines:.    
-00004a40: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00004a50: 656c 662e 5f6b 6c69 6e65 735b 7061 6972  elf._klines[pair
-00004a60: 5f69 6e74 6572 7661 6c5d 2e63 6f70 7928  _interval].copy(
-00004a70: 2920 6966 2063 6f70 7920 656c 7365 2073  ) if copy else s
-00004a80: 656c 662e 5f6b 6c69 6e65 735b 7061 6972  elf._klines[pair
-00004a90: 5f69 6e74 6572 7661 6c5d 0a20 2020 2020  _interval].     
-00004aa0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00004ab0: 2020 2020 2072 6574 7572 6e20 4461 7461       return Data
-00004ac0: 4672 616d 6528 290a 0a20 2020 2064 6566  Frame()..    def
-00004ad0: 2067 6574 5f63 6f6e 7472 6163 745f 7369   get_contract_si
-00004ae0: 7a65 2873 656c 662c 2070 6169 723a 2073  ze(self, pair: s
-00004af0: 7472 2920 2d3e 204f 7074 696f 6e61 6c5b  tr) -> Optional[
-00004b00: 666c 6f61 745d 3a0a 2020 2020 2020 2020  float]:.        
-00004b10: 6966 2073 656c 662e 7472 6164 696e 675f  if self.trading_
-00004b20: 6d6f 6465 203d 3d20 5472 6164 696e 674d  mode == TradingM
-00004b30: 6f64 652e 4655 5455 5245 533a 0a20 2020  ode.FUTURES:.   
-00004b40: 2020 2020 2020 2020 206d 6172 6b65 7420           market 
-00004b50: 3d20 7365 6c66 2e6d 6172 6b65 7473 2e67  = self.markets.g
-00004b60: 6574 2870 6169 722c 207b 7d29 0a20 2020  et(pair, {}).   
-00004b70: 2020 2020 2020 2020 2063 6f6e 7472 6163           contrac
-00004b80: 745f 7369 7a65 3a20 666c 6f61 7420 3d20  t_size: float = 
-00004b90: 312e 300a 2020 2020 2020 2020 2020 2020  1.0.            
-00004ba0: 6966 206e 6f74 206d 6172 6b65 743a 0a20  if not market:. 
-00004bb0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00004bc0: 6574 7572 6e20 4e6f 6e65 0a20 2020 2020  eturn None.     
-00004bd0: 2020 2020 2020 2069 6620 6d61 726b 6574         if market
-00004be0: 2e67 6574 2827 636f 6e74 7261 6374 5369  .get('contractSi
-00004bf0: 7a65 2729 2069 7320 6e6f 7420 4e6f 6e65  ze') is not None
-00004c00: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00004c10: 2020 2320 6363 7874 2068 6173 2063 6f6e    # ccxt has con
-00004c20: 7472 6163 7453 697a 6520 696e 206d 6172  tractSize in mar
-00004c30: 6b65 7473 2061 7320 7374 7269 6e67 0a20  kets as string. 
-00004c40: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00004c50: 6f6e 7472 6163 745f 7369 7a65 203d 2066  ontract_size = f
-00004c60: 6c6f 6174 286d 6172 6b65 745b 2763 6f6e  loat(market['con
-00004c70: 7472 6163 7453 697a 6527 5d29 0a20 2020  tractSize']).   
-00004c80: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00004c90: 636f 6e74 7261 6374 5f73 697a 650a 2020  contract_size.  
-00004ca0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00004cb0: 2020 2020 2020 2020 7265 7475 726e 2031          return 1
-00004cc0: 0a0a 2020 2020 6465 6620 5f74 7261 6465  ..    def _trade
-00004cd0: 735f 636f 6e74 7261 6374 735f 746f 5f61  s_contracts_to_a
-00004ce0: 6d6f 756e 7428 7365 6c66 2c20 7472 6164  mount(self, trad
-00004cf0: 6573 3a20 4c69 7374 2920 2d3e 204c 6973  es: List) -> Lis
-00004d00: 743a 0a20 2020 2020 2020 2069 6620 6c65  t:.        if le
-00004d10: 6e28 7472 6164 6573 2920 3e20 3020 616e  n(trades) > 0 an
-00004d20: 6420 2773 796d 626f 6c27 2069 6e20 7472  d 'symbol' in tr
-00004d30: 6164 6573 5b30 5d3a 0a20 2020 2020 2020  ades[0]:.       
-00004d40: 2020 2020 2063 6f6e 7472 6163 745f 7369       contract_si
-00004d50: 7a65 203d 2073 656c 662e 6765 745f 636f  ze = self.get_co
-00004d60: 6e74 7261 6374 5f73 697a 6528 7472 6164  ntract_size(trad
-00004d70: 6573 5b30 5d5b 2773 796d 626f 6c27 5d29  es[0]['symbol'])
-00004d80: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00004d90: 636f 6e74 7261 6374 5f73 697a 6520 213d  contract_size !=
-00004da0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-00004db0: 2020 2020 666f 7220 7472 6164 6520 696e      for trade in
-00004dc0: 2074 7261 6465 733a 0a20 2020 2020 2020   trades:.       
-00004dd0: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00004de0: 6465 5b27 616d 6f75 6e74 275d 203d 2074  de['amount'] = t
-00004df0: 7261 6465 5b27 616d 6f75 6e74 275d 202a  rade['amount'] *
-00004e00: 2063 6f6e 7472 6163 745f 7369 7a65 0a20   contract_size. 
-00004e10: 2020 2020 2020 2072 6574 7572 6e20 7472         return tr
-00004e20: 6164 6573 0a0a 2020 2020 6465 6620 5f6f  ades..    def _o
-00004e30: 7264 6572 5f63 6f6e 7472 6163 7473 5f74  rder_contracts_t
-00004e40: 6f5f 616d 6f75 6e74 2873 656c 662c 206f  o_amount(self, o
-00004e50: 7264 6572 3a20 4469 6374 2920 2d3e 2044  rder: Dict) -> D
-00004e60: 6963 743a 0a20 2020 2020 2020 2069 6620  ict:.        if 
-00004e70: 2773 796d 626f 6c27 2069 6e20 6f72 6465  'symbol' in orde
-00004e80: 7220 616e 6420 6f72 6465 725b 2773 796d  r and order['sym
-00004e90: 626f 6c27 5d20 6973 206e 6f74 204e 6f6e  bol'] is not Non
-00004ea0: 653a 0a20 2020 2020 2020 2020 2020 2063  e:.            c
-00004eb0: 6f6e 7472 6163 745f 7369 7a65 203d 2073  ontract_size = s
-00004ec0: 656c 662e 6765 745f 636f 6e74 7261 6374  elf.get_contract
-00004ed0: 5f73 697a 6528 6f72 6465 725b 2773 796d  _size(order['sym
-00004ee0: 626f 6c27 5d29 0a20 2020 2020 2020 2020  bol']).         
-00004ef0: 2020 2069 6620 636f 6e74 7261 6374 5f73     if contract_s
-00004f00: 697a 6520 213d 2031 3a0a 2020 2020 2020  ize != 1:.      
-00004f10: 2020 2020 2020 2020 2020 666f 7220 7072            for pr
-00004f20: 6f70 2069 6e20 7365 6c66 2e5f 6674 5f68  op in self._ft_h
-00004f30: 6173 2e67 6574 2827 6f72 6465 725f 7072  as.get('order_pr
-00004f40: 6f70 735f 696e 5f63 6f6e 7472 6163 7473  ops_in_contracts
-00004f50: 272c 205b 5d29 3a0a 2020 2020 2020 2020  ', []):.        
-00004f60: 2020 2020 2020 2020 2020 2020 6966 2070              if p
-00004f70: 726f 7020 696e 206f 7264 6572 2061 6e64  rop in order and
-00004f80: 206f 7264 6572 5b70 726f 705d 2069 7320   order[prop] is 
-00004f90: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00004fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004fb0: 2020 6f72 6465 725b 7072 6f70 5d20 3d20    order[prop] = 
-00004fc0: 6f72 6465 725b 7072 6f70 5d20 2a20 636f  order[prop] * co
-00004fd0: 6e74 7261 6374 5f73 697a 650a 2020 2020  ntract_size.    
-00004fe0: 2020 2020 7265 7475 726e 206f 7264 6572      return order
-00004ff0: 0a0a 2020 2020 6465 6620 5f61 6d6f 756e  ..    def _amoun
-00005000: 745f 746f 5f63 6f6e 7472 6163 7473 2873  t_to_contracts(s
-00005010: 656c 662c 2070 6169 723a 2073 7472 2c20  elf, pair: str, 
-00005020: 616d 6f75 6e74 3a20 666c 6f61 7429 202d  amount: float) -
-00005030: 3e20 666c 6f61 743a 0a0a 2020 2020 2020  > float:..      
-00005040: 2020 636f 6e74 7261 6374 5f73 697a 6520    contract_size 
-00005050: 3d20 7365 6c66 2e67 6574 5f63 6f6e 7472  = self.get_contr
-00005060: 6163 745f 7369 7a65 2870 6169 7229 0a20  act_size(pair). 
-00005070: 2020 2020 2020 2072 6574 7572 6e20 616d         return am
-00005080: 6f75 6e74 5f74 6f5f 636f 6e74 7261 6374  ount_to_contract
-00005090: 7328 616d 6f75 6e74 2c20 636f 6e74 7261  s(amount, contra
-000050a0: 6374 5f73 697a 6529 0a0a 2020 2020 6465  ct_size)..    de
-000050b0: 6620 5f63 6f6e 7472 6163 7473 5f74 6f5f  f _contracts_to_
-000050c0: 616d 6f75 6e74 2873 656c 662c 2070 6169  amount(self, pai
-000050d0: 723a 2073 7472 2c20 6e75 6d5f 636f 6e74  r: str, num_cont
-000050e0: 7261 6374 733a 2066 6c6f 6174 2920 2d3e  racts: float) ->
-000050f0: 2066 6c6f 6174 3a0a 0a20 2020 2020 2020   float:..       
-00005100: 2063 6f6e 7472 6163 745f 7369 7a65 203d   contract_size =
-00005110: 2073 656c 662e 6765 745f 636f 6e74 7261   self.get_contra
-00005120: 6374 5f73 697a 6528 7061 6972 290a 2020  ct_size(pair).  
-00005130: 2020 2020 2020 7265 7475 726e 2063 6f6e        return con
-00005140: 7472 6163 7473 5f74 6f5f 616d 6f75 6e74  tracts_to_amount
-00005150: 286e 756d 5f63 6f6e 7472 6163 7473 2c20  (num_contracts, 
-00005160: 636f 6e74 7261 6374 5f73 697a 6529 0a0a  contract_size)..
-00005170: 2020 2020 6465 6620 616d 6f75 6e74 5f74      def amount_t
-00005180: 6f5f 636f 6e74 7261 6374 5f70 7265 6369  o_contract_preci
-00005190: 7369 6f6e 2873 656c 662c 2070 6169 723a  sion(self, pair:
-000051a0: 2073 7472 2c20 616d 6f75 6e74 3a20 666c   str, amount: fl
-000051b0: 6f61 7429 202d 3e20 666c 6f61 743a 0a20  oat) -> float:. 
-000051c0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-000051d0: 2020 2048 656c 7065 7220 7772 6170 7065     Helper wrappe
-000051e0: 7220 6172 6f75 6e64 2061 6d6f 756e 745f  r around amount_
-000051f0: 746f 5f63 6f6e 7472 6163 745f 7072 6563  to_contract_prec
-00005200: 6973 696f 6e0a 2020 2020 2020 2020 2222  ision.        ""
-00005210: 220a 2020 2020 2020 2020 636f 6e74 7261  ".        contra
-00005220: 6374 5f73 697a 6520 3d20 7365 6c66 2e67  ct_size = self.g
-00005230: 6574 5f63 6f6e 7472 6163 745f 7369 7a65  et_contract_size
-00005240: 2870 6169 7229 0a0a 2020 2020 2020 2020  (pair)..        
-00005250: 7265 7475 726e 2061 6d6f 756e 745f 746f  return amount_to
-00005260: 5f63 6f6e 7472 6163 745f 7072 6563 6973  _contract_precis
-00005270: 696f 6e28 616d 6f75 6e74 2c20 7365 6c66  ion(amount, self
-00005280: 2e67 6574 5f70 7265 6369 7369 6f6e 5f61  .get_precision_a
-00005290: 6d6f 756e 7428 7061 6972 292c 0a20 2020  mount(pair),.   
-000052a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000052b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000052c0: 2020 2020 2020 2020 2073 656c 662e 7072           self.pr
-000052d0: 6563 6973 696f 6e4d 6f64 652c 2063 6f6e  ecisionMode, con
-000052e0: 7472 6163 745f 7369 7a65 290a 0a20 2020  tract_size)..   
-000052f0: 2064 6566 205f 6c6f 6164 5f61 7379 6e63   def _load_async
-00005300: 5f6d 6172 6b65 7473 2873 656c 662c 2072  _markets(self, r
-00005310: 656c 6f61 643a 2062 6f6f 6c20 3d20 4661  eload: bool = Fa
-00005320: 6c73 6529 202d 3e20 4e6f 6e65 3a0a 2020  lse) -> None:.  
-00005330: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
-00005340: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
-00005350: 6170 695f 6173 796e 633a 0a20 2020 2020  api_async:.     
-00005360: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00005370: 6c6f 6f70 2e72 756e 5f75 6e74 696c 5f63  loop.run_until_c
-00005380: 6f6d 706c 6574 6528 0a20 2020 2020 2020  omplete(.       
-00005390: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-000053a0: 662e 5f61 7069 5f61 7379 6e63 2e6c 6f61  f._api_async.loa
-000053b0: 645f 6d61 726b 6574 7328 7265 6c6f 6164  d_markets(reload
-000053c0: 3d72 656c 6f61 642c 2070 6172 616d 733d  =reload, params=
-000053d0: 7b7d 2929 0a0a 2020 2020 2020 2020 6578  {}))..        ex
-000053e0: 6365 7074 2028 6173 796e 6369 6f2e 5469  cept (asyncio.Ti
-000053f0: 6d65 6f75 7445 7272 6f72 2c20 6363 7874  meoutError, ccxt
-00005400: 2e42 6173 6545 7272 6f72 2920 6173 2065  .BaseError) as e
+00000040: 6f72 740a 2222 220a 0a69 6d70 6f72 7420  ort."""..import 
+00000050: 6173 796e 6369 6f0a 696d 706f 7274 2069  asyncio.import i
+00000060: 6e73 7065 6374 0a69 6d70 6f72 7420 6c6f  nspect.import lo
+00000070: 6767 696e 670a 696d 706f 7274 2073 6967  gging.import sig
+00000080: 6e61 6c0a 6672 6f6d 2063 6f70 7920 696d  nal.from copy im
+00000090: 706f 7274 2064 6565 7063 6f70 790a 6672  port deepcopy.fr
+000000a0: 6f6d 2064 6174 6574 696d 6520 696d 706f  om datetime impo
+000000b0: 7274 2064 6174 6574 696d 652c 2074 696d  rt datetime, tim
+000000c0: 6564 656c 7461 2c20 7469 6d65 7a6f 6e65  edelta, timezone
+000000d0: 0a66 726f 6d20 6d61 7468 2069 6d70 6f72  .from math impor
+000000e0: 7420 666c 6f6f 722c 2069 736e 616e 0a66  t floor, isnan.f
+000000f0: 726f 6d20 7468 7265 6164 696e 6720 696d  rom threading im
+00000100: 706f 7274 204c 6f63 6b0a 6672 6f6d 2074  port Lock.from t
+00000110: 7970 696e 6720 696d 706f 7274 2041 6e79  yping import Any
+00000120: 2c20 436f 726f 7574 696e 652c 2044 6963  , Coroutine, Dic
+00000130: 742c 204c 6973 742c 204c 6974 6572 616c  t, List, Literal
+00000140: 2c20 4f70 7469 6f6e 616c 2c20 5475 706c  , Optional, Tupl
+00000150: 652c 2055 6e69 6f6e 0a0a 696d 706f 7274  e, Union..import
+00000160: 2063 6378 740a 696d 706f 7274 2063 6378   ccxt.import ccx
+00000170: 742e 6173 796e 635f 7375 7070 6f72 7420  t.async_support 
+00000180: 6173 2063 6378 745f 6173 796e 630a 6672  as ccxt_async.fr
+00000190: 6f6d 2063 6163 6865 746f 6f6c 7320 696d  om cachetools im
+000001a0: 706f 7274 2054 544c 4361 6368 650a 6672  port TTLCache.fr
+000001b0: 6f6d 2063 6378 7420 696d 706f 7274 2054  om ccxt import T
+000001c0: 4943 4b5f 5349 5a45 0a66 726f 6d20 6461  ICK_SIZE.from da
+000001d0: 7465 7574 696c 2069 6d70 6f72 7420 7061  teutil import pa
+000001e0: 7273 6572 0a66 726f 6d20 7061 6e64 6173  rser.from pandas
+000001f0: 2069 6d70 6f72 7420 4461 7461 4672 616d   import DataFram
+00000200: 652c 2063 6f6e 6361 740a 0a66 726f 6d20  e, concat..from 
+00000210: 6672 6571 7472 6164 652e 636f 6e73 7461  freqtrade.consta
+00000220: 6e74 7320 696d 706f 7274 2028 0a20 2020  nts import (.   
+00000230: 2044 4546 4155 4c54 5f41 4d4f 554e 545f   DEFAULT_AMOUNT_
+00000240: 5245 5345 5256 455f 5045 5243 454e 542c  RESERVE_PERCENT,
+00000250: 0a20 2020 204e 4f4e 5f4f 5045 4e5f 4558  .    NON_OPEN_EX
+00000260: 4348 414e 4745 5f53 5441 5445 532c 0a20  CHANGE_STATES,. 
+00000270: 2020 2042 6964 4173 6b2c 0a20 2020 2042     BidAsk,.    B
+00000280: 7579 5365 6c6c 2c0a 2020 2020 436f 6e66  uySell,.    Conf
+00000290: 6967 2c0a 2020 2020 456e 7472 7945 7869  ig,.    EntryExi
+000002a0: 742c 0a20 2020 2045 7863 6861 6e67 6543  t,.    ExchangeC
+000002b0: 6f6e 6669 672c 0a20 2020 204c 6973 7450  onfig,.    ListP
+000002c0: 6169 7273 5769 7468 5469 6d65 6672 616d  airsWithTimefram
+000002d0: 6573 2c0a 2020 2020 4d61 6b65 7254 616b  es,.    MakerTak
+000002e0: 6572 2c0a 2020 2020 4f42 4c69 7465 7261  er,.    OBLitera
+000002f0: 6c2c 0a20 2020 2050 6169 7257 6974 6854  l,.    PairWithT
+00000300: 696d 6566 7261 6d65 2c0a 290a 6672 6f6d  imeframe,.).from
+00000310: 2066 7265 7174 7261 6465 2e64 6174 612e   freqtrade.data.
+00000320: 636f 6e76 6572 7465 7220 696d 706f 7274  converter import
+00000330: 2063 6c65 616e 5f6f 686c 6376 5f64 6174   clean_ohlcv_dat
+00000340: 6166 7261 6d65 2c20 6f68 6c63 765f 746f  aframe, ohlcv_to
+00000350: 5f64 6174 6166 7261 6d65 2c20 7472 6164  _dataframe, trad
+00000360: 6573 5f64 6963 745f 746f 5f6c 6973 740a  es_dict_to_list.
+00000370: 6672 6f6d 2066 7265 7174 7261 6465 2e65  from freqtrade.e
+00000380: 6e75 6d73 2069 6d70 6f72 7420 4f50 5449  nums import OPTI
+00000390: 4d49 5a45 5f4d 4f44 4553 2c20 4361 6e64  MIZE_MODES, Cand
+000003a0: 6c65 5479 7065 2c20 4d61 7267 696e 4d6f  leType, MarginMo
+000003b0: 6465 2c20 5072 6963 6554 7970 652c 2052  de, PriceType, R
+000003c0: 756e 4d6f 6465 2c20 5472 6164 696e 674d  unMode, TradingM
+000003d0: 6f64 650a 6672 6f6d 2066 7265 7174 7261  ode.from freqtra
+000003e0: 6465 2e65 7863 6570 7469 6f6e 7320 696d  de.exceptions im
+000003f0: 706f 7274 2028 0a20 2020 2043 6f6e 6669  port (.    Confi
+00000400: 6775 7261 7469 6f6e 4572 726f 722c 0a20  gurationError,. 
+00000410: 2020 2044 446f 7350 726f 7465 6374 696f     DDosProtectio
+00000420: 6e2c 0a20 2020 2045 7863 6861 6e67 6545  n,.    ExchangeE
+00000430: 7272 6f72 2c0a 2020 2020 496e 7375 6666  rror,.    Insuff
+00000440: 6963 6965 6e74 4675 6e64 7345 7272 6f72  icientFundsError
+00000450: 2c0a 2020 2020 496e 7661 6c69 644f 7264  ,.    InvalidOrd
+00000460: 6572 4578 6365 7074 696f 6e2c 0a20 2020  erException,.   
+00000470: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
+00000480: 7074 696f 6e2c 0a20 2020 2050 7269 6369  ption,.    Prici
+00000490: 6e67 4572 726f 722c 0a20 2020 2052 6574  ngError,.    Ret
+000004a0: 7279 6162 6c65 4f72 6465 7245 7272 6f72  ryableOrderError
+000004b0: 2c0a 2020 2020 5465 6d70 6f72 6172 7945  ,.    TemporaryE
+000004c0: 7272 6f72 2c0a 290a 6672 6f6d 2066 7265  rror,.).from fre
+000004d0: 7174 7261 6465 2e65 7863 6861 6e67 652e  qtrade.exchange.
+000004e0: 636f 6d6d 6f6e 2069 6d70 6f72 7420 280a  common import (.
+000004f0: 2020 2020 4150 495f 4645 5443 485f 4f52      API_FETCH_OR
+00000500: 4445 525f 5245 5452 595f 434f 554e 542c  DER_RETRY_COUNT,
+00000510: 0a20 2020 2072 656d 6f76 655f 6578 6368  .    remove_exch
+00000520: 616e 6765 5f63 7265 6465 6e74 6961 6c73  ange_credentials
+00000530: 2c0a 2020 2020 7265 7472 6965 722c 0a20  ,.    retrier,. 
+00000540: 2020 2072 6574 7269 6572 5f61 7379 6e63     retrier_async
+00000550: 2c0a 290a 6672 6f6d 2066 7265 7174 7261  ,.).from freqtra
+00000560: 6465 2e65 7863 6861 6e67 652e 6578 6368  de.exchange.exch
+00000570: 616e 6765 5f75 7469 6c73 2069 6d70 6f72  ange_utils impor
+00000580: 7420 280a 2020 2020 524f 554e 442c 0a20  t (.    ROUND,. 
+00000590: 2020 2052 4f55 4e44 5f44 4f57 4e2c 0a20     ROUND_DOWN,. 
+000005a0: 2020 2052 4f55 4e44 5f55 502c 0a20 2020     ROUND_UP,.   
+000005b0: 2043 6378 744d 6f64 756c 6554 7970 652c   CcxtModuleType,
+000005c0: 0a20 2020 2061 6d6f 756e 745f 746f 5f63  .    amount_to_c
+000005d0: 6f6e 7472 6163 745f 7072 6563 6973 696f  ontract_precisio
+000005e0: 6e2c 0a20 2020 2061 6d6f 756e 745f 746f  n,.    amount_to
+000005f0: 5f63 6f6e 7472 6163 7473 2c0a 2020 2020  _contracts,.    
+00000600: 616d 6f75 6e74 5f74 6f5f 7072 6563 6973  amount_to_precis
+00000610: 696f 6e2c 0a20 2020 2063 6f6e 7472 6163  ion,.    contrac
+00000620: 7473 5f74 6f5f 616d 6f75 6e74 2c0a 2020  ts_to_amount,.  
+00000630: 2020 6461 7465 5f6d 696e 7573 5f63 616e    date_minus_can
+00000640: 646c 6573 2c0a 2020 2020 6973 5f65 7863  dles,.    is_exc
+00000650: 6861 6e67 655f 6b6e 6f77 6e5f 6363 7874  hange_known_ccxt
+00000660: 2c0a 2020 2020 6d61 726b 6574 5f69 735f  ,.    market_is_
+00000670: 6163 7469 7665 2c0a 2020 2020 7072 6963  active,.    pric
+00000680: 655f 746f 5f70 7265 6369 7369 6f6e 2c0a  e_to_precision,.
+00000690: 290a 6672 6f6d 2066 7265 7174 7261 6465  ).from freqtrade
+000006a0: 2e65 7863 6861 6e67 652e 6578 6368 616e  .exchange.exchan
+000006b0: 6765 5f75 7469 6c73 5f74 696d 6566 7261  ge_utils_timefra
+000006c0: 6d65 2069 6d70 6f72 7420 280a 2020 2020  me import (.    
+000006d0: 7469 6d65 6672 616d 655f 746f 5f6d 696e  timeframe_to_min
+000006e0: 7574 6573 2c0a 2020 2020 7469 6d65 6672  utes,.    timefr
+000006f0: 616d 655f 746f 5f6d 7365 6373 2c0a 2020  ame_to_msecs,.  
+00000700: 2020 7469 6d65 6672 616d 655f 746f 5f6e    timeframe_to_n
+00000710: 6578 745f 6461 7465 2c0a 2020 2020 7469  ext_date,.    ti
+00000720: 6d65 6672 616d 655f 746f 5f70 7265 765f  meframe_to_prev_
+00000730: 6461 7465 2c0a 2020 2020 7469 6d65 6672  date,.    timefr
+00000740: 616d 655f 746f 5f73 6563 6f6e 6473 2c0a  ame_to_seconds,.
+00000750: 290a 6672 6f6d 2066 7265 7174 7261 6465  ).from freqtrade
+00000760: 2e65 7863 6861 6e67 652e 7479 7065 7320  .exchange.types 
+00000770: 696d 706f 7274 204f 484c 4356 5265 7370  import OHLCVResp
+00000780: 6f6e 7365 2c20 4f72 6465 7242 6f6f 6b2c  onse, OrderBook,
+00000790: 2054 6963 6b65 722c 2054 6963 6b65 7273   Ticker, Tickers
+000007a0: 0a66 726f 6d20 6672 6571 7472 6164 652e  .from freqtrade.
+000007b0: 6d69 7363 2069 6d70 6f72 7420 280a 2020  misc import (.  
+000007c0: 2020 6368 756e 6b73 2c0a 2020 2020 6465    chunks,.    de
+000007d0: 6570 5f6d 6572 6765 5f64 6963 7473 2c0a  ep_merge_dicts,.
+000007e0: 2020 2020 6669 6c65 5f64 756d 705f 6a73      file_dump_js
+000007f0: 6f6e 2c0a 2020 2020 6669 6c65 5f6c 6f61  on,.    file_loa
+00000800: 645f 6a73 6f6e 2c0a 2020 2020 7361 6665  d_json,.    safe
+00000810: 5f76 616c 7565 5f66 616c 6c62 6163 6b32  _value_fallback2
+00000820: 2c0a 290a 6672 6f6d 2066 7265 7174 7261  ,.).from freqtra
+00000830: 6465 2e70 6c75 6769 6e73 2e70 6169 726c  de.plugins.pairl
+00000840: 6973 742e 7061 6972 6c69 7374 5f68 656c  ist.pairlist_hel
+00000850: 7065 7273 2069 6d70 6f72 7420 6578 7061  pers import expa
+00000860: 6e64 5f70 6169 726c 6973 740a 6672 6f6d  nd_pairlist.from
+00000870: 2066 7265 7174 7261 6465 2e75 7469 6c20   freqtrade.util 
+00000880: 696d 706f 7274 2064 745f 6672 6f6d 5f74  import dt_from_t
+00000890: 732c 2064 745f 6e6f 770a 6672 6f6d 2066  s, dt_now.from f
+000008a0: 7265 7174 7261 6465 2e75 7469 6c2e 6461  reqtrade.util.da
+000008b0: 7465 7469 6d65 5f68 656c 7065 7273 2069  tetime_helpers i
+000008c0: 6d70 6f72 7420 6474 5f68 756d 616e 697a  mport dt_humaniz
+000008d0: 655f 6465 6c74 612c 2064 745f 7473 0a66  e_delta, dt_ts.f
+000008e0: 726f 6d20 6672 6571 7472 6164 652e 7574  rom freqtrade.ut
+000008f0: 696c 2e70 6572 696f 6469 635f 6361 6368  il.periodic_cach
+00000900: 6520 696d 706f 7274 2050 6572 696f 6469  e import Periodi
+00000910: 6343 6163 6865 0a0a 0a6c 6f67 6765 7220  cCache...logger 
+00000920: 3d20 6c6f 6767 696e 672e 6765 744c 6f67  = logging.getLog
+00000930: 6765 7228 5f5f 6e61 6d65 5f5f 290a 0a0a  ger(__name__)...
+00000940: 636c 6173 7320 4578 6368 616e 6765 3a0a  class Exchange:.
+00000950: 2020 2020 2320 5061 7261 6d65 7465 7273      # Parameters
+00000960: 2074 6f20 6164 6420 6469 7265 6374 6c79   to add directly
+00000970: 2074 6f20 6275 792f 7365 6c6c 2063 616c   to buy/sell cal
+00000980: 6c73 2028 6c69 6b65 2061 6772 6565 696e  ls (like agreein
+00000990: 6720 746f 2074 7261 6469 6e67 2061 6772  g to trading agr
+000009a0: 6565 6d65 6e74 290a 2020 2020 5f70 6172  eement).    _par
+000009b0: 616d 733a 2044 6963 7420 3d20 7b7d 0a0a  ams: Dict = {}..
+000009c0: 2020 2020 2320 4164 6469 7469 6f6e 616c      # Additional
+000009d0: 2070 6172 616d 6574 6572 7320 2d20 6164   parameters - ad
+000009e0: 6465 6420 746f 2074 6865 2063 6378 7420  ded to the ccxt 
+000009f0: 6f62 6a65 6374 0a20 2020 205f 6363 7874  object.    _ccxt
+00000a00: 5f70 6172 616d 733a 2044 6963 7420 3d20  _params: Dict = 
+00000a10: 7b7d 0a0a 2020 2020 2320 4469 6374 2074  {}..    # Dict t
+00000a20: 6f20 7370 6563 6966 7920 7768 6963 6820  o specify which 
+00000a30: 6f70 7469 6f6e 7320 6561 6368 2065 7863  options each exc
+00000a40: 6861 6e67 6520 696d 706c 656d 656e 7473  hange implements
+00000a50: 0a20 2020 2023 2054 6869 7320 6465 6669  .    # This defi
+00000a60: 6e65 7320 6465 6661 756c 7473 2c20 7768  nes defaults, wh
+00000a70: 6963 6820 6361 6e20 6265 2073 656c 6563  ich can be selec
+00000a80: 7469 7665 6c79 206f 7665 7272 6964 6465  tively overridde
+00000a90: 6e20 6279 2073 7562 636c 6173 7365 7320  n by subclasses 
+00000aa0: 7573 696e 6720 5f66 745f 6861 730a 2020  using _ft_has.  
+00000ab0: 2020 2320 6f72 2062 7920 7370 6563 6966    # or by specif
+00000ac0: 7969 6e67 2074 6865 6d20 696e 2074 6865  ying them in the
+00000ad0: 2063 6f6e 6669 6775 7261 7469 6f6e 2e0a   configuration..
+00000ae0: 2020 2020 5f66 745f 6861 735f 6465 6661      _ft_has_defa
+00000af0: 756c 743a 2044 6963 7420 3d20 7b0a 2020  ult: Dict = {.  
+00000b00: 2020 2020 2020 2273 746f 706c 6f73 735f        "stoploss_
+00000b10: 6f6e 5f65 7863 6861 6e67 6522 3a20 4661  on_exchange": Fa
+00000b20: 6c73 652c 0a20 2020 2020 2020 2022 7374  lse,.        "st
+00000b30: 6f70 5f70 7269 6365 5f70 6172 616d 223a  op_price_param":
+00000b40: 2022 7374 6f70 4c6f 7373 5072 6963 6522   "stopLossPrice"
+00000b50: 2c20 2023 2055 7365 6420 666f 7220 7374  ,  # Used for st
+00000b60: 6f70 6c6f 7373 5f6f 6e5f 6578 6368 616e  oploss_on_exchan
+00000b70: 6765 2072 6571 7565 7374 0a20 2020 2020  ge request.     
+00000b80: 2020 2022 7374 6f70 5f70 7269 6365 5f70     "stop_price_p
+00000b90: 726f 7022 3a20 2273 746f 704c 6f73 7350  rop": "stopLossP
+00000ba0: 7269 6365 222c 2020 2320 5573 6564 2066  rice",  # Used f
+00000bb0: 6f72 2073 746f 706c 6f73 735f 6f6e 5f65  or stoploss_on_e
+00000bc0: 7863 6861 6e67 6520 7265 7370 6f6e 7365  xchange response
+00000bd0: 2070 6172 7369 6e67 0a20 2020 2020 2020   parsing.       
+00000be0: 2022 6f72 6465 725f 7469 6d65 5f69 6e5f   "order_time_in_
+00000bf0: 666f 7263 6522 3a20 5b22 4754 4322 5d2c  force": ["GTC"],
+00000c00: 0a20 2020 2020 2020 2022 6f68 6c63 765f  .        "ohlcv_
+00000c10: 7061 7261 6d73 223a 207b 7d2c 0a20 2020  params": {},.   
+00000c20: 2020 2020 2022 6f68 6c63 765f 6361 6e64       "ohlcv_cand
+00000c30: 6c65 5f6c 696d 6974 223a 2035 3030 2c0a  le_limit": 500,.
+00000c40: 2020 2020 2020 2020 226f 686c 6376 5f68          "ohlcv_h
+00000c50: 6173 5f68 6973 746f 7279 223a 2054 7275  as_history": Tru
+00000c60: 652c 2020 2320 536f 6d65 2065 7863 6861  e,  # Some excha
+00000c70: 6e67 6573 2028 4b72 616b 656e 2920 646f  nges (Kraken) do
+00000c80: 6e27 7420 7072 6f76 6964 6520 6869 7374  n't provide hist
+00000c90: 6f72 7920 7669 6120 6f68 6c63 760a 2020  ory via ohlcv.  
+00000ca0: 2020 2020 2020 226f 686c 6376 5f70 6172        "ohlcv_par
+00000cb0: 7469 616c 5f63 616e 646c 6522 3a20 5472  tial_candle": Tr
+00000cc0: 7565 2c0a 2020 2020 2020 2020 226f 686c  ue,.        "ohl
+00000cd0: 6376 5f72 6571 7569 7265 5f73 696e 6365  cv_require_since
+00000ce0: 223a 2046 616c 7365 2c0a 2020 2020 2020  ": False,.      
+00000cf0: 2020 2320 4368 6563 6b20 6874 7470 733a    # Check https:
+00000d00: 2f2f 6769 7468 7562 2e63 6f6d 2f63 6378  //github.com/ccx
+00000d10: 742f 6363 7874 2f69 7373 7565 732f 3130  t/ccxt/issues/10
+00000d20: 3736 3720 666f 7220 7265 6d6f 7661 6c20  767 for removal 
+00000d30: 6f66 206f 686c 6376 5f76 6f6c 756d 655f  of ohlcv_volume_
+00000d40: 6375 7272 656e 6379 0a20 2020 2020 2020  currency.       
+00000d50: 2022 6f68 6c63 765f 766f 6c75 6d65 5f63   "ohlcv_volume_c
+00000d60: 7572 7265 6e63 7922 3a20 2262 6173 6522  urrency": "base"
+00000d70: 2c20 2023 2022 6261 7365 2220 6f72 2022  ,  # "base" or "
+00000d80: 7175 6f74 6522 0a20 2020 2020 2020 2022  quote".        "
+00000d90: 7469 636b 6572 735f 6861 7665 5f71 756f  tickers_have_quo
+00000da0: 7465 566f 6c75 6d65 223a 2054 7275 652c  teVolume": True,
+00000db0: 0a20 2020 2020 2020 2022 7469 636b 6572  .        "ticker
+00000dc0: 735f 6861 7665 5f62 6964 5f61 736b 223a  s_have_bid_ask":
+00000dd0: 2054 7275 652c 2020 2320 6269 6420 2f20   True,  # bid / 
+00000de0: 6173 6b20 656d 7074 7920 666f 7220 6665  ask empty for fe
+00000df0: 7463 685f 7469 636b 6572 730a 2020 2020  tch_tickers.    
+00000e00: 2020 2020 2274 6963 6b65 7273 5f68 6176      "tickers_hav
+00000e10: 655f 7072 6963 6522 3a20 5472 7565 2c0a  e_price": True,.
+00000e20: 2020 2020 2020 2020 2274 7261 6465 735f          "trades_
+00000e30: 7061 6769 6e61 7469 6f6e 223a 2022 7469  pagination": "ti
+00000e40: 6d65 222c 2020 2320 506f 7373 6962 6c65  me",  # Possible
+00000e50: 2061 7265 2022 7469 6d65 2220 6f72 2022   are "time" or "
+00000e60: 6964 220a 2020 2020 2020 2020 2274 7261  id".        "tra
+00000e70: 6465 735f 7061 6769 6e61 7469 6f6e 5f61  des_pagination_a
+00000e80: 7267 223a 2022 7369 6e63 6522 2c0a 2020  rg": "since",.  
+00000e90: 2020 2020 2020 226c 325f 6c69 6d69 745f        "l2_limit_
+00000ea0: 7261 6e67 6522 3a20 4e6f 6e65 2c0a 2020  range": None,.  
+00000eb0: 2020 2020 2020 226c 325f 6c69 6d69 745f        "l2_limit_
+00000ec0: 7261 6e67 655f 7265 7175 6972 6564 223a  range_required":
+00000ed0: 2054 7275 652c 2020 2320 416c 6c6f 7720   True,  # Allow 
+00000ee0: 456d 7074 7920 4c32 206c 696d 6974 2028  Empty L2 limit (
+00000ef0: 6b75 636f 696e 290a 2020 2020 2020 2020  kucoin).        
+00000f00: 226d 6172 6b5f 6f68 6c63 765f 7072 6963  "mark_ohlcv_pric
+00000f10: 6522 3a20 226d 6172 6b22 2c0a 2020 2020  e": "mark",.    
+00000f20: 2020 2020 226d 6172 6b5f 6f68 6c63 765f      "mark_ohlcv_
+00000f30: 7469 6d65 6672 616d 6522 3a20 2238 6822  timeframe": "8h"
+00000f40: 2c0a 2020 2020 2020 2020 2266 756e 6469  ,.        "fundi
+00000f50: 6e67 5f66 6565 5f74 696d 6566 7261 6d65  ng_fee_timeframe
+00000f60: 223a 2022 3868 222c 0a20 2020 2020 2020  ": "8h",.       
+00000f70: 2022 6363 7874 5f66 7574 7572 6573 5f6e   "ccxt_futures_n
+00000f80: 616d 6522 3a20 2273 7761 7022 2c0a 2020  ame": "swap",.  
+00000f90: 2020 2020 2020 226e 6565 6473 5f74 7261        "needs_tra
+00000fa0: 6469 6e67 5f66 6565 7322 3a20 4661 6c73  ding_fees": Fals
+00000fb0: 652c 2020 2320 7573 6520 6665 7463 685f  e,  # use fetch_
+00000fc0: 7472 6164 696e 675f 6665 6573 2074 6f20  trading_fees to 
+00000fd0: 6361 6368 6520 6665 6573 0a20 2020 2020  cache fees.     
+00000fe0: 2020 2022 6f72 6465 725f 7072 6f70 735f     "order_props_
+00000ff0: 696e 5f63 6f6e 7472 6163 7473 223a 205b  in_contracts": [
+00001000: 2261 6d6f 756e 7422 2c20 2266 696c 6c65  "amount", "fille
+00001010: 6422 2c20 2272 656d 6169 6e69 6e67 225d  d", "remaining"]
+00001020: 2c0a 2020 2020 2020 2020 2320 4f76 6572  ,.        # Over
+00001030: 7269 6465 2063 7265 6174 654d 6172 6b65  ride createMarke
+00001040: 7442 7579 4f72 6465 7252 6571 7569 7265  tBuyOrderRequire
+00001050: 7350 7269 6365 2077 6865 7265 2063 6378  sPrice where ccx
+00001060: 7420 6861 7320 6974 2077 726f 6e67 0a20  t has it wrong. 
+00001070: 2020 2020 2020 2022 6d61 726b 6574 4f72         "marketOr
+00001080: 6465 7252 6571 7569 7265 7350 7269 6365  derRequiresPrice
+00001090: 223a 2046 616c 7365 2c0a 2020 2020 2020  ": False,.      
+000010a0: 2020 2265 7863 6861 6e67 655f 6861 735f    "exchange_has_
+000010b0: 6f76 6572 7269 6465 7322 3a20 7b7d 2c20  overrides": {}, 
+000010c0: 2023 2044 6963 7469 6f6e 6172 7920 6f76   # Dictionary ov
+000010d0: 6572 7269 6469 6e67 2063 6378 7427 7320  erriding ccxt's 
+000010e0: 2268 6173 222e 0a20 2020 2020 2020 2023  "has"..        #
+000010f0: 2045 7870 6563 7465 6420 746f 2062 6520   Expected to be 
+00001100: 696e 2074 6865 2066 6f72 6d61 7420 7b22  in the format {"
+00001110: 6665 7463 684f 484c 4356 223a 2054 7275  fetchOHLCV": Tru
+00001120: 657d 206f 7220 7b22 6665 7463 684f 484c  e} or {"fetchOHL
+00001130: 4356 223a 2046 616c 7365 7d0a 2020 2020  CV": False}.    
+00001140: 7d0a 2020 2020 5f66 745f 6861 733a 2044  }.    _ft_has: D
+00001150: 6963 7420 3d20 7b7d 0a20 2020 205f 6674  ict = {}.    _ft
+00001160: 5f68 6173 5f66 7574 7572 6573 3a20 4469  _has_futures: Di
+00001170: 6374 203d 207b 7d0a 0a20 2020 205f 7375  ct = {}..    _su
+00001180: 7070 6f72 7465 645f 7472 6164 696e 675f  pported_trading_
+00001190: 6d6f 6465 5f6d 6172 6769 6e5f 7061 6972  mode_margin_pair
+000011a0: 733a 204c 6973 745b 5475 706c 655b 5472  s: List[Tuple[Tr
+000011b0: 6164 696e 674d 6f64 652c 204d 6172 6769  adingMode, Margi
+000011c0: 6e4d 6f64 655d 5d20 3d20 5b0a 2020 2020  nMode]] = [.    
+000011d0: 2020 2020 2320 5472 6164 696e 674d 6f64      # TradingMod
+000011e0: 652e 5350 4f54 2061 6c77 6179 7320 7375  e.SPOT always su
+000011f0: 7070 6f72 7465 6420 616e 6420 6e6f 7420  pported and not 
+00001200: 7265 7175 6972 6564 2069 6e20 7468 6973  required in this
+00001210: 206c 6973 740a 2020 2020 5d0a 0a20 2020   list.    ]..   
+00001220: 2064 6566 205f 5f69 6e69 745f 5f28 0a20   def __init__(. 
+00001230: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
+00001240: 2020 2020 2063 6f6e 6669 673a 2043 6f6e       config: Con
+00001250: 6669 672c 0a20 2020 2020 2020 202a 2c0a  fig,.        *,.
+00001260: 2020 2020 2020 2020 6578 6368 616e 6765          exchange
+00001270: 5f63 6f6e 6669 673a 204f 7074 696f 6e61  _config: Optiona
+00001280: 6c5b 4578 6368 616e 6765 436f 6e66 6967  l[ExchangeConfig
+00001290: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+000012a0: 2020 7661 6c69 6461 7465 3a20 626f 6f6c    validate: bool
+000012b0: 203d 2054 7275 652c 0a20 2020 2020 2020   = True,.       
+000012c0: 206c 6f61 645f 6c65 7665 7261 6765 5f74   load_leverage_t
+000012d0: 6965 7273 3a20 626f 6f6c 203d 2046 616c  iers: bool = Fal
+000012e0: 7365 2c0a 2020 2020 2920 2d3e 204e 6f6e  se,.    ) -> Non
+000012f0: 653a 0a20 2020 2020 2020 2022 2222 0a20  e:.        """. 
+00001300: 2020 2020 2020 2049 6e69 7469 616c 697a         Initializ
+00001310: 6573 2074 6869 7320 6d6f 6475 6c65 2077  es this module w
+00001320: 6974 6820 7468 6520 6769 7665 6e20 636f  ith the given co
+00001330: 6e66 6967 2c0a 2020 2020 2020 2020 6974  nfig,.        it
+00001340: 2064 6f65 7320 6261 7369 6320 7661 6c69   does basic vali
+00001350: 6461 7469 6f6e 2077 6865 7468 6572 2074  dation whether t
+00001360: 6865 2073 7065 6369 6669 6564 2065 7863  he specified exc
+00001370: 6861 6e67 6520 616e 6420 7061 6972 7320  hange and pairs 
+00001380: 6172 6520 7661 6c69 642e 0a20 2020 2020  are valid..     
+00001390: 2020 203a 7265 7475 726e 3a20 4e6f 6e65     :return: None
+000013a0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+000013b0: 2020 2020 2073 656c 662e 5f61 7069 3a20       self._api: 
+000013c0: 6363 7874 2e45 7863 6861 6e67 650a 2020  ccxt.Exchange.  
+000013d0: 2020 2020 2020 7365 6c66 2e5f 6170 695f        self._api_
+000013e0: 6173 796e 633a 2063 6378 745f 6173 796e  async: ccxt_asyn
+000013f0: 632e 4578 6368 616e 6765 203d 204e 6f6e  c.Exchange = Non
+00001400: 650a 2020 2020 2020 2020 7365 6c66 2e5f  e.        self._
+00001410: 6d61 726b 6574 733a 2044 6963 7420 3d20  markets: Dict = 
+00001420: 7b7d 0a20 2020 2020 2020 2073 656c 662e  {}.        self.
+00001430: 5f74 7261 6469 6e67 5f66 6565 733a 2044  _trading_fees: D
+00001440: 6963 745b 7374 722c 2041 6e79 5d20 3d20  ict[str, Any] = 
+00001450: 7b7d 0a20 2020 2020 2020 2073 656c 662e  {}.        self.
+00001460: 5f6c 6576 6572 6167 655f 7469 6572 733a  _leverage_tiers:
+00001470: 2044 6963 745b 7374 722c 204c 6973 745b   Dict[str, List[
+00001480: 4469 6374 5d5d 203d 207b 7d0a 2020 2020  Dict]] = {}.    
+00001490: 2020 2020 2320 4c6f 636b 2065 7665 6e74      # Lock event
+000014a0: 206c 6f6f 702e 2054 6869 7320 6973 206e   loop. This is n
+000014b0: 6563 6573 7361 7279 2074 6f20 6176 6f69  ecessary to avoi
+000014c0: 6420 7261 6365 2d63 6f6e 6469 7469 6f6e  d race-condition
+000014d0: 7320 7768 656e 2075 7369 6e67 2066 6f72  s when using for
+000014e0: 6365 2a20 636f 6d6d 616e 6473 0a20 2020  ce* commands.   
+000014f0: 2020 2020 2023 2044 7565 2074 6f20 6675       # Due to fu
+00001500: 6e64 696e 6720 6665 6520 6665 7463 6869  nding fee fetchi
+00001510: 6e67 2e0a 2020 2020 2020 2020 7365 6c66  ng..        self
+00001520: 2e5f 6c6f 6f70 5f6c 6f63 6b20 3d20 4c6f  ._loop_lock = Lo
+00001530: 636b 2829 0a20 2020 2020 2020 2073 656c  ck().        sel
+00001540: 662e 6c6f 6f70 203d 2073 656c 662e 5f69  f.loop = self._i
+00001550: 6e69 745f 6173 796e 635f 6c6f 6f70 2829  nit_async_loop()
+00001560: 0a20 2020 2020 2020 2073 656c 662e 5f63  .        self._c
+00001570: 6f6e 6669 673a 2043 6f6e 6669 6720 3d20  onfig: Config = 
+00001580: 7b7d 0a0a 2020 2020 2020 2020 7365 6c66  {}..        self
+00001590: 2e5f 636f 6e66 6967 2e75 7064 6174 6528  ._config.update(
+000015a0: 636f 6e66 6967 290a 0a20 2020 2020 2020  config)..       
+000015b0: 2023 2048 6f6c 6473 206c 6173 7420 6361   # Holds last ca
+000015c0: 6e64 6c65 2072 6566 7265 7368 6564 2074  ndle refreshed t
+000015d0: 696d 6520 6f66 2065 6163 6820 7061 6972  ime of each pair
+000015e0: 0a20 2020 2020 2020 2073 656c 662e 5f70  .        self._p
+000015f0: 6169 7273 5f6c 6173 745f 7265 6672 6573  airs_last_refres
+00001600: 685f 7469 6d65 3a20 4469 6374 5b50 6169  h_time: Dict[Pai
+00001610: 7257 6974 6854 696d 6566 7261 6d65 2c20  rWithTimeframe, 
+00001620: 696e 745d 203d 207b 7d0a 2020 2020 2020  int] = {}.      
+00001630: 2020 2320 5469 6d65 7374 616d 7020 6f66    # Timestamp of
+00001640: 206c 6173 7420 6d61 726b 6574 7320 7265   last markets re
+00001650: 6672 6573 680a 2020 2020 2020 2020 7365  fresh.        se
+00001660: 6c66 2e5f 6c61 7374 5f6d 6172 6b65 7473  lf._last_markets
+00001670: 5f72 6566 7265 7368 3a20 696e 7420 3d20  _refresh: int = 
+00001680: 300a 0a20 2020 2020 2020 2023 2043 6163  0..        # Cac
+00001690: 6865 2066 6f72 2031 3020 6d69 6e75 7465  he for 10 minute
+000016a0: 7320 2e2e 2e0a 2020 2020 2020 2020 7365  s ....        se
+000016b0: 6c66 2e5f 6361 6368 655f 6c6f 636b 203d  lf._cache_lock =
+000016c0: 204c 6f63 6b28 290a 2020 2020 2020 2020   Lock().        
+000016d0: 7365 6c66 2e5f 6665 7463 685f 7469 636b  self._fetch_tick
+000016e0: 6572 735f 6361 6368 653a 2054 544c 4361  ers_cache: TTLCa
+000016f0: 6368 6520 3d20 5454 4c43 6163 6865 286d  che = TTLCache(m
+00001700: 6178 7369 7a65 3d32 2c20 7474 6c3d 3630  axsize=2, ttl=60
+00001710: 202a 2031 3029 0a20 2020 2020 2020 2023   * 10).        #
+00001720: 2043 6163 6865 2076 616c 7565 7320 666f   Cache values fo
+00001730: 7220 3330 3020 746f 2061 766f 6964 2066  r 300 to avoid f
+00001740: 7265 7175 656e 7420 706f 6c6c 696e 6720  requent polling 
+00001750: 6f66 2074 6865 2065 7863 6861 6e67 6520  of the exchange 
+00001760: 666f 7220 7072 6963 6573 0a20 2020 2020  for prices.     
+00001770: 2020 2023 2043 6163 6869 6e67 206f 6e6c     # Caching onl
+00001780: 7920 6170 706c 6965 7320 746f 2052 5043  y applies to RPC
+00001790: 206d 6574 686f 6473 2c20 736f 2070 7269   methods, so pri
+000017a0: 6365 7320 666f 7220 6f70 656e 2074 7261  ces for open tra
+000017b0: 6465 7320 6172 6520 7374 696c 6c0a 2020  des are still.  
+000017c0: 2020 2020 2020 2320 7265 6672 6573 6865        # refreshe
+000017d0: 6420 6f6e 6365 2065 7665 7279 2069 7465  d once every ite
+000017e0: 7261 7469 6f6e 2e0a 2020 2020 2020 2020  ration..        
+000017f0: 2320 5368 6f75 6c64 6e27 7420 6265 2074  # Shouldn't be t
+00001800: 6f6f 2068 6967 6820 6569 7468 6572 2c20  oo high either, 
+00001810: 6173 2069 7427 6c6c 2066 7265 657a 6520  as it'll freeze 
+00001820: 5549 2075 7064 6174 6573 2069 6e20 6361  UI updates in ca
+00001830: 7365 206f 6620 6f70 656e 206f 7264 6572  se of open order
+00001840: 732e 0a20 2020 2020 2020 2073 656c 662e  s..        self.
+00001850: 5f65 7869 745f 7261 7465 5f63 6163 6865  _exit_rate_cache
+00001860: 3a20 5454 4c43 6163 6865 203d 2054 544c  : TTLCache = TTL
+00001870: 4361 6368 6528 6d61 7873 697a 653d 3130  Cache(maxsize=10
+00001880: 302c 2074 746c 3d33 3030 290a 2020 2020  0, ttl=300).    
+00001890: 2020 2020 7365 6c66 2e5f 656e 7472 795f      self._entry_
+000018a0: 7261 7465 5f63 6163 6865 3a20 5454 4c43  rate_cache: TTLC
+000018b0: 6163 6865 203d 2054 544c 4361 6368 6528  ache = TTLCache(
+000018c0: 6d61 7873 697a 653d 3130 302c 2074 746c  maxsize=100, ttl
+000018d0: 3d33 3030 290a 0a20 2020 2020 2020 2023  =300)..        #
+000018e0: 2048 6f6c 6473 2063 616e 646c 6573 0a20   Holds candles. 
+000018f0: 2020 2020 2020 2073 656c 662e 5f6b 6c69         self._kli
+00001900: 6e65 733a 2044 6963 745b 5061 6972 5769  nes: Dict[PairWi
+00001910: 7468 5469 6d65 6672 616d 652c 2044 6174  thTimeframe, Dat
+00001920: 6146 7261 6d65 5d20 3d20 7b7d 0a20 2020  aFrame] = {}.   
+00001930: 2020 2020 2073 656c 662e 5f65 7870 6972       self._expir
+00001940: 696e 675f 6361 6e64 6c65 5f63 6163 6865  ing_candle_cache
+00001950: 3a20 4469 6374 5b54 7570 6c65 5b73 7472  : Dict[Tuple[str
+00001960: 2c20 696e 745d 2c20 5065 7269 6f64 6963  , int], Periodic
+00001970: 4361 6368 655d 203d 207b 7d0a 0a20 2020  Cache] = {}..   
+00001980: 2020 2020 2023 2048 6f6c 6473 2061 6c6c       # Holds all
+00001990: 206f 7065 6e20 7365 6c6c 206f 7264 6572   open sell order
+000019a0: 7320 666f 7220 6472 795f 7275 6e0a 2020  s for dry_run.  
+000019b0: 2020 2020 2020 7365 6c66 2e5f 6472 795f        self._dry_
+000019c0: 7275 6e5f 6f70 656e 5f6f 7264 6572 733a  run_open_orders:
+000019d0: 2044 6963 745b 7374 722c 2041 6e79 5d20   Dict[str, Any] 
+000019e0: 3d20 7b7d 0a0a 2020 2020 2020 2020 6966  = {}..        if
+000019f0: 2063 6f6e 6669 675b 2264 7279 5f72 756e   config["dry_run
+00001a00: 225d 3a0a 2020 2020 2020 2020 2020 2020  "]:.            
+00001a10: 6c6f 6767 6572 2e69 6e66 6f28 2249 6e73  logger.info("Ins
+00001a20: 7461 6e63 6520 6973 2072 756e 6e69 6e67  tance is running
+00001a30: 2077 6974 6820 6472 795f 7275 6e20 656e   with dry_run en
+00001a40: 6162 6c65 6422 290a 2020 2020 2020 2020  abled").        
+00001a50: 6c6f 6767 6572 2e69 6e66 6f28 6622 5573  logger.info(f"Us
+00001a60: 696e 6720 4343 5854 207b 6363 7874 2e5f  ing CCXT {ccxt._
+00001a70: 5f76 6572 7369 6f6e 5f5f 7d22 290a 2020  _version__}").  
+00001a80: 2020 2020 2020 6578 6368 616e 6765 5f63        exchange_c
+00001a90: 6f6e 663a 2044 6963 745b 7374 722c 2041  onf: Dict[str, A
+00001aa0: 6e79 5d20 3d20 6578 6368 616e 6765 5f63  ny] = exchange_c
+00001ab0: 6f6e 6669 6720 6966 2065 7863 6861 6e67  onfig if exchang
+00001ac0: 655f 636f 6e66 6967 2065 6c73 6520 636f  e_config else co
+00001ad0: 6e66 6967 5b22 6578 6368 616e 6765 225d  nfig["exchange"]
+00001ae0: 0a20 2020 2020 2020 2072 656d 6f76 655f  .        remove_
+00001af0: 6578 6368 616e 6765 5f63 7265 6465 6e74  exchange_credent
+00001b00: 6961 6c73 2865 7863 6861 6e67 655f 636f  ials(exchange_co
+00001b10: 6e66 2c20 636f 6e66 6967 2e67 6574 2822  nf, config.get("
+00001b20: 6472 795f 7275 6e22 2c20 4661 6c73 6529  dry_run", False)
+00001b30: 290a 2020 2020 2020 2020 7365 6c66 2e6c  ).        self.l
+00001b40: 6f67 5f72 6573 706f 6e73 6573 203d 2065  og_responses = e
+00001b50: 7863 6861 6e67 655f 636f 6e66 2e67 6574  xchange_conf.get
+00001b60: 2822 6c6f 675f 7265 7370 6f6e 7365 7322  ("log_responses"
+00001b70: 2c20 4661 6c73 6529 0a0a 2020 2020 2020  , False)..      
+00001b80: 2020 2320 4c65 7665 7261 6765 2070 726f    # Leverage pro
+00001b90: 7065 7274 6965 730a 2020 2020 2020 2020  perties.        
+00001ba0: 7365 6c66 2e74 7261 6469 6e67 5f6d 6f64  self.trading_mod
+00001bb0: 653a 2054 7261 6469 6e67 4d6f 6465 203d  e: TradingMode =
+00001bc0: 2063 6f6e 6669 672e 6765 7428 2274 7261   config.get("tra
+00001bd0: 6469 6e67 5f6d 6f64 6522 2c20 5472 6164  ding_mode", Trad
+00001be0: 696e 674d 6f64 652e 5350 4f54 290a 2020  ingMode.SPOT).  
+00001bf0: 2020 2020 2020 7365 6c66 2e6d 6172 6769        self.margi
+00001c00: 6e5f 6d6f 6465 3a20 4d61 7267 696e 4d6f  n_mode: MarginMo
+00001c10: 6465 203d 2028 0a20 2020 2020 2020 2020  de = (.         
+00001c20: 2020 204d 6172 6769 6e4d 6f64 6528 636f     MarginMode(co
+00001c30: 6e66 6967 2e67 6574 2822 6d61 7267 696e  nfig.get("margin
+00001c40: 5f6d 6f64 6522 2929 2069 6620 636f 6e66  _mode")) if conf
+00001c50: 6967 2e67 6574 2822 6d61 7267 696e 5f6d  ig.get("margin_m
+00001c60: 6f64 6522 2920 656c 7365 204d 6172 6769  ode") else Margi
+00001c70: 6e4d 6f64 652e 4e4f 4e45 0a20 2020 2020  nMode.NONE.     
+00001c80: 2020 2029 0a20 2020 2020 2020 2073 656c     ).        sel
+00001c90: 662e 6c69 7175 6964 6174 696f 6e5f 6275  f.liquidation_bu
+00001ca0: 6666 6572 203d 2063 6f6e 6669 672e 6765  ffer = config.ge
+00001cb0: 7428 226c 6971 7569 6461 7469 6f6e 5f62  t("liquidation_b
+00001cc0: 7566 6665 7222 2c20 302e 3035 290a 0a20  uffer", 0.05).. 
+00001cd0: 2020 2020 2020 2023 2044 6565 7020 6d65         # Deep me
+00001ce0: 7267 6520 6674 5f68 6173 2077 6974 6820  rge ft_has with 
+00001cf0: 6465 6661 756c 7420 6674 5f68 6173 206f  default ft_has o
+00001d00: 7074 696f 6e73 0a20 2020 2020 2020 2073  ptions.        s
+00001d10: 656c 662e 5f66 745f 6861 7320 3d20 6465  elf._ft_has = de
+00001d20: 6570 5f6d 6572 6765 5f64 6963 7473 2873  ep_merge_dicts(s
+00001d30: 656c 662e 5f66 745f 6861 732c 2064 6565  elf._ft_has, dee
+00001d40: 7063 6f70 7928 7365 6c66 2e5f 6674 5f68  pcopy(self._ft_h
+00001d50: 6173 5f64 6566 6175 6c74 2929 0a20 2020  as_default)).   
+00001d60: 2020 2020 2069 6620 7365 6c66 2e74 7261       if self.tra
+00001d70: 6469 6e67 5f6d 6f64 6520 3d3d 2054 7261  ding_mode == Tra
+00001d80: 6469 6e67 4d6f 6465 2e46 5554 5552 4553  dingMode.FUTURES
+00001d90: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+00001da0: 6c66 2e5f 6674 5f68 6173 203d 2064 6565  lf._ft_has = dee
+00001db0: 705f 6d65 7267 655f 6469 6374 7328 7365  p_merge_dicts(se
+00001dc0: 6c66 2e5f 6674 5f68 6173 5f66 7574 7572  lf._ft_has_futur
+00001dd0: 6573 2c20 7365 6c66 2e5f 6674 5f68 6173  es, self._ft_has
+00001de0: 290a 2020 2020 2020 2020 6966 2065 7863  ).        if exc
+00001df0: 6861 6e67 655f 636f 6e66 2e67 6574 2822  hange_conf.get("
+00001e00: 5f66 745f 6861 735f 7061 7261 6d73 2229  _ft_has_params")
+00001e10: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+00001e20: 6c66 2e5f 6674 5f68 6173 203d 2064 6565  lf._ft_has = dee
+00001e30: 705f 6d65 7267 655f 6469 6374 7328 6578  p_merge_dicts(ex
+00001e40: 6368 616e 6765 5f63 6f6e 662e 6765 7428  change_conf.get(
+00001e50: 225f 6674 5f68 6173 5f70 6172 616d 7322  "_ft_has_params"
+00001e60: 292c 2073 656c 662e 5f66 745f 6861 7329  ), self._ft_has)
+00001e70: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
+00001e80: 6765 722e 696e 666f 2822 4f76 6572 7269  ger.info("Overri
+00001e90: 6469 6e67 2065 7863 6861 6e67 652e 5f66  ding exchange._f
+00001ea0: 745f 6861 7320 7769 7468 2063 6f6e 6669  t_has with confi
+00001eb0: 6720 7061 7261 6d73 2c20 7265 7375 6c74  g params, result
+00001ec0: 3a20 2573 222c 2073 656c 662e 5f66 745f  : %s", self._ft_
+00001ed0: 6861 7329 0a0a 2020 2020 2020 2020 2320  has)..        # 
+00001ee0: 4173 7369 676e 2074 6869 7320 6469 7265  Assign this dire
+00001ef0: 6374 6c79 2066 6f72 2065 6173 7920 6163  ctly for easy ac
+00001f00: 6365 7373 0a20 2020 2020 2020 2073 656c  cess.        sel
+00001f10: 662e 5f6f 686c 6376 5f70 6172 7469 616c  f._ohlcv_partial
+00001f20: 5f63 616e 646c 6520 3d20 7365 6c66 2e5f  _candle = self._
+00001f30: 6674 5f68 6173 5b22 6f68 6c63 765f 7061  ft_has["ohlcv_pa
+00001f40: 7274 6961 6c5f 6361 6e64 6c65 225d 0a0a  rtial_candle"]..
+00001f50: 2020 2020 2020 2020 7365 6c66 2e5f 7472          self._tr
+00001f60: 6164 6573 5f70 6167 696e 6174 696f 6e20  ades_pagination 
+00001f70: 3d20 7365 6c66 2e5f 6674 5f68 6173 5b22  = self._ft_has["
+00001f80: 7472 6164 6573 5f70 6167 696e 6174 696f  trades_paginatio
+00001f90: 6e22 5d0a 2020 2020 2020 2020 7365 6c66  n"].        self
+00001fa0: 2e5f 7472 6164 6573 5f70 6167 696e 6174  ._trades_paginat
+00001fb0: 696f 6e5f 6172 6720 3d20 7365 6c66 2e5f  ion_arg = self._
+00001fc0: 6674 5f68 6173 5b22 7472 6164 6573 5f70  ft_has["trades_p
+00001fd0: 6167 696e 6174 696f 6e5f 6172 6722 5d0a  agination_arg"].
+00001fe0: 0a20 2020 2020 2020 2023 2049 6e69 7469  .        # Initi
+00001ff0: 616c 697a 6520 6363 7874 206f 626a 6563  alize ccxt objec
+00002000: 7473 0a20 2020 2020 2020 2063 6378 745f  ts.        ccxt_
+00002010: 636f 6e66 6967 203d 2073 656c 662e 5f63  config = self._c
+00002020: 6378 745f 636f 6e66 6967 0a20 2020 2020  cxt_config.     
+00002030: 2020 2063 6378 745f 636f 6e66 6967 203d     ccxt_config =
+00002040: 2064 6565 705f 6d65 7267 655f 6469 6374   deep_merge_dict
+00002050: 7328 6578 6368 616e 6765 5f63 6f6e 662e  s(exchange_conf.
+00002060: 6765 7428 2263 6378 745f 636f 6e66 6967  get("ccxt_config
+00002070: 222c 207b 7d29 2c20 6363 7874 5f63 6f6e  ", {}), ccxt_con
+00002080: 6669 6729 0a20 2020 2020 2020 2063 6378  fig).        ccx
+00002090: 745f 636f 6e66 6967 203d 2064 6565 705f  t_config = deep_
+000020a0: 6d65 7267 655f 6469 6374 7328 6578 6368  merge_dicts(exch
+000020b0: 616e 6765 5f63 6f6e 662e 6765 7428 2263  ange_conf.get("c
+000020c0: 6378 745f 7379 6e63 5f63 6f6e 6669 6722  cxt_sync_config"
+000020d0: 2c20 7b7d 292c 2063 6378 745f 636f 6e66  , {}), ccxt_conf
+000020e0: 6967 290a 0a20 2020 2020 2020 2073 656c  ig)..        sel
+000020f0: 662e 5f61 7069 203d 2073 656c 662e 5f69  f._api = self._i
+00002100: 6e69 745f 6363 7874 2865 7863 6861 6e67  nit_ccxt(exchang
+00002110: 655f 636f 6e66 2c20 6363 7874 5f6b 7761  e_conf, ccxt_kwa
+00002120: 7267 733d 6363 7874 5f63 6f6e 6669 6729  rgs=ccxt_config)
+00002130: 0a0a 2020 2020 2020 2020 6363 7874 5f61  ..        ccxt_a
+00002140: 7379 6e63 5f63 6f6e 6669 6720 3d20 7365  sync_config = se
+00002150: 6c66 2e5f 6363 7874 5f63 6f6e 6669 670a  lf._ccxt_config.
+00002160: 2020 2020 2020 2020 6363 7874 5f61 7379          ccxt_asy
+00002170: 6e63 5f63 6f6e 6669 6720 3d20 6465 6570  nc_config = deep
+00002180: 5f6d 6572 6765 5f64 6963 7473 280a 2020  _merge_dicts(.  
+00002190: 2020 2020 2020 2020 2020 6578 6368 616e            exchan
+000021a0: 6765 5f63 6f6e 662e 6765 7428 2263 6378  ge_conf.get("ccx
+000021b0: 745f 636f 6e66 6967 222c 207b 7d29 2c20  t_config", {}), 
+000021c0: 6363 7874 5f61 7379 6e63 5f63 6f6e 6669  ccxt_async_confi
+000021d0: 670a 2020 2020 2020 2020 290a 2020 2020  g.        ).    
+000021e0: 2020 2020 6363 7874 5f61 7379 6e63 5f63      ccxt_async_c
+000021f0: 6f6e 6669 6720 3d20 6465 6570 5f6d 6572  onfig = deep_mer
+00002200: 6765 5f64 6963 7473 280a 2020 2020 2020  ge_dicts(.      
+00002210: 2020 2020 2020 6578 6368 616e 6765 5f63        exchange_c
+00002220: 6f6e 662e 6765 7428 2263 6378 745f 6173  onf.get("ccxt_as
+00002230: 796e 635f 636f 6e66 6967 222c 207b 7d29  ync_config", {})
+00002240: 2c20 6363 7874 5f61 7379 6e63 5f63 6f6e  , ccxt_async_con
+00002250: 6669 670a 2020 2020 2020 2020 290a 2020  fig.        ).  
+00002260: 2020 2020 2020 7365 6c66 2e5f 6170 695f        self._api_
+00002270: 6173 796e 6320 3d20 7365 6c66 2e5f 696e  async = self._in
+00002280: 6974 5f63 6378 7428 6578 6368 616e 6765  it_ccxt(exchange
+00002290: 5f63 6f6e 662c 2063 6378 745f 6173 796e  _conf, ccxt_asyn
+000022a0: 632c 2063 6378 745f 6b77 6172 6773 3d63  c, ccxt_kwargs=c
+000022b0: 6378 745f 6173 796e 635f 636f 6e66 6967  cxt_async_config
+000022c0: 290a 0a20 2020 2020 2020 206c 6f67 6765  )..        logge
+000022d0: 722e 696e 666f 2866 2755 7369 6e67 2045  r.info(f'Using E
+000022e0: 7863 6861 6e67 6520 227b 7365 6c66 2e6e  xchange "{self.n
+000022f0: 616d 657d 2227 290a 2020 2020 2020 2020  ame}"').        
+00002300: 7365 6c66 2e72 6571 7569 7265 645f 6361  self.required_ca
+00002310: 6e64 6c65 5f63 616c 6c5f 636f 756e 7420  ndle_call_count 
+00002320: 3d20 310a 2020 2020 2020 2020 6966 2076  = 1.        if v
+00002330: 616c 6964 6174 653a 0a20 2020 2020 2020  alidate:.       
+00002340: 2020 2020 2023 2049 6e69 7469 616c 206d       # Initial m
+00002350: 6172 6b65 7473 206c 6f61 640a 2020 2020  arkets load.    
+00002360: 2020 2020 2020 2020 7365 6c66 2e5f 6c6f          self._lo
+00002370: 6164 5f6d 6172 6b65 7473 2829 0a20 2020  ad_markets().   
+00002380: 2020 2020 2020 2020 2073 656c 662e 7661           self.va
+00002390: 6c69 6461 7465 5f63 6f6e 6669 6728 636f  lidate_config(co
+000023a0: 6e66 6967 290a 2020 2020 2020 2020 2020  nfig).          
+000023b0: 2020 7365 6c66 2e5f 7374 6172 7475 705f    self._startup_
+000023c0: 6361 6e64 6c65 5f63 6f75 6e74 3a20 696e  candle_count: in
+000023d0: 7420 3d20 636f 6e66 6967 2e67 6574 2822  t = config.get("
+000023e0: 7374 6172 7475 705f 6361 6e64 6c65 5f63  startup_candle_c
+000023f0: 6f75 6e74 222c 2030 290a 2020 2020 2020  ount", 0).      
+00002400: 2020 2020 2020 7365 6c66 2e72 6571 7569        self.requi
+00002410: 7265 645f 6361 6e64 6c65 5f63 616c 6c5f  red_candle_call_
+00002420: 636f 756e 7420 3d20 7365 6c66 2e76 616c  count = self.val
+00002430: 6964 6174 655f 7265 7175 6972 6564 5f73  idate_required_s
+00002440: 7461 7274 7570 5f63 616e 646c 6573 280a  tartup_candles(.
+00002450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002460: 7365 6c66 2e5f 7374 6172 7475 705f 6361  self._startup_ca
+00002470: 6e64 6c65 5f63 6f75 6e74 2c20 636f 6e66  ndle_count, conf
+00002480: 6967 2e67 6574 2822 7469 6d65 6672 616d  ig.get("timefram
+00002490: 6522 2c20 2222 290a 2020 2020 2020 2020  e", "").        
+000024a0: 2020 2020 290a 0a20 2020 2020 2020 2023      )..        #
+000024b0: 2043 6f6e 7665 7274 7320 7468 6520 696e   Converts the in
+000024c0: 7465 7276 616c 2070 726f 7669 6465 6420  terval provided 
+000024d0: 696e 206d 696e 7574 6573 2069 6e20 636f  in minutes in co
+000024e0: 6e66 6967 2074 6f20 7365 636f 6e64 730a  nfig to seconds.
+000024f0: 2020 2020 2020 2020 7365 6c66 2e6d 6172          self.mar
+00002500: 6b65 7473 5f72 6566 7265 7368 5f69 6e74  kets_refresh_int
+00002510: 6572 7661 6c3a 2069 6e74 203d 2028 0a20  erval: int = (. 
+00002520: 2020 2020 2020 2020 2020 2065 7863 6861             excha
+00002530: 6e67 655f 636f 6e66 2e67 6574 2822 6d61  nge_conf.get("ma
+00002540: 726b 6574 735f 7265 6672 6573 685f 696e  rkets_refresh_in
+00002550: 7465 7276 616c 222c 2036 3029 202a 2036  terval", 60) * 6
+00002560: 3020 2a20 3130 3030 0a20 2020 2020 2020  0 * 1000.       
+00002570: 2029 0a0a 2020 2020 2020 2020 6966 2073   )..        if s
+00002580: 656c 662e 7472 6164 696e 675f 6d6f 6465  elf.trading_mode
+00002590: 2021 3d20 5472 6164 696e 674d 6f64 652e   != TradingMode.
+000025a0: 5350 4f54 2061 6e64 206c 6f61 645f 6c65  SPOT and load_le
+000025b0: 7665 7261 6765 5f74 6965 7273 3a0a 2020  verage_tiers:.  
+000025c0: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
+000025d0: 696c 6c5f 6c65 7665 7261 6765 5f74 6965  ill_leverage_tie
+000025e0: 7273 2829 0a20 2020 2020 2020 2073 656c  rs().        sel
+000025f0: 662e 6164 6469 7469 6f6e 616c 5f65 7863  f.additional_exc
+00002600: 6861 6e67 655f 696e 6974 2829 0a0a 2020  hange_init()..  
+00002610: 2020 6465 6620 5f5f 6465 6c5f 5f28 7365    def __del__(se
+00002620: 6c66 293a 0a20 2020 2020 2020 2022 2222  lf):.        """
+00002630: 0a20 2020 2020 2020 2044 6573 7472 7563  .        Destruc
+00002640: 746f 7220 2d20 636c 6561 6e20 7570 2061  tor - clean up a
+00002650: 7379 6e63 2073 7475 6666 0a20 2020 2020  sync stuff.     
+00002660: 2020 2022 2222 0a20 2020 2020 2020 2073     """.        s
+00002670: 656c 662e 636c 6f73 6528 290a 0a20 2020  elf.close()..   
+00002680: 2064 6566 2063 6c6f 7365 2873 656c 6629   def close(self)
+00002690: 3a0a 2020 2020 2020 2020 6c6f 6767 6572  :.        logger
+000026a0: 2e64 6562 7567 2822 4578 6368 616e 6765  .debug("Exchange
+000026b0: 206f 626a 6563 7420 6465 7374 726f 7965   object destroye
+000026c0: 642c 2063 6c6f 7369 6e67 2061 7379 6e63  d, closing async
+000026d0: 206c 6f6f 7022 290a 2020 2020 2020 2020   loop").        
+000026e0: 6966 2028 0a20 2020 2020 2020 2020 2020  if (.           
+000026f0: 2073 656c 662e 5f61 7069 5f61 7379 6e63   self._api_async
+00002700: 0a20 2020 2020 2020 2020 2020 2061 6e64  .            and
+00002710: 2069 6e73 7065 6374 2e69 7363 6f72 6f75   inspect.iscorou
+00002720: 7469 6e65 6675 6e63 7469 6f6e 2873 656c  tinefunction(sel
+00002730: 662e 5f61 7069 5f61 7379 6e63 2e63 6c6f  f._api_async.clo
+00002740: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
+00002750: 616e 6420 7365 6c66 2e5f 6170 695f 6173  and self._api_as
+00002760: 796e 632e 7365 7373 696f 6e0a 2020 2020  ync.session.    
+00002770: 2020 2020 293a 0a20 2020 2020 2020 2020      ):.         
+00002780: 2020 206c 6f67 6765 722e 6465 6275 6728     logger.debug(
+00002790: 2243 6c6f 7369 6e67 2061 7379 6e63 2063  "Closing async c
+000027a0: 6378 7420 7365 7373 696f 6e2e 2229 0a20  cxt session."). 
+000027b0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000027c0: 6c6f 6f70 2e72 756e 5f75 6e74 696c 5f63  loop.run_until_c
+000027d0: 6f6d 706c 6574 6528 7365 6c66 2e5f 6170  omplete(self._ap
+000027e0: 695f 6173 796e 632e 636c 6f73 6528 2929  i_async.close())
+000027f0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00002800: 2e6c 6f6f 7020 616e 6420 6e6f 7420 7365  .loop and not se
+00002810: 6c66 2e6c 6f6f 702e 6973 5f63 6c6f 7365  lf.loop.is_close
+00002820: 6428 293a 0a20 2020 2020 2020 2020 2020  d():.           
+00002830: 2073 656c 662e 6c6f 6f70 2e63 6c6f 7365   self.loop.close
+00002840: 2829 0a0a 2020 2020 6465 6620 5f69 6e69  ()..    def _ini
+00002850: 745f 6173 796e 635f 6c6f 6f70 2873 656c  t_async_loop(sel
+00002860: 6629 202d 3e20 6173 796e 6369 6f2e 4162  f) -> asyncio.Ab
+00002870: 7374 7261 6374 4576 656e 744c 6f6f 703a  stractEventLoop:
+00002880: 0a20 2020 2020 2020 206c 6f6f 7020 3d20  .        loop = 
+00002890: 6173 796e 6369 6f2e 6e65 775f 6576 656e  asyncio.new_even
+000028a0: 745f 6c6f 6f70 2829 0a20 2020 2020 2020  t_loop().       
+000028b0: 2061 7379 6e63 696f 2e73 6574 5f65 7665   asyncio.set_eve
+000028c0: 6e74 5f6c 6f6f 7028 6c6f 6f70 290a 2020  nt_loop(loop).  
+000028d0: 2020 2020 2020 7265 7475 726e 206c 6f6f        return loo
+000028e0: 700a 0a20 2020 2064 6566 2076 616c 6964  p..    def valid
+000028f0: 6174 655f 636f 6e66 6967 2873 656c 662c  ate_config(self,
+00002900: 2063 6f6e 6669 6729 3a0a 2020 2020 2020   config):.      
+00002910: 2020 2320 4368 6563 6b20 6966 2074 696d    # Check if tim
+00002920: 6566 7261 6d65 2069 7320 6176 6169 6c61  eframe is availa
+00002930: 626c 650a 2020 2020 2020 2020 7365 6c66  ble.        self
+00002940: 2e76 616c 6964 6174 655f 7469 6d65 6672  .validate_timefr
+00002950: 616d 6573 2863 6f6e 6669 672e 6765 7428  ames(config.get(
+00002960: 2274 696d 6566 7261 6d65 2229 290a 0a20  "timeframe")).. 
+00002970: 2020 2020 2020 2023 2043 6865 636b 2069         # Check i
+00002980: 6620 616c 6c20 7061 6972 7320 6172 6520  f all pairs are 
+00002990: 6176 6169 6c61 626c 650a 2020 2020 2020  available.      
+000029a0: 2020 7365 6c66 2e76 616c 6964 6174 655f    self.validate_
+000029b0: 7374 616b 6563 7572 7265 6e63 7928 636f  stakecurrency(co
+000029c0: 6e66 6967 5b22 7374 616b 655f 6375 7272  nfig["stake_curr
+000029d0: 656e 6379 225d 290a 2020 2020 2020 2020  ency"]).        
+000029e0: 6966 206e 6f74 2063 6f6e 6669 675b 2265  if not config["e
+000029f0: 7863 6861 6e67 6522 5d2e 6765 7428 2273  xchange"].get("s
+00002a00: 6b69 705f 7061 6972 5f76 616c 6964 6174  kip_pair_validat
+00002a10: 696f 6e22 293a 0a20 2020 2020 2020 2020  ion"):.         
+00002a20: 2020 2073 656c 662e 7661 6c69 6461 7465     self.validate
+00002a30: 5f70 6169 7273 2863 6f6e 6669 675b 2265  _pairs(config["e
+00002a40: 7863 6861 6e67 6522 5d5b 2270 6169 725f  xchange"]["pair_
+00002a50: 7768 6974 656c 6973 7422 5d29 0a20 2020  whitelist"]).   
+00002a60: 2020 2020 2073 656c 662e 7661 6c69 6461       self.valida
+00002a70: 7465 5f6f 7264 6572 7479 7065 7328 636f  te_ordertypes(co
+00002a80: 6e66 6967 2e67 6574 2822 6f72 6465 725f  nfig.get("order_
+00002a90: 7479 7065 7322 2c20 7b7d 2929 0a20 2020  types", {})).   
+00002aa0: 2020 2020 2073 656c 662e 7661 6c69 6461       self.valida
+00002ab0: 7465 5f6f 7264 6572 5f74 696d 655f 696e  te_order_time_in
+00002ac0: 5f66 6f72 6365 2863 6f6e 6669 672e 6765  _force(config.ge
+00002ad0: 7428 226f 7264 6572 5f74 696d 655f 696e  t("order_time_in
+00002ae0: 5f66 6f72 6365 222c 207b 7d29 290a 2020  _force", {})).  
+00002af0: 2020 2020 2020 7365 6c66 2e76 616c 6964        self.valid
+00002b00: 6174 655f 7472 6164 696e 675f 6d6f 6465  ate_trading_mode
+00002b10: 5f61 6e64 5f6d 6172 6769 6e5f 6d6f 6465  _and_margin_mode
+00002b20: 2873 656c 662e 7472 6164 696e 675f 6d6f  (self.trading_mo
+00002b30: 6465 2c20 7365 6c66 2e6d 6172 6769 6e5f  de, self.margin_
+00002b40: 6d6f 6465 290a 2020 2020 2020 2020 7365  mode).        se
+00002b50: 6c66 2e76 616c 6964 6174 655f 7072 6963  lf.validate_pric
+00002b60: 696e 6728 636f 6e66 6967 5b22 6578 6974  ing(config["exit
+00002b70: 5f70 7269 6369 6e67 225d 290a 2020 2020  _pricing"]).    
+00002b80: 2020 2020 7365 6c66 2e76 616c 6964 6174      self.validat
+00002b90: 655f 7072 6963 696e 6728 636f 6e66 6967  e_pricing(config
+00002ba0: 5b22 656e 7472 795f 7072 6963 696e 6722  ["entry_pricing"
+00002bb0: 5d29 0a0a 2020 2020 6465 6620 5f69 6e69  ])..    def _ini
+00002bc0: 745f 6363 7874 280a 2020 2020 2020 2020  t_ccxt(.        
+00002bd0: 7365 6c66 2c0a 2020 2020 2020 2020 6578  self,.        ex
+00002be0: 6368 616e 6765 5f63 6f6e 6669 673a 2044  change_config: D
+00002bf0: 6963 745b 7374 722c 2041 6e79 5d2c 0a20  ict[str, Any],. 
+00002c00: 2020 2020 2020 2063 6378 745f 6d6f 6475         ccxt_modu
+00002c10: 6c65 3a20 4363 7874 4d6f 6475 6c65 5479  le: CcxtModuleTy
+00002c20: 7065 203d 2063 6378 742c 0a20 2020 2020  pe = ccxt,.     
+00002c30: 2020 202a 2c0a 2020 2020 2020 2020 6363     *,.        cc
+00002c40: 7874 5f6b 7761 7267 733a 2044 6963 742c  xt_kwargs: Dict,
+00002c50: 0a20 2020 2029 202d 3e20 6363 7874 2e45  .    ) -> ccxt.E
+00002c60: 7863 6861 6e67 653a 0a20 2020 2020 2020  xchange:.       
+00002c70: 2022 2222 0a20 2020 2020 2020 2049 6e69   """.        Ini
+00002c80: 7469 616c 697a 6520 6363 7874 2077 6974  tialize ccxt wit
+00002c90: 6820 6769 7665 6e20 636f 6e66 6967 2061  h given config a
+00002ca0: 6e64 2072 6574 7572 6e20 7661 6c69 640a  nd return valid.
+00002cb0: 2020 2020 2020 2020 6363 7874 2069 6e73          ccxt ins
+00002cc0: 7461 6e63 652e 0a20 2020 2020 2020 2022  tance..        "
+00002cd0: 2222 0a20 2020 2020 2020 2023 2046 696e  "".        # Fin
+00002ce0: 6420 6d61 7463 6869 6e67 2063 6c61 7373  d matching class
+00002cf0: 2066 6f72 2074 6865 2067 6976 656e 2065   for the given e
+00002d00: 7863 6861 6e67 6520 6e61 6d65 0a20 2020  xchange name.   
+00002d10: 2020 2020 206e 616d 6520 3d20 6578 6368       name = exch
+00002d20: 616e 6765 5f63 6f6e 6669 675b 226e 616d  ange_config["nam
+00002d30: 6522 5d0a 0a20 2020 2020 2020 2069 6620  e"]..        if 
+00002d40: 6e6f 7420 6973 5f65 7863 6861 6e67 655f  not is_exchange_
+00002d50: 6b6e 6f77 6e5f 6363 7874 286e 616d 652c  known_ccxt(name,
+00002d60: 2063 6378 745f 6d6f 6475 6c65 293a 0a20   ccxt_module):. 
+00002d70: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00002d80: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
+00002d90: 7074 696f 6e28 6622 4578 6368 616e 6765  ption(f"Exchange
+00002da0: 207b 6e61 6d65 7d20 6973 206e 6f74 2073   {name} is not s
+00002db0: 7570 706f 7274 6564 2062 7920 6363 7874  upported by ccxt
+00002dc0: 2229 0a0a 2020 2020 2020 2020 6578 5f63  ")..        ex_c
+00002dd0: 6f6e 6669 6720 3d20 7b0a 2020 2020 2020  onfig = {.      
+00002de0: 2020 2020 2020 2261 7069 4b65 7922 3a20        "apiKey": 
+00002df0: 6578 6368 616e 6765 5f63 6f6e 6669 672e  exchange_config.
+00002e00: 6765 7428 226b 6579 2229 2c0a 2020 2020  get("key"),.    
+00002e10: 2020 2020 2020 2020 2273 6563 7265 7422          "secret"
+00002e20: 3a20 6578 6368 616e 6765 5f63 6f6e 6669  : exchange_confi
+00002e30: 672e 6765 7428 2273 6563 7265 7422 292c  g.get("secret"),
+00002e40: 0a20 2020 2020 2020 2020 2020 2022 7061  .            "pa
+00002e50: 7373 776f 7264 223a 2065 7863 6861 6e67  ssword": exchang
+00002e60: 655f 636f 6e66 6967 2e67 6574 2822 7061  e_config.get("pa
+00002e70: 7373 776f 7264 2229 2c0a 2020 2020 2020  ssword"),.      
+00002e80: 2020 2020 2020 2275 6964 223a 2065 7863        "uid": exc
+00002e90: 6861 6e67 655f 636f 6e66 6967 2e67 6574  hange_config.get
+00002ea0: 2822 7569 6422 2c20 2222 292c 0a20 2020  ("uid", ""),.   
+00002eb0: 2020 2020 207d 0a20 2020 2020 2020 2069       }.        i
+00002ec0: 6620 6363 7874 5f6b 7761 7267 733a 0a20  f ccxt_kwargs:. 
+00002ed0: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+00002ee0: 722e 696e 666f 2822 4170 706c 7969 6e67  r.info("Applying
+00002ef0: 2061 6464 6974 696f 6e61 6c20 6363 7874   additional ccxt
+00002f00: 2063 6f6e 6669 673a 2025 7322 2c20 6363   config: %s", cc
+00002f10: 7874 5f6b 7761 7267 7329 0a20 2020 2020  xt_kwargs).     
+00002f20: 2020 2069 6620 7365 6c66 2e5f 6363 7874     if self._ccxt
+00002f30: 5f70 6172 616d 733a 0a20 2020 2020 2020  _params:.       
+00002f40: 2020 2020 2023 2049 6e6a 6563 7420 7374       # Inject st
+00002f50: 6174 6963 206f 7074 696f 6e73 2061 6674  atic options aft
+00002f60: 6572 2074 6865 2061 626f 7665 206f 7574  er the above out
+00002f70: 7075 7420 746f 206e 6f74 2063 6f6e 6675  put to not confu
+00002f80: 7365 2075 7365 7273 2e0a 2020 2020 2020  se users..      
+00002f90: 2020 2020 2020 6363 7874 5f6b 7761 7267        ccxt_kwarg
+00002fa0: 7320 3d20 6465 6570 5f6d 6572 6765 5f64  s = deep_merge_d
+00002fb0: 6963 7473 2873 656c 662e 5f63 6378 745f  icts(self._ccxt_
+00002fc0: 7061 7261 6d73 2c20 6363 7874 5f6b 7761  params, ccxt_kwa
+00002fd0: 7267 7329 0a20 2020 2020 2020 2069 6620  rgs).        if 
+00002fe0: 6363 7874 5f6b 7761 7267 733a 0a20 2020  ccxt_kwargs:.   
+00002ff0: 2020 2020 2020 2020 2065 785f 636f 6e66           ex_conf
+00003000: 6967 2e75 7064 6174 6528 6363 7874 5f6b  ig.update(ccxt_k
+00003010: 7761 7267 7329 0a20 2020 2020 2020 2074  wargs).        t
+00003020: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
+00003030: 6170 6920 3d20 6765 7461 7474 7228 6363  api = getattr(cc
+00003040: 7874 5f6d 6f64 756c 652c 206e 616d 652e  xt_module, name.
+00003050: 6c6f 7765 7228 2929 2865 785f 636f 6e66  lower())(ex_conf
+00003060: 6967 290a 2020 2020 2020 2020 6578 6365  ig).        exce
+00003070: 7074 2028 4b65 7945 7272 6f72 2c20 4174  pt (KeyError, At
+00003080: 7472 6962 7574 6545 7272 6f72 2920 6173  tributeError) as
+00003090: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
+000030a0: 7261 6973 6520 4f70 6572 6174 696f 6e61  raise Operationa
+000030b0: 6c45 7863 6570 7469 6f6e 2866 2245 7863  lException(f"Exc
+000030c0: 6861 6e67 6520 7b6e 616d 657d 2069 7320  hange {name} is 
+000030d0: 6e6f 7420 7375 7070 6f72 7465 6422 2920  not supported") 
+000030e0: 6672 6f6d 2065 0a20 2020 2020 2020 2065  from e.        e
+000030f0: 7863 6570 7420 6363 7874 2e42 6173 6545  xcept ccxt.BaseE
+00003100: 7272 6f72 2061 7320 653a 0a20 2020 2020  rror as e:.     
+00003110: 2020 2020 2020 2072 6169 7365 204f 7065         raise Ope
+00003120: 7261 7469 6f6e 616c 4578 6365 7074 696f  rationalExceptio
+00003130: 6e28 6622 496e 6974 6961 6c69 7a61 7469  n(f"Initializati
+00003140: 6f6e 206f 6620 6363 7874 2066 6169 6c65  on of ccxt faile
+00003150: 642e 2052 6561 736f 6e3a 207b 657d 2229  d. Reason: {e}")
+00003160: 2066 726f 6d20 650a 0a20 2020 2020 2020   from e..       
+00003170: 2072 6574 7572 6e20 6170 690a 0a20 2020   return api..   
+00003180: 2040 7072 6f70 6572 7479 0a20 2020 2064   @property.    d
+00003190: 6566 205f 6363 7874 5f63 6f6e 6669 6728  ef _ccxt_config(
+000031a0: 7365 6c66 2920 2d3e 2044 6963 743a 0a20  self) -> Dict:. 
+000031b0: 2020 2020 2020 2023 2050 6172 616d 6574         # Paramet
+000031c0: 6572 7320 746f 2061 6464 2064 6972 6563  ers to add direc
+000031d0: 746c 7920 746f 2063 6378 7420 7379 6e63  tly to ccxt sync
+000031e0: 2f61 7379 6e63 2069 6e69 7469 616c 697a  /async initializ
+000031f0: 6174 696f 6e2e 0a20 2020 2020 2020 2069  ation..        i
+00003200: 6620 7365 6c66 2e74 7261 6469 6e67 5f6d  f self.trading_m
+00003210: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
+00003220: 6465 2e4d 4152 4749 4e3a 0a20 2020 2020  de.MARGIN:.     
+00003230: 2020 2020 2020 2072 6574 7572 6e20 7b22         return {"
+00003240: 6f70 7469 6f6e 7322 3a20 7b22 6465 6661  options": {"defa
+00003250: 756c 7454 7970 6522 3a20 226d 6172 6769  ultType": "margi
+00003260: 6e22 7d7d 0a20 2020 2020 2020 2065 6c69  n"}}.        eli
+00003270: 6620 7365 6c66 2e74 7261 6469 6e67 5f6d  f self.trading_m
+00003280: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
+00003290: 6465 2e46 5554 5552 4553 3a0a 2020 2020  de.FUTURES:.    
+000032a0: 2020 2020 2020 2020 7265 7475 726e 207b          return {
+000032b0: 226f 7074 696f 6e73 223a 207b 2264 6566  "options": {"def
+000032c0: 6175 6c74 5479 7065 223a 2073 656c 662e  aultType": self.
+000032d0: 5f66 745f 6861 735b 2263 6378 745f 6675  _ft_has["ccxt_fu
+000032e0: 7475 7265 735f 6e61 6d65 225d 7d7d 0a20  tures_name"]}}. 
+000032f0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00003300: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00003310: 7b7d 0a0a 2020 2020 4070 726f 7065 7274  {}..    @propert
+00003320: 790a 2020 2020 6465 6620 6e61 6d65 2873  y.    def name(s
+00003330: 656c 6629 202d 3e20 7374 723a 0a20 2020  elf) -> str:.   
+00003340: 2020 2020 2022 2222 6578 6368 616e 6765       """exchange
+00003350: 204e 616d 6520 2866 726f 6d20 6363 7874   Name (from ccxt
+00003360: 2922 2222 0a20 2020 2020 2020 2072 6574  )""".        ret
+00003370: 7572 6e20 7365 6c66 2e5f 6170 692e 6e61  urn self._api.na
+00003380: 6d65 0a0a 2020 2020 4070 726f 7065 7274  me..    @propert
+00003390: 790a 2020 2020 6465 6620 6964 2873 656c  y.    def id(sel
+000033a0: 6629 202d 3e20 7374 723a 0a20 2020 2020  f) -> str:.     
+000033b0: 2020 2022 2222 6578 6368 616e 6765 2063     """exchange c
+000033c0: 6378 7420 6964 2222 220a 2020 2020 2020  cxt id""".      
+000033d0: 2020 7265 7475 726e 2073 656c 662e 5f61    return self._a
+000033e0: 7069 2e69 640a 0a20 2020 2040 7072 6f70  pi.id..    @prop
+000033f0: 6572 7479 0a20 2020 2064 6566 2074 696d  erty.    def tim
+00003400: 6566 7261 6d65 7328 7365 6c66 2920 2d3e  eframes(self) ->
+00003410: 204c 6973 745b 7374 725d 3a0a 2020 2020   List[str]:.    
+00003420: 2020 2020 7265 7475 726e 206c 6973 7428      return list(
+00003430: 2873 656c 662e 5f61 7069 2e74 696d 6566  (self._api.timef
+00003440: 7261 6d65 7320 6f72 207b 7d29 2e6b 6579  rames or {}).key
+00003450: 7328 2929 0a0a 2020 2020 4070 726f 7065  s())..    @prope
+00003460: 7274 790a 2020 2020 6465 6620 6d61 726b  rty.    def mark
+00003470: 6574 7328 7365 6c66 2920 2d3e 2044 6963  ets(self) -> Dic
+00003480: 745b 7374 722c 2041 6e79 5d3a 0a20 2020  t[str, Any]:.   
+00003490: 2020 2020 2022 2222 6578 6368 616e 6765       """exchange
+000034a0: 2063 6378 7420 6d61 726b 6574 7322 2222   ccxt markets"""
+000034b0: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+000034c0: 7365 6c66 2e5f 6d61 726b 6574 733a 0a20  self._markets:. 
+000034d0: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+000034e0: 722e 696e 666f 2822 4d61 726b 6574 7320  r.info("Markets 
+000034f0: 7765 7265 206e 6f74 206c 6f61 6465 642e  were not loaded.
+00003500: 204c 6f61 6469 6e67 2074 6865 6d20 6e6f   Loading them no
+00003510: 772e 2e22 290a 2020 2020 2020 2020 2020  w..").          
+00003520: 2020 7365 6c66 2e5f 6c6f 6164 5f6d 6172    self._load_mar
+00003530: 6b65 7473 2829 0a20 2020 2020 2020 2072  kets().        r
+00003540: 6574 7572 6e20 7365 6c66 2e5f 6d61 726b  eturn self._mark
+00003550: 6574 730a 0a20 2020 2040 7072 6f70 6572  ets..    @proper
+00003560: 7479 0a20 2020 2064 6566 2070 7265 6369  ty.    def preci
+00003570: 7369 6f6e 4d6f 6465 2873 656c 6629 202d  sionMode(self) -
+00003580: 3e20 696e 743a 0a20 2020 2020 2020 2022  > int:.        "
+00003590: 2222 6578 6368 616e 6765 2063 6378 7420  ""exchange ccxt 
+000035a0: 7072 6563 6973 696f 6e4d 6f64 6522 2222  precisionMode"""
+000035b0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000035c0: 7365 6c66 2e5f 6170 692e 7072 6563 6973  self._api.precis
+000035d0: 696f 6e4d 6f64 650a 0a20 2020 2064 6566  ionMode..    def
+000035e0: 2061 6464 6974 696f 6e61 6c5f 6578 6368   additional_exch
+000035f0: 616e 6765 5f69 6e69 7428 7365 6c66 2920  ange_init(self) 
+00003600: 2d3e 204e 6f6e 653a 0a20 2020 2020 2020  -> None:.       
+00003610: 2022 2222 0a20 2020 2020 2020 2041 6464   """.        Add
+00003620: 6974 696f 6e61 6c20 6578 6368 616e 6765  itional exchange
+00003630: 2069 6e69 7469 616c 697a 6174 696f 6e20   initialization 
+00003640: 6c6f 6769 632e 0a20 2020 2020 2020 202e  logic..        .
+00003650: 6170 6920 7769 6c6c 2062 6520 6176 6169  api will be avai
+00003660: 6c61 626c 6520 6174 2074 6869 7320 706f  lable at this po
+00003670: 696e 742e 0a20 2020 2020 2020 204d 7573  int..        Mus
+00003680: 7420 6265 206f 7665 7272 6964 6465 6e20  t be overridden 
+00003690: 696e 2063 6869 6c64 206d 6574 686f 6473  in child methods
+000036a0: 2069 6620 7265 7175 6972 6564 2e0a 2020   if required..  
+000036b0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+000036c0: 2020 7061 7373 0a0a 2020 2020 6465 6620    pass..    def 
+000036d0: 5f6c 6f67 5f65 7863 6861 6e67 655f 7265  _log_exchange_re
+000036e0: 7370 6f6e 7365 2873 656c 662c 2065 6e64  sponse(self, end
+000036f0: 706f 696e 743a 2073 7472 2c20 7265 7370  point: str, resp
+00003700: 6f6e 7365 2c20 2a2c 2061 6464 5f69 6e66  onse, *, add_inf
+00003710: 6f3d 4e6f 6e65 2920 2d3e 204e 6f6e 653a  o=None) -> None:
+00003720: 0a20 2020 2020 2020 2022 2222 4c6f 6720  .        """Log 
+00003730: 6578 6368 616e 6765 2072 6573 706f 6e73  exchange respons
+00003740: 6573 2222 220a 2020 2020 2020 2020 6966  es""".        if
+00003750: 2073 656c 662e 6c6f 675f 7265 7370 6f6e   self.log_respon
+00003760: 7365 733a 0a20 2020 2020 2020 2020 2020  ses:.           
+00003770: 2061 6464 5f69 6e66 6f5f 7374 7220 3d20   add_info_str = 
+00003780: 2222 2069 6620 6164 645f 696e 666f 2069  "" if add_info i
+00003790: 7320 4e6f 6e65 2065 6c73 6520 6622 207b  s None else f" {
+000037a0: 6164 645f 696e 666f 7d3a 2022 0a20 2020  add_info}: ".   
+000037b0: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+000037c0: 696e 666f 2866 2241 5049 207b 656e 6470  info(f"API {endp
+000037d0: 6f69 6e74 7d3a 207b 6164 645f 696e 666f  oint}: {add_info
+000037e0: 5f73 7472 7d7b 7265 7370 6f6e 7365 7d22  _str}{response}"
+000037f0: 290a 0a20 2020 2064 6566 206f 686c 6376  )..    def ohlcv
+00003800: 5f63 616e 646c 655f 6c69 6d69 7428 0a20  _candle_limit(. 
+00003810: 2020 2020 2020 2073 656c 662c 2074 696d         self, tim
+00003820: 6566 7261 6d65 3a20 7374 722c 2063 616e  eframe: str, can
+00003830: 646c 655f 7479 7065 3a20 4361 6e64 6c65  dle_type: Candle
+00003840: 5479 7065 2c20 7369 6e63 655f 6d73 3a20  Type, since_ms: 
+00003850: 4f70 7469 6f6e 616c 5b69 6e74 5d20 3d20  Optional[int] = 
+00003860: 4e6f 6e65 0a20 2020 2029 202d 3e20 696e  None.    ) -> in
+00003870: 743a 0a20 2020 2020 2020 2022 2222 0a20  t:.        """. 
+00003880: 2020 2020 2020 2045 7863 6861 6e67 6520         Exchange 
+00003890: 6f68 6c63 7620 6361 6e64 6c65 206c 696d  ohlcv candle lim
+000038a0: 6974 0a20 2020 2020 2020 2055 7365 7320  it.        Uses 
+000038b0: 6f68 6c63 765f 6361 6e64 6c65 5f6c 696d  ohlcv_candle_lim
+000038c0: 6974 5f70 6572 5f74 696d 6566 7261 6d65  it_per_timeframe
+000038d0: 2069 6620 7468 6520 6578 6368 616e 6765   if the exchange
+000038e0: 2068 6173 2064 6966 6665 7265 6e74 206c   has different l
+000038f0: 696d 6974 730a 2020 2020 2020 2020 7065  imits.        pe
+00003900: 7220 7469 6d65 6672 616d 6520 2865 2e67  r timeframe (e.g
+00003910: 2e20 6269 7474 7265 7829 2c20 6f74 6865  . bittrex), othe
+00003920: 7277 6973 6520 6661 6c6c 7320 6261 636b  rwise falls back
+00003930: 2074 6f20 6f68 6c63 765f 6361 6e64 6c65   to ohlcv_candle
+00003940: 5f6c 696d 6974 0a20 2020 2020 2020 2054  _limit.        T
+00003950: 4f44 4f3a 2074 6869 7320 6973 206d 6f73  ODO: this is mos
+00003960: 7420 6c69 6b65 6c79 206e 6f20 6c6f 6e67  t likely no long
+00003970: 6572 206e 6565 6465 6420 7369 6e63 6520  er needed since 
+00003980: 6f6e 6c79 2062 6974 7472 6578 206e 6565  only bittrex nee
+00003990: 6465 6420 7468 6973 2e0a 2020 2020 2020  ded this..      
+000039a0: 2020 3a70 6172 616d 2074 696d 6566 7261    :param timefra
+000039b0: 6d65 3a20 5469 6d65 6672 616d 6520 746f  me: Timeframe to
+000039c0: 2063 6865 636b 0a20 2020 2020 2020 203a   check.        :
+000039d0: 7061 7261 6d20 6361 6e64 6c65 5f74 7970  param candle_typ
+000039e0: 653a 2043 616e 646c 652d 7479 7065 0a20  e: Candle-type. 
+000039f0: 2020 2020 2020 203a 7061 7261 6d20 7369         :param si
+00003a00: 6e63 655f 6d73 3a20 5374 6172 7469 6e67  nce_ms: Starting
+00003a10: 2074 696d 6573 7461 6d70 0a20 2020 2020   timestamp.     
+00003a20: 2020 203a 7265 7475 726e 3a20 4361 6e64     :return: Cand
+00003a30: 6c65 206c 696d 6974 2061 7320 696e 7465  le limit as inte
+00003a40: 6765 720a 2020 2020 2020 2020 2222 220a  ger.        """.
+00003a50: 2020 2020 2020 2020 7265 7475 726e 2069          return i
+00003a60: 6e74 280a 2020 2020 2020 2020 2020 2020  nt(.            
+00003a70: 7365 6c66 2e5f 6674 5f68 6173 2e67 6574  self._ft_has.get
+00003a80: 2822 6f68 6c63 765f 6361 6e64 6c65 5f6c  ("ohlcv_candle_l
+00003a90: 696d 6974 5f70 6572 5f74 696d 6566 7261  imit_per_timefra
+00003aa0: 6d65 222c 207b 7d29 2e67 6574 280a 2020  me", {}).get(.  
+00003ab0: 2020 2020 2020 2020 2020 2020 2020 7469                ti
+00003ac0: 6d65 6672 616d 652c 2073 656c 662e 5f66  meframe, self._f
+00003ad0: 745f 6861 732e 6765 7428 226f 686c 6376  t_has.get("ohlcv
+00003ae0: 5f63 616e 646c 655f 6c69 6d69 7422 290a  _candle_limit").
+00003af0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00003b00: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
+00003b10: 2067 6574 5f6d 6172 6b65 7473 280a 2020   get_markets(.  
+00003b20: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
+00003b30: 2020 2020 6261 7365 5f63 7572 7265 6e63      base_currenc
+00003b40: 6965 733a 204f 7074 696f 6e61 6c5b 4c69  ies: Optional[Li
+00003b50: 7374 5b73 7472 5d5d 203d 204e 6f6e 652c  st[str]] = None,
+00003b60: 0a20 2020 2020 2020 2071 756f 7465 5f63  .        quote_c
+00003b70: 7572 7265 6e63 6965 733a 204f 7074 696f  urrencies: Optio
+00003b80: 6e61 6c5b 4c69 7374 5b73 7472 5d5d 203d  nal[List[str]] =
+00003b90: 204e 6f6e 652c 0a20 2020 2020 2020 2073   None,.        s
+00003ba0: 706f 745f 6f6e 6c79 3a20 626f 6f6c 203d  pot_only: bool =
+00003bb0: 2046 616c 7365 2c0a 2020 2020 2020 2020   False,.        
+00003bc0: 6d61 7267 696e 5f6f 6e6c 793a 2062 6f6f  margin_only: boo
+00003bd0: 6c20 3d20 4661 6c73 652c 0a20 2020 2020  l = False,.     
+00003be0: 2020 2066 7574 7572 6573 5f6f 6e6c 793a     futures_only:
+00003bf0: 2062 6f6f 6c20 3d20 4661 6c73 652c 0a20   bool = False,. 
+00003c00: 2020 2020 2020 2074 7261 6461 626c 655f         tradable_
+00003c10: 6f6e 6c79 3a20 626f 6f6c 203d 2054 7275  only: bool = Tru
+00003c20: 652c 0a20 2020 2020 2020 2061 6374 6976  e,.        activ
+00003c30: 655f 6f6e 6c79 3a20 626f 6f6c 203d 2046  e_only: bool = F
+00003c40: 616c 7365 2c0a 2020 2020 2920 2d3e 2044  alse,.    ) -> D
+00003c50: 6963 745b 7374 722c 2041 6e79 5d3a 0a20  ict[str, Any]:. 
+00003c60: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00003c70: 2020 2052 6574 7572 6e20 6578 6368 616e     Return exchan
+00003c80: 6765 2063 6378 7420 6d61 726b 6574 732c  ge ccxt markets,
+00003c90: 2066 696c 7465 7265 6420 6f75 7420 6279   filtered out by
+00003ca0: 2062 6173 6520 6375 7272 656e 6379 2061   base currency a
+00003cb0: 6e64 2071 756f 7465 2063 7572 7265 6e63  nd quote currenc
+00003cc0: 790a 2020 2020 2020 2020 6966 2074 6869  y.        if thi
+00003cd0: 7320 7761 7320 7265 7175 6573 7465 6420  s was requested 
+00003ce0: 696e 2070 6172 616d 6574 6572 732e 0a20  in parameters.. 
+00003cf0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00003d00: 2020 206d 6172 6b65 7473 203d 2073 656c     markets = sel
+00003d10: 662e 6d61 726b 6574 730a 2020 2020 2020  f.markets.      
+00003d20: 2020 6966 206e 6f74 206d 6172 6b65 7473    if not markets
+00003d30: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+00003d40: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
+00003d50: 7863 6570 7469 6f6e 2822 4d61 726b 6574  xception("Market
+00003d60: 7320 7765 7265 206e 6f74 206c 6f61 6465  s were not loade
+00003d70: 642e 2229 0a0a 2020 2020 2020 2020 6966  d.")..        if
+00003d80: 2062 6173 655f 6375 7272 656e 6369 6573   base_currencies
+00003d90: 3a0a 2020 2020 2020 2020 2020 2020 6d61  :.            ma
+00003da0: 726b 6574 7320 3d20 7b6b 3a20 7620 666f  rkets = {k: v fo
+00003db0: 7220 6b2c 2076 2069 6e20 6d61 726b 6574  r k, v in market
+00003dc0: 732e 6974 656d 7328 2920 6966 2076 5b22  s.items() if v["
+00003dd0: 6261 7365 225d 2069 6e20 6261 7365 5f63  base"] in base_c
+00003de0: 7572 7265 6e63 6965 737d 0a20 2020 2020  urrencies}.     
+00003df0: 2020 2069 6620 7175 6f74 655f 6375 7272     if quote_curr
+00003e00: 656e 6369 6573 3a0a 2020 2020 2020 2020  encies:.        
+00003e10: 2020 2020 6d61 726b 6574 7320 3d20 7b6b      markets = {k
+00003e20: 3a20 7620 666f 7220 6b2c 2076 2069 6e20  : v for k, v in 
+00003e30: 6d61 726b 6574 732e 6974 656d 7328 2920  markets.items() 
+00003e40: 6966 2076 5b22 7175 6f74 6522 5d20 696e  if v["quote"] in
+00003e50: 2071 756f 7465 5f63 7572 7265 6e63 6965   quote_currencie
+00003e60: 737d 0a20 2020 2020 2020 2069 6620 7472  s}.        if tr
+00003e70: 6164 6162 6c65 5f6f 6e6c 793a 0a20 2020  adable_only:.   
+00003e80: 2020 2020 2020 2020 206d 6172 6b65 7473           markets
+00003e90: 203d 207b 6b3a 2076 2066 6f72 206b 2c20   = {k: v for k, 
+00003ea0: 7620 696e 206d 6172 6b65 7473 2e69 7465  v in markets.ite
+00003eb0: 6d73 2829 2069 6620 7365 6c66 2e6d 6172  ms() if self.mar
+00003ec0: 6b65 745f 6973 5f74 7261 6461 626c 6528  ket_is_tradable(
+00003ed0: 7629 7d0a 2020 2020 2020 2020 6966 2073  v)}.        if s
+00003ee0: 706f 745f 6f6e 6c79 3a0a 2020 2020 2020  pot_only:.      
+00003ef0: 2020 2020 2020 6d61 726b 6574 7320 3d20        markets = 
+00003f00: 7b6b 3a20 7620 666f 7220 6b2c 2076 2069  {k: v for k, v i
+00003f10: 6e20 6d61 726b 6574 732e 6974 656d 7328  n markets.items(
+00003f20: 2920 6966 2073 656c 662e 6d61 726b 6574  ) if self.market
+00003f30: 5f69 735f 7370 6f74 2876 297d 0a20 2020  _is_spot(v)}.   
+00003f40: 2020 2020 2069 6620 6d61 7267 696e 5f6f       if margin_o
+00003f50: 6e6c 793a 0a20 2020 2020 2020 2020 2020  nly:.           
+00003f60: 206d 6172 6b65 7473 203d 207b 6b3a 2076   markets = {k: v
+00003f70: 2066 6f72 206b 2c20 7620 696e 206d 6172   for k, v in mar
+00003f80: 6b65 7473 2e69 7465 6d73 2829 2069 6620  kets.items() if 
+00003f90: 7365 6c66 2e6d 6172 6b65 745f 6973 5f6d  self.market_is_m
+00003fa0: 6172 6769 6e28 7629 7d0a 2020 2020 2020  argin(v)}.      
+00003fb0: 2020 6966 2066 7574 7572 6573 5f6f 6e6c    if futures_onl
+00003fc0: 793a 0a20 2020 2020 2020 2020 2020 206d  y:.            m
+00003fd0: 6172 6b65 7473 203d 207b 6b3a 2076 2066  arkets = {k: v f
+00003fe0: 6f72 206b 2c20 7620 696e 206d 6172 6b65  or k, v in marke
+00003ff0: 7473 2e69 7465 6d73 2829 2069 6620 7365  ts.items() if se
+00004000: 6c66 2e6d 6172 6b65 745f 6973 5f66 7574  lf.market_is_fut
+00004010: 7572 6528 7629 7d0a 2020 2020 2020 2020  ure(v)}.        
+00004020: 6966 2061 6374 6976 655f 6f6e 6c79 3a0a  if active_only:.
+00004030: 2020 2020 2020 2020 2020 2020 6d61 726b              mark
+00004040: 6574 7320 3d20 7b6b 3a20 7620 666f 7220  ets = {k: v for 
+00004050: 6b2c 2076 2069 6e20 6d61 726b 6574 732e  k, v in markets.
+00004060: 6974 656d 7328 2920 6966 206d 6172 6b65  items() if marke
+00004070: 745f 6973 5f61 6374 6976 6528 7629 7d0a  t_is_active(v)}.
+00004080: 2020 2020 2020 2020 7265 7475 726e 206d          return m
+00004090: 6172 6b65 7473 0a0a 2020 2020 6465 6620  arkets..    def 
+000040a0: 6765 745f 7175 6f74 655f 6375 7272 656e  get_quote_curren
+000040b0: 6369 6573 2873 656c 6629 202d 3e20 4c69  cies(self) -> Li
+000040c0: 7374 5b73 7472 5d3a 0a20 2020 2020 2020  st[str]:.       
+000040d0: 2022 2222 0a20 2020 2020 2020 2052 6574   """.        Ret
+000040e0: 7572 6e20 6120 6c69 7374 206f 6620 7375  urn a list of su
+000040f0: 7070 6f72 7465 6420 7175 6f74 6520 6375  pported quote cu
+00004100: 7272 656e 6369 6573 0a20 2020 2020 2020  rrencies.       
+00004110: 2022 2222 0a20 2020 2020 2020 206d 6172   """.        mar
+00004120: 6b65 7473 203d 2073 656c 662e 6d61 726b  kets = self.mark
+00004130: 6574 730a 2020 2020 2020 2020 7265 7475  ets.        retu
+00004140: 726e 2073 6f72 7465 6428 7365 7428 5b78  rn sorted(set([x
+00004150: 5b22 7175 6f74 6522 5d20 666f 7220 5f2c  ["quote"] for _,
+00004160: 2078 2069 6e20 6d61 726b 6574 732e 6974   x in markets.it
+00004170: 656d 7328 295d 2929 0a0a 2020 2020 6465  ems()]))..    de
+00004180: 6620 6765 745f 7061 6972 5f71 756f 7465  f get_pair_quote
+00004190: 5f63 7572 7265 6e63 7928 7365 6c66 2c20  _currency(self, 
+000041a0: 7061 6972 3a20 7374 7229 202d 3e20 7374  pair: str) -> st
+000041b0: 723a 0a20 2020 2020 2020 2022 2222 5265  r:.        """Re
+000041c0: 7475 726e 2061 2070 6169 7227 7320 7175  turn a pair's qu
+000041d0: 6f74 6520 6375 7272 656e 6379 2028 6261  ote currency (ba
+000041e0: 7365 2f71 756f 7465 3a73 6574 746c 656d  se/quote:settlem
+000041f0: 656e 7429 2222 220a 2020 2020 2020 2020  ent)""".        
+00004200: 7265 7475 726e 2073 656c 662e 6d61 726b  return self.mark
+00004210: 6574 732e 6765 7428 7061 6972 2c20 7b7d  ets.get(pair, {}
+00004220: 292e 6765 7428 2271 756f 7465 222c 2022  ).get("quote", "
+00004230: 2229 0a0a 2020 2020 6465 6620 6765 745f  ")..    def get_
+00004240: 7061 6972 5f62 6173 655f 6375 7272 656e  pair_base_curren
+00004250: 6379 2873 656c 662c 2070 6169 723a 2073  cy(self, pair: s
+00004260: 7472 2920 2d3e 2073 7472 3a0a 2020 2020  tr) -> str:.    
+00004270: 2020 2020 2222 2252 6574 7572 6e20 6120      """Return a 
+00004280: 7061 6972 2773 2062 6173 6520 6375 7272  pair's base curr
+00004290: 656e 6379 2028 6261 7365 2f71 756f 7465  ency (base/quote
+000042a0: 3a73 6574 746c 656d 656e 7429 2222 220a  :settlement)""".
+000042b0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+000042c0: 656c 662e 6d61 726b 6574 732e 6765 7428  elf.markets.get(
+000042d0: 7061 6972 2c20 7b7d 292e 6765 7428 2262  pair, {}).get("b
+000042e0: 6173 6522 2c20 2222 290a 0a20 2020 2064  ase", "")..    d
+000042f0: 6566 206d 6172 6b65 745f 6973 5f66 7574  ef market_is_fut
+00004300: 7572 6528 7365 6c66 2c20 6d61 726b 6574  ure(self, market
+00004310: 3a20 4469 6374 5b73 7472 2c20 416e 795d  : Dict[str, Any]
+00004320: 2920 2d3e 2062 6f6f 6c3a 0a20 2020 2020  ) -> bool:.     
+00004330: 2020 2072 6574 7572 6e20 280a 2020 2020     return (.    
+00004340: 2020 2020 2020 2020 6d61 726b 6574 2e67          market.g
+00004350: 6574 2873 656c 662e 5f66 745f 6861 735b  et(self._ft_has[
+00004360: 2263 6378 745f 6675 7475 7265 735f 6e61  "ccxt_futures_na
+00004370: 6d65 225d 2c20 4661 6c73 6529 2069 7320  me"], False) is 
+00004380: 5472 7565 0a20 2020 2020 2020 2020 2020  True.           
+00004390: 2061 6e64 206d 6172 6b65 742e 6765 7428   and market.get(
+000043a0: 226c 696e 6561 7222 2c20 4661 6c73 6529  "linear", False)
+000043b0: 2069 7320 5472 7565 0a20 2020 2020 2020   is True.       
+000043c0: 2029 0a0a 2020 2020 6465 6620 6d61 726b   )..    def mark
+000043d0: 6574 5f69 735f 7370 6f74 2873 656c 662c  et_is_spot(self,
+000043e0: 206d 6172 6b65 743a 2044 6963 745b 7374   market: Dict[st
+000043f0: 722c 2041 6e79 5d29 202d 3e20 626f 6f6c  r, Any]) -> bool
+00004400: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
+00004410: 206d 6172 6b65 742e 6765 7428 2273 706f   market.get("spo
+00004420: 7422 2c20 4661 6c73 6529 2069 7320 5472  t", False) is Tr
+00004430: 7565 0a0a 2020 2020 6465 6620 6d61 726b  ue..    def mark
+00004440: 6574 5f69 735f 6d61 7267 696e 2873 656c  et_is_margin(sel
+00004450: 662c 206d 6172 6b65 743a 2044 6963 745b  f, market: Dict[
+00004460: 7374 722c 2041 6e79 5d29 202d 3e20 626f  str, Any]) -> bo
+00004470: 6f6c 3a0a 2020 2020 2020 2020 7265 7475  ol:.        retu
+00004480: 726e 206d 6172 6b65 742e 6765 7428 226d  rn market.get("m
+00004490: 6172 6769 6e22 2c20 4661 6c73 6529 2069  argin", False) i
+000044a0: 7320 5472 7565 0a0a 2020 2020 6465 6620  s True..    def 
+000044b0: 6d61 726b 6574 5f69 735f 7472 6164 6162  market_is_tradab
+000044c0: 6c65 2873 656c 662c 206d 6172 6b65 743a  le(self, market:
+000044d0: 2044 6963 745b 7374 722c 2041 6e79 5d29   Dict[str, Any])
+000044e0: 202d 3e20 626f 6f6c 3a0a 2020 2020 2020   -> bool:.      
+000044f0: 2020 2222 220a 2020 2020 2020 2020 4368    """.        Ch
+00004500: 6563 6b20 6966 2074 6865 206d 6172 6b65  eck if the marke
+00004510: 7420 7379 6d62 6f6c 2069 7320 7472 6164  t symbol is trad
+00004520: 6162 6c65 2062 7920 4672 6571 7472 6164  able by Freqtrad
+00004530: 652e 0a20 2020 2020 2020 2045 6e73 7572  e..        Ensur
+00004540: 6573 2074 6861 7420 436f 6e66 6967 7572  es that Configur
+00004550: 6564 206d 6f64 6520 616c 6967 6e73 2074  ed mode aligns t
+00004560: 6f0a 2020 2020 2020 2020 2222 220a 2020  o.        """.  
+00004570: 2020 2020 2020 7265 7475 726e 2028 0a20        return (. 
+00004580: 2020 2020 2020 2020 2020 206d 6172 6b65             marke
+00004590: 742e 6765 7428 2271 756f 7465 222c 204e  t.get("quote", N
+000045a0: 6f6e 6529 2069 7320 6e6f 7420 4e6f 6e65  one) is not None
+000045b0: 0a20 2020 2020 2020 2020 2020 2061 6e64  .            and
+000045c0: 206d 6172 6b65 742e 6765 7428 2262 6173   market.get("bas
+000045d0: 6522 2c20 4e6f 6e65 2920 6973 206e 6f74  e", None) is not
+000045e0: 204e 6f6e 650a 2020 2020 2020 2020 2020   None.          
+000045f0: 2020 616e 6420 280a 2020 2020 2020 2020    and (.        
+00004600: 2020 2020 2020 2020 7365 6c66 2e70 7265          self.pre
+00004610: 6369 7369 6f6e 4d6f 6465 2021 3d20 5449  cisionMode != TI
+00004620: 434b 5f53 495a 450a 2020 2020 2020 2020  CK_SIZE.        
+00004630: 2020 2020 2020 2020 2320 546f 6f20 6c6f          # Too lo
+00004640: 7720 7072 6563 6973 696f 6e20 7769 6c6c  w precision will
+00004650: 2066 616c 7369 6679 2063 616c 6375 6c61   falsify calcula
+00004660: 7469 6f6e 730a 2020 2020 2020 2020 2020  tions.          
+00004670: 2020 2020 2020 6f72 206d 6172 6b65 742e        or market.
+00004680: 6765 7428 2270 7265 6369 7369 6f6e 222c  get("precision",
+00004690: 207b 7d29 2e67 6574 2822 7072 6963 6522   {}).get("price"
+000046a0: 2920 3e20 3165 2d31 310a 2020 2020 2020  ) > 1e-11.      
+000046b0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+000046c0: 2020 2020 616e 6420 280a 2020 2020 2020      and (.      
+000046d0: 2020 2020 2020 2020 2020 2873 656c 662e            (self.
+000046e0: 7472 6164 696e 675f 6d6f 6465 203d 3d20  trading_mode == 
+000046f0: 5472 6164 696e 674d 6f64 652e 5350 4f54  TradingMode.SPOT
+00004700: 2061 6e64 2073 656c 662e 6d61 726b 6574   and self.market
+00004710: 5f69 735f 7370 6f74 286d 6172 6b65 7429  _is_spot(market)
+00004720: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00004730: 2020 6f72 2028 7365 6c66 2e74 7261 6469    or (self.tradi
+00004740: 6e67 5f6d 6f64 6520 3d3d 2054 7261 6469  ng_mode == Tradi
+00004750: 6e67 4d6f 6465 2e4d 4152 4749 4e20 616e  ngMode.MARGIN an
+00004760: 6420 7365 6c66 2e6d 6172 6b65 745f 6973  d self.market_is
+00004770: 5f6d 6172 6769 6e28 6d61 726b 6574 2929  _margin(market))
+00004780: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004790: 206f 7220 2873 656c 662e 7472 6164 696e   or (self.tradin
+000047a0: 675f 6d6f 6465 203d 3d20 5472 6164 696e  g_mode == Tradin
+000047b0: 674d 6f64 652e 4655 5455 5245 5320 616e  gMode.FUTURES an
+000047c0: 6420 7365 6c66 2e6d 6172 6b65 745f 6973  d self.market_is
+000047d0: 5f66 7574 7572 6528 6d61 726b 6574 2929  _future(market))
+000047e0: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
+000047f0: 2020 2020 2020 2029 0a0a 2020 2020 6465         )..    de
+00004800: 6620 6b6c 696e 6573 2873 656c 662c 2070  f klines(self, p
+00004810: 6169 725f 696e 7465 7276 616c 3a20 5061  air_interval: Pa
+00004820: 6972 5769 7468 5469 6d65 6672 616d 652c  irWithTimeframe,
+00004830: 2063 6f70 793a 2062 6f6f 6c20 3d20 5472   copy: bool = Tr
+00004840: 7565 2920 2d3e 2044 6174 6146 7261 6d65  ue) -> DataFrame
+00004850: 3a0a 2020 2020 2020 2020 6966 2070 6169  :.        if pai
+00004860: 725f 696e 7465 7276 616c 2069 6e20 7365  r_interval in se
+00004870: 6c66 2e5f 6b6c 696e 6573 3a0a 2020 2020  lf._klines:.    
+00004880: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00004890: 656c 662e 5f6b 6c69 6e65 735b 7061 6972  elf._klines[pair
+000048a0: 5f69 6e74 6572 7661 6c5d 2e63 6f70 7928  _interval].copy(
+000048b0: 2920 6966 2063 6f70 7920 656c 7365 2073  ) if copy else s
+000048c0: 656c 662e 5f6b 6c69 6e65 735b 7061 6972  elf._klines[pair
+000048d0: 5f69 6e74 6572 7661 6c5d 0a20 2020 2020  _interval].     
+000048e0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+000048f0: 2020 2020 2072 6574 7572 6e20 4461 7461       return Data
+00004900: 4672 616d 6528 290a 0a20 2020 2064 6566  Frame()..    def
+00004910: 2067 6574 5f63 6f6e 7472 6163 745f 7369   get_contract_si
+00004920: 7a65 2873 656c 662c 2070 6169 723a 2073  ze(self, pair: s
+00004930: 7472 2920 2d3e 204f 7074 696f 6e61 6c5b  tr) -> Optional[
+00004940: 666c 6f61 745d 3a0a 2020 2020 2020 2020  float]:.        
+00004950: 6966 2073 656c 662e 7472 6164 696e 675f  if self.trading_
+00004960: 6d6f 6465 203d 3d20 5472 6164 696e 674d  mode == TradingM
+00004970: 6f64 652e 4655 5455 5245 533a 0a20 2020  ode.FUTURES:.   
+00004980: 2020 2020 2020 2020 206d 6172 6b65 7420           market 
+00004990: 3d20 7365 6c66 2e6d 6172 6b65 7473 2e67  = self.markets.g
+000049a0: 6574 2870 6169 722c 207b 7d29 0a20 2020  et(pair, {}).   
+000049b0: 2020 2020 2020 2020 2063 6f6e 7472 6163           contrac
+000049c0: 745f 7369 7a65 3a20 666c 6f61 7420 3d20  t_size: float = 
+000049d0: 312e 300a 2020 2020 2020 2020 2020 2020  1.0.            
+000049e0: 6966 206e 6f74 206d 6172 6b65 743a 0a20  if not market:. 
+000049f0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00004a00: 6574 7572 6e20 4e6f 6e65 0a20 2020 2020  eturn None.     
+00004a10: 2020 2020 2020 2069 6620 6d61 726b 6574         if market
+00004a20: 2e67 6574 2822 636f 6e74 7261 6374 5369  .get("contractSi
+00004a30: 7a65 2229 2069 7320 6e6f 7420 4e6f 6e65  ze") is not None
+00004a40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00004a50: 2020 2320 6363 7874 2068 6173 2063 6f6e    # ccxt has con
+00004a60: 7472 6163 7453 697a 6520 696e 206d 6172  tractSize in mar
+00004a70: 6b65 7473 2061 7320 7374 7269 6e67 0a20  kets as string. 
+00004a80: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00004a90: 6f6e 7472 6163 745f 7369 7a65 203d 2066  ontract_size = f
+00004aa0: 6c6f 6174 286d 6172 6b65 745b 2263 6f6e  loat(market["con
+00004ab0: 7472 6163 7453 697a 6522 5d29 0a20 2020  tractSize"]).   
+00004ac0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00004ad0: 636f 6e74 7261 6374 5f73 697a 650a 2020  contract_size.  
+00004ae0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00004af0: 2020 2020 2020 2020 7265 7475 726e 2031          return 1
+00004b00: 0a0a 2020 2020 6465 6620 5f74 7261 6465  ..    def _trade
+00004b10: 735f 636f 6e74 7261 6374 735f 746f 5f61  s_contracts_to_a
+00004b20: 6d6f 756e 7428 7365 6c66 2c20 7472 6164  mount(self, trad
+00004b30: 6573 3a20 4c69 7374 2920 2d3e 204c 6973  es: List) -> Lis
+00004b40: 743a 0a20 2020 2020 2020 2069 6620 6c65  t:.        if le
+00004b50: 6e28 7472 6164 6573 2920 3e20 3020 616e  n(trades) > 0 an
+00004b60: 6420 2273 796d 626f 6c22 2069 6e20 7472  d "symbol" in tr
+00004b70: 6164 6573 5b30 5d3a 0a20 2020 2020 2020  ades[0]:.       
+00004b80: 2020 2020 2063 6f6e 7472 6163 745f 7369       contract_si
+00004b90: 7a65 203d 2073 656c 662e 6765 745f 636f  ze = self.get_co
+00004ba0: 6e74 7261 6374 5f73 697a 6528 7472 6164  ntract_size(trad
+00004bb0: 6573 5b30 5d5b 2273 796d 626f 6c22 5d29  es[0]["symbol"])
+00004bc0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00004bd0: 636f 6e74 7261 6374 5f73 697a 6520 213d  contract_size !=
+00004be0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
+00004bf0: 2020 2020 666f 7220 7472 6164 6520 696e      for trade in
+00004c00: 2074 7261 6465 733a 0a20 2020 2020 2020   trades:.       
+00004c10: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+00004c20: 6465 5b22 616d 6f75 6e74 225d 203d 2074  de["amount"] = t
+00004c30: 7261 6465 5b22 616d 6f75 6e74 225d 202a  rade["amount"] *
+00004c40: 2063 6f6e 7472 6163 745f 7369 7a65 0a20   contract_size. 
+00004c50: 2020 2020 2020 2072 6574 7572 6e20 7472         return tr
+00004c60: 6164 6573 0a0a 2020 2020 6465 6620 5f6f  ades..    def _o
+00004c70: 7264 6572 5f63 6f6e 7472 6163 7473 5f74  rder_contracts_t
+00004c80: 6f5f 616d 6f75 6e74 2873 656c 662c 206f  o_amount(self, o
+00004c90: 7264 6572 3a20 4469 6374 2920 2d3e 2044  rder: Dict) -> D
+00004ca0: 6963 743a 0a20 2020 2020 2020 2069 6620  ict:.        if 
+00004cb0: 2273 796d 626f 6c22 2069 6e20 6f72 6465  "symbol" in orde
+00004cc0: 7220 616e 6420 6f72 6465 725b 2273 796d  r and order["sym
+00004cd0: 626f 6c22 5d20 6973 206e 6f74 204e 6f6e  bol"] is not Non
+00004ce0: 653a 0a20 2020 2020 2020 2020 2020 2063  e:.            c
+00004cf0: 6f6e 7472 6163 745f 7369 7a65 203d 2073  ontract_size = s
+00004d00: 656c 662e 6765 745f 636f 6e74 7261 6374  elf.get_contract
+00004d10: 5f73 697a 6528 6f72 6465 725b 2273 796d  _size(order["sym
+00004d20: 626f 6c22 5d29 0a20 2020 2020 2020 2020  bol"]).         
+00004d30: 2020 2069 6620 636f 6e74 7261 6374 5f73     if contract_s
+00004d40: 697a 6520 213d 2031 3a0a 2020 2020 2020  ize != 1:.      
+00004d50: 2020 2020 2020 2020 2020 666f 7220 7072            for pr
+00004d60: 6f70 2069 6e20 7365 6c66 2e5f 6674 5f68  op in self._ft_h
+00004d70: 6173 2e67 6574 2822 6f72 6465 725f 7072  as.get("order_pr
+00004d80: 6f70 735f 696e 5f63 6f6e 7472 6163 7473  ops_in_contracts
+00004d90: 222c 205b 5d29 3a0a 2020 2020 2020 2020  ", []):.        
+00004da0: 2020 2020 2020 2020 2020 2020 6966 2070              if p
+00004db0: 726f 7020 696e 206f 7264 6572 2061 6e64  rop in order and
+00004dc0: 206f 7264 6572 5b70 726f 705d 2069 7320   order[prop] is 
+00004dd0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00004de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004df0: 2020 6f72 6465 725b 7072 6f70 5d20 3d20    order[prop] = 
+00004e00: 6f72 6465 725b 7072 6f70 5d20 2a20 636f  order[prop] * co
+00004e10: 6e74 7261 6374 5f73 697a 650a 2020 2020  ntract_size.    
+00004e20: 2020 2020 7265 7475 726e 206f 7264 6572      return order
+00004e30: 0a0a 2020 2020 6465 6620 5f61 6d6f 756e  ..    def _amoun
+00004e40: 745f 746f 5f63 6f6e 7472 6163 7473 2873  t_to_contracts(s
+00004e50: 656c 662c 2070 6169 723a 2073 7472 2c20  elf, pair: str, 
+00004e60: 616d 6f75 6e74 3a20 666c 6f61 7429 202d  amount: float) -
+00004e70: 3e20 666c 6f61 743a 0a20 2020 2020 2020  > float:.       
+00004e80: 2063 6f6e 7472 6163 745f 7369 7a65 203d   contract_size =
+00004e90: 2073 656c 662e 6765 745f 636f 6e74 7261   self.get_contra
+00004ea0: 6374 5f73 697a 6528 7061 6972 290a 2020  ct_size(pair).  
+00004eb0: 2020 2020 2020 7265 7475 726e 2061 6d6f        return amo
+00004ec0: 756e 745f 746f 5f63 6f6e 7472 6163 7473  unt_to_contracts
+00004ed0: 2861 6d6f 756e 742c 2063 6f6e 7472 6163  (amount, contrac
+00004ee0: 745f 7369 7a65 290a 0a20 2020 2064 6566  t_size)..    def
+00004ef0: 205f 636f 6e74 7261 6374 735f 746f 5f61   _contracts_to_a
+00004f00: 6d6f 756e 7428 7365 6c66 2c20 7061 6972  mount(self, pair
+00004f10: 3a20 7374 722c 206e 756d 5f63 6f6e 7472  : str, num_contr
+00004f20: 6163 7473 3a20 666c 6f61 7429 202d 3e20  acts: float) -> 
+00004f30: 666c 6f61 743a 0a20 2020 2020 2020 2063  float:.        c
+00004f40: 6f6e 7472 6163 745f 7369 7a65 203d 2073  ontract_size = s
+00004f50: 656c 662e 6765 745f 636f 6e74 7261 6374  elf.get_contract
+00004f60: 5f73 697a 6528 7061 6972 290a 2020 2020  _size(pair).    
+00004f70: 2020 2020 7265 7475 726e 2063 6f6e 7472      return contr
+00004f80: 6163 7473 5f74 6f5f 616d 6f75 6e74 286e  acts_to_amount(n
+00004f90: 756d 5f63 6f6e 7472 6163 7473 2c20 636f  um_contracts, co
+00004fa0: 6e74 7261 6374 5f73 697a 6529 0a0a 2020  ntract_size)..  
+00004fb0: 2020 6465 6620 616d 6f75 6e74 5f74 6f5f    def amount_to_
+00004fc0: 636f 6e74 7261 6374 5f70 7265 6369 7369  contract_precisi
+00004fd0: 6f6e 2873 656c 662c 2070 6169 723a 2073  on(self, pair: s
+00004fe0: 7472 2c20 616d 6f75 6e74 3a20 666c 6f61  tr, amount: floa
+00004ff0: 7429 202d 3e20 666c 6f61 743a 0a20 2020  t) -> float:.   
+00005000: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00005010: 2048 656c 7065 7220 7772 6170 7065 7220   Helper wrapper 
+00005020: 6172 6f75 6e64 2061 6d6f 756e 745f 746f  around amount_to
+00005030: 5f63 6f6e 7472 6163 745f 7072 6563 6973  _contract_precis
+00005040: 696f 6e0a 2020 2020 2020 2020 2222 220a  ion.        """.
+00005050: 2020 2020 2020 2020 636f 6e74 7261 6374          contract
+00005060: 5f73 697a 6520 3d20 7365 6c66 2e67 6574  _size = self.get
+00005070: 5f63 6f6e 7472 6163 745f 7369 7a65 2870  _contract_size(p
+00005080: 6169 7229 0a0a 2020 2020 2020 2020 7265  air)..        re
+00005090: 7475 726e 2061 6d6f 756e 745f 746f 5f63  turn amount_to_c
+000050a0: 6f6e 7472 6163 745f 7072 6563 6973 696f  ontract_precisio
+000050b0: 6e28 0a20 2020 2020 2020 2020 2020 2061  n(.            a
+000050c0: 6d6f 756e 742c 2073 656c 662e 6765 745f  mount, self.get_
+000050d0: 7072 6563 6973 696f 6e5f 616d 6f75 6e74  precision_amount
+000050e0: 2870 6169 7229 2c20 7365 6c66 2e70 7265  (pair), self.pre
+000050f0: 6369 7369 6f6e 4d6f 6465 2c20 636f 6e74  cisionMode, cont
+00005100: 7261 6374 5f73 697a 650a 2020 2020 2020  ract_size.      
+00005110: 2020 290a 0a20 2020 2064 6566 205f 6c6f    )..    def _lo
+00005120: 6164 5f61 7379 6e63 5f6d 6172 6b65 7473  ad_async_markets
+00005130: 2873 656c 662c 2072 656c 6f61 643a 2062  (self, reload: b
+00005140: 6f6f 6c20 3d20 4661 6c73 6529 202d 3e20  ool = False) -> 
+00005150: 4e6f 6e65 3a0a 2020 2020 2020 2020 7472  None:.        tr
+00005160: 793a 0a20 2020 2020 2020 2020 2020 2069  y:.            i
+00005170: 6620 7365 6c66 2e5f 6170 695f 6173 796e  f self._api_asyn
+00005180: 633a 0a20 2020 2020 2020 2020 2020 2020  c:.             
+00005190: 2020 2073 656c 662e 6c6f 6f70 2e72 756e     self.loop.run
+000051a0: 5f75 6e74 696c 5f63 6f6d 706c 6574 6528  _until_complete(
+000051b0: 7365 6c66 2e5f 6170 695f 6173 796e 632e  self._api_async.
+000051c0: 6c6f 6164 5f6d 6172 6b65 7473 2872 656c  load_markets(rel
+000051d0: 6f61 643d 7265 6c6f 6164 2c20 7061 7261  oad=reload, para
+000051e0: 6d73 3d7b 7d29 290a 0a20 2020 2020 2020  ms={}))..       
+000051f0: 2065 7863 6570 7420 2861 7379 6e63 696f   except (asyncio
+00005200: 2e54 696d 656f 7574 4572 726f 722c 2063  .TimeoutError, c
+00005210: 6378 742e 4261 7365 4572 726f 7229 2061  cxt.BaseError) a
+00005220: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
+00005230: 206c 6f67 6765 722e 7761 726e 696e 6728   logger.warning(
+00005240: 2243 6f75 6c64 206e 6f74 206c 6f61 6420  "Could not load 
+00005250: 6173 796e 6320 6d61 726b 6574 732e 2052  async markets. R
+00005260: 6561 736f 6e3a 2025 7322 2c20 6529 0a20  eason: %s", e). 
+00005270: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00005280: 6e0a 0a20 2020 2064 6566 205f 6c6f 6164  n..    def _load
+00005290: 5f6d 6172 6b65 7473 2873 656c 6629 202d  _markets(self) -
+000052a0: 3e20 4e6f 6e65 3a0a 2020 2020 2020 2020  > None:.        
+000052b0: 2222 2249 6e69 7469 616c 697a 6520 6d61  """Initialize ma
+000052c0: 726b 6574 7320 626f 7468 2073 796e 6320  rkets both sync 
+000052d0: 616e 6420 6173 796e 6322 2222 0a20 2020  and async""".   
+000052e0: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
+000052f0: 2020 2020 2020 7365 6c66 2e5f 6d61 726b        self._mark
+00005300: 6574 7320 3d20 7365 6c66 2e5f 6170 692e  ets = self._api.
+00005310: 6c6f 6164 5f6d 6172 6b65 7473 2870 6172  load_markets(par
+00005320: 616d 733d 7b7d 290a 2020 2020 2020 2020  ams={}).        
+00005330: 2020 2020 7365 6c66 2e5f 6c6f 6164 5f61      self._load_a
+00005340: 7379 6e63 5f6d 6172 6b65 7473 2829 0a20  sync_markets(). 
+00005350: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00005360: 5f6c 6173 745f 6d61 726b 6574 735f 7265  _last_markets_re
+00005370: 6672 6573 6820 3d20 6474 5f74 7328 290a  fresh = dt_ts().
+00005380: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00005390: 656c 662e 5f66 745f 6861 735b 226e 6565  elf._ft_has["nee
+000053a0: 6473 5f74 7261 6469 6e67 5f66 6565 7322  ds_trading_fees"
+000053b0: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
+000053c0: 2020 2073 656c 662e 5f74 7261 6469 6e67     self._trading
+000053d0: 5f66 6565 7320 3d20 7365 6c66 2e66 6574  _fees = self.fet
+000053e0: 6368 5f74 7261 6469 6e67 5f66 6565 7328  ch_trading_fees(
+000053f0: 290a 0a20 2020 2020 2020 2065 7863 6570  )..        excep
+00005400: 7420 6363 7874 2e42 6173 6545 7272 6f72  t ccxt.BaseError
 00005410: 3a0a 2020 2020 2020 2020 2020 2020 6c6f  :.            lo
-00005420: 6767 6572 2e77 6172 6e69 6e67 2827 436f  gger.warning('Co
-00005430: 756c 6420 6e6f 7420 6c6f 6164 2061 7379  uld not load asy
-00005440: 6e63 206d 6172 6b65 7473 2e20 5265 6173  nc markets. Reas
-00005450: 6f6e 3a20 2573 272c 2065 290a 2020 2020  on: %s', e).    
-00005460: 2020 2020 2020 2020 7265 7475 726e 0a0a          return..
-00005470: 2020 2020 6465 6620 5f6c 6f61 645f 6d61      def _load_ma
-00005480: 726b 6574 7328 7365 6c66 2920 2d3e 204e  rkets(self) -> N
-00005490: 6f6e 653a 0a20 2020 2020 2020 2022 2222  one:.        """
-000054a0: 2049 6e69 7469 616c 697a 6520 6d61 726b   Initialize mark
-000054b0: 6574 7320 626f 7468 2073 796e 6320 616e  ets both sync an
-000054c0: 6420 6173 796e 6320 2222 220a 2020 2020  d async """.    
-000054d0: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-000054e0: 2020 2020 2073 656c 662e 5f6d 6172 6b65       self._marke
-000054f0: 7473 203d 2073 656c 662e 5f61 7069 2e6c  ts = self._api.l
-00005500: 6f61 645f 6d61 726b 6574 7328 7061 7261  oad_markets(para
-00005510: 6d73 3d7b 7d29 0a20 2020 2020 2020 2020  ms={}).         
-00005520: 2020 2073 656c 662e 5f6c 6f61 645f 6173     self._load_as
-00005530: 796e 635f 6d61 726b 6574 7328 290a 2020  ync_markets().  
-00005540: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-00005550: 6c61 7374 5f6d 6172 6b65 7473 5f72 6566  last_markets_ref
-00005560: 7265 7368 203d 2064 745f 7473 2829 0a20  resh = dt_ts(). 
-00005570: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00005580: 6c66 2e5f 6674 5f68 6173 5b27 6e65 6564  lf._ft_has['need
-00005590: 735f 7472 6164 696e 675f 6665 6573 275d  s_trading_fees']
-000055a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000055b0: 2020 7365 6c66 2e5f 7472 6164 696e 675f    self._trading_
-000055c0: 6665 6573 203d 2073 656c 662e 6665 7463  fees = self.fetc
-000055d0: 685f 7472 6164 696e 675f 6665 6573 2829  h_trading_fees()
-000055e0: 0a0a 2020 2020 2020 2020 6578 6365 7074  ..        except
-000055f0: 2063 6378 742e 4261 7365 4572 726f 723a   ccxt.BaseError:
-00005600: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
-00005610: 6765 722e 6578 6365 7074 696f 6e28 2755  ger.exception('U
-00005620: 6e61 626c 6520 746f 2069 6e69 7469 616c  nable to initial
-00005630: 697a 6520 6d61 726b 6574 732e 2729 0a0a  ize markets.')..
-00005640: 2020 2020 6465 6620 7265 6c6f 6164 5f6d      def reload_m
-00005650: 6172 6b65 7473 2873 656c 662c 2066 6f72  arkets(self, for
-00005660: 6365 3a20 626f 6f6c 203d 2046 616c 7365  ce: bool = False
-00005670: 2920 2d3e 204e 6f6e 653a 0a20 2020 2020  ) -> None:.     
-00005680: 2020 2022 2222 5265 6c6f 6164 206d 6172     """Reload mar
-00005690: 6b65 7473 2062 6f74 6820 7379 6e63 2061  kets both sync a
-000056a0: 6e64 2061 7379 6e63 2069 6620 7265 6672  nd async if refr
-000056b0: 6573 6820 696e 7465 7276 616c 2068 6173  esh interval has
-000056c0: 2070 6173 7365 6420 2222 220a 2020 2020   passed """.    
-000056d0: 2020 2020 2320 4368 6563 6b20 7768 6574      # Check whet
-000056e0: 6865 7220 6d61 726b 6574 7320 6861 7665  her markets have
-000056f0: 2074 6f20 6265 2072 656c 6f61 6465 640a   to be reloaded.
-00005700: 2020 2020 2020 2020 6966 2028 0a20 2020          if (.   
-00005710: 2020 2020 2020 2020 206e 6f74 2066 6f72           not for
-00005720: 6365 0a20 2020 2020 2020 2020 2020 2061  ce.            a
-00005730: 6e64 2073 656c 662e 5f6c 6173 745f 6d61  nd self._last_ma
-00005740: 726b 6574 735f 7265 6672 6573 6820 3e20  rkets_refresh > 
-00005750: 300a 2020 2020 2020 2020 2020 2020 616e  0.            an
-00005760: 6420 2873 656c 662e 5f6c 6173 745f 6d61  d (self._last_ma
-00005770: 726b 6574 735f 7265 6672 6573 6820 2b20  rkets_refresh + 
-00005780: 7365 6c66 2e6d 6172 6b65 7473 5f72 6566  self.markets_ref
-00005790: 7265 7368 5f69 6e74 6572 7661 6c20 3e20  resh_interval > 
-000057a0: 6474 5f74 7328 2929 0a20 2020 2020 2020  dt_ts()).       
-000057b0: 2029 3a0a 2020 2020 2020 2020 2020 2020   ):.            
-000057c0: 7265 7475 726e 204e 6f6e 650a 2020 2020  return None.    
-000057d0: 2020 2020 6c6f 6767 6572 2e64 6562 7567      logger.debug
-000057e0: 2822 5065 7266 6f72 6d69 6e67 2073 6368  ("Performing sch
-000057f0: 6564 756c 6564 206d 6172 6b65 7420 7265  eduled market re
-00005800: 6c6f 6164 2e2e 2229 0a20 2020 2020 2020  load..").       
-00005810: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
-00005820: 2020 7365 6c66 2e5f 6d61 726b 6574 7320    self._markets 
-00005830: 3d20 7365 6c66 2e5f 6170 692e 6c6f 6164  = self._api.load
-00005840: 5f6d 6172 6b65 7473 2872 656c 6f61 643d  _markets(reload=
-00005850: 5472 7565 2c20 7061 7261 6d73 3d7b 7d29  True, params={})
-00005860: 0a20 2020 2020 2020 2020 2020 2023 2041  .            # A
-00005870: 6c73 6f20 7265 6c6f 6164 2061 7379 6e63  lso reload async
-00005880: 206d 6172 6b65 7473 2074 6f20 6176 6f69   markets to avoi
-00005890: 6420 6973 7375 6573 2077 6974 6820 6e65  d issues with ne
-000058a0: 776c 7920 6c69 7374 6564 2070 6169 7273  wly listed pairs
-000058b0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-000058c0: 662e 5f6c 6f61 645f 6173 796e 635f 6d61  f._load_async_ma
-000058d0: 726b 6574 7328 7265 6c6f 6164 3d54 7275  rkets(reload=Tru
-000058e0: 6529 0a20 2020 2020 2020 2020 2020 2073  e).            s
-000058f0: 656c 662e 5f6c 6173 745f 6d61 726b 6574  elf._last_market
-00005900: 735f 7265 6672 6573 6820 3d20 6474 5f74  s_refresh = dt_t
-00005910: 7328 290a 2020 2020 2020 2020 2020 2020  s().            
-00005920: 7365 6c66 2e66 696c 6c5f 6c65 7665 7261  self.fill_levera
-00005930: 6765 5f74 6965 7273 2829 0a20 2020 2020  ge_tiers().     
-00005940: 2020 2065 7863 6570 7420 6363 7874 2e42     except ccxt.B
-00005950: 6173 6545 7272 6f72 3a0a 2020 2020 2020  aseError:.      
-00005960: 2020 2020 2020 6c6f 6767 6572 2e65 7863        logger.exc
-00005970: 6570 7469 6f6e 2822 436f 756c 6420 6e6f  eption("Could no
-00005980: 7420 7265 6c6f 6164 206d 6172 6b65 7473  t reload markets
-00005990: 2e22 290a 0a20 2020 2064 6566 2076 616c  .")..    def val
-000059a0: 6964 6174 655f 7374 616b 6563 7572 7265  idate_stakecurre
-000059b0: 6e63 7928 7365 6c66 2c20 7374 616b 655f  ncy(self, stake_
-000059c0: 6375 7272 656e 6379 3a20 7374 7229 202d  currency: str) -
-000059d0: 3e20 4e6f 6e65 3a0a 2020 2020 2020 2020  > None:.        
-000059e0: 2222 220a 2020 2020 2020 2020 4368 6563  """.        Chec
-000059f0: 6b73 2073 7461 6b65 2d63 7572 7265 6e63  ks stake-currenc
-00005a00: 7920 6167 6169 6e73 7420 6176 6169 6c61  y against availa
-00005a10: 626c 6520 6375 7272 656e 6369 6573 206f  ble currencies o
-00005a20: 6e20 7468 6520 6578 6368 616e 6765 2e0a  n the exchange..
-00005a30: 2020 2020 2020 2020 4f6e 6c79 2072 756e          Only run
-00005a40: 7320 6f6e 2073 7461 7274 7570 2e20 4966  s on startup. If
-00005a50: 206d 6172 6b65 7473 2068 6176 6520 6e6f   markets have no
-00005a60: 7420 6265 656e 206c 6f61 6465 642c 2074  t been loaded, t
-00005a70: 6865 7265 2773 2062 6565 6e20 6120 7072  here's been a pr
-00005a80: 6f62 6c65 6d20 7769 7468 0a20 2020 2020  oblem with.     
-00005a90: 2020 2074 6865 2063 6f6e 6e65 6374 696f     the connectio
-00005aa0: 6e20 746f 2074 6865 2065 7863 6861 6e67  n to the exchang
-00005ab0: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
-00005ac0: 6d20 7374 616b 655f 6375 7272 656e 6379  m stake_currency
-00005ad0: 3a20 5374 616b 652d 6375 7272 656e 6379  : Stake-currency
-00005ae0: 2074 6f20 7661 6c69 6461 7465 0a20 2020   to validate.   
-00005af0: 2020 2020 203a 7261 6973 653a 204f 7065       :raise: Ope
-00005b00: 7261 7469 6f6e 616c 4578 6365 7074 696f  rationalExceptio
-00005b10: 6e20 6966 2073 7461 6b65 2d63 7572 7265  n if stake-curre
-00005b20: 6e63 7920 6973 206e 6f74 2061 7661 696c  ncy is not avail
-00005b30: 6162 6c65 2e0a 2020 2020 2020 2020 2222  able..        ""
-00005b40: 220a 2020 2020 2020 2020 6966 206e 6f74  ".        if not
-00005b50: 2073 656c 662e 5f6d 6172 6b65 7473 3a0a   self._markets:.
-00005b60: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00005b70: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
-00005b80: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
-00005b90: 2020 2020 2020 2020 2743 6f75 6c64 206e          'Could n
-00005ba0: 6f74 206c 6f61 6420 6d61 726b 6574 732c  ot load markets,
-00005bb0: 2074 6865 7265 666f 7265 2063 616e 6e6f   therefore canno
-00005bc0: 7420 7374 6172 742e 2027 0a20 2020 2020  t start. '.     
-00005bd0: 2020 2020 2020 2020 2020 2027 506c 6561             'Plea
-00005be0: 7365 2069 6e76 6573 7469 6761 7465 2074  se investigate t
-00005bf0: 6865 2061 626f 7665 2065 7272 6f72 2066  he above error f
-00005c00: 6f72 206d 6f72 6520 6465 7461 696c 732e  or more details.
-00005c10: 270a 2020 2020 2020 2020 2020 2020 290a  '.            ).
-00005c20: 2020 2020 2020 2020 7175 6f74 655f 6375          quote_cu
-00005c30: 7272 656e 6369 6573 203d 2073 656c 662e  rrencies = self.
-00005c40: 6765 745f 7175 6f74 655f 6375 7272 656e  get_quote_curren
-00005c50: 6369 6573 2829 0a20 2020 2020 2020 2069  cies().        i
-00005c60: 6620 7374 616b 655f 6375 7272 656e 6379  f stake_currency
-00005c70: 206e 6f74 2069 6e20 7175 6f74 655f 6375   not in quote_cu
-00005c80: 7272 656e 6369 6573 3a0a 2020 2020 2020  rrencies:.      
-00005c90: 2020 2020 2020 7261 6973 6520 436f 6e66        raise Conf
-00005ca0: 6967 7572 6174 696f 6e45 7272 6f72 280a  igurationError(.
-00005cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005cc0: 6622 7b73 7461 6b65 5f63 7572 7265 6e63  f"{stake_currenc
-00005cd0: 797d 2069 7320 6e6f 7420 6176 6169 6c61  y} is not availa
-00005ce0: 626c 6520 6173 2073 7461 6b65 206f 6e20  ble as stake on 
-00005cf0: 7b73 656c 662e 6e61 6d65 7d2e 2022 0a20  {self.name}. ". 
-00005d00: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00005d10: 2241 7661 696c 6162 6c65 2063 7572 7265  "Available curre
-00005d20: 6e63 6965 7320 6172 653a 207b 272c 2027  ncies are: {', '
-00005d30: 2e6a 6f69 6e28 7175 6f74 655f 6375 7272  .join(quote_curr
-00005d40: 656e 6369 6573 297d 2229 0a0a 2020 2020  encies)}")..    
-00005d50: 6465 6620 7661 6c69 6461 7465 5f70 6169  def validate_pai
-00005d60: 7273 2873 656c 662c 2070 6169 7273 3a20  rs(self, pairs: 
-00005d70: 4c69 7374 5b73 7472 5d29 202d 3e20 4e6f  List[str]) -> No
-00005d80: 6e65 3a0a 2020 2020 2020 2020 2222 220a  ne:.        """.
-00005d90: 2020 2020 2020 2020 4368 6563 6b73 2069          Checks i
-00005da0: 6620 616c 6c20 6769 7665 6e20 7061 6972  f all given pair
-00005db0: 7320 6172 6520 7472 6164 6162 6c65 206f  s are tradable o
-00005dc0: 6e20 7468 6520 6375 7272 656e 7420 6578  n the current ex
-00005dd0: 6368 616e 6765 2e0a 2020 2020 2020 2020  change..        
-00005de0: 3a70 6172 616d 2070 6169 7273 3a20 6c69  :param pairs: li
-00005df0: 7374 206f 6620 7061 6972 730a 2020 2020  st of pairs.    
-00005e00: 2020 2020 3a72 6169 7365 3a20 4f70 6572      :raise: Oper
-00005e10: 6174 696f 6e61 6c45 7863 6570 7469 6f6e  ationalException
-00005e20: 2069 6620 6f6e 6520 7061 6972 2069 7320   if one pair is 
-00005e30: 6e6f 7420 6176 6169 6c61 626c 650a 2020  not available.  
-00005e40: 2020 2020 2020 3a72 6574 7572 6e3a 204e        :return: N
-00005e50: 6f6e 650a 2020 2020 2020 2020 2222 220a  one.        """.
-00005e60: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00005e70: 7365 6c66 2e6d 6172 6b65 7473 3a0a 2020  self.markets:.  
-00005e80: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
-00005e90: 2e77 6172 6e69 6e67 2827 556e 6162 6c65  .warning('Unable
-00005ea0: 2074 6f20 7661 6c69 6461 7465 2070 6169   to validate pai
-00005eb0: 7273 2028 6173 7375 6d69 6e67 2074 6865  rs (assuming the
-00005ec0: 7920 6172 6520 636f 7272 6563 7429 2e27  y are correct).'
-00005ed0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
-00005ee0: 7475 726e 0a20 2020 2020 2020 2065 7874  turn.        ext
-00005ef0: 656e 6465 645f 7061 6972 7320 3d20 6578  ended_pairs = ex
-00005f00: 7061 6e64 5f70 6169 726c 6973 7428 7061  pand_pairlist(pa
-00005f10: 6972 732c 206c 6973 7428 7365 6c66 2e6d  irs, list(self.m
-00005f20: 6172 6b65 7473 292c 206b 6565 705f 696e  arkets), keep_in
-00005f30: 7661 6c69 643d 5472 7565 290a 2020 2020  valid=True).    
-00005f40: 2020 2020 696e 7661 6c69 645f 7061 6972      invalid_pair
-00005f50: 7320 3d20 5b5d 0a20 2020 2020 2020 2066  s = [].        f
-00005f60: 6f72 2070 6169 7220 696e 2065 7874 656e  or pair in exten
-00005f70: 6465 645f 7061 6972 733a 0a20 2020 2020  ded_pairs:.     
-00005f80: 2020 2020 2020 2023 204e 6f74 653a 2063         # Note: c
-00005f90: 6378 7420 6861 7320 4261 7365 4375 7272  cxt has BaseCurr
-00005fa0: 656e 6379 2f51 756f 7465 4375 7272 656e  ency/QuoteCurren
-00005fb0: 6379 2066 6f72 6d61 7420 666f 7220 7061  cy format for pa
-00005fc0: 6972 730a 2020 2020 2020 2020 2020 2020  irs.            
-00005fd0: 6966 2073 656c 662e 6d61 726b 6574 7320  if self.markets 
-00005fe0: 616e 6420 7061 6972 206e 6f74 2069 6e20  and pair not in 
-00005ff0: 7365 6c66 2e6d 6172 6b65 7473 3a0a 2020  self.markets:.  
-00006000: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-00006010: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
-00006020: 7863 6570 7469 6f6e 280a 2020 2020 2020  xception(.      
-00006030: 2020 2020 2020 2020 2020 2020 2020 6627                f'
-00006040: 5061 6972 207b 7061 6972 7d20 6973 206e  Pair {pair} is n
-00006050: 6f74 2061 7661 696c 6162 6c65 206f 6e20  ot available on 
-00006060: 7b73 656c 662e 6e61 6d65 7d20 7b73 656c  {self.name} {sel
-00006070: 662e 7472 6164 696e 675f 6d6f 6465 2e76  f.trading_mode.v
-00006080: 616c 7565 7d2e 2027 0a20 2020 2020 2020  alue}. '.       
-00006090: 2020 2020 2020 2020 2020 2020 2066 2750               f'P
-000060a0: 6c65 6173 6520 7265 6d6f 7665 207b 7061  lease remove {pa
-000060b0: 6972 7d20 6672 6f6d 2079 6f75 7220 7768  ir} from your wh
-000060c0: 6974 656c 6973 742e 2729 0a0a 2020 2020  itelist.')..    
-000060d0: 2020 2020 2020 2020 2020 2020 2320 4672              # Fr
-000060e0: 6f6d 2063 6378 7420 446f 6375 6d65 6e74  om ccxt Document
-000060f0: 6174 696f 6e3a 0a20 2020 2020 2020 2020  ation:.         
-00006100: 2020 2020 2020 2023 206d 6172 6b65 7473         # markets
-00006110: 2e69 6e66 6f3a 2041 6e20 6173 736f 6369  .info: An associ
-00006120: 6174 6976 6520 6172 7261 7920 6f66 206e  ative array of n
-00006130: 6f6e 2d63 6f6d 6d6f 6e20 6d61 726b 6574  on-common market
-00006140: 2070 726f 7065 7274 6965 732c 0a20 2020   properties,.   
-00006150: 2020 2020 2020 2020 2020 2020 2023 2069               # i
-00006160: 6e63 6c75 6469 6e67 2066 6565 732c 2072  ncluding fees, r
-00006170: 6174 6573 2c20 6c69 6d69 7473 2061 6e64  ates, limits and
-00006180: 206f 7468 6572 2067 656e 6572 616c 206d   other general m
-00006190: 6172 6b65 7420 696e 666f 726d 6174 696f  arket informatio
-000061a0: 6e2e 0a20 2020 2020 2020 2020 2020 2020  n..             
-000061b0: 2020 2023 2054 6865 2069 6e74 6572 6e61     # The interna
-000061c0: 6c20 696e 666f 2061 7272 6179 2069 7320  l info array is 
-000061d0: 6469 6666 6572 656e 7420 666f 7220 6561  different for ea
-000061e0: 6368 2070 6172 7469 6375 6c61 7220 6d61  ch particular ma
-000061f0: 726b 6574 2c0a 2020 2020 2020 2020 2020  rket,.          
-00006200: 2020 2020 2020 2320 6974 7320 636f 6e74        # its cont
-00006210: 656e 7473 2064 6570 656e 6420 6f6e 2074  ents depend on t
-00006220: 6865 2065 7863 6861 6e67 652e 0a20 2020  he exchange..   
-00006230: 2020 2020 2020 2020 2020 2020 2023 2049               # I
-00006240: 7420 6361 6e20 616c 736f 2062 6520 6120  t can also be a 
-00006250: 7374 7269 6e67 206f 7220 7369 6d69 6c61  string or simila
-00006260: 7220 2e2e 2e20 736f 2077 6520 6e65 6564  r ... so we need
-00006270: 2074 6f20 7665 7269 6679 2074 6861 7420   to verify that 
-00006280: 6669 7273 742e 0a20 2020 2020 2020 2020  first..         
-00006290: 2020 2065 6c69 6620 2869 7369 6e73 7461     elif (isinsta
-000062a0: 6e63 6528 7365 6c66 2e6d 6172 6b65 7473  nce(self.markets
-000062b0: 5b70 6169 725d 2e67 6574 2827 696e 666f  [pair].get('info
-000062c0: 2729 2c20 6469 6374 290a 2020 2020 2020  '), dict).      
-000062d0: 2020 2020 2020 2020 2020 2020 616e 6420              and 
-000062e0: 7365 6c66 2e6d 6172 6b65 7473 5b70 6169  self.markets[pai
-000062f0: 725d 2e67 6574 2827 696e 666f 272c 207b  r].get('info', {
-00006300: 7d29 2e67 6574 2827 7072 6f68 6962 6974  }).get('prohibit
-00006310: 6564 496e 272c 2046 616c 7365 2929 3a0a  edIn', False)):.
-00006320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006330: 2320 5761 726e 2075 7365 7273 2061 626f  # Warn users abo
-00006340: 7574 2072 6573 7472 6963 7465 6420 7061  ut restricted pa
-00006350: 6972 7320 696e 2077 6869 7465 6c69 7374  irs in whitelist
-00006360: 2e0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00006370: 2020 2320 5765 2063 616e 6e6f 7420 6465    # We cannot de
-00006380: 7465 726d 696e 6520 7265 6c69 6162 6c79  termine reliably
-00006390: 2069 6620 5573 6572 7320 6172 6520 6166   if Users are af
-000063a0: 6665 6374 6564 2e0a 2020 2020 2020 2020  fected..        
-000063b0: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
-000063c0: 6172 6e69 6e67 2866 2250 6169 7220 7b70  arning(f"Pair {p
-000063d0: 6169 727d 2069 7320 7265 7374 7269 6374  air} is restrict
-000063e0: 6564 2066 6f72 2073 6f6d 6520 7573 6572  ed for some user
-000063f0: 7320 6f6e 2074 6869 7320 6578 6368 616e  s on this exchan
-00006400: 6765 2e22 0a20 2020 2020 2020 2020 2020  ge.".           
-00006410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006420: 2020 2020 6622 506c 6561 7365 2063 6865      f"Please che
-00006430: 636b 2069 6620 796f 7520 6172 6520 696d  ck if you are im
-00006440: 7061 6374 6564 2062 7920 7468 6973 2072  pacted by this r
-00006450: 6573 7472 6963 7469 6f6e 2022 0a20 2020  estriction ".   
-00006460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006470: 2020 2020 2020 2020 2020 2020 6622 6f6e              f"on
-00006480: 2074 6865 2065 7863 6861 6e67 6520 616e   the exchange an
-00006490: 6420 6576 656e 7475 616c 6c79 2072 656d  d eventually rem
-000064a0: 6f76 6520 7b70 6169 727d 2066 726f 6d20  ove {pair} from 
-000064b0: 796f 7572 2077 6869 7465 6c69 7374 2e22  your whitelist."
-000064c0: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-000064d0: 2028 7365 6c66 2e5f 636f 6e66 6967 5b27   (self._config['
-000064e0: 7374 616b 655f 6375 7272 656e 6379 275d  stake_currency']
-000064f0: 2061 6e64 0a20 2020 2020 2020 2020 2020   and.           
-00006500: 2020 2020 2020 2020 2073 656c 662e 6765           self.ge
-00006510: 745f 7061 6972 5f71 756f 7465 5f63 7572  t_pair_quote_cur
-00006520: 7265 6e63 7928 7061 6972 2920 213d 2073  rency(pair) != s
-00006530: 656c 662e 5f63 6f6e 6669 675b 2773 7461  elf._config['sta
-00006540: 6b65 5f63 7572 7265 6e63 7927 5d29 3a0a  ke_currency']):.
-00006550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006560: 696e 7661 6c69 645f 7061 6972 732e 6170  invalid_pairs.ap
-00006570: 7065 6e64 2870 6169 7229 0a20 2020 2020  pend(pair).     
-00006580: 2020 2069 6620 696e 7661 6c69 645f 7061     if invalid_pa
-00006590: 6972 733a 0a20 2020 2020 2020 2020 2020  irs:.           
-000065a0: 2072 6169 7365 204f 7065 7261 7469 6f6e   raise Operation
-000065b0: 616c 4578 6365 7074 696f 6e28 0a20 2020  alException(.   
-000065c0: 2020 2020 2020 2020 2020 2020 2066 2253               f"S
-000065d0: 7461 6b65 2d63 7572 7265 6e63 7920 277b  take-currency '{
-000065e0: 7365 6c66 2e5f 636f 6e66 6967 5b27 7374  self._config['st
-000065f0: 616b 655f 6375 7272 656e 6379 275d 7d27  ake_currency']}'
-00006600: 206e 6f74 2063 6f6d 7061 7469 626c 6520   not compatible 
-00006610: 7769 7468 2022 0a20 2020 2020 2020 2020  with ".         
-00006620: 2020 2020 2020 2066 2270 6169 722d 7768         f"pair-wh
-00006630: 6974 656c 6973 742e 2050 6c65 6173 6520  itelist. Please 
-00006640: 7265 6d6f 7665 2074 6865 2066 6f6c 6c6f  remove the follo
-00006650: 7769 6e67 2070 6169 7273 3a20 7b69 6e76  wing pairs: {inv
-00006660: 616c 6964 5f70 6169 7273 7d22 290a 0a20  alid_pairs}").. 
-00006670: 2020 2064 6566 2067 6574 5f76 616c 6964     def get_valid
-00006680: 5f70 6169 725f 636f 6d62 696e 6174 696f  _pair_combinatio
-00006690: 6e28 7365 6c66 2c20 6375 7272 5f31 3a20  n(self, curr_1: 
-000066a0: 7374 722c 2063 7572 725f 323a 2073 7472  str, curr_2: str
-000066b0: 2920 2d3e 2073 7472 3a0a 2020 2020 2020  ) -> str:.      
-000066c0: 2020 2222 220a 2020 2020 2020 2020 4765    """.        Ge
-000066d0: 7420 7661 6c69 6420 7061 6972 2063 6f6d  t valid pair com
-000066e0: 6269 6e61 7469 6f6e 206f 6620 6375 7272  bination of curr
-000066f0: 5f31 2061 6e64 2063 7572 725f 3220 6279  _1 and curr_2 by
-00006700: 2074 7279 696e 6720 626f 7468 2063 6f6d   trying both com
-00006710: 6269 6e61 7469 6f6e 732e 0a20 2020 2020  binations..     
-00006720: 2020 2022 2222 0a20 2020 2020 2020 2066     """.        f
-00006730: 6f72 2070 6169 7220 696e 205b 6622 7b63  or pair in [f"{c
-00006740: 7572 725f 317d 2f7b 6375 7272 5f32 7d22  urr_1}/{curr_2}"
-00006750: 2c20 6622 7b63 7572 725f 327d 2f7b 6375  , f"{curr_2}/{cu
-00006760: 7272 5f31 7d22 5d3a 0a20 2020 2020 2020  rr_1}"]:.       
-00006770: 2020 2020 2069 6620 7061 6972 2069 6e20       if pair in 
-00006780: 7365 6c66 2e6d 6172 6b65 7473 2061 6e64  self.markets and
-00006790: 2073 656c 662e 6d61 726b 6574 735b 7061   self.markets[pa
-000067a0: 6972 5d2e 6765 7428 2761 6374 6976 6527  ir].get('active'
-000067b0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-000067c0: 2020 2072 6574 7572 6e20 7061 6972 0a20     return pair. 
-000067d0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-000067e0: 7565 4572 726f 7228 6622 436f 756c 6420  ueError(f"Could 
-000067f0: 6e6f 7420 636f 6d62 696e 6520 7b63 7572  not combine {cur
-00006800: 725f 317d 2061 6e64 207b 6375 7272 5f32  r_1} and {curr_2
-00006810: 7d20 746f 2067 6574 2061 2076 616c 6964  } to get a valid
-00006820: 2070 6169 722e 2229 0a0a 2020 2020 6465   pair.")..    de
-00006830: 6620 7661 6c69 6461 7465 5f74 696d 6566  f validate_timef
-00006840: 7261 6d65 7328 7365 6c66 2c20 7469 6d65  rames(self, time
-00006850: 6672 616d 653a 204f 7074 696f 6e61 6c5b  frame: Optional[
-00006860: 7374 725d 2920 2d3e 204e 6f6e 653a 0a20  str]) -> None:. 
-00006870: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-00006880: 2020 2043 6865 636b 2069 6620 7469 6d65     Check if time
-00006890: 6672 616d 6520 6672 6f6d 2063 6f6e 6669  frame from confi
-000068a0: 6720 6973 2061 2073 7570 706f 7274 6564  g is a supported
-000068b0: 2074 696d 6566 7261 6d65 206f 6e20 7468   timeframe on th
-000068c0: 6520 6578 6368 616e 6765 0a20 2020 2020  e exchange.     
-000068d0: 2020 2022 2222 0a20 2020 2020 2020 2069     """.        i
-000068e0: 6620 6e6f 7420 6861 7361 7474 7228 7365  f not hasattr(se
-000068f0: 6c66 2e5f 6170 692c 2022 7469 6d65 6672  lf._api, "timefr
-00006900: 616d 6573 2229 206f 7220 7365 6c66 2e5f  ames") or self._
-00006910: 6170 692e 7469 6d65 6672 616d 6573 2069  api.timeframes i
-00006920: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-00006930: 2020 2020 2320 4966 2074 696d 6566 7261      # If timefra
-00006940: 6d65 7320 6174 7472 6962 7574 6520 6973  mes attribute is
-00006950: 206d 6973 7369 6e67 2028 6f72 2069 7320   missing (or is 
-00006960: 4e6f 6e65 292c 2074 6865 2065 7863 6861  None), the excha
-00006970: 6e67 6520 7072 6f62 6162 6c79 0a20 2020  nge probably.   
-00006980: 2020 2020 2020 2020 2023 2068 6173 206e           # has n
-00006990: 6f20 6665 7463 684f 484c 4356 206d 6574  o fetchOHLCV met
-000069a0: 686f 642e 0a20 2020 2020 2020 2020 2020  hod..           
-000069b0: 2023 2054 6865 7265 666f 7265 2077 6520   # Therefore we 
-000069c0: 616c 736f 2073 686f 7720 7468 6174 2e0a  also show that..
-000069d0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-000069e0: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
-000069f0: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
-00006a00: 2020 2020 2020 2020 6622 5468 6520 6363          f"The cc
-00006a10: 7874 206c 6962 7261 7279 2064 6f65 7320  xt library does 
-00006a20: 6e6f 7420 7072 6f76 6964 6520 7468 6520  not provide the 
-00006a30: 6c69 7374 206f 6620 7469 6d65 6672 616d  list of timefram
-00006a40: 6573 2022 0a20 2020 2020 2020 2020 2020  es ".           
-00006a50: 2020 2020 2066 2266 6f72 2074 6865 2065       f"for the e
-00006a60: 7863 6861 6e67 6520 7b73 656c 662e 6e61  xchange {self.na
-00006a70: 6d65 7d20 616e 6420 7468 6973 2065 7863  me} and this exc
-00006a80: 6861 6e67 6520 220a 2020 2020 2020 2020  hange ".        
-00006a90: 2020 2020 2020 2020 6622 6973 2074 6865          f"is the
-00006aa0: 7265 666f 7265 206e 6f74 2073 7570 706f  refore not suppo
-00006ab0: 7274 6564 2e20 6363 7874 2066 6574 6368  rted. ccxt fetch
-00006ac0: 4f48 4c43 563a 207b 7365 6c66 2e65 7863  OHLCV: {self.exc
-00006ad0: 6861 6e67 655f 6861 7328 2766 6574 6368  hange_has('fetch
-00006ae0: 4f48 4c43 5627 297d 2229 0a0a 2020 2020  OHLCV')}")..    
-00006af0: 2020 2020 6966 2074 696d 6566 7261 6d65      if timeframe
-00006b00: 2061 6e64 2028 7469 6d65 6672 616d 6520   and (timeframe 
-00006b10: 6e6f 7420 696e 2073 656c 662e 7469 6d65  not in self.time
-00006b20: 6672 616d 6573 293a 0a20 2020 2020 2020  frames):.       
-00006b30: 2020 2020 2072 6169 7365 2043 6f6e 6669       raise Confi
-00006b40: 6775 7261 7469 6f6e 4572 726f 7228 0a20  gurationError(. 
-00006b50: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00006b60: 2249 6e76 616c 6964 2074 696d 6566 7261  "Invalid timefra
-00006b70: 6d65 2027 7b74 696d 6566 7261 6d65 7d27  me '{timeframe}'
-00006b80: 2e20 5468 6973 2065 7863 6861 6e67 6520  . This exchange 
-00006b90: 7375 7070 6f72 7473 3a20 7b73 656c 662e  supports: {self.
-00006ba0: 7469 6d65 6672 616d 6573 7d22 290a 0a20  timeframes}").. 
-00006bb0: 2020 2020 2020 2069 6620 280a 2020 2020         if (.    
-00006bc0: 2020 2020 2020 2020 7469 6d65 6672 616d          timefram
-00006bd0: 650a 2020 2020 2020 2020 2020 2020 616e  e.            an
-00006be0: 6420 7365 6c66 2e5f 636f 6e66 6967 5b27  d self._config['
-00006bf0: 7275 6e6d 6f64 6527 5d20 213d 2052 756e  runmode'] != Run
-00006c00: 4d6f 6465 2e55 5449 4c5f 4558 4348 414e  Mode.UTIL_EXCHAN
-00006c10: 4745 0a20 2020 2020 2020 2020 2020 2061  GE.            a
-00006c20: 6e64 2074 696d 6566 7261 6d65 5f74 6f5f  nd timeframe_to_
-00006c30: 6d69 6e75 7465 7328 7469 6d65 6672 616d  minutes(timefram
-00006c40: 6529 203c 2031 0a20 2020 2020 2020 2029  e) < 1.        )
-00006c50: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-00006c60: 6973 6520 436f 6e66 6967 7572 6174 696f  ise Configuratio
-00006c70: 6e45 7272 6f72 2822 5469 6d65 6672 616d  nError("Timefram
-00006c80: 6573 203c 2031 6d20 6172 6520 6375 7272  es < 1m are curr
-00006c90: 656e 746c 7920 6e6f 7420 7375 7070 6f72  ently not suppor
-00006ca0: 7465 6420 6279 2046 7265 7174 7261 6465  ted by Freqtrade
-00006cb0: 2e22 290a 0a20 2020 2064 6566 2076 616c  .")..    def val
-00006cc0: 6964 6174 655f 6f72 6465 7274 7970 6573  idate_ordertypes
-00006cd0: 2873 656c 662c 206f 7264 6572 5f74 7970  (self, order_typ
-00006ce0: 6573 3a20 4469 6374 2920 2d3e 204e 6f6e  es: Dict) -> Non
-00006cf0: 653a 0a20 2020 2020 2020 2022 2222 0a20  e:.        """. 
-00006d00: 2020 2020 2020 2043 6865 636b 7320 6966         Checks if
-00006d10: 206f 7264 6572 2d74 7970 6573 2063 6f6e   order-types con
-00006d20: 6669 6775 7265 6420 696e 2073 7472 6174  figured in strat
-00006d30: 6567 792f 636f 6e66 6967 2061 7265 2073  egy/config are s
-00006d40: 7570 706f 7274 6564 0a20 2020 2020 2020  upported.       
-00006d50: 2022 2222 0a20 2020 2020 2020 2069 6620   """.        if 
-00006d60: 616e 7928 7620 3d3d 2027 6d61 726b 6574  any(v == 'market
-00006d70: 2720 666f 7220 6b2c 2076 2069 6e20 6f72  ' for k, v in or
-00006d80: 6465 725f 7479 7065 732e 6974 656d 7328  der_types.items(
-00006d90: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
-00006da0: 6966 206e 6f74 2073 656c 662e 6578 6368  if not self.exch
-00006db0: 616e 6765 5f68 6173 2827 6372 6561 7465  ange_has('create
-00006dc0: 4d61 726b 6574 4f72 6465 7227 293a 0a20  MarketOrder'):. 
-00006dd0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00006de0: 6169 7365 2043 6f6e 6669 6775 7261 7469  aise Configurati
-00006df0: 6f6e 4572 726f 7228 0a20 2020 2020 2020  onError(.       
-00006e00: 2020 2020 2020 2020 2020 2020 2066 2745               f'E
-00006e10: 7863 6861 6e67 6520 7b73 656c 662e 6e61  xchange {self.na
-00006e20: 6d65 7d20 646f 6573 206e 6f74 2073 7570  me} does not sup
-00006e30: 706f 7274 206d 6172 6b65 7420 6f72 6465  port market orde
-00006e40: 7273 2e27 290a 2020 2020 2020 2020 7365  rs.').        se
-00006e50: 6c66 2e76 616c 6964 6174 655f 7374 6f70  lf.validate_stop
-00006e60: 5f6f 7264 6572 7479 7065 7328 6f72 6465  _ordertypes(orde
-00006e70: 725f 7479 7065 7329 0a0a 2020 2020 6465  r_types)..    de
-00006e80: 6620 7661 6c69 6461 7465 5f73 746f 705f  f validate_stop_
-00006e90: 6f72 6465 7274 7970 6573 2873 656c 662c  ordertypes(self,
-00006ea0: 206f 7264 6572 5f74 7970 6573 3a20 4469   order_types: Di
-00006eb0: 6374 2920 2d3e 204e 6f6e 653a 0a20 2020  ct) -> None:.   
-00006ec0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00006ed0: 2056 616c 6964 6174 6520 7374 6f70 6c6f   Validate stoplo
-00006ee0: 7373 206f 7264 6572 2074 7970 6573 0a20  ss order types. 
-00006ef0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-00006f00: 2020 2069 6620 286f 7264 6572 5f74 7970     if (order_typ
-00006f10: 6573 2e67 6574 2822 7374 6f70 6c6f 7373  es.get("stoploss
-00006f20: 5f6f 6e5f 6578 6368 616e 6765 2229 0a20  _on_exchange"). 
-00006f30: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-00006f40: 6e64 206e 6f74 2073 656c 662e 5f66 745f  nd not self._ft_
-00006f50: 6861 732e 6765 7428 2273 746f 706c 6f73  has.get("stoplos
-00006f60: 735f 6f6e 5f65 7863 6861 6e67 6522 2c20  s_on_exchange", 
-00006f70: 4661 6c73 6529 293a 0a20 2020 2020 2020  False)):.       
-00006f80: 2020 2020 2072 6169 7365 2043 6f6e 6669       raise Confi
-00006f90: 6775 7261 7469 6f6e 4572 726f 7228 0a20  gurationError(. 
-00006fa0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00006fb0: 274f 6e20 6578 6368 616e 6765 2073 746f  'On exchange sto
-00006fc0: 706c 6f73 7320 6973 206e 6f74 2073 7570  ploss is not sup
-00006fd0: 706f 7274 6564 2066 6f72 207b 7365 6c66  ported for {self
-00006fe0: 2e6e 616d 657d 2e27 0a20 2020 2020 2020  .name}.'.       
-00006ff0: 2020 2020 2029 0a20 2020 2020 2020 2069       ).        i
-00007000: 6620 7365 6c66 2e74 7261 6469 6e67 5f6d  f self.trading_m
-00007010: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
-00007020: 6465 2e46 5554 5552 4553 3a0a 2020 2020  de.FUTURES:.    
-00007030: 2020 2020 2020 2020 7072 6963 655f 6d61          price_ma
-00007040: 7070 696e 6720 3d20 7365 6c66 2e5f 6674  pping = self._ft
-00007050: 5f68 6173 2e67 6574 2827 7374 6f70 5f70  _has.get('stop_p
-00007060: 7269 6365 5f74 7970 655f 7661 6c75 655f  rice_type_value_
-00007070: 6d61 7070 696e 6727 2c20 7b7d 292e 6b65  mapping', {}).ke
-00007080: 7973 2829 0a20 2020 2020 2020 2020 2020  ys().           
-00007090: 2069 6620 280a 2020 2020 2020 2020 2020   if (.          
-000070a0: 2020 2020 2020 6f72 6465 725f 7479 7065        order_type
-000070b0: 732e 6765 7428 2273 746f 706c 6f73 735f  s.get("stoploss_
-000070c0: 6f6e 5f65 7863 6861 6e67 6522 2c20 4661  on_exchange", Fa
-000070d0: 6c73 6529 2069 7320 5472 7565 0a20 2020  lse) is True.   
-000070e0: 2020 2020 2020 2020 2020 2020 2061 6e64               and
-000070f0: 2027 7374 6f70 6c6f 7373 5f70 7269 6365   'stoploss_price
-00007100: 5f74 7970 6527 2069 6e20 6f72 6465 725f  _type' in order_
-00007110: 7479 7065 730a 2020 2020 2020 2020 2020  types.          
-00007120: 2020 2020 2020 616e 6420 6f72 6465 725f        and order_
-00007130: 7479 7065 735b 2773 746f 706c 6f73 735f  types['stoploss_
-00007140: 7072 6963 655f 7479 7065 275d 206e 6f74  price_type'] not
-00007150: 2069 6e20 7072 6963 655f 6d61 7070 696e   in price_mappin
-00007160: 670a 2020 2020 2020 2020 2020 2020 293a  g.            ):
-00007170: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007180: 2072 6169 7365 2043 6f6e 6669 6775 7261   raise Configura
-00007190: 7469 6f6e 4572 726f 7228 0a20 2020 2020  tionError(.     
-000071a0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-000071b0: 274f 6e20 6578 6368 616e 6765 2073 746f  'On exchange sto
-000071c0: 706c 6f73 7320 7072 6963 6520 7479 7065  ploss price type
-000071d0: 2069 7320 6e6f 7420 7375 7070 6f72 7465   is not supporte
-000071e0: 6420 666f 7220 7b73 656c 662e 6e61 6d65  d for {self.name
-000071f0: 7d2e 270a 2020 2020 2020 2020 2020 2020  }.'.            
-00007200: 2020 2020 290a 0a20 2020 2064 6566 2076      )..    def v
-00007210: 616c 6964 6174 655f 7072 6963 696e 6728  alidate_pricing(
-00007220: 7365 6c66 2c20 7072 6963 696e 673a 2044  self, pricing: D
-00007230: 6963 7429 202d 3e20 4e6f 6e65 3a0a 2020  ict) -> None:.  
-00007240: 2020 2020 2020 6966 2070 7269 6369 6e67        if pricing
-00007250: 2e67 6574 2827 7573 655f 6f72 6465 725f  .get('use_order_
-00007260: 626f 6f6b 272c 2046 616c 7365 2920 616e  book', False) an
-00007270: 6420 6e6f 7420 7365 6c66 2e65 7863 6861  d not self.excha
-00007280: 6e67 655f 6861 7328 2766 6574 6368 4c32  nge_has('fetchL2
-00007290: 4f72 6465 7242 6f6f 6b27 293a 0a20 2020  OrderBook'):.   
-000072a0: 2020 2020 2020 2020 2072 6169 7365 2043           raise C
-000072b0: 6f6e 6669 6775 7261 7469 6f6e 4572 726f  onfigurationErro
-000072c0: 7228 6627 4f72 6465 7262 6f6f 6b20 6e6f  r(f'Orderbook no
-000072d0: 7420 6176 6169 6c61 626c 6520 666f 7220  t available for 
-000072e0: 7b73 656c 662e 6e61 6d65 7d2e 2729 0a20  {self.name}.'). 
-000072f0: 2020 2020 2020 2069 6620 286e 6f74 2070         if (not p
-00007300: 7269 6369 6e67 2e67 6574 2827 7573 655f  ricing.get('use_
-00007310: 6f72 6465 725f 626f 6f6b 272c 2046 616c  order_book', Fal
-00007320: 7365 2920 616e 6420 280a 2020 2020 2020  se) and (.      
-00007330: 2020 2020 2020 2020 2020 6e6f 7420 7365            not se
-00007340: 6c66 2e65 7863 6861 6e67 655f 6861 7328  lf.exchange_has(
-00007350: 2766 6574 6368 5469 636b 6572 2729 0a20  'fetchTicker'). 
-00007360: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00007370: 7220 6e6f 7420 7365 6c66 2e5f 6674 5f68  r not self._ft_h
-00007380: 6173 5b27 7469 636b 6572 735f 6861 7665  as['tickers_have
-00007390: 5f70 7269 6365 275d 2929 3a0a 2020 2020  _price'])):.    
-000073a0: 2020 2020 2020 2020 7261 6973 6520 436f          raise Co
-000073b0: 6e66 6967 7572 6174 696f 6e45 7272 6f72  nfigurationError
-000073c0: 2866 2754 6963 6b65 7220 7072 6963 696e  (f'Ticker pricin
-000073d0: 6720 6e6f 7420 6176 6169 6c61 626c 6520  g not available 
-000073e0: 666f 7220 7b73 656c 662e 6e61 6d65 7d2e  for {self.name}.
-000073f0: 2729 0a0a 2020 2020 6465 6620 7661 6c69  ')..    def vali
-00007400: 6461 7465 5f6f 7264 6572 5f74 696d 655f  date_order_time_
-00007410: 696e 5f66 6f72 6365 2873 656c 662c 206f  in_force(self, o
-00007420: 7264 6572 5f74 696d 655f 696e 5f66 6f72  rder_time_in_for
-00007430: 6365 3a20 4469 6374 2920 2d3e 204e 6f6e  ce: Dict) -> Non
-00007440: 653a 0a20 2020 2020 2020 2022 2222 0a20  e:.        """. 
-00007450: 2020 2020 2020 2043 6865 636b 7320 6966         Checks if
-00007460: 206f 7264 6572 2074 696d 6520 696e 2066   order time in f
-00007470: 6f72 6365 2063 6f6e 6669 6775 7265 6420  orce configured 
-00007480: 696e 2073 7472 6174 6567 792f 636f 6e66  in strategy/conf
-00007490: 6967 2061 7265 2073 7570 706f 7274 6564  ig are supported
-000074a0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-000074b0: 2020 2020 2069 6620 616e 7928 762e 7570       if any(v.up
-000074c0: 7065 7228 2920 6e6f 7420 696e 2073 656c  per() not in sel
-000074d0: 662e 5f66 745f 6861 735b 226f 7264 6572  f._ft_has["order
-000074e0: 5f74 696d 655f 696e 5f66 6f72 6365 225d  _time_in_force"]
-000074f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007500: 666f 7220 6b2c 2076 2069 6e20 6f72 6465  for k, v in orde
-00007510: 725f 7469 6d65 5f69 6e5f 666f 7263 652e  r_time_in_force.
-00007520: 6974 656d 7328 2929 3a0a 2020 2020 2020  items()):.      
-00007530: 2020 2020 2020 7261 6973 6520 436f 6e66        raise Conf
-00007540: 6967 7572 6174 696f 6e45 7272 6f72 280a  igurationError(.
-00007550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007560: 6627 5469 6d65 2069 6e20 666f 7263 6520  f'Time in force 
-00007570: 706f 6c69 6369 6573 2061 7265 206e 6f74  policies are not
-00007580: 2073 7570 706f 7274 6564 2066 6f72 207b   supported for {
-00007590: 7365 6c66 2e6e 616d 657d 2079 6574 2e27  self.name} yet.'
-000075a0: 290a 0a20 2020 2064 6566 2076 616c 6964  )..    def valid
-000075b0: 6174 655f 7265 7175 6972 6564 5f73 7461  ate_required_sta
-000075c0: 7274 7570 5f63 616e 646c 6573 2873 656c  rtup_candles(sel
-000075d0: 662c 2073 7461 7274 7570 5f63 616e 646c  f, startup_candl
-000075e0: 6573 3a20 696e 742c 2074 696d 6566 7261  es: int, timefra
-000075f0: 6d65 3a20 7374 7229 202d 3e20 696e 743a  me: str) -> int:
-00007600: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00007610: 2020 2020 2043 6865 636b 7320 6966 2072       Checks if r
-00007620: 6571 7569 7265 6420 7374 6172 7475 705f  equired startup_
-00007630: 6361 6e64 6c65 7320 6973 206d 6f72 6520  candles is more 
-00007640: 7468 616e 206f 686c 6376 5f63 616e 646c  than ohlcv_candl
-00007650: 655f 6c69 6d69 7428 292e 0a20 2020 2020  e_limit()..     
-00007660: 2020 2052 6571 7569 7265 7320 6120 6772     Requires a gr
-00007670: 6163 652d 7065 7269 6f64 206f 6620 3520  ace-period of 5 
-00007680: 6361 6e64 6c65 7320 2d20 736f 2061 2073  candles - so a s
-00007690: 7461 7274 7570 2d70 6572 696f 6420 7570  tartup-period up
-000076a0: 2074 6f20 3439 3420 6973 2061 6c6c 6f77   to 494 is allow
-000076b0: 6564 2062 7920 6465 6661 756c 742e 0a20  ed by default.. 
-000076c0: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-000076d0: 2020 2020 6361 6e64 6c65 5f6c 696d 6974      candle_limit
-000076e0: 203d 2073 656c 662e 6f68 6c63 765f 6361   = self.ohlcv_ca
-000076f0: 6e64 6c65 5f6c 696d 6974 280a 2020 2020  ndle_limit(.    
-00007700: 2020 2020 2020 2020 7469 6d65 6672 616d          timefram
-00007710: 652c 2073 656c 662e 5f63 6f6e 6669 675b  e, self._config[
-00007720: 2763 616e 646c 655f 7479 7065 5f64 6566  'candle_type_def
-00007730: 275d 2c0a 2020 2020 2020 2020 2020 2020  '],.            
-00007740: 6474 5f74 7328 6461 7465 5f6d 696e 7573  dt_ts(date_minus
-00007750: 5f63 616e 646c 6573 2874 696d 6566 7261  _candles(timefra
-00007760: 6d65 2c20 7374 6172 7475 705f 6361 6e64  me, startup_cand
-00007770: 6c65 7329 290a 2020 2020 2020 2020 2020  les)).          
-00007780: 2020 6966 2074 696d 6566 7261 6d65 2065    if timeframe e
-00007790: 6c73 6520 4e6f 6e65 290a 2020 2020 2020  lse None).      
-000077a0: 2020 2320 5265 7175 6972 6520 6f6e 6520    # Require one 
-000077b0: 6d6f 7265 2063 616e 646c 6520 2d20 746f  more candle - to
-000077c0: 2061 6363 6f75 6e74 2066 6f72 2074 6865   account for the
-000077d0: 2073 7469 6c6c 206f 7065 6e20 6361 6e64   still open cand
-000077e0: 6c65 2e0a 2020 2020 2020 2020 6361 6e64  le..        cand
-000077f0: 6c65 5f63 6f75 6e74 203d 2073 7461 7274  le_count = start
-00007800: 7570 5f63 616e 646c 6573 202b 2031 0a20  up_candles + 1. 
-00007810: 2020 2020 2020 2023 2041 6c6c 6f77 2035         # Allow 5
-00007820: 2063 616c 6c73 2074 6f20 7468 6520 6578   calls to the ex
-00007830: 6368 616e 6765 2070 6572 2070 6169 720a  change per pair.
-00007840: 2020 2020 2020 2020 7265 7175 6972 6564          required
-00007850: 5f63 616e 646c 655f 6361 6c6c 5f63 6f75  _candle_call_cou
-00007860: 6e74 203d 2069 6e74 280a 2020 2020 2020  nt = int(.      
-00007870: 2020 2020 2020 2863 616e 646c 655f 636f        (candle_co
-00007880: 756e 7420 2f20 6361 6e64 6c65 5f6c 696d  unt / candle_lim
-00007890: 6974 2920 2b20 2830 2069 6620 6361 6e64  it) + (0 if cand
-000078a0: 6c65 5f63 6f75 6e74 2025 2063 616e 646c  le_count % candl
-000078b0: 655f 6c69 6d69 7420 3d3d 2030 2065 6c73  e_limit == 0 els
-000078c0: 6520 3129 290a 2020 2020 2020 2020 6966  e 1)).        if
-000078d0: 2073 656c 662e 5f66 745f 6861 735b 276f   self._ft_has['o
-000078e0: 686c 6376 5f68 6173 5f68 6973 746f 7279  hlcv_has_history
-000078f0: 275d 3a0a 0a20 2020 2020 2020 2020 2020  ']:..           
-00007900: 2069 6620 7265 7175 6972 6564 5f63 616e   if required_can
-00007910: 646c 655f 6361 6c6c 5f63 6f75 6e74 203e  dle_call_count >
-00007920: 2035 3a0a 2020 2020 2020 2020 2020 2020   5:.            
-00007930: 2020 2020 2320 4f6e 6c79 2061 6c6c 6f77      # Only allow
-00007940: 2035 2063 616c 6c73 2070 6572 2070 6169   5 calls per pai
-00007950: 7220 746f 2073 6f6d 6577 6861 7420 6c69  r to somewhat li
-00007960: 6d69 7420 7468 6520 696d 7061 6374 0a20  mit the impact. 
-00007970: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00007980: 6169 7365 2043 6f6e 6669 6775 7261 7469  aise Configurati
-00007990: 6f6e 4572 726f 7228 0a20 2020 2020 2020  onError(.       
-000079a0: 2020 2020 2020 2020 2020 2020 2066 2254               f"T
-000079b0: 6869 7320 7374 7261 7465 6779 2072 6571  his strategy req
-000079c0: 7569 7265 7320 7b73 7461 7274 7570 5f63  uires {startup_c
-000079d0: 616e 646c 6573 7d20 6361 6e64 6c65 7320  andles} candles 
-000079e0: 746f 2073 7461 7274 2c20 220a 2020 2020  to start, ".    
-000079f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007a00: 2277 6869 6368 2069 7320 6d6f 7265 2074  "which is more t
-00007a10: 6861 6e20 3578 2022 0a20 2020 2020 2020  han 5x ".       
-00007a20: 2020 2020 2020 2020 2020 2020 2066 2274               f"t
-00007a30: 6865 2061 6d6f 756e 7420 6f66 2063 616e  he amount of can
-00007a40: 646c 6573 207b 7365 6c66 2e6e 616d 657d  dles {self.name}
-00007a50: 2070 726f 7669 6465 7320 666f 7220 7b74   provides for {t
-00007a60: 696d 6566 7261 6d65 7d2e 2229 0a20 2020  imeframe}.").   
-00007a70: 2020 2020 2065 6c69 6620 7265 7175 6972       elif requir
-00007a80: 6564 5f63 616e 646c 655f 6361 6c6c 5f63  ed_candle_call_c
-00007a90: 6f75 6e74 203e 2031 3a0a 2020 2020 2020  ount > 1:.      
-00007aa0: 2020 2020 2020 7261 6973 6520 436f 6e66        raise Conf
-00007ab0: 6967 7572 6174 696f 6e45 7272 6f72 280a  igurationError(.
-00007ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ad0: 6622 5468 6973 2073 7472 6174 6567 7920  f"This strategy 
-00007ae0: 7265 7175 6972 6573 207b 7374 6172 7475  requires {startu
-00007af0: 705f 6361 6e64 6c65 737d 2063 616e 646c  p_candles} candl
-00007b00: 6573 2074 6f20 7374 6172 742c 2077 6869  es to start, whi
-00007b10: 6368 2069 7320 6d6f 7265 2074 6861 6e20  ch is more than 
-00007b20: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00007b30: 2020 6622 7468 6520 616d 6f75 6e74 206f    f"the amount o
-00007b40: 6620 6361 6e64 6c65 7320 7b73 656c 662e  f candles {self.
-00007b50: 6e61 6d65 7d20 7072 6f76 6964 6573 2066  name} provides f
-00007b60: 6f72 207b 7469 6d65 6672 616d 657d 2e22  or {timeframe}."
-00007b70: 290a 2020 2020 2020 2020 6966 2072 6571  ).        if req
-00007b80: 7569 7265 645f 6361 6e64 6c65 5f63 616c  uired_candle_cal
-00007b90: 6c5f 636f 756e 7420 3e20 313a 0a20 2020  l_count > 1:.   
-00007ba0: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
-00007bb0: 7761 726e 696e 6728 6622 5573 696e 6720  warning(f"Using 
-00007bc0: 7b72 6571 7569 7265 645f 6361 6e64 6c65  {required_candle
-00007bd0: 5f63 616c 6c5f 636f 756e 747d 2063 616c  _call_count} cal
-00007be0: 6c73 2074 6f20 6765 7420 4f48 4c43 562e  ls to get OHLCV.
-00007bf0: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
-00007c00: 2020 2020 2020 2020 2020 2020 2020 6622                f"
-00007c10: 5468 6973 2063 616e 2072 6573 756c 7420  This can result 
-00007c20: 696e 2073 6c6f 7765 7220 6f70 6572 6174  in slower operat
-00007c30: 696f 6e73 2066 6f72 2074 6865 2062 6f74  ions for the bot
-00007c40: 2e20 506c 6561 7365 2063 6865 636b 2022  . Please check "
-00007c50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007c60: 2020 2020 2020 2020 2020 2020 6622 6966              f"if
-00007c70: 2079 6f75 2072 6561 6c6c 7920 6e65 6564   you really need
-00007c80: 207b 7374 6172 7475 705f 6361 6e64 6c65   {startup_candle
-00007c90: 737d 2063 616e 646c 6573 2066 6f72 2079  s} candles for y
-00007ca0: 6f75 7220 7374 7261 7465 6779 2229 0a20  our strategy"). 
-00007cb0: 2020 2020 2020 2072 6574 7572 6e20 7265         return re
-00007cc0: 7175 6972 6564 5f63 616e 646c 655f 6361  quired_candle_ca
-00007cd0: 6c6c 5f63 6f75 6e74 0a0a 2020 2020 6465  ll_count..    de
-00007ce0: 6620 7661 6c69 6461 7465 5f74 7261 6469  f validate_tradi
-00007cf0: 6e67 5f6d 6f64 655f 616e 645f 6d61 7267  ng_mode_and_marg
-00007d00: 696e 5f6d 6f64 6528 0a20 2020 2020 2020  in_mode(.       
-00007d10: 2073 656c 662c 0a20 2020 2020 2020 2074   self,.        t
-00007d20: 7261 6469 6e67 5f6d 6f64 653a 2054 7261  rading_mode: Tra
-00007d30: 6469 6e67 4d6f 6465 2c0a 2020 2020 2020  dingMode,.      
-00007d40: 2020 6d61 7267 696e 5f6d 6f64 653a 204f    margin_mode: O
-00007d50: 7074 696f 6e61 6c5b 4d61 7267 696e 4d6f  ptional[MarginMo
-00007d60: 6465 5d20 2023 204f 6e6c 7920 4e6f 6e65  de]  # Only None
-00007d70: 2077 6865 6e20 7472 6164 696e 675f 6d6f   when trading_mo
-00007d80: 6465 203d 2054 7261 6469 6e67 4d6f 6465  de = TradingMode
-00007d90: 2e53 504f 540a 2020 2020 293a 0a20 2020  .SPOT.    ):.   
-00007da0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00007db0: 2043 6865 636b 7320 6966 2066 7265 7174   Checks if freqt
-00007dc0: 7261 6465 2063 616e 2070 6572 666f 726d  rade can perform
-00007dd0: 2074 7261 6465 7320 7573 696e 6720 7468   trades using th
-00007de0: 6520 636f 6e66 6967 7572 6564 0a20 2020  e configured.   
-00007df0: 2020 2020 2074 7261 6469 6e67 206d 6f64       trading mod
-00007e00: 6528 4d61 7267 696e 2c20 4675 7475 7265  e(Margin, Future
-00007e10: 7329 2061 6e64 204d 6172 6769 6e4d 6f64  s) and MarginMod
-00007e20: 6528 4372 6f73 732c 2049 736f 6c61 7465  e(Cross, Isolate
-00007e30: 6429 0a20 2020 2020 2020 2054 6872 6f77  d).        Throw
-00007e40: 7320 4f70 6572 6174 696f 6e61 6c45 7863  s OperationalExc
-00007e50: 6570 7469 6f6e 3a0a 2020 2020 2020 2020  eption:.        
-00007e60: 2020 2020 4966 2074 6865 2074 7261 6469      If the tradi
-00007e70: 6e67 5f6d 6f64 652f 6d61 7267 696e 5f6d  ng_mode/margin_m
-00007e80: 6f64 6520 7479 7065 2061 7265 206e 6f74  ode type are not
-00007e90: 2073 7570 706f 7274 6564 2062 7920 6672   supported by fr
-00007ea0: 6571 7472 6164 6520 6f6e 2074 6869 7320  eqtrade on this 
-00007eb0: 6578 6368 616e 6765 0a20 2020 2020 2020  exchange.       
-00007ec0: 2022 2222 0a20 2020 2020 2020 2069 6620   """.        if 
-00007ed0: 7472 6164 696e 675f 6d6f 6465 2021 3d20  trading_mode != 
-00007ee0: 5472 6164 696e 674d 6f64 652e 5350 4f54  TradingMode.SPOT
-00007ef0: 2061 6e64 2028 0a20 2020 2020 2020 2020   and (.         
-00007f00: 2020 2028 7472 6164 696e 675f 6d6f 6465     (trading_mode
-00007f10: 2c20 6d61 7267 696e 5f6d 6f64 6529 206e  , margin_mode) n
-00007f20: 6f74 2069 6e20 7365 6c66 2e5f 7375 7070  ot in self._supp
-00007f30: 6f72 7465 645f 7472 6164 696e 675f 6d6f  orted_trading_mo
-00007f40: 6465 5f6d 6172 6769 6e5f 7061 6972 730a  de_margin_pairs.
-00007f50: 2020 2020 2020 2020 293a 0a20 2020 2020          ):.     
-00007f60: 2020 2020 2020 206d 6d5f 7661 6c75 6520         mm_value 
-00007f70: 3d20 6d61 7267 696e 5f6d 6f64 6520 616e  = margin_mode an
-00007f80: 6420 6d61 7267 696e 5f6d 6f64 652e 7661  d margin_mode.va
-00007f90: 6c75 650a 2020 2020 2020 2020 2020 2020  lue.            
-00007fa0: 7261 6973 6520 4f70 6572 6174 696f 6e61  raise Operationa
-00007fb0: 6c45 7863 6570 7469 6f6e 280a 2020 2020  lException(.    
-00007fc0: 2020 2020 2020 2020 2020 2020 6622 4672              f"Fr
-00007fd0: 6571 7472 6164 6520 646f 6573 206e 6f74  eqtrade does not
-00007fe0: 2073 7570 706f 7274 207b 6d6d 5f76 616c   support {mm_val
-00007ff0: 7565 7d20 7b74 7261 6469 6e67 5f6d 6f64  ue} {trading_mod
-00008000: 652e 7661 6c75 657d 206f 6e20 7b73 656c  e.value} on {sel
-00008010: 662e 6e61 6d65 7d22 0a20 2020 2020 2020  f.name}".       
-00008020: 2020 2020 2029 0a0a 2020 2020 6465 6620       )..    def 
-00008030: 6765 745f 6f70 7469 6f6e 2873 656c 662c  get_option(self,
-00008040: 2070 6172 616d 3a20 7374 722c 2064 6566   param: str, def
-00008050: 6175 6c74 3a20 4f70 7469 6f6e 616c 5b41  ault: Optional[A
-00008060: 6e79 5d20 3d20 4e6f 6e65 2920 2d3e 2041  ny] = None) -> A
-00008070: 6e79 3a0a 2020 2020 2020 2020 2222 220a  ny:.        """.
-00008080: 2020 2020 2020 2020 4765 7420 7061 7261          Get para
-00008090: 6d65 7465 7220 7661 6c75 6520 6672 6f6d  meter value from
-000080a0: 205f 6674 5f68 6173 0a20 2020 2020 2020   _ft_has.       
-000080b0: 2022 2222 0a20 2020 2020 2020 2072 6574   """.        ret
-000080c0: 7572 6e20 7365 6c66 2e5f 6674 5f68 6173  urn self._ft_has
-000080d0: 2e67 6574 2870 6172 616d 2c20 6465 6661  .get(param, defa
-000080e0: 756c 7429 0a0a 2020 2020 6465 6620 6578  ult)..    def ex
-000080f0: 6368 616e 6765 5f68 6173 2873 656c 662c  change_has(self,
-00008100: 2065 6e64 706f 696e 743a 2073 7472 2920   endpoint: str) 
-00008110: 2d3e 2062 6f6f 6c3a 0a20 2020 2020 2020  -> bool:.       
-00008120: 2022 2222 0a20 2020 2020 2020 2043 6865   """.        Che
-00008130: 636b 7320 6966 2065 7863 6861 6e67 6520  cks if exchange 
-00008140: 696d 706c 656d 656e 7473 2061 2073 7065  implements a spe
-00008150: 6369 6669 6320 4150 4920 656e 6470 6f69  cific API endpoi
-00008160: 6e74 2e0a 2020 2020 2020 2020 5772 6170  nt..        Wrap
-00008170: 7065 7220 6172 6f75 6e64 2063 6378 7420  per around ccxt 
-00008180: 2768 6173 2720 6174 7472 6962 7574 650a  'has' attribute.
-00008190: 2020 2020 2020 2020 3a70 6172 616d 2065          :param e
-000081a0: 6e64 706f 696e 743a 204e 616d 6520 6f66  ndpoint: Name of
-000081b0: 2065 6e64 706f 696e 7420 2865 2e67 2e20   endpoint (e.g. 
-000081c0: 2766 6574 6368 4f48 4c43 5627 2c20 2766  'fetchOHLCV', 'f
-000081d0: 6574 6368 5469 636b 6572 7327 290a 2020  etchTickers').  
-000081e0: 2020 2020 2020 3a72 6574 7572 6e3a 2062        :return: b
-000081f0: 6f6f 6c0a 2020 2020 2020 2020 2222 220a  ool.        """.
-00008200: 2020 2020 2020 2020 6966 2065 6e64 706f          if endpo
-00008210: 696e 7420 696e 2073 656c 662e 5f66 745f  int in self._ft_
-00008220: 6861 732e 6765 7428 2765 7863 6861 6e67  has.get('exchang
-00008230: 655f 6861 735f 6f76 6572 7269 6465 7327  e_has_overrides'
-00008240: 2c20 7b7d 293a 0a20 2020 2020 2020 2020  , {}):.         
-00008250: 2020 2072 6574 7572 6e20 7365 6c66 2e5f     return self._
-00008260: 6674 5f68 6173 5b27 6578 6368 616e 6765  ft_has['exchange
-00008270: 5f68 6173 5f6f 7665 7272 6964 6573 275d  _has_overrides']
-00008280: 5b65 6e64 706f 696e 745d 0a20 2020 2020  [endpoint].     
-00008290: 2020 2072 6574 7572 6e20 656e 6470 6f69     return endpoi
-000082a0: 6e74 2069 6e20 7365 6c66 2e5f 6170 692e  nt in self._api.
-000082b0: 6861 7320 616e 6420 7365 6c66 2e5f 6170  has and self._ap
-000082c0: 692e 6861 735b 656e 6470 6f69 6e74 5d0a  i.has[endpoint].
-000082d0: 0a20 2020 2064 6566 2067 6574 5f70 7265  .    def get_pre
-000082e0: 6369 7369 6f6e 5f61 6d6f 756e 7428 7365  cision_amount(se
-000082f0: 6c66 2c20 7061 6972 3a20 7374 7229 202d  lf, pair: str) -
-00008300: 3e20 4f70 7469 6f6e 616c 5b66 6c6f 6174  > Optional[float
-00008310: 5d3a 0a20 2020 2020 2020 2022 2222 0a20  ]:.        """. 
-00008320: 2020 2020 2020 2052 6574 7572 6e73 2074         Returns t
-00008330: 6865 2061 6d6f 756e 7420 7072 6563 6973  he amount precis
-00008340: 696f 6e20 6f66 2074 6865 2065 7863 6861  ion of the excha
-00008350: 6e67 652e 0a20 2020 2020 2020 203a 7061  nge..        :pa
-00008360: 7261 6d20 7061 6972 3a20 5061 6972 2074  ram pair: Pair t
-00008370: 6f20 6765 7420 7072 6563 6973 696f 6e20  o get precision 
-00008380: 666f 720a 2020 2020 2020 2020 3a72 6574  for.        :ret
-00008390: 7572 6e3a 2070 7265 6369 7369 6f6e 2066  urn: precision f
-000083a0: 6f72 2061 6d6f 756e 7420 6f72 204e 6f6e  or amount or Non
-000083b0: 652e 204d 7573 7420 6265 2075 7365 6420  e. Must be used 
-000083c0: 696e 2063 6f6d 6269 6e61 7469 6f6e 2077  in combination w
-000083d0: 6974 6820 7072 6563 6973 696f 6e4d 6f64  ith precisionMod
-000083e0: 650a 2020 2020 2020 2020 2222 220a 2020  e.        """.  
-000083f0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-00008400: 662e 6d61 726b 6574 732e 6765 7428 7061  f.markets.get(pa
-00008410: 6972 2c20 7b7d 292e 6765 7428 2770 7265  ir, {}).get('pre
-00008420: 6369 7369 6f6e 272c 207b 7d29 2e67 6574  cision', {}).get
-00008430: 2827 616d 6f75 6e74 272c 204e 6f6e 6529  ('amount', None)
-00008440: 0a0a 2020 2020 6465 6620 6765 745f 7072  ..    def get_pr
-00008450: 6563 6973 696f 6e5f 7072 6963 6528 7365  ecision_price(se
-00008460: 6c66 2c20 7061 6972 3a20 7374 7229 202d  lf, pair: str) -
-00008470: 3e20 4f70 7469 6f6e 616c 5b66 6c6f 6174  > Optional[float
-00008480: 5d3a 0a20 2020 2020 2020 2022 2222 0a20  ]:.        """. 
-00008490: 2020 2020 2020 2052 6574 7572 6e73 2074         Returns t
-000084a0: 6865 2070 7269 6365 2070 7265 6369 7369  he price precisi
-000084b0: 6f6e 206f 6620 7468 6520 6578 6368 616e  on of the exchan
-000084c0: 6765 2e0a 2020 2020 2020 2020 3a70 6172  ge..        :par
-000084d0: 616d 2070 6169 723a 2050 6169 7220 746f  am pair: Pair to
-000084e0: 2067 6574 2070 7265 6369 7369 6f6e 2066   get precision f
-000084f0: 6f72 0a20 2020 2020 2020 203a 7265 7475  or.        :retu
-00008500: 726e 3a20 7072 6563 6973 696f 6e20 666f  rn: precision fo
-00008510: 7220 7072 6963 6520 6f72 204e 6f6e 652e  r price or None.
-00008520: 204d 7573 7420 6265 2075 7365 6420 696e   Must be used in
-00008530: 2063 6f6d 6269 6e61 7469 6f6e 2077 6974   combination wit
-00008540: 6820 7072 6563 6973 696f 6e4d 6f64 650a  h precisionMode.
-00008550: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00008560: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-00008570: 6d61 726b 6574 732e 6765 7428 7061 6972  markets.get(pair
-00008580: 2c20 7b7d 292e 6765 7428 2770 7265 6369  , {}).get('preci
-00008590: 7369 6f6e 272c 207b 7d29 2e67 6574 2827  sion', {}).get('
-000085a0: 7072 6963 6527 2c20 4e6f 6e65 290a 0a20  price', None).. 
-000085b0: 2020 2064 6566 2061 6d6f 756e 745f 746f     def amount_to
-000085c0: 5f70 7265 6369 7369 6f6e 2873 656c 662c  _precision(self,
-000085d0: 2070 6169 723a 2073 7472 2c20 616d 6f75   pair: str, amou
-000085e0: 6e74 3a20 666c 6f61 7429 202d 3e20 666c  nt: float) -> fl
-000085f0: 6f61 743a 0a20 2020 2020 2020 2022 2222  oat:.        """
-00008600: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
-00008610: 2074 6865 2061 6d6f 756e 7420 746f 2062   the amount to b
-00008620: 7579 206f 7220 7365 6c6c 2074 6f20 6120  uy or sell to a 
-00008630: 7072 6563 6973 696f 6e20 7468 6520 4578  precision the Ex
-00008640: 6368 616e 6765 2061 6363 6570 7473 0a0a  change accepts..
-00008650: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00008660: 2020 2020 7265 7475 726e 2061 6d6f 756e      return amoun
-00008670: 745f 746f 5f70 7265 6369 7369 6f6e 2861  t_to_precision(a
-00008680: 6d6f 756e 742c 2073 656c 662e 6765 745f  mount, self.get_
-00008690: 7072 6563 6973 696f 6e5f 616d 6f75 6e74  precision_amount
-000086a0: 2870 6169 7229 2c20 7365 6c66 2e70 7265  (pair), self.pre
-000086b0: 6369 7369 6f6e 4d6f 6465 290a 0a20 2020  cisionMode)..   
-000086c0: 2064 6566 2070 7269 6365 5f74 6f5f 7072   def price_to_pr
-000086d0: 6563 6973 696f 6e28 7365 6c66 2c20 7061  ecision(self, pa
-000086e0: 6972 3a20 7374 722c 2070 7269 6365 3a20  ir: str, price: 
-000086f0: 666c 6f61 742c 202a 2c20 726f 756e 6469  float, *, roundi
-00008700: 6e67 5f6d 6f64 653a 2069 6e74 203d 2052  ng_mode: int = R
-00008710: 4f55 4e44 2920 2d3e 2066 6c6f 6174 3a0a  OUND) -> float:.
-00008720: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00008730: 2020 2020 5265 7475 726e 7320 7468 6520      Returns the 
-00008740: 7072 6963 6520 726f 756e 6465 6420 746f  price rounded to
-00008750: 2074 6865 2070 7265 6369 7369 6f6e 2074   the precision t
-00008760: 6865 2045 7863 6861 6e67 6520 6163 6365  he Exchange acce
-00008770: 7074 732e 0a20 2020 2020 2020 2054 6865  pts..        The
-00008780: 2064 6566 6175 6c74 2070 7269 6365 5f72   default price_r
-00008790: 6f75 6e64 696e 675f 6d6f 6465 2069 6e20  ounding_mode in 
-000087a0: 636f 6e66 2069 7320 524f 554e 442e 0a20  conf is ROUND.. 
-000087b0: 2020 2020 2020 2046 6f72 2073 746f 706c         For stopl
-000087c0: 6f73 7320 6361 6c63 756c 6174 696f 6e73  oss calculations
-000087d0: 2c20 6d75 7374 2075 7365 2052 4f55 4e44  , must use ROUND
-000087e0: 5f55 5020 666f 7220 6c6f 6e67 732c 2061  _UP for longs, a
-000087f0: 6e64 2052 4f55 4e44 5f44 4f57 4e20 666f  nd ROUND_DOWN fo
-00008800: 7220 7368 6f72 7473 2e0a 2020 2020 2020  r shorts..      
-00008810: 2020 2222 220a 2020 2020 2020 2020 7265    """.        re
-00008820: 7475 726e 2070 7269 6365 5f74 6f5f 7072  turn price_to_pr
-00008830: 6563 6973 696f 6e28 7072 6963 652c 2073  ecision(price, s
-00008840: 656c 662e 6765 745f 7072 6563 6973 696f  elf.get_precisio
-00008850: 6e5f 7072 6963 6528 7061 6972 292c 0a20  n_price(pair),. 
-00008860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008880: 2073 656c 662e 7072 6563 6973 696f 6e4d   self.precisionM
-00008890: 6f64 652c 2072 6f75 6e64 696e 675f 6d6f  ode, rounding_mo
-000088a0: 6465 3d72 6f75 6e64 696e 675f 6d6f 6465  de=rounding_mode
-000088b0: 290a 0a20 2020 2064 6566 2070 7269 6365  )..    def price
-000088c0: 5f67 6574 5f6f 6e65 5f70 6970 2873 656c  _get_one_pip(sel
-000088d0: 662c 2070 6169 723a 2073 7472 2c20 7072  f, pair: str, pr
-000088e0: 6963 653a 2066 6c6f 6174 2920 2d3e 2066  ice: float) -> f
-000088f0: 6c6f 6174 3a0a 2020 2020 2020 2020 2222  loat:.        ""
-00008900: 220a 2020 2020 2020 2020 4765 7473 2074  ".        Gets t
-00008910: 6865 2022 3120 7069 7022 2076 616c 7565  he "1 pip" value
-00008920: 2066 6f72 2074 6869 7320 7061 6972 2e0a   for this pair..
-00008930: 2020 2020 2020 2020 5573 6564 2069 6e20          Used in 
-00008940: 5072 6963 6546 696c 7465 7220 746f 2063  PriceFilter to c
-00008950: 616c 6375 6c61 7465 2074 6865 2031 7069  alculate the 1pi
-00008960: 7020 6d6f 7665 6d65 6e74 732e 0a20 2020  p movements..   
-00008970: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00008980: 2070 7265 6369 7369 6f6e 203d 2073 656c   precision = sel
-00008990: 662e 6d61 726b 6574 735b 7061 6972 5d5b  f.markets[pair][
-000089a0: 2770 7265 6369 7369 6f6e 275d 5b27 7072  'precision']['pr
-000089b0: 6963 6527 5d0a 2020 2020 2020 2020 6966  ice'].        if
-000089c0: 2073 656c 662e 7072 6563 6973 696f 6e4d   self.precisionM
-000089d0: 6f64 6520 3d3d 2054 4943 4b5f 5349 5a45  ode == TICK_SIZE
-000089e0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-000089f0: 7475 726e 2070 7265 6369 7369 6f6e 0a20  turn precision. 
-00008a00: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-00008a10: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00008a20: 3120 2f20 706f 7728 3130 2c20 7072 6563  1 / pow(10, prec
-00008a30: 6973 696f 6e29 0a0a 2020 2020 6465 6620  ision)..    def 
-00008a40: 6765 745f 6d69 6e5f 7061 6972 5f73 7461  get_min_pair_sta
-00008a50: 6b65 5f61 6d6f 756e 7428 0a20 2020 2020  ke_amount(.     
-00008a60: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
-00008a70: 2070 6169 723a 2073 7472 2c0a 2020 2020   pair: str,.    
-00008a80: 2020 2020 7072 6963 653a 2066 6c6f 6174      price: float
-00008a90: 2c0a 2020 2020 2020 2020 7374 6f70 6c6f  ,.        stoplo
-00008aa0: 7373 3a20 666c 6f61 742c 0a20 2020 2020  ss: float,.     
-00008ab0: 2020 206c 6576 6572 6167 653a 204f 7074     leverage: Opt
-00008ac0: 696f 6e61 6c5b 666c 6f61 745d 203d 2031  ional[float] = 1
-00008ad0: 2e30 0a20 2020 2029 202d 3e20 4f70 7469  .0.    ) -> Opti
-00008ae0: 6f6e 616c 5b66 6c6f 6174 5d3a 0a20 2020  onal[float]:.   
-00008af0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00008b00: 2e5f 6765 745f 7374 616b 655f 616d 6f75  ._get_stake_amou
-00008b10: 6e74 5f6c 696d 6974 2870 6169 722c 2070  nt_limit(pair, p
-00008b20: 7269 6365 2c20 7374 6f70 6c6f 7373 2c20  rice, stoploss, 
-00008b30: 276d 696e 272c 206c 6576 6572 6167 6529  'min', leverage)
-00008b40: 0a0a 2020 2020 6465 6620 6765 745f 6d61  ..    def get_ma
-00008b50: 785f 7061 6972 5f73 7461 6b65 5f61 6d6f  x_pair_stake_amo
-00008b60: 756e 7428 7365 6c66 2c20 7061 6972 3a20  unt(self, pair: 
-00008b70: 7374 722c 2070 7269 6365 3a20 666c 6f61  str, price: floa
-00008b80: 742c 206c 6576 6572 6167 653a 2066 6c6f  t, leverage: flo
-00008b90: 6174 203d 2031 2e30 2920 2d3e 2066 6c6f  at = 1.0) -> flo
-00008ba0: 6174 3a0a 2020 2020 2020 2020 6d61 785f  at:.        max_
-00008bb0: 7374 616b 655f 616d 6f75 6e74 203d 2073  stake_amount = s
-00008bc0: 656c 662e 5f67 6574 5f73 7461 6b65 5f61  elf._get_stake_a
-00008bd0: 6d6f 756e 745f 6c69 6d69 7428 7061 6972  mount_limit(pair
-00008be0: 2c20 7072 6963 652c 2030 2e30 2c20 276d  , price, 0.0, 'm
-00008bf0: 6178 272c 206c 6576 6572 6167 6529 0a20  ax', leverage). 
-00008c00: 2020 2020 2020 2069 6620 6d61 785f 7374         if max_st
-00008c10: 616b 655f 616d 6f75 6e74 2069 7320 4e6f  ake_amount is No
-00008c20: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00008c30: 2320 2a20 5368 6f75 6c64 206e 6576 6572  # * Should never
-00008c40: 2062 6520 6578 6563 7574 6564 0a20 2020   be executed.   
-00008c50: 2020 2020 2020 2020 2072 6169 7365 204f           raise O
-00008c60: 7065 7261 7469 6f6e 616c 4578 6365 7074  perationalExcept
-00008c70: 696f 6e28 6627 7b73 656c 662e 6e61 6d65  ion(f'{self.name
-00008c80: 7d2e 6765 745f 6d61 785f 7061 6972 5f73  }.get_max_pair_s
-00008c90: 7461 6b65 5f61 6d6f 756e 7420 7368 6f75  take_amount shou
-00008ca0: 6c64 270a 2020 2020 2020 2020 2020 2020  ld'.            
-00008cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008cc0: 2020 2020 2020 2020 2020 2027 6e65 7665             'neve
-00008cd0: 7220 7365 7420 6d61 785f 7374 616b 655f  r set max_stake_
-00008ce0: 616d 6f75 6e74 2074 6f20 4e6f 6e65 2729  amount to None')
-00008cf0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00008d00: 6d61 785f 7374 616b 655f 616d 6f75 6e74  max_stake_amount
-00008d10: 0a0a 2020 2020 6465 6620 5f67 6574 5f73  ..    def _get_s
-00008d20: 7461 6b65 5f61 6d6f 756e 745f 6c69 6d69  take_amount_limi
-00008d30: 7428 0a20 2020 2020 2020 2073 656c 662c  t(.        self,
-00008d40: 0a20 2020 2020 2020 2070 6169 723a 2073  .        pair: s
-00008d50: 7472 2c0a 2020 2020 2020 2020 7072 6963  tr,.        pric
-00008d60: 653a 2066 6c6f 6174 2c0a 2020 2020 2020  e: float,.      
-00008d70: 2020 7374 6f70 6c6f 7373 3a20 666c 6f61    stoploss: floa
-00008d80: 742c 0a20 2020 2020 2020 206c 696d 6974  t,.        limit
-00008d90: 3a20 4c69 7465 7261 6c5b 276d 696e 272c  : Literal['min',
-00008da0: 2027 6d61 7827 5d2c 0a20 2020 2020 2020   'max'],.       
-00008db0: 206c 6576 6572 6167 653a 204f 7074 696f   leverage: Optio
-00008dc0: 6e61 6c5b 666c 6f61 745d 203d 2031 2e30  nal[float] = 1.0
-00008dd0: 0a20 2020 2029 202d 3e20 4f70 7469 6f6e  .    ) -> Option
-00008de0: 616c 5b66 6c6f 6174 5d3a 0a0a 2020 2020  al[float]:..    
-00008df0: 2020 2020 6973 4d69 6e20 3d20 6c69 6d69      isMin = limi
-00008e00: 7420 3d3d 2027 6d69 6e27 0a0a 2020 2020  t == 'min'..    
-00008e10: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-00008e20: 2020 2020 206d 6172 6b65 7420 3d20 7365       market = se
-00008e30: 6c66 2e6d 6172 6b65 7473 5b70 6169 725d  lf.markets[pair]
-00008e40: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-00008e50: 4b65 7945 7272 6f72 3a0a 2020 2020 2020  KeyError:.      
-00008e60: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-00008e70: 6545 7272 6f72 2866 2243 616e 2774 2067  eError(f"Can't g
-00008e80: 6574 206d 6172 6b65 7420 696e 666f 726d  et market inform
-00008e90: 6174 696f 6e20 666f 7220 7379 6d62 6f6c  ation for symbol
-00008ea0: 207b 7061 6972 7d22 290a 0a20 2020 2020   {pair}")..     
-00008eb0: 2020 2069 6620 6973 4d69 6e3a 0a20 2020     if isMin:.   
-00008ec0: 2020 2020 2020 2020 2023 2072 6573 6572           # reser
-00008ed0: 7665 2073 6f6d 6520 7065 7263 656e 7420  ve some percent 
-00008ee0: 6465 6669 6e65 6420 696e 2063 6f6e 6669  defined in confi
-00008ef0: 6720 2835 2520 6465 6661 756c 7429 202b  g (5% default) +
-00008f00: 2073 746f 706c 6f73 730a 2020 2020 2020   stoploss.      
-00008f10: 2020 2020 2020 6d61 7267 696e 5f72 6573        margin_res
-00008f20: 6572 7665 3a20 666c 6f61 7420 3d20 312e  erve: float = 1.
-00008f30: 3020 2b20 7365 6c66 2e5f 636f 6e66 6967  0 + self._config
-00008f40: 2e67 6574 2827 616d 6f75 6e74 5f72 6573  .get('amount_res
-00008f50: 6572 7665 5f70 6572 6365 6e74 272c 0a20  erve_percent',. 
-00008f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008f90: 2020 2020 2020 2020 2020 4445 4641 554c            DEFAUL
-00008fa0: 545f 414d 4f55 4e54 5f52 4553 4552 5645  T_AMOUNT_RESERVE
-00008fb0: 5f50 4552 4345 4e54 290a 2020 2020 2020  _PERCENT).      
-00008fc0: 2020 2020 2020 7374 6f70 6c6f 7373 5f72        stoploss_r
-00008fd0: 6573 6572 7665 203d 2028 0a20 2020 2020  eserve = (.     
-00008fe0: 2020 2020 2020 2020 2020 206d 6172 6769             margi
-00008ff0: 6e5f 7265 7365 7276 6520 2f20 2831 202d  n_reserve / (1 -
-00009000: 2061 6273 2873 746f 706c 6f73 7329 2920   abs(stoploss)) 
-00009010: 6966 2061 6273 2873 746f 706c 6f73 7329  if abs(stoploss)
-00009020: 2021 3d20 3120 656c 7365 2031 2e35 0a20   != 1 else 1.5. 
-00009030: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
-00009040: 2020 2020 2020 2020 2023 2069 7420 7368           # it sh
-00009050: 6f75 6c64 206e 6f74 2062 6520 6d6f 7265  ould not be more
-00009060: 2074 6861 6e20 3530 250a 2020 2020 2020   than 50%.      
-00009070: 2020 2020 2020 7374 6f70 6c6f 7373 5f72        stoploss_r
-00009080: 6573 6572 7665 203d 206d 6178 286d 696e  eserve = max(min
-00009090: 2873 746f 706c 6f73 735f 7265 7365 7276  (stoploss_reserv
-000090a0: 652c 2031 2e35 292c 2031 290a 2020 2020  e, 1.5), 1).    
-000090b0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-000090c0: 2020 2020 2020 6d61 7267 696e 5f72 6573        margin_res
-000090d0: 6572 7665 203d 2031 2e30 0a20 2020 2020  erve = 1.0.     
-000090e0: 2020 2020 2020 2073 746f 706c 6f73 735f         stoploss_
-000090f0: 7265 7365 7276 6520 3d20 312e 300a 0a20  reserve = 1.0.. 
-00009100: 2020 2020 2020 2073 7461 6b65 5f6c 696d         stake_lim
-00009110: 6974 7320 3d20 5b5d 0a20 2020 2020 2020  its = [].       
-00009120: 206c 696d 6974 7320 3d20 6d61 726b 6574   limits = market
-00009130: 5b27 6c69 6d69 7473 275d 0a20 2020 2020  ['limits'].     
-00009140: 2020 2069 6620 286c 696d 6974 735b 2763     if (limits['c
-00009150: 6f73 7427 5d5b 6c69 6d69 745d 2069 7320  ost'][limit] is 
-00009160: 6e6f 7420 4e6f 6e65 293a 0a20 2020 2020  not None):.     
-00009170: 2020 2020 2020 2073 7461 6b65 5f6c 696d         stake_lim
-00009180: 6974 732e 6170 7065 6e64 280a 2020 2020  its.append(.    
-00009190: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000091a0: 2e5f 636f 6e74 7261 6374 735f 746f 5f61  ._contracts_to_a
-000091b0: 6d6f 756e 7428 7061 6972 2c20 6c69 6d69  mount(pair, limi
-000091c0: 7473 5b27 636f 7374 275d 5b6c 696d 6974  ts['cost'][limit
-000091d0: 5d29 202a 2073 746f 706c 6f73 735f 7265  ]) * stoploss_re
-000091e0: 7365 7276 650a 2020 2020 2020 2020 2020  serve.          
-000091f0: 2020 290a 0a20 2020 2020 2020 2069 6620    )..        if 
-00009200: 286c 696d 6974 735b 2761 6d6f 756e 7427  (limits['amount'
-00009210: 5d5b 6c69 6d69 745d 2069 7320 6e6f 7420  ][limit] is not 
-00009220: 4e6f 6e65 293a 0a20 2020 2020 2020 2020  None):.         
-00009230: 2020 2073 7461 6b65 5f6c 696d 6974 732e     stake_limits.
-00009240: 6170 7065 6e64 280a 2020 2020 2020 2020  append(.        
-00009250: 2020 2020 2020 2020 7365 6c66 2e5f 636f          self._co
-00009260: 6e74 7261 6374 735f 746f 5f61 6d6f 756e  ntracts_to_amoun
-00009270: 7428 7061 6972 2c20 6c69 6d69 7473 5b27  t(pair, limits['
-00009280: 616d 6f75 6e74 275d 5b6c 696d 6974 5d29  amount'][limit])
-00009290: 202a 2070 7269 6365 202a 206d 6172 6769   * price * margi
-000092a0: 6e5f 7265 7365 7276 650a 2020 2020 2020  n_reserve.      
-000092b0: 2020 2020 2020 290a 0a20 2020 2020 2020        )..       
-000092c0: 2069 6620 6e6f 7420 7374 616b 655f 6c69   if not stake_li
-000092d0: 6d69 7473 3a0a 2020 2020 2020 2020 2020  mits:.          
-000092e0: 2020 7265 7475 726e 204e 6f6e 6520 6966    return None if
-000092f0: 2069 734d 696e 2065 6c73 6520 666c 6f61   isMin else floa
-00009300: 7428 2769 6e66 2729 0a0a 2020 2020 2020  t('inf')..      
-00009310: 2020 2320 5468 6520 7661 6c75 6520 7265    # The value re
-00009320: 7475 726e 6564 2073 686f 756c 6420 7361  turned should sa
-00009330: 7469 7366 7920 626f 7468 206c 696d 6974  tisfy both limit
-00009340: 733a 2066 6f72 2061 6d6f 756e 7420 2862  s: for amount (b
-00009350: 6173 6520 6375 7272 656e 6379 2920 616e  ase currency) an
-00009360: 640a 2020 2020 2020 2020 2320 666f 7220  d.        # for 
-00009370: 636f 7374 2028 7175 6f74 652c 2073 7461  cost (quote, sta
-00009380: 6b65 2063 7572 7265 6e63 7929 2c20 736f  ke currency), so
-00009390: 206d 6178 2829 2069 7320 7573 6564 2068   max() is used h
-000093a0: 6572 652e 0a20 2020 2020 2020 2023 2053  ere..        # S
-000093b0: 6565 2061 6c73 6f20 2332 3537 3520 6174  ee also #2575 at
-000093c0: 2067 6974 6875 622e 0a20 2020 2020 2020   github..       
-000093d0: 2072 6574 7572 6e20 7365 6c66 2e5f 6765   return self._ge
-000093e0: 745f 7374 616b 655f 616d 6f75 6e74 5f63  t_stake_amount_c
-000093f0: 6f6e 7369 6465 7269 6e67 5f6c 6576 6572  onsidering_lever
-00009400: 6167 6528 0a20 2020 2020 2020 2020 2020  age(.           
-00009410: 206d 6178 2873 7461 6b65 5f6c 696d 6974   max(stake_limit
-00009420: 7329 2069 6620 6973 4d69 6e20 656c 7365  s) if isMin else
-00009430: 206d 696e 2873 7461 6b65 5f6c 696d 6974   min(stake_limit
-00009440: 7329 2c0a 2020 2020 2020 2020 2020 2020  s),.            
-00009450: 6c65 7665 7261 6765 206f 7220 312e 300a  leverage or 1.0.
-00009460: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
-00009470: 6566 205f 6765 745f 7374 616b 655f 616d  ef _get_stake_am
-00009480: 6f75 6e74 5f63 6f6e 7369 6465 7269 6e67  ount_considering
-00009490: 5f6c 6576 6572 6167 6528 7365 6c66 2c20  _leverage(self, 
-000094a0: 7374 616b 655f 616d 6f75 6e74 3a20 666c  stake_amount: fl
-000094b0: 6f61 742c 206c 6576 6572 6167 653a 2066  oat, leverage: f
-000094c0: 6c6f 6174 2920 2d3e 2066 6c6f 6174 3a0a  loat) -> float:.
-000094d0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-000094e0: 2020 2020 5461 6b65 7320 7468 6520 6d69      Takes the mi
-000094f0: 6e69 6d75 6d20 7374 616b 6520 616d 6f75  nimum stake amou
-00009500: 6e74 2066 6f72 2061 2070 6169 7220 7769  nt for a pair wi
-00009510: 7468 206e 6f20 6c65 7665 7261 6765 2061  th no leverage a
-00009520: 6e64 2072 6574 7572 6e73 2074 6865 206d  nd returns the m
-00009530: 696e 696d 756d 0a20 2020 2020 2020 2073  inimum.        s
-00009540: 7461 6b65 2061 6d6f 756e 7420 7768 656e  take amount when
-00009550: 206c 6576 6572 6167 6520 6973 2063 6f6e   leverage is con
-00009560: 7369 6465 7265 640a 2020 2020 2020 2020  sidered.        
-00009570: 3a70 6172 616d 2073 7461 6b65 5f61 6d6f  :param stake_amo
-00009580: 756e 743a 2054 6865 2073 7461 6b65 2061  unt: The stake a
-00009590: 6d6f 756e 7420 666f 7220 6120 7061 6972  mount for a pair
-000095a0: 2062 6566 6f72 6520 6c65 7665 7261 6765   before leverage
-000095b0: 2069 7320 636f 6e73 6964 6572 6564 0a20   is considered. 
-000095c0: 2020 2020 2020 203a 7061 7261 6d20 6c65         :param le
-000095d0: 7665 7261 6765 3a20 5468 6520 616d 6f75  verage: The amou
-000095e0: 6e74 206f 6620 6c65 7665 7261 6765 2062  nt of leverage b
-000095f0: 6569 6e67 2075 7365 6420 6f6e 2074 6865  eing used on the
-00009600: 2063 7572 7265 6e74 2074 7261 6465 0a20   current trade. 
-00009610: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-00009620: 2020 2072 6574 7572 6e20 7374 616b 655f     return stake_
-00009630: 616d 6f75 6e74 202f 206c 6576 6572 6167  amount / leverag
-00009640: 650a 0a20 2020 2023 2044 7279 2d72 756e  e..    # Dry-run
-00009650: 206d 6574 686f 6473 0a0a 2020 2020 6465   methods..    de
-00009660: 6620 6372 6561 7465 5f64 7279 5f72 756e  f create_dry_run
-00009670: 5f6f 7264 6572 2873 656c 662c 2070 6169  _order(self, pai
-00009680: 723a 2073 7472 2c20 6f72 6465 7274 7970  r: str, ordertyp
-00009690: 653a 2073 7472 2c20 7369 6465 3a20 7374  e: str, side: st
-000096a0: 722c 2061 6d6f 756e 743a 2066 6c6f 6174  r, amount: float
-000096b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000096c0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-000096d0: 6174 653a 2066 6c6f 6174 2c20 6c65 7665  ate: float, leve
-000096e0: 7261 6765 3a20 666c 6f61 742c 2070 6172  rage: float, par
-000096f0: 616d 733a 204f 7074 696f 6e61 6c5b 4469  ams: Optional[Di
-00009700: 6374 5d20 3d20 4e6f 6e65 2c0a 2020 2020  ct] = None,.    
-00009710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009720: 2020 2020 2020 2020 2073 746f 705f 6c6f           stop_lo
-00009730: 7373 3a20 626f 6f6c 203d 2046 616c 7365  ss: bool = False
-00009740: 2920 2d3e 2044 6963 745b 7374 722c 2041  ) -> Dict[str, A
-00009750: 6e79 5d3a 0a20 2020 2020 2020 206e 6f77  ny]:.        now
-00009760: 203d 2064 745f 6e6f 7728 290a 2020 2020   = dt_now().    
-00009770: 2020 2020 6f72 6465 725f 6964 203d 2066      order_id = f
-00009780: 2764 7279 5f72 756e 5f7b 7369 6465 7d5f  'dry_run_{side}_
-00009790: 7b70 6169 727d 5f7b 6e6f 772e 7469 6d65  {pair}_{now.time
-000097a0: 7374 616d 7028 297d 270a 2020 2020 2020  stamp()}'.      
-000097b0: 2020 2320 526f 756e 6469 6e67 2068 6572    # Rounding her
-000097c0: 6520 6d75 7374 2072 6573 7065 6374 2074  e must respect t
-000097d0: 6f20 636f 6e74 7261 6374 2073 697a 6573  o contract sizes
-000097e0: 0a20 2020 2020 2020 205f 616d 6f75 6e74  .        _amount
-000097f0: 203d 2073 656c 662e 5f63 6f6e 7472 6163   = self._contrac
-00009800: 7473 5f74 6f5f 616d 6f75 6e74 280a 2020  ts_to_amount(.  
-00009810: 2020 2020 2020 2020 2020 7061 6972 2c20            pair, 
-00009820: 7365 6c66 2e61 6d6f 756e 745f 746f 5f70  self.amount_to_p
-00009830: 7265 6369 7369 6f6e 2870 6169 722c 2073  recision(pair, s
-00009840: 656c 662e 5f61 6d6f 756e 745f 746f 5f63  elf._amount_to_c
-00009850: 6f6e 7472 6163 7473 2870 6169 722c 2061  ontracts(pair, a
-00009860: 6d6f 756e 7429 2929 0a20 2020 2020 2020  mount))).       
-00009870: 2064 7279 5f6f 7264 6572 3a20 4469 6374   dry_order: Dict
-00009880: 5b73 7472 2c20 416e 795d 203d 207b 0a20  [str, Any] = {. 
-00009890: 2020 2020 2020 2020 2020 2027 6964 273a             'id':
-000098a0: 206f 7264 6572 5f69 642c 0a20 2020 2020   order_id,.     
-000098b0: 2020 2020 2020 2027 7379 6d62 6f6c 273a         'symbol':
-000098c0: 2070 6169 722c 0a20 2020 2020 2020 2020   pair,.         
-000098d0: 2020 2027 7072 6963 6527 3a20 7261 7465     'price': rate
-000098e0: 2c0a 2020 2020 2020 2020 2020 2020 2761  ,.            'a
-000098f0: 7665 7261 6765 273a 2072 6174 652c 0a20  verage': rate,. 
-00009900: 2020 2020 2020 2020 2020 2027 616d 6f75             'amou
-00009910: 6e74 273a 205f 616d 6f75 6e74 2c0a 2020  nt': _amount,.  
-00009920: 2020 2020 2020 2020 2020 2763 6f73 7427            'cost'
-00009930: 3a20 5f61 6d6f 756e 7420 2a20 7261 7465  : _amount * rate
-00009940: 2c0a 2020 2020 2020 2020 2020 2020 2774  ,.            't
-00009950: 7970 6527 3a20 6f72 6465 7274 7970 652c  ype': ordertype,
-00009960: 0a20 2020 2020 2020 2020 2020 2027 7369  .            'si
-00009970: 6465 273a 2073 6964 652c 0a20 2020 2020  de': side,.     
-00009980: 2020 2020 2020 2027 6669 6c6c 6564 273a         'filled':
-00009990: 2030 2c0a 2020 2020 2020 2020 2020 2020   0,.            
-000099a0: 2772 656d 6169 6e69 6e67 273a 205f 616d  'remaining': _am
-000099b0: 6f75 6e74 2c0a 2020 2020 2020 2020 2020  ount,.          
-000099c0: 2020 2764 6174 6574 696d 6527 3a20 6e6f    'datetime': no
-000099d0: 772e 7374 7266 7469 6d65 2827 2559 2d25  w.strftime('%Y-%
-000099e0: 6d2d 2564 5425 483a 254d 3a25 532e 2566  m-%dT%H:%M:%S.%f
-000099f0: 5a27 292c 0a20 2020 2020 2020 2020 2020  Z'),.           
-00009a00: 2027 7469 6d65 7374 616d 7027 3a20 6474   'timestamp': dt
-00009a10: 5f74 7328 6e6f 7729 2c0a 2020 2020 2020  _ts(now),.      
-00009a20: 2020 2020 2020 2773 7461 7475 7327 3a20        'status': 
-00009a30: 226f 7065 6e22 2c0a 2020 2020 2020 2020  "open",.        
-00009a40: 2020 2020 2766 6565 273a 204e 6f6e 652c      'fee': None,
-00009a50: 0a20 2020 2020 2020 2020 2020 2027 696e  .            'in
-00009a60: 666f 273a 207b 7d2c 0a20 2020 2020 2020  fo': {},.       
-00009a70: 2020 2020 2027 6c65 7665 7261 6765 273a       'leverage':
-00009a80: 206c 6576 6572 6167 650a 2020 2020 2020   leverage.      
-00009a90: 2020 7d0a 2020 2020 2020 2020 6966 2073    }.        if s
-00009aa0: 746f 705f 6c6f 7373 3a0a 2020 2020 2020  top_loss:.      
-00009ab0: 2020 2020 2020 6472 795f 6f72 6465 725b        dry_order[
-00009ac0: 2269 6e66 6f22 5d20 3d20 7b22 7374 6f70  "info"] = {"stop
-00009ad0: 5072 6963 6522 3a20 6472 795f 6f72 6465  Price": dry_orde
-00009ae0: 725b 2270 7269 6365 225d 7d0a 2020 2020  r["price"]}.    
-00009af0: 2020 2020 2020 2020 6472 795f 6f72 6465          dry_orde
-00009b00: 725b 7365 6c66 2e5f 6674 5f68 6173 5b27  r[self._ft_has['
-00009b10: 7374 6f70 5f70 7269 6365 5f70 726f 7027  stop_price_prop'
-00009b20: 5d5d 203d 2064 7279 5f6f 7264 6572 5b22  ]] = dry_order["
-00009b30: 7072 6963 6522 5d0a 2020 2020 2020 2020  price"].        
-00009b40: 2020 2020 2320 576f 726b 6172 6f75 6e64      # Workaround
-00009b50: 2074 6f20 6176 6f69 6420 6669 6c6c 696e   to avoid fillin
-00009b60: 6720 7374 6f70 6c6f 7373 206f 7264 6572  g stoploss order
-00009b70: 7320 696d 6d65 6469 6174 656c 790a 2020  s immediately.  
-00009b80: 2020 2020 2020 2020 2020 6472 795f 6f72            dry_or
-00009b90: 6465 725b 2266 745f 6f72 6465 725f 7479  der["ft_order_ty
-00009ba0: 7065 225d 203d 2022 7374 6f70 6c6f 7373  pe"] = "stoploss
-00009bb0: 220a 2020 2020 2020 2020 6f72 6465 7262  ".        orderb
-00009bc0: 6f6f 6b3a 204f 7074 696f 6e61 6c5b 4f72  ook: Optional[Or
-00009bd0: 6465 7242 6f6f 6b5d 203d 204e 6f6e 650a  derBook] = None.
-00009be0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00009bf0: 6578 6368 616e 6765 5f68 6173 2827 6665  exchange_has('fe
-00009c00: 7463 684c 324f 7264 6572 426f 6f6b 2729  tchL2OrderBook')
-00009c10: 3a0a 2020 2020 2020 2020 2020 2020 6f72  :.            or
-00009c20: 6465 7262 6f6f 6b20 3d20 7365 6c66 2e66  derbook = self.f
-00009c30: 6574 6368 5f6c 325f 6f72 6465 725f 626f  etch_l2_order_bo
-00009c40: 6f6b 2870 6169 722c 2032 3029 0a20 2020  ok(pair, 20).   
-00009c50: 2020 2020 2069 6620 6f72 6465 7274 7970       if ordertyp
-00009c60: 6520 3d3d 2022 6c69 6d69 7422 2061 6e64  e == "limit" and
-00009c70: 206f 7264 6572 626f 6f6b 3a0a 2020 2020   orderbook:.    
-00009c80: 2020 2020 2020 2020 2320 416c 6c6f 7720          # Allow 
-00009c90: 6120 3125 2070 7269 6365 2064 6966 6665  a 1% price diffe
-00009ca0: 7265 6e63 650a 2020 2020 2020 2020 2020  rence.          
-00009cb0: 2020 616c 6c6f 7765 645f 6469 6666 203d    allowed_diff =
-00009cc0: 2030 2e30 310a 2020 2020 2020 2020 2020   0.01.          
-00009cd0: 2020 6966 2073 656c 662e 5f64 7279 5f69    if self._dry_i
-00009ce0: 735f 7072 6963 655f 6372 6f73 7365 6428  s_price_crossed(
-00009cf0: 7061 6972 2c20 7369 6465 2c20 7261 7465  pair, side, rate
-00009d00: 2c20 6f72 6465 7262 6f6f 6b2c 2061 6c6c  , orderbook, all
-00009d10: 6f77 6564 5f64 6966 6629 3a0a 2020 2020  owed_diff):.    
-00009d20: 2020 2020 2020 2020 2020 2020 6c6f 6767              logg
-00009d30: 6572 2e69 6e66 6f28 0a20 2020 2020 2020  er.info(.       
-00009d40: 2020 2020 2020 2020 2020 2020 2066 2243               f"C
-00009d50: 6f6e 7665 7274 6564 206f 7264 6572 207b  onverted order {
-00009d60: 7061 6972 7d20 746f 206d 6172 6b65 7420  pair} to market 
-00009d70: 6f72 6465 7220 6475 6520 746f 2070 7269  order due to pri
-00009d80: 6365 207b 7261 7465 7d20 6372 6f73 7369  ce {rate} crossi
-00009d90: 6e67 2073 7072 6561 6420 220a 2020 2020  ng spread ".    
-00009da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009db0: 6622 6279 206d 6f72 6520 7468 616e 207b  f"by more than {
-00009dc0: 616c 6c6f 7765 645f 6469 6666 3a2e 3225  allowed_diff:.2%
-00009dd0: 7d2e 2229 0a20 2020 2020 2020 2020 2020  }.").           
-00009de0: 2020 2020 2064 7279 5f6f 7264 6572 5b22       dry_order["
-00009df0: 7479 7065 225d 203d 2022 6d61 726b 6574  type"] = "market
-00009e00: 220a 0a20 2020 2020 2020 2069 6620 6472  "..        if dr
-00009e10: 795f 6f72 6465 725b 2274 7970 6522 5d20  y_order["type"] 
-00009e20: 3d3d 2022 6d61 726b 6574 2220 616e 6420  == "market" and 
-00009e30: 6e6f 7420 6472 795f 6f72 6465 722e 6765  not dry_order.ge
-00009e40: 7428 2266 745f 6f72 6465 725f 7479 7065  t("ft_order_type
-00009e50: 2229 3a0a 2020 2020 2020 2020 2020 2020  "):.            
-00009e60: 2320 5570 6461 7465 206d 6172 6b65 7420  # Update market 
-00009e70: 6f72 6465 7220 7072 6963 696e 670a 2020  order pricing.  
-00009e80: 2020 2020 2020 2020 2020 6176 6572 6167            averag
-00009e90: 6520 3d20 7365 6c66 2e67 6574 5f64 7279  e = self.get_dry
-00009ea0: 5f6d 6172 6b65 745f 6669 6c6c 5f70 7269  _market_fill_pri
-00009eb0: 6365 2870 6169 722c 2073 6964 652c 2061  ce(pair, side, a
-00009ec0: 6d6f 756e 742c 2072 6174 652c 206f 7264  mount, rate, ord
-00009ed0: 6572 626f 6f6b 290a 2020 2020 2020 2020  erbook).        
-00009ee0: 2020 2020 6472 795f 6f72 6465 722e 7570      dry_order.up
-00009ef0: 6461 7465 287b 0a20 2020 2020 2020 2020  date({.         
-00009f00: 2020 2020 2020 2027 6176 6572 6167 6527         'average'
-00009f10: 3a20 6176 6572 6167 652c 0a20 2020 2020  : average,.     
-00009f20: 2020 2020 2020 2020 2020 2027 6669 6c6c             'fill
-00009f30: 6564 273a 205f 616d 6f75 6e74 2c0a 2020  ed': _amount,.  
-00009f40: 2020 2020 2020 2020 2020 2020 2020 2772                'r
-00009f50: 656d 6169 6e69 6e67 273a 2030 2e30 2c0a  emaining': 0.0,.
-00009f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009f70: 2773 7461 7475 7327 3a20 2263 6c6f 7365  'status': "close
-00009f80: 6422 2c0a 2020 2020 2020 2020 2020 2020  d",.            
-00009f90: 2020 2020 2763 6f73 7427 3a20 2864 7279      'cost': (dry
-00009fa0: 5f6f 7264 6572 5b27 616d 6f75 6e74 275d  _order['amount']
-00009fb0: 202a 2061 7665 7261 6765 290a 2020 2020   * average).    
-00009fc0: 2020 2020 2020 2020 7d29 0a20 2020 2020          }).     
-00009fd0: 2020 2020 2020 2023 206d 6172 6b65 7420         # market 
-00009fe0: 6f72 6465 7273 2077 696c 6c20 616c 7761  orders will alwa
-00009ff0: 7973 2069 6e63 7572 7220 7461 6b65 7220  ys incurr taker 
-0000a000: 6665 6573 0a20 2020 2020 2020 2020 2020  fees.           
-0000a010: 2064 7279 5f6f 7264 6572 203d 2073 656c   dry_order = sel
-0000a020: 662e 6164 645f 6472 795f 6f72 6465 725f  f.add_dry_order_
-0000a030: 6665 6528 7061 6972 2c20 6472 795f 6f72  fee(pair, dry_or
-0000a040: 6465 722c 2027 7461 6b65 7227 290a 0a20  der, 'taker').. 
-0000a050: 2020 2020 2020 2064 7279 5f6f 7264 6572         dry_order
-0000a060: 203d 2073 656c 662e 6368 6563 6b5f 6472   = self.check_dr
-0000a070: 795f 6c69 6d69 745f 6f72 6465 725f 6669  y_limit_order_fi
-0000a080: 6c6c 6564 280a 2020 2020 2020 2020 2020  lled(.          
-0000a090: 2020 6472 795f 6f72 6465 722c 2069 6d6d    dry_order, imm
-0000a0a0: 6564 6961 7465 3d54 7275 652c 206f 7264  ediate=True, ord
-0000a0b0: 6572 626f 6f6b 3d6f 7264 6572 626f 6f6b  erbook=orderbook
-0000a0c0: 290a 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-0000a0d0: 5f64 7279 5f72 756e 5f6f 7065 6e5f 6f72  _dry_run_open_or
-0000a0e0: 6465 7273 5b64 7279 5f6f 7264 6572 5b22  ders[dry_order["
-0000a0f0: 6964 225d 5d20 3d20 6472 795f 6f72 6465  id"]] = dry_orde
-0000a100: 720a 2020 2020 2020 2020 2320 436f 7079  r.        # Copy
-0000a110: 206f 7264 6572 2061 6e64 2063 6c6f 7365   order and close
-0000a120: 2069 7420 2d20 736f 2074 6865 2072 6574   it - so the ret
-0000a130: 7572 6e65 6420 6f72 6465 7220 6973 206f  urned order is o
-0000a140: 7065 6e20 756e 6c65 7373 2069 7427 7320  pen unless it's 
-0000a150: 6120 6d61 726b 6574 206f 7264 6572 0a20  a market order. 
-0000a160: 2020 2020 2020 2072 6574 7572 6e20 6472         return dr
-0000a170: 795f 6f72 6465 720a 0a20 2020 2064 6566  y_order..    def
-0000a180: 2061 6464 5f64 7279 5f6f 7264 6572 5f66   add_dry_order_f
-0000a190: 6565 280a 2020 2020 2020 2020 7365 6c66  ee(.        self
-0000a1a0: 2c0a 2020 2020 2020 2020 7061 6972 3a20  ,.        pair: 
-0000a1b0: 7374 722c 0a20 2020 2020 2020 2064 7279  str,.        dry
-0000a1c0: 5f6f 7264 6572 3a20 4469 6374 5b73 7472  _order: Dict[str
-0000a1d0: 2c20 416e 795d 2c0a 2020 2020 2020 2020  , Any],.        
-0000a1e0: 7461 6b65 725f 6f72 5f6d 616b 6572 3a20  taker_or_maker: 
-0000a1f0: 4d61 6b65 7254 616b 6572 2c0a 2020 2020  MakerTaker,.    
-0000a200: 2920 2d3e 2044 6963 745b 7374 722c 2041  ) -> Dict[str, A
-0000a210: 6e79 5d3a 0a20 2020 2020 2020 2066 6565  ny]:.        fee
-0000a220: 203d 2073 656c 662e 6765 745f 6665 6528   = self.get_fee(
-0000a230: 7061 6972 2c20 7461 6b65 725f 6f72 5f6d  pair, taker_or_m
-0000a240: 616b 6572 3d74 616b 6572 5f6f 725f 6d61  aker=taker_or_ma
-0000a250: 6b65 7229 0a20 2020 2020 2020 2064 7279  ker).        dry
-0000a260: 5f6f 7264 6572 2e75 7064 6174 6528 7b0a  _order.update({.
-0000a270: 2020 2020 2020 2020 2020 2020 2766 6565              'fee
-0000a280: 273a 207b 0a20 2020 2020 2020 2020 2020  ': {.           
-0000a290: 2020 2020 2027 6375 7272 656e 6379 273a       'currency':
-0000a2a0: 2073 656c 662e 6765 745f 7061 6972 5f71   self.get_pair_q
-0000a2b0: 756f 7465 5f63 7572 7265 6e63 7928 7061  uote_currency(pa
-0000a2c0: 6972 292c 0a20 2020 2020 2020 2020 2020  ir),.           
-0000a2d0: 2020 2020 2027 636f 7374 273a 2064 7279       'cost': dry
-0000a2e0: 5f6f 7264 6572 5b27 636f 7374 275d 202a  _order['cost'] *
-0000a2f0: 2066 6565 2c0a 2020 2020 2020 2020 2020   fee,.          
-0000a300: 2020 2020 2020 2772 6174 6527 3a20 6665        'rate': fe
-0000a310: 650a 2020 2020 2020 2020 2020 2020 7d0a  e.            }.
-0000a320: 2020 2020 2020 2020 7d29 0a20 2020 2020          }).     
-0000a330: 2020 2072 6574 7572 6e20 6472 795f 6f72     return dry_or
-0000a340: 6465 720a 0a20 2020 2064 6566 2067 6574  der..    def get
-0000a350: 5f64 7279 5f6d 6172 6b65 745f 6669 6c6c  _dry_market_fill
-0000a360: 5f70 7269 6365 2873 656c 662c 2070 6169  _price(self, pai
-0000a370: 723a 2073 7472 2c20 7369 6465 3a20 7374  r: str, side: st
-0000a380: 722c 2061 6d6f 756e 743a 2066 6c6f 6174  r, amount: float
-0000a390: 2c20 7261 7465 3a20 666c 6f61 742c 0a20  , rate: float,. 
-0000a3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a3c0: 206f 7264 6572 626f 6f6b 3a20 4f70 7469   orderbook: Opti
-0000a3d0: 6f6e 616c 5b4f 7264 6572 426f 6f6b 5d29  onal[OrderBook])
-0000a3e0: 202d 3e20 666c 6f61 743a 0a20 2020 2020   -> float:.     
-0000a3f0: 2020 2022 2222 0a20 2020 2020 2020 2047     """.        G
-0000a400: 6574 2074 6865 206d 6172 6b65 7420 6f72  et the market or
-0000a410: 6465 7220 6669 6c6c 2070 7269 6365 2062  der fill price b
-0000a420: 6173 6564 206f 6e20 6f72 6465 7262 6f6f  ased on orderboo
-0000a430: 6b20 696e 7465 7270 6f6c 6174 696f 6e0a  k interpolation.
-0000a440: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-0000a450: 2020 2020 6966 2073 656c 662e 6578 6368      if self.exch
-0000a460: 616e 6765 5f68 6173 2827 6665 7463 684c  ange_has('fetchL
-0000a470: 324f 7264 6572 426f 6f6b 2729 3a0a 2020  2OrderBook'):.  
-0000a480: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
-0000a490: 206f 7264 6572 626f 6f6b 3a0a 2020 2020   orderbook:.    
-0000a4a0: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
-0000a4b0: 7262 6f6f 6b20 3d20 7365 6c66 2e66 6574  rbook = self.fet
-0000a4c0: 6368 5f6c 325f 6f72 6465 725f 626f 6f6b  ch_l2_order_book
-0000a4d0: 2870 6169 722c 2032 3029 0a20 2020 2020  (pair, 20).     
-0000a4e0: 2020 2020 2020 206f 625f 7479 7065 3a20         ob_type: 
-0000a4f0: 4f42 4c69 7465 7261 6c20 3d20 2761 736b  OBLiteral = 'ask
-0000a500: 7327 2069 6620 7369 6465 203d 3d20 2762  s' if side == 'b
-0000a510: 7579 2720 656c 7365 2027 6269 6473 270a  uy' else 'bids'.
-0000a520: 2020 2020 2020 2020 2020 2020 736c 6970              slip
-0000a530: 7061 6765 203d 2030 2e30 350a 2020 2020  page = 0.05.    
-0000a540: 2020 2020 2020 2020 6d61 785f 736c 6970          max_slip
-0000a550: 7061 6765 5f76 616c 203d 2072 6174 6520  page_val = rate 
-0000a560: 2a20 2828 3120 2b20 736c 6970 7061 6765  * ((1 + slippage
-0000a570: 2920 6966 2073 6964 6520 3d3d 2027 6275  ) if side == 'bu
-0000a580: 7927 2065 6c73 6520 2831 202d 2073 6c69  y' else (1 - sli
-0000a590: 7070 6167 6529 290a 0a20 2020 2020 2020  ppage))..       
-0000a5a0: 2020 2020 2072 656d 6169 6e69 6e67 5f61       remaining_a
-0000a5b0: 6d6f 756e 7420 3d20 616d 6f75 6e74 0a20  mount = amount. 
-0000a5c0: 2020 2020 2020 2020 2020 2066 696c 6c65             fille
-0000a5d0: 645f 7661 6c75 6520 3d20 302e 300a 2020  d_value = 0.0.  
-0000a5e0: 2020 2020 2020 2020 2020 626f 6f6b 5f65            book_e
-0000a5f0: 6e74 7279 5f70 7269 6365 203d 2030 2e30  ntry_price = 0.0
-0000a600: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-0000a610: 2062 6f6f 6b5f 656e 7472 7920 696e 206f   book_entry in o
-0000a620: 7264 6572 626f 6f6b 5b6f 625f 7479 7065  rderbook[ob_type
-0000a630: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
-0000a640: 2020 2062 6f6f 6b5f 656e 7472 795f 7072     book_entry_pr
-0000a650: 6963 6520 3d20 626f 6f6b 5f65 6e74 7279  ice = book_entry
-0000a660: 5b30 5d0a 2020 2020 2020 2020 2020 2020  [0].            
-0000a670: 2020 2020 626f 6f6b 5f65 6e74 7279 5f63      book_entry_c
-0000a680: 6f69 6e5f 766f 6c75 6d65 203d 2062 6f6f  oin_volume = boo
-0000a690: 6b5f 656e 7472 795b 315d 0a20 2020 2020  k_entry[1].     
-0000a6a0: 2020 2020 2020 2020 2020 2069 6620 7265             if re
-0000a6b0: 6d61 696e 696e 675f 616d 6f75 6e74 203e  maining_amount >
-0000a6c0: 2030 3a0a 2020 2020 2020 2020 2020 2020   0:.            
-0000a6d0: 2020 2020 2020 2020 6966 2072 656d 6169          if remai
-0000a6e0: 6e69 6e67 5f61 6d6f 756e 7420 3c20 626f  ning_amount < bo
-0000a6f0: 6f6b 5f65 6e74 7279 5f63 6f69 6e5f 766f  ok_entry_coin_vo
-0000a700: 6c75 6d65 3a0a 2020 2020 2020 2020 2020  lume:.          
-0000a710: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0000a720: 4f72 6465 7262 6f6f 6b20 6174 2074 6869  Orderbook at thi
-0000a730: 7320 736c 6f74 2062 6967 6765 7220 7468  s slot bigger th
-0000a740: 616e 2072 656d 6169 6e69 6e67 2061 6d6f  an remaining amo
-0000a750: 756e 740a 2020 2020 2020 2020 2020 2020  unt.            
-0000a760: 2020 2020 2020 2020 2020 2020 6669 6c6c              fill
-0000a770: 6564 5f76 616c 7565 202b 3d20 7265 6d61  ed_value += rema
-0000a780: 696e 696e 675f 616d 6f75 6e74 202a 2062  ining_amount * b
-0000a790: 6f6f 6b5f 656e 7472 795f 7072 6963 650a  ook_entry_price.
-0000a7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a7b0: 2020 2020 2020 2020 6272 6561 6b0a 2020          break.  
-0000a7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a7d0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0000a7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a7f0: 6669 6c6c 6564 5f76 616c 7565 202b 3d20  filled_value += 
-0000a800: 626f 6f6b 5f65 6e74 7279 5f63 6f69 6e5f  book_entry_coin_
-0000a810: 766f 6c75 6d65 202a 2062 6f6f 6b5f 656e  volume * book_en
-0000a820: 7472 795f 7072 6963 650a 2020 2020 2020  try_price.      
-0000a830: 2020 2020 2020 2020 2020 2020 2020 7265                re
-0000a840: 6d61 696e 696e 675f 616d 6f75 6e74 202d  maining_amount -
-0000a850: 3d20 626f 6f6b 5f65 6e74 7279 5f63 6f69  = book_entry_coi
-0000a860: 6e5f 766f 6c75 6d65 0a20 2020 2020 2020  n_volume.       
-0000a870: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-0000a880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a890: 2020 2062 7265 616b 0a20 2020 2020 2020     break.       
-0000a8a0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-0000a8b0: 2020 2020 2020 2020 2020 2023 2049 6620             # If 
-0000a8c0: 7265 6d61 696e 696e 675f 616d 6f75 6e74  remaining_amount
-0000a8d0: 2077 6173 6e27 7420 636f 6e73 756d 6564   wasn't consumed
-0000a8e0: 2063 6f6d 706c 6574 656c 7920 2862 7265   completely (bre
-0000a8f0: 616b 2077 6173 206e 6f74 2063 616c 6c65  ak was not calle
-0000a900: 6429 0a20 2020 2020 2020 2020 2020 2020  d).             
-0000a910: 2020 2066 696c 6c65 645f 7661 6c75 6520     filled_value 
-0000a920: 2b3d 2072 656d 6169 6e69 6e67 5f61 6d6f  += remaining_amo
-0000a930: 756e 7420 2a20 626f 6f6b 5f65 6e74 7279  unt * book_entry
-0000a940: 5f70 7269 6365 0a20 2020 2020 2020 2020  _price.         
-0000a950: 2020 2066 6f72 6563 6173 745f 6176 675f     forecast_avg_
-0000a960: 6669 6c6c 6564 5f70 7269 6365 203d 206d  filled_price = m
-0000a970: 6178 2866 696c 6c65 645f 7661 6c75 652c  ax(filled_value,
-0000a980: 2030 2920 2f20 616d 6f75 6e74 0a20 2020   0) / amount.   
-0000a990: 2020 2020 2020 2020 2023 204c 696d 6974           # Limit
-0000a9a0: 206d 6178 2e20 736c 6970 7061 6765 2074   max. slippage t
-0000a9b0: 6f20 7370 6563 6966 6965 6420 7661 6c75  o specified valu
-0000a9c0: 650a 2020 2020 2020 2020 2020 2020 6966  e.            if
-0000a9d0: 2073 6964 6520 3d3d 2027 6275 7927 3a0a   side == 'buy':.
-0000a9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a9f0: 666f 7265 6361 7374 5f61 7667 5f66 696c  forecast_avg_fil
-0000aa00: 6c65 645f 7072 6963 6520 3d20 6d69 6e28  led_price = min(
-0000aa10: 666f 7265 6361 7374 5f61 7667 5f66 696c  forecast_avg_fil
-0000aa20: 6c65 645f 7072 6963 652c 206d 6178 5f73  led_price, max_s
-0000aa30: 6c69 7070 6167 655f 7661 6c29 0a0a 2020  lippage_val)..  
-0000aa40: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-0000aa50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000aa60: 666f 7265 6361 7374 5f61 7667 5f66 696c  forecast_avg_fil
-0000aa70: 6c65 645f 7072 6963 6520 3d20 6d61 7828  led_price = max(
-0000aa80: 666f 7265 6361 7374 5f61 7667 5f66 696c  forecast_avg_fil
-0000aa90: 6c65 645f 7072 6963 652c 206d 6178 5f73  led_price, max_s
-0000aaa0: 6c69 7070 6167 655f 7661 6c29 0a0a 2020  lippage_val)..  
-0000aab0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0000aac0: 2073 656c 662e 7072 6963 655f 746f 5f70   self.price_to_p
-0000aad0: 7265 6369 7369 6f6e 2870 6169 722c 2066  recision(pair, f
-0000aae0: 6f72 6563 6173 745f 6176 675f 6669 6c6c  orecast_avg_fill
-0000aaf0: 6564 5f70 7269 6365 290a 0a20 2020 2020  ed_price)..     
-0000ab00: 2020 2072 6574 7572 6e20 7261 7465 0a0a     return rate..
-0000ab10: 2020 2020 6465 6620 5f64 7279 5f69 735f      def _dry_is_
-0000ab20: 7072 6963 655f 6372 6f73 7365 6428 7365  price_crossed(se
-0000ab30: 6c66 2c20 7061 6972 3a20 7374 722c 2073  lf, pair: str, s
-0000ab40: 6964 653a 2073 7472 2c20 6c69 6d69 743a  ide: str, limit:
-0000ab50: 2066 6c6f 6174 2c0a 2020 2020 2020 2020   float,.        
-0000ab60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ab70: 2020 2020 2020 6f72 6465 7262 6f6f 6b3a        orderbook:
-0000ab80: 204f 7074 696f 6e61 6c5b 4f72 6465 7242   Optional[OrderB
-0000ab90: 6f6f 6b5d 203d 204e 6f6e 652c 206f 6666  ook] = None, off
-0000aba0: 7365 743a 2066 6c6f 6174 203d 2030 2e30  set: float = 0.0
-0000abb0: 2920 2d3e 2062 6f6f 6c3a 0a20 2020 2020  ) -> bool:.     
-0000abc0: 2020 2069 6620 6e6f 7420 7365 6c66 2e65     if not self.e
-0000abd0: 7863 6861 6e67 655f 6861 7328 2766 6574  xchange_has('fet
-0000abe0: 6368 4c32 4f72 6465 7242 6f6f 6b27 293a  chL2OrderBook'):
-0000abf0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0000ac00: 7572 6e20 5472 7565 0a20 2020 2020 2020  urn True.       
-0000ac10: 2069 6620 6e6f 7420 6f72 6465 7262 6f6f   if not orderboo
-0000ac20: 6b3a 0a20 2020 2020 2020 2020 2020 206f  k:.            o
-0000ac30: 7264 6572 626f 6f6b 203d 2073 656c 662e  rderbook = self.
-0000ac40: 6665 7463 685f 6c32 5f6f 7264 6572 5f62  fetch_l2_order_b
-0000ac50: 6f6f 6b28 7061 6972 2c20 3129 0a20 2020  ook(pair, 1).   
-0000ac60: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
-0000ac70: 2020 2020 2020 6966 2073 6964 6520 3d3d        if side ==
-0000ac80: 2027 6275 7927 3a0a 2020 2020 2020 2020   'buy':.        
-0000ac90: 2020 2020 2020 2020 7072 6963 6520 3d20          price = 
-0000aca0: 6f72 6465 7262 6f6f 6b5b 2761 736b 7327  orderbook['asks'
-0000acb0: 5d5b 305d 5b30 5d0a 2020 2020 2020 2020  ][0][0].        
-0000acc0: 2020 2020 2020 2020 6966 206c 696d 6974          if limit
-0000acd0: 202a 2028 3120 2d20 6f66 6673 6574 2920   * (1 - offset) 
-0000ace0: 3e3d 2070 7269 6365 3a0a 2020 2020 2020  >= price:.      
-0000acf0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-0000ad00: 7475 726e 2054 7275 650a 2020 2020 2020  turn True.      
-0000ad10: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-0000ad20: 2020 2020 2020 2020 2020 2020 7072 6963              pric
-0000ad30: 6520 3d20 6f72 6465 7262 6f6f 6b5b 2762  e = orderbook['b
-0000ad40: 6964 7327 5d5b 305d 5b30 5d0a 2020 2020  ids'][0][0].    
-0000ad50: 2020 2020 2020 2020 2020 2020 6966 206c              if l
-0000ad60: 696d 6974 202a 2028 3120 2b20 6f66 6673  imit * (1 + offs
-0000ad70: 6574 2920 3c3d 2070 7269 6365 3a0a 2020  et) <= price:.  
-0000ad80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ad90: 2020 7265 7475 726e 2054 7275 650a 2020    return True.  
-0000ada0: 2020 2020 2020 6578 6365 7074 2049 6e64        except Ind
-0000adb0: 6578 4572 726f 723a 0a20 2020 2020 2020  exError:.       
-0000adc0: 2020 2020 2023 2049 676e 6f72 6520 656d       # Ignore em
-0000add0: 7074 7920 6f72 6465 7262 6f6f 6b73 2077  pty orderbooks w
-0000ade0: 6865 6e20 6669 6c6c 696e 6720 2d20 6361  hen filling - ca
-0000adf0: 6e20 6265 2066 696c 6c65 6420 7769 7468  n be filled with
-0000ae00: 2074 6865 206e 6578 7420 6974 6572 6174   the next iterat
-0000ae10: 696f 6e2e 0a20 2020 2020 2020 2020 2020  ion..           
-0000ae20: 2070 6173 730a 2020 2020 2020 2020 7265   pass.        re
-0000ae30: 7475 726e 2046 616c 7365 0a0a 2020 2020  turn False..    
-0000ae40: 6465 6620 6368 6563 6b5f 6472 795f 6c69  def check_dry_li
-0000ae50: 6d69 745f 6f72 6465 725f 6669 6c6c 6564  mit_order_filled
-0000ae60: 280a 2020 2020 2020 2020 2020 2020 7365  (.            se
-0000ae70: 6c66 2c20 6f72 6465 723a 2044 6963 745b  lf, order: Dict[
-0000ae80: 7374 722c 2041 6e79 5d2c 2069 6d6d 6564  str, Any], immed
-0000ae90: 6961 7465 3a20 626f 6f6c 203d 2046 616c  iate: bool = Fal
-0000aea0: 7365 2c0a 2020 2020 2020 2020 2020 2020  se,.            
-0000aeb0: 6f72 6465 7262 6f6f 6b3a 204f 7074 696f  orderbook: Optio
-0000aec0: 6e61 6c5b 4f72 6465 7242 6f6f 6b5d 203d  nal[OrderBook] =
-0000aed0: 204e 6f6e 6529 202d 3e20 4469 6374 5b73   None) -> Dict[s
-0000aee0: 7472 2c20 416e 795d 3a0a 2020 2020 2020  tr, Any]:.      
-0000aef0: 2020 2222 220a 2020 2020 2020 2020 4368    """.        Ch
-0000af00: 6563 6b20 6472 792d 7275 6e20 6c69 6d69  eck dry-run limi
-0000af10: 7420 6f72 6465 7220 6669 6c6c 2061 6e64  t order fill and
-0000af20: 2075 7064 6174 6520 6665 6520 2869 6620   update fee (if 
-0000af30: 6974 2066 696c 6c65 6429 2e0a 2020 2020  it filled)..    
-0000af40: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-0000af50: 6966 2028 6f72 6465 725b 2773 7461 7475  if (order['statu
-0000af60: 7327 5d20 213d 2022 636c 6f73 6564 220a  s'] != "closed".
-0000af70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000af80: 616e 6420 6f72 6465 725b 2774 7970 6527  and order['type'
-0000af90: 5d20 696e 205b 226c 696d 6974 225d 0a20  ] in ["limit"]. 
-0000afa0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-0000afb0: 6e64 206e 6f74 206f 7264 6572 2e67 6574  nd not order.get
-0000afc0: 2827 6674 5f6f 7264 6572 5f74 7970 6527  ('ft_order_type'
-0000afd0: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
-0000afe0: 7061 6972 203d 206f 7264 6572 5b27 7379  pair = order['sy
-0000aff0: 6d62 6f6c 275d 0a20 2020 2020 2020 2020  mbol'].         
-0000b000: 2020 2069 6620 7365 6c66 2e5f 6472 795f     if self._dry_
-0000b010: 6973 5f70 7269 6365 5f63 726f 7373 6564  is_price_crossed
-0000b020: 2870 6169 722c 206f 7264 6572 5b27 7369  (pair, order['si
-0000b030: 6465 275d 2c20 6f72 6465 725b 2770 7269  de'], order['pri
-0000b040: 6365 275d 2c20 6f72 6465 7262 6f6f 6b29  ce'], orderbook)
-0000b050: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000b060: 2020 6f72 6465 722e 7570 6461 7465 287b    order.update({
-0000b070: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b080: 2020 2020 2027 7374 6174 7573 273a 2027       'status': '
-0000b090: 636c 6f73 6564 272c 0a20 2020 2020 2020  closed',.       
-0000b0a0: 2020 2020 2020 2020 2020 2020 2027 6669               'fi
-0000b0b0: 6c6c 6564 273a 206f 7264 6572 5b27 616d  lled': order['am
-0000b0c0: 6f75 6e74 275d 2c0a 2020 2020 2020 2020  ount'],.        
-0000b0d0: 2020 2020 2020 2020 2020 2020 2772 656d              'rem
-0000b0e0: 6169 6e69 6e67 273a 2030 2c0a 2020 2020  aining': 0,.    
-0000b0f0: 2020 2020 2020 2020 2020 2020 7d29 0a0a              })..
-0000b100: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b110: 7365 6c66 2e61 6464 5f64 7279 5f6f 7264  self.add_dry_ord
-0000b120: 6572 5f66 6565 280a 2020 2020 2020 2020  er_fee(.        
-0000b130: 2020 2020 2020 2020 2020 2020 7061 6972              pair
-0000b140: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000b150: 2020 2020 2020 6f72 6465 722c 0a20 2020        order,.   
-0000b160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b170: 2027 7461 6b65 7227 2069 6620 696d 6d65   'taker' if imme
-0000b180: 6469 6174 6520 656c 7365 2027 6d61 6b65  diate else 'make
-0000b190: 7227 2c0a 2020 2020 2020 2020 2020 2020  r',.            
-0000b1a0: 2020 2020 290a 0a20 2020 2020 2020 2072      )..        r
-0000b1b0: 6574 7572 6e20 6f72 6465 720a 0a20 2020  eturn order..   
-0000b1c0: 2064 6566 2066 6574 6368 5f64 7279 5f72   def fetch_dry_r
-0000b1d0: 756e 5f6f 7264 6572 2873 656c 662c 206f  un_order(self, o
-0000b1e0: 7264 6572 5f69 6429 202d 3e20 4469 6374  rder_id) -> Dict
-0000b1f0: 5b73 7472 2c20 416e 795d 3a0a 2020 2020  [str, Any]:.    
-0000b200: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-0000b210: 5265 7475 726e 2064 7279 2d72 756e 206f  Return dry-run o
-0000b220: 7264 6572 0a20 2020 2020 2020 204f 6e6c  rder.        Onl
-0000b230: 7920 6361 6c6c 2069 6620 7275 6e6e 696e  y call if runnin
-0000b240: 6720 696e 2064 7279 2d72 756e 206d 6f64  g in dry-run mod
-0000b250: 652e 0a20 2020 2020 2020 2022 2222 0a20  e..        """. 
-0000b260: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000b270: 2020 2020 2020 2020 6f72 6465 7220 3d20          order = 
-0000b280: 7365 6c66 2e5f 6472 795f 7275 6e5f 6f70  self._dry_run_op
-0000b290: 656e 5f6f 7264 6572 735b 6f72 6465 725f  en_orders[order_
-0000b2a0: 6964 5d0a 2020 2020 2020 2020 2020 2020  id].            
-0000b2b0: 6f72 6465 7220 3d20 7365 6c66 2e63 6865  order = self.che
-0000b2c0: 636b 5f64 7279 5f6c 696d 6974 5f6f 7264  ck_dry_limit_ord
-0000b2d0: 6572 5f66 696c 6c65 6428 6f72 6465 7229  er_filled(order)
-0000b2e0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0000b2f0: 7572 6e20 6f72 6465 720a 2020 2020 2020  urn order.      
-0000b300: 2020 6578 6365 7074 204b 6579 4572 726f    except KeyErro
-0000b310: 7220 6173 2065 3a0a 2020 2020 2020 2020  r as e:.        
-0000b320: 2020 2020 6672 6f6d 2066 7265 7174 7261      from freqtra
-0000b330: 6465 2e70 6572 7369 7374 656e 6365 2069  de.persistence i
-0000b340: 6d70 6f72 7420 4f72 6465 720a 2020 2020  mport Order.    
-0000b350: 2020 2020 2020 2020 6f72 6465 7220 3d20          order = 
-0000b360: 4f72 6465 722e 6f72 6465 725f 6279 5f69  Order.order_by_i
-0000b370: 6428 6f72 6465 725f 6964 290a 2020 2020  d(order_id).    
-0000b380: 2020 2020 2020 2020 6966 206f 7264 6572          if order
-0000b390: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000b3a0: 2020 6363 7874 5f6f 7264 6572 203d 206f    ccxt_order = o
-0000b3b0: 7264 6572 2e74 6f5f 6363 7874 5f6f 626a  rder.to_ccxt_obj
-0000b3c0: 6563 7428 7365 6c66 2e5f 6674 5f68 6173  ect(self._ft_has
-0000b3d0: 5b27 7374 6f70 5f70 7269 6365 5f70 726f  ['stop_price_pro
-0000b3e0: 7027 5d29 0a20 2020 2020 2020 2020 2020  p']).           
-0000b3f0: 2020 2020 2073 656c 662e 5f64 7279 5f72       self._dry_r
-0000b400: 756e 5f6f 7065 6e5f 6f72 6465 7273 5b6f  un_open_orders[o
-0000b410: 7264 6572 5f69 645d 203d 2063 6378 745f  rder_id] = ccxt_
-0000b420: 6f72 6465 720a 2020 2020 2020 2020 2020  order.          
-0000b430: 2020 2020 2020 7265 7475 726e 2063 6378        return ccx
-0000b440: 745f 6f72 6465 720a 2020 2020 2020 2020  t_order.        
-0000b450: 2020 2020 2320 4772 6163 6566 756c 6c79      # Gracefully
-0000b460: 2068 616e 646c 6520 6572 726f 7273 2077   handle errors w
-0000b470: 6974 6820 6472 792d 7275 6e20 6f72 6465  ith dry-run orde
-0000b480: 7273 2e0a 2020 2020 2020 2020 2020 2020  rs..            
-0000b490: 7261 6973 6520 496e 7661 6c69 644f 7264  raise InvalidOrd
-0000b4a0: 6572 4578 6365 7074 696f 6e28 0a20 2020  erException(.   
-0000b4b0: 2020 2020 2020 2020 2020 2020 2066 2754               f'T
-0000b4c0: 7269 6564 2074 6f20 6765 7420 616e 2069  ried to get an i
-0000b4d0: 6e76 616c 6964 2064 7279 2d72 756e 2d6f  nvalid dry-run-o
-0000b4e0: 7264 6572 2028 6964 3a20 7b6f 7264 6572  rder (id: {order
-0000b4f0: 5f69 647d 292e 204d 6573 7361 6765 3a20  _id}). Message: 
-0000b500: 7b65 7d27 2920 6672 6f6d 2065 0a0a 2020  {e}') from e..  
-0000b510: 2020 2320 4f72 6465 7220 6861 6e64 6c69    # Order handli
-0000b520: 6e67 0a0a 2020 2020 6465 6620 5f6c 6576  ng..    def _lev
-0000b530: 5f70 7265 7028 7365 6c66 2c20 7061 6972  _prep(self, pair
-0000b540: 3a20 7374 722c 206c 6576 6572 6167 653a  : str, leverage:
-0000b550: 2066 6c6f 6174 2c20 7369 6465 3a20 4275   float, side: Bu
-0000b560: 7953 656c 6c2c 2061 6363 6570 745f 6661  ySell, accept_fa
-0000b570: 696c 3a20 626f 6f6c 203d 2046 616c 7365  il: bool = False
-0000b580: 293a 0a20 2020 2020 2020 2069 6620 7365  ):.        if se
-0000b590: 6c66 2e74 7261 6469 6e67 5f6d 6f64 6520  lf.trading_mode 
-0000b5a0: 213d 2054 7261 6469 6e67 4d6f 6465 2e53  != TradingMode.S
-0000b5b0: 504f 543a 0a20 2020 2020 2020 2020 2020  POT:.           
-0000b5c0: 2073 656c 662e 7365 745f 6d61 7267 696e   self.set_margin
-0000b5d0: 5f6d 6f64 6528 7061 6972 2c20 7365 6c66  _mode(pair, self
-0000b5e0: 2e6d 6172 6769 6e5f 6d6f 6465 2c20 6163  .margin_mode, ac
-0000b5f0: 6365 7074 5f66 6169 6c29 0a20 2020 2020  cept_fail).     
-0000b600: 2020 2020 2020 2073 656c 662e 5f73 6574         self._set
-0000b610: 5f6c 6576 6572 6167 6528 6c65 7665 7261  _leverage(levera
-0000b620: 6765 2c20 7061 6972 2c20 6163 6365 7074  ge, pair, accept
-0000b630: 5f66 6169 6c29 0a0a 2020 2020 6465 6620  _fail)..    def 
-0000b640: 5f67 6574 5f70 6172 616d 7328 0a20 2020  _get_params(.   
-0000b650: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
-0000b660: 2020 2073 6964 653a 2042 7579 5365 6c6c     side: BuySell
-0000b670: 2c0a 2020 2020 2020 2020 6f72 6465 7274  ,.        ordert
-0000b680: 7970 653a 2073 7472 2c0a 2020 2020 2020  ype: str,.      
-0000b690: 2020 6c65 7665 7261 6765 3a20 666c 6f61    leverage: floa
-0000b6a0: 742c 0a20 2020 2020 2020 2072 6564 7563  t,.        reduc
-0000b6b0: 654f 6e6c 793a 2062 6f6f 6c2c 0a20 2020  eOnly: bool,.   
-0000b6c0: 2020 2020 2074 696d 655f 696e 5f66 6f72       time_in_for
-0000b6d0: 6365 3a20 7374 7220 3d20 2747 5443 272c  ce: str = 'GTC',
-0000b6e0: 0a20 2020 2029 202d 3e20 4469 6374 3a0a  .    ) -> Dict:.
-0000b6f0: 2020 2020 2020 2020 7061 7261 6d73 203d          params =
-0000b700: 2073 656c 662e 5f70 6172 616d 732e 636f   self._params.co
-0000b710: 7079 2829 0a20 2020 2020 2020 2069 6620  py().        if 
-0000b720: 7469 6d65 5f69 6e5f 666f 7263 6520 213d  time_in_force !=
-0000b730: 2027 4754 4327 2061 6e64 206f 7264 6572   'GTC' and order
-0000b740: 7479 7065 2021 3d20 276d 6172 6b65 7427  type != 'market'
-0000b750: 3a0a 2020 2020 2020 2020 2020 2020 7061  :.            pa
-0000b760: 7261 6d73 2e75 7064 6174 6528 7b27 7469  rams.update({'ti
-0000b770: 6d65 496e 466f 7263 6527 3a20 7469 6d65  meInForce': time
-0000b780: 5f69 6e5f 666f 7263 652e 7570 7065 7228  _in_force.upper(
-0000b790: 297d 290a 2020 2020 2020 2020 6966 2072  )}).        if r
-0000b7a0: 6564 7563 654f 6e6c 793a 0a20 2020 2020  educeOnly:.     
-0000b7b0: 2020 2020 2020 2070 6172 616d 732e 7570         params.up
-0000b7c0: 6461 7465 287b 2772 6564 7563 654f 6e6c  date({'reduceOnl
-0000b7d0: 7927 3a20 5472 7565 7d29 0a20 2020 2020  y': True}).     
-0000b7e0: 2020 2072 6574 7572 6e20 7061 7261 6d73     return params
-0000b7f0: 0a0a 2020 2020 6465 6620 5f6f 7264 6572  ..    def _order
-0000b800: 5f6e 6565 6473 5f70 7269 6365 2873 656c  _needs_price(sel
-0000b810: 662c 206f 7264 6572 7479 7065 3a20 7374  f, ordertype: st
-0000b820: 7229 202d 3e20 626f 6f6c 3a0a 2020 2020  r) -> bool:.    
-0000b830: 2020 2020 7265 7475 726e 2028 0a20 2020      return (.   
-0000b840: 2020 2020 2020 2020 206f 7264 6572 7479           orderty
-0000b850: 7065 2021 3d20 276d 6172 6b65 7427 0a20  pe != 'market'. 
-0000b860: 2020 2020 2020 2020 2020 206f 7220 7365             or se
-0000b870: 6c66 2e5f 6170 692e 6f70 7469 6f6e 732e  lf._api.options.
-0000b880: 6765 7428 2263 7265 6174 654d 6172 6b65  get("createMarke
-0000b890: 7442 7579 4f72 6465 7252 6571 7569 7265  tBuyOrderRequire
-0000b8a0: 7350 7269 6365 222c 2046 616c 7365 290a  sPrice", False).
-0000b8b0: 2020 2020 2020 2020 2020 2020 6f72 2073              or s
-0000b8c0: 656c 662e 5f66 745f 6861 732e 6765 7428  elf._ft_has.get(
-0000b8d0: 276d 6172 6b65 744f 7264 6572 5265 7175  'marketOrderRequ
-0000b8e0: 6972 6573 5072 6963 6527 2c20 4661 6c73  iresPrice', Fals
-0000b8f0: 6529 0a20 2020 2020 2020 2029 0a0a 2020  e).        )..  
-0000b900: 2020 6465 6620 6372 6561 7465 5f6f 7264    def create_ord
-0000b910: 6572 280a 2020 2020 2020 2020 7365 6c66  er(.        self
-0000b920: 2c0a 2020 2020 2020 2020 2a2c 0a20 2020  ,.        *,.   
-0000b930: 2020 2020 2070 6169 723a 2073 7472 2c0a       pair: str,.
-0000b940: 2020 2020 2020 2020 6f72 6465 7274 7970          ordertyp
-0000b950: 653a 2073 7472 2c0a 2020 2020 2020 2020  e: str,.        
-0000b960: 7369 6465 3a20 4275 7953 656c 6c2c 0a20  side: BuySell,. 
-0000b970: 2020 2020 2020 2061 6d6f 756e 743a 2066         amount: f
-0000b980: 6c6f 6174 2c0a 2020 2020 2020 2020 7261  loat,.        ra
-0000b990: 7465 3a20 666c 6f61 742c 0a20 2020 2020  te: float,.     
-0000b9a0: 2020 206c 6576 6572 6167 653a 2066 6c6f     leverage: flo
-0000b9b0: 6174 2c0a 2020 2020 2020 2020 7265 6475  at,.        redu
-0000b9c0: 6365 4f6e 6c79 3a20 626f 6f6c 203d 2046  ceOnly: bool = F
-0000b9d0: 616c 7365 2c0a 2020 2020 2020 2020 7469  alse,.        ti
-0000b9e0: 6d65 5f69 6e5f 666f 7263 653a 2073 7472  me_in_force: str
-0000b9f0: 203d 2027 4754 4327 2c0a 2020 2020 2920   = 'GTC',.    ) 
-0000ba00: 2d3e 2044 6963 743a 0a20 2020 2020 2020  -> Dict:.       
-0000ba10: 2069 6620 7365 6c66 2e5f 636f 6e66 6967   if self._config
-0000ba20: 5b27 6472 795f 7275 6e27 5d3a 0a20 2020  ['dry_run']:.   
-0000ba30: 2020 2020 2020 2020 2064 7279 5f6f 7264           dry_ord
-0000ba40: 6572 203d 2073 656c 662e 6372 6561 7465  er = self.create
-0000ba50: 5f64 7279 5f72 756e 5f6f 7264 6572 280a  _dry_run_order(.
-0000ba60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ba70: 7061 6972 2c20 6f72 6465 7274 7970 652c  pair, ordertype,
-0000ba80: 2073 6964 652c 2061 6d6f 756e 742c 2073   side, amount, s
-0000ba90: 656c 662e 7072 6963 655f 746f 5f70 7265  elf.price_to_pre
-0000baa0: 6369 7369 6f6e 2870 6169 722c 2072 6174  cision(pair, rat
-0000bab0: 6529 2c20 6c65 7665 7261 6765 290a 2020  e), leverage).  
-0000bac0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0000bad0: 2064 7279 5f6f 7264 6572 0a0a 2020 2020   dry_order..    
-0000bae0: 2020 2020 7061 7261 6d73 203d 2073 656c      params = sel
-0000baf0: 662e 5f67 6574 5f70 6172 616d 7328 7369  f._get_params(si
-0000bb00: 6465 2c20 6f72 6465 7274 7970 652c 206c  de, ordertype, l
-0000bb10: 6576 6572 6167 652c 2072 6564 7563 654f  everage, reduceO
-0000bb20: 6e6c 792c 2074 696d 655f 696e 5f66 6f72  nly, time_in_for
-0000bb30: 6365 290a 0a20 2020 2020 2020 2074 7279  ce)..        try
-0000bb40: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
-0000bb50: 5365 7420 7468 6520 7072 6563 6973 696f  Set the precisio
-0000bb60: 6e20 666f 7220 616d 6f75 6e74 2061 6e64  n for amount and
-0000bb70: 2070 7269 6365 2872 6174 6529 2061 7320   price(rate) as 
-0000bb80: 6163 6365 7074 6564 2062 7920 7468 6520  accepted by the 
-0000bb90: 6578 6368 616e 6765 0a20 2020 2020 2020  exchange.       
-0000bba0: 2020 2020 2061 6d6f 756e 7420 3d20 7365       amount = se
-0000bbb0: 6c66 2e61 6d6f 756e 745f 746f 5f70 7265  lf.amount_to_pre
-0000bbc0: 6369 7369 6f6e 2870 6169 722c 2073 656c  cision(pair, sel
-0000bbd0: 662e 5f61 6d6f 756e 745f 746f 5f63 6f6e  f._amount_to_con
-0000bbe0: 7472 6163 7473 2870 6169 722c 2061 6d6f  tracts(pair, amo
-0000bbf0: 756e 7429 290a 2020 2020 2020 2020 2020  unt)).          
-0000bc00: 2020 6e65 6564 735f 7072 6963 6520 3d20    needs_price = 
-0000bc10: 7365 6c66 2e5f 6f72 6465 725f 6e65 6564  self._order_need
-0000bc20: 735f 7072 6963 6528 6f72 6465 7274 7970  s_price(ordertyp
-0000bc30: 6529 0a20 2020 2020 2020 2020 2020 2072  e).            r
-0000bc40: 6174 655f 666f 725f 6f72 6465 7220 3d20  ate_for_order = 
-0000bc50: 7365 6c66 2e70 7269 6365 5f74 6f5f 7072  self.price_to_pr
-0000bc60: 6563 6973 696f 6e28 7061 6972 2c20 7261  ecision(pair, ra
-0000bc70: 7465 2920 6966 206e 6565 6473 5f70 7269  te) if needs_pri
-0000bc80: 6365 2065 6c73 6520 4e6f 6e65 0a0a 2020  ce else None..  
-0000bc90: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
-0000bca0: 2072 6564 7563 654f 6e6c 793a 0a20 2020   reduceOnly:.   
-0000bcb0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-0000bcc0: 662e 5f6c 6576 5f70 7265 7028 7061 6972  f._lev_prep(pair
-0000bcd0: 2c20 6c65 7665 7261 6765 2c20 7369 6465  , leverage, side
-0000bce0: 290a 0a20 2020 2020 2020 2020 2020 206f  )..            o
-0000bcf0: 7264 6572 203d 2073 656c 662e 5f61 7069  rder = self._api
-0000bd00: 2e63 7265 6174 655f 6f72 6465 7228 0a20  .create_order(. 
-0000bd10: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-0000bd20: 6169 722c 0a20 2020 2020 2020 2020 2020  air,.           
-0000bd30: 2020 2020 206f 7264 6572 7479 7065 2c0a       ordertype,.
-0000bd40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bd50: 7369 6465 2c0a 2020 2020 2020 2020 2020  side,.          
-0000bd60: 2020 2020 2020 616d 6f75 6e74 2c0a 2020        amount,.  
-0000bd70: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-0000bd80: 7465 5f66 6f72 5f6f 7264 6572 2c0a 2020  te_for_order,.  
-0000bd90: 2020 2020 2020 2020 2020 2020 2020 7061                pa
-0000bda0: 7261 6d73 2c0a 2020 2020 2020 2020 2020  rams,.          
-0000bdb0: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
-0000bdc0: 6966 206f 7264 6572 2e67 6574 2827 7374  if order.get('st
-0000bdd0: 6174 7573 2729 2069 7320 4e6f 6e65 3a0a  atus') is None:.
-0000bde0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bdf0: 2320 4d61 7020 656d 7074 7920 7374 6174  # Map empty stat
-0000be00: 7573 2074 6f20 6f70 656e 2e0a 2020 2020  us to open..    
-0000be10: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
-0000be20: 725b 2773 7461 7475 7327 5d20 3d20 276f  r['status'] = 'o
-0000be30: 7065 6e27 0a0a 2020 2020 2020 2020 2020  pen'..          
-0000be40: 2020 6966 206f 7264 6572 2e67 6574 2827    if order.get('
-0000be50: 7479 7065 2729 2069 7320 4e6f 6e65 3a0a  type') is None:.
-0000be60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000be70: 6f72 6465 725b 2774 7970 6527 5d20 3d20  order['type'] = 
-0000be80: 6f72 6465 7274 7970 650a 0a20 2020 2020  ordertype..     
-0000be90: 2020 2020 2020 2073 656c 662e 5f6c 6f67         self._log
-0000bea0: 5f65 7863 6861 6e67 655f 7265 7370 6f6e  _exchange_respon
-0000beb0: 7365 2827 6372 6561 7465 5f6f 7264 6572  se('create_order
-0000bec0: 272c 206f 7264 6572 290a 2020 2020 2020  ', order).      
-0000bed0: 2020 2020 2020 6f72 6465 7220 3d20 7365        order = se
-0000bee0: 6c66 2e5f 6f72 6465 725f 636f 6e74 7261  lf._order_contra
-0000bef0: 6374 735f 746f 5f61 6d6f 756e 7428 6f72  cts_to_amount(or
-0000bf00: 6465 7229 0a20 2020 2020 2020 2020 2020  der).           
-0000bf10: 2072 6574 7572 6e20 6f72 6465 720a 0a20   return order.. 
-0000bf20: 2020 2020 2020 2065 7863 6570 7420 6363         except cc
-0000bf30: 7874 2e49 6e73 7566 6669 6369 656e 7446  xt.InsufficientF
-0000bf40: 756e 6473 2061 7320 653a 0a20 2020 2020  unds as e:.     
-0000bf50: 2020 2020 2020 2072 6169 7365 2049 6e73         raise Ins
-0000bf60: 7566 6669 6369 656e 7446 756e 6473 4572  ufficientFundsEr
-0000bf70: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
-0000bf80: 2020 2020 2066 2749 6e73 7566 6669 6369       f'Insuffici
-0000bf90: 656e 7420 6675 6e64 7320 746f 2063 7265  ent funds to cre
-0000bfa0: 6174 6520 7b6f 7264 6572 7479 7065 7d20  ate {ordertype} 
-0000bfb0: 7b73 6964 657d 206f 7264 6572 206f 6e20  {side} order on 
-0000bfc0: 6d61 726b 6574 207b 7061 6972 7d2e 2027  market {pair}. '
-0000bfd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000bfe0: 2066 2754 7269 6564 2074 6f20 7b73 6964   f'Tried to {sid
-0000bff0: 657d 2061 6d6f 756e 7420 7b61 6d6f 756e  e} amount {amoun
-0000c000: 747d 2061 7420 7261 7465 207b 7261 7465  t} at rate {rate
-0000c010: 7d2e 270a 2020 2020 2020 2020 2020 2020  }.'.            
-0000c020: 2020 2020 6627 4d65 7373 6167 653a 207b      f'Message: {
-0000c030: 657d 2729 2066 726f 6d20 650a 2020 2020  e}') from e.    
-0000c040: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
-0000c050: 496e 7661 6c69 644f 7264 6572 2061 7320  InvalidOrder as 
-0000c060: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
-0000c070: 6169 7365 2049 6e76 616c 6964 4f72 6465  aise InvalidOrde
-0000c080: 7245 7863 6570 7469 6f6e 280a 2020 2020  rException(.    
-0000c090: 2020 2020 2020 2020 2020 2020 6627 436f              f'Co
-0000c0a0: 756c 6420 6e6f 7420 6372 6561 7465 207b  uld not create {
-0000c0b0: 6f72 6465 7274 7970 657d 207b 7369 6465  ordertype} {side
-0000c0c0: 7d20 6f72 6465 7220 6f6e 206d 6172 6b65  } order on marke
-0000c0d0: 7420 7b70 6169 727d 2e20 270a 2020 2020  t {pair}. '.    
-0000c0e0: 2020 2020 2020 2020 2020 2020 6627 5472              f'Tr
-0000c0f0: 6965 6420 746f 207b 7369 6465 7d20 616d  ied to {side} am
-0000c100: 6f75 6e74 207b 616d 6f75 6e74 7d20 6174  ount {amount} at
-0000c110: 2072 6174 6520 7b72 6174 657d 2e20 270a   rate {rate}. '.
-0000c120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c130: 6627 4d65 7373 6167 653a 207b 657d 2729  f'Message: {e}')
-0000c140: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
-0000c150: 6578 6365 7074 2063 6378 742e 4444 6f53  except ccxt.DDoS
-0000c160: 5072 6f74 6563 7469 6f6e 2061 7320 653a  Protection as e:
-0000c170: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0000c180: 7365 2044 446f 7350 726f 7465 6374 696f  se DDosProtectio
-0000c190: 6e28 6529 2066 726f 6d20 650a 2020 2020  n(e) from e.    
-0000c1a0: 2020 2020 6578 6365 7074 2028 6363 7874      except (ccxt
-0000c1b0: 2e4f 7065 7261 7469 6f6e 4661 696c 6564  .OperationFailed
-0000c1c0: 2c20 6363 7874 2e45 7863 6861 6e67 6545  , ccxt.ExchangeE
-0000c1d0: 7272 6f72 2920 6173 2065 3a0a 2020 2020  rror) as e:.    
-0000c1e0: 2020 2020 2020 2020 7261 6973 6520 5465          raise Te
-0000c1f0: 6d70 6f72 6172 7945 7272 6f72 280a 2020  mporaryError(.  
-0000c200: 2020 2020 2020 2020 2020 2020 2020 6627                f'
-0000c210: 436f 756c 6420 6e6f 7420 706c 6163 6520  Could not place 
-0000c220: 7b73 6964 657d 206f 7264 6572 2064 7565  {side} order due
-0000c230: 2074 6f20 7b65 2e5f 5f63 6c61 7373 5f5f   to {e.__class__
-0000c240: 2e5f 5f6e 616d 655f 5f7d 2e20 4d65 7373  .__name__}. Mess
-0000c250: 6167 653a 207b 657d 2729 2066 726f 6d20  age: {e}') from 
-0000c260: 650a 2020 2020 2020 2020 6578 6365 7074  e.        except
-0000c270: 2063 6378 742e 4261 7365 4572 726f 7220   ccxt.BaseError 
-0000c280: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
-0000c290: 2020 7261 6973 6520 4f70 6572 6174 696f    raise Operatio
-0000c2a0: 6e61 6c45 7863 6570 7469 6f6e 2865 2920  nalException(e) 
-0000c2b0: 6672 6f6d 2065 0a0a 2020 2020 6465 6620  from e..    def 
-0000c2c0: 7374 6f70 6c6f 7373 5f61 646a 7573 7428  stoploss_adjust(
-0000c2d0: 7365 6c66 2c20 7374 6f70 5f6c 6f73 733a  self, stop_loss:
-0000c2e0: 2066 6c6f 6174 2c20 6f72 6465 723a 2044   float, order: D
-0000c2f0: 6963 742c 2073 6964 653a 2073 7472 2920  ict, side: str) 
-0000c300: 2d3e 2062 6f6f 6c3a 0a20 2020 2020 2020  -> bool:.       
-0000c310: 2022 2222 0a20 2020 2020 2020 2056 6572   """.        Ver
-0000c320: 6966 7920 7374 6f70 5f6c 6f73 7320 6167  ify stop_loss ag
-0000c330: 6169 6e73 7420 7374 6f70 6c6f 7373 2d6f  ainst stoploss-o
-0000c340: 7264 6572 2076 616c 7565 2028 6c69 6d69  rder value (limi
-0000c350: 7420 6f72 2070 7269 6365 290a 2020 2020  t or price).    
-0000c360: 2020 2020 5265 7475 726e 7320 5472 7565      Returns True
-0000c370: 2069 6620 6164 6a75 7374 6d65 6e74 2069   if adjustment i
-0000c380: 7320 6e65 6365 7373 6172 792e 0a20 2020  s necessary..   
-0000c390: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0000c3a0: 2069 6620 6e6f 7420 7365 6c66 2e5f 6674   if not self._ft
-0000c3b0: 5f68 6173 2e67 6574 2827 7374 6f70 6c6f  _has.get('stoplo
-0000c3c0: 7373 5f6f 6e5f 6578 6368 616e 6765 2729  ss_on_exchange')
-0000c3d0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0000c3e0: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
-0000c3f0: 7863 6570 7469 6f6e 2866 2273 746f 706c  xception(f"stopl
-0000c400: 6f73 7320 6973 206e 6f74 2069 6d70 6c65  oss is not imple
-0000c410: 6d65 6e74 6564 2066 6f72 207b 7365 6c66  mented for {self
-0000c420: 2e6e 616d 657d 2e22 290a 2020 2020 2020  .name}.").      
-0000c430: 2020 7072 6963 655f 7061 7261 6d20 3d20    price_param = 
-0000c440: 7365 6c66 2e5f 6674 5f68 6173 5b27 7374  self._ft_has['st
-0000c450: 6f70 5f70 7269 6365 5f70 726f 7027 5d0a  op_price_prop'].
-0000c460: 2020 2020 2020 2020 7265 7475 726e 2028          return (
-0000c470: 0a20 2020 2020 2020 2020 2020 206f 7264  .            ord
-0000c480: 6572 2e67 6574 2870 7269 6365 5f70 6172  er.get(price_par
-0000c490: 616d 2c20 4e6f 6e65 2920 6973 204e 6f6e  am, None) is Non
-0000c4a0: 650a 2020 2020 2020 2020 2020 2020 6f72  e.            or
-0000c4b0: 2028 2873 6964 6520 3d3d 2022 7365 6c6c   ((side == "sell
-0000c4c0: 2220 616e 6420 7374 6f70 5f6c 6f73 7320  " and stop_loss 
-0000c4d0: 3e20 666c 6f61 7428 6f72 6465 725b 7072  > float(order[pr
-0000c4e0: 6963 655f 7061 7261 6d5d 2929 206f 720a  ice_param])) or.
-0000c4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c500: 2873 6964 6520 3d3d 2022 6275 7922 2061  (side == "buy" a
-0000c510: 6e64 2073 746f 705f 6c6f 7373 203c 2066  nd stop_loss < f
-0000c520: 6c6f 6174 286f 7264 6572 5b70 7269 6365  loat(order[price
-0000c530: 5f70 6172 616d 5d29 2929 0a20 2020 2020  _param]))).     
-0000c540: 2020 2029 0a0a 2020 2020 6465 6620 5f67     )..    def _g
-0000c550: 6574 5f73 746f 705f 6f72 6465 725f 7479  et_stop_order_ty
-0000c560: 7065 2873 656c 662c 2075 7365 725f 6f72  pe(self, user_or
-0000c570: 6465 725f 7479 7065 2920 2d3e 2054 7570  der_type) -> Tup
-0000c580: 6c65 5b73 7472 2c20 7374 725d 3a0a 0a20  le[str, str]:.. 
-0000c590: 2020 2020 2020 2061 7661 696c 6162 6c65         available
-0000c5a0: 5f6f 7264 6572 5f54 7970 6573 3a20 4469  _order_Types: Di
-0000c5b0: 6374 5b73 7472 2c20 7374 725d 203d 2073  ct[str, str] = s
-0000c5c0: 656c 662e 5f66 745f 6861 735b 2273 746f  elf._ft_has["sto
-0000c5d0: 706c 6f73 735f 6f72 6465 725f 7479 7065  ploss_order_type
-0000c5e0: 7322 5d0a 0a20 2020 2020 2020 2069 6620  s"]..        if 
-0000c5f0: 7573 6572 5f6f 7264 6572 5f74 7970 6520  user_order_type 
-0000c600: 696e 2061 7661 696c 6162 6c65 5f6f 7264  in available_ord
-0000c610: 6572 5f54 7970 6573 2e6b 6579 7328 293a  er_Types.keys():
-0000c620: 0a20 2020 2020 2020 2020 2020 206f 7264  .            ord
-0000c630: 6572 7479 7065 203d 2061 7661 696c 6162  ertype = availab
-0000c640: 6c65 5f6f 7264 6572 5f54 7970 6573 5b75  le_order_Types[u
-0000c650: 7365 725f 6f72 6465 725f 7479 7065 5d0a  ser_order_type].
-0000c660: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0000c670: 2020 2020 2020 2020 2020 2320 4f74 6865            # Othe
-0000c680: 7277 6973 6520 7069 636b 206f 6e6c 7920  rwise pick only 
-0000c690: 6f6e 6520 6176 6169 6c61 626c 650a 2020  one available.  
-0000c6a0: 2020 2020 2020 2020 2020 6f72 6465 7274            ordert
-0000c6b0: 7970 6520 3d20 6c69 7374 2861 7661 696c  ype = list(avail
-0000c6c0: 6162 6c65 5f6f 7264 6572 5f54 7970 6573  able_order_Types
-0000c6d0: 2e76 616c 7565 7328 2929 5b30 5d0a 2020  .values())[0].  
-0000c6e0: 2020 2020 2020 2020 2020 7573 6572 5f6f            user_o
-0000c6f0: 7264 6572 5f74 7970 6520 3d20 6c69 7374  rder_type = list
-0000c700: 2861 7661 696c 6162 6c65 5f6f 7264 6572  (available_order
-0000c710: 5f54 7970 6573 2e6b 6579 7328 2929 5b30  _Types.keys())[0
-0000c720: 5d0a 2020 2020 2020 2020 7265 7475 726e  ].        return
-0000c730: 206f 7264 6572 7479 7065 2c20 7573 6572   ordertype, user
-0000c740: 5f6f 7264 6572 5f74 7970 650a 0a20 2020  _order_type..   
-0000c750: 2064 6566 205f 6765 745f 7374 6f70 5f6c   def _get_stop_l
-0000c760: 696d 6974 5f72 6174 6528 7365 6c66 2c20  imit_rate(self, 
-0000c770: 7374 6f70 5f70 7269 6365 3a20 666c 6f61  stop_price: floa
-0000c780: 742c 206f 7264 6572 5f74 7970 6573 3a20  t, order_types: 
-0000c790: 4469 6374 2c20 7369 6465 3a20 7374 7229  Dict, side: str)
-0000c7a0: 202d 3e20 666c 6f61 743a 0a20 2020 2020   -> float:.     
-0000c7b0: 2020 2023 204c 696d 6974 2070 7269 6365     # Limit price
-0000c7c0: 2074 6872 6573 686f 6c64 3a20 4173 206c   threshold: As l
-0000c7d0: 696d 6974 2070 7269 6365 2073 686f 756c  imit price shoul
-0000c7e0: 6420 616c 7761 7973 2062 6520 6265 6c6f  d always be belo
-0000c7f0: 7720 7374 6f70 2d70 7269 6365 0a20 2020  w stop-price.   
-0000c800: 2020 2020 206c 696d 6974 5f70 7269 6365       limit_price
-0000c810: 5f70 6374 203d 206f 7264 6572 5f74 7970  _pct = order_typ
-0000c820: 6573 2e67 6574 2827 7374 6f70 6c6f 7373  es.get('stoploss
-0000c830: 5f6f 6e5f 6578 6368 616e 6765 5f6c 696d  _on_exchange_lim
-0000c840: 6974 5f72 6174 696f 272c 2030 2e39 3929  it_ratio', 0.99)
-0000c850: 0a20 2020 2020 2020 2069 6620 7369 6465  .        if side
-0000c860: 203d 3d20 2273 656c 6c22 3a0a 2020 2020   == "sell":.    
-0000c870: 2020 2020 2020 2020 6c69 6d69 745f 7261          limit_ra
-0000c880: 7465 203d 2073 746f 705f 7072 6963 6520  te = stop_price 
-0000c890: 2a20 6c69 6d69 745f 7072 6963 655f 7063  * limit_price_pc
-0000c8a0: 740a 2020 2020 2020 2020 656c 7365 3a0a  t.        else:.
-0000c8b0: 2020 2020 2020 2020 2020 2020 6c69 6d69              limi
-0000c8c0: 745f 7261 7465 203d 2073 746f 705f 7072  t_rate = stop_pr
-0000c8d0: 6963 6520 2a20 2832 202d 206c 696d 6974  ice * (2 - limit
-0000c8e0: 5f70 7269 6365 5f70 6374 290a 0a20 2020  _price_pct)..   
-0000c8f0: 2020 2020 2062 6164 5f73 746f 705f 7072       bad_stop_pr
-0000c900: 6963 6520 3d20 2828 7374 6f70 5f70 7269  ice = ((stop_pri
-0000c910: 6365 203c 206c 696d 6974 5f72 6174 6529  ce < limit_rate)
-0000c920: 2069 6620 7369 6465 203d 3d0a 2020 2020   if side ==.    
-0000c930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c940: 2020 2020 2020 2273 656c 6c22 2065 6c73        "sell" els
-0000c950: 6520 2873 746f 705f 7072 6963 6520 3e20  e (stop_price > 
-0000c960: 6c69 6d69 745f 7261 7465 2929 0a20 2020  limit_rate)).   
-0000c970: 2020 2020 2023 2045 6e73 7572 6520 7261       # Ensure ra
-0000c980: 7465 2069 7320 6c65 7373 2074 6861 6e20  te is less than 
-0000c990: 7374 6f70 2070 7269 6365 0a20 2020 2020  stop price.     
-0000c9a0: 2020 2069 6620 6261 645f 7374 6f70 5f70     if bad_stop_p
-0000c9b0: 7269 6365 3a0a 2020 2020 2020 2020 2020  rice:.          
-0000c9c0: 2020 2320 5468 6973 2063 616e 2066 6f72    # This can for
-0000c9d0: 2065 7861 6d70 6c65 2068 6170 7065 6e20   example happen 
-0000c9e0: 6966 2074 6865 2073 746f 7020 2f20 6c69  if the stop / li
-0000c9f0: 7175 6964 6174 696f 6e20 7072 6963 6520  quidation price 
-0000ca00: 6973 2073 6574 2074 6f20 300a 2020 2020  is set to 0.    
-0000ca10: 2020 2020 2020 2020 2320 5768 6963 6820          # Which 
-0000ca20: 6973 2070 6f73 7369 626c 6520 6966 2061  is possible if a
-0000ca30: 206d 6172 6b65 742d 6f72 6465 7220 636c   market-order cl
-0000ca40: 6f73 6573 2072 6967 6874 2061 7761 792e  oses right away.
-0000ca50: 0a20 2020 2020 2020 2020 2020 2023 2054  .            # T
-0000ca60: 6865 2049 6e76 616c 6964 4f72 6465 7245  he InvalidOrderE
-0000ca70: 7863 6570 7469 6f6e 2077 696c 6c20 6275  xception will bu
-0000ca80: 6262 6c65 2075 7020 746f 2065 7869 745f  bble up to exit_
-0000ca90: 706f 7369 7469 6f6e 732c 2077 6865 7265  positions, where
-0000caa0: 2069 7420 7769 6c6c 2062 650a 2020 2020   it will be.    
-0000cab0: 2020 2020 2020 2020 2320 6861 6e64 6c65          # handle
-0000cac0: 6420 6772 6163 6566 756c 6c79 2e0a 2020  d gracefully..  
-0000cad0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0000cae0: 496e 7661 6c69 644f 7264 6572 4578 6365  InvalidOrderExce
-0000caf0: 7074 696f 6e28 0a20 2020 2020 2020 2020  ption(.         
-0000cb00: 2020 2020 2020 2022 496e 2073 746f 706c         "In stopl
-0000cb10: 6f73 7320 6c69 6d69 7420 6f72 6465 722c  oss limit order,
-0000cb20: 2073 746f 7020 7072 6963 6520 7368 6f75   stop price shou
-0000cb30: 6c64 2062 6520 6d6f 7265 2074 6861 6e20  ld be more than 
-0000cb40: 6c69 6d69 7420 7072 6963 652e 2022 0a20  limit price. ". 
-0000cb50: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0000cb60: 2253 746f 7020 7072 6963 653a 207b 7374  "Stop price: {st
-0000cb70: 6f70 5f70 7269 6365 7d2c 204c 696d 6974  op_price}, Limit
-0000cb80: 2070 7269 6365 3a20 7b6c 696d 6974 5f72   price: {limit_r
-0000cb90: 6174 657d 2c20 220a 2020 2020 2020 2020  ate}, ".        
-0000cba0: 2020 2020 2020 2020 6622 4c69 6d69 7420          f"Limit 
-0000cbb0: 5072 6963 6520 7063 743a 207b 6c69 6d69  Price pct: {limi
-0000cbc0: 745f 7072 6963 655f 7063 747d 220a 2020  t_price_pct}".  
-0000cbd0: 2020 2020 2020 2020 2020 2020 2020 290a                ).
-0000cbe0: 2020 2020 2020 2020 7265 7475 726e 206c          return l
-0000cbf0: 696d 6974 5f72 6174 650a 0a20 2020 2064  imit_rate..    d
-0000cc00: 6566 205f 6765 745f 7374 6f70 5f70 6172  ef _get_stop_par
-0000cc10: 616d 7328 7365 6c66 2c20 7369 6465 3a20  ams(self, side: 
-0000cc20: 4275 7953 656c 6c2c 206f 7264 6572 7479  BuySell, orderty
-0000cc30: 7065 3a20 7374 722c 2073 746f 705f 7072  pe: str, stop_pr
-0000cc40: 6963 653a 2066 6c6f 6174 2920 2d3e 2044  ice: float) -> D
-0000cc50: 6963 743a 0a20 2020 2020 2020 2070 6172  ict:.        par
-0000cc60: 616d 7320 3d20 7365 6c66 2e5f 7061 7261  ams = self._para
-0000cc70: 6d73 2e63 6f70 7928 290a 2020 2020 2020  ms.copy().      
-0000cc80: 2020 2320 5665 7269 6679 2069 6620 7374    # Verify if st
-0000cc90: 6f70 5072 6963 6520 776f 726b 7320 666f  opPrice works fo
-0000cca0: 7220 796f 7572 2065 7863 6861 6e67 652c  r your exchange,
-0000ccb0: 2065 6c73 6520 636f 6e66 6967 7572 6520   else configure 
-0000ccc0: 7374 6f70 5f70 7269 6365 5f70 6172 616d  stop_price_param
-0000ccd0: 0a20 2020 2020 2020 2070 6172 616d 732e  .        params.
-0000cce0: 7570 6461 7465 287b 7365 6c66 2e5f 6674  update({self._ft
-0000ccf0: 5f68 6173 5b27 7374 6f70 5f70 7269 6365  _has['stop_price
-0000cd00: 5f70 6172 616d 275d 3a20 7374 6f70 5f70  _param']: stop_p
-0000cd10: 7269 6365 7d29 0a20 2020 2020 2020 2072  rice}).        r
-0000cd20: 6574 7572 6e20 7061 7261 6d73 0a0a 2020  eturn params..  
-0000cd30: 2020 4072 6574 7269 6572 2872 6574 7269    @retrier(retri
-0000cd40: 6573 3d30 290a 2020 2020 6465 6620 6372  es=0).    def cr
-0000cd50: 6561 7465 5f73 746f 706c 6f73 7328 7365  eate_stoploss(se
-0000cd60: 6c66 2c20 7061 6972 3a20 7374 722c 2061  lf, pair: str, a
-0000cd70: 6d6f 756e 743a 2066 6c6f 6174 2c20 7374  mount: float, st
-0000cd80: 6f70 5f70 7269 6365 3a20 666c 6f61 742c  op_price: float,
-0000cd90: 206f 7264 6572 5f74 7970 6573 3a20 4469   order_types: Di
-0000cda0: 6374 2c0a 2020 2020 2020 2020 2020 2020  ct,.            
-0000cdb0: 2020 2020 2020 2020 2020 2020 7369 6465              side
-0000cdc0: 3a20 4275 7953 656c 6c2c 206c 6576 6572  : BuySell, lever
-0000cdd0: 6167 653a 2066 6c6f 6174 2920 2d3e 2044  age: float) -> D
-0000cde0: 6963 743a 0a20 2020 2020 2020 2022 2222  ict:.        """
-0000cdf0: 0a20 2020 2020 2020 2063 7265 6174 6573  .        creates
-0000ce00: 2061 2073 746f 706c 6f73 7320 6f72 6465   a stoploss orde
-0000ce10: 722e 0a20 2020 2020 2020 2072 6571 7569  r..        requi
-0000ce20: 7265 7320 605f 6674 5f68 6173 5b27 7374  res `_ft_has['st
-0000ce30: 6f70 6c6f 7373 5f6f 7264 6572 5f74 7970  oploss_order_typ
-0000ce40: 6573 275d 6020 746f 2062 6520 7365 7420  es']` to be set 
-0000ce50: 6173 2061 2064 6963 7420 6d61 7070 696e  as a dict mappin
-0000ce60: 6720 6c69 6d69 7420 616e 6420 6d61 726b  g limit and mark
-0000ce70: 6574 0a20 2020 2020 2020 2020 2020 2074  et.            t
-0000ce80: 6f20 7468 6520 636f 7272 6573 706f 6e64  o the correspond
-0000ce90: 696e 6720 6578 6368 616e 6765 2074 7970  ing exchange typ
-0000cea0: 652e 0a0a 2020 2020 2020 2020 5468 6520  e...        The 
-0000ceb0: 7072 6563 6973 6520 6f72 6465 7274 7970  precise ordertyp
-0000cec0: 6520 6973 2064 6574 6572 6d69 6e65 6420  e is determined 
-0000ced0: 6279 2074 6865 206f 7264 6572 5f74 7970  by the order_typ
-0000cee0: 6573 2064 6963 7420 6f72 2065 7863 6861  es dict or excha
-0000cef0: 6e67 6520 6465 6661 756c 742e 0a0a 2020  nge default...  
-0000cf00: 2020 2020 2020 5468 6520 6578 6365 7074        The except
-0000cf10: 696f 6e20 6265 6c6f 7720 7368 6f75 6c64  ion below should
-0000cf20: 206e 6576 6572 2072 6169 7365 2c20 7369   never raise, si
-0000cf30: 6e63 6520 7765 2064 6973 616c 6c6f 770a  nce we disallow.
-0000cf40: 2020 2020 2020 2020 7374 6172 7469 6e67          starting
-0000cf50: 2074 6865 2062 6f74 2069 6e20 7661 6c69   the bot in vali
-0000cf60: 6461 7465 5f6f 7264 6572 7479 7065 7328  date_ordertypes(
-0000cf70: 290a 0a20 2020 2020 2020 2054 6869 7320  )..        This 
-0000cf80: 6d61 7920 776f 726b 2077 6974 6820 6120  may work with a 
-0000cf90: 6c69 6d69 7465 6420 6e75 6d62 6572 206f  limited number o
-0000cfa0: 6620 6f74 6865 7220 6578 6368 616e 6765  f other exchange
-0000cfb0: 732c 2062 7574 2063 6f72 7265 6374 2077  s, but correct w
-0000cfc0: 6f72 6b69 6e67 0a20 2020 2020 2020 2020  orking.         
-0000cfd0: 2020 206e 6565 6473 2074 6f20 6265 2074     needs to be t
-0000cfe0: 6573 7465 6420 696e 6469 7669 6475 616c  ested individual
-0000cff0: 6c79 2e0a 2020 2020 2020 2020 5741 524e  ly..        WARN
-0000d000: 494e 473a 2073 6574 7469 6e67 2060 7374  ING: setting `st
-0000d010: 6f70 6c6f 7373 5f6f 6e5f 6578 6368 616e  oploss_on_exchan
-0000d020: 6765 6020 746f 2054 7275 6520 7769 6c6c  ge` to True will
-0000d030: 204e 4f54 2061 7574 6f2d 656e 6162 6c65   NOT auto-enable
-0000d040: 2073 746f 706c 6f73 7320 6f6e 2065 7863   stoploss on exc
-0000d050: 6861 6e67 652e 0a20 2020 2020 2020 2020  hange..         
-0000d060: 2020 2060 7374 6f70 6c6f 7373 5f61 646a     `stoploss_adj
-0000d070: 7573 7460 206d 7573 7420 7374 696c 6c20  ust` must still 
-0000d080: 6265 2069 6d70 6c65 6d65 6e74 6564 2066  be implemented f
-0000d090: 6f72 2074 6869 7320 746f 2077 6f72 6b2e  or this to work.
-0000d0a0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-0000d0b0: 2020 2020 2069 6620 6e6f 7420 7365 6c66       if not self
-0000d0c0: 2e5f 6674 5f68 6173 5b27 7374 6f70 6c6f  ._ft_has['stoplo
-0000d0d0: 7373 5f6f 6e5f 6578 6368 616e 6765 275d  ss_on_exchange']
-0000d0e0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0000d0f0: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
-0000d100: 7863 6570 7469 6f6e 2866 2273 746f 706c  xception(f"stopl
-0000d110: 6f73 7320 6973 206e 6f74 2069 6d70 6c65  oss is not imple
-0000d120: 6d65 6e74 6564 2066 6f72 207b 7365 6c66  mented for {self
-0000d130: 2e6e 616d 657d 2e22 290a 0a20 2020 2020  .name}.")..     
-0000d140: 2020 2075 7365 725f 6f72 6465 725f 7479     user_order_ty
-0000d150: 7065 203d 206f 7264 6572 5f74 7970 6573  pe = order_types
-0000d160: 2e67 6574 2827 7374 6f70 6c6f 7373 272c  .get('stoploss',
-0000d170: 2027 6d61 726b 6574 2729 0a20 2020 2020   'market').     
-0000d180: 2020 206f 7264 6572 7479 7065 2c20 7573     ordertype, us
-0000d190: 6572 5f6f 7264 6572 5f74 7970 6520 3d20  er_order_type = 
-0000d1a0: 7365 6c66 2e5f 6765 745f 7374 6f70 5f6f  self._get_stop_o
-0000d1b0: 7264 6572 5f74 7970 6528 7573 6572 5f6f  rder_type(user_o
-0000d1c0: 7264 6572 5f74 7970 6529 0a20 2020 2020  rder_type).     
-0000d1d0: 2020 2072 6f75 6e64 5f6d 6f64 6520 3d20     round_mode = 
-0000d1e0: 524f 554e 445f 444f 574e 2069 6620 7369  ROUND_DOWN if si
-0000d1f0: 6465 203d 3d20 2762 7579 2720 656c 7365  de == 'buy' else
-0000d200: 2052 4f55 4e44 5f55 500a 2020 2020 2020   ROUND_UP.      
-0000d210: 2020 7374 6f70 5f70 7269 6365 5f6e 6f72    stop_price_nor
-0000d220: 6d20 3d20 7365 6c66 2e70 7269 6365 5f74  m = self.price_t
-0000d230: 6f5f 7072 6563 6973 696f 6e28 7061 6972  o_precision(pair
-0000d240: 2c20 7374 6f70 5f70 7269 6365 2c20 726f  , stop_price, ro
-0000d250: 756e 6469 6e67 5f6d 6f64 653d 726f 756e  unding_mode=roun
-0000d260: 645f 6d6f 6465 290a 2020 2020 2020 2020  d_mode).        
-0000d270: 6c69 6d69 745f 7261 7465 203d 204e 6f6e  limit_rate = Non
-0000d280: 650a 2020 2020 2020 2020 6966 2075 7365  e.        if use
-0000d290: 725f 6f72 6465 725f 7479 7065 203d 3d20  r_order_type == 
-0000d2a0: 276c 696d 6974 273a 0a20 2020 2020 2020  'limit':.       
-0000d2b0: 2020 2020 206c 696d 6974 5f72 6174 6520       limit_rate 
-0000d2c0: 3d20 7365 6c66 2e5f 6765 745f 7374 6f70  = self._get_stop
-0000d2d0: 5f6c 696d 6974 5f72 6174 6528 7374 6f70  _limit_rate(stop
-0000d2e0: 5f70 7269 6365 2c20 6f72 6465 725f 7479  _price, order_ty
-0000d2f0: 7065 732c 2073 6964 6529 0a20 2020 2020  pes, side).     
-0000d300: 2020 2020 2020 206c 696d 6974 5f72 6174         limit_rat
-0000d310: 6520 3d20 7365 6c66 2e70 7269 6365 5f74  e = self.price_t
-0000d320: 6f5f 7072 6563 6973 696f 6e28 7061 6972  o_precision(pair
-0000d330: 2c20 6c69 6d69 745f 7261 7465 2c20 726f  , limit_rate, ro
-0000d340: 756e 6469 6e67 5f6d 6f64 653d 726f 756e  unding_mode=roun
-0000d350: 645f 6d6f 6465 290a 0a20 2020 2020 2020  d_mode)..       
-0000d360: 2069 6620 7365 6c66 2e5f 636f 6e66 6967   if self._config
-0000d370: 5b27 6472 795f 7275 6e27 5d3a 0a20 2020  ['dry_run']:.   
-0000d380: 2020 2020 2020 2020 2064 7279 5f6f 7264           dry_ord
-0000d390: 6572 203d 2073 656c 662e 6372 6561 7465  er = self.create
-0000d3a0: 5f64 7279 5f72 756e 5f6f 7264 6572 280a  _dry_run_order(.
-0000d3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d3c0: 7061 6972 2c0a 2020 2020 2020 2020 2020  pair,.          
-0000d3d0: 2020 2020 2020 6f72 6465 7274 7970 652c        ordertype,
-0000d3e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d3f0: 2073 6964 652c 0a20 2020 2020 2020 2020   side,.         
-0000d400: 2020 2020 2020 2061 6d6f 756e 742c 0a20         amount,. 
-0000d410: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000d420: 746f 705f 7072 6963 655f 6e6f 726d 2c0a  top_price_norm,.
-0000d430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d440: 7374 6f70 5f6c 6f73 733d 5472 7565 2c0a  stop_loss=True,.
-0000d450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d460: 6c65 7665 7261 6765 3d6c 6576 6572 6167  leverage=leverag
-0000d470: 652c 0a20 2020 2020 2020 2020 2020 2029  e,.            )
-0000d480: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0000d490: 7572 6e20 6472 795f 6f72 6465 720a 0a20  urn dry_order.. 
-0000d4a0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000d4b0: 2020 2020 2020 2020 7061 7261 6d73 203d          params =
-0000d4c0: 2073 656c 662e 5f67 6574 5f73 746f 705f   self._get_stop_
-0000d4d0: 7061 7261 6d73 2873 6964 653d 7369 6465  params(side=side
-0000d4e0: 2c20 6f72 6465 7274 7970 653d 6f72 6465  , ordertype=orde
-0000d4f0: 7274 7970 652c 0a20 2020 2020 2020 2020  rtype,.         
-0000d500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d520: 2020 7374 6f70 5f70 7269 6365 3d73 746f    stop_price=sto
-0000d530: 705f 7072 6963 655f 6e6f 726d 290a 2020  p_price_norm).  
-0000d540: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-0000d550: 662e 7472 6164 696e 675f 6d6f 6465 203d  f.trading_mode =
-0000d560: 3d20 5472 6164 696e 674d 6f64 652e 4655  = TradingMode.FU
-0000d570: 5455 5245 533a 0a20 2020 2020 2020 2020  TURES:.         
-0000d580: 2020 2020 2020 2070 6172 616d 735b 2772         params['r
-0000d590: 6564 7563 654f 6e6c 7927 5d20 3d20 5472  educeOnly'] = Tr
-0000d5a0: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
-0000d5b0: 2020 2069 6620 2773 746f 706c 6f73 735f     if 'stoploss_
-0000d5c0: 7072 6963 655f 7479 7065 2720 696e 206f  price_type' in o
-0000d5d0: 7264 6572 5f74 7970 6573 2061 6e64 2027  rder_types and '
-0000d5e0: 7374 6f70 5f70 7269 6365 5f74 7970 655f  stop_price_type_
-0000d5f0: 6669 656c 6427 2069 6e20 7365 6c66 2e5f  field' in self._
-0000d600: 6674 5f68 6173 3a0a 2020 2020 2020 2020  ft_has:.        
-0000d610: 2020 2020 2020 2020 2020 2020 7072 6963              pric
-0000d620: 655f 7479 7065 203d 2073 656c 662e 5f66  e_type = self._f
-0000d630: 745f 6861 735b 2773 746f 705f 7072 6963  t_has['stop_pric
-0000d640: 655f 7479 7065 5f76 616c 7565 5f6d 6170  e_type_value_map
-0000d650: 7069 6e67 275d 5b0a 2020 2020 2020 2020  ping'][.        
-0000d660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d670: 6f72 6465 725f 7479 7065 732e 6765 7428  order_types.get(
-0000d680: 2773 746f 706c 6f73 735f 7072 6963 655f  'stoploss_price_
-0000d690: 7479 7065 272c 2050 7269 6365 5479 7065  type', PriceType
-0000d6a0: 2e4c 4153 5429 5d0a 2020 2020 2020 2020  .LAST)].        
-0000d6b0: 2020 2020 2020 2020 2020 2020 7061 7261              para
-0000d6c0: 6d73 5b73 656c 662e 5f66 745f 6861 735b  ms[self._ft_has[
-0000d6d0: 2773 746f 705f 7072 6963 655f 7479 7065  'stop_price_type
-0000d6e0: 5f66 6965 6c64 275d 5d20 3d20 7072 6963  _field']] = pric
-0000d6f0: 655f 7479 7065 0a0a 2020 2020 2020 2020  e_type..        
-0000d700: 2020 2020 616d 6f75 6e74 203d 2073 656c      amount = sel
-0000d710: 662e 616d 6f75 6e74 5f74 6f5f 7072 6563  f.amount_to_prec
-0000d720: 6973 696f 6e28 7061 6972 2c20 7365 6c66  ision(pair, self
-0000d730: 2e5f 616d 6f75 6e74 5f74 6f5f 636f 6e74  ._amount_to_cont
-0000d740: 7261 6374 7328 7061 6972 2c20 616d 6f75  racts(pair, amou
-0000d750: 6e74 2929 0a0a 2020 2020 2020 2020 2020  nt))..          
-0000d760: 2020 7365 6c66 2e5f 6c65 765f 7072 6570    self._lev_prep
-0000d770: 2870 6169 722c 206c 6576 6572 6167 652c  (pair, leverage,
-0000d780: 2073 6964 652c 2061 6363 6570 745f 6661   side, accept_fa
-0000d790: 696c 3d54 7275 6529 0a20 2020 2020 2020  il=True).       
-0000d7a0: 2020 2020 206f 7264 6572 203d 2073 656c       order = sel
-0000d7b0: 662e 5f61 7069 2e63 7265 6174 655f 6f72  f._api.create_or
-0000d7c0: 6465 7228 7379 6d62 6f6c 3d70 6169 722c  der(symbol=pair,
-0000d7d0: 2074 7970 653d 6f72 6465 7274 7970 652c   type=ordertype,
-0000d7e0: 2073 6964 653d 7369 6465 2c0a 2020 2020   side=side,.    
-0000d7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d810: 2020 2020 2020 2061 6d6f 756e 743d 616d         amount=am
-0000d820: 6f75 6e74 2c20 7072 6963 653d 6c69 6d69  ount, price=limi
-0000d830: 745f 7261 7465 2c20 7061 7261 6d73 3d70  t_rate, params=p
-0000d840: 6172 616d 7329 0a20 2020 2020 2020 2020  arams).         
-0000d850: 2020 2073 656c 662e 5f6c 6f67 5f65 7863     self._log_exc
-0000d860: 6861 6e67 655f 7265 7370 6f6e 7365 2827  hange_response('
-0000d870: 6372 6561 7465 5f73 746f 706c 6f73 735f  create_stoploss_
-0000d880: 6f72 6465 7227 2c20 6f72 6465 7229 0a20  order', order). 
-0000d890: 2020 2020 2020 2020 2020 206f 7264 6572             order
-0000d8a0: 203d 2073 656c 662e 5f6f 7264 6572 5f63   = self._order_c
-0000d8b0: 6f6e 7472 6163 7473 5f74 6f5f 616d 6f75  ontracts_to_amou
-0000d8c0: 6e74 286f 7264 6572 290a 2020 2020 2020  nt(order).      
-0000d8d0: 2020 2020 2020 6c6f 6767 6572 2e69 6e66        logger.inf
-0000d8e0: 6f28 6622 7374 6f70 6c6f 7373 207b 7573  o(f"stoploss {us
-0000d8f0: 6572 5f6f 7264 6572 5f74 7970 657d 206f  er_order_type} o
-0000d900: 7264 6572 2061 6464 6564 2066 6f72 207b  rder added for {
-0000d910: 7061 6972 7d2e 2022 0a20 2020 2020 2020  pair}. ".       
-0000d920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d930: 2066 2273 746f 7020 7072 6963 653a 207b   f"stop price: {
-0000d940: 7374 6f70 5f70 7269 6365 7d2e 206c 696d  stop_price}. lim
-0000d950: 6974 3a20 7b6c 696d 6974 5f72 6174 657d  it: {limit_rate}
-0000d960: 2229 0a20 2020 2020 2020 2020 2020 2072  ").            r
-0000d970: 6574 7572 6e20 6f72 6465 720a 2020 2020  eturn order.    
-0000d980: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
-0000d990: 496e 7375 6666 6963 6965 6e74 4675 6e64  InsufficientFund
-0000d9a0: 7320 6173 2065 3a0a 2020 2020 2020 2020  s as e:.        
-0000d9b0: 2020 2020 7261 6973 6520 496e 7375 6666      raise Insuff
-0000d9c0: 6963 6965 6e74 4675 6e64 7345 7272 6f72  icientFundsError
-0000d9d0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000d9e0: 2020 6627 496e 7375 6666 6963 6965 6e74    f'Insufficient
-0000d9f0: 2066 756e 6473 2074 6f20 6372 6561 7465   funds to create
-0000da00: 207b 6f72 6465 7274 7970 657d 207b 7369   {ordertype} {si
-0000da10: 6465 7d20 6f72 6465 7220 6f6e 206d 6172  de} order on mar
-0000da20: 6b65 7420 7b70 6169 727d 2e20 270a 2020  ket {pair}. '.  
-0000da30: 2020 2020 2020 2020 2020 2020 2020 6627                f'
-0000da40: 5472 6965 6420 746f 207b 7369 6465 7d20  Tried to {side} 
-0000da50: 616d 6f75 6e74 207b 616d 6f75 6e74 7d20  amount {amount} 
-0000da60: 6174 2072 6174 6520 7b6c 696d 6974 5f72  at rate {limit_r
-0000da70: 6174 657d 2077 6974 6820 270a 2020 2020  ate} with '.    
-0000da80: 2020 2020 2020 2020 2020 2020 6627 7374              f'st
-0000da90: 6f70 2d70 7269 6365 207b 7374 6f70 5f70  op-price {stop_p
-0000daa0: 7269 6365 5f6e 6f72 6d7d 2e20 4d65 7373  rice_norm}. Mess
-0000dab0: 6167 653a 207b 657d 2729 2066 726f 6d20  age: {e}') from 
-0000dac0: 650a 2020 2020 2020 2020 6578 6365 7074  e.        except
-0000dad0: 2028 6363 7874 2e49 6e76 616c 6964 4f72   (ccxt.InvalidOr
-0000dae0: 6465 722c 2063 6378 742e 4261 6452 6571  der, ccxt.BadReq
-0000daf0: 7565 7374 2c20 6363 7874 2e4f 7065 7261  uest, ccxt.Opera
-0000db00: 7469 6f6e 5265 6a65 6374 6564 2920 6173  tionRejected) as
-0000db10: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-0000db20: 2320 4572 726f 7273 3a0a 2020 2020 2020  # Errors:.      
-0000db30: 2020 2020 2020 2320 604f 7264 6572 2077        # `Order w
-0000db40: 6f75 6c64 2074 7269 6767 6572 2069 6d6d  ould trigger imm
-0000db50: 6564 6961 7465 6c79 2e60 0a20 2020 2020  ediately.`.     
-0000db60: 2020 2020 2020 2072 6169 7365 2049 6e76         raise Inv
-0000db70: 616c 6964 4f72 6465 7245 7863 6570 7469  alidOrderExcepti
-0000db80: 6f6e 280a 2020 2020 2020 2020 2020 2020  on(.            
-0000db90: 2020 2020 6627 436f 756c 6420 6e6f 7420      f'Could not 
-0000dba0: 6372 6561 7465 207b 6f72 6465 7274 7970  create {ordertyp
-0000dbb0: 657d 207b 7369 6465 7d20 6f72 6465 7220  e} {side} order 
-0000dbc0: 6f6e 206d 6172 6b65 7420 7b70 6169 727d  on market {pair}
-0000dbd0: 2e20 270a 2020 2020 2020 2020 2020 2020  . '.            
-0000dbe0: 2020 2020 6627 5472 6965 6420 746f 207b      f'Tried to {
-0000dbf0: 7369 6465 7d20 616d 6f75 6e74 207b 616d  side} amount {am
-0000dc00: 6f75 6e74 7d20 6174 2072 6174 6520 7b6c  ount} at rate {l
-0000dc10: 696d 6974 5f72 6174 657d 2077 6974 6820  imit_rate} with 
-0000dc20: 270a 2020 2020 2020 2020 2020 2020 2020  '.              
-0000dc30: 2020 6627 7374 6f70 2d70 7269 6365 207b    f'stop-price {
-0000dc40: 7374 6f70 5f70 7269 6365 5f6e 6f72 6d7d  stop_price_norm}
-0000dc50: 2e20 4d65 7373 6167 653a 207b 657d 2729  . Message: {e}')
-0000dc60: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
-0000dc70: 6578 6365 7074 2063 6378 742e 4444 6f53  except ccxt.DDoS
-0000dc80: 5072 6f74 6563 7469 6f6e 2061 7320 653a  Protection as e:
-0000dc90: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0000dca0: 7365 2044 446f 7350 726f 7465 6374 696f  se DDosProtectio
-0000dcb0: 6e28 6529 2066 726f 6d20 650a 2020 2020  n(e) from e.    
-0000dcc0: 2020 2020 6578 6365 7074 2028 6363 7874      except (ccxt
-0000dcd0: 2e4f 7065 7261 7469 6f6e 4661 696c 6564  .OperationFailed
-0000dce0: 2c20 6363 7874 2e45 7863 6861 6e67 6545  , ccxt.ExchangeE
-0000dcf0: 7272 6f72 2920 6173 2065 3a0a 2020 2020  rror) as e:.    
-0000dd00: 2020 2020 2020 2020 7261 6973 6520 5465          raise Te
-0000dd10: 6d70 6f72 6172 7945 7272 6f72 280a 2020  mporaryError(.  
-0000dd20: 2020 2020 2020 2020 2020 2020 2020 6622                f"
-0000dd30: 436f 756c 6420 6e6f 7420 706c 6163 6520  Could not place 
-0000dd40: 7374 6f70 6c6f 7373 206f 7264 6572 2064  stoploss order d
-0000dd50: 7565 2074 6f20 7b65 2e5f 5f63 6c61 7373  ue to {e.__class
-0000dd60: 5f5f 2e5f 5f6e 616d 655f 5f7d 2e20 220a  __.__name__}. ".
-0000dd70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dd80: 6622 4d65 7373 6167 653a 207b 657d 2229  f"Message: {e}")
-0000dd90: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
-0000dda0: 6578 6365 7074 2063 6378 742e 4261 7365  except ccxt.Base
-0000ddb0: 4572 726f 7220 6173 2065 3a0a 2020 2020  Error as e:.    
-0000ddc0: 2020 2020 2020 2020 7261 6973 6520 4f70          raise Op
-0000ddd0: 6572 6174 696f 6e61 6c45 7863 6570 7469  erationalExcepti
-0000dde0: 6f6e 2865 2920 6672 6f6d 2065 0a0a 2020  on(e) from e..  
-0000ddf0: 2020 6465 6620 6665 7463 685f 6f72 6465    def fetch_orde
-0000de00: 725f 656d 756c 6174 6564 2873 656c 662c  r_emulated(self,
-0000de10: 206f 7264 6572 5f69 643a 2073 7472 2c20   order_id: str, 
-0000de20: 7061 6972 3a20 7374 722c 2070 6172 616d  pair: str, param
-0000de30: 733a 2044 6963 7429 202d 3e20 4469 6374  s: Dict) -> Dict
-0000de40: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-0000de50: 2020 2020 2020 456d 756c 6174 6564 2066        Emulated f
-0000de60: 6574 6368 5f6f 7264 6572 2069 6620 7468  etch_order if th
-0000de70: 6520 6578 6368 616e 6765 2064 6f65 736e  e exchange doesn
-0000de80: 2774 2073 7570 706f 7274 2066 6574 6368  't support fetch
-0000de90: 5f6f 7264 6572 2c20 6275 7420 7265 7175  _order, but requ
-0000dea0: 6972 6573 2073 6570 6172 6174 650a 2020  ires separate.  
-0000deb0: 2020 2020 2020 6361 6c6c 7320 666f 7220        calls for 
-0000dec0: 6f70 656e 2061 6e64 2063 6c6f 7365 6420  open and closed 
-0000ded0: 6f72 6465 7273 2e0a 2020 2020 2020 2020  orders..        
-0000dee0: 2222 220a 2020 2020 2020 2020 7472 793a  """.        try:
-0000def0: 0a20 2020 2020 2020 2020 2020 206f 7264  .            ord
-0000df00: 6572 203d 2073 656c 662e 5f61 7069 2e66  er = self._api.f
-0000df10: 6574 6368 5f6f 7065 6e5f 6f72 6465 7228  etch_open_order(
-0000df20: 6f72 6465 725f 6964 2c20 7061 6972 2c20  order_id, pair, 
-0000df30: 7061 7261 6d73 3d70 6172 616d 7329 0a20  params=params). 
-0000df40: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0000df50: 5f6c 6f67 5f65 7863 6861 6e67 655f 7265  _log_exchange_re
-0000df60: 7370 6f6e 7365 2827 6665 7463 685f 6f70  sponse('fetch_op
-0000df70: 656e 5f6f 7264 6572 272c 206f 7264 6572  en_order', order
-0000df80: 290a 2020 2020 2020 2020 2020 2020 6f72  ).            or
-0000df90: 6465 7220 3d20 7365 6c66 2e5f 6f72 6465  der = self._orde
-0000dfa0: 725f 636f 6e74 7261 6374 735f 746f 5f61  r_contracts_to_a
-0000dfb0: 6d6f 756e 7428 6f72 6465 7229 0a20 2020  mount(order).   
-0000dfc0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0000dfd0: 6f72 6465 720a 2020 2020 2020 2020 6578  order.        ex
-0000dfe0: 6365 7074 2063 6378 742e 4f72 6465 724e  cept ccxt.OrderN
-0000dff0: 6f74 466f 756e 643a 0a20 2020 2020 2020  otFound:.       
-0000e000: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
-0000e010: 2020 2020 2020 2020 2020 6f72 6465 7220            order 
-0000e020: 3d20 7365 6c66 2e5f 6170 692e 6665 7463  = self._api.fetc
-0000e030: 685f 636c 6f73 6564 5f6f 7264 6572 286f  h_closed_order(o
-0000e040: 7264 6572 5f69 642c 2070 6169 722c 2070  rder_id, pair, p
-0000e050: 6172 616d 733d 7061 7261 6d73 290a 2020  arams=params).  
-0000e060: 2020 2020 2020 2020 2020 2020 2020 7365                se
-0000e070: 6c66 2e5f 6c6f 675f 6578 6368 616e 6765  lf._log_exchange
-0000e080: 5f72 6573 706f 6e73 6528 2766 6574 6368  _response('fetch
-0000e090: 5f63 6c6f 7365 645f 6f72 6465 7227 2c20  _closed_order', 
-0000e0a0: 6f72 6465 7229 0a20 2020 2020 2020 2020  order).         
-0000e0b0: 2020 2020 2020 206f 7264 6572 203d 2073         order = s
-0000e0c0: 656c 662e 5f6f 7264 6572 5f63 6f6e 7472  elf._order_contr
-0000e0d0: 6163 7473 5f74 6f5f 616d 6f75 6e74 286f  acts_to_amount(o
-0000e0e0: 7264 6572 290a 2020 2020 2020 2020 2020  rder).          
-0000e0f0: 2020 2020 2020 7265 7475 726e 206f 7264        return ord
-0000e100: 6572 0a20 2020 2020 2020 2020 2020 2065  er.            e
-0000e110: 7863 6570 7420 6363 7874 2e4f 7264 6572  xcept ccxt.Order
-0000e120: 4e6f 7446 6f75 6e64 2061 7320 653a 0a20  NotFound as e:. 
-0000e130: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0000e140: 6169 7365 2052 6574 7279 6162 6c65 4f72  aise RetryableOr
-0000e150: 6465 7245 7272 6f72 280a 2020 2020 2020  derError(.      
-0000e160: 2020 2020 2020 2020 2020 2020 2020 6627                f'
-0000e170: 4f72 6465 7220 6e6f 7420 666f 756e 6420  Order not found 
-0000e180: 2870 6169 723a 207b 7061 6972 7d20 6964  (pair: {pair} id
-0000e190: 3a20 7b6f 7264 6572 5f69 647d 292e 204d  : {order_id}). M
-0000e1a0: 6573 7361 6765 3a20 7b65 7d27 2920 6672  essage: {e}') fr
-0000e1b0: 6f6d 2065 0a20 2020 2020 2020 2065 7863  om e.        exc
-0000e1c0: 6570 7420 6363 7874 2e49 6e76 616c 6964  ept ccxt.Invalid
-0000e1d0: 4f72 6465 7220 6173 2065 3a0a 2020 2020  Order as e:.    
-0000e1e0: 2020 2020 2020 2020 7261 6973 6520 496e          raise In
-0000e1f0: 7661 6c69 644f 7264 6572 4578 6365 7074  validOrderExcept
-0000e200: 696f 6e28 0a20 2020 2020 2020 2020 2020  ion(.           
-0000e210: 2020 2020 2066 2754 7269 6564 2074 6f20       f'Tried to 
-0000e220: 6765 7420 616e 2069 6e76 616c 6964 206f  get an invalid o
-0000e230: 7264 6572 2028 7061 6972 3a20 7b70 6169  rder (pair: {pai
-0000e240: 727d 2069 643a 207b 6f72 6465 725f 6964  r} id: {order_id
-0000e250: 7d29 2e20 4d65 7373 6167 653a 207b 657d  }). Message: {e}
-0000e260: 2729 2066 726f 6d20 650a 2020 2020 2020  ') from e.      
-0000e270: 2020 6578 6365 7074 2063 6378 742e 4444    except ccxt.DD
-0000e280: 6f53 5072 6f74 6563 7469 6f6e 2061 7320  oSProtection as 
-0000e290: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
-0000e2a0: 6169 7365 2044 446f 7350 726f 7465 6374  aise DDosProtect
-0000e2b0: 696f 6e28 6529 2066 726f 6d20 650a 2020  ion(e) from e.  
-0000e2c0: 2020 2020 2020 6578 6365 7074 2028 6363        except (cc
-0000e2d0: 7874 2e4f 7065 7261 7469 6f6e 4661 696c  xt.OperationFail
-0000e2e0: 6564 2c20 6363 7874 2e45 7863 6861 6e67  ed, ccxt.Exchang
-0000e2f0: 6545 7272 6f72 2920 6173 2065 3a0a 2020  eError) as e:.  
-0000e300: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0000e310: 5465 6d70 6f72 6172 7945 7272 6f72 280a  TemporaryError(.
-0000e320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e330: 6627 436f 756c 6420 6e6f 7420 6765 7420  f'Could not get 
-0000e340: 6f72 6465 7220 6475 6520 746f 207b 652e  order due to {e.
-0000e350: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
-0000e360: 5f5f 7d2e 204d 6573 7361 6765 3a20 7b65  __}. Message: {e
-0000e370: 7d27 2920 6672 6f6d 2065 0a20 2020 2020  }') from e.     
-0000e380: 2020 2065 7863 6570 7420 6363 7874 2e42     except ccxt.B
-0000e390: 6173 6545 7272 6f72 2061 7320 653a 0a20  aseError as e:. 
-0000e3a0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0000e3b0: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
-0000e3c0: 7074 696f 6e28 6529 2066 726f 6d20 650a  ption(e) from e.
-0000e3d0: 0a20 2020 2040 7265 7472 6965 7228 7265  .    @retrier(re
-0000e3e0: 7472 6965 733d 4150 495f 4645 5443 485f  tries=API_FETCH_
-0000e3f0: 4f52 4445 525f 5245 5452 595f 434f 554e  ORDER_RETRY_COUN
-0000e400: 5429 0a20 2020 2064 6566 2066 6574 6368  T).    def fetch
-0000e410: 5f6f 7264 6572 2873 656c 662c 206f 7264  _order(self, ord
-0000e420: 6572 5f69 643a 2073 7472 2c20 7061 6972  er_id: str, pair
-0000e430: 3a20 7374 722c 2070 6172 616d 733a 204f  : str, params: O
-0000e440: 7074 696f 6e61 6c5b 4469 6374 5d20 3d20  ptional[Dict] = 
-0000e450: 4e6f 6e65 2920 2d3e 2044 6963 743a 0a20  None) -> Dict:. 
-0000e460: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
-0000e470: 636f 6e66 6967 5b27 6472 795f 7275 6e27  config['dry_run'
-0000e480: 5d3a 0a20 2020 2020 2020 2020 2020 2072  ]:.            r
-0000e490: 6574 7572 6e20 7365 6c66 2e66 6574 6368  eturn self.fetch
-0000e4a0: 5f64 7279 5f72 756e 5f6f 7264 6572 286f  _dry_run_order(o
-0000e4b0: 7264 6572 5f69 6429 0a20 2020 2020 2020  rder_id).       
-0000e4c0: 2069 6620 7061 7261 6d73 2069 7320 4e6f   if params is No
-0000e4d0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-0000e4e0: 7061 7261 6d73 203d 207b 7d0a 2020 2020  params = {}.    
-0000e4f0: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0000e500: 2020 2020 2069 6620 6e6f 7420 7365 6c66       if not self
-0000e510: 2e65 7863 6861 6e67 655f 6861 7328 2766  .exchange_has('f
-0000e520: 6574 6368 4f72 6465 7227 293a 0a20 2020  etchOrder'):.   
-0000e530: 2020 2020 2020 2020 2020 2020 2072 6574               ret
-0000e540: 7572 6e20 7365 6c66 2e66 6574 6368 5f6f  urn self.fetch_o
-0000e550: 7264 6572 5f65 6d75 6c61 7465 6428 6f72  rder_emulated(or
-0000e560: 6465 725f 6964 2c20 7061 6972 2c20 7061  der_id, pair, pa
-0000e570: 7261 6d73 290a 2020 2020 2020 2020 2020  rams).          
-0000e580: 2020 6f72 6465 7220 3d20 7365 6c66 2e5f    order = self._
-0000e590: 6170 692e 6665 7463 685f 6f72 6465 7228  api.fetch_order(
-0000e5a0: 6f72 6465 725f 6964 2c20 7061 6972 2c20  order_id, pair, 
-0000e5b0: 7061 7261 6d73 3d70 6172 616d 7329 0a20  params=params). 
-0000e5c0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0000e5d0: 5f6c 6f67 5f65 7863 6861 6e67 655f 7265  _log_exchange_re
-0000e5e0: 7370 6f6e 7365 2827 6665 7463 685f 6f72  sponse('fetch_or
-0000e5f0: 6465 7227 2c20 6f72 6465 7229 0a20 2020  der', order).   
-0000e600: 2020 2020 2020 2020 206f 7264 6572 203d           order =
-0000e610: 2073 656c 662e 5f6f 7264 6572 5f63 6f6e   self._order_con
-0000e620: 7472 6163 7473 5f74 6f5f 616d 6f75 6e74  tracts_to_amount
-0000e630: 286f 7264 6572 290a 2020 2020 2020 2020  (order).        
-0000e640: 2020 2020 7265 7475 726e 206f 7264 6572      return order
-0000e650: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-0000e660: 6363 7874 2e4f 7264 6572 4e6f 7446 6f75  ccxt.OrderNotFou
-0000e670: 6e64 2061 7320 653a 0a20 2020 2020 2020  nd as e:.       
-0000e680: 2020 2020 2072 6169 7365 2052 6574 7279       raise Retry
-0000e690: 6162 6c65 4f72 6465 7245 7272 6f72 280a  ableOrderError(.
-0000e6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e6b0: 6627 4f72 6465 7220 6e6f 7420 666f 756e  f'Order not foun
-0000e6c0: 6420 2870 6169 723a 207b 7061 6972 7d20  d (pair: {pair} 
-0000e6d0: 6964 3a20 7b6f 7264 6572 5f69 647d 292e  id: {order_id}).
-0000e6e0: 204d 6573 7361 6765 3a20 7b65 7d27 2920   Message: {e}') 
-0000e6f0: 6672 6f6d 2065 0a20 2020 2020 2020 2065  from e.        e
-0000e700: 7863 6570 7420 6363 7874 2e49 6e76 616c  xcept ccxt.Inval
-0000e710: 6964 4f72 6465 7220 6173 2065 3a0a 2020  idOrder as e:.  
-0000e720: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0000e730: 496e 7661 6c69 644f 7264 6572 4578 6365  InvalidOrderExce
-0000e740: 7074 696f 6e28 0a20 2020 2020 2020 2020  ption(.         
-0000e750: 2020 2020 2020 2066 2754 7269 6564 2074         f'Tried t
-0000e760: 6f20 6765 7420 616e 2069 6e76 616c 6964  o get an invalid
-0000e770: 206f 7264 6572 2028 7061 6972 3a20 7b70   order (pair: {p
-0000e780: 6169 727d 2069 643a 207b 6f72 6465 725f  air} id: {order_
-0000e790: 6964 7d29 2e20 4d65 7373 6167 653a 207b  id}). Message: {
-0000e7a0: 657d 2729 2066 726f 6d20 650a 2020 2020  e}') from e.    
-0000e7b0: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
-0000e7c0: 4444 6f53 5072 6f74 6563 7469 6f6e 2061  DDoSProtection a
-0000e7d0: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
-0000e7e0: 2072 6169 7365 2044 446f 7350 726f 7465   raise DDosProte
-0000e7f0: 6374 696f 6e28 6529 2066 726f 6d20 650a  ction(e) from e.
-0000e800: 2020 2020 2020 2020 6578 6365 7074 2028          except (
-0000e810: 6363 7874 2e4f 7065 7261 7469 6f6e 4661  ccxt.OperationFa
-0000e820: 696c 6564 2c20 6363 7874 2e45 7863 6861  iled, ccxt.Excha
-0000e830: 6e67 6545 7272 6f72 2920 6173 2065 3a0a  ngeError) as e:.
-0000e840: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0000e850: 6520 5465 6d70 6f72 6172 7945 7272 6f72  e TemporaryError
-0000e860: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000e870: 2020 6627 436f 756c 6420 6e6f 7420 6765    f'Could not ge
-0000e880: 7420 6f72 6465 7220 6475 6520 746f 207b  t order due to {
-0000e890: 652e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  e.__class__.__na
-0000e8a0: 6d65 5f5f 7d2e 204d 6573 7361 6765 3a20  me__}. Message: 
-0000e8b0: 7b65 7d27 2920 6672 6f6d 2065 0a20 2020  {e}') from e.   
-0000e8c0: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
-0000e8d0: 2e42 6173 6545 7272 6f72 2061 7320 653a  .BaseError as e:
-0000e8e0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0000e8f0: 7365 204f 7065 7261 7469 6f6e 616c 4578  se OperationalEx
-0000e900: 6365 7074 696f 6e28 6529 2066 726f 6d20  ception(e) from 
-0000e910: 650a 0a20 2020 2064 6566 2066 6574 6368  e..    def fetch
-0000e920: 5f73 746f 706c 6f73 735f 6f72 6465 7228  _stoploss_order(
-0000e930: 7365 6c66 2c20 6f72 6465 725f 6964 3a20  self, order_id: 
-0000e940: 7374 722c 2070 6169 723a 2073 7472 2c20  str, pair: str, 
-0000e950: 7061 7261 6d73 3a20 4f70 7469 6f6e 616c  params: Optional
-0000e960: 5b44 6963 745d 203d 204e 6f6e 6529 202d  [Dict] = None) -
-0000e970: 3e20 4469 6374 3a0a 2020 2020 2020 2020  > Dict:.        
-0000e980: 7265 7475 726e 2073 656c 662e 6665 7463  return self.fetc
-0000e990: 685f 6f72 6465 7228 6f72 6465 725f 6964  h_order(order_id
-0000e9a0: 2c20 7061 6972 2c20 7061 7261 6d73 290a  , pair, params).
-0000e9b0: 0a20 2020 2064 6566 2066 6574 6368 5f6f  .    def fetch_o
-0000e9c0: 7264 6572 5f6f 725f 7374 6f70 6c6f 7373  rder_or_stoploss
-0000e9d0: 5f6f 7264 6572 2873 656c 662c 206f 7264  _order(self, ord
-0000e9e0: 6572 5f69 643a 2073 7472 2c20 7061 6972  er_id: str, pair
-0000e9f0: 3a20 7374 722c 0a20 2020 2020 2020 2020  : str,.         
-0000ea00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ea10: 2020 2020 2020 2020 2020 2020 2073 746f               sto
-0000ea20: 706c 6f73 735f 6f72 6465 723a 2062 6f6f  ploss_order: boo
-0000ea30: 6c20 3d20 4661 6c73 6529 202d 3e20 4469  l = False) -> Di
-0000ea40: 6374 3a0a 2020 2020 2020 2020 2222 220a  ct:.        """.
-0000ea50: 2020 2020 2020 2020 5369 6d70 6c65 2077          Simple w
-0000ea60: 7261 7070 6572 2063 616c 6c69 6e67 2065  rapper calling e
-0000ea70: 6974 6865 7220 6665 7463 685f 6f72 6465  ither fetch_orde
-0000ea80: 7220 6f72 2066 6574 6368 5f73 746f 706c  r or fetch_stopl
-0000ea90: 6f73 735f 6f72 6465 7220 6465 7065 6e64  oss_order depend
-0000eaa0: 696e 6720 6f6e 0a20 2020 2020 2020 2074  ing on.        t
-0000eab0: 6865 2073 746f 706c 6f73 735f 6f72 6465  he stoploss_orde
-0000eac0: 7220 7061 7261 6d65 7465 720a 2020 2020  r parameter.    
-0000ead0: 2020 2020 3a70 6172 616d 206f 7264 6572      :param order
-0000eae0: 5f69 643a 204f 7264 6572 4964 2074 6f20  _id: OrderId to 
-0000eaf0: 6665 7463 6820 6f72 6465 720a 2020 2020  fetch order.    
-0000eb00: 2020 2020 3a70 6172 616d 2070 6169 723a      :param pair:
-0000eb10: 2050 6169 7220 636f 7272 6573 706f 6e64   Pair correspond
-0000eb20: 696e 6720 746f 206f 7264 6572 5f69 640a  ing to order_id.
-0000eb30: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
-0000eb40: 746f 706c 6f73 735f 6f72 6465 723a 2049  toploss_order: I
-0000eb50: 6620 7472 7565 2c20 7573 6573 2066 6574  f true, uses fet
-0000eb60: 6368 5f73 746f 706c 6f73 735f 6f72 6465  ch_stoploss_orde
-0000eb70: 722c 206f 7468 6572 7769 7365 2066 6574  r, otherwise fet
-0000eb80: 6368 5f6f 7264 6572 2e0a 2020 2020 2020  ch_order..      
-0000eb90: 2020 2222 220a 2020 2020 2020 2020 6966    """.        if
-0000eba0: 2073 746f 706c 6f73 735f 6f72 6465 723a   stoploss_order:
-0000ebb0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0000ebc0: 7572 6e20 7365 6c66 2e66 6574 6368 5f73  urn self.fetch_s
-0000ebd0: 746f 706c 6f73 735f 6f72 6465 7228 6f72  toploss_order(or
-0000ebe0: 6465 725f 6964 2c20 7061 6972 290a 2020  der_id, pair).  
-0000ebf0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-0000ec00: 662e 6665 7463 685f 6f72 6465 7228 6f72  f.fetch_order(or
-0000ec10: 6465 725f 6964 2c20 7061 6972 290a 0a20  der_id, pair).. 
-0000ec20: 2020 2064 6566 2063 6865 636b 5f6f 7264     def check_ord
-0000ec30: 6572 5f63 616e 6365 6c65 645f 656d 7074  er_canceled_empt
-0000ec40: 7928 7365 6c66 2c20 6f72 6465 723a 2044  y(self, order: D
-0000ec50: 6963 7429 202d 3e20 626f 6f6c 3a0a 2020  ict) -> bool:.  
-0000ec60: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-0000ec70: 2020 5665 7269 6679 2069 6620 616e 206f    Verify if an o
-0000ec80: 7264 6572 2068 6173 2062 6565 6e20 6361  rder has been ca
-0000ec90: 6e63 656c 6c65 6420 7769 7468 6f75 7420  ncelled without 
-0000eca0: 6265 696e 6720 7061 7274 6961 6c6c 7920  being partially 
-0000ecb0: 6669 6c6c 6564 0a20 2020 2020 2020 203a  filled.        :
-0000ecc0: 7061 7261 6d20 6f72 6465 723a 204f 7264  param order: Ord
-0000ecd0: 6572 2064 6963 7420 6173 2072 6574 7572  er dict as retur
-0000ece0: 6e65 6420 6672 6f6d 2066 6574 6368 5f6f  ned from fetch_o
-0000ecf0: 7264 6572 2829 0a20 2020 2020 2020 203a  rder().        :
-0000ed00: 7265 7475 726e 3a20 5472 7565 2069 6620  return: True if 
-0000ed10: 6f72 6465 7220 6861 7320 6265 656e 2063  order has been c
-0000ed20: 616e 6365 6c6c 6564 2077 6974 686f 7574  ancelled without
-0000ed30: 2062 6569 6e67 2066 696c 6c65 642c 2046   being filled, F
-0000ed40: 616c 7365 206f 7468 6572 7769 7365 2e0a  alse otherwise..
-0000ed50: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-0000ed60: 2020 2020 7265 7475 726e 2028 6f72 6465      return (orde
-0000ed70: 722e 6765 7428 2773 7461 7475 7327 2920  r.get('status') 
-0000ed80: 696e 204e 4f4e 5f4f 5045 4e5f 4558 4348  in NON_OPEN_EXCH
-0000ed90: 414e 4745 5f53 5441 5445 530a 2020 2020  ANGE_STATES.    
-0000eda0: 2020 2020 2020 2020 2020 2020 616e 6420              and 
-0000edb0: 6f72 6465 722e 6765 7428 2766 696c 6c65  order.get('fille
-0000edc0: 6427 2920 3d3d 2030 2e30 290a 0a20 2020  d') == 0.0)..   
-0000edd0: 2040 7265 7472 6965 720a 2020 2020 6465   @retrier.    de
-0000ede0: 6620 6361 6e63 656c 5f6f 7264 6572 2873  f cancel_order(s
-0000edf0: 656c 662c 206f 7264 6572 5f69 643a 2073  elf, order_id: s
-0000ee00: 7472 2c20 7061 6972 3a20 7374 722c 2070  tr, pair: str, p
-0000ee10: 6172 616d 733a 204f 7074 696f 6e61 6c5b  arams: Optional[
-0000ee20: 4469 6374 5d20 3d20 4e6f 6e65 2920 2d3e  Dict] = None) ->
-0000ee30: 2044 6963 743a 0a20 2020 2020 2020 2069   Dict:.        i
-0000ee40: 6620 7365 6c66 2e5f 636f 6e66 6967 5b27  f self._config['
-0000ee50: 6472 795f 7275 6e27 5d3a 0a20 2020 2020  dry_run']:.     
-0000ee60: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000ee70: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
-0000ee80: 7220 3d20 7365 6c66 2e66 6574 6368 5f64  r = self.fetch_d
-0000ee90: 7279 5f72 756e 5f6f 7264 6572 286f 7264  ry_run_order(ord
-0000eea0: 6572 5f69 6429 0a0a 2020 2020 2020 2020  er_id)..        
-0000eeb0: 2020 2020 2020 2020 6f72 6465 722e 7570          order.up
-0000eec0: 6461 7465 287b 2773 7461 7475 7327 3a20  date({'status': 
-0000eed0: 2763 616e 6365 6c65 6427 2c20 2766 696c  'canceled', 'fil
-0000eee0: 6c65 6427 3a20 302e 302c 2027 7265 6d61  led': 0.0, 'rema
-0000eef0: 696e 696e 6727 3a20 6f72 6465 725b 2761  ining': order['a
-0000ef00: 6d6f 756e 7427 5d7d 290a 2020 2020 2020  mount']}).      
-0000ef10: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0000ef20: 206f 7264 6572 0a20 2020 2020 2020 2020   order.         
-0000ef30: 2020 2065 7863 6570 7420 496e 7661 6c69     except Invali
-0000ef40: 644f 7264 6572 4578 6365 7074 696f 6e3a  dOrderException:
-0000ef50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ef60: 2072 6574 7572 6e20 7b7d 0a0a 2020 2020   return {}..    
-0000ef70: 2020 2020 6966 2070 6172 616d 7320 6973      if params is
-0000ef80: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-0000ef90: 2020 2070 6172 616d 7320 3d20 7b7d 0a20     params = {}. 
-0000efa0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000efb0: 2020 2020 2020 2020 6f72 6465 7220 3d20          order = 
-0000efc0: 7365 6c66 2e5f 6170 692e 6361 6e63 656c  self._api.cancel
-0000efd0: 5f6f 7264 6572 286f 7264 6572 5f69 642c  _order(order_id,
-0000efe0: 2070 6169 722c 2070 6172 616d 733d 7061   pair, params=pa
-0000eff0: 7261 6d73 290a 2020 2020 2020 2020 2020  rams).          
-0000f000: 2020 7365 6c66 2e5f 6c6f 675f 6578 6368    self._log_exch
-0000f010: 616e 6765 5f72 6573 706f 6e73 6528 2763  ange_response('c
-0000f020: 616e 6365 6c5f 6f72 6465 7227 2c20 6f72  ancel_order', or
-0000f030: 6465 7229 0a20 2020 2020 2020 2020 2020  der).           
-0000f040: 206f 7264 6572 203d 2073 656c 662e 5f6f   order = self._o
-0000f050: 7264 6572 5f63 6f6e 7472 6163 7473 5f74  rder_contracts_t
-0000f060: 6f5f 616d 6f75 6e74 286f 7264 6572 290a  o_amount(order).
-0000f070: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0000f080: 726e 206f 7264 6572 0a20 2020 2020 2020  rn order.       
-0000f090: 2065 7863 6570 7420 6363 7874 2e49 6e76   except ccxt.Inv
-0000f0a0: 616c 6964 4f72 6465 7220 6173 2065 3a0a  alidOrder as e:.
-0000f0b0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0000f0c0: 6520 496e 7661 6c69 644f 7264 6572 4578  e InvalidOrderEx
-0000f0d0: 6365 7074 696f 6e28 0a20 2020 2020 2020  ception(.       
-0000f0e0: 2020 2020 2020 2020 2066 2743 6f75 6c64           f'Could
-0000f0f0: 206e 6f74 2063 616e 6365 6c20 6f72 6465   not cancel orde
-0000f100: 722e 204d 6573 7361 6765 3a20 7b65 7d27  r. Message: {e}'
-0000f110: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
-0000f120: 2065 7863 6570 7420 6363 7874 2e44 446f   except ccxt.DDo
-0000f130: 5350 726f 7465 6374 696f 6e20 6173 2065  SProtection as e
-0000f140: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0000f150: 6973 6520 4444 6f73 5072 6f74 6563 7469  ise DDosProtecti
-0000f160: 6f6e 2865 2920 6672 6f6d 2065 0a20 2020  on(e) from e.   
-0000f170: 2020 2020 2065 7863 6570 7420 2863 6378       except (ccx
-0000f180: 742e 4f70 6572 6174 696f 6e46 6169 6c65  t.OperationFaile
-0000f190: 642c 2063 6378 742e 4578 6368 616e 6765  d, ccxt.Exchange
-0000f1a0: 4572 726f 7229 2061 7320 653a 0a20 2020  Error) as e:.   
-0000f1b0: 2020 2020 2020 2020 2072 6169 7365 2054           raise T
-0000f1c0: 656d 706f 7261 7279 4572 726f 7228 0a20  emporaryError(. 
-0000f1d0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0000f1e0: 2743 6f75 6c64 206e 6f74 2063 616e 6365  'Could not cance
-0000f1f0: 6c20 6f72 6465 7220 6475 6520 746f 207b  l order due to {
-0000f200: 652e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  e.__class__.__na
-0000f210: 6d65 5f5f 7d2e 204d 6573 7361 6765 3a20  me__}. Message: 
-0000f220: 7b65 7d27 2920 6672 6f6d 2065 0a20 2020  {e}') from e.   
-0000f230: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
-0000f240: 2e42 6173 6545 7272 6f72 2061 7320 653a  .BaseError as e:
-0000f250: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0000f260: 7365 204f 7065 7261 7469 6f6e 616c 4578  se OperationalEx
-0000f270: 6365 7074 696f 6e28 6529 2066 726f 6d20  ception(e) from 
-0000f280: 650a 0a20 2020 2064 6566 2063 616e 6365  e..    def cance
-0000f290: 6c5f 7374 6f70 6c6f 7373 5f6f 7264 6572  l_stoploss_order
-0000f2a0: 280a 2020 2020 2020 2020 2020 2020 7365  (.            se
-0000f2b0: 6c66 2c20 6f72 6465 725f 6964 3a20 7374  lf, order_id: st
-0000f2c0: 722c 2070 6169 723a 2073 7472 2c20 7061  r, pair: str, pa
-0000f2d0: 7261 6d73 3a20 4f70 7469 6f6e 616c 5b44  rams: Optional[D
-0000f2e0: 6963 745d 203d 204e 6f6e 6529 202d 3e20  ict] = None) -> 
-0000f2f0: 4469 6374 3a0a 2020 2020 2020 2020 7265  Dict:.        re
-0000f300: 7475 726e 2073 656c 662e 6361 6e63 656c  turn self.cancel
-0000f310: 5f6f 7264 6572 286f 7264 6572 5f69 642c  _order(order_id,
-0000f320: 2070 6169 722c 2070 6172 616d 7329 0a0a   pair, params)..
-0000f330: 2020 2020 6465 6620 6973 5f63 616e 6365      def is_cance
-0000f340: 6c5f 6f72 6465 725f 7265 7375 6c74 5f73  l_order_result_s
-0000f350: 7569 7461 626c 6528 7365 6c66 2c20 636f  uitable(self, co
-0000f360: 7264 6572 2920 2d3e 2062 6f6f 6c3a 0a20  rder) -> bool:. 
-0000f370: 2020 2020 2020 2069 6620 6e6f 7420 6973         if not is
-0000f380: 696e 7374 616e 6365 2863 6f72 6465 722c  instance(corder,
-0000f390: 2064 6963 7429 3a0a 2020 2020 2020 2020   dict):.        
-0000f3a0: 2020 2020 7265 7475 726e 2046 616c 7365      return False
-0000f3b0: 0a0a 2020 2020 2020 2020 7265 7175 6972  ..        requir
-0000f3c0: 6564 203d 2028 2766 6565 272c 2027 7374  ed = ('fee', 'st
-0000f3d0: 6174 7573 272c 2027 616d 6f75 6e74 2729  atus', 'amount')
-0000f3e0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000f3f0: 616c 6c28 636f 7264 6572 2e67 6574 286b  all(corder.get(k
-0000f400: 2c20 4e6f 6e65 2920 6973 206e 6f74 204e  , None) is not N
-0000f410: 6f6e 6520 666f 7220 6b20 696e 2072 6571  one for k in req
-0000f420: 7569 7265 6429 0a0a 2020 2020 6465 6620  uired)..    def 
-0000f430: 6361 6e63 656c 5f6f 7264 6572 5f77 6974  cancel_order_wit
-0000f440: 685f 7265 7375 6c74 2873 656c 662c 206f  h_result(self, o
-0000f450: 7264 6572 5f69 643a 2073 7472 2c20 7061  rder_id: str, pa
-0000f460: 6972 3a20 7374 722c 2061 6d6f 756e 743a  ir: str, amount:
-0000f470: 2066 6c6f 6174 2920 2d3e 2044 6963 743a   float) -> Dict:
-0000f480: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-0000f490: 2020 2020 2043 616e 6365 6c20 6f72 6465       Cancel orde
-0000f4a0: 7220 7265 7475 726e 696e 6720 6120 7265  r returning a re
-0000f4b0: 7375 6c74 2e0a 2020 2020 2020 2020 4372  sult..        Cr
-0000f4c0: 6561 7465 7320 6120 6661 6b65 2072 6573  eates a fake res
-0000f4d0: 756c 7420 6966 2063 616e 6365 6c20 6f72  ult if cancel or
-0000f4e0: 6465 7220 7265 7475 726e 7320 6120 6e6f  der returns a no
-0000f4f0: 6e2d 7573 6162 6c65 2072 6573 756c 740a  n-usable result.
-0000f500: 2020 2020 2020 2020 616e 6420 6665 7463          and fetc
-0000f510: 685f 6f72 6465 7220 646f 6573 206e 6f74  h_order does not
-0000f520: 2077 6f72 6b20 2863 6572 7461 696e 2065   work (certain e
-0000f530: 7863 6861 6e67 6573 2064 6f6e 2774 2072  xchanges don't r
-0000f540: 6574 7572 6e20 6361 6e63 656c 6c65 6420  eturn cancelled 
-0000f550: 6f72 6465 7273 290a 2020 2020 2020 2020  orders).        
-0000f560: 3a70 6172 616d 206f 7264 6572 5f69 643a  :param order_id:
-0000f570: 204f 7264 6572 6964 2074 6f20 6361 6e63   Orderid to canc
-0000f580: 656c 0a20 2020 2020 2020 203a 7061 7261  el.        :para
-0000f590: 6d20 7061 6972 3a20 5061 6972 2063 6f72  m pair: Pair cor
-0000f5a0: 7265 7370 6f6e 6469 6e67 2074 6f20 6f72  responding to or
-0000f5b0: 6465 725f 6964 0a20 2020 2020 2020 203a  der_id.        :
-0000f5c0: 7061 7261 6d20 616d 6f75 6e74 3a20 416d  param amount: Am
-0000f5d0: 6f75 6e74 2074 6f20 7573 6520 666f 7220  ount to use for 
-0000f5e0: 6661 6b65 2072 6573 706f 6e73 650a 2020  fake response.  
-0000f5f0: 2020 2020 2020 3a72 6574 7572 6e3a 2052        :return: R
-0000f600: 6573 756c 7420 6672 6f6d 2065 6974 6865  esult from eithe
-0000f610: 7220 6361 6e63 656c 5f6f 7264 6572 2069  r cancel_order i
-0000f620: 6620 7573 6162 6c65 2c20 6f72 2066 6574  f usable, or fet
-0000f630: 6368 5f6f 7264 6572 0a20 2020 2020 2020  ch_order.       
-0000f640: 2022 2222 0a20 2020 2020 2020 2074 7279   """.        try
-0000f650: 3a0a 2020 2020 2020 2020 2020 2020 636f  :.            co
-0000f660: 7264 6572 203d 2073 656c 662e 6361 6e63  rder = self.canc
-0000f670: 656c 5f6f 7264 6572 286f 7264 6572 5f69  el_order(order_i
-0000f680: 642c 2070 6169 7229 0a20 2020 2020 2020  d, pair).       
-0000f690: 2020 2020 2069 6620 7365 6c66 2e69 735f       if self.is_
-0000f6a0: 6361 6e63 656c 5f6f 7264 6572 5f72 6573  cancel_order_res
-0000f6b0: 756c 745f 7375 6974 6162 6c65 2863 6f72  ult_suitable(cor
-0000f6c0: 6465 7229 3a0a 2020 2020 2020 2020 2020  der):.          
-0000f6d0: 2020 2020 2020 7265 7475 726e 2063 6f72        return cor
-0000f6e0: 6465 720a 2020 2020 2020 2020 6578 6365  der.        exce
-0000f6f0: 7074 2049 6e76 616c 6964 4f72 6465 7245  pt InvalidOrderE
-0000f700: 7863 6570 7469 6f6e 3a0a 2020 2020 2020  xception:.      
-0000f710: 2020 2020 2020 6c6f 6767 6572 2e77 6172        logger.war
-0000f720: 6e69 6e67 2866 2243 6f75 6c64 206e 6f74  ning(f"Could not
-0000f730: 2063 616e 6365 6c20 6f72 6465 7220 7b6f   cancel order {o
-0000f740: 7264 6572 5f69 647d 2066 6f72 207b 7061  rder_id} for {pa
-0000f750: 6972 7d2e 2229 0a20 2020 2020 2020 2074  ir}.").        t
-0000f760: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
-0000f770: 6f72 6465 7220 3d20 7365 6c66 2e66 6574  order = self.fet
-0000f780: 6368 5f6f 7264 6572 286f 7264 6572 5f69  ch_order(order_i
-0000f790: 642c 2070 6169 7229 0a20 2020 2020 2020  d, pair).       
-0000f7a0: 2065 7863 6570 7420 496e 7661 6c69 644f   except InvalidO
-0000f7b0: 7264 6572 4578 6365 7074 696f 6e3a 0a20  rderException:. 
-0000f7c0: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
-0000f7d0: 722e 7761 726e 696e 6728 6622 436f 756c  r.warning(f"Coul
-0000f7e0: 6420 6e6f 7420 6665 7463 6820 6361 6e63  d not fetch canc
-0000f7f0: 656c 6c65 6420 6f72 6465 7220 7b6f 7264  elled order {ord
-0000f800: 6572 5f69 647d 2e22 290a 2020 2020 2020  er_id}.").      
-0000f810: 2020 2020 2020 6f72 6465 7220 3d20 7b0a        order = {.
-0000f820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f830: 2769 6427 3a20 6f72 6465 725f 6964 2c0a  'id': order_id,.
-0000f840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f850: 2773 7461 7475 7327 3a20 2763 616e 6365  'status': 'cance
-0000f860: 6c65 6427 2c0a 2020 2020 2020 2020 2020  led',.          
-0000f870: 2020 2020 2020 2761 6d6f 756e 7427 3a20        'amount': 
-0000f880: 616d 6f75 6e74 2c0a 2020 2020 2020 2020  amount,.        
-0000f890: 2020 2020 2020 2020 2766 696c 6c65 6427          'filled'
-0000f8a0: 3a20 302e 302c 0a20 2020 2020 2020 2020  : 0.0,.         
-0000f8b0: 2020 2020 2020 2027 6665 6527 3a20 7b7d         'fee': {}
-0000f8c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000f8d0: 2020 2769 6e66 6f27 3a20 7b7d 0a20 2020    'info': {}.   
-0000f8e0: 2020 2020 2020 2020 207d 0a0a 2020 2020           }..    
-0000f8f0: 2020 2020 7265 7475 726e 206f 7264 6572      return order
-0000f900: 0a0a 2020 2020 6465 6620 6361 6e63 656c  ..    def cancel
-0000f910: 5f73 746f 706c 6f73 735f 6f72 6465 725f  _stoploss_order_
-0000f920: 7769 7468 5f72 6573 756c 7428 7365 6c66  with_result(self
-0000f930: 2c20 6f72 6465 725f 6964 3a20 7374 722c  , order_id: str,
-0000f940: 2070 6169 723a 2073 7472 2c20 616d 6f75   pair: str, amou
-0000f950: 6e74 3a20 666c 6f61 7429 202d 3e20 4469  nt: float) -> Di
-0000f960: 6374 3a0a 2020 2020 2020 2020 2222 220a  ct:.        """.
-0000f970: 2020 2020 2020 2020 4361 6e63 656c 2073          Cancel s
-0000f980: 746f 706c 6f73 7320 6f72 6465 7220 7265  toploss order re
-0000f990: 7475 726e 696e 6720 6120 7265 7375 6c74  turning a result
-0000f9a0: 2e0a 2020 2020 2020 2020 4372 6561 7465  ..        Create
-0000f9b0: 7320 6120 6661 6b65 2072 6573 756c 7420  s a fake result 
-0000f9c0: 6966 2063 616e 6365 6c20 6f72 6465 7220  if cancel order 
-0000f9d0: 7265 7475 726e 7320 6120 6e6f 6e2d 7573  returns a non-us
-0000f9e0: 6162 6c65 2072 6573 756c 740a 2020 2020  able result.    
-0000f9f0: 2020 2020 616e 6420 6665 7463 685f 6f72      and fetch_or
-0000fa00: 6465 7220 646f 6573 206e 6f74 2077 6f72  der does not wor
-0000fa10: 6b20 2863 6572 7461 696e 2065 7863 6861  k (certain excha
-0000fa20: 6e67 6573 2064 6f6e 2774 2072 6574 7572  nges don't retur
-0000fa30: 6e20 6361 6e63 656c 6c65 6420 6f72 6465  n cancelled orde
-0000fa40: 7273 290a 2020 2020 2020 2020 3a70 6172  rs).        :par
-0000fa50: 616d 206f 7264 6572 5f69 643a 2073 746f  am order_id: sto
-0000fa60: 706c 6f73 732d 6f72 6465 722d 6964 2074  ploss-order-id t
-0000fa70: 6f20 6361 6e63 656c 0a20 2020 2020 2020  o cancel.       
-0000fa80: 203a 7061 7261 6d20 7061 6972 3a20 5061   :param pair: Pa
-0000fa90: 6972 2063 6f72 7265 7370 6f6e 6469 6e67  ir corresponding
-0000faa0: 2074 6f20 6f72 6465 725f 6964 0a20 2020   to order_id.   
-0000fab0: 2020 2020 203a 7061 7261 6d20 616d 6f75       :param amou
-0000fac0: 6e74 3a20 416d 6f75 6e74 2074 6f20 7573  nt: Amount to us
-0000fad0: 6520 666f 7220 6661 6b65 2072 6573 706f  e for fake respo
-0000fae0: 6e73 650a 2020 2020 2020 2020 3a72 6574  nse.        :ret
-0000faf0: 7572 6e3a 2052 6573 756c 7420 6672 6f6d  urn: Result from
-0000fb00: 2065 6974 6865 7220 6361 6e63 656c 5f6f   either cancel_o
-0000fb10: 7264 6572 2069 6620 7573 6162 6c65 2c20  rder if usable, 
-0000fb20: 6f72 2066 6574 6368 5f6f 7264 6572 0a20  or fetch_order. 
-0000fb30: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-0000fb40: 2020 2063 6f72 6465 7220 3d20 7365 6c66     corder = self
-0000fb50: 2e63 616e 6365 6c5f 7374 6f70 6c6f 7373  .cancel_stoploss
-0000fb60: 5f6f 7264 6572 286f 7264 6572 5f69 642c  _order(order_id,
-0000fb70: 2070 6169 7229 0a20 2020 2020 2020 2069   pair).        i
-0000fb80: 6620 7365 6c66 2e69 735f 6361 6e63 656c  f self.is_cancel
-0000fb90: 5f6f 7264 6572 5f72 6573 756c 745f 7375  _order_result_su
-0000fba0: 6974 6162 6c65 2863 6f72 6465 7229 3a0a  itable(corder):.
-0000fbb0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0000fbc0: 726e 2063 6f72 6465 720a 2020 2020 2020  rn corder.      
-0000fbd0: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
-0000fbe0: 2020 206f 7264 6572 203d 2073 656c 662e     order = self.
-0000fbf0: 6665 7463 685f 7374 6f70 6c6f 7373 5f6f  fetch_stoploss_o
-0000fc00: 7264 6572 286f 7264 6572 5f69 642c 2070  rder(order_id, p
-0000fc10: 6169 7229 0a20 2020 2020 2020 2065 7863  air).        exc
-0000fc20: 6570 7420 496e 7661 6c69 644f 7264 6572  ept InvalidOrder
-0000fc30: 4578 6365 7074 696f 6e3a 0a20 2020 2020  Exception:.     
-0000fc40: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
-0000fc50: 726e 696e 6728 6622 436f 756c 6420 6e6f  rning(f"Could no
-0000fc60: 7420 6665 7463 6820 6361 6e63 656c 6c65  t fetch cancelle
-0000fc70: 6420 7374 6f70 6c6f 7373 206f 7264 6572  d stoploss order
-0000fc80: 207b 6f72 6465 725f 6964 7d2e 2229 0a20   {order_id}."). 
-0000fc90: 2020 2020 2020 2020 2020 206f 7264 6572             order
-0000fca0: 203d 207b 2769 6427 3a20 6f72 6465 725f   = {'id': order_
-0000fcb0: 6964 2c20 2766 6565 273a 207b 7d2c 2027  id, 'fee': {}, '
-0000fcc0: 7374 6174 7573 273a 2027 6361 6e63 656c  status': 'cancel
-0000fcd0: 6564 272c 2027 616d 6f75 6e74 273a 2061  ed', 'amount': a
-0000fce0: 6d6f 756e 742c 2027 696e 666f 273a 207b  mount, 'info': {
-0000fcf0: 7d7d 0a0a 2020 2020 2020 2020 7265 7475  }}..        retu
-0000fd00: 726e 206f 7264 6572 0a0a 2020 2020 4072  rn order..    @r
-0000fd10: 6574 7269 6572 0a20 2020 2064 6566 2067  etrier.    def g
-0000fd20: 6574 5f62 616c 616e 6365 7328 7365 6c66  et_balances(self
-0000fd30: 2920 2d3e 2064 6963 743a 0a0a 2020 2020  ) -> dict:..    
-0000fd40: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0000fd50: 2020 2020 2062 616c 616e 6365 7320 3d20       balances = 
-0000fd60: 7365 6c66 2e5f 6170 692e 6665 7463 685f  self._api.fetch_
-0000fd70: 6261 6c61 6e63 6528 290a 2020 2020 2020  balance().      
-0000fd80: 2020 2020 2020 2320 5265 6d6f 7665 2061        # Remove a
-0000fd90: 6464 6974 696f 6e61 6c20 696e 666f 2066  dditional info f
-0000fda0: 726f 6d20 6363 7874 2072 6573 756c 7473  rom ccxt results
-0000fdb0: 0a20 2020 2020 2020 2020 2020 2062 616c  .            bal
-0000fdc0: 616e 6365 732e 706f 7028 2269 6e66 6f22  ances.pop("info"
-0000fdd0: 2c20 4e6f 6e65 290a 2020 2020 2020 2020  , None).        
-0000fde0: 2020 2020 6261 6c61 6e63 6573 2e70 6f70      balances.pop
-0000fdf0: 2822 6672 6565 222c 204e 6f6e 6529 0a20  ("free", None). 
-0000fe00: 2020 2020 2020 2020 2020 2062 616c 616e             balan
-0000fe10: 6365 732e 706f 7028 2274 6f74 616c 222c  ces.pop("total",
-0000fe20: 204e 6f6e 6529 0a20 2020 2020 2020 2020   None).         
-0000fe30: 2020 2062 616c 616e 6365 732e 706f 7028     balances.pop(
-0000fe40: 2275 7365 6422 2c20 4e6f 6e65 290a 0a20  "used", None).. 
-0000fe50: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0000fe60: 6e20 6261 6c61 6e63 6573 0a20 2020 2020  n balances.     
-0000fe70: 2020 2065 7863 6570 7420 6363 7874 2e44     except ccxt.D
-0000fe80: 446f 5350 726f 7465 6374 696f 6e20 6173  DoSProtection as
-0000fe90: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-0000fea0: 7261 6973 6520 4444 6f73 5072 6f74 6563  raise DDosProtec
-0000feb0: 7469 6f6e 2865 2920 6672 6f6d 2065 0a20  tion(e) from e. 
-0000fec0: 2020 2020 2020 2065 7863 6570 7420 2863         except (c
-0000fed0: 6378 742e 4f70 6572 6174 696f 6e46 6169  cxt.OperationFai
-0000fee0: 6c65 642c 2063 6378 742e 4578 6368 616e  led, ccxt.Exchan
-0000fef0: 6765 4572 726f 7229 2061 7320 653a 0a20  geError) as e:. 
-0000ff00: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0000ff10: 2054 656d 706f 7261 7279 4572 726f 7228   TemporaryError(
-0000ff20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ff30: 2066 2743 6f75 6c64 206e 6f74 2067 6574   f'Could not get
-0000ff40: 2062 616c 616e 6365 2064 7565 2074 6f20   balance due to 
-0000ff50: 7b65 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e  {e.__class__.__n
-0000ff60: 616d 655f 5f7d 2e20 4d65 7373 6167 653a  ame__}. Message:
-0000ff70: 207b 657d 2729 2066 726f 6d20 650a 2020   {e}') from e.  
-0000ff80: 2020 2020 2020 6578 6365 7074 2063 6378        except ccx
-0000ff90: 742e 4261 7365 4572 726f 7220 6173 2065  t.BaseError as e
-0000ffa0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0000ffb0: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
-0000ffc0: 7863 6570 7469 6f6e 2865 2920 6672 6f6d  xception(e) from
-0000ffd0: 2065 0a0a 2020 2020 4072 6574 7269 6572   e..    @retrier
-0000ffe0: 0a20 2020 2064 6566 2066 6574 6368 5f70  .    def fetch_p
-0000fff0: 6f73 6974 696f 6e73 2873 656c 662c 2070  ositions(self, p
-00010000: 6169 723a 204f 7074 696f 6e61 6c5b 7374  air: Optional[st
-00010010: 725d 203d 204e 6f6e 6529 202d 3e20 4c69  r] = None) -> Li
-00010020: 7374 5b44 6963 745d 3a0a 2020 2020 2020  st[Dict]:.      
-00010030: 2020 2222 220a 2020 2020 2020 2020 4665    """.        Fe
-00010040: 7463 6820 706f 7369 7469 6f6e 7320 6672  tch positions fr
-00010050: 6f6d 2074 6865 2065 7863 6861 6e67 652e  om the exchange.
-00010060: 0a20 2020 2020 2020 2049 6620 6e6f 2070  .        If no p
-00010070: 6169 7220 6973 2067 6976 656e 2c20 616c  air is given, al
-00010080: 6c20 706f 7369 7469 6f6e 7320 6172 6520  l positions are 
-00010090: 7265 7475 726e 6564 2e0a 2020 2020 2020  returned..      
-000100a0: 2020 3a70 6172 616d 2070 6169 723a 2050    :param pair: P
-000100b0: 6169 7220 666f 7220 7468 6520 7175 6572  air for the quer
-000100c0: 790a 2020 2020 2020 2020 2222 220a 2020  y.        """.  
-000100d0: 2020 2020 2020 6966 2073 656c 662e 5f63        if self._c
-000100e0: 6f6e 6669 675b 2764 7279 5f72 756e 275d  onfig['dry_run']
-000100f0: 206f 7220 7365 6c66 2e74 7261 6469 6e67   or self.trading
-00010100: 5f6d 6f64 6520 213d 2054 7261 6469 6e67  _mode != Trading
-00010110: 4d6f 6465 2e46 5554 5552 4553 3a0a 2020  Mode.FUTURES:.  
-00010120: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00010130: 205b 5d0a 2020 2020 2020 2020 7472 793a   [].        try:
-00010140: 0a20 2020 2020 2020 2020 2020 2073 796d  .            sym
-00010150: 626f 6c73 203d 205b 5d0a 2020 2020 2020  bols = [].      
-00010160: 2020 2020 2020 6966 2070 6169 723a 0a20        if pair:. 
-00010170: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00010180: 796d 626f 6c73 2e61 7070 656e 6428 7061  ymbols.append(pa
-00010190: 6972 290a 2020 2020 2020 2020 2020 2020  ir).            
-000101a0: 706f 7369 7469 6f6e 733a 204c 6973 745b  positions: List[
-000101b0: 4469 6374 5d20 3d20 7365 6c66 2e5f 6170  Dict] = self._ap
-000101c0: 692e 6665 7463 685f 706f 7369 7469 6f6e  i.fetch_position
-000101d0: 7328 7379 6d62 6f6c 7329 0a20 2020 2020  s(symbols).     
-000101e0: 2020 2020 2020 2073 656c 662e 5f6c 6f67         self._log
-000101f0: 5f65 7863 6861 6e67 655f 7265 7370 6f6e  _exchange_respon
-00010200: 7365 2827 6665 7463 685f 706f 7369 7469  se('fetch_positi
-00010210: 6f6e 7327 2c20 706f 7369 7469 6f6e 7329  ons', positions)
-00010220: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00010230: 7572 6e20 706f 7369 7469 6f6e 730a 2020  urn positions.  
-00010240: 2020 2020 2020 6578 6365 7074 2063 6378        except ccx
-00010250: 742e 4444 6f53 5072 6f74 6563 7469 6f6e  t.DDoSProtection
-00010260: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
-00010270: 2020 2072 6169 7365 2044 446f 7350 726f     raise DDosPro
-00010280: 7465 6374 696f 6e28 6529 2066 726f 6d20  tection(e) from 
-00010290: 650a 2020 2020 2020 2020 6578 6365 7074  e.        except
-000102a0: 2028 6363 7874 2e4f 7065 7261 7469 6f6e   (ccxt.Operation
-000102b0: 4661 696c 6564 2c20 6363 7874 2e45 7863  Failed, ccxt.Exc
-000102c0: 6861 6e67 6545 7272 6f72 2920 6173 2065  hangeError) as e
-000102d0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-000102e0: 6973 6520 5465 6d70 6f72 6172 7945 7272  ise TemporaryErr
-000102f0: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
-00010300: 2020 2020 6627 436f 756c 6420 6e6f 7420      f'Could not 
-00010310: 6765 7420 706f 7369 7469 6f6e 7320 6475  get positions du
-00010320: 6520 746f 207b 652e 5f5f 636c 6173 735f  e to {e.__class_
-00010330: 5f2e 5f5f 6e61 6d65 5f5f 7d2e 204d 6573  _.__name__}. Mes
-00010340: 7361 6765 3a20 7b65 7d27 2920 6672 6f6d  sage: {e}') from
-00010350: 2065 0a20 2020 2020 2020 2065 7863 6570   e.        excep
-00010360: 7420 6363 7874 2e42 6173 6545 7272 6f72  t ccxt.BaseError
-00010370: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
-00010380: 2020 2072 6169 7365 204f 7065 7261 7469     raise Operati
-00010390: 6f6e 616c 4578 6365 7074 696f 6e28 6529  onalException(e)
-000103a0: 2066 726f 6d20 650a 0a20 2020 2064 6566   from e..    def
-000103b0: 205f 6665 7463 685f 6f72 6465 7273 5f65   _fetch_orders_e
-000103c0: 6d75 6c61 7465 2873 656c 662c 2070 6169  mulate(self, pai
-000103d0: 723a 2073 7472 2c20 7369 6e63 655f 6d73  r: str, since_ms
-000103e0: 3a20 696e 7429 202d 3e20 4c69 7374 5b44  : int) -> List[D
-000103f0: 6963 745d 3a0a 2020 2020 2020 2020 6f72  ict]:.        or
-00010400: 6465 7273 203d 205b 5d0a 2020 2020 2020  ders = [].      
-00010410: 2020 6966 2073 656c 662e 6578 6368 616e    if self.exchan
-00010420: 6765 5f68 6173 2827 6665 7463 6843 6c6f  ge_has('fetchClo
-00010430: 7365 644f 7264 6572 7327 293a 0a20 2020  sedOrders'):.   
-00010440: 2020 2020 2020 2020 206f 7264 6572 7320           orders 
-00010450: 3d20 7365 6c66 2e5f 6170 692e 6665 7463  = self._api.fetc
-00010460: 685f 636c 6f73 6564 5f6f 7264 6572 7328  h_closed_orders(
-00010470: 7061 6972 2c20 7369 6e63 653d 7369 6e63  pair, since=sinc
-00010480: 655f 6d73 290a 2020 2020 2020 2020 2020  e_ms).          
-00010490: 2020 6966 2073 656c 662e 6578 6368 616e    if self.exchan
-000104a0: 6765 5f68 6173 2827 6665 7463 684f 7065  ge_has('fetchOpe
-000104b0: 6e4f 7264 6572 7327 293a 0a20 2020 2020  nOrders'):.     
-000104c0: 2020 2020 2020 2020 2020 206f 7264 6572             order
-000104d0: 735f 6f70 656e 203d 2073 656c 662e 5f61  s_open = self._a
-000104e0: 7069 2e66 6574 6368 5f6f 7065 6e5f 6f72  pi.fetch_open_or
-000104f0: 6465 7273 2870 6169 722c 2073 696e 6365  ders(pair, since
-00010500: 3d73 696e 6365 5f6d 7329 0a20 2020 2020  =since_ms).     
-00010510: 2020 2020 2020 2020 2020 206f 7264 6572             order
-00010520: 732e 6578 7465 6e64 286f 7264 6572 735f  s.extend(orders_
-00010530: 6f70 656e 290a 2020 2020 2020 2020 7265  open).        re
-00010540: 7475 726e 206f 7264 6572 730a 0a20 2020  turn orders..   
-00010550: 2040 7265 7472 6965 7228 7265 7472 6965   @retrier(retrie
-00010560: 733d 3029 0a20 2020 2064 6566 2066 6574  s=0).    def fet
-00010570: 6368 5f6f 7264 6572 7328 7365 6c66 2c20  ch_orders(self, 
-00010580: 7061 6972 3a20 7374 722c 2073 696e 6365  pair: str, since
-00010590: 3a20 6461 7465 7469 6d65 2c20 7061 7261  : datetime, para
-000105a0: 6d73 3a20 4f70 7469 6f6e 616c 5b44 6963  ms: Optional[Dic
-000105b0: 745d 203d 204e 6f6e 6529 202d 3e20 4c69  t] = None) -> Li
-000105c0: 7374 5b44 6963 745d 3a0a 2020 2020 2020  st[Dict]:.      
-000105d0: 2020 2222 220a 2020 2020 2020 2020 4665    """.        Fe
-000105e0: 7463 6820 616c 6c20 6f72 6465 7273 2066  tch all orders f
-000105f0: 6f72 2061 2070 6169 7220 2273 696e 6365  or a pair "since
-00010600: 220a 2020 2020 2020 2020 3a70 6172 616d  ".        :param
-00010610: 2070 6169 723a 2050 6169 7220 666f 7220   pair: Pair for 
-00010620: 7468 6520 7175 6572 790a 2020 2020 2020  the query.      
-00010630: 2020 3a70 6172 616d 2073 696e 6365 3a20    :param since: 
-00010640: 5374 6172 7469 6e67 2074 696d 6520 666f  Starting time fo
-00010650: 7220 7468 6520 7175 6572 790a 2020 2020  r the query.    
-00010660: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-00010670: 6966 2073 656c 662e 5f63 6f6e 6669 675b  if self._config[
-00010680: 2764 7279 5f72 756e 275d 3a0a 2020 2020  'dry_run']:.    
-00010690: 2020 2020 2020 2020 7265 7475 726e 205b          return [
-000106a0: 5d0a 0a20 2020 2020 2020 2074 7279 3a0a  ]..        try:.
-000106b0: 2020 2020 2020 2020 2020 2020 7369 6e63              sinc
-000106c0: 655f 6d73 203d 2069 6e74 2828 7369 6e63  e_ms = int((sinc
-000106d0: 652e 7469 6d65 7374 616d 7028 2920 2d20  e.timestamp() - 
-000106e0: 3130 2920 2a20 3130 3030 290a 0a20 2020  10) * 1000)..   
-000106f0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00010700: 2e65 7863 6861 6e67 655f 6861 7328 2766  .exchange_has('f
-00010710: 6574 6368 4f72 6465 7273 2729 3a0a 2020  etchOrders'):.  
-00010720: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00010730: 206e 6f74 2070 6172 616d 733a 0a20 2020   not params:.   
-00010740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010750: 2070 6172 616d 7320 3d20 7b7d 0a20 2020   params = {}.   
-00010760: 2020 2020 2020 2020 2020 2020 2074 7279               try
-00010770: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00010780: 2020 2020 2020 6f72 6465 7273 3a20 4c69        orders: Li
-00010790: 7374 5b44 6963 745d 203d 2073 656c 662e  st[Dict] = self.
-000107a0: 5f61 7069 2e66 6574 6368 5f6f 7264 6572  _api.fetch_order
-000107b0: 7328 7061 6972 2c20 7369 6e63 653d 7369  s(pair, since=si
-000107c0: 6e63 655f 6d73 2c20 7061 7261 6d73 3d70  nce_ms, params=p
-000107d0: 6172 616d 7329 0a20 2020 2020 2020 2020  arams).         
-000107e0: 2020 2020 2020 2065 7863 6570 7420 6363         except cc
-000107f0: 7874 2e4e 6f74 5375 7070 6f72 7465 643a  xt.NotSupported:
-00010800: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00010810: 2020 2020 2023 2053 6f6d 6520 6578 6368       # Some exch
-00010820: 616e 6765 7320 646f 6e27 7420 7375 7070  anges don't supp
-00010830: 6f72 7420 6665 7463 684f 7264 6572 730a  ort fetchOrders.
-00010840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010850: 2020 2020 2320 6174 7465 6d70 7420 746f      # attempt to
-00010860: 2066 6574 6368 206f 7065 6e20 616e 6420   fetch open and 
-00010870: 636c 6f73 6564 206f 7264 6572 7320 7365  closed orders se
-00010880: 7061 7261 7465 6c79 0a20 2020 2020 2020  parately.       
-00010890: 2020 2020 2020 2020 2020 2020 206f 7264               ord
-000108a0: 6572 7320 3d20 7365 6c66 2e5f 6665 7463  ers = self._fetc
-000108b0: 685f 6f72 6465 7273 5f65 6d75 6c61 7465  h_orders_emulate
-000108c0: 2870 6169 722c 2073 696e 6365 5f6d 7329  (pair, since_ms)
-000108d0: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-000108e0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-000108f0: 2020 206f 7264 6572 7320 3d20 7365 6c66     orders = self
-00010900: 2e5f 6665 7463 685f 6f72 6465 7273 5f65  ._fetch_orders_e
-00010910: 6d75 6c61 7465 2870 6169 722c 2073 696e  mulate(pair, sin
-00010920: 6365 5f6d 7329 0a20 2020 2020 2020 2020  ce_ms).         
-00010930: 2020 2073 656c 662e 5f6c 6f67 5f65 7863     self._log_exc
-00010940: 6861 6e67 655f 7265 7370 6f6e 7365 2827  hange_response('
-00010950: 6665 7463 685f 6f72 6465 7273 272c 206f  fetch_orders', o
-00010960: 7264 6572 7329 0a20 2020 2020 2020 2020  rders).         
-00010970: 2020 206f 7264 6572 7320 3d20 5b73 656c     orders = [sel
-00010980: 662e 5f6f 7264 6572 5f63 6f6e 7472 6163  f._order_contrac
-00010990: 7473 5f74 6f5f 616d 6f75 6e74 286f 2920  ts_to_amount(o) 
-000109a0: 666f 7220 6f20 696e 206f 7264 6572 735d  for o in orders]
-000109b0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-000109c0: 7572 6e20 6f72 6465 7273 0a20 2020 2020  urn orders.     
-000109d0: 2020 2065 7863 6570 7420 6363 7874 2e44     except ccxt.D
-000109e0: 446f 5350 726f 7465 6374 696f 6e20 6173  DoSProtection as
-000109f0: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-00010a00: 7261 6973 6520 4444 6f73 5072 6f74 6563  raise DDosProtec
-00010a10: 7469 6f6e 2865 2920 6672 6f6d 2065 0a20  tion(e) from e. 
-00010a20: 2020 2020 2020 2065 7863 6570 7420 2863         except (c
-00010a30: 6378 742e 4f70 6572 6174 696f 6e46 6169  cxt.OperationFai
-00010a40: 6c65 642c 2063 6378 742e 4578 6368 616e  led, ccxt.Exchan
-00010a50: 6765 4572 726f 7229 2061 7320 653a 0a20  geError) as e:. 
-00010a60: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00010a70: 2054 656d 706f 7261 7279 4572 726f 7228   TemporaryError(
-00010a80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00010a90: 2066 2743 6f75 6c64 206e 6f74 2066 6574   f'Could not fet
-00010aa0: 6368 2070 6f73 6974 696f 6e73 2064 7565  ch positions due
-00010ab0: 2074 6f20 7b65 2e5f 5f63 6c61 7373 5f5f   to {e.__class__
-00010ac0: 2e5f 5f6e 616d 655f 5f7d 2e20 4d65 7373  .__name__}. Mess
-00010ad0: 6167 653a 207b 657d 2729 2066 726f 6d20  age: {e}') from 
-00010ae0: 650a 2020 2020 2020 2020 6578 6365 7074  e.        except
-00010af0: 2063 6378 742e 4261 7365 4572 726f 7220   ccxt.BaseError 
-00010b00: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
-00010b10: 2020 7261 6973 6520 4f70 6572 6174 696f    raise Operatio
-00010b20: 6e61 6c45 7863 6570 7469 6f6e 2865 2920  nalException(e) 
-00010b30: 6672 6f6d 2065 0a0a 2020 2020 4072 6574  from e..    @ret
-00010b40: 7269 6572 0a20 2020 2064 6566 2066 6574  rier.    def fet
-00010b50: 6368 5f74 7261 6469 6e67 5f66 6565 7328  ch_trading_fees(
-00010b60: 7365 6c66 2920 2d3e 2044 6963 745b 7374  self) -> Dict[st
-00010b70: 722c 2041 6e79 5d3a 0a20 2020 2020 2020  r, Any]:.       
-00010b80: 2022 2222 0a20 2020 2020 2020 2046 6574   """.        Fet
-00010b90: 6368 2075 7365 7220 6163 636f 756e 7420  ch user account 
-00010ba0: 7472 6164 696e 6720 6665 6573 0a20 2020  trading fees.   
-00010bb0: 2020 2020 2043 616e 2062 6520 6361 6368       Can be cach
-00010bc0: 6564 2c20 7368 6f75 6c64 206e 6f74 2075  ed, should not u
-00010bd0: 7064 6174 6520 6f66 7465 6e2e 0a20 2020  pdate often..   
-00010be0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00010bf0: 2069 6620 2873 656c 662e 5f63 6f6e 6669   if (self._confi
-00010c00: 675b 2764 7279 5f72 756e 275d 206f 7220  g['dry_run'] or 
-00010c10: 7365 6c66 2e74 7261 6469 6e67 5f6d 6f64  self.trading_mod
-00010c20: 6520 213d 2054 7261 6469 6e67 4d6f 6465  e != TradingMode
-00010c30: 2e46 5554 5552 4553 0a20 2020 2020 2020  .FUTURES.       
-00010c40: 2020 2020 2020 2020 206f 7220 6e6f 7420           or not 
-00010c50: 7365 6c66 2e65 7863 6861 6e67 655f 6861  self.exchange_ha
-00010c60: 7328 2766 6574 6368 5472 6164 696e 6746  s('fetchTradingF
-00010c70: 6565 7327 2929 3a0a 2020 2020 2020 2020  ees')):.        
-00010c80: 2020 2020 7265 7475 726e 207b 7d0a 2020      return {}.  
-00010c90: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
-00010ca0: 2020 2020 2020 2074 7261 6469 6e67 5f66         trading_f
-00010cb0: 6565 733a 2044 6963 745b 7374 722c 2041  ees: Dict[str, A
-00010cc0: 6e79 5d20 3d20 7365 6c66 2e5f 6170 692e  ny] = self._api.
-00010cd0: 6665 7463 685f 7472 6164 696e 675f 6665  fetch_trading_fe
-00010ce0: 6573 2829 0a20 2020 2020 2020 2020 2020  es().           
-00010cf0: 2073 656c 662e 5f6c 6f67 5f65 7863 6861   self._log_excha
-00010d00: 6e67 655f 7265 7370 6f6e 7365 2827 6665  nge_response('fe
-00010d10: 7463 685f 7472 6164 696e 675f 6665 6573  tch_trading_fees
-00010d20: 272c 2074 7261 6469 6e67 5f66 6565 7329  ', trading_fees)
-00010d30: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00010d40: 7572 6e20 7472 6164 696e 675f 6665 6573  urn trading_fees
-00010d50: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-00010d60: 6363 7874 2e44 446f 5350 726f 7465 6374  ccxt.DDoSProtect
-00010d70: 696f 6e20 6173 2065 3a0a 2020 2020 2020  ion as e:.      
-00010d80: 2020 2020 2020 7261 6973 6520 4444 6f73        raise DDos
-00010d90: 5072 6f74 6563 7469 6f6e 2865 2920 6672  Protection(e) fr
-00010da0: 6f6d 2065 0a20 2020 2020 2020 2065 7863  om e.        exc
-00010db0: 6570 7420 2863 6378 742e 4f70 6572 6174  ept (ccxt.Operat
-00010dc0: 696f 6e46 6169 6c65 642c 2063 6378 742e  ionFailed, ccxt.
-00010dd0: 4578 6368 616e 6765 4572 726f 7229 2061  ExchangeError) a
-00010de0: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
-00010df0: 2072 6169 7365 2054 656d 706f 7261 7279   raise Temporary
-00010e00: 4572 726f 7228 0a20 2020 2020 2020 2020  Error(.         
-00010e10: 2020 2020 2020 2066 2743 6f75 6c64 206e         f'Could n
-00010e20: 6f74 2066 6574 6368 2074 7261 6469 6e67  ot fetch trading
-00010e30: 2066 6565 7320 6475 6520 746f 207b 652e   fees due to {e.
-00010e40: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
-00010e50: 5f5f 7d2e 204d 6573 7361 6765 3a20 7b65  __}. Message: {e
-00010e60: 7d27 2920 6672 6f6d 2065 0a20 2020 2020  }') from e.     
-00010e70: 2020 2065 7863 6570 7420 6363 7874 2e42     except ccxt.B
-00010e80: 6173 6545 7272 6f72 2061 7320 653a 0a20  aseError as e:. 
-00010e90: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00010ea0: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
-00010eb0: 7074 696f 6e28 6529 2066 726f 6d20 650a  ption(e) from e.
-00010ec0: 0a20 2020 2040 7265 7472 6965 720a 2020  .    @retrier.  
-00010ed0: 2020 6465 6620 6665 7463 685f 6269 6473    def fetch_bids
-00010ee0: 5f61 736b 7328 7365 6c66 2c20 7379 6d62  _asks(self, symb
-00010ef0: 6f6c 733a 204f 7074 696f 6e61 6c5b 4c69  ols: Optional[Li
-00010f00: 7374 5b73 7472 5d5d 203d 204e 6f6e 652c  st[str]] = None,
-00010f10: 2063 6163 6865 643a 2062 6f6f 6c20 3d20   cached: bool = 
-00010f20: 4661 6c73 6529 202d 3e20 4469 6374 3a0a  False) -> Dict:.
-00010f30: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00010f40: 2020 2020 3a70 6172 616d 2073 796d 626f      :param symbo
-00010f50: 6c73 3a20 4c69 7374 206f 6620 7379 6d62  ls: List of symb
-00010f60: 6f6c 7320 746f 2066 6574 6368 0a20 2020  ols to fetch.   
-00010f70: 2020 2020 203a 7061 7261 6d20 6361 6368       :param cach
-00010f80: 6564 3a20 416c 6c6f 7720 6361 6368 6564  ed: Allow cached
-00010f90: 2072 6573 756c 740a 2020 2020 2020 2020   result.        
-00010fa0: 3a72 6574 7572 6e3a 2066 6574 6368 5f62  :return: fetch_b
-00010fb0: 6964 735f 6173 6b73 2072 6573 756c 740a  ids_asks result.
-00010fc0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00010fd0: 2020 2020 6966 206e 6f74 2073 656c 662e      if not self.
-00010fe0: 6578 6368 616e 6765 5f68 6173 2827 6665  exchange_has('fe
-00010ff0: 7463 6842 6964 7341 736b 7327 293a 0a20  tchBidsAsks'):. 
-00011000: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00011010: 6e20 7b7d 0a20 2020 2020 2020 2069 6620  n {}.        if 
-00011020: 6361 6368 6564 3a0a 2020 2020 2020 2020  cached:.        
-00011030: 2020 2020 7769 7468 2073 656c 662e 5f63      with self._c
-00011040: 6163 6865 5f6c 6f63 6b3a 0a20 2020 2020  ache_lock:.     
-00011050: 2020 2020 2020 2020 2020 2074 6963 6b65             ticke
-00011060: 7273 203d 2073 656c 662e 5f66 6574 6368  rs = self._fetch
-00011070: 5f74 6963 6b65 7273 5f63 6163 6865 2e67  _tickers_cache.g
-00011080: 6574 2827 6665 7463 685f 6269 6473 5f61  et('fetch_bids_a
-00011090: 736b 7327 290a 2020 2020 2020 2020 2020  sks').          
-000110a0: 2020 6966 2074 6963 6b65 7273 3a0a 2020    if tickers:.  
-000110b0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-000110c0: 7475 726e 2074 6963 6b65 7273 0a20 2020  turn tickers.   
-000110d0: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
-000110e0: 2020 2020 2020 7469 636b 6572 7320 3d20        tickers = 
-000110f0: 7365 6c66 2e5f 6170 692e 6665 7463 685f  self._api.fetch_
-00011100: 6269 6473 5f61 736b 7328 7379 6d62 6f6c  bids_asks(symbol
-00011110: 7329 0a20 2020 2020 2020 2020 2020 2077  s).            w
-00011120: 6974 6820 7365 6c66 2e5f 6361 6368 655f  ith self._cache_
-00011130: 6c6f 636b 3a0a 2020 2020 2020 2020 2020  lock:.          
-00011140: 2020 2020 2020 7365 6c66 2e5f 6665 7463        self._fetc
-00011150: 685f 7469 636b 6572 735f 6361 6368 655b  h_tickers_cache[
-00011160: 2766 6574 6368 5f62 6964 735f 6173 6b73  'fetch_bids_asks
-00011170: 275d 203d 2074 6963 6b65 7273 0a20 2020  '] = tickers.   
-00011180: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00011190: 7469 636b 6572 730a 2020 2020 2020 2020  tickers.        
-000111a0: 6578 6365 7074 2063 6378 742e 4e6f 7453  except ccxt.NotS
-000111b0: 7570 706f 7274 6564 2061 7320 653a 0a20  upported as e:. 
-000111c0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-000111d0: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
-000111e0: 7074 696f 6e28 0a20 2020 2020 2020 2020  ption(.         
-000111f0: 2020 2020 2020 2066 2745 7863 6861 6e67         f'Exchang
-00011200: 6520 7b73 656c 662e 5f61 7069 2e6e 616d  e {self._api.nam
-00011210: 657d 2064 6f65 7320 6e6f 7420 7375 7070  e} does not supp
-00011220: 6f72 7420 6665 7463 6869 6e67 2062 6964  ort fetching bid
-00011230: 732f 6173 6b73 2069 6e20 6261 7463 682e  s/asks in batch.
-00011240: 2027 0a20 2020 2020 2020 2020 2020 2020   '.             
-00011250: 2020 2066 274d 6573 7361 6765 3a20 7b65     f'Message: {e
-00011260: 7d27 2920 6672 6f6d 2065 0a20 2020 2020  }') from e.     
-00011270: 2020 2065 7863 6570 7420 6363 7874 2e44     except ccxt.D
-00011280: 446f 5350 726f 7465 6374 696f 6e20 6173  DoSProtection as
-00011290: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-000112a0: 7261 6973 6520 4444 6f73 5072 6f74 6563  raise DDosProtec
-000112b0: 7469 6f6e 2865 2920 6672 6f6d 2065 0a20  tion(e) from e. 
-000112c0: 2020 2020 2020 2065 7863 6570 7420 2863         except (c
-000112d0: 6378 742e 4f70 6572 6174 696f 6e46 6169  cxt.OperationFai
-000112e0: 6c65 642c 2063 6378 742e 4578 6368 616e  led, ccxt.Exchan
-000112f0: 6765 4572 726f 7229 2061 7320 653a 0a20  geError) as e:. 
-00011300: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00011310: 2054 656d 706f 7261 7279 4572 726f 7228   TemporaryError(
-00011320: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011330: 2066 2743 6f75 6c64 206e 6f74 206c 6f61   f'Could not loa
-00011340: 6420 6269 6473 2f61 736b 7320 6475 6520  d bids/asks due 
-00011350: 746f 207b 652e 5f5f 636c 6173 735f 5f2e  to {e.__class__.
-00011360: 5f5f 6e61 6d65 5f5f 7d2e 204d 6573 7361  __name__}. Messa
-00011370: 6765 3a20 7b65 7d27 2920 6672 6f6d 2065  ge: {e}') from e
-00011380: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-00011390: 6363 7874 2e42 6173 6545 7272 6f72 2061  ccxt.BaseError a
-000113a0: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
-000113b0: 2072 6169 7365 204f 7065 7261 7469 6f6e   raise Operation
-000113c0: 616c 4578 6365 7074 696f 6e28 6529 2066  alException(e) f
-000113d0: 726f 6d20 650a 0a20 2020 2040 7265 7472  rom e..    @retr
-000113e0: 6965 720a 2020 2020 6465 6620 6765 745f  ier.    def get_
-000113f0: 7469 636b 6572 7328 7365 6c66 2c20 7379  tickers(self, sy
-00011400: 6d62 6f6c 733a 204f 7074 696f 6e61 6c5b  mbols: Optional[
-00011410: 4c69 7374 5b73 7472 5d5d 203d 204e 6f6e  List[str]] = Non
-00011420: 652c 2063 6163 6865 643a 2062 6f6f 6c20  e, cached: bool 
-00011430: 3d20 4661 6c73 6529 202d 3e20 5469 636b  = False) -> Tick
-00011440: 6572 733a 0a20 2020 2020 2020 2022 2222  ers:.        """
-00011450: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00011460: 6361 6368 6564 3a20 416c 6c6f 7720 6361  cached: Allow ca
-00011470: 6368 6564 2072 6573 756c 740a 2020 2020  ched result.    
-00011480: 2020 2020 3a72 6574 7572 6e3a 2066 6574      :return: fet
-00011490: 6368 5f74 6963 6b65 7273 2072 6573 756c  ch_tickers resul
-000114a0: 740a 2020 2020 2020 2020 2222 220a 2020  t.        """.  
-000114b0: 2020 2020 2020 7469 636b 6572 733a 2054        tickers: T
-000114c0: 6963 6b65 7273 0a20 2020 2020 2020 2069  ickers.        i
-000114d0: 6620 6e6f 7420 7365 6c66 2e65 7863 6861  f not self.excha
-000114e0: 6e67 655f 6861 7328 2766 6574 6368 5469  nge_has('fetchTi
-000114f0: 636b 6572 7327 293a 0a20 2020 2020 2020  ckers'):.       
-00011500: 2020 2020 2072 6574 7572 6e20 7b7d 0a20       return {}. 
-00011510: 2020 2020 2020 2069 6620 6361 6368 6564         if cached
-00011520: 3a0a 2020 2020 2020 2020 2020 2020 7769  :.            wi
-00011530: 7468 2073 656c 662e 5f63 6163 6865 5f6c  th self._cache_l
-00011540: 6f63 6b3a 0a20 2020 2020 2020 2020 2020  ock:.           
-00011550: 2020 2020 2074 6963 6b65 7273 203d 2073       tickers = s
-00011560: 656c 662e 5f66 6574 6368 5f74 6963 6b65  elf._fetch_ticke
-00011570: 7273 5f63 6163 6865 2e67 6574 2827 6665  rs_cache.get('fe
-00011580: 7463 685f 7469 636b 6572 7327 2920 2023  tch_tickers')  #
-00011590: 2074 7970 653a 2069 676e 6f72 650a 2020   type: ignore.  
-000115a0: 2020 2020 2020 2020 2020 6966 2074 6963            if tic
-000115b0: 6b65 7273 3a0a 2020 2020 2020 2020 2020  kers:.          
-000115c0: 2020 2020 2020 7265 7475 726e 2074 6963        return tic
-000115d0: 6b65 7273 0a20 2020 2020 2020 2074 7279  kers.        try
-000115e0: 3a0a 2020 2020 2020 2020 2020 2020 7469  :.            ti
-000115f0: 636b 6572 7320 3d20 7365 6c66 2e5f 6170  ckers = self._ap
-00011600: 692e 6665 7463 685f 7469 636b 6572 7328  i.fetch_tickers(
-00011610: 7379 6d62 6f6c 7329 0a20 2020 2020 2020  symbols).       
-00011620: 2020 2020 2077 6974 6820 7365 6c66 2e5f       with self._
-00011630: 6361 6368 655f 6c6f 636b 3a0a 2020 2020  cache_lock:.    
-00011640: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00011650: 2e5f 6665 7463 685f 7469 636b 6572 735f  ._fetch_tickers_
-00011660: 6361 6368 655b 2766 6574 6368 5f74 6963  cache['fetch_tic
-00011670: 6b65 7273 275d 203d 2074 6963 6b65 7273  kers'] = tickers
-00011680: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00011690: 7572 6e20 7469 636b 6572 730a 2020 2020  urn tickers.    
-000116a0: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
-000116b0: 4e6f 7453 7570 706f 7274 6564 2061 7320  NotSupported as 
-000116c0: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
-000116d0: 6169 7365 204f 7065 7261 7469 6f6e 616c  aise Operational
-000116e0: 4578 6365 7074 696f 6e28 0a20 2020 2020  Exception(.     
-000116f0: 2020 2020 2020 2020 2020 2066 2745 7863             f'Exc
-00011700: 6861 6e67 6520 7b73 656c 662e 5f61 7069  hange {self._api
-00011710: 2e6e 616d 657d 2064 6f65 7320 6e6f 7420  .name} does not 
-00011720: 7375 7070 6f72 7420 6665 7463 6869 6e67  support fetching
-00011730: 2074 6963 6b65 7273 2069 6e20 6261 7463   tickers in batc
-00011740: 682e 2027 0a20 2020 2020 2020 2020 2020  h. '.           
-00011750: 2020 2020 2066 274d 6573 7361 6765 3a20       f'Message: 
-00011760: 7b65 7d27 2920 6672 6f6d 2065 0a20 2020  {e}') from e.   
-00011770: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
-00011780: 2e42 6164 5379 6d62 6f6c 2061 7320 653a  .BadSymbol as e:
-00011790: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
-000117a0: 6765 722e 7761 726e 696e 6728 6622 436f  ger.warning(f"Co
-000117b0: 756c 6420 6e6f 7420 6c6f 6164 2074 6963  uld not load tic
-000117c0: 6b65 7273 2064 7565 2074 6f20 7b65 2e5f  kers due to {e._
-000117d0: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
-000117e0: 5f7d 2e20 4d65 7373 6167 653a 207b 657d  _}. Message: {e}
-000117f0: 202e 220a 2020 2020 2020 2020 2020 2020   .".            
-00011800: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00011810: 5265 6c6f 6164 696e 6720 6d61 726b 6574  Reloading market
-00011820: 732e 2229 0a20 2020 2020 2020 2020 2020  s.").           
-00011830: 2073 656c 662e 7265 6c6f 6164 5f6d 6172   self.reload_mar
-00011840: 6b65 7473 2854 7275 6529 0a20 2020 2020  kets(True).     
-00011850: 2020 2020 2020 2023 2052 652d 7261 6973         # Re-rais
-00011860: 6520 6578 6365 7074 696f 6e20 746f 2072  e exception to r
-00011870: 6570 6561 7420 7468 6520 6361 6c6c 2e0a  epeat the call..
-00011880: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00011890: 6520 5465 6d70 6f72 6172 7945 7272 6f72  e TemporaryError
-000118a0: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
-000118b0: 6578 6365 7074 2063 6378 742e 4444 6f53  except ccxt.DDoS
-000118c0: 5072 6f74 6563 7469 6f6e 2061 7320 653a  Protection as e:
-000118d0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-000118e0: 7365 2044 446f 7350 726f 7465 6374 696f  se DDosProtectio
-000118f0: 6e28 6529 2066 726f 6d20 650a 2020 2020  n(e) from e.    
-00011900: 2020 2020 6578 6365 7074 2028 6363 7874      except (ccxt
-00011910: 2e4f 7065 7261 7469 6f6e 4661 696c 6564  .OperationFailed
-00011920: 2c20 6363 7874 2e45 7863 6861 6e67 6545  , ccxt.ExchangeE
-00011930: 7272 6f72 2920 6173 2065 3a0a 2020 2020  rror) as e:.    
-00011940: 2020 2020 2020 2020 7261 6973 6520 5465          raise Te
-00011950: 6d70 6f72 6172 7945 7272 6f72 280a 2020  mporaryError(.  
-00011960: 2020 2020 2020 2020 2020 2020 2020 6627                f'
-00011970: 436f 756c 6420 6e6f 7420 6c6f 6164 2074  Could not load t
-00011980: 6963 6b65 7273 2064 7565 2074 6f20 7b65  ickers due to {e
-00011990: 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e 616d  .__class__.__nam
-000119a0: 655f 5f7d 2e20 4d65 7373 6167 653a 207b  e__}. Message: {
-000119b0: 657d 2729 2066 726f 6d20 650a 2020 2020  e}') from e.    
-000119c0: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
-000119d0: 4261 7365 4572 726f 7220 6173 2065 3a0a  BaseError as e:.
-000119e0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-000119f0: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
-00011a00: 6570 7469 6f6e 2865 2920 6672 6f6d 2065  eption(e) from e
-00011a10: 0a0a 2020 2020 2320 5072 6963 696e 6720  ..    # Pricing 
-00011a20: 696e 666f 0a0a 2020 2020 4072 6574 7269  info..    @retri
-00011a30: 6572 0a20 2020 2064 6566 2066 6574 6368  er.    def fetch
-00011a40: 5f74 6963 6b65 7228 7365 6c66 2c20 7061  _ticker(self, pa
-00011a50: 6972 3a20 7374 7229 202d 3e20 5469 636b  ir: str) -> Tick
-00011a60: 6572 3a0a 2020 2020 2020 2020 7472 793a  er:.        try:
-00011a70: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00011a80: 2870 6169 7220 6e6f 7420 696e 2073 656c  (pair not in sel
-00011a90: 662e 6d61 726b 6574 7320 6f72 0a20 2020  f.markets or.   
-00011aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ab0: 2073 656c 662e 6d61 726b 6574 735b 7061   self.markets[pa
-00011ac0: 6972 5d2e 6765 7428 2761 6374 6976 6527  ir].get('active'
-00011ad0: 2c20 4661 6c73 6529 2069 7320 4661 6c73  , False) is Fals
-00011ae0: 6529 3a0a 2020 2020 2020 2020 2020 2020  e):.            
-00011af0: 2020 2020 7261 6973 6520 4578 6368 616e      raise Exchan
-00011b00: 6765 4572 726f 7228 6622 5061 6972 207b  geError(f"Pair {
-00011b10: 7061 6972 7d20 6e6f 7420 6176 6169 6c61  pair} not availa
-00011b20: 626c 6522 290a 2020 2020 2020 2020 2020  ble").          
-00011b30: 2020 6461 7461 3a20 5469 636b 6572 203d    data: Ticker =
-00011b40: 2073 656c 662e 5f61 7069 2e66 6574 6368   self._api.fetch
-00011b50: 5f74 6963 6b65 7228 7061 6972 290a 2020  _ticker(pair).  
-00011b60: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00011b70: 2064 6174 610a 2020 2020 2020 2020 6578   data.        ex
-00011b80: 6365 7074 2063 6378 742e 4444 6f53 5072  cept ccxt.DDoSPr
-00011b90: 6f74 6563 7469 6f6e 2061 7320 653a 0a20  otection as e:. 
-00011ba0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00011bb0: 2044 446f 7350 726f 7465 6374 696f 6e28   DDosProtection(
-00011bc0: 6529 2066 726f 6d20 650a 2020 2020 2020  e) from e.      
-00011bd0: 2020 6578 6365 7074 2028 6363 7874 2e4f    except (ccxt.O
-00011be0: 7065 7261 7469 6f6e 4661 696c 6564 2c20  perationFailed, 
-00011bf0: 6363 7874 2e45 7863 6861 6e67 6545 7272  ccxt.ExchangeErr
-00011c00: 6f72 2920 6173 2065 3a0a 2020 2020 2020  or) as e:.      
-00011c10: 2020 2020 2020 7261 6973 6520 5465 6d70        raise Temp
-00011c20: 6f72 6172 7945 7272 6f72 280a 2020 2020  oraryError(.    
-00011c30: 2020 2020 2020 2020 2020 2020 6627 436f              f'Co
-00011c40: 756c 6420 6e6f 7420 6c6f 6164 2074 6963  uld not load tic
-00011c50: 6b65 7220 6475 6520 746f 207b 652e 5f5f  ker due to {e.__
-00011c60: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
-00011c70: 7d2e 204d 6573 7361 6765 3a20 7b65 7d27  }. Message: {e}'
-00011c80: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
-00011c90: 2065 7863 6570 7420 6363 7874 2e42 6173   except ccxt.Bas
-00011ca0: 6545 7272 6f72 2061 7320 653a 0a20 2020  eError as e:.   
-00011cb0: 2020 2020 2020 2020 2072 6169 7365 204f           raise O
-00011cc0: 7065 7261 7469 6f6e 616c 4578 6365 7074  perationalExcept
-00011cd0: 696f 6e28 6529 2066 726f 6d20 650a 0a20  ion(e) from e.. 
-00011ce0: 2020 2040 7374 6174 6963 6d65 7468 6f64     @staticmethod
-00011cf0: 0a20 2020 2064 6566 2067 6574 5f6e 6578  .    def get_nex
-00011d00: 745f 6c69 6d69 745f 696e 5f6c 6973 7428  t_limit_in_list(
-00011d10: 6c69 6d69 743a 2069 6e74 2c20 6c69 6d69  limit: int, limi
-00011d20: 745f 7261 6e67 653a 204f 7074 696f 6e61  t_range: Optiona
-00011d30: 6c5b 4c69 7374 5b69 6e74 5d5d 2c0a 2020  l[List[int]],.  
-00011d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011d50: 2020 2020 2020 2020 2020 2020 2072 616e               ran
-00011d60: 6765 5f72 6571 7569 7265 643a 2062 6f6f  ge_required: boo
-00011d70: 6c20 3d20 5472 7565 293a 0a20 2020 2020  l = True):.     
-00011d80: 2020 2022 2222 0a20 2020 2020 2020 2047     """.        G
-00011d90: 6574 206e 6578 7420 6772 6561 7465 7220  et next greater 
-00011da0: 7661 6c75 6520 696e 2074 6865 206c 6973  value in the lis
-00011db0: 742e 0a20 2020 2020 2020 2055 7365 6420  t..        Used 
-00011dc0: 6279 2066 6574 6368 5f6c 325f 6f72 6465  by fetch_l2_orde
-00011dd0: 725f 626f 6f6b 2069 6620 7468 6520 6170  r_book if the ap
-00011de0: 6920 6f6e 6c79 2073 7570 706f 7274 7320  i only supports 
-00011df0: 6120 6c69 6d69 7465 6420 7261 6e67 650a  a limited range.
-00011e00: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00011e10: 2020 2020 6966 206e 6f74 206c 696d 6974      if not limit
-00011e20: 5f72 616e 6765 3a0a 2020 2020 2020 2020  _range:.        
-00011e30: 2020 2020 7265 7475 726e 206c 696d 6974      return limit
-00011e40: 0a0a 2020 2020 2020 2020 7265 7375 6c74  ..        result
-00011e50: 203d 206d 696e 285b 7820 666f 7220 7820   = min([x for x 
-00011e60: 696e 206c 696d 6974 5f72 616e 6765 2069  in limit_range i
-00011e70: 6620 6c69 6d69 7420 3c3d 2078 5d20 2b20  f limit <= x] + 
-00011e80: 5b6d 6178 286c 696d 6974 5f72 616e 6765  [max(limit_range
-00011e90: 295d 290a 2020 2020 2020 2020 6966 206e  )]).        if n
-00011ea0: 6f74 2072 616e 6765 5f72 6571 7569 7265  ot range_require
-00011eb0: 6420 616e 6420 6c69 6d69 7420 3e20 7265  d and limit > re
-00011ec0: 7375 6c74 3a0a 2020 2020 2020 2020 2020  sult:.          
-00011ed0: 2020 2320 5261 6e67 6520 6973 206e 6f74    # Range is not
-00011ee0: 2072 6571 7569 7265 6420 2d20 7765 2063   required - we c
-00011ef0: 616e 2075 7365 204e 6f6e 6520 6173 2070  an use None as p
-00011f00: 6172 616d 6574 6572 2e0a 2020 2020 2020  arameter..      
-00011f10: 2020 2020 2020 7265 7475 726e 204e 6f6e        return Non
-00011f20: 650a 2020 2020 2020 2020 7265 7475 726e  e.        return
-00011f30: 2072 6573 756c 740a 0a20 2020 2040 7265   result..    @re
-00011f40: 7472 6965 720a 2020 2020 6465 6620 6665  trier.    def fe
-00011f50: 7463 685f 6c32 5f6f 7264 6572 5f62 6f6f  tch_l2_order_boo
-00011f60: 6b28 7365 6c66 2c20 7061 6972 3a20 7374  k(self, pair: st
-00011f70: 722c 206c 696d 6974 3a20 696e 7420 3d20  r, limit: int = 
-00011f80: 3130 3029 202d 3e20 4f72 6465 7242 6f6f  100) -> OrderBoo
-00011f90: 6b3a 0a20 2020 2020 2020 2022 2222 0a20  k:.        """. 
-00011fa0: 2020 2020 2020 2047 6574 204c 3220 6f72         Get L2 or
-00011fb0: 6465 7220 626f 6f6b 2066 726f 6d20 6578  der book from ex
-00011fc0: 6368 616e 6765 2e0a 2020 2020 2020 2020  change..        
-00011fd0: 4361 6e20 6265 206c 696d 6974 6564 2074  Can be limited t
-00011fe0: 6f20 6120 6365 7274 6169 6e20 616d 6f75  o a certain amou
-00011ff0: 6e74 2028 6966 2073 7570 706f 7274 6564  nt (if supported
-00012000: 292e 0a20 2020 2020 2020 2052 6574 7572  )..        Retur
-00012010: 6e73 2061 2064 6963 7420 696e 2074 6865  ns a dict in the
-00012020: 2066 6f72 6d61 740a 2020 2020 2020 2020   format.        
-00012030: 7b27 6173 6b73 273a 205b 7072 6963 652c  {'asks': [price,
-00012040: 2076 6f6c 756d 655d 2c20 2762 6964 7327   volume], 'bids'
-00012050: 3a20 5b70 7269 6365 2c20 766f 6c75 6d65  : [price, volume
-00012060: 5d7d 0a20 2020 2020 2020 2022 2222 0a20  ]}.        """. 
-00012070: 2020 2020 2020 206c 696d 6974 3120 3d20         limit1 = 
-00012080: 7365 6c66 2e67 6574 5f6e 6578 745f 6c69  self.get_next_li
-00012090: 6d69 745f 696e 5f6c 6973 7428 6c69 6d69  mit_in_list(limi
-000120a0: 742c 2073 656c 662e 5f66 745f 6861 735b  t, self._ft_has[
-000120b0: 276c 325f 6c69 6d69 745f 7261 6e67 6527  'l2_limit_range'
-000120c0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-000120d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000120e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000120f0: 7365 6c66 2e5f 6674 5f68 6173 5b27 6c32  self._ft_has['l2
-00012100: 5f6c 696d 6974 5f72 616e 6765 5f72 6571  _limit_range_req
-00012110: 7569 7265 6427 5d29 0a20 2020 2020 2020  uired']).       
-00012120: 2074 7279 3a0a 0a20 2020 2020 2020 2020   try:..         
-00012130: 2020 2072 6574 7572 6e20 7365 6c66 2e5f     return self._
-00012140: 6170 692e 6665 7463 685f 6c32 5f6f 7264  api.fetch_l2_ord
-00012150: 6572 5f62 6f6f 6b28 7061 6972 2c20 6c69  er_book(pair, li
-00012160: 6d69 7431 290a 2020 2020 2020 2020 6578  mit1).        ex
-00012170: 6365 7074 2063 6378 742e 4e6f 7453 7570  cept ccxt.NotSup
-00012180: 706f 7274 6564 2061 7320 653a 0a20 2020  ported as e:.   
-00012190: 2020 2020 2020 2020 2072 6169 7365 204f           raise O
-000121a0: 7065 7261 7469 6f6e 616c 4578 6365 7074  perationalExcept
-000121b0: 696f 6e28 0a20 2020 2020 2020 2020 2020  ion(.           
-000121c0: 2020 2020 2066 2745 7863 6861 6e67 6520       f'Exchange 
-000121d0: 7b73 656c 662e 5f61 7069 2e6e 616d 657d  {self._api.name}
-000121e0: 2064 6f65 7320 6e6f 7420 7375 7070 6f72   does not suppor
-000121f0: 7420 6665 7463 6869 6e67 206f 7264 6572  t fetching order
-00012200: 2062 6f6f 6b2e 270a 2020 2020 2020 2020   book.'.        
-00012210: 2020 2020 2020 2020 6627 4d65 7373 6167          f'Messag
-00012220: 653a 207b 657d 2729 2066 726f 6d20 650a  e: {e}') from e.
-00012230: 2020 2020 2020 2020 6578 6365 7074 2063          except c
-00012240: 6378 742e 4444 6f53 5072 6f74 6563 7469  cxt.DDoSProtecti
-00012250: 6f6e 2061 7320 653a 0a20 2020 2020 2020  on as e:.       
-00012260: 2020 2020 2072 6169 7365 2044 446f 7350       raise DDosP
-00012270: 726f 7465 6374 696f 6e28 6529 2066 726f  rotection(e) fro
-00012280: 6d20 650a 2020 2020 2020 2020 6578 6365  m e.        exce
-00012290: 7074 2028 6363 7874 2e4f 7065 7261 7469  pt (ccxt.Operati
-000122a0: 6f6e 4661 696c 6564 2c20 6363 7874 2e45  onFailed, ccxt.E
-000122b0: 7863 6861 6e67 6545 7272 6f72 2920 6173  xchangeError) as
-000122c0: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-000122d0: 7261 6973 6520 5465 6d70 6f72 6172 7945  raise TemporaryE
-000122e0: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
-000122f0: 2020 2020 2020 6627 436f 756c 6420 6e6f        f'Could no
-00012300: 7420 6765 7420 6f72 6465 7220 626f 6f6b  t get order book
-00012310: 2064 7565 2074 6f20 7b65 2e5f 5f63 6c61   due to {e.__cla
-00012320: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2e20  ss__.__name__}. 
-00012330: 4d65 7373 6167 653a 207b 657d 2729 2066  Message: {e}') f
-00012340: 726f 6d20 650a 2020 2020 2020 2020 6578  rom e.        ex
-00012350: 6365 7074 2063 6378 742e 4261 7365 4572  cept ccxt.BaseEr
-00012360: 726f 7220 6173 2065 3a0a 2020 2020 2020  ror as e:.      
-00012370: 2020 2020 2020 7261 6973 6520 4f70 6572        raise Oper
-00012380: 6174 696f 6e61 6c45 7863 6570 7469 6f6e  ationalException
-00012390: 2865 2920 6672 6f6d 2065 0a0a 2020 2020  (e) from e..    
-000123a0: 6465 6620 5f67 6574 5f70 7269 6365 5f73  def _get_price_s
-000123b0: 6964 6528 7365 6c66 2c20 7369 6465 3a20  ide(self, side: 
-000123c0: 7374 722c 2069 735f 7368 6f72 743a 2062  str, is_short: b
-000123d0: 6f6f 6c2c 2063 6f6e 665f 7374 7261 7465  ool, conf_strate
-000123e0: 6779 3a20 4469 6374 2920 2d3e 2042 6964  gy: Dict) -> Bid
-000123f0: 4173 6b3a 0a20 2020 2020 2020 2070 7269  Ask:.        pri
-00012400: 6365 5f73 6964 6520 3d20 636f 6e66 5f73  ce_side = conf_s
-00012410: 7472 6174 6567 795b 2770 7269 6365 5f73  trategy['price_s
-00012420: 6964 6527 5d0a 0a20 2020 2020 2020 2069  ide']..        i
-00012430: 6620 7072 6963 655f 7369 6465 2069 6e20  f price_side in 
-00012440: 2827 7361 6d65 272c 2027 6f74 6865 7227  ('same', 'other'
-00012450: 293a 0a20 2020 2020 2020 2020 2020 2070  ):.            p
-00012460: 7269 6365 5f6d 6170 203d 207b 0a20 2020  rice_map = {.   
-00012470: 2020 2020 2020 2020 2020 2020 2028 2765               ('e
-00012480: 6e74 7279 272c 2027 6c6f 6e67 272c 2027  ntry', 'long', '
-00012490: 7361 6d65 2729 3a20 2762 6964 272c 0a20  same'): 'bid',. 
-000124a0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-000124b0: 2765 6e74 7279 272c 2027 6c6f 6e67 272c  'entry', 'long',
-000124c0: 2027 6f74 6865 7227 293a 2027 6173 6b27   'other'): 'ask'
-000124d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000124e0: 2020 2827 656e 7472 7927 2c20 2773 686f    ('entry', 'sho
-000124f0: 7274 272c 2027 7361 6d65 2729 3a20 2761  rt', 'same'): 'a
-00012500: 736b 272c 0a20 2020 2020 2020 2020 2020  sk',.           
-00012510: 2020 2020 2028 2765 6e74 7279 272c 2027       ('entry', '
-00012520: 7368 6f72 7427 2c20 276f 7468 6572 2729  short', 'other')
-00012530: 3a20 2762 6964 272c 0a20 2020 2020 2020  : 'bid',.       
-00012540: 2020 2020 2020 2020 2028 2765 7869 7427           ('exit'
-00012550: 2c20 276c 6f6e 6727 2c20 2773 616d 6527  , 'long', 'same'
-00012560: 293a 2027 6173 6b27 2c0a 2020 2020 2020  ): 'ask',.      
-00012570: 2020 2020 2020 2020 2020 2827 6578 6974            ('exit
-00012580: 272c 2027 6c6f 6e67 272c 2027 6f74 6865  ', 'long', 'othe
-00012590: 7227 293a 2027 6269 6427 2c0a 2020 2020  r'): 'bid',.    
-000125a0: 2020 2020 2020 2020 2020 2020 2827 6578              ('ex
-000125b0: 6974 272c 2027 7368 6f72 7427 2c20 2773  it', 'short', 's
-000125c0: 616d 6527 293a 2027 6269 6427 2c0a 2020  ame'): 'bid',.  
-000125d0: 2020 2020 2020 2020 2020 2020 2020 2827                ('
-000125e0: 6578 6974 272c 2027 7368 6f72 7427 2c20  exit', 'short', 
-000125f0: 276f 7468 6572 2729 3a20 2761 736b 272c  'other'): 'ask',
-00012600: 0a20 2020 2020 2020 2020 2020 207d 0a20  .            }. 
-00012610: 2020 2020 2020 2020 2020 2070 7269 6365             price
-00012620: 5f73 6964 6520 3d20 7072 6963 655f 6d61  _side = price_ma
-00012630: 705b 2873 6964 652c 2027 7368 6f72 7427  p[(side, 'short'
-00012640: 2069 6620 6973 5f73 686f 7274 2065 6c73   if is_short els
-00012650: 6520 276c 6f6e 6727 2c20 7072 6963 655f  e 'long', price_
-00012660: 7369 6465 295d 0a20 2020 2020 2020 2072  side)].        r
-00012670: 6574 7572 6e20 7072 6963 655f 7369 6465  eturn price_side
-00012680: 0a0a 2020 2020 6465 6620 6765 745f 7261  ..    def get_ra
-00012690: 7465 2873 656c 662c 2070 6169 723a 2073  te(self, pair: s
-000126a0: 7472 2c20 7265 6672 6573 683a 2062 6f6f  tr, refresh: boo
-000126b0: 6c2c 0a20 2020 2020 2020 2020 2020 2020  l,.             
-000126c0: 2020 2020 7369 6465 3a20 456e 7472 7945      side: EntryE
-000126d0: 7869 742c 2069 735f 7368 6f72 743a 2062  xit, is_short: b
-000126e0: 6f6f 6c2c 0a20 2020 2020 2020 2020 2020  ool,.           
-000126f0: 2020 2020 2020 6f72 6465 725f 626f 6f6b        order_book
-00012700: 3a20 4f70 7469 6f6e 616c 5b4f 7264 6572  : Optional[Order
-00012710: 426f 6f6b 5d20 3d20 4e6f 6e65 2c20 7469  Book] = None, ti
-00012720: 636b 6572 3a20 4f70 7469 6f6e 616c 5b54  cker: Optional[T
-00012730: 6963 6b65 725d 203d 204e 6f6e 6529 202d  icker] = None) -
-00012740: 3e20 666c 6f61 743a 0a20 2020 2020 2020  > float:.       
-00012750: 2022 2222 0a20 2020 2020 2020 2043 616c   """.        Cal
-00012760: 6375 6c61 7465 7320 6269 642f 6173 6b20  culates bid/ask 
-00012770: 7461 7267 6574 0a20 2020 2020 2020 2062  target.        b
-00012780: 6964 2072 6174 6520 2d20 6265 7477 6565  id rate - betwee
-00012790: 6e20 6375 7272 656e 7420 6173 6b20 7072  n current ask pr
-000127a0: 6963 6520 616e 6420 6c61 7374 2070 7269  ice and last pri
-000127b0: 6365 0a20 2020 2020 2020 2061 736b 2072  ce.        ask r
-000127c0: 6174 6520 2d20 6569 7468 6572 2075 7369  ate - either usi
-000127d0: 6e67 2074 6963 6b65 7220 6269 6420 6f72  ng ticker bid or
-000127e0: 2066 6972 7374 2062 6964 2062 6173 6564   first bid based
-000127f0: 206f 6e20 6f72 6465 7262 6f6f 6b0a 2020   on orderbook.  
-00012800: 2020 2020 2020 6f72 2072 656d 6169 6e20        or remain 
-00012810: 7374 6174 6963 2069 6e20 616e 7920 6f74  static in any ot
-00012820: 6865 7220 6361 7365 2073 696e 6365 2069  her case since i
-00012830: 7427 7320 6e6f 7420 7570 6461 7469 6e67  t's not updating
-00012840: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-00012850: 2070 6169 723a 2050 6169 7220 746f 2067   pair: Pair to g
-00012860: 6574 2072 6174 6520 666f 720a 2020 2020  et rate for.    
-00012870: 2020 2020 3a70 6172 616d 2072 6566 7265      :param refre
-00012880: 7368 3a20 616c 6c6f 7720 6361 6368 6564  sh: allow cached
-00012890: 2064 6174 610a 2020 2020 2020 2020 3a70   data.        :p
-000128a0: 6172 616d 2073 6964 653a 2022 6275 7922  aram side: "buy"
-000128b0: 206f 7220 2273 656c 6c22 0a20 2020 2020   or "sell".     
-000128c0: 2020 203a 7265 7475 726e 3a20 666c 6f61     :return: floa
-000128d0: 743a 2050 7269 6365 0a20 2020 2020 2020  t: Price.       
-000128e0: 203a 7261 6973 6573 2050 7269 6369 6e67   :raises Pricing
-000128f0: 4572 726f 7220 6966 206f 7264 6572 626f  Error if orderbo
-00012900: 6f6b 2070 7269 6365 2063 6f75 6c64 206e  ok price could n
-00012910: 6f74 2062 6520 6465 7465 726d 696e 6564  ot be determined
-00012920: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
-00012930: 2020 2020 2020 6e61 6d65 203d 2073 6964        name = sid
-00012940: 652e 6361 7069 7461 6c69 7a65 2829 0a20  e.capitalize(). 
-00012950: 2020 2020 2020 2073 7472 6174 5f6e 616d         strat_nam
-00012960: 6520 3d20 2765 6e74 7279 5f70 7269 6369  e = 'entry_prici
-00012970: 6e67 2720 6966 2073 6964 6520 3d3d 2022  ng' if side == "
-00012980: 656e 7472 7922 2065 6c73 6520 2765 7869  entry" else 'exi
-00012990: 745f 7072 6963 696e 6727 0a0a 2020 2020  t_pricing'..    
-000129a0: 2020 2020 6361 6368 655f 7261 7465 3a20      cache_rate: 
-000129b0: 5454 4c43 6163 6865 203d 2073 656c 662e  TTLCache = self.
-000129c0: 5f65 6e74 7279 5f72 6174 655f 6361 6368  _entry_rate_cach
-000129d0: 6520 6966 2073 6964 6520 3d3d 2022 656e  e if side == "en
-000129e0: 7472 7922 2065 6c73 6520 7365 6c66 2e5f  try" else self._
-000129f0: 6578 6974 5f72 6174 655f 6361 6368 650a  exit_rate_cache.
-00012a00: 2020 2020 2020 2020 6966 206e 6f74 2072          if not r
-00012a10: 6566 7265 7368 3a0a 2020 2020 2020 2020  efresh:.        
-00012a20: 2020 2020 7769 7468 2073 656c 662e 5f63      with self._c
-00012a30: 6163 6865 5f6c 6f63 6b3a 0a20 2020 2020  ache_lock:.     
-00012a40: 2020 2020 2020 2020 2020 2072 6174 6520             rate 
-00012a50: 3d20 6361 6368 655f 7261 7465 2e67 6574  = cache_rate.get
-00012a60: 2870 6169 7229 0a20 2020 2020 2020 2020  (pair).         
-00012a70: 2020 2023 2043 6865 636b 2069 6620 6361     # Check if ca
-00012a80: 6368 6520 6861 7320 6265 656e 2069 6e76  che has been inv
-00012a90: 616c 6964 6174 6564 0a20 2020 2020 2020  alidated.       
-00012aa0: 2020 2020 2069 6620 7261 7465 3a0a 2020       if rate:.  
-00012ab0: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-00012ac0: 6767 6572 2e64 6562 7567 2866 2255 7369  gger.debug(f"Usi
-00012ad0: 6e67 2063 6163 6865 6420 7b73 6964 657d  ng cached {side}
-00012ae0: 2072 6174 6520 666f 7220 7b70 6169 727d   rate for {pair}
-00012af0: 2e22 290a 2020 2020 2020 2020 2020 2020  .").            
-00012b00: 2020 2020 7265 7475 726e 2072 6174 650a      return rate.
-00012b10: 0a20 2020 2020 2020 2063 6f6e 665f 7374  .        conf_st
-00012b20: 7261 7465 6779 203d 2073 656c 662e 5f63  rategy = self._c
-00012b30: 6f6e 6669 672e 6765 7428 7374 7261 745f  onfig.get(strat_
-00012b40: 6e61 6d65 2c20 7b7d 290a 0a20 2020 2020  name, {})..     
-00012b50: 2020 2070 7269 6365 5f73 6964 6520 3d20     price_side = 
-00012b60: 7365 6c66 2e5f 6765 745f 7072 6963 655f  self._get_price_
-00012b70: 7369 6465 2873 6964 652c 2069 735f 7368  side(side, is_sh
-00012b80: 6f72 742c 2063 6f6e 665f 7374 7261 7465  ort, conf_strate
-00012b90: 6779 290a 0a20 2020 2020 2020 2069 6620  gy)..        if 
-00012ba0: 636f 6e66 5f73 7472 6174 6567 792e 6765  conf_strategy.ge
-00012bb0: 7428 2775 7365 5f6f 7264 6572 5f62 6f6f  t('use_order_boo
-00012bc0: 6b27 2c20 4661 6c73 6529 3a0a 0a20 2020  k', False):..   
-00012bd0: 2020 2020 2020 2020 206f 7264 6572 5f62           order_b
-00012be0: 6f6f 6b5f 746f 7020 3d20 636f 6e66 5f73  ook_top = conf_s
-00012bf0: 7472 6174 6567 792e 6765 7428 276f 7264  trategy.get('ord
-00012c00: 6572 5f62 6f6f 6b5f 746f 7027 2c20 3129  er_book_top', 1)
-00012c10: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00012c20: 6f72 6465 725f 626f 6f6b 2069 7320 4e6f  order_book is No
-00012c30: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00012c40: 2020 2020 6f72 6465 725f 626f 6f6b 203d      order_book =
-00012c50: 2073 656c 662e 6665 7463 685f 6c32 5f6f   self.fetch_l2_o
-00012c60: 7264 6572 5f62 6f6f 6b28 7061 6972 2c20  rder_book(pair, 
-00012c70: 6f72 6465 725f 626f 6f6b 5f74 6f70 290a  order_book_top).
-00012c80: 2020 2020 2020 2020 2020 2020 7261 7465              rate
-00012c90: 203d 2073 656c 662e 5f67 6574 5f72 6174   = self._get_rat
-00012ca0: 655f 6672 6f6d 5f6f 6228 7061 6972 2c20  e_from_ob(pair, 
-00012cb0: 7369 6465 2c20 6f72 6465 725f 626f 6f6b  side, order_book
-00012cc0: 2c20 6e61 6d65 2c20 7072 6963 655f 7369  , name, price_si
-00012cd0: 6465 2c0a 2020 2020 2020 2020 2020 2020  de,.            
-00012ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012cf0: 2020 2020 2020 2020 2020 2020 2020 6f72                or
-00012d00: 6465 725f 626f 6f6b 5f74 6f70 290a 2020  der_book_top).  
-00012d10: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00012d20: 2020 2020 2020 2020 6c6f 6767 6572 2e64          logger.d
-00012d30: 6562 7567 2866 2255 7369 6e67 204c 6173  ebug(f"Using Las
-00012d40: 7420 7b70 7269 6365 5f73 6964 652e 6361  t {price_side.ca
-00012d50: 7069 7461 6c69 7a65 2829 7d20 2f20 4c61  pitalize()} / La
-00012d60: 7374 2050 7269 6365 2229 0a20 2020 2020  st Price").     
-00012d70: 2020 2020 2020 2069 6620 7469 636b 6572         if ticker
-00012d80: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-00012d90: 2020 2020 2020 2020 2020 7469 636b 6572            ticker
-00012da0: 203d 2073 656c 662e 6665 7463 685f 7469   = self.fetch_ti
-00012db0: 636b 6572 2870 6169 7229 0a20 2020 2020  cker(pair).     
-00012dc0: 2020 2020 2020 2072 6174 6520 3d20 7365         rate = se
-00012dd0: 6c66 2e5f 6765 745f 7261 7465 5f66 726f  lf._get_rate_fro
-00012de0: 6d5f 7469 636b 6572 2873 6964 652c 2074  m_ticker(side, t
-00012df0: 6963 6b65 722c 2063 6f6e 665f 7374 7261  icker, conf_stra
-00012e00: 7465 6779 2c20 7072 6963 655f 7369 6465  tegy, price_side
-00012e10: 290a 0a20 2020 2020 2020 2069 6620 7261  )..        if ra
-00012e20: 7465 2069 7320 4e6f 6e65 3a0a 2020 2020  te is None:.    
-00012e30: 2020 2020 2020 2020 7261 6973 6520 5072          raise Pr
-00012e40: 6963 696e 6745 7272 6f72 2866 227b 6e61  icingError(f"{na
-00012e50: 6d65 7d2d 5261 7465 2066 6f72 207b 7061  me}-Rate for {pa
-00012e60: 6972 7d20 7761 7320 656d 7074 792e 2229  ir} was empty.")
-00012e70: 0a20 2020 2020 2020 2077 6974 6820 7365  .        with se
-00012e80: 6c66 2e5f 6361 6368 655f 6c6f 636b 3a0a  lf._cache_lock:.
-00012e90: 2020 2020 2020 2020 2020 2020 6361 6368              cach
-00012ea0: 655f 7261 7465 5b70 6169 725d 203d 2072  e_rate[pair] = r
-00012eb0: 6174 650a 0a20 2020 2020 2020 2072 6574  ate..        ret
-00012ec0: 7572 6e20 7261 7465 0a0a 2020 2020 6465  urn rate..    de
-00012ed0: 6620 5f67 6574 5f72 6174 655f 6672 6f6d  f _get_rate_from
-00012ee0: 5f74 6963 6b65 7228 7365 6c66 2c20 7369  _ticker(self, si
-00012ef0: 6465 3a20 456e 7472 7945 7869 742c 2074  de: EntryExit, t
-00012f00: 6963 6b65 723a 2054 6963 6b65 722c 2063  icker: Ticker, c
-00012f10: 6f6e 665f 7374 7261 7465 6779 3a20 4469  onf_strategy: Di
-00012f20: 6374 5b73 7472 2c20 416e 795d 2c0a 2020  ct[str, Any],.  
-00012f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012f40: 2020 2020 2020 2020 2020 2020 7072 6963              pric
-00012f50: 655f 7369 6465 3a20 4269 6441 736b 2920  e_side: BidAsk) 
-00012f60: 2d3e 204f 7074 696f 6e61 6c5b 666c 6f61  -> Optional[floa
-00012f70: 745d 3a0a 2020 2020 2020 2020 2222 220a  t]:.        """.
-00012f80: 2020 2020 2020 2020 4765 7420 7261 7465          Get rate
-00012f90: 2066 726f 6d20 7469 636b 6572 2e0a 2020   from ticker..  
-00012fa0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-00012fb0: 2020 7469 636b 6572 5f72 6174 6520 3d20    ticker_rate = 
-00012fc0: 7469 636b 6572 5b70 7269 6365 5f73 6964  ticker[price_sid
-00012fd0: 655d 0a20 2020 2020 2020 2069 6620 7469  e].        if ti
-00012fe0: 636b 6572 5b27 6c61 7374 275d 2061 6e64  cker['last'] and
-00012ff0: 2074 6963 6b65 725f 7261 7465 3a0a 2020   ticker_rate:.  
-00013000: 2020 2020 2020 2020 2020 6966 2073 6964            if sid
-00013010: 6520 3d3d 2027 656e 7472 7927 2061 6e64  e == 'entry' and
-00013020: 2074 6963 6b65 725f 7261 7465 203e 2074   ticker_rate > t
-00013030: 6963 6b65 725b 276c 6173 7427 5d3a 0a20  icker['last']:. 
-00013040: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-00013050: 616c 616e 6365 203d 2063 6f6e 665f 7374  alance = conf_st
-00013060: 7261 7465 6779 2e67 6574 2827 7072 6963  rategy.get('pric
-00013070: 655f 6c61 7374 5f62 616c 616e 6365 272c  e_last_balance',
-00013080: 2030 2e30 290a 2020 2020 2020 2020 2020   0.0).          
-00013090: 2020 2020 2020 7469 636b 6572 5f72 6174        ticker_rat
-000130a0: 6520 3d20 7469 636b 6572 5f72 6174 6520  e = ticker_rate 
-000130b0: 2b20 6261 6c61 6e63 6520 2a20 2874 6963  + balance * (tic
-000130c0: 6b65 725b 276c 6173 7427 5d20 2d20 7469  ker['last'] - ti
-000130d0: 636b 6572 5f72 6174 6529 0a20 2020 2020  cker_rate).     
-000130e0: 2020 2020 2020 2065 6c69 6620 7369 6465         elif side
-000130f0: 203d 3d20 2765 7869 7427 2061 6e64 2074   == 'exit' and t
-00013100: 6963 6b65 725f 7261 7465 203c 2074 6963  icker_rate < tic
-00013110: 6b65 725b 276c 6173 7427 5d3a 0a20 2020  ker['last']:.   
-00013120: 2020 2020 2020 2020 2020 2020 2062 616c               bal
-00013130: 616e 6365 203d 2063 6f6e 665f 7374 7261  ance = conf_stra
-00013140: 7465 6779 2e67 6574 2827 7072 6963 655f  tegy.get('price_
-00013150: 6c61 7374 5f62 616c 616e 6365 272c 2030  last_balance', 0
-00013160: 2e30 290a 2020 2020 2020 2020 2020 2020  .0).            
-00013170: 2020 2020 7469 636b 6572 5f72 6174 6520      ticker_rate 
-00013180: 3d20 7469 636b 6572 5f72 6174 6520 2d20  = ticker_rate - 
-00013190: 6261 6c61 6e63 6520 2a20 2874 6963 6b65  balance * (ticke
-000131a0: 725f 7261 7465 202d 2074 6963 6b65 725b  r_rate - ticker[
-000131b0: 276c 6173 7427 5d29 0a20 2020 2020 2020  'last']).       
-000131c0: 2072 6174 6520 3d20 7469 636b 6572 5f72   rate = ticker_r
-000131d0: 6174 650a 2020 2020 2020 2020 7265 7475  ate.        retu
-000131e0: 726e 2072 6174 650a 0a20 2020 2064 6566  rn rate..    def
-000131f0: 205f 6765 745f 7261 7465 5f66 726f 6d5f   _get_rate_from_
-00013200: 6f62 2873 656c 662c 2070 6169 723a 2073  ob(self, pair: s
-00013210: 7472 2c20 7369 6465 3a20 456e 7472 7945  tr, side: EntryE
-00013220: 7869 742c 206f 7264 6572 5f62 6f6f 6b3a  xit, order_book:
-00013230: 204f 7264 6572 426f 6f6b 2c20 6e61 6d65   OrderBook, name
-00013240: 3a20 7374 722c 0a20 2020 2020 2020 2020  : str,.         
-00013250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013260: 2070 7269 6365 5f73 6964 653a 2042 6964   price_side: Bid
-00013270: 4173 6b2c 206f 7264 6572 5f62 6f6f 6b5f  Ask, order_book_
-00013280: 746f 703a 2069 6e74 2920 2d3e 2066 6c6f  top: int) -> flo
-00013290: 6174 3a0a 2020 2020 2020 2020 2222 220a  at:.        """.
-000132a0: 2020 2020 2020 2020 4765 7420 7261 7465          Get rate
-000132b0: 2066 726f 6d20 6f72 6465 7262 6f6f 6b0a   from orderbook.
-000132c0: 2020 2020 2020 2020 3a72 6169 7365 733a          :raises:
-000132d0: 2050 7269 6369 6e67 4572 726f 7220 6966   PricingError if
-000132e0: 2072 6174 6520 636f 756c 6420 6e6f 7420   rate could not 
-000132f0: 6265 2064 6574 6572 6d69 6e65 642e 0a20  be determined.. 
-00013300: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-00013310: 2020 206c 6f67 6765 722e 6465 6275 6728     logger.debug(
-00013320: 276f 7264 6572 5f62 6f6f 6b20 2573 272c  'order_book %s',
-00013330: 206f 7264 6572 5f62 6f6f 6b29 0a20 2020   order_book).   
-00013340: 2020 2020 2023 2074 6f70 2031 203d 2069       # top 1 = i
-00013350: 6e64 6578 2030 0a20 2020 2020 2020 2074  ndex 0.        t
-00013360: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
-00013370: 6f62 7369 6465 3a20 4f42 4c69 7465 7261  obside: OBLitera
-00013380: 6c20 3d20 2762 6964 7327 2069 6620 7072  l = 'bids' if pr
-00013390: 6963 655f 7369 6465 203d 3d20 2762 6964  ice_side == 'bid
-000133a0: 2720 656c 7365 2027 6173 6b73 270a 2020  ' else 'asks'.  
-000133b0: 2020 2020 2020 2020 2020 7261 7465 203d            rate =
-000133c0: 206f 7264 6572 5f62 6f6f 6b5b 6f62 7369   order_book[obsi
-000133d0: 6465 5d5b 6f72 6465 725f 626f 6f6b 5f74  de][order_book_t
-000133e0: 6f70 202d 2031 5d5b 305d 0a20 2020 2020  op - 1][0].     
-000133f0: 2020 2065 7863 6570 7420 2849 6e64 6578     except (Index
-00013400: 4572 726f 722c 204b 6579 4572 726f 7229  Error, KeyError)
-00013410: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
-00013420: 2020 206c 6f67 6765 722e 7761 726e 696e     logger.warnin
-00013430: 6728 0a20 2020 2020 2020 2020 2020 2020  g(.             
-00013440: 2020 2020 2020 2066 227b 7061 6972 7d20         f"{pair} 
-00013450: 2d20 7b6e 616d 657d 2050 7269 6365 2061  - {name} Price a
-00013460: 7420 6c6f 6361 7469 6f6e 207b 6f72 6465  t location {orde
-00013470: 725f 626f 6f6b 5f74 6f70 7d20 6672 6f6d  r_book_top} from
-00013480: 206f 7264 6572 626f 6f6b 2022 0a20 2020   orderbook ".   
-00013490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000134a0: 2066 2263 6f75 6c64 206e 6f74 2062 6520   f"could not be 
-000134b0: 6465 7465 726d 696e 6564 2e20 4f72 6465  determined. Orde
-000134c0: 7262 6f6f 6b3a 207b 6f72 6465 725f 626f  rbook: {order_bo
-000134d0: 6f6b 7d22 0a20 2020 2020 2020 2020 2020  ok}".           
-000134e0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
-000134f0: 2020 2072 6169 7365 2050 7269 6369 6e67     raise Pricing
-00013500: 4572 726f 7220 6672 6f6d 2065 0a20 2020  Error from e.   
-00013510: 2020 2020 206c 6f67 6765 722e 6465 6275       logger.debu
-00013520: 6728 6622 7b70 6169 727d 202d 207b 6e61  g(f"{pair} - {na
-00013530: 6d65 7d20 7072 6963 6520 6672 6f6d 206f  me} price from o
-00013540: 7264 6572 626f 6f6b 207b 7072 6963 655f  rderbook {price_
-00013550: 7369 6465 2e63 6170 6974 616c 697a 6528  side.capitalize(
-00013560: 297d 220a 2020 2020 2020 2020 2020 2020  )}".            
-00013570: 2020 2020 2020 2020 2066 2273 6964 6520           f"side 
-00013580: 2d20 746f 7020 7b6f 7264 6572 5f62 6f6f  - top {order_boo
-00013590: 6b5f 746f 707d 206f 7264 6572 2062 6f6f  k_top} order boo
-000135a0: 6b20 7b73 6964 657d 2072 6174 6520 7b72  k {side} rate {r
-000135b0: 6174 653a 2e38 667d 2229 0a20 2020 2020  ate:.8f}").     
-000135c0: 2020 2072 6574 7572 6e20 7261 7465 0a0a     return rate..
-000135d0: 2020 2020 6465 6620 6765 745f 7261 7465      def get_rate
-000135e0: 7328 7365 6c66 2c20 7061 6972 3a20 7374  s(self, pair: st
-000135f0: 722c 2072 6566 7265 7368 3a20 626f 6f6c  r, refresh: bool
-00013600: 2c20 6973 5f73 686f 7274 3a20 626f 6f6c  , is_short: bool
-00013610: 2920 2d3e 2054 7570 6c65 5b66 6c6f 6174  ) -> Tuple[float
-00013620: 2c20 666c 6f61 745d 3a0a 2020 2020 2020  , float]:.      
-00013630: 2020 656e 7472 795f 7261 7465 203d 204e    entry_rate = N
-00013640: 6f6e 650a 2020 2020 2020 2020 6578 6974  one.        exit
-00013650: 5f72 6174 6520 3d20 4e6f 6e65 0a20 2020  _rate = None.   
-00013660: 2020 2020 2069 6620 6e6f 7420 7265 6672       if not refr
-00013670: 6573 683a 0a20 2020 2020 2020 2020 2020  esh:.           
-00013680: 2077 6974 6820 7365 6c66 2e5f 6361 6368   with self._cach
-00013690: 655f 6c6f 636b 3a0a 2020 2020 2020 2020  e_lock:.        
-000136a0: 2020 2020 2020 2020 656e 7472 795f 7261          entry_ra
-000136b0: 7465 203d 2073 656c 662e 5f65 6e74 7279  te = self._entry
-000136c0: 5f72 6174 655f 6361 6368 652e 6765 7428  _rate_cache.get(
-000136d0: 7061 6972 290a 2020 2020 2020 2020 2020  pair).          
-000136e0: 2020 2020 2020 6578 6974 5f72 6174 6520        exit_rate 
-000136f0: 3d20 7365 6c66 2e5f 6578 6974 5f72 6174  = self._exit_rat
-00013700: 655f 6361 6368 652e 6765 7428 7061 6972  e_cache.get(pair
-00013710: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-00013720: 2065 6e74 7279 5f72 6174 653a 0a20 2020   entry_rate:.   
-00013730: 2020 2020 2020 2020 2020 2020 206c 6f67               log
-00013740: 6765 722e 6465 6275 6728 6622 5573 696e  ger.debug(f"Usin
-00013750: 6720 6361 6368 6564 2062 7579 2072 6174  g cached buy rat
-00013760: 6520 666f 7220 7b70 6169 727d 2e22 290a  e for {pair}.").
-00013770: 2020 2020 2020 2020 2020 2020 6966 2065              if e
-00013780: 7869 745f 7261 7465 3a0a 2020 2020 2020  xit_rate:.      
-00013790: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
-000137a0: 2e64 6562 7567 2866 2255 7369 6e67 2063  .debug(f"Using c
-000137b0: 6163 6865 6420 7365 6c6c 2072 6174 6520  ached sell rate 
-000137c0: 666f 7220 7b70 6169 727d 2e22 290a 0a20  for {pair}.").. 
-000137d0: 2020 2020 2020 2065 6e74 7279 5f70 7269         entry_pri
-000137e0: 6369 6e67 203d 2073 656c 662e 5f63 6f6e  cing = self._con
-000137f0: 6669 672e 6765 7428 2765 6e74 7279 5f70  fig.get('entry_p
-00013800: 7269 6369 6e67 272c 207b 7d29 0a20 2020  ricing', {}).   
-00013810: 2020 2020 2065 7869 745f 7072 6963 696e       exit_pricin
-00013820: 6720 3d20 7365 6c66 2e5f 636f 6e66 6967  g = self._config
-00013830: 2e67 6574 2827 6578 6974 5f70 7269 6369  .get('exit_prici
-00013840: 6e67 272c 207b 7d29 0a20 2020 2020 2020  ng', {}).       
-00013850: 206f 7264 6572 5f62 6f6f 6b20 3d20 7469   order_book = ti
-00013860: 636b 6572 203d 204e 6f6e 650a 2020 2020  cker = None.    
-00013870: 2020 2020 6966 206e 6f74 2065 6e74 7279      if not entry
-00013880: 5f72 6174 6520 616e 6420 656e 7472 795f  _rate and entry_
-00013890: 7072 6963 696e 672e 6765 7428 2775 7365  pricing.get('use
-000138a0: 5f6f 7264 6572 5f62 6f6f 6b27 2c20 4661  _order_book', Fa
-000138b0: 6c73 6529 3a0a 2020 2020 2020 2020 2020  lse):.          
-000138c0: 2020 6f72 6465 725f 626f 6f6b 5f74 6f70    order_book_top
-000138d0: 203d 206d 6178 2865 6e74 7279 5f70 7269   = max(entry_pri
-000138e0: 6369 6e67 2e67 6574 2827 6f72 6465 725f  cing.get('order_
-000138f0: 626f 6f6b 5f74 6f70 272c 2031 292c 0a20  book_top', 1),. 
-00013900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013920: 6578 6974 5f70 7269 6369 6e67 2e67 6574  exit_pricing.get
-00013930: 2827 6f72 6465 725f 626f 6f6b 5f74 6f70  ('order_book_top
-00013940: 272c 2031 2929 0a20 2020 2020 2020 2020  ', 1)).         
-00013950: 2020 206f 7264 6572 5f62 6f6f 6b20 3d20     order_book = 
-00013960: 7365 6c66 2e66 6574 6368 5f6c 325f 6f72  self.fetch_l2_or
-00013970: 6465 725f 626f 6f6b 2870 6169 722c 206f  der_book(pair, o
-00013980: 7264 6572 5f62 6f6f 6b5f 746f 7029 0a20  rder_book_top). 
-00013990: 2020 2020 2020 2020 2020 2065 6e74 7279             entry
-000139a0: 5f72 6174 6520 3d20 7365 6c66 2e67 6574  _rate = self.get
-000139b0: 5f72 6174 6528 7061 6972 2c20 7265 6672  _rate(pair, refr
-000139c0: 6573 682c 2027 656e 7472 7927 2c20 6973  esh, 'entry', is
-000139d0: 5f73 686f 7274 2c20 6f72 6465 725f 626f  _short, order_bo
-000139e0: 6f6b 3d6f 7264 6572 5f62 6f6f 6b29 0a20  ok=order_book). 
-000139f0: 2020 2020 2020 2065 6c69 6620 6e6f 7420         elif not 
-00013a00: 656e 7472 795f 7261 7465 3a0a 2020 2020  entry_rate:.    
-00013a10: 2020 2020 2020 2020 7469 636b 6572 203d          ticker =
-00013a20: 2073 656c 662e 6665 7463 685f 7469 636b   self.fetch_tick
-00013a30: 6572 2870 6169 7229 0a20 2020 2020 2020  er(pair).       
-00013a40: 2020 2020 2065 6e74 7279 5f72 6174 6520       entry_rate 
-00013a50: 3d20 7365 6c66 2e67 6574 5f72 6174 6528  = self.get_rate(
-00013a60: 7061 6972 2c20 7265 6672 6573 682c 2027  pair, refresh, '
-00013a70: 656e 7472 7927 2c20 6973 5f73 686f 7274  entry', is_short
-00013a80: 2c20 7469 636b 6572 3d74 6963 6b65 7229  , ticker=ticker)
-00013a90: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00013aa0: 6578 6974 5f72 6174 653a 0a20 2020 2020  exit_rate:.     
-00013ab0: 2020 2020 2020 2065 7869 745f 7261 7465         exit_rate
-00013ac0: 203d 2073 656c 662e 6765 745f 7261 7465   = self.get_rate
-00013ad0: 2870 6169 722c 2072 6566 7265 7368 2c20  (pair, refresh, 
-00013ae0: 2765 7869 7427 2c0a 2020 2020 2020 2020  'exit',.        
-00013af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013b00: 2020 2020 2020 2020 2020 2020 2020 6973                is
-00013b10: 5f73 686f 7274 2c20 6f72 6465 725f 626f  _short, order_bo
-00013b20: 6f6b 3d6f 7264 6572 5f62 6f6f 6b2c 2074  ok=order_book, t
-00013b30: 6963 6b65 723d 7469 636b 6572 290a 2020  icker=ticker).  
-00013b40: 2020 2020 2020 7265 7475 726e 2065 6e74        return ent
-00013b50: 7279 5f72 6174 652c 2065 7869 745f 7261  ry_rate, exit_ra
-00013b60: 7465 0a0a 2020 2020 2320 4665 6520 6861  te..    # Fee ha
-00013b70: 6e64 6c69 6e67 0a0a 2020 2020 4072 6574  ndling..    @ret
-00013b80: 7269 6572 0a20 2020 2064 6566 2067 6574  rier.    def get
-00013b90: 5f74 7261 6465 735f 666f 725f 6f72 6465  _trades_for_orde
-00013ba0: 7228 7365 6c66 2c20 6f72 6465 725f 6964  r(self, order_id
-00013bb0: 3a20 7374 722c 2070 6169 723a 2073 7472  : str, pair: str
-00013bc0: 2c20 7369 6e63 653a 2064 6174 6574 696d  , since: datetim
-00013bd0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-00013be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013bf0: 7061 7261 6d73 3a20 4f70 7469 6f6e 616c  params: Optional
-00013c00: 5b44 6963 745d 203d 204e 6f6e 6529 202d  [Dict] = None) -
-00013c10: 3e20 4c69 7374 3a0a 2020 2020 2020 2020  > List:.        
-00013c20: 2222 220a 2020 2020 2020 2020 4665 7463  """.        Fetc
-00013c30: 6820 4f72 6465 7273 2075 7369 6e67 2074  h Orders using t
-00013c40: 6865 2022 6665 7463 685f 6d79 5f74 7261  he "fetch_my_tra
-00013c50: 6465 7322 2065 6e64 706f 696e 7420 616e  des" endpoint an
-00013c60: 6420 6669 6c74 6572 2074 6865 6d20 6279  d filter them by
-00013c70: 206f 7264 6572 2d69 642e 0a20 2020 2020   order-id..     
-00013c80: 2020 2054 6865 2022 7369 6e63 6522 2061     The "since" a
-00013c90: 7267 756d 656e 7420 7061 7373 6564 2069  rgument passed i
-00013ca0: 6e20 6973 2063 6f6d 696e 6720 6672 6f6d  n is coming from
-00013cb0: 2074 6865 2064 6174 6162 6173 6520 616e   the database an
-00013cc0: 6420 6973 2069 6e20 5554 432c 0a20 2020  d is in UTC,.   
-00013cd0: 2020 2020 2061 7320 7469 6d65 7a6f 6e65       as timezone
-00013ce0: 2d6e 6174 6976 6520 6461 7465 7469 6d65  -native datetime
-00013cf0: 206f 626a 6563 742e 0a20 2020 2020 2020   object..       
-00013d00: 2046 726f 6d20 7468 6520 7079 7468 6f6e   From the python
-00013d10: 2064 6f63 756d 656e 7461 7469 6f6e 3a0a   documentation:.
-00013d20: 2020 2020 2020 2020 2020 2020 3e20 4e61              > Na
-00013d30: 6976 6520 6461 7465 7469 6d65 2069 6e73  ive datetime ins
-00013d40: 7461 6e63 6573 2061 7265 2061 7373 756d  tances are assum
-00013d50: 6564 2074 6f20 7265 7072 6573 656e 7420  ed to represent 
-00013d60: 6c6f 6361 6c20 7469 6d65 0a20 2020 2020  local time.     
-00013d70: 2020 2054 6865 7265 666f 7265 2c20 6361     Therefore, ca
-00013d80: 6c6c 696e 6720 2273 696e 6365 2e74 696d  lling "since.tim
-00013d90: 6573 7461 6d70 2829 2220 7769 6c6c 2067  estamp()" will g
-00013da0: 6574 2074 6865 2055 5443 2074 696d 6573  et the UTC times
-00013db0: 7461 6d70 2c20 6166 7465 7220 6170 706c  tamp, after appl
-00013dc0: 7969 6e67 2074 6865 0a20 2020 2020 2020  ying the.       
-00013dd0: 2074 7261 6e73 666f 726d 6174 696f 6e20   transformation 
-00013de0: 6672 6f6d 206c 6f63 616c 2074 696d 657a  from local timez
-00013df0: 6f6e 6520 746f 2055 5443 2e0a 2020 2020  one to UTC..    
-00013e00: 2020 2020 5468 6973 2077 6f72 6b73 2066      This works f
-00013e10: 6f72 2074 696d 657a 6f6e 6573 2055 5443  or timezones UTC
-00013e20: 2b20 7369 6e63 6520 7468 656e 2074 6865  + since then the
-00013e30: 2072 6573 756c 7420 7769 6c6c 2063 6f6e   result will con
-00013e40: 7461 696e 2074 7261 6465 7320 6672 6f6d  tain trades from
-00013e50: 2061 2066 6577 2068 6f75 7273 0a20 2020   a few hours.   
-00013e60: 2020 2020 2069 6e73 7465 6164 206f 6620       instead of 
-00013e70: 6672 6f6d 2074 6865 206c 6173 7420 3520  from the last 5 
-00013e80: 7365 636f 6e64 732c 2068 6f77 6576 6572  seconds, however
-00013e90: 2066 6169 6c73 2066 6f72 2055 5443 2d20   fails for UTC- 
-00013ea0: 7469 6d65 7a6f 6e65 732c 0a20 2020 2020  timezones,.     
-00013eb0: 2020 2073 696e 6365 2077 6527 7265 2074     since we're t
-00013ec0: 6865 6e20 6173 6b69 6e67 2066 6f72 2074  hen asking for t
-00013ed0: 7261 6465 7320 7769 7468 2061 2022 7369  rades with a "si
-00013ee0: 6e63 6522 2061 7267 756d 656e 7420 696e  nce" argument in
-00013ef0: 2074 6865 2066 7574 7572 652e 0a0a 2020   the future...  
-00013f00: 2020 2020 2020 3a70 6172 616d 206f 7264        :param ord
-00013f10: 6572 5f69 6420 6f72 6465 725f 6964 3a20  er_id order_id: 
-00013f20: 4f72 6465 722d 6964 2061 7320 6769 7665  Order-id as give
-00013f30: 6e20 7768 656e 2063 7265 6174 696e 6720  n when creating 
-00013f40: 7468 6520 6f72 6465 720a 2020 2020 2020  the order.      
-00013f50: 2020 3a70 6172 616d 2070 6169 723a 2050    :param pair: P
-00013f60: 6169 7220 7468 6520 6f72 6465 7220 6973  air the order is
-00013f70: 2066 6f72 0a20 2020 2020 2020 203a 7061   for.        :pa
-00013f80: 7261 6d20 7369 6e63 653a 2064 6174 6574  ram since: datet
-00013f90: 696d 6520 6f62 6a65 6374 206f 6620 7468  ime object of th
-00013fa0: 6520 6f72 6465 7220 6372 6561 7469 6f6e  e order creation
-00013fb0: 2074 696d 652e 2041 7373 756d 6573 206f   time. Assumes o
-00013fc0: 626a 6563 7420 6973 2069 6e20 5554 432e  bject is in UTC.
-00013fd0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00013fe0: 2020 2020 2069 6620 7365 6c66 2e5f 636f       if self._co
-00013ff0: 6e66 6967 5b27 6472 795f 7275 6e27 5d3a  nfig['dry_run']:
-00014000: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00014010: 7572 6e20 5b5d 0a20 2020 2020 2020 2069  urn [].        i
-00014020: 6620 6e6f 7420 7365 6c66 2e65 7863 6861  f not self.excha
-00014030: 6e67 655f 6861 7328 2766 6574 6368 4d79  nge_has('fetchMy
-00014040: 5472 6164 6573 2729 3a0a 2020 2020 2020  Trades'):.      
-00014050: 2020 2020 2020 7265 7475 726e 205b 5d0a        return [].
-00014060: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
-00014070: 2020 2020 2020 2020 2023 2041 6c6c 6f77           # Allow
-00014080: 2035 7320 6f66 6673 6574 2074 6f20 6361   5s offset to ca
-00014090: 7463 6820 736c 6967 6874 2074 696d 6520  tch slight time 
-000140a0: 6f66 6673 6574 7320 2864 6973 636f 7665  offsets (discove
-000140b0: 7265 6420 696e 2023 3131 3835 290a 2020  red in #1185).  
-000140c0: 2020 2020 2020 2020 2020 2320 7369 6e63            # sinc
-000140d0: 6520 6e65 6564 7320 746f 2062 6520 696e  e needs to be in
-000140e0: 7420 696e 206d 696c 6c69 7365 636f 6e64  t in millisecond
-000140f0: 730a 2020 2020 2020 2020 2020 2020 5f70  s.            _p
-00014100: 6172 616d 7320 3d20 7061 7261 6d73 2069  arams = params i
-00014110: 6620 7061 7261 6d73 2065 6c73 6520 7b7d  f params else {}
-00014120: 0a20 2020 2020 2020 2020 2020 206d 795f  .            my_
-00014130: 7472 6164 6573 203d 2073 656c 662e 5f61  trades = self._a
-00014140: 7069 2e66 6574 6368 5f6d 795f 7472 6164  pi.fetch_my_trad
-00014150: 6573 280a 2020 2020 2020 2020 2020 2020  es(.            
-00014160: 2020 2020 7061 6972 2c20 696e 7428 2873      pair, int((s
-00014170: 696e 6365 2e72 6570 6c61 6365 2874 7a69  ince.replace(tzi
-00014180: 6e66 6f3d 7469 6d65 7a6f 6e65 2e75 7463  nfo=timezone.utc
-00014190: 292e 7469 6d65 7374 616d 7028 2920 2d20  ).timestamp() - 
-000141a0: 3529 202a 2031 3030 3029 2c0a 2020 2020  5) * 1000),.    
-000141b0: 2020 2020 2020 2020 2020 2020 7061 7261              para
-000141c0: 6d73 3d5f 7061 7261 6d73 290a 2020 2020  ms=_params).    
-000141d0: 2020 2020 2020 2020 6d61 7463 6865 645f          matched_
-000141e0: 7472 6164 6573 203d 205b 7472 6164 6520  trades = [trade 
-000141f0: 666f 7220 7472 6164 6520 696e 206d 795f  for trade in my_
-00014200: 7472 6164 6573 2069 6620 7472 6164 655b  trades if trade[
-00014210: 276f 7264 6572 275d 203d 3d20 6f72 6465  'order'] == orde
-00014220: 725f 6964 5d0a 0a20 2020 2020 2020 2020  r_id]..         
-00014230: 2020 2073 656c 662e 5f6c 6f67 5f65 7863     self._log_exc
-00014240: 6861 6e67 655f 7265 7370 6f6e 7365 2827  hange_response('
-00014250: 6765 745f 7472 6164 6573 5f66 6f72 5f6f  get_trades_for_o
-00014260: 7264 6572 272c 206d 6174 6368 6564 5f74  rder', matched_t
-00014270: 7261 6465 7329 0a0a 2020 2020 2020 2020  rades)..        
-00014280: 2020 2020 6d61 7463 6865 645f 7472 6164      matched_trad
-00014290: 6573 203d 2073 656c 662e 5f74 7261 6465  es = self._trade
-000142a0: 735f 636f 6e74 7261 6374 735f 746f 5f61  s_contracts_to_a
-000142b0: 6d6f 756e 7428 6d61 7463 6865 645f 7472  mount(matched_tr
-000142c0: 6164 6573 290a 0a20 2020 2020 2020 2020  ades)..         
-000142d0: 2020 2072 6574 7572 6e20 6d61 7463 6865     return matche
-000142e0: 645f 7472 6164 6573 0a20 2020 2020 2020  d_trades.       
-000142f0: 2065 7863 6570 7420 6363 7874 2e44 446f   except ccxt.DDo
-00014300: 5350 726f 7465 6374 696f 6e20 6173 2065  SProtection as e
-00014310: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-00014320: 6973 6520 4444 6f73 5072 6f74 6563 7469  ise DDosProtecti
-00014330: 6f6e 2865 2920 6672 6f6d 2065 0a20 2020  on(e) from e.   
-00014340: 2020 2020 2065 7863 6570 7420 2863 6378       except (ccx
-00014350: 742e 4f70 6572 6174 696f 6e46 6169 6c65  t.OperationFaile
-00014360: 642c 2063 6378 742e 4578 6368 616e 6765  d, ccxt.Exchange
-00014370: 4572 726f 7229 2061 7320 653a 0a20 2020  Error) as e:.   
-00014380: 2020 2020 2020 2020 2072 6169 7365 2054           raise T
-00014390: 656d 706f 7261 7279 4572 726f 7228 0a20  emporaryError(. 
-000143a0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-000143b0: 2743 6f75 6c64 206e 6f74 2067 6574 2074  'Could not get t
-000143c0: 7261 6465 7320 6475 6520 746f 207b 652e  rades due to {e.
-000143d0: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
-000143e0: 5f5f 7d2e 204d 6573 7361 6765 3a20 7b65  __}. Message: {e
-000143f0: 7d27 2920 6672 6f6d 2065 0a20 2020 2020  }') from e.     
-00014400: 2020 2065 7863 6570 7420 6363 7874 2e42     except ccxt.B
-00014410: 6173 6545 7272 6f72 2061 7320 653a 0a20  aseError as e:. 
-00014420: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00014430: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
-00014440: 7074 696f 6e28 6529 2066 726f 6d20 650a  ption(e) from e.
-00014450: 0a20 2020 2064 6566 2067 6574 5f6f 7264  .    def get_ord
-00014460: 6572 5f69 645f 636f 6e64 6974 696f 6e61  er_id_conditiona
-00014470: 6c28 7365 6c66 2c20 6f72 6465 723a 2044  l(self, order: D
-00014480: 6963 745b 7374 722c 2041 6e79 5d29 202d  ict[str, Any]) -
-00014490: 3e20 7374 723a 0a20 2020 2020 2020 2072  > str:.        r
-000144a0: 6574 7572 6e20 6f72 6465 725b 2769 6427  eturn order['id'
-000144b0: 5d0a 0a20 2020 2040 7265 7472 6965 720a  ]..    @retrier.
-000144c0: 2020 2020 6465 6620 6765 745f 6665 6528      def get_fee(
-000144d0: 7365 6c66 2c20 7379 6d62 6f6c 3a20 7374  self, symbol: st
-000144e0: 722c 2074 7970 653a 2073 7472 203d 2027  r, type: str = '
-000144f0: 272c 2073 6964 653a 2073 7472 203d 2027  ', side: str = '
-00014500: 272c 2061 6d6f 756e 743a 2066 6c6f 6174  ', amount: float
-00014510: 203d 2031 2c0a 2020 2020 2020 2020 2020   = 1,.          
-00014520: 2020 2020 2020 7072 6963 653a 2066 6c6f        price: flo
-00014530: 6174 203d 2031 2c20 7461 6b65 725f 6f72  at = 1, taker_or
-00014540: 5f6d 616b 6572 3a20 4d61 6b65 7254 616b  _maker: MakerTak
-00014550: 6572 203d 2027 6d61 6b65 7227 2920 2d3e  er = 'maker') ->
-00014560: 2066 6c6f 6174 3a0a 2020 2020 2020 2020   float:.        
-00014570: 2222 220a 2020 2020 2020 2020 5265 7472  """.        Retr
-00014580: 6965 7665 2066 6565 2066 726f 6d20 6578  ieve fee from ex
-00014590: 6368 616e 6765 0a20 2020 2020 2020 203a  change.        :
-000145a0: 7061 7261 6d20 7379 6d62 6f6c 3a20 5061  param symbol: Pa
-000145b0: 6972 0a20 2020 2020 2020 203a 7061 7261  ir.        :para
-000145c0: 6d20 7479 7065 3a20 5479 7065 206f 6620  m type: Type of 
-000145d0: 6f72 6465 7220 286d 6172 6b65 742c 206c  order (market, l
-000145e0: 696d 6974 2c20 2e2e 2e29 0a20 2020 2020  imit, ...).     
-000145f0: 2020 203a 7061 7261 6d20 7369 6465 3a20     :param side: 
-00014600: 5369 6465 206f 6620 6f72 6465 7220 2862  Side of order (b
-00014610: 7579 2c20 7365 6c6c 290a 2020 2020 2020  uy, sell).      
-00014620: 2020 3a70 6172 616d 2061 6d6f 756e 743a    :param amount:
-00014630: 2041 6d6f 756e 7420 6f66 206f 7264 6572   Amount of order
-00014640: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00014650: 7072 6963 653a 2050 7269 6365 206f 6620  price: Price of 
-00014660: 6f72 6465 720a 2020 2020 2020 2020 3a70  order.        :p
-00014670: 6172 616d 2074 616b 6572 5f6f 725f 6d61  aram taker_or_ma
-00014680: 6b65 723a 2027 6d61 6b65 7227 206f 7220  ker: 'maker' or 
-00014690: 2774 616b 6572 2720 2869 676e 6f72 6564  'taker' (ignored
-000146a0: 2069 6620 2274 7970 6522 2069 7320 7072   if "type" is pr
-000146b0: 6f76 6964 6564 290a 2020 2020 2020 2020  ovided).        
-000146c0: 2222 220a 2020 2020 2020 2020 6966 2074  """.        if t
-000146d0: 7970 6520 616e 6420 7479 7065 203d 3d20  ype and type == 
-000146e0: 276d 6172 6b65 7427 3a0a 2020 2020 2020  'market':.      
-000146f0: 2020 2020 2020 7461 6b65 725f 6f72 5f6d        taker_or_m
-00014700: 616b 6572 203d 2027 7461 6b65 7227 0a20  aker = 'taker'. 
-00014710: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-00014720: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00014730: 5f63 6f6e 6669 675b 2764 7279 5f72 756e  _config['dry_run
-00014740: 275d 2061 6e64 2073 656c 662e 5f63 6f6e  '] and self._con
-00014750: 6669 672e 6765 7428 2766 6565 272c 204e  fig.get('fee', N
-00014760: 6f6e 6529 2069 7320 6e6f 7420 4e6f 6e65  one) is not None
-00014770: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00014780: 2020 7265 7475 726e 2073 656c 662e 5f63    return self._c
-00014790: 6f6e 6669 675b 2766 6565 275d 0a20 2020  onfig['fee'].   
-000147a0: 2020 2020 2020 2020 2023 2076 616c 6964           # valid
-000147b0: 6174 6520 7468 6174 206d 6172 6b65 7473  ate that markets
-000147c0: 2061 7265 206c 6f61 6465 6420 6265 666f   are loaded befo
-000147d0: 7265 2074 7279 696e 6720 746f 2067 6574  re trying to get
-000147e0: 2066 6565 0a20 2020 2020 2020 2020 2020   fee.           
-000147f0: 2069 6620 7365 6c66 2e5f 6170 692e 6d61   if self._api.ma
-00014800: 726b 6574 7320 6973 204e 6f6e 6520 6f72  rkets is None or
-00014810: 206c 656e 2873 656c 662e 5f61 7069 2e6d   len(self._api.m
-00014820: 6172 6b65 7473 2920 3d3d 2030 3a0a 2020  arkets) == 0:.  
-00014830: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00014840: 6c66 2e5f 6170 692e 6c6f 6164 5f6d 6172  lf._api.load_mar
-00014850: 6b65 7473 2870 6172 616d 733d 7b7d 290a  kets(params={}).
-00014860: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00014870: 7572 6e20 7365 6c66 2e5f 6170 692e 6361  urn self._api.ca
-00014880: 6c63 756c 6174 655f 6665 6528 7379 6d62  lculate_fee(symb
-00014890: 6f6c 3d73 796d 626f 6c2c 2074 7970 653d  ol=symbol, type=
-000148a0: 7479 7065 2c20 7369 6465 3d73 6964 652c  type, side=side,
-000148b0: 2061 6d6f 756e 743d 616d 6f75 6e74 2c0a   amount=amount,.
-000148c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000148d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000148e0: 2020 2020 2020 2020 2020 2070 7269 6365             price
-000148f0: 3d70 7269 6365 2c20 7461 6b65 724f 724d  =price, takerOrM
-00014900: 616b 6572 3d74 616b 6572 5f6f 725f 6d61  aker=taker_or_ma
-00014910: 6b65 7229 5b27 7261 7465 275d 0a20 2020  ker)['rate'].   
-00014920: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
-00014930: 2e44 446f 5350 726f 7465 6374 696f 6e20  .DDoSProtection 
-00014940: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
-00014950: 2020 7261 6973 6520 4444 6f73 5072 6f74    raise DDosProt
-00014960: 6563 7469 6f6e 2865 2920 6672 6f6d 2065  ection(e) from e
-00014970: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-00014980: 2863 6378 742e 4f70 6572 6174 696f 6e46  (ccxt.OperationF
-00014990: 6169 6c65 642c 2063 6378 742e 4578 6368  ailed, ccxt.Exch
-000149a0: 616e 6765 4572 726f 7229 2061 7320 653a  angeError) as e:
-000149b0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-000149c0: 7365 2054 656d 706f 7261 7279 4572 726f  se TemporaryErro
-000149d0: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
-000149e0: 2020 2066 2743 6f75 6c64 206e 6f74 2067     f'Could not g
-000149f0: 6574 2066 6565 2069 6e66 6f20 6475 6520  et fee info due 
-00014a00: 746f 207b 652e 5f5f 636c 6173 735f 5f2e  to {e.__class__.
-00014a10: 5f5f 6e61 6d65 5f5f 7d2e 204d 6573 7361  __name__}. Messa
-00014a20: 6765 3a20 7b65 7d27 2920 6672 6f6d 2065  ge: {e}') from e
-00014a30: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-00014a40: 6363 7874 2e42 6173 6545 7272 6f72 2061  ccxt.BaseError a
-00014a50: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
-00014a60: 2072 6169 7365 204f 7065 7261 7469 6f6e   raise Operation
-00014a70: 616c 4578 6365 7074 696f 6e28 6529 2066  alException(e) f
-00014a80: 726f 6d20 650a 0a20 2020 2040 7374 6174  rom e..    @stat
-00014a90: 6963 6d65 7468 6f64 0a20 2020 2064 6566  icmethod.    def
-00014aa0: 206f 7264 6572 5f68 6173 5f66 6565 286f   order_has_fee(o
-00014ab0: 7264 6572 3a20 4469 6374 2920 2d3e 2062  rder: Dict) -> b
-00014ac0: 6f6f 6c3a 0a20 2020 2020 2020 2022 2222  ool:.        """
-00014ad0: 0a20 2020 2020 2020 2056 6572 6966 6965  .        Verifie
-00014ae0: 7320 6966 2074 6865 2070 6173 7365 6420  s if the passed 
-00014af0: 696e 206f 7264 6572 2064 6963 7420 6861  in order dict ha
-00014b00: 7320 7468 6520 6e65 6564 6564 206b 6579  s the needed key
-00014b10: 7320 746f 2065 7874 7261 6374 2066 6565  s to extract fee
-00014b20: 732c 0a20 2020 2020 2020 2061 6e64 2074  s,.        and t
-00014b30: 6861 7420 7468 6573 6520 6b65 7973 2028  hat these keys (
-00014b40: 6375 7272 656e 6379 2c20 636f 7374 2920  currency, cost) 
-00014b50: 6172 6520 6e6f 7420 656d 7074 792e 0a20  are not empty.. 
-00014b60: 2020 2020 2020 203a 7061 7261 6d20 6f72         :param or
-00014b70: 6465 723a 204f 7264 6572 206f 7220 7472  der: Order or tr
-00014b80: 6164 6520 286f 6e65 2074 7261 6465 2920  ade (one trade) 
-00014b90: 6469 6374 0a20 2020 2020 2020 203a 7265  dict.        :re
-00014ba0: 7475 726e 3a20 5472 7565 2069 6620 7468  turn: True if th
-00014bb0: 6520 6665 6520 7375 6273 7472 7563 7475  e fee substructu
-00014bc0: 7265 2063 6f6e 7461 696e 7320 6375 7272  re contains curr
-00014bd0: 656e 6379 2061 6e64 2063 6f73 742c 2066  ency and cost, f
-00014be0: 616c 7365 206f 7468 6572 7769 7365 0a20  alse otherwise. 
-00014bf0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-00014c00: 2020 2069 6620 6e6f 7420 6973 696e 7374     if not isinst
-00014c10: 616e 6365 286f 7264 6572 2c20 6469 6374  ance(order, dict
-00014c20: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
-00014c30: 6574 7572 6e20 4661 6c73 650a 2020 2020  eturn False.    
-00014c40: 2020 2020 7265 7475 726e 2028 2766 6565      return ('fee
-00014c50: 2720 696e 206f 7264 6572 2061 6e64 206f  ' in order and o
-00014c60: 7264 6572 5b27 6665 6527 5d20 6973 206e  rder['fee'] is n
-00014c70: 6f74 204e 6f6e 650a 2020 2020 2020 2020  ot None.        
-00014c80: 2020 2020 2020 2020 616e 6420 286f 7264          and (ord
-00014c90: 6572 5b27 6665 6527 5d2e 6b65 7973 2829  er['fee'].keys()
-00014ca0: 203e 3d20 7b27 6375 7272 656e 6379 272c   >= {'currency',
-00014cb0: 2027 636f 7374 277d 290a 2020 2020 2020   'cost'}).      
-00014cc0: 2020 2020 2020 2020 2020 616e 6420 6f72            and or
-00014cd0: 6465 725b 2766 6565 275d 5b27 6375 7272  der['fee']['curr
-00014ce0: 656e 6379 275d 2069 7320 6e6f 7420 4e6f  ency'] is not No
-00014cf0: 6e65 0a20 2020 2020 2020 2020 2020 2020  ne.             
-00014d00: 2020 2061 6e64 206f 7264 6572 5b27 6665     and order['fe
-00014d10: 6527 5d5b 2763 6f73 7427 5d20 6973 206e  e']['cost'] is n
-00014d20: 6f74 204e 6f6e 650a 2020 2020 2020 2020  ot None.        
-00014d30: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
-00014d40: 6566 2063 616c 6375 6c61 7465 5f66 6565  ef calculate_fee
-00014d50: 5f72 6174 6528 0a20 2020 2020 2020 2020  _rate(.         
-00014d60: 2020 2073 656c 662c 2066 6565 3a20 4469     self, fee: Di
-00014d70: 6374 2c20 7379 6d62 6f6c 3a20 7374 722c  ct, symbol: str,
-00014d80: 2063 6f73 743a 2066 6c6f 6174 2c20 616d   cost: float, am
-00014d90: 6f75 6e74 3a20 666c 6f61 7429 202d 3e20  ount: float) -> 
-00014da0: 4f70 7469 6f6e 616c 5b66 6c6f 6174 5d3a  Optional[float]:
-00014db0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00014dc0: 2020 2020 2043 616c 6375 6c61 7465 2066       Calculate f
-00014dd0: 6565 2072 6174 6520 6966 2069 7427 7320  ee rate if it's 
-00014de0: 6e6f 7420 6769 7665 6e20 6279 2074 6865  not given by the
-00014df0: 2065 7863 6861 6e67 652e 0a20 2020 2020   exchange..     
-00014e00: 2020 203a 7061 7261 6d20 6665 653a 2063     :param fee: c
-00014e10: 6378 7420 4665 6520 6469 6374 202d 206d  cxt Fee dict - m
-00014e20: 7573 7420 636f 6e74 6169 6e20 636f 7374  ust contain cost
-00014e30: 202f 2063 7572 7265 6e63 7920 2f20 7261   / currency / ra
-00014e40: 7465 0a20 2020 2020 2020 203a 7061 7261  te.        :para
-00014e50: 6d20 7379 6d62 6f6c 3a20 5379 6d62 6f6c  m symbol: Symbol
-00014e60: 206f 6620 7468 6520 6f72 6465 720a 2020   of the order.  
-00014e70: 2020 2020 2020 3a70 6172 616d 2063 6f73        :param cos
-00014e80: 743a 2054 6f74 616c 2063 6f73 7420 6f66  t: Total cost of
-00014e90: 2074 6865 206f 7264 6572 0a20 2020 2020   the order.     
-00014ea0: 2020 203a 7061 7261 6d20 616d 6f75 6e74     :param amount
-00014eb0: 3a20 416d 6f75 6e74 206f 6620 7468 6520  : Amount of the 
-00014ec0: 6f72 6465 720a 2020 2020 2020 2020 2222  order.        ""
-00014ed0: 220a 2020 2020 2020 2020 6966 2066 6565  ".        if fee
-00014ee0: 2e67 6574 2827 7261 7465 2729 2069 7320  .get('rate') is 
-00014ef0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00014f00: 2020 2020 2020 7265 7475 726e 2066 6565        return fee
-00014f10: 2e67 6574 2827 7261 7465 2729 0a20 2020  .get('rate').   
-00014f20: 2020 2020 2066 6565 5f63 7572 7220 3d20       fee_curr = 
-00014f30: 6665 652e 6765 7428 2763 7572 7265 6e63  fee.get('currenc
-00014f40: 7927 290a 2020 2020 2020 2020 6966 2066  y').        if f
-00014f50: 6565 5f63 7572 7220 6973 204e 6f6e 653a  ee_curr is None:
-00014f60: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00014f70: 7572 6e20 4e6f 6e65 0a20 2020 2020 2020  urn None.       
-00014f80: 2066 6565 5f63 6f73 7420 3d20 666c 6f61   fee_cost = floa
-00014f90: 7428 6665 655b 2763 6f73 7427 5d29 0a0a  t(fee['cost'])..
-00014fa0: 2020 2020 2020 2020 2320 4361 6c63 756c          # Calcul
-00014fb0: 6174 6520 6665 6520 6261 7365 6420 6f6e  ate fee based on
-00014fc0: 206f 7264 6572 2064 6574 6169 6c73 0a20   order details. 
-00014fd0: 2020 2020 2020 2069 6620 6665 655f 6375         if fee_cu
-00014fe0: 7272 203d 3d20 7365 6c66 2e67 6574 5f70  rr == self.get_p
-00014ff0: 6169 725f 6261 7365 5f63 7572 7265 6e63  air_base_currenc
-00015000: 7928 7379 6d62 6f6c 293a 0a20 2020 2020  y(symbol):.     
-00015010: 2020 2020 2020 2023 2042 6173 6520 6375         # Base cu
-00015020: 7272 656e 6379 202d 2064 6976 6964 6520  rrency - divide 
-00015030: 6279 2061 6d6f 756e 740a 2020 2020 2020  by amount.      
-00015040: 2020 2020 2020 7265 7475 726e 2072 6f75        return rou
-00015050: 6e64 2866 6565 5f63 6f73 7420 2f20 616d  nd(fee_cost / am
-00015060: 6f75 6e74 2c20 3829 0a20 2020 2020 2020  ount, 8).       
-00015070: 2065 6c69 6620 6665 655f 6375 7272 203d   elif fee_curr =
-00015080: 3d20 7365 6c66 2e67 6574 5f70 6169 725f  = self.get_pair_
-00015090: 7175 6f74 655f 6375 7272 656e 6379 2873  quote_currency(s
-000150a0: 796d 626f 6c29 3a0a 2020 2020 2020 2020  ymbol):.        
-000150b0: 2020 2020 2320 5175 6f74 6520 6375 7272      # Quote curr
-000150c0: 656e 6379 202d 2064 6976 6964 6520 6279  ency - divide by
-000150d0: 2063 6f73 740a 2020 2020 2020 2020 2020   cost.          
-000150e0: 2020 7265 7475 726e 2072 6f75 6e64 2866    return round(f
-000150f0: 6565 5f63 6f73 7420 2f20 636f 7374 2c20  ee_cost / cost, 
-00015100: 3829 2069 6620 636f 7374 2065 6c73 6520  8) if cost else 
-00015110: 4e6f 6e65 0a20 2020 2020 2020 2065 6c73  None.        els
-00015120: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
-00015130: 2049 6620 4665 6520 6375 7272 656e 6379   If Fee currency
-00015140: 2069 7320 6120 6469 6666 6572 656e 7420   is a different 
-00015150: 6375 7272 656e 6379 0a20 2020 2020 2020  currency.       
-00015160: 2020 2020 2069 6620 6e6f 7420 636f 7374       if not cost
-00015170: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00015180: 2020 2320 4966 2063 6f73 7420 6973 204e    # If cost is N
-00015190: 6f6e 6520 6f72 2030 2e30 202d 3e20 6661  one or 0.0 -> fa
-000151a0: 6c73 792c 2072 6574 7572 6e20 4e6f 6e65  lsy, return None
-000151b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000151c0: 2072 6574 7572 6e20 4e6f 6e65 0a20 2020   return None.   
-000151d0: 2020 2020 2020 2020 2074 7279 3a0a 2020           try:.  
-000151e0: 2020 2020 2020 2020 2020 2020 2020 636f                co
-000151f0: 6d62 203d 2073 656c 662e 6765 745f 7661  mb = self.get_va
-00015200: 6c69 645f 7061 6972 5f63 6f6d 6269 6e61  lid_pair_combina
-00015210: 7469 6f6e 2866 6565 5f63 7572 722c 2073  tion(fee_curr, s
-00015220: 656c 662e 5f63 6f6e 6669 675b 2773 7461  elf._config['sta
-00015230: 6b65 5f63 7572 7265 6e63 7927 5d29 0a20  ke_currency']). 
-00015240: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00015250: 6963 6b20 3d20 7365 6c66 2e66 6574 6368  ick = self.fetch
-00015260: 5f74 6963 6b65 7228 636f 6d62 290a 0a20  _ticker(comb).. 
-00015270: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00015280: 6565 5f74 6f5f 7175 6f74 655f 7261 7465  ee_to_quote_rate
-00015290: 203d 2073 6166 655f 7661 6c75 655f 6661   = safe_value_fa
-000152a0: 6c6c 6261 636b 3228 7469 636b 2c20 7469  llback2(tick, ti
-000152b0: 636b 2c20 276c 6173 7427 2c20 2761 736b  ck, 'last', 'ask
-000152c0: 2729 0a20 2020 2020 2020 2020 2020 2065  ').            e
-000152d0: 7863 6570 7420 2856 616c 7565 4572 726f  xcept (ValueErro
-000152e0: 722c 2045 7863 6861 6e67 6545 7272 6f72  r, ExchangeError
-000152f0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00015300: 2020 2066 6565 5f74 6f5f 7175 6f74 655f     fee_to_quote_
-00015310: 7261 7465 203d 2073 656c 662e 5f63 6f6e  rate = self._con
-00015320: 6669 675b 2765 7863 6861 6e67 6527 5d2e  fig['exchange'].
-00015330: 6765 7428 2775 6e6b 6e6f 776e 5f66 6565  get('unknown_fee
-00015340: 5f72 6174 6527 2c20 4e6f 6e65 290a 2020  _rate', None).  
-00015350: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00015360: 206e 6f74 2066 6565 5f74 6f5f 7175 6f74   not fee_to_quot
-00015370: 655f 7261 7465 3a0a 2020 2020 2020 2020  e_rate:.        
-00015380: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00015390: 726e 204e 6f6e 650a 2020 2020 2020 2020  rn None.        
-000153a0: 2020 2020 7265 7475 726e 2072 6f75 6e64      return round
-000153b0: 2828 6665 655f 636f 7374 202a 2066 6565  ((fee_cost * fee
-000153c0: 5f74 6f5f 7175 6f74 655f 7261 7465 2920  _to_quote_rate) 
-000153d0: 2f20 636f 7374 2c20 3829 0a0a 2020 2020  / cost, 8)..    
-000153e0: 6465 6620 6578 7472 6163 745f 636f 7374  def extract_cost
-000153f0: 5f63 7572 725f 7261 7465 2873 656c 662c  _curr_rate(self,
-00015400: 2066 6565 3a20 4469 6374 2c20 7379 6d62   fee: Dict, symb
-00015410: 6f6c 3a20 7374 722c 2063 6f73 743a 2066  ol: str, cost: f
-00015420: 6c6f 6174 2c0a 2020 2020 2020 2020 2020  loat,.          
-00015430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015440: 2020 2020 2061 6d6f 756e 743a 2066 6c6f       amount: flo
-00015450: 6174 2920 2d3e 2054 7570 6c65 5b66 6c6f  at) -> Tuple[flo
-00015460: 6174 2c20 7374 722c 204f 7074 696f 6e61  at, str, Optiona
-00015470: 6c5b 666c 6f61 745d 5d3a 0a20 2020 2020  l[float]]:.     
-00015480: 2020 2022 2222 0a20 2020 2020 2020 2045     """.        E
-00015490: 7874 7261 6374 2074 7570 6c65 206f 6620  xtract tuple of 
-000154a0: 636f 7374 2c20 6375 7272 656e 6379 2c20  cost, currency, 
-000154b0: 7261 7465 2e0a 2020 2020 2020 2020 5265  rate..        Re
-000154c0: 7175 6972 6573 206f 7264 6572 5f68 6173  quires order_has
-000154d0: 5f66 6565 2074 6f20 7275 6e20 6669 7273  _fee to run firs
-000154e0: 7421 0a20 2020 2020 2020 203a 7061 7261  t!.        :para
-000154f0: 6d20 6665 653a 2063 6378 7420 4665 6520  m fee: ccxt Fee 
-00015500: 6469 6374 202d 206d 7573 7420 636f 6e74  dict - must cont
-00015510: 6169 6e20 636f 7374 202f 2063 7572 7265  ain cost / curre
-00015520: 6e63 7920 2f20 7261 7465 0a20 2020 2020  ncy / rate.     
-00015530: 2020 203a 7061 7261 6d20 7379 6d62 6f6c     :param symbol
-00015540: 3a20 5379 6d62 6f6c 206f 6620 7468 6520  : Symbol of the 
-00015550: 6f72 6465 720a 2020 2020 2020 2020 3a70  order.        :p
-00015560: 6172 616d 2063 6f73 743a 2054 6f74 616c  aram cost: Total
-00015570: 2063 6f73 7420 6f66 2074 6865 206f 7264   cost of the ord
-00015580: 6572 0a20 2020 2020 2020 203a 7061 7261  er.        :para
-00015590: 6d20 616d 6f75 6e74 3a20 416d 6f75 6e74  m amount: Amount
-000155a0: 206f 6620 7468 6520 6f72 6465 720a 2020   of the order.  
-000155b0: 2020 2020 2020 3a72 6574 7572 6e3a 2054        :return: T
-000155c0: 7570 6c65 2077 6974 6820 636f 7374 2c20  uple with cost, 
-000155d0: 6375 7272 656e 6379 2c20 7261 7465 206f  currency, rate o
-000155e0: 6620 7468 6520 6769 7665 6e20 6665 6520  f the given fee 
-000155f0: 6469 6374 0a20 2020 2020 2020 2022 2222  dict.        """
-00015600: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00015610: 2866 6c6f 6174 2866 6565 5b27 636f 7374  (float(fee['cost
-00015620: 275d 292c 0a20 2020 2020 2020 2020 2020  ']),.           
-00015630: 2020 2020 2066 6565 5b27 6375 7272 656e       fee['curren
-00015640: 6379 275d 2c0a 2020 2020 2020 2020 2020  cy'],.          
-00015650: 2020 2020 2020 7365 6c66 2e63 616c 6375        self.calcu
-00015660: 6c61 7465 5f66 6565 5f72 6174 6528 0a20  late_fee_rate(. 
-00015670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015680: 2020 2066 6565 2c0a 2020 2020 2020 2020     fee,.        
-00015690: 2020 2020 2020 2020 2020 2020 7379 6d62              symb
-000156a0: 6f6c 2c0a 2020 2020 2020 2020 2020 2020  ol,.            
-000156b0: 2020 2020 2020 2020 636f 7374 2c0a 2020          cost,.  
-000156c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000156d0: 2020 616d 6f75 6e74 0a20 2020 2020 2020    amount.       
-000156e0: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
-000156f0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
-00015700: 0a0a 2020 2020 2320 4869 7374 6f72 6963  ..    # Historic
-00015710: 2064 6174 610a 0a20 2020 2064 6566 2067   data..    def g
-00015720: 6574 5f68 6973 746f 7269 635f 6f68 6c63  et_historic_ohlc
-00015730: 7628 7365 6c66 2c20 7061 6972 3a20 7374  v(self, pair: st
-00015740: 722c 2074 696d 6566 7261 6d65 3a20 7374  r, timeframe: st
-00015750: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
-00015760: 2020 2020 2020 2020 2020 2020 2020 7369                si
-00015770: 6e63 655f 6d73 3a20 696e 742c 2063 616e  nce_ms: int, can
-00015780: 646c 655f 7479 7065 3a20 4361 6e64 6c65  dle_type: Candle
-00015790: 5479 7065 2c0a 2020 2020 2020 2020 2020  Type,.          
-000157a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000157b0: 2069 735f 6e65 775f 7061 6972 3a20 626f   is_new_pair: bo
-000157c0: 6f6c 203d 2046 616c 7365 2c0a 2020 2020  ol = False,.    
-000157d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000157e0: 2020 2020 2020 2075 6e74 696c 5f6d 733a         until_ms:
-000157f0: 204f 7074 696f 6e61 6c5b 696e 745d 203d   Optional[int] =
-00015800: 204e 6f6e 6529 202d 3e20 4c69 7374 3a0a   None) -> List:.
-00015810: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00015820: 2020 2020 4765 7420 6361 6e64 6c65 2068      Get candle h
-00015830: 6973 746f 7279 2075 7369 6e67 2061 7379  istory using asy
-00015840: 6e63 696f 2061 6e64 2072 6574 7572 6e73  ncio and returns
-00015850: 2074 6865 206c 6973 7420 6f66 2063 616e   the list of can
-00015860: 646c 6573 2e0a 2020 2020 2020 2020 4861  dles..        Ha
-00015870: 6e64 6c65 7320 616c 6c20 6173 796e 6320  ndles all async 
-00015880: 776f 726b 2066 6f72 2074 6869 732e 0a20  work for this.. 
-00015890: 2020 2020 2020 2041 7379 6e63 206f 7665         Async ove
-000158a0: 7220 6f6e 6520 7061 6972 2c20 6173 7375  r one pair, assu
-000158b0: 6d69 6e67 2077 6520 6765 7420 6073 656c  ming we get `sel
-000158c0: 662e 6f68 6c63 765f 6361 6e64 6c65 5f6c  f.ohlcv_candle_l
-000158d0: 696d 6974 2829 6020 6361 6e64 6c65 7320  imit()` candles 
-000158e0: 7065 7220 6361 6c6c 2e0a 2020 2020 2020  per call..      
-000158f0: 2020 3a70 6172 616d 2070 6169 723a 2050    :param pair: P
-00015900: 6169 7220 746f 2064 6f77 6e6c 6f61 640a  air to download.
-00015910: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
-00015920: 696d 6566 7261 6d65 3a20 5469 6d65 6672  imeframe: Timefr
-00015930: 616d 6520 746f 2067 6574 2064 6174 6120  ame to get data 
-00015940: 666f 720a 2020 2020 2020 2020 3a70 6172  for.        :par
-00015950: 616d 2073 696e 6365 5f6d 733a 2054 696d  am since_ms: Tim
-00015960: 6573 7461 6d70 2069 6e20 6d69 6c6c 6973  estamp in millis
-00015970: 6563 6f6e 6473 2074 6f20 6765 7420 6869  econds to get hi
-00015980: 7374 6f72 7920 6672 6f6d 0a20 2020 2020  story from.     
-00015990: 2020 203a 7061 7261 6d20 756e 7469 6c5f     :param until_
-000159a0: 6d73 3a20 5469 6d65 7374 616d 7020 696e  ms: Timestamp in
-000159b0: 206d 696c 6c69 7365 636f 6e64 7320 746f   milliseconds to
-000159c0: 2067 6574 2068 6973 746f 7279 2075 7020   get history up 
-000159d0: 746f 0a20 2020 2020 2020 203a 7061 7261  to.        :para
-000159e0: 6d20 6361 6e64 6c65 5f74 7970 653a 2027  m candle_type: '
-000159f0: 272c 206d 6172 6b2c 2069 6e64 6578 2c20  ', mark, index, 
-00015a00: 7072 656d 6975 6d49 6e64 6578 2c20 6f72  premiumIndex, or
-00015a10: 2066 756e 6469 6e67 5f72 6174 650a 2020   funding_rate.  
-00015a20: 2020 2020 2020 3a72 6574 7572 6e3a 204c        :return: L
-00015a30: 6973 7420 7769 7468 2063 616e 646c 6520  ist with candle 
-00015a40: 284f 484c 4356 2920 6461 7461 0a20 2020  (OHLCV) data.   
-00015a50: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00015a60: 2070 6169 722c 205f 2c20 5f2c 2064 6174   pair, _, _, dat
-00015a70: 612c 205f 203d 2073 656c 662e 6c6f 6f70  a, _ = self.loop
-00015a80: 2e72 756e 5f75 6e74 696c 5f63 6f6d 706c  .run_until_compl
-00015a90: 6574 6528 0a20 2020 2020 2020 2020 2020  ete(.           
-00015aa0: 2073 656c 662e 5f61 7379 6e63 5f67 6574   self._async_get
-00015ab0: 5f68 6973 746f 7269 635f 6f68 6c63 7628  _historic_ohlcv(
-00015ac0: 7061 6972 3d70 6169 722c 2074 696d 6566  pair=pair, timef
-00015ad0: 7261 6d65 3d74 696d 6566 7261 6d65 2c0a  rame=timeframe,.
-00015ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015b00: 2020 2020 2020 2020 2020 2073 696e 6365             since
-00015b10: 5f6d 733d 7369 6e63 655f 6d73 2c20 756e  _ms=since_ms, un
-00015b20: 7469 6c5f 6d73 3d75 6e74 696c 5f6d 732c  til_ms=until_ms,
-00015b30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015b50: 2020 2020 2020 2020 2020 2020 6973 5f6e              is_n
-00015b60: 6577 5f70 6169 723d 6973 5f6e 6577 5f70  ew_pair=is_new_p
-00015b70: 6169 722c 2063 616e 646c 655f 7479 7065  air, candle_type
-00015b80: 3d63 616e 646c 655f 7479 7065 2929 0a20  =candle_type)). 
-00015b90: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
-00015ba0: 666f 2866 2244 6f77 6e6c 6f61 6465 6420  fo(f"Downloaded 
-00015bb0: 6461 7461 2066 6f72 207b 7061 6972 7d20  data for {pair} 
-00015bc0: 7769 7468 206c 656e 6774 6820 7b6c 656e  with length {len
-00015bd0: 2864 6174 6129 7d2e 2229 0a20 2020 2020  (data)}.").     
-00015be0: 2020 2072 6574 7572 6e20 6461 7461 0a0a     return data..
-00015bf0: 2020 2020 6173 796e 6320 6465 6620 5f61      async def _a
-00015c00: 7379 6e63 5f67 6574 5f68 6973 746f 7269  sync_get_histori
-00015c10: 635f 6f68 6c63 7628 7365 6c66 2c20 7061  c_ohlcv(self, pa
-00015c20: 6972 3a20 7374 722c 2074 696d 6566 7261  ir: str, timefra
-00015c30: 6d65 3a20 7374 722c 0a20 2020 2020 2020  me: str,.       
-00015c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015c60: 2073 696e 6365 5f6d 733a 2069 6e74 2c20   since_ms: int, 
-00015c70: 6361 6e64 6c65 5f74 7970 653a 2043 616e  candle_type: Can
-00015c80: 646c 6554 7970 652c 0a20 2020 2020 2020  dleType,.       
-00015c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015cb0: 2069 735f 6e65 775f 7061 6972 3a20 626f   is_new_pair: bo
-00015cc0: 6f6c 203d 2046 616c 7365 2c20 7261 6973  ol = False, rais
-00015cd0: 655f 3a20 626f 6f6c 203d 2046 616c 7365  e_: bool = False
-00015ce0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00015cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015d00: 2020 2020 2020 2020 2020 756e 7469 6c5f            until_
-00015d10: 6d73 3a20 4f70 7469 6f6e 616c 5b69 6e74  ms: Optional[int
-00015d20: 5d20 3d20 4e6f 6e65 0a20 2020 2020 2020  ] = None.       
-00015d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015d50: 2029 202d 3e20 4f48 4c43 5652 6573 706f   ) -> OHLCVRespo
-00015d60: 6e73 653a 0a20 2020 2020 2020 2022 2222  nse:.        """
-00015d70: 0a20 2020 2020 2020 2044 6f77 6e6c 6f61  .        Downloa
-00015d80: 6420 6869 7374 6f72 6963 206f 686c 6376  d historic ohlcv
-00015d90: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00015da0: 6973 5f6e 6577 5f70 6169 723a 2075 7365  is_new_pair: use
-00015db0: 6420 6279 2062 696e 616e 6365 2073 7562  d by binance sub
-00015dc0: 636c 6173 7320 746f 2061 6c6c 6f77 2022  class to allow "
-00015dd0: 6661 7374 2220 6e65 7720 7061 6972 2064  fast" new pair d
-00015de0: 6f77 6e6c 6f61 6469 6e67 0a20 2020 2020  ownloading.     
-00015df0: 2020 203a 7061 7261 6d20 6361 6e64 6c65     :param candle
-00015e00: 5f74 7970 653a 2041 6e79 206f 6620 7468  _type: Any of th
-00015e10: 6520 656e 756d 2043 616e 646c 6554 7970  e enum CandleTyp
-00015e20: 6520 286d 7573 7420 6d61 7463 6820 7472  e (must match tr
-00015e30: 6164 696e 6720 6d6f 6465 2129 0a20 2020  ading mode!).   
-00015e40: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
-00015e50: 2020 6f6e 655f 6361 6c6c 203d 2074 696d    one_call = tim
-00015e60: 6566 7261 6d65 5f74 6f5f 6d73 6563 7328  eframe_to_msecs(
-00015e70: 7469 6d65 6672 616d 6529 202a 2073 656c  timeframe) * sel
-00015e80: 662e 6f68 6c63 765f 6361 6e64 6c65 5f6c  f.ohlcv_candle_l
-00015e90: 696d 6974 280a 2020 2020 2020 2020 2020  imit(.          
-00015ea0: 2020 7469 6d65 6672 616d 652c 2063 616e    timeframe, can
-00015eb0: 646c 655f 7479 7065 2c20 7369 6e63 655f  dle_type, since_
-00015ec0: 6d73 290a 2020 2020 2020 2020 6c6f 6767  ms).        logg
-00015ed0: 6572 2e64 6562 7567 280a 2020 2020 2020  er.debug(.      
-00015ee0: 2020 2020 2020 226f 6e65 5f63 616c 6c3a        "one_call:
-00015ef0: 2025 7320 6d73 6563 7320 2825 7329 222c   %s msecs (%s)",
-00015f00: 0a20 2020 2020 2020 2020 2020 206f 6e65  .            one
-00015f10: 5f63 616c 6c2c 0a20 2020 2020 2020 2020  _call,.         
-00015f20: 2020 2064 745f 6875 6d61 6e69 7a65 5f64     dt_humanize_d
-00015f30: 656c 7461 2864 745f 6e6f 7728 2920 2d20  elta(dt_now() - 
-00015f40: 7469 6d65 6465 6c74 6128 6d69 6c6c 6973  timedelta(millis
-00015f50: 6563 6f6e 6473 3d6f 6e65 5f63 616c 6c29  econds=one_call)
-00015f60: 290a 2020 2020 2020 2020 290a 2020 2020  ).        ).    
-00015f70: 2020 2020 696e 7075 745f 636f 726f 7574      input_corout
-00015f80: 696e 6573 203d 205b 7365 6c66 2e5f 6173  ines = [self._as
-00015f90: 796e 635f 6765 745f 6361 6e64 6c65 5f68  ync_get_candle_h
-00015fa0: 6973 746f 7279 280a 2020 2020 2020 2020  istory(.        
-00015fb0: 2020 2020 7061 6972 2c20 7469 6d65 6672      pair, timefr
-00015fc0: 616d 652c 2063 616e 646c 655f 7479 7065  ame, candle_type
-00015fd0: 2c20 7369 6e63 6529 2066 6f72 2073 696e  , since) for sin
-00015fe0: 6365 2069 6e0a 2020 2020 2020 2020 2020  ce in.          
-00015ff0: 2020 7261 6e67 6528 7369 6e63 655f 6d73    range(since_ms
-00016000: 2c20 756e 7469 6c5f 6d73 206f 7220 6474  , until_ms or dt
-00016010: 5f74 7328 292c 206f 6e65 5f63 616c 6c29  _ts(), one_call)
-00016020: 5d0a 0a20 2020 2020 2020 2064 6174 613a  ]..        data:
-00016030: 204c 6973 7420 3d20 5b5d 0a20 2020 2020   List = [].     
-00016040: 2020 2023 2043 6875 6e6b 2072 6571 7565     # Chunk reque
-00016050: 7374 7320 696e 746f 2062 6174 6368 6573  sts into batches
-00016060: 206f 6620 3130 3020 746f 2061 766f 6964   of 100 to avoid
-00016070: 206f 7665 7277 6865 6c6d 696e 6720 6363   overwhelming cc
-00016080: 7874 2054 6872 6f74 746c 696e 670a 2020  xt Throttling.  
-00016090: 2020 2020 2020 666f 7220 696e 7075 745f        for input_
-000160a0: 636f 726f 2069 6e20 6368 756e 6b73 2869  coro in chunks(i
-000160b0: 6e70 7574 5f63 6f72 6f75 7469 6e65 732c  nput_coroutines,
-000160c0: 2031 3030 293a 0a0a 2020 2020 2020 2020   100):..        
-000160d0: 2020 2020 7265 7375 6c74 7320 3d20 6177      results = aw
-000160e0: 6169 7420 6173 796e 6369 6f2e 6761 7468  ait asyncio.gath
-000160f0: 6572 282a 696e 7075 745f 636f 726f 2c20  er(*input_coro, 
-00016100: 7265 7475 726e 5f65 7863 6570 7469 6f6e  return_exception
-00016110: 733d 5472 7565 290a 2020 2020 2020 2020  s=True).        
-00016120: 2020 2020 666f 7220 7265 7320 696e 2072      for res in r
-00016130: 6573 756c 7473 3a0a 2020 2020 2020 2020  esults:.        
-00016140: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
-00016150: 7461 6e63 6528 7265 732c 2042 6173 6545  tance(res, BaseE
-00016160: 7863 6570 7469 6f6e 293a 0a20 2020 2020  xception):.     
-00016170: 2020 2020 2020 2020 2020 2020 2020 206c                 l
-00016180: 6f67 6765 722e 7761 726e 696e 6728 6622  ogger.warning(f"
-00016190: 4173 796e 6320 636f 6465 2072 6169 7365  Async code raise
-000161a0: 6420 616e 2065 7863 6570 7469 6f6e 3a20  d an exception: 
-000161b0: 7b72 6570 7228 7265 7329 7d22 290a 2020  {repr(res)}").  
-000161c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000161d0: 2020 6966 2072 6169 7365 5f3a 0a20 2020    if raise_:.   
-000161e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000161f0: 2020 2020 2072 6169 7365 0a20 2020 2020       raise.     
-00016200: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00016210: 6f6e 7469 6e75 650a 2020 2020 2020 2020  ontinue.        
-00016220: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00016230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016240: 2020 2320 4465 636f 6e73 7472 7563 7420    # Deconstruct 
-00016250: 7475 706c 6520 6966 2069 7427 7320 6e6f  tuple if it's no
-00016260: 7420 616e 2065 7863 6570 7469 6f6e 0a20  t an exception. 
-00016270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016280: 2020 2070 2c20 5f2c 2063 2c20 6e65 775f     p, _, c, new_
-00016290: 6461 7461 2c20 5f20 3d20 7265 730a 2020  data, _ = res.  
-000162a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000162b0: 2020 6966 2070 203d 3d20 7061 6972 2061    if p == pair a
-000162c0: 6e64 2063 203d 3d20 6361 6e64 6c65 5f74  nd c == candle_t
-000162d0: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
-000162e0: 2020 2020 2020 2020 2020 2020 2064 6174               dat
-000162f0: 612e 6578 7465 6e64 286e 6577 5f64 6174  a.extend(new_dat
-00016300: 6129 0a20 2020 2020 2020 2023 2053 6f72  a).        # Sor
-00016310: 7420 6461 7461 2061 6761 696e 2061 6674  t data again aft
-00016320: 6572 2065 7874 656e 6469 6e67 2074 6865  er extending the
-00016330: 2072 6573 756c 7420 2d20 6162 6f76 6520   result - above 
-00016340: 6361 6c6c 7320 7265 7475 726e 2069 6e20  calls return in 
-00016350: 2261 7379 6e63 206f 7264 6572 220a 2020  "async order".  
-00016360: 2020 2020 2020 6461 7461 203d 2073 6f72        data = sor
-00016370: 7465 6428 6461 7461 2c20 6b65 793d 6c61  ted(data, key=la
-00016380: 6d62 6461 2078 3a20 785b 305d 290a 2020  mbda x: x[0]).  
-00016390: 2020 2020 2020 7265 7475 726e 2070 6169        return pai
-000163a0: 722c 2074 696d 6566 7261 6d65 2c20 6361  r, timeframe, ca
-000163b0: 6e64 6c65 5f74 7970 652c 2064 6174 612c  ndle_type, data,
-000163c0: 2073 656c 662e 5f6f 686c 6376 5f70 6172   self._ohlcv_par
-000163d0: 7469 616c 5f63 616e 646c 650a 0a20 2020  tial_candle..   
-000163e0: 2064 6566 205f 6275 696c 645f 636f 726f   def _build_coro
-000163f0: 7574 696e 6528 0a20 2020 2020 2020 2020  utine(.         
-00016400: 2020 2073 656c 662c 2070 6169 723a 2073     self, pair: s
-00016410: 7472 2c20 7469 6d65 6672 616d 653a 2073  tr, timeframe: s
-00016420: 7472 2c20 6361 6e64 6c65 5f74 7970 653a  tr, candle_type:
-00016430: 2043 616e 646c 6554 7970 652c 0a20 2020   CandleType,.   
-00016440: 2020 2020 2020 2020 2073 696e 6365 5f6d           since_m
-00016450: 733a 204f 7074 696f 6e61 6c5b 696e 745d  s: Optional[int]
-00016460: 2c20 6361 6368 653a 2062 6f6f 6c29 202d  , cache: bool) -
-00016470: 3e20 436f 726f 7574 696e 655b 416e 792c  > Coroutine[Any,
-00016480: 2041 6e79 2c20 4f48 4c43 5652 6573 706f   Any, OHLCVRespo
-00016490: 6e73 655d 3a0a 2020 2020 2020 2020 6e6f  nse]:.        no
-000164a0: 745f 616c 6c5f 6461 7461 203d 2063 6163  t_all_data = cac
-000164b0: 6865 2061 6e64 2073 656c 662e 7265 7175  he and self.requ
-000164c0: 6972 6564 5f63 616e 646c 655f 6361 6c6c  ired_candle_call
-000164d0: 5f63 6f75 6e74 203e 2031 0a20 2020 2020  _count > 1.     
-000164e0: 2020 2069 6620 6361 6368 6520 616e 6420     if cache and 
-000164f0: 2870 6169 722c 2074 696d 6566 7261 6d65  (pair, timeframe
-00016500: 2c20 6361 6e64 6c65 5f74 7970 6529 2069  , candle_type) i
-00016510: 6e20 7365 6c66 2e5f 6b6c 696e 6573 3a0a  n self._klines:.
-00016520: 2020 2020 2020 2020 2020 2020 6361 6e64              cand
-00016530: 6c65 5f6c 696d 6974 203d 2073 656c 662e  le_limit = self.
-00016540: 6f68 6c63 765f 6361 6e64 6c65 5f6c 696d  ohlcv_candle_lim
-00016550: 6974 2874 696d 6566 7261 6d65 2c20 6361  it(timeframe, ca
-00016560: 6e64 6c65 5f74 7970 6529 0a20 2020 2020  ndle_type).     
-00016570: 2020 2020 2020 206d 696e 5f64 6174 6520         min_date 
-00016580: 3d20 6461 7465 5f6d 696e 7573 5f63 616e  = date_minus_can
-00016590: 646c 6573 2874 696d 6566 7261 6d65 2c20  dles(timeframe, 
-000165a0: 6361 6e64 6c65 5f6c 696d 6974 202d 2035  candle_limit - 5
-000165b0: 292e 7469 6d65 7374 616d 7028 290a 2020  ).timestamp().  
-000165c0: 2020 2020 2020 2020 2020 2320 4368 6563            # Chec
-000165d0: 6b20 6966 2031 2063 616c 6c20 6361 6e20  k if 1 call can 
-000165e0: 6765 7420 7573 2075 7064 6174 6564 2063  get us updated c
-000165f0: 616e 646c 6573 2077 6974 686f 7574 2068  andles without h
-00016600: 6f6c 6520 696e 2074 6865 2064 6174 612e  ole in the data.
-00016610: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00016620: 6d69 6e5f 6461 7465 203c 2073 656c 662e  min_date < self.
-00016630: 5f70 6169 7273 5f6c 6173 745f 7265 6672  _pairs_last_refr
-00016640: 6573 685f 7469 6d65 2e67 6574 2828 7061  esh_time.get((pa
-00016650: 6972 2c20 7469 6d65 6672 616d 652c 2063  ir, timeframe, c
-00016660: 616e 646c 655f 7479 7065 292c 2030 293a  andle_type), 0):
-00016670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00016680: 2023 2043 6163 6865 2063 616e 2062 6520   # Cache can be 
-00016690: 7573 6564 202d 2064 6f20 6f6e 652d 6f66  used - do one-of
-000166a0: 6620 6361 6c6c 2e0a 2020 2020 2020 2020  f call..        
-000166b0: 2020 2020 2020 2020 6e6f 745f 616c 6c5f          not_all_
-000166c0: 6461 7461 203d 2046 616c 7365 0a20 2020  data = False.   
-000166d0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-000166e0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-000166f0: 2054 696d 6520 6a75 6d70 2064 6574 6563   Time jump detec
-00016700: 7465 642c 2065 7669 6374 2063 6163 6865  ted, evict cache
-00016710: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00016720: 206c 6f67 6765 722e 696e 666f 280a 2020   logger.info(.  
-00016730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016740: 2020 6622 5469 6d65 206a 756d 7020 6465    f"Time jump de
-00016750: 7465 6374 6564 2e20 4576 6963 7469 6e67  tected. Evicting
-00016760: 2063 6163 6865 2066 6f72 207b 7061 6972   cache for {pair
-00016770: 7d2c 207b 7469 6d65 6672 616d 657d 2c20  }, {timeframe}, 
-00016780: 7b63 616e 646c 655f 7479 7065 7d22 290a  {candle_type}").
-00016790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000167a0: 6465 6c20 7365 6c66 2e5f 6b6c 696e 6573  del self._klines
-000167b0: 5b28 7061 6972 2c20 7469 6d65 6672 616d  [(pair, timefram
-000167c0: 652c 2063 616e 646c 655f 7479 7065 295d  e, candle_type)]
-000167d0: 0a0a 2020 2020 2020 2020 6966 2028 6e6f  ..        if (no
-000167e0: 7420 7369 6e63 655f 6d73 2061 6e64 2028  t since_ms and (
-000167f0: 7365 6c66 2e5f 6674 5f68 6173 5b22 6f68  self._ft_has["oh
-00016800: 6c63 765f 7265 7175 6972 655f 7369 6e63  lcv_require_sinc
-00016810: 6522 5d20 6f72 206e 6f74 5f61 6c6c 5f64  e"] or not_all_d
-00016820: 6174 6129 293a 0a20 2020 2020 2020 2020  ata)):.         
-00016830: 2020 2023 204d 756c 7469 706c 6520 6361     # Multiple ca
-00016840: 6c6c 7320 666f 7220 6f6e 6520 7061 6972  lls for one pair
-00016850: 202d 2074 6f20 6765 7420 6d6f 7265 2068   - to get more h
-00016860: 6973 746f 7279 0a20 2020 2020 2020 2020  istory.         
-00016870: 2020 206f 6e65 5f63 616c 6c20 3d20 7469     one_call = ti
-00016880: 6d65 6672 616d 655f 746f 5f6d 7365 6373  meframe_to_msecs
-00016890: 2874 696d 6566 7261 6d65 2920 2a20 7365  (timeframe) * se
-000168a0: 6c66 2e6f 686c 6376 5f63 616e 646c 655f  lf.ohlcv_candle_
-000168b0: 6c69 6d69 7428 0a20 2020 2020 2020 2020  limit(.         
-000168c0: 2020 2020 2020 2074 696d 6566 7261 6d65         timeframe
-000168d0: 2c20 6361 6e64 6c65 5f74 7970 652c 2073  , candle_type, s
-000168e0: 696e 6365 5f6d 7329 0a20 2020 2020 2020  ince_ms).       
-000168f0: 2020 2020 206d 6f76 655f 746f 203d 206f       move_to = o
-00016900: 6e65 5f63 616c 6c20 2a20 7365 6c66 2e72  ne_call * self.r
-00016910: 6571 7569 7265 645f 6361 6e64 6c65 5f63  equired_candle_c
-00016920: 616c 6c5f 636f 756e 740a 2020 2020 2020  all_count.      
-00016930: 2020 2020 2020 6e6f 7720 3d20 7469 6d65        now = time
-00016940: 6672 616d 655f 746f 5f6e 6578 745f 6461  frame_to_next_da
-00016950: 7465 2874 696d 6566 7261 6d65 290a 2020  te(timeframe).  
-00016960: 2020 2020 2020 2020 2020 7369 6e63 655f            since_
-00016970: 6d73 203d 2064 745f 7473 286e 6f77 202d  ms = dt_ts(now -
-00016980: 2074 696d 6564 656c 7461 2873 6563 6f6e   timedelta(secon
-00016990: 6473 3d6d 6f76 655f 746f 202f 2f20 3130  ds=move_to // 10
-000169a0: 3030 2929 0a0a 2020 2020 2020 2020 6966  00))..        if
-000169b0: 2073 696e 6365 5f6d 733a 0a20 2020 2020   since_ms:.     
-000169c0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-000169d0: 6c66 2e5f 6173 796e 635f 6765 745f 6869  lf._async_get_hi
-000169e0: 7374 6f72 6963 5f6f 686c 6376 280a 2020  storic_ohlcv(.  
-000169f0: 2020 2020 2020 2020 2020 2020 2020 7061                pa
-00016a00: 6972 2c20 7469 6d65 6672 616d 652c 2073  ir, timeframe, s
-00016a10: 696e 6365 5f6d 733d 7369 6e63 655f 6d73  ince_ms=since_ms
-00016a20: 2c20 7261 6973 655f 3d54 7275 652c 2063  , raise_=True, c
-00016a30: 616e 646c 655f 7479 7065 3d63 616e 646c  andle_type=candl
-00016a40: 655f 7479 7065 290a 2020 2020 2020 2020  e_type).        
-00016a50: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00016a60: 2020 2320 4f6e 6520 6361 6c6c 202e 2e2e    # One call ...
-00016a70: 2022 7265 6775 6c61 7222 2072 6566 7265   "regular" refre
-00016a80: 7368 0a20 2020 2020 2020 2020 2020 2072  sh.            r
-00016a90: 6574 7572 6e20 7365 6c66 2e5f 6173 796e  eturn self._asyn
-00016aa0: 635f 6765 745f 6361 6e64 6c65 5f68 6973  c_get_candle_his
-00016ab0: 746f 7279 280a 2020 2020 2020 2020 2020  tory(.          
-00016ac0: 2020 2020 2020 7061 6972 2c20 7469 6d65        pair, time
-00016ad0: 6672 616d 652c 2073 696e 6365 5f6d 733d  frame, since_ms=
-00016ae0: 7369 6e63 655f 6d73 2c20 6361 6e64 6c65  since_ms, candle
-00016af0: 5f74 7970 653d 6361 6e64 6c65 5f74 7970  _type=candle_typ
-00016b00: 6529 0a0a 2020 2020 6465 6620 5f62 7569  e)..    def _bui
-00016b10: 6c64 5f6f 686c 6376 5f64 6c5f 6a6f 6273  ld_ohlcv_dl_jobs
-00016b20: 280a 2020 2020 2020 2020 2020 2020 7365  (.            se
-00016b30: 6c66 2c20 7061 6972 5f6c 6973 743a 204c  lf, pair_list: L
-00016b40: 6973 7450 6169 7273 5769 7468 5469 6d65  istPairsWithTime
-00016b50: 6672 616d 6573 2c20 7369 6e63 655f 6d73  frames, since_ms
-00016b60: 3a20 4f70 7469 6f6e 616c 5b69 6e74 5d2c  : Optional[int],
-00016b70: 0a20 2020 2020 2020 2020 2020 2063 6163  .            cac
-00016b80: 6865 3a20 626f 6f6c 2920 2d3e 2054 7570  he: bool) -> Tup
-00016b90: 6c65 5b4c 6973 745b 436f 726f 7574 696e  le[List[Coroutin
-00016ba0: 655d 2c20 4c69 7374 5b54 7570 6c65 5b73  e], List[Tuple[s
-00016bb0: 7472 2c20 7374 722c 2043 616e 646c 6554  tr, str, CandleT
-00016bc0: 7970 655d 5d5d 3a0a 2020 2020 2020 2020  ype]]]:.        
-00016bd0: 2222 220a 2020 2020 2020 2020 4275 696c  """.        Buil
-00016be0: 6420 436f 726f 7574 696e 6573 2074 6f20  d Coroutines to 
-00016bf0: 6578 6563 7574 6520 6173 2070 6172 7420  execute as part 
-00016c00: 6f66 2072 6566 7265 7368 5f6c 6174 6573  of refresh_lates
-00016c10: 745f 6f68 6c63 760a 2020 2020 2020 2020  t_ohlcv.        
-00016c20: 2222 220a 2020 2020 2020 2020 696e 7075  """.        inpu
-00016c30: 745f 636f 726f 7574 696e 6573 3a20 4c69  t_coroutines: Li
-00016c40: 7374 5b43 6f72 6f75 7469 6e65 5b41 6e79  st[Coroutine[Any
-00016c50: 2c20 416e 792c 204f 484c 4356 5265 7370  , Any, OHLCVResp
-00016c60: 6f6e 7365 5d5d 203d 205b 5d0a 2020 2020  onse]] = [].    
-00016c70: 2020 2020 6361 6368 6564 5f70 6169 7273      cached_pairs
-00016c80: 203d 205b 5d0a 2020 2020 2020 2020 666f   = [].        fo
-00016c90: 7220 7061 6972 2c20 7469 6d65 6672 616d  r pair, timefram
-00016ca0: 652c 2063 616e 646c 655f 7479 7065 2069  e, candle_type i
-00016cb0: 6e20 7365 7428 7061 6972 5f6c 6973 7429  n set(pair_list)
-00016cc0: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-00016cd0: 2028 7469 6d65 6672 616d 6520 6e6f 7420   (timeframe not 
-00016ce0: 696e 2073 656c 662e 7469 6d65 6672 616d  in self.timefram
-00016cf0: 6573 0a20 2020 2020 2020 2020 2020 2020  es.             
-00016d00: 2020 2020 2020 2061 6e64 2063 616e 646c         and candl
-00016d10: 655f 7479 7065 2069 6e20 2843 616e 646c  e_type in (Candl
-00016d20: 6554 7970 652e 5350 4f54 2c20 4361 6e64  eType.SPOT, Cand
-00016d30: 6c65 5479 7065 2e46 5554 5552 4553 2929  leType.FUTURES))
-00016d40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00016d50: 2020 6c6f 6767 6572 2e77 6172 6e69 6e67    logger.warning
-00016d60: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00016d70: 2020 2020 2020 6622 4361 6e6e 6f74 2064        f"Cannot d
-00016d80: 6f77 6e6c 6f61 6420 287b 7061 6972 7d2c  ownload ({pair},
-00016d90: 207b 7469 6d65 6672 616d 657d 2920 636f   {timeframe}) co
-00016da0: 6d62 696e 6174 696f 6e20 6173 2074 6869  mbination as thi
-00016db0: 7320 7469 6d65 6672 616d 6520 6973 2022  s timeframe is "
-00016dc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00016dd0: 2020 2020 2066 226e 6f74 2061 7661 696c       f"not avail
-00016de0: 6162 6c65 206f 6e20 7b73 656c 662e 6e61  able on {self.na
-00016df0: 6d65 7d2e 2041 7661 696c 6162 6c65 2074  me}. Available t
-00016e00: 696d 6566 7261 6d65 7320 6172 6520 220a  imeframes are ".
-00016e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016e20: 2020 2020 6622 7b27 2c20 272e 6a6f 696e      f"{', '.join
-00016e30: 2873 656c 662e 7469 6d65 6672 616d 6573  (self.timeframes
-00016e40: 297d 2e22 290a 2020 2020 2020 2020 2020  )}.").          
-00016e50: 2020 2020 2020 636f 6e74 696e 7565 0a0a        continue..
-00016e60: 2020 2020 2020 2020 2020 2020 6966 2028              if (
-00016e70: 2870 6169 722c 2074 696d 6566 7261 6d65  (pair, timeframe
-00016e80: 2c20 6361 6e64 6c65 5f74 7970 6529 206e  , candle_type) n
-00016e90: 6f74 2069 6e20 7365 6c66 2e5f 6b6c 696e  ot in self._klin
-00016ea0: 6573 206f 7220 6e6f 7420 6361 6368 650a  es or not cache.
-00016eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ec0: 2020 2020 6f72 2073 656c 662e 5f6e 6f77      or self._now
-00016ed0: 5f69 735f 7469 6d65 5f74 6f5f 7265 6672  _is_time_to_refr
-00016ee0: 6573 6828 7061 6972 2c20 7469 6d65 6672  esh(pair, timefr
-00016ef0: 616d 652c 2063 616e 646c 655f 7479 7065  ame, candle_type
-00016f00: 2929 3a0a 0a20 2020 2020 2020 2020 2020  )):..           
-00016f10: 2020 2020 2069 6e70 7574 5f63 6f72 6f75       input_corou
-00016f20: 7469 6e65 732e 6170 7065 6e64 280a 2020  tines.append(.  
-00016f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016f40: 2020 7365 6c66 2e5f 6275 696c 645f 636f    self._build_co
-00016f50: 726f 7574 696e 6528 7061 6972 2c20 7469  routine(pair, ti
-00016f60: 6d65 6672 616d 652c 2063 616e 646c 655f  meframe, candle_
-00016f70: 7479 7065 2c20 7369 6e63 655f 6d73 2c20  type, since_ms, 
-00016f80: 6361 6368 6529 290a 0a20 2020 2020 2020  cache))..       
-00016f90: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00016fa0: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
-00016fb0: 722e 6465 6275 6728 0a20 2020 2020 2020  r.debug(.       
-00016fc0: 2020 2020 2020 2020 2020 2020 2066 2255               f"U
-00016fd0: 7369 6e67 2063 6163 6865 6420 6361 6e64  sing cached cand
-00016fe0: 6c65 2028 4f48 4c43 5629 2064 6174 6120  le (OHLCV) data 
-00016ff0: 666f 7220 7b70 6169 727d 2c20 7b74 696d  for {pair}, {tim
-00017000: 6566 7261 6d65 7d2c 207b 6361 6e64 6c65  eframe}, {candle
-00017010: 5f74 7970 657d 202e 2e2e 220a 2020 2020  _type} ...".    
-00017020: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-00017030: 2020 2020 2020 2020 2020 2020 2020 6361                ca
-00017040: 6368 6564 5f70 6169 7273 2e61 7070 656e  ched_pairs.appen
-00017050: 6428 2870 6169 722c 2074 696d 6566 7261  d((pair, timefra
-00017060: 6d65 2c20 6361 6e64 6c65 5f74 7970 6529  me, candle_type)
-00017070: 290a 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-00017080: 6e20 696e 7075 745f 636f 726f 7574 696e  n input_coroutin
-00017090: 6573 2c20 6361 6368 6564 5f70 6169 7273  es, cached_pairs
-000170a0: 0a0a 2020 2020 6465 6620 5f70 726f 6365  ..    def _proce
-000170b0: 7373 5f6f 686c 6376 5f64 6628 7365 6c66  ss_ohlcv_df(self
-000170c0: 2c20 7061 6972 3a20 7374 722c 2074 696d  , pair: str, tim
-000170d0: 6566 7261 6d65 3a20 7374 722c 2063 5f74  eframe: str, c_t
-000170e0: 7970 653a 2043 616e 646c 6554 7970 652c  ype: CandleType,
-000170f0: 2074 6963 6b73 3a20 4c69 7374 5b4c 6973   ticks: List[Lis
-00017100: 745d 2c0a 2020 2020 2020 2020 2020 2020  t],.            
-00017110: 2020 2020 2020 2020 2020 2020 2020 6361                ca
-00017120: 6368 653a 2062 6f6f 6c2c 2064 726f 705f  che: bool, drop_
-00017130: 696e 636f 6d70 6c65 7465 3a20 626f 6f6c  incomplete: bool
-00017140: 2920 2d3e 2044 6174 6146 7261 6d65 3a0a  ) -> DataFrame:.
-00017150: 2020 2020 2020 2020 2320 6b65 6570 696e          # keepin
-00017160: 6720 6c61 7374 2063 616e 646c 6520 7469  g last candle ti
-00017170: 6d65 2061 7320 6c61 7374 2072 6566 7265  me as last refre
-00017180: 7368 6564 2074 696d 6520 6f66 2074 6865  shed time of the
-00017190: 2070 6169 720a 2020 2020 2020 2020 6966   pair.        if
-000171a0: 2074 6963 6b73 2061 6e64 2063 6163 6865   ticks and cache
-000171b0: 3a0a 2020 2020 2020 2020 2020 2020 6964  :.            id
-000171c0: 7820 3d20 2d32 2069 6620 6472 6f70 5f69  x = -2 if drop_i
-000171d0: 6e63 6f6d 706c 6574 6520 616e 6420 6c65  ncomplete and le
-000171e0: 6e28 7469 636b 7329 203e 2031 2065 6c73  n(ticks) > 1 els
-000171f0: 6520 2d31 0a20 2020 2020 2020 2020 2020  e -1.           
-00017200: 2073 656c 662e 5f70 6169 7273 5f6c 6173   self._pairs_las
-00017210: 745f 7265 6672 6573 685f 7469 6d65 5b28  t_refresh_time[(
-00017220: 7061 6972 2c20 7469 6d65 6672 616d 652c  pair, timeframe,
-00017230: 2063 5f74 7970 6529 5d20 3d20 7469 636b   c_type)] = tick
-00017240: 735b 6964 785d 5b30 5d20 2f2f 2031 3030  s[idx][0] // 100
-00017250: 300a 2020 2020 2020 2020 2320 6b65 6570  0.        # keep
-00017260: 696e 6720 7061 7273 6564 2064 6174 6166  ing parsed dataf
-00017270: 7261 6d65 2069 6e20 6361 6368 650a 2020  rame in cache.  
-00017280: 2020 2020 2020 6f68 6c63 765f 6466 203d        ohlcv_df =
-00017290: 206f 686c 6376 5f74 6f5f 6461 7461 6672   ohlcv_to_datafr
-000172a0: 616d 6528 7469 636b 732c 2074 696d 6566  ame(ticks, timef
-000172b0: 7261 6d65 2c20 7061 6972 3d70 6169 722c  rame, pair=pair,
-000172c0: 2066 696c 6c5f 6d69 7373 696e 673d 5472   fill_missing=Tr
-000172d0: 7565 2c0a 2020 2020 2020 2020 2020 2020  ue,.            
-000172e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000172f0: 2020 2020 2020 2020 2020 6472 6f70 5f69            drop_i
-00017300: 6e63 6f6d 706c 6574 653d 6472 6f70 5f69  ncomplete=drop_i
-00017310: 6e63 6f6d 706c 6574 6529 0a20 2020 2020  ncomplete).     
-00017320: 2020 2069 6620 6361 6368 653a 0a20 2020     if cache:.   
-00017330: 2020 2020 2020 2020 2069 6620 2870 6169           if (pai
-00017340: 722c 2074 696d 6566 7261 6d65 2c20 635f  r, timeframe, c_
-00017350: 7479 7065 2920 696e 2073 656c 662e 5f6b  type) in self._k
-00017360: 6c69 6e65 733a 0a20 2020 2020 2020 2020  lines:.         
-00017370: 2020 2020 2020 206f 6c64 203d 2073 656c         old = sel
-00017380: 662e 5f6b 6c69 6e65 735b 2870 6169 722c  f._klines[(pair,
-00017390: 2074 696d 6566 7261 6d65 2c20 635f 7479   timeframe, c_ty
-000173a0: 7065 295d 0a20 2020 2020 2020 2020 2020  pe)].           
-000173b0: 2020 2020 2023 2052 6561 7373 6967 6e20       # Reassign 
-000173c0: 736f 2077 6520 7265 7475 726e 2074 6865  so we return the
-000173d0: 2075 7064 6174 6564 2c20 636f 6d62 696e   updated, combin
-000173e0: 6564 2064 660a 2020 2020 2020 2020 2020  ed df.          
-000173f0: 2020 2020 2020 6f68 6c63 765f 6466 203d        ohlcv_df =
-00017400: 2063 6c65 616e 5f6f 686c 6376 5f64 6174   clean_ohlcv_dat
-00017410: 6166 7261 6d65 2863 6f6e 6361 7428 5b6f  aframe(concat([o
-00017420: 6c64 2c20 6f68 6c63 765f 6466 5d2c 2061  ld, ohlcv_df], a
-00017430: 7869 733d 3029 2c20 7469 6d65 6672 616d  xis=0), timefram
-00017440: 652c 2070 6169 722c 0a20 2020 2020 2020  e, pair,.       
-00017450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017470: 2020 2020 2020 2020 2020 6669 6c6c 5f6d            fill_m
-00017480: 6973 7369 6e67 3d54 7275 652c 2064 726f  issing=True, dro
-00017490: 705f 696e 636f 6d70 6c65 7465 3d46 616c  p_incomplete=Fal
-000174a0: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
-000174b0: 2020 2020 6361 6e64 6c65 5f6c 696d 6974      candle_limit
-000174c0: 203d 2073 656c 662e 6f68 6c63 765f 6361   = self.ohlcv_ca
-000174d0: 6e64 6c65 5f6c 696d 6974 2874 696d 6566  ndle_limit(timef
-000174e0: 7261 6d65 2c20 7365 6c66 2e5f 636f 6e66  rame, self._conf
-000174f0: 6967 5b27 6361 6e64 6c65 5f74 7970 655f  ig['candle_type_
-00017500: 6465 6627 5d29 0a20 2020 2020 2020 2020  def']).         
-00017510: 2020 2020 2020 2023 2041 6765 206f 7574         # Age out
-00017520: 206f 6c64 2063 616e 646c 6573 0a20 2020   old candles.   
-00017530: 2020 2020 2020 2020 2020 2020 206f 686c               ohl
-00017540: 6376 5f64 6620 3d20 6f68 6c63 765f 6466  cv_df = ohlcv_df
-00017550: 2e74 6169 6c28 6361 6e64 6c65 5f6c 696d  .tail(candle_lim
-00017560: 6974 202b 2073 656c 662e 5f73 7461 7274  it + self._start
-00017570: 7570 5f63 616e 646c 655f 636f 756e 7429  up_candle_count)
-00017580: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017590: 206f 686c 6376 5f64 6620 3d20 6f68 6c63   ohlcv_df = ohlc
-000175a0: 765f 6466 2e72 6573 6574 5f69 6e64 6578  v_df.reset_index
-000175b0: 2864 726f 703d 5472 7565 290a 2020 2020  (drop=True).    
-000175c0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000175d0: 2e5f 6b6c 696e 6573 5b28 7061 6972 2c20  ._klines[(pair, 
-000175e0: 7469 6d65 6672 616d 652c 2063 5f74 7970  timeframe, c_typ
-000175f0: 6529 5d20 3d20 6f68 6c63 765f 6466 0a20  e)] = ohlcv_df. 
-00017600: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-00017610: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017620: 2073 656c 662e 5f6b 6c69 6e65 735b 2870   self._klines[(p
-00017630: 6169 722c 2074 696d 6566 7261 6d65 2c20  air, timeframe, 
-00017640: 635f 7479 7065 295d 203d 206f 686c 6376  c_type)] = ohlcv
-00017650: 5f64 660a 2020 2020 2020 2020 7265 7475  _df.        retu
-00017660: 726e 206f 686c 6376 5f64 660a 0a20 2020  rn ohlcv_df..   
-00017670: 2064 6566 2072 6566 7265 7368 5f6c 6174   def refresh_lat
-00017680: 6573 745f 6f68 6c63 7628 7365 6c66 2c20  est_ohlcv(self, 
-00017690: 7061 6972 5f6c 6973 743a 204c 6973 7450  pair_list: ListP
-000176a0: 6169 7273 5769 7468 5469 6d65 6672 616d  airsWithTimefram
-000176b0: 6573 2c20 2a2c 0a20 2020 2020 2020 2020  es, *,.         
-000176c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000176d0: 2020 2020 7369 6e63 655f 6d73 3a20 4f70      since_ms: Op
-000176e0: 7469 6f6e 616c 5b69 6e74 5d20 3d20 4e6f  tional[int] = No
-000176f0: 6e65 2c20 6361 6368 653a 2062 6f6f 6c20  ne, cache: bool 
-00017700: 3d20 5472 7565 2c0a 2020 2020 2020 2020  = True,.        
-00017710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017720: 2020 2020 2064 726f 705f 696e 636f 6d70       drop_incomp
-00017730: 6c65 7465 3a20 4f70 7469 6f6e 616c 5b62  lete: Optional[b
-00017740: 6f6f 6c5d 203d 204e 6f6e 650a 2020 2020  ool] = None.    
-00017750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017760: 2020 2020 2020 2020 2029 202d 3e20 4469           ) -> Di
-00017770: 6374 5b50 6169 7257 6974 6854 696d 6566  ct[PairWithTimef
-00017780: 7261 6d65 2c20 4461 7461 4672 616d 655d  rame, DataFrame]
-00017790: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-000177a0: 2020 2020 2020 5265 6672 6573 6820 696e        Refresh in
-000177b0: 2d6d 656d 6f72 7920 4f48 4c43 5620 6173  -memory OHLCV as
-000177c0: 796e 6368 726f 6e6f 7573 6c79 2061 6e64  ynchronously and
-000177d0: 2073 6574 2060 5f6b 6c69 6e65 7360 2077   set `_klines` w
-000177e0: 6974 6820 7468 6520 7265 7375 6c74 0a20  ith the result. 
-000177f0: 2020 2020 2020 204c 6f6f 7073 2061 7379         Loops asy
-00017800: 6e63 6872 6f6e 6f75 736c 7920 6f76 6572  nchronously over
-00017810: 2070 6169 725f 6c69 7374 2061 6e64 2064   pair_list and d
-00017820: 6f77 6e6c 6f61 6473 2061 6c6c 2070 6169  ownloads all pai
-00017830: 7273 2061 7379 6e63 2028 7365 6d69 2d70  rs async (semi-p
-00017840: 6172 616c 6c65 6c29 2e0a 2020 2020 2020  arallel)..      
-00017850: 2020 4f6e 6c79 2075 7365 6420 696e 2074    Only used in t
-00017860: 6865 2064 6174 6170 726f 7669 6465 722e  he dataprovider.
-00017870: 7265 6672 6573 6828 2920 6d65 7468 6f64  refresh() method
-00017880: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-00017890: 2070 6169 725f 6c69 7374 3a20 4c69 7374   pair_list: List
-000178a0: 206f 6620 3220 656c 656d 656e 7420 7475   of 2 element tu
-000178b0: 706c 6573 2063 6f6e 7461 696e 696e 6720  ples containing 
-000178c0: 7061 6972 2c20 696e 7465 7276 616c 2074  pair, interval t
-000178d0: 6f20 7265 6672 6573 680a 2020 2020 2020  o refresh.      
-000178e0: 2020 3a70 6172 616d 2073 696e 6365 5f6d    :param since_m
-000178f0: 733a 2074 696d 6520 7369 6e63 6520 7768  s: time since wh
-00017900: 656e 2074 6f20 646f 776e 6c6f 6164 2c20  en to download, 
-00017910: 696e 206d 696c 6c69 7365 636f 6e64 730a  in milliseconds.
-00017920: 2020 2020 2020 2020 3a70 6172 616d 2063          :param c
-00017930: 6163 6865 3a20 4173 7369 676e 2072 6573  ache: Assign res
-00017940: 756c 7420 746f 205f 6b6c 696e 6573 2e20  ult to _klines. 
-00017950: 5573 6566 756c 2066 6f72 206f 6e65 2d6f  Useful for one-o
-00017960: 6666 2064 6f77 6e6c 6f61 6473 206c 696b  ff downloads lik
-00017970: 6520 666f 7220 7061 6972 6c69 7374 730a  e for pairlists.
-00017980: 2020 2020 2020 2020 3a70 6172 616d 2064          :param d
-00017990: 726f 705f 696e 636f 6d70 6c65 7465 3a20  rop_incomplete: 
-000179a0: 436f 6e74 726f 6c20 6361 6e64 6c65 2064  Control candle d
-000179b0: 726f 7070 696e 672e 0a20 2020 2020 2020  ropping..       
-000179c0: 2020 2020 2053 7065 6369 6679 696e 6720       Specifying 
-000179d0: 4e6f 6e65 2064 6566 6175 6c74 7320 746f  None defaults to
-000179e0: 205f 6f68 6c63 765f 7061 7274 6961 6c5f   _ohlcv_partial_
-000179f0: 6361 6e64 6c65 0a20 2020 2020 2020 203a  candle.        :
-00017a00: 7265 7475 726e 3a20 4469 6374 206f 6620  return: Dict of 
-00017a10: 5b7b 2870 6169 722c 2074 696d 6566 7261  [{(pair, timefra
-00017a20: 6d65 293a 2044 6174 6166 7261 6d65 7d5d  me): Dataframe}]
-00017a30: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00017a40: 2020 2020 206c 6f67 6765 722e 6465 6275       logger.debu
-00017a50: 6728 2252 6566 7265 7368 696e 6720 6361  g("Refreshing ca
-00017a60: 6e64 6c65 2028 4f48 4c43 5629 2064 6174  ndle (OHLCV) dat
-00017a70: 6120 666f 7220 2564 2070 6169 7273 222c  a for %d pairs",
-00017a80: 206c 656e 2870 6169 725f 6c69 7374 2929   len(pair_list))
-00017a90: 0a0a 2020 2020 2020 2020 2320 4761 7468  ..        # Gath
-00017aa0: 6572 2063 6f72 6f75 7469 6e65 7320 746f  er coroutines to
-00017ab0: 2072 756e 0a20 2020 2020 2020 2069 6e70   run.        inp
-00017ac0: 7574 5f63 6f72 6f75 7469 6e65 732c 2063  ut_coroutines, c
-00017ad0: 6163 6865 645f 7061 6972 7320 3d20 7365  ached_pairs = se
-00017ae0: 6c66 2e5f 6275 696c 645f 6f68 6c63 765f  lf._build_ohlcv_
-00017af0: 646c 5f6a 6f62 7328 7061 6972 5f6c 6973  dl_jobs(pair_lis
-00017b00: 742c 2073 696e 6365 5f6d 732c 2063 6163  t, since_ms, cac
-00017b10: 6865 290a 0a20 2020 2020 2020 2072 6573  he)..        res
-00017b20: 756c 7473 5f64 6620 3d20 7b7d 0a20 2020  ults_df = {}.   
-00017b30: 2020 2020 2023 2043 6875 6e6b 2072 6571       # Chunk req
-00017b40: 7565 7374 7320 696e 746f 2062 6174 6368  uests into batch
-00017b50: 6573 206f 6620 3130 3020 746f 2061 766f  es of 100 to avo
-00017b60: 6964 206f 7665 7277 6865 6c6d 696e 6720  id overwhelming 
-00017b70: 6363 7874 2054 6872 6f74 746c 696e 670a  ccxt Throttling.
-00017b80: 2020 2020 2020 2020 666f 7220 696e 7075          for inpu
-00017b90: 745f 636f 726f 2069 6e20 6368 756e 6b73  t_coro in chunks
-00017ba0: 2869 6e70 7574 5f63 6f72 6f75 7469 6e65  (input_coroutine
-00017bb0: 732c 2031 3030 293a 0a20 2020 2020 2020  s, 100):.       
-00017bc0: 2020 2020 2061 7379 6e63 2064 6566 2067       async def g
-00017bd0: 6174 6865 725f 7374 7566 6628 293a 0a20  ather_stuff():. 
-00017be0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00017bf0: 6574 7572 6e20 6177 6169 7420 6173 796e  eturn await asyn
-00017c00: 6369 6f2e 6761 7468 6572 282a 696e 7075  cio.gather(*inpu
-00017c10: 745f 636f 726f 2c20 7265 7475 726e 5f65  t_coro, return_e
-00017c20: 7863 6570 7469 6f6e 733d 5472 7565 290a  xceptions=True).
-00017c30: 0a20 2020 2020 2020 2020 2020 2077 6974  .            wit
-00017c40: 6820 7365 6c66 2e5f 6c6f 6f70 5f6c 6f63  h self._loop_loc
-00017c50: 6b3a 0a20 2020 2020 2020 2020 2020 2020  k:.             
-00017c60: 2020 2072 6573 756c 7473 203d 2073 656c     results = sel
-00017c70: 662e 6c6f 6f70 2e72 756e 5f75 6e74 696c  f.loop.run_until
-00017c80: 5f63 6f6d 706c 6574 6528 6761 7468 6572  _complete(gather
-00017c90: 5f73 7475 6666 2829 290a 0a20 2020 2020  _stuff())..     
-00017ca0: 2020 2020 2020 2066 6f72 2072 6573 2069         for res i
-00017cb0: 6e20 7265 7375 6c74 733a 0a20 2020 2020  n results:.     
-00017cc0: 2020 2020 2020 2020 2020 2069 6620 6973             if is
-00017cd0: 696e 7374 616e 6365 2872 6573 2c20 4578  instance(res, Ex
-00017ce0: 6365 7074 696f 6e29 3a0a 2020 2020 2020  ception):.      
-00017cf0: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-00017d00: 6767 6572 2e77 6172 6e69 6e67 2866 2241  gger.warning(f"A
-00017d10: 7379 6e63 2063 6f64 6520 7261 6973 6564  sync code raised
-00017d20: 2061 6e20 6578 6365 7074 696f 6e3a 207b   an exception: {
-00017d30: 7265 7072 2872 6573 297d 2229 0a20 2020  repr(res)}").   
-00017d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017d50: 2063 6f6e 7469 6e75 650a 2020 2020 2020   continue.      
-00017d60: 2020 2020 2020 2020 2020 2320 4465 636f            # Deco
-00017d70: 6e73 7472 7563 7420 7475 706c 6520 2868  nstruct tuple (h
-00017d80: 6173 2035 2065 6c65 6d65 6e74 7329 0a20  as 5 elements). 
-00017d90: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-00017da0: 6169 722c 2074 696d 6566 7261 6d65 2c20  air, timeframe, 
-00017db0: 635f 7479 7065 2c20 7469 636b 732c 2064  c_type, ticks, d
-00017dc0: 726f 705f 6869 6e74 203d 2072 6573 0a20  rop_hint = res. 
-00017dd0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00017de0: 726f 705f 696e 636f 6d70 6c65 7465 5f20  rop_incomplete_ 
-00017df0: 3d20 6472 6f70 5f68 696e 7420 6966 2064  = drop_hint if d
-00017e00: 726f 705f 696e 636f 6d70 6c65 7465 2069  rop_incomplete i
-00017e10: 7320 4e6f 6e65 2065 6c73 6520 6472 6f70  s None else drop
-00017e20: 5f69 6e63 6f6d 706c 6574 650a 2020 2020  _incomplete.    
-00017e30: 2020 2020 2020 2020 2020 2020 6f68 6c63              ohlc
-00017e40: 765f 6466 203d 2073 656c 662e 5f70 726f  v_df = self._pro
-00017e50: 6365 7373 5f6f 686c 6376 5f64 6628 0a20  cess_ohlcv_df(. 
-00017e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017e70: 2020 2070 6169 722c 2074 696d 6566 7261     pair, timefra
-00017e80: 6d65 2c20 635f 7479 7065 2c20 7469 636b  me, c_type, tick
-00017e90: 732c 2063 6163 6865 2c20 6472 6f70 5f69  s, cache, drop_i
-00017ea0: 6e63 6f6d 706c 6574 655f 290a 0a20 2020  ncomplete_)..   
-00017eb0: 2020 2020 2020 2020 2020 2020 2072 6573               res
-00017ec0: 756c 7473 5f64 665b 2870 6169 722c 2074  ults_df[(pair, t
-00017ed0: 696d 6566 7261 6d65 2c20 635f 7479 7065  imeframe, c_type
-00017ee0: 295d 203d 206f 686c 6376 5f64 660a 0a20  )] = ohlcv_df.. 
-00017ef0: 2020 2020 2020 2023 2052 6574 7572 6e20         # Return 
-00017f00: 6361 6368 6564 206b 6c69 6e65 730a 2020  cached klines.  
-00017f10: 2020 2020 2020 666f 7220 7061 6972 2c20        for pair, 
-00017f20: 7469 6d65 6672 616d 652c 2063 5f74 7970  timeframe, c_typ
-00017f30: 6520 696e 2063 6163 6865 645f 7061 6972  e in cached_pair
-00017f40: 733a 0a20 2020 2020 2020 2020 2020 2072  s:.            r
-00017f50: 6573 756c 7473 5f64 665b 2870 6169 722c  esults_df[(pair,
-00017f60: 2074 696d 6566 7261 6d65 2c20 635f 7479   timeframe, c_ty
-00017f70: 7065 295d 203d 2073 656c 662e 6b6c 696e  pe)] = self.klin
-00017f80: 6573 280a 2020 2020 2020 2020 2020 2020  es(.            
-00017f90: 2020 2020 2870 6169 722c 2074 696d 6566      (pair, timef
-00017fa0: 7261 6d65 2c20 635f 7479 7065 292c 0a20  rame, c_type),. 
-00017fb0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00017fc0: 6f70 793d 4661 6c73 650a 2020 2020 2020  opy=False.      
+00005420: 6767 6572 2e65 7863 6570 7469 6f6e 2822  gger.exception("
+00005430: 556e 6162 6c65 2074 6f20 696e 6974 6961  Unable to initia
+00005440: 6c69 7a65 206d 6172 6b65 7473 2e22 290a  lize markets.").
+00005450: 0a20 2020 2064 6566 2072 656c 6f61 645f  .    def reload_
+00005460: 6d61 726b 6574 7328 7365 6c66 2c20 666f  markets(self, fo
+00005470: 7263 653a 2062 6f6f 6c20 3d20 4661 6c73  rce: bool = Fals
+00005480: 6529 202d 3e20 4e6f 6e65 3a0a 2020 2020  e) -> None:.    
+00005490: 2020 2020 2222 2252 656c 6f61 6420 6d61      """Reload ma
+000054a0: 726b 6574 7320 626f 7468 2073 796e 6320  rkets both sync 
+000054b0: 616e 6420 6173 796e 6320 6966 2072 6566  and async if ref
+000054c0: 7265 7368 2069 6e74 6572 7661 6c20 6861  resh interval ha
+000054d0: 7320 7061 7373 6564 2222 220a 2020 2020  s passed""".    
+000054e0: 2020 2020 2320 4368 6563 6b20 7768 6574      # Check whet
+000054f0: 6865 7220 6d61 726b 6574 7320 6861 7665  her markets have
+00005500: 2074 6f20 6265 2072 656c 6f61 6465 640a   to be reloaded.
+00005510: 2020 2020 2020 2020 6966 2028 0a20 2020          if (.   
+00005520: 2020 2020 2020 2020 206e 6f74 2066 6f72           not for
+00005530: 6365 0a20 2020 2020 2020 2020 2020 2061  ce.            a
+00005540: 6e64 2073 656c 662e 5f6c 6173 745f 6d61  nd self._last_ma
+00005550: 726b 6574 735f 7265 6672 6573 6820 3e20  rkets_refresh > 
+00005560: 300a 2020 2020 2020 2020 2020 2020 616e  0.            an
+00005570: 6420 2873 656c 662e 5f6c 6173 745f 6d61  d (self._last_ma
+00005580: 726b 6574 735f 7265 6672 6573 6820 2b20  rkets_refresh + 
+00005590: 7365 6c66 2e6d 6172 6b65 7473 5f72 6566  self.markets_ref
+000055a0: 7265 7368 5f69 6e74 6572 7661 6c20 3e20  resh_interval > 
+000055b0: 6474 5f74 7328 2929 0a20 2020 2020 2020  dt_ts()).       
+000055c0: 2029 3a0a 2020 2020 2020 2020 2020 2020   ):.            
+000055d0: 7265 7475 726e 204e 6f6e 650a 2020 2020  return None.    
+000055e0: 2020 2020 6c6f 6767 6572 2e64 6562 7567      logger.debug
+000055f0: 2822 5065 7266 6f72 6d69 6e67 2073 6368  ("Performing sch
+00005600: 6564 756c 6564 206d 6172 6b65 7420 7265  eduled market re
+00005610: 6c6f 6164 2e2e 2229 0a20 2020 2020 2020  load..").       
+00005620: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
+00005630: 2020 7365 6c66 2e5f 6d61 726b 6574 7320    self._markets 
+00005640: 3d20 7365 6c66 2e5f 6170 692e 6c6f 6164  = self._api.load
+00005650: 5f6d 6172 6b65 7473 2872 656c 6f61 643d  _markets(reload=
+00005660: 5472 7565 2c20 7061 7261 6d73 3d7b 7d29  True, params={})
+00005670: 0a20 2020 2020 2020 2020 2020 2023 2041  .            # A
+00005680: 6c73 6f20 7265 6c6f 6164 2061 7379 6e63  lso reload async
+00005690: 206d 6172 6b65 7473 2074 6f20 6176 6f69   markets to avoi
+000056a0: 6420 6973 7375 6573 2077 6974 6820 6e65  d issues with ne
+000056b0: 776c 7920 6c69 7374 6564 2070 6169 7273  wly listed pairs
+000056c0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+000056d0: 662e 5f6c 6f61 645f 6173 796e 635f 6d61  f._load_async_ma
+000056e0: 726b 6574 7328 7265 6c6f 6164 3d54 7275  rkets(reload=Tru
+000056f0: 6529 0a20 2020 2020 2020 2020 2020 2073  e).            s
+00005700: 656c 662e 5f6c 6173 745f 6d61 726b 6574  elf._last_market
+00005710: 735f 7265 6672 6573 6820 3d20 6474 5f74  s_refresh = dt_t
+00005720: 7328 290a 2020 2020 2020 2020 2020 2020  s().            
+00005730: 7365 6c66 2e66 696c 6c5f 6c65 7665 7261  self.fill_levera
+00005740: 6765 5f74 6965 7273 2829 0a20 2020 2020  ge_tiers().     
+00005750: 2020 2065 7863 6570 7420 6363 7874 2e42     except ccxt.B
+00005760: 6173 6545 7272 6f72 3a0a 2020 2020 2020  aseError:.      
+00005770: 2020 2020 2020 6c6f 6767 6572 2e65 7863        logger.exc
+00005780: 6570 7469 6f6e 2822 436f 756c 6420 6e6f  eption("Could no
+00005790: 7420 7265 6c6f 6164 206d 6172 6b65 7473  t reload markets
+000057a0: 2e22 290a 0a20 2020 2064 6566 2076 616c  .")..    def val
+000057b0: 6964 6174 655f 7374 616b 6563 7572 7265  idate_stakecurre
+000057c0: 6e63 7928 7365 6c66 2c20 7374 616b 655f  ncy(self, stake_
+000057d0: 6375 7272 656e 6379 3a20 7374 7229 202d  currency: str) -
+000057e0: 3e20 4e6f 6e65 3a0a 2020 2020 2020 2020  > None:.        
+000057f0: 2222 220a 2020 2020 2020 2020 4368 6563  """.        Chec
+00005800: 6b73 2073 7461 6b65 2d63 7572 7265 6e63  ks stake-currenc
+00005810: 7920 6167 6169 6e73 7420 6176 6169 6c61  y against availa
+00005820: 626c 6520 6375 7272 656e 6369 6573 206f  ble currencies o
+00005830: 6e20 7468 6520 6578 6368 616e 6765 2e0a  n the exchange..
+00005840: 2020 2020 2020 2020 4f6e 6c79 2072 756e          Only run
+00005850: 7320 6f6e 2073 7461 7274 7570 2e20 4966  s on startup. If
+00005860: 206d 6172 6b65 7473 2068 6176 6520 6e6f   markets have no
+00005870: 7420 6265 656e 206c 6f61 6465 642c 2074  t been loaded, t
+00005880: 6865 7265 2773 2062 6565 6e20 6120 7072  here's been a pr
+00005890: 6f62 6c65 6d20 7769 7468 0a20 2020 2020  oblem with.     
+000058a0: 2020 2074 6865 2063 6f6e 6e65 6374 696f     the connectio
+000058b0: 6e20 746f 2074 6865 2065 7863 6861 6e67  n to the exchang
+000058c0: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
+000058d0: 6d20 7374 616b 655f 6375 7272 656e 6379  m stake_currency
+000058e0: 3a20 5374 616b 652d 6375 7272 656e 6379  : Stake-currency
+000058f0: 2074 6f20 7661 6c69 6461 7465 0a20 2020   to validate.   
+00005900: 2020 2020 203a 7261 6973 653a 204f 7065       :raise: Ope
+00005910: 7261 7469 6f6e 616c 4578 6365 7074 696f  rationalExceptio
+00005920: 6e20 6966 2073 7461 6b65 2d63 7572 7265  n if stake-curre
+00005930: 6e63 7920 6973 206e 6f74 2061 7661 696c  ncy is not avail
+00005940: 6162 6c65 2e0a 2020 2020 2020 2020 2222  able..        ""
+00005950: 220a 2020 2020 2020 2020 6966 206e 6f74  ".        if not
+00005960: 2073 656c 662e 5f6d 6172 6b65 7473 3a0a   self._markets:.
+00005970: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00005980: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
+00005990: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
+000059a0: 2020 2020 2020 2020 2243 6f75 6c64 206e          "Could n
+000059b0: 6f74 206c 6f61 6420 6d61 726b 6574 732c  ot load markets,
+000059c0: 2074 6865 7265 666f 7265 2063 616e 6e6f   therefore canno
+000059d0: 7420 7374 6172 742e 2022 0a20 2020 2020  t start. ".     
+000059e0: 2020 2020 2020 2020 2020 2022 506c 6561             "Plea
+000059f0: 7365 2069 6e76 6573 7469 6761 7465 2074  se investigate t
+00005a00: 6865 2061 626f 7665 2065 7272 6f72 2066  he above error f
+00005a10: 6f72 206d 6f72 6520 6465 7461 696c 732e  or more details.
+00005a20: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
+00005a30: 2020 2020 2020 2020 7175 6f74 655f 6375          quote_cu
+00005a40: 7272 656e 6369 6573 203d 2073 656c 662e  rrencies = self.
+00005a50: 6765 745f 7175 6f74 655f 6375 7272 656e  get_quote_curren
+00005a60: 6369 6573 2829 0a20 2020 2020 2020 2069  cies().        i
+00005a70: 6620 7374 616b 655f 6375 7272 656e 6379  f stake_currency
+00005a80: 206e 6f74 2069 6e20 7175 6f74 655f 6375   not in quote_cu
+00005a90: 7272 656e 6369 6573 3a0a 2020 2020 2020  rrencies:.      
+00005aa0: 2020 2020 2020 7261 6973 6520 436f 6e66        raise Conf
+00005ab0: 6967 7572 6174 696f 6e45 7272 6f72 280a  igurationError(.
+00005ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005ad0: 6622 7b73 7461 6b65 5f63 7572 7265 6e63  f"{stake_currenc
+00005ae0: 797d 2069 7320 6e6f 7420 6176 6169 6c61  y} is not availa
+00005af0: 626c 6520 6173 2073 7461 6b65 206f 6e20  ble as stake on 
+00005b00: 7b73 656c 662e 6e61 6d65 7d2e 2022 0a20  {self.name}. ". 
+00005b10: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00005b20: 2241 7661 696c 6162 6c65 2063 7572 7265  "Available curre
+00005b30: 6e63 6965 7320 6172 653a 207b 272c 2027  ncies are: {', '
+00005b40: 2e6a 6f69 6e28 7175 6f74 655f 6375 7272  .join(quote_curr
+00005b50: 656e 6369 6573 297d 220a 2020 2020 2020  encies)}".      
+00005b60: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
+00005b70: 2076 616c 6964 6174 655f 7061 6972 7328   validate_pairs(
+00005b80: 7365 6c66 2c20 7061 6972 733a 204c 6973  self, pairs: Lis
+00005b90: 745b 7374 725d 2920 2d3e 204e 6f6e 653a  t[str]) -> None:
+00005ba0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00005bb0: 2020 2020 2043 6865 636b 7320 6966 2061       Checks if a
+00005bc0: 6c6c 2067 6976 656e 2070 6169 7273 2061  ll given pairs a
+00005bd0: 7265 2074 7261 6461 626c 6520 6f6e 2074  re tradable on t
+00005be0: 6865 2063 7572 7265 6e74 2065 7863 6861  he current excha
+00005bf0: 6e67 652e 0a20 2020 2020 2020 203a 7061  nge..        :pa
+00005c00: 7261 6d20 7061 6972 733a 206c 6973 7420  ram pairs: list 
+00005c10: 6f66 2070 6169 7273 0a20 2020 2020 2020  of pairs.       
+00005c20: 203a 7261 6973 653a 204f 7065 7261 7469   :raise: Operati
+00005c30: 6f6e 616c 4578 6365 7074 696f 6e20 6966  onalException if
+00005c40: 206f 6e65 2070 6169 7220 6973 206e 6f74   one pair is not
+00005c50: 2061 7661 696c 6162 6c65 0a20 2020 2020   available.     
+00005c60: 2020 203a 7265 7475 726e 3a20 4e6f 6e65     :return: None
+00005c70: 0a20 2020 2020 2020 2022 2222 0a0a 2020  .        """..  
+00005c80: 2020 2020 2020 6966 206e 6f74 2073 656c        if not sel
+00005c90: 662e 6d61 726b 6574 733a 0a20 2020 2020  f.markets:.     
+00005ca0: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
+00005cb0: 726e 696e 6728 2255 6e61 626c 6520 746f  rning("Unable to
+00005cc0: 2076 616c 6964 6174 6520 7061 6972 7320   validate pairs 
+00005cd0: 2861 7373 756d 696e 6720 7468 6579 2061  (assuming they a
+00005ce0: 7265 2063 6f72 7265 6374 292e 2229 0a20  re correct)."). 
+00005cf0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00005d00: 6e0a 2020 2020 2020 2020 6578 7465 6e64  n.        extend
+00005d10: 6564 5f70 6169 7273 203d 2065 7870 616e  ed_pairs = expan
+00005d20: 645f 7061 6972 6c69 7374 2870 6169 7273  d_pairlist(pairs
+00005d30: 2c20 6c69 7374 2873 656c 662e 6d61 726b  , list(self.mark
+00005d40: 6574 7329 2c20 6b65 6570 5f69 6e76 616c  ets), keep_inval
+00005d50: 6964 3d54 7275 6529 0a20 2020 2020 2020  id=True).       
+00005d60: 2069 6e76 616c 6964 5f70 6169 7273 203d   invalid_pairs =
+00005d70: 205b 5d0a 2020 2020 2020 2020 666f 7220   [].        for 
+00005d80: 7061 6972 2069 6e20 6578 7465 6e64 6564  pair in extended
+00005d90: 5f70 6169 7273 3a0a 2020 2020 2020 2020  _pairs:.        
+00005da0: 2020 2020 2320 4e6f 7465 3a20 6363 7874      # Note: ccxt
+00005db0: 2068 6173 2042 6173 6543 7572 7265 6e63   has BaseCurrenc
+00005dc0: 792f 5175 6f74 6543 7572 7265 6e63 7920  y/QuoteCurrency 
+00005dd0: 666f 726d 6174 2066 6f72 2070 6169 7273  format for pairs
+00005de0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00005df0: 7365 6c66 2e6d 6172 6b65 7473 2061 6e64  self.markets and
+00005e00: 2070 6169 7220 6e6f 7420 696e 2073 656c   pair not in sel
+00005e10: 662e 6d61 726b 6574 733a 0a20 2020 2020  f.markets:.     
+00005e20: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00005e30: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
+00005e40: 7074 696f 6e28 0a20 2020 2020 2020 2020  ption(.         
+00005e50: 2020 2020 2020 2020 2020 2066 2250 6169             f"Pai
+00005e60: 7220 7b70 6169 727d 2069 7320 6e6f 7420  r {pair} is not 
+00005e70: 6176 6169 6c61 626c 6520 6f6e 207b 7365  available on {se
+00005e80: 6c66 2e6e 616d 657d 207b 7365 6c66 2e74  lf.name} {self.t
+00005e90: 7261 6469 6e67 5f6d 6f64 652e 7661 6c75  rading_mode.valu
+00005ea0: 657d 2e20 220a 2020 2020 2020 2020 2020  e}. ".          
+00005eb0: 2020 2020 2020 2020 2020 6622 506c 6561            f"Plea
+00005ec0: 7365 2072 656d 6f76 6520 7b70 6169 727d  se remove {pair}
+00005ed0: 2066 726f 6d20 796f 7572 2077 6869 7465   from your white
+00005ee0: 6c69 7374 2e22 0a20 2020 2020 2020 2020  list.".         
+00005ef0: 2020 2020 2020 2029 0a0a 2020 2020 2020         )..      
+00005f00: 2020 2020 2020 2020 2020 2320 4672 6f6d            # From
+00005f10: 2063 6378 7420 446f 6375 6d65 6e74 6174   ccxt Documentat
+00005f20: 696f 6e3a 0a20 2020 2020 2020 2020 2020  ion:.           
+00005f30: 2020 2020 2023 206d 6172 6b65 7473 2e69       # markets.i
+00005f40: 6e66 6f3a 2041 6e20 6173 736f 6369 6174  nfo: An associat
+00005f50: 6976 6520 6172 7261 7920 6f66 206e 6f6e  ive array of non
+00005f60: 2d63 6f6d 6d6f 6e20 6d61 726b 6574 2070  -common market p
+00005f70: 726f 7065 7274 6965 732c 0a20 2020 2020  roperties,.     
+00005f80: 2020 2020 2020 2020 2020 2023 2069 6e63             # inc
+00005f90: 6c75 6469 6e67 2066 6565 732c 2072 6174  luding fees, rat
+00005fa0: 6573 2c20 6c69 6d69 7473 2061 6e64 206f  es, limits and o
+00005fb0: 7468 6572 2067 656e 6572 616c 206d 6172  ther general mar
+00005fc0: 6b65 7420 696e 666f 726d 6174 696f 6e2e  ket information.
+00005fd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005fe0: 2023 2054 6865 2069 6e74 6572 6e61 6c20   # The internal 
+00005ff0: 696e 666f 2061 7272 6179 2069 7320 6469  info array is di
+00006000: 6666 6572 656e 7420 666f 7220 6561 6368  fferent for each
+00006010: 2070 6172 7469 6375 6c61 7220 6d61 726b   particular mark
+00006020: 6574 2c0a 2020 2020 2020 2020 2020 2020  et,.            
+00006030: 2020 2020 2320 6974 7320 636f 6e74 656e      # its conten
+00006040: 7473 2064 6570 656e 6420 6f6e 2074 6865  ts depend on the
+00006050: 2065 7863 6861 6e67 652e 0a20 2020 2020   exchange..     
+00006060: 2020 2020 2020 2020 2020 2023 2049 7420             # It 
+00006070: 6361 6e20 616c 736f 2062 6520 6120 7374  can also be a st
+00006080: 7269 6e67 206f 7220 7369 6d69 6c61 7220  ring or similar 
+00006090: 2e2e 2e20 736f 2077 6520 6e65 6564 2074  ... so we need t
+000060a0: 6f20 7665 7269 6679 2074 6861 7420 6669  o verify that fi
+000060b0: 7273 742e 0a20 2020 2020 2020 2020 2020  rst..           
+000060c0: 2065 6c69 6620 6973 696e 7374 616e 6365   elif isinstance
+000060d0: 2873 656c 662e 6d61 726b 6574 735b 7061  (self.markets[pa
+000060e0: 6972 5d2e 6765 7428 2269 6e66 6f22 292c  ir].get("info"),
+000060f0: 2064 6963 7429 2061 6e64 2073 656c 662e   dict) and self.
+00006100: 6d61 726b 6574 735b 7061 6972 5d2e 6765  markets[pair].ge
+00006110: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
+00006120: 2020 2022 696e 666f 222c 207b 7d0a 2020     "info", {}.  
+00006130: 2020 2020 2020 2020 2020 292e 6765 7428            ).get(
+00006140: 2270 726f 6869 6269 7465 6449 6e22 2c20  "prohibitedIn", 
+00006150: 4661 6c73 6529 3a0a 2020 2020 2020 2020  False):.        
+00006160: 2020 2020 2020 2020 2320 5761 726e 2075          # Warn u
+00006170: 7365 7273 2061 626f 7574 2072 6573 7472  sers about restr
+00006180: 6963 7465 6420 7061 6972 7320 696e 2077  icted pairs in w
+00006190: 6869 7465 6c69 7374 2e0a 2020 2020 2020  hitelist..      
+000061a0: 2020 2020 2020 2020 2020 2320 5765 2063            # We c
+000061b0: 616e 6e6f 7420 6465 7465 726d 696e 6520  annot determine 
+000061c0: 7265 6c69 6162 6c79 2069 6620 5573 6572  reliably if User
+000061d0: 7320 6172 6520 6166 6665 6374 6564 2e0a  s are affected..
+000061e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000061f0: 6c6f 6767 6572 2e77 6172 6e69 6e67 280a  logger.warning(.
+00006200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006210: 2020 2020 6622 5061 6972 207b 7061 6972      f"Pair {pair
+00006220: 7d20 6973 2072 6573 7472 6963 7465 6420  } is restricted 
+00006230: 666f 7220 736f 6d65 2075 7365 7273 206f  for some users o
+00006240: 6e20 7468 6973 2065 7863 6861 6e67 652e  n this exchange.
+00006250: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00006260: 2020 2020 2020 6622 506c 6561 7365 2063        f"Please c
+00006270: 6865 636b 2069 6620 796f 7520 6172 6520  heck if you are 
+00006280: 696d 7061 6374 6564 2062 7920 7468 6973  impacted by this
+00006290: 2072 6573 7472 6963 7469 6f6e 2022 0a20   restriction ". 
+000062a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000062b0: 2020 2066 226f 6e20 7468 6520 6578 6368     f"on the exch
+000062c0: 616e 6765 2061 6e64 2065 7665 6e74 7561  ange and eventua
+000062d0: 6c6c 7920 7265 6d6f 7665 207b 7061 6972  lly remove {pair
+000062e0: 7d20 6672 6f6d 2079 6f75 7220 7768 6974  } from your whit
+000062f0: 656c 6973 742e 220a 2020 2020 2020 2020  elist.".        
+00006300: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00006310: 2020 2020 2020 6966 2028 0a20 2020 2020        if (.     
+00006320: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00006330: 5f63 6f6e 6669 675b 2273 7461 6b65 5f63  _config["stake_c
+00006340: 7572 7265 6e63 7922 5d0a 2020 2020 2020  urrency"].      
+00006350: 2020 2020 2020 2020 2020 616e 6420 7365            and se
+00006360: 6c66 2e67 6574 5f70 6169 725f 7175 6f74  lf.get_pair_quot
+00006370: 655f 6375 7272 656e 6379 2870 6169 7229  e_currency(pair)
+00006380: 2021 3d20 7365 6c66 2e5f 636f 6e66 6967   != self._config
+00006390: 5b22 7374 616b 655f 6375 7272 656e 6379  ["stake_currency
+000063a0: 225d 0a20 2020 2020 2020 2020 2020 2029  "].            )
+000063b0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000063c0: 2020 696e 7661 6c69 645f 7061 6972 732e    invalid_pairs.
+000063d0: 6170 7065 6e64 2870 6169 7229 0a20 2020  append(pair).   
+000063e0: 2020 2020 2069 6620 696e 7661 6c69 645f       if invalid_
+000063f0: 7061 6972 733a 0a20 2020 2020 2020 2020  pairs:.         
+00006400: 2020 2072 6169 7365 204f 7065 7261 7469     raise Operati
+00006410: 6f6e 616c 4578 6365 7074 696f 6e28 0a20  onalException(. 
+00006420: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00006430: 2253 7461 6b65 2d63 7572 7265 6e63 7920  "Stake-currency 
+00006440: 277b 7365 6c66 2e5f 636f 6e66 6967 5b27  '{self._config['
+00006450: 7374 616b 655f 6375 7272 656e 6379 275d  stake_currency']
+00006460: 7d27 206e 6f74 2063 6f6d 7061 7469 626c  }' not compatibl
+00006470: 6520 7769 7468 2022 0a20 2020 2020 2020  e with ".       
+00006480: 2020 2020 2020 2020 2066 2270 6169 722d           f"pair-
+00006490: 7768 6974 656c 6973 742e 2050 6c65 6173  whitelist. Pleas
+000064a0: 6520 7265 6d6f 7665 2074 6865 2066 6f6c  e remove the fol
+000064b0: 6c6f 7769 6e67 2070 6169 7273 3a20 7b69  lowing pairs: {i
+000064c0: 6e76 616c 6964 5f70 6169 7273 7d22 0a20  nvalid_pairs}". 
+000064d0: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
+000064e0: 2020 6465 6620 6765 745f 7661 6c69 645f    def get_valid_
+000064f0: 7061 6972 5f63 6f6d 6269 6e61 7469 6f6e  pair_combination
+00006500: 2873 656c 662c 2063 7572 725f 313a 2073  (self, curr_1: s
+00006510: 7472 2c20 6375 7272 5f32 3a20 7374 7229  tr, curr_2: str)
+00006520: 202d 3e20 7374 723a 0a20 2020 2020 2020   -> str:.       
+00006530: 2022 2222 0a20 2020 2020 2020 2047 6574   """.        Get
+00006540: 2076 616c 6964 2070 6169 7220 636f 6d62   valid pair comb
+00006550: 696e 6174 696f 6e20 6f66 2063 7572 725f  ination of curr_
+00006560: 3120 616e 6420 6375 7272 5f32 2062 7920  1 and curr_2 by 
+00006570: 7472 7969 6e67 2062 6f74 6820 636f 6d62  trying both comb
+00006580: 696e 6174 696f 6e73 2e0a 2020 2020 2020  inations..      
+00006590: 2020 2222 220a 2020 2020 2020 2020 666f    """.        fo
+000065a0: 7220 7061 6972 2069 6e20 5b66 227b 6375  r pair in [f"{cu
+000065b0: 7272 5f31 7d2f 7b63 7572 725f 327d 222c  rr_1}/{curr_2}",
+000065c0: 2066 227b 6375 7272 5f32 7d2f 7b63 7572   f"{curr_2}/{cur
+000065d0: 725f 317d 225d 3a0a 2020 2020 2020 2020  r_1}"]:.        
+000065e0: 2020 2020 6966 2070 6169 7220 696e 2073      if pair in s
+000065f0: 656c 662e 6d61 726b 6574 7320 616e 6420  elf.markets and 
+00006600: 7365 6c66 2e6d 6172 6b65 7473 5b70 6169  self.markets[pai
+00006610: 725d 2e67 6574 2822 6163 7469 7665 2229  r].get("active")
+00006620: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00006630: 2020 7265 7475 726e 2070 6169 720a 2020    return pair.  
+00006640: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+00006650: 6545 7272 6f72 2866 2243 6f75 6c64 206e  eError(f"Could n
+00006660: 6f74 2063 6f6d 6269 6e65 207b 6375 7272  ot combine {curr
+00006670: 5f31 7d20 616e 6420 7b63 7572 725f 327d  _1} and {curr_2}
+00006680: 2074 6f20 6765 7420 6120 7661 6c69 6420   to get a valid 
+00006690: 7061 6972 2e22 290a 0a20 2020 2064 6566  pair.")..    def
+000066a0: 2076 616c 6964 6174 655f 7469 6d65 6672   validate_timefr
+000066b0: 616d 6573 2873 656c 662c 2074 696d 6566  ames(self, timef
+000066c0: 7261 6d65 3a20 4f70 7469 6f6e 616c 5b73  rame: Optional[s
+000066d0: 7472 5d29 202d 3e20 4e6f 6e65 3a0a 2020  tr]) -> None:.  
+000066e0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+000066f0: 2020 4368 6563 6b20 6966 2074 696d 6566    Check if timef
+00006700: 7261 6d65 2066 726f 6d20 636f 6e66 6967  rame from config
+00006710: 2069 7320 6120 7375 7070 6f72 7465 6420   is a supported 
+00006720: 7469 6d65 6672 616d 6520 6f6e 2074 6865  timeframe on the
+00006730: 2065 7863 6861 6e67 650a 2020 2020 2020   exchange.      
+00006740: 2020 2222 220a 2020 2020 2020 2020 6966    """.        if
+00006750: 206e 6f74 2068 6173 6174 7472 2873 656c   not hasattr(sel
+00006760: 662e 5f61 7069 2c20 2274 696d 6566 7261  f._api, "timefra
+00006770: 6d65 7322 2920 6f72 2073 656c 662e 5f61  mes") or self._a
+00006780: 7069 2e74 696d 6566 7261 6d65 7320 6973  pi.timeframes is
+00006790: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+000067a0: 2020 2023 2049 6620 7469 6d65 6672 616d     # If timefram
+000067b0: 6573 2061 7474 7269 6275 7465 2069 7320  es attribute is 
+000067c0: 6d69 7373 696e 6720 286f 7220 6973 204e  missing (or is N
+000067d0: 6f6e 6529 2c20 7468 6520 6578 6368 616e  one), the exchan
+000067e0: 6765 2070 726f 6261 626c 790a 2020 2020  ge probably.    
+000067f0: 2020 2020 2020 2020 2320 6861 7320 6e6f          # has no
+00006800: 2066 6574 6368 4f48 4c43 5620 6d65 7468   fetchOHLCV meth
+00006810: 6f64 2e0a 2020 2020 2020 2020 2020 2020  od..            
+00006820: 2320 5468 6572 6566 6f72 6520 7765 2061  # Therefore we a
+00006830: 6c73 6f20 7368 6f77 2074 6861 742e 0a20  lso show that.. 
+00006840: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00006850: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
+00006860: 7074 696f 6e28 0a20 2020 2020 2020 2020  ption(.         
+00006870: 2020 2020 2020 2066 2254 6865 2063 6378         f"The ccx
+00006880: 7420 6c69 6272 6172 7920 646f 6573 206e  t library does n
+00006890: 6f74 2070 726f 7669 6465 2074 6865 206c  ot provide the l
+000068a0: 6973 7420 6f66 2074 696d 6566 7261 6d65  ist of timeframe
+000068b0: 7320 220a 2020 2020 2020 2020 2020 2020  s ".            
+000068c0: 2020 2020 6622 666f 7220 7468 6520 6578      f"for the ex
+000068d0: 6368 616e 6765 207b 7365 6c66 2e6e 616d  change {self.nam
+000068e0: 657d 2061 6e64 2074 6869 7320 6578 6368  e} and this exch
+000068f0: 616e 6765 2022 0a20 2020 2020 2020 2020  ange ".         
+00006900: 2020 2020 2020 2066 2269 7320 7468 6572         f"is ther
+00006910: 6566 6f72 6520 6e6f 7420 7375 7070 6f72  efore not suppor
+00006920: 7465 642e 2063 6378 7420 6665 7463 684f  ted. ccxt fetchO
+00006930: 484c 4356 3a20 7b73 656c 662e 6578 6368  HLCV: {self.exch
+00006940: 616e 6765 5f68 6173 2827 6665 7463 684f  ange_has('fetchO
+00006950: 484c 4356 2729 7d22 0a20 2020 2020 2020  HLCV')}".       
+00006960: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
+00006970: 6966 2074 696d 6566 7261 6d65 2061 6e64  if timeframe and
+00006980: 2028 7469 6d65 6672 616d 6520 6e6f 7420   (timeframe not 
+00006990: 696e 2073 656c 662e 7469 6d65 6672 616d  in self.timefram
+000069a0: 6573 293a 0a20 2020 2020 2020 2020 2020  es):.           
+000069b0: 2072 6169 7365 2043 6f6e 6669 6775 7261   raise Configura
+000069c0: 7469 6f6e 4572 726f 7228 0a20 2020 2020  tionError(.     
+000069d0: 2020 2020 2020 2020 2020 2066 2249 6e76             f"Inv
+000069e0: 616c 6964 2074 696d 6566 7261 6d65 2027  alid timeframe '
+000069f0: 7b74 696d 6566 7261 6d65 7d27 2e20 5468  {timeframe}'. Th
+00006a00: 6973 2065 7863 6861 6e67 6520 7375 7070  is exchange supp
+00006a10: 6f72 7473 3a20 7b73 656c 662e 7469 6d65  orts: {self.time
+00006a20: 6672 616d 6573 7d22 0a20 2020 2020 2020  frames}".       
+00006a30: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
+00006a40: 6966 2028 0a20 2020 2020 2020 2020 2020  if (.           
+00006a50: 2074 696d 6566 7261 6d65 0a20 2020 2020   timeframe.     
+00006a60: 2020 2020 2020 2061 6e64 2073 656c 662e         and self.
+00006a70: 5f63 6f6e 6669 675b 2272 756e 6d6f 6465  _config["runmode
+00006a80: 225d 2021 3d20 5275 6e4d 6f64 652e 5554  "] != RunMode.UT
+00006a90: 494c 5f45 5843 4841 4e47 450a 2020 2020  IL_EXCHANGE.    
+00006aa0: 2020 2020 2020 2020 616e 6420 7469 6d65          and time
+00006ab0: 6672 616d 655f 746f 5f6d 696e 7574 6573  frame_to_minutes
+00006ac0: 2874 696d 6566 7261 6d65 2920 3c20 310a  (timeframe) < 1.
+00006ad0: 2020 2020 2020 2020 293a 0a20 2020 2020          ):.     
+00006ae0: 2020 2020 2020 2072 6169 7365 2043 6f6e         raise Con
+00006af0: 6669 6775 7261 7469 6f6e 4572 726f 7228  figurationError(
+00006b00: 2254 696d 6566 7261 6d65 7320 3c20 316d  "Timeframes < 1m
+00006b10: 2061 7265 2063 7572 7265 6e74 6c79 206e   are currently n
+00006b20: 6f74 2073 7570 706f 7274 6564 2062 7920  ot supported by 
+00006b30: 4672 6571 7472 6164 652e 2229 0a0a 2020  Freqtrade.")..  
+00006b40: 2020 6465 6620 7661 6c69 6461 7465 5f6f    def validate_o
+00006b50: 7264 6572 7479 7065 7328 7365 6c66 2c20  rdertypes(self, 
+00006b60: 6f72 6465 725f 7479 7065 733a 2044 6963  order_types: Dic
+00006b70: 7429 202d 3e20 4e6f 6e65 3a0a 2020 2020  t) -> None:.    
+00006b80: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00006b90: 4368 6563 6b73 2069 6620 6f72 6465 722d  Checks if order-
+00006ba0: 7479 7065 7320 636f 6e66 6967 7572 6564  types configured
+00006bb0: 2069 6e20 7374 7261 7465 6779 2f63 6f6e   in strategy/con
+00006bc0: 6669 6720 6172 6520 7375 7070 6f72 7465  fig are supporte
+00006bd0: 640a 2020 2020 2020 2020 2222 220a 2020  d.        """.  
+00006be0: 2020 2020 2020 6966 2061 6e79 2876 203d        if any(v =
+00006bf0: 3d20 226d 6172 6b65 7422 2066 6f72 206b  = "market" for k
+00006c00: 2c20 7620 696e 206f 7264 6572 5f74 7970  , v in order_typ
+00006c10: 6573 2e69 7465 6d73 2829 293a 0a20 2020  es.items()):.   
+00006c20: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
+00006c30: 7365 6c66 2e65 7863 6861 6e67 655f 6861  self.exchange_ha
+00006c40: 7328 2263 7265 6174 654d 6172 6b65 744f  s("createMarketO
+00006c50: 7264 6572 2229 3a0a 2020 2020 2020 2020  rder"):.        
+00006c60: 2020 2020 2020 2020 7261 6973 6520 436f          raise Co
+00006c70: 6e66 6967 7572 6174 696f 6e45 7272 6f72  nfigurationError
+00006c80: 2866 2245 7863 6861 6e67 6520 7b73 656c  (f"Exchange {sel
+00006c90: 662e 6e61 6d65 7d20 646f 6573 206e 6f74  f.name} does not
+00006ca0: 2073 7570 706f 7274 206d 6172 6b65 7420   support market 
+00006cb0: 6f72 6465 7273 2e22 290a 2020 2020 2020  orders.").      
+00006cc0: 2020 7365 6c66 2e76 616c 6964 6174 655f    self.validate_
+00006cd0: 7374 6f70 5f6f 7264 6572 7479 7065 7328  stop_ordertypes(
+00006ce0: 6f72 6465 725f 7479 7065 7329 0a0a 2020  order_types)..  
+00006cf0: 2020 6465 6620 7661 6c69 6461 7465 5f73    def validate_s
+00006d00: 746f 705f 6f72 6465 7274 7970 6573 2873  top_ordertypes(s
+00006d10: 656c 662c 206f 7264 6572 5f74 7970 6573  elf, order_types
+00006d20: 3a20 4469 6374 2920 2d3e 204e 6f6e 653a  : Dict) -> None:
+00006d30: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00006d40: 2020 2020 2056 616c 6964 6174 6520 7374       Validate st
+00006d50: 6f70 6c6f 7373 206f 7264 6572 2074 7970  oploss order typ
+00006d60: 6573 0a20 2020 2020 2020 2022 2222 0a20  es.        """. 
+00006d70: 2020 2020 2020 2069 6620 6f72 6465 725f         if order_
+00006d80: 7479 7065 732e 6765 7428 2273 746f 706c  types.get("stopl
+00006d90: 6f73 735f 6f6e 5f65 7863 6861 6e67 6522  oss_on_exchange"
+00006da0: 2920 616e 6420 6e6f 7420 7365 6c66 2e5f  ) and not self._
+00006db0: 6674 5f68 6173 2e67 6574 280a 2020 2020  ft_has.get(.    
+00006dc0: 2020 2020 2020 2020 2273 746f 706c 6f73          "stoplos
+00006dd0: 735f 6f6e 5f65 7863 6861 6e67 6522 2c20  s_on_exchange", 
+00006de0: 4661 6c73 650a 2020 2020 2020 2020 293a  False.        ):
+00006df0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00006e00: 7365 2043 6f6e 6669 6775 7261 7469 6f6e  se Configuration
+00006e10: 4572 726f 7228 6622 4f6e 2065 7863 6861  Error(f"On excha
+00006e20: 6e67 6520 7374 6f70 6c6f 7373 2069 7320  nge stoploss is 
+00006e30: 6e6f 7420 7375 7070 6f72 7465 6420 666f  not supported fo
+00006e40: 7220 7b73 656c 662e 6e61 6d65 7d2e 2229  r {self.name}.")
+00006e50: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00006e60: 2e74 7261 6469 6e67 5f6d 6f64 6520 3d3d  .trading_mode ==
+00006e70: 2054 7261 6469 6e67 4d6f 6465 2e46 5554   TradingMode.FUT
+00006e80: 5552 4553 3a0a 2020 2020 2020 2020 2020  URES:.          
+00006e90: 2020 7072 6963 655f 6d61 7070 696e 6720    price_mapping 
+00006ea0: 3d20 7365 6c66 2e5f 6674 5f68 6173 2e67  = self._ft_has.g
+00006eb0: 6574 2822 7374 6f70 5f70 7269 6365 5f74  et("stop_price_t
+00006ec0: 7970 655f 7661 6c75 655f 6d61 7070 696e  ype_value_mappin
+00006ed0: 6722 2c20 7b7d 292e 6b65 7973 2829 0a20  g", {}).keys(). 
+00006ee0: 2020 2020 2020 2020 2020 2069 6620 280a             if (.
+00006ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f00: 6f72 6465 725f 7479 7065 732e 6765 7428  order_types.get(
+00006f10: 2273 746f 706c 6f73 735f 6f6e 5f65 7863  "stoploss_on_exc
+00006f20: 6861 6e67 6522 2c20 4661 6c73 6529 2069  hange", False) i
+00006f30: 7320 5472 7565 0a20 2020 2020 2020 2020  s True.         
+00006f40: 2020 2020 2020 2061 6e64 2022 7374 6f70         and "stop
+00006f50: 6c6f 7373 5f70 7269 6365 5f74 7970 6522  loss_price_type"
+00006f60: 2069 6e20 6f72 6465 725f 7479 7065 730a   in order_types.
+00006f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f80: 616e 6420 6f72 6465 725f 7479 7065 735b  and order_types[
+00006f90: 2273 746f 706c 6f73 735f 7072 6963 655f  "stoploss_price_
+00006fa0: 7479 7065 225d 206e 6f74 2069 6e20 7072  type"] not in pr
+00006fb0: 6963 655f 6d61 7070 696e 670a 2020 2020  ice_mapping.    
+00006fc0: 2020 2020 2020 2020 293a 0a20 2020 2020          ):.     
+00006fd0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00006fe0: 2043 6f6e 6669 6775 7261 7469 6f6e 4572   ConfigurationEr
+00006ff0: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
+00007000: 2020 2020 2020 2020 2066 224f 6e20 6578           f"On ex
+00007010: 6368 616e 6765 2073 746f 706c 6f73 7320  change stoploss 
+00007020: 7072 6963 6520 7479 7065 2069 7320 6e6f  price type is no
+00007030: 7420 7375 7070 6f72 7465 6420 666f 7220  t supported for 
+00007040: 7b73 656c 662e 6e61 6d65 7d2e 220a 2020  {self.name}.".  
+00007050: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00007060: 0a20 2020 2064 6566 2076 616c 6964 6174  .    def validat
+00007070: 655f 7072 6963 696e 6728 7365 6c66 2c20  e_pricing(self, 
+00007080: 7072 6963 696e 673a 2044 6963 7429 202d  pricing: Dict) -
+00007090: 3e20 4e6f 6e65 3a0a 2020 2020 2020 2020  > None:.        
+000070a0: 6966 2070 7269 6369 6e67 2e67 6574 2822  if pricing.get("
+000070b0: 7573 655f 6f72 6465 725f 626f 6f6b 222c  use_order_book",
+000070c0: 2046 616c 7365 2920 616e 6420 6e6f 7420   False) and not 
+000070d0: 7365 6c66 2e65 7863 6861 6e67 655f 6861  self.exchange_ha
+000070e0: 7328 2266 6574 6368 4c32 4f72 6465 7242  s("fetchL2OrderB
+000070f0: 6f6f 6b22 293a 0a20 2020 2020 2020 2020  ook"):.         
+00007100: 2020 2072 6169 7365 2043 6f6e 6669 6775     raise Configu
+00007110: 7261 7469 6f6e 4572 726f 7228 6622 4f72  rationError(f"Or
+00007120: 6465 7262 6f6f 6b20 6e6f 7420 6176 6169  derbook not avai
+00007130: 6c61 626c 6520 666f 7220 7b73 656c 662e  lable for {self.
+00007140: 6e61 6d65 7d2e 2229 0a20 2020 2020 2020  name}.").       
+00007150: 2069 6620 6e6f 7420 7072 6963 696e 672e   if not pricing.
+00007160: 6765 7428 2275 7365 5f6f 7264 6572 5f62  get("use_order_b
+00007170: 6f6f 6b22 2c20 4661 6c73 6529 2061 6e64  ook", False) and
+00007180: 2028 0a20 2020 2020 2020 2020 2020 206e   (.            n
+00007190: 6f74 2073 656c 662e 6578 6368 616e 6765  ot self.exchange
+000071a0: 5f68 6173 2822 6665 7463 6854 6963 6b65  _has("fetchTicke
+000071b0: 7222 2920 6f72 206e 6f74 2073 656c 662e  r") or not self.
+000071c0: 5f66 745f 6861 735b 2274 6963 6b65 7273  _ft_has["tickers
+000071d0: 5f68 6176 655f 7072 6963 6522 5d0a 2020  _have_price"].  
+000071e0: 2020 2020 2020 293a 0a20 2020 2020 2020        ):.       
+000071f0: 2020 2020 2072 6169 7365 2043 6f6e 6669       raise Confi
+00007200: 6775 7261 7469 6f6e 4572 726f 7228 6622  gurationError(f"
+00007210: 5469 636b 6572 2070 7269 6369 6e67 206e  Ticker pricing n
+00007220: 6f74 2061 7661 696c 6162 6c65 2066 6f72  ot available for
+00007230: 207b 7365 6c66 2e6e 616d 657d 2e22 290a   {self.name}.").
+00007240: 0a20 2020 2064 6566 2076 616c 6964 6174  .    def validat
+00007250: 655f 6f72 6465 725f 7469 6d65 5f69 6e5f  e_order_time_in_
+00007260: 666f 7263 6528 7365 6c66 2c20 6f72 6465  force(self, orde
+00007270: 725f 7469 6d65 5f69 6e5f 666f 7263 653a  r_time_in_force:
+00007280: 2044 6963 7429 202d 3e20 4e6f 6e65 3a0a   Dict) -> None:.
+00007290: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+000072a0: 2020 2020 4368 6563 6b73 2069 6620 6f72      Checks if or
+000072b0: 6465 7220 7469 6d65 2069 6e20 666f 7263  der time in forc
+000072c0: 6520 636f 6e66 6967 7572 6564 2069 6e20  e configured in 
+000072d0: 7374 7261 7465 6779 2f63 6f6e 6669 6720  strategy/config 
+000072e0: 6172 6520 7375 7070 6f72 7465 640a 2020  are supported.  
+000072f0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00007300: 2020 6966 2061 6e79 280a 2020 2020 2020    if any(.      
+00007310: 2020 2020 2020 762e 7570 7065 7228 2920        v.upper() 
+00007320: 6e6f 7420 696e 2073 656c 662e 5f66 745f  not in self._ft_
+00007330: 6861 735b 226f 7264 6572 5f74 696d 655f  has["order_time_
+00007340: 696e 5f66 6f72 6365 225d 0a20 2020 2020  in_force"].     
+00007350: 2020 2020 2020 2066 6f72 206b 2c20 7620         for k, v 
+00007360: 696e 206f 7264 6572 5f74 696d 655f 696e  in order_time_in
+00007370: 5f66 6f72 6365 2e69 7465 6d73 2829 0a20  _force.items(). 
+00007380: 2020 2020 2020 2029 3a0a 2020 2020 2020         ):.      
+00007390: 2020 2020 2020 7261 6973 6520 436f 6e66        raise Conf
+000073a0: 6967 7572 6174 696f 6e45 7272 6f72 280a  igurationError(.
+000073b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000073c0: 6622 5469 6d65 2069 6e20 666f 7263 6520  f"Time in force 
+000073d0: 706f 6c69 6369 6573 2061 7265 206e 6f74  policies are not
+000073e0: 2073 7570 706f 7274 6564 2066 6f72 207b   supported for {
+000073f0: 7365 6c66 2e6e 616d 657d 2079 6574 2e22  self.name} yet."
+00007400: 0a20 2020 2020 2020 2020 2020 2029 0a0a  .            )..
+00007410: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
+00007420: 5f72 6571 7569 7265 645f 7374 6172 7475  _required_startu
+00007430: 705f 6361 6e64 6c65 7328 7365 6c66 2c20  p_candles(self, 
+00007440: 7374 6172 7475 705f 6361 6e64 6c65 733a  startup_candles:
+00007450: 2069 6e74 2c20 7469 6d65 6672 616d 653a   int, timeframe:
+00007460: 2073 7472 2920 2d3e 2069 6e74 3a0a 2020   str) -> int:.  
+00007470: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00007480: 2020 4368 6563 6b73 2069 6620 7265 7175    Checks if requ
+00007490: 6972 6564 2073 7461 7274 7570 5f63 616e  ired startup_can
+000074a0: 646c 6573 2069 7320 6d6f 7265 2074 6861  dles is more tha
+000074b0: 6e20 6f68 6c63 765f 6361 6e64 6c65 5f6c  n ohlcv_candle_l
+000074c0: 696d 6974 2829 2e0a 2020 2020 2020 2020  imit()..        
+000074d0: 5265 7175 6972 6573 2061 2067 7261 6365  Requires a grace
+000074e0: 2d70 6572 696f 6420 6f66 2035 2063 616e  -period of 5 can
+000074f0: 646c 6573 202d 2073 6f20 6120 7374 6172  dles - so a star
+00007500: 7475 702d 7065 7269 6f64 2075 7020 746f  tup-period up to
+00007510: 2034 3934 2069 7320 616c 6c6f 7765 6420   494 is allowed 
+00007520: 6279 2064 6566 6175 6c74 2e0a 2020 2020  by default..    
+00007530: 2020 2020 2222 220a 0a20 2020 2020 2020      """..       
+00007540: 2063 616e 646c 655f 6c69 6d69 7420 3d20   candle_limit = 
+00007550: 7365 6c66 2e6f 686c 6376 5f63 616e 646c  self.ohlcv_candl
+00007560: 655f 6c69 6d69 7428 0a20 2020 2020 2020  e_limit(.       
+00007570: 2020 2020 2074 696d 6566 7261 6d65 2c0a       timeframe,.
+00007580: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00007590: 2e5f 636f 6e66 6967 5b22 6361 6e64 6c65  ._config["candle
+000075a0: 5f74 7970 655f 6465 6622 5d2c 0a20 2020  _type_def"],.   
+000075b0: 2020 2020 2020 2020 2064 745f 7473 2864           dt_ts(d
+000075c0: 6174 655f 6d69 6e75 735f 6361 6e64 6c65  ate_minus_candle
+000075d0: 7328 7469 6d65 6672 616d 652c 2073 7461  s(timeframe, sta
+000075e0: 7274 7570 5f63 616e 646c 6573 2929 2069  rtup_candles)) i
+000075f0: 6620 7469 6d65 6672 616d 6520 656c 7365  f timeframe else
+00007600: 204e 6f6e 652c 0a20 2020 2020 2020 2029   None,.        )
+00007610: 0a20 2020 2020 2020 2023 2052 6571 7569  .        # Requi
+00007620: 7265 206f 6e65 206d 6f72 6520 6361 6e64  re one more cand
+00007630: 6c65 202d 2074 6f20 6163 636f 756e 7420  le - to account 
+00007640: 666f 7220 7468 6520 7374 696c 6c20 6f70  for the still op
+00007650: 656e 2063 616e 646c 652e 0a20 2020 2020  en candle..     
+00007660: 2020 2063 616e 646c 655f 636f 756e 7420     candle_count 
+00007670: 3d20 7374 6172 7475 705f 6361 6e64 6c65  = startup_candle
+00007680: 7320 2b20 310a 2020 2020 2020 2020 2320  s + 1.        # 
+00007690: 416c 6c6f 7720 3520 6361 6c6c 7320 746f  Allow 5 calls to
+000076a0: 2074 6865 2065 7863 6861 6e67 6520 7065   the exchange pe
+000076b0: 7220 7061 6972 0a20 2020 2020 2020 2072  r pair.        r
+000076c0: 6571 7569 7265 645f 6361 6e64 6c65 5f63  equired_candle_c
+000076d0: 616c 6c5f 636f 756e 7420 3d20 696e 7428  all_count = int(
+000076e0: 0a20 2020 2020 2020 2020 2020 2028 6361  .            (ca
+000076f0: 6e64 6c65 5f63 6f75 6e74 202f 2063 616e  ndle_count / can
+00007700: 646c 655f 6c69 6d69 7429 202b 2028 3020  dle_limit) + (0 
+00007710: 6966 2063 616e 646c 655f 636f 756e 7420  if candle_count 
+00007720: 2520 6361 6e64 6c65 5f6c 696d 6974 203d  % candle_limit =
+00007730: 3d20 3020 656c 7365 2031 290a 2020 2020  = 0 else 1).    
+00007740: 2020 2020 290a 2020 2020 2020 2020 6966      ).        if
+00007750: 2073 656c 662e 5f66 745f 6861 735b 226f   self._ft_has["o
+00007760: 686c 6376 5f68 6173 5f68 6973 746f 7279  hlcv_has_history
+00007770: 225d 3a0a 2020 2020 2020 2020 2020 2020  "]:.            
+00007780: 6966 2072 6571 7569 7265 645f 6361 6e64  if required_cand
+00007790: 6c65 5f63 616c 6c5f 636f 756e 7420 3e20  le_call_count > 
+000077a0: 353a 0a20 2020 2020 2020 2020 2020 2020  5:.             
+000077b0: 2020 2023 204f 6e6c 7920 616c 6c6f 7720     # Only allow 
+000077c0: 3520 6361 6c6c 7320 7065 7220 7061 6972  5 calls per pair
+000077d0: 2074 6f20 736f 6d65 7768 6174 206c 696d   to somewhat lim
+000077e0: 6974 2074 6865 2069 6d70 6163 740a 2020  it the impact.  
+000077f0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
+00007800: 6973 6520 436f 6e66 6967 7572 6174 696f  ise Configuratio
+00007810: 6e45 7272 6f72 280a 2020 2020 2020 2020  nError(.        
+00007820: 2020 2020 2020 2020 2020 2020 6622 5468              f"Th
+00007830: 6973 2073 7472 6174 6567 7920 7265 7175  is strategy requ
+00007840: 6972 6573 207b 7374 6172 7475 705f 6361  ires {startup_ca
+00007850: 6e64 6c65 737d 2063 616e 646c 6573 2074  ndles} candles t
+00007860: 6f20 7374 6172 742c 2022 0a20 2020 2020  o start, ".     
+00007870: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00007880: 7768 6963 6820 6973 206d 6f72 6520 7468  which is more th
+00007890: 616e 2035 7820 220a 2020 2020 2020 2020  an 5x ".        
+000078a0: 2020 2020 2020 2020 2020 2020 6622 7468              f"th
+000078b0: 6520 616d 6f75 6e74 206f 6620 6361 6e64  e amount of cand
+000078c0: 6c65 7320 7b73 656c 662e 6e61 6d65 7d20  les {self.name} 
+000078d0: 7072 6f76 6964 6573 2066 6f72 207b 7469  provides for {ti
+000078e0: 6d65 6672 616d 657d 2e22 0a20 2020 2020  meframe}.".     
+000078f0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00007900: 2020 2020 2065 6c69 6620 7265 7175 6972       elif requir
+00007910: 6564 5f63 616e 646c 655f 6361 6c6c 5f63  ed_candle_call_c
+00007920: 6f75 6e74 203e 2031 3a0a 2020 2020 2020  ount > 1:.      
+00007930: 2020 2020 2020 7261 6973 6520 436f 6e66        raise Conf
+00007940: 6967 7572 6174 696f 6e45 7272 6f72 280a  igurationError(.
+00007950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007960: 6622 5468 6973 2073 7472 6174 6567 7920  f"This strategy 
+00007970: 7265 7175 6972 6573 207b 7374 6172 7475  requires {startu
+00007980: 705f 6361 6e64 6c65 737d 2063 616e 646c  p_candles} candl
+00007990: 6573 2074 6f20 7374 6172 742c 2077 6869  es to start, whi
+000079a0: 6368 2069 7320 6d6f 7265 2074 6861 6e20  ch is more than 
+000079b0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+000079c0: 2020 6622 7468 6520 616d 6f75 6e74 206f    f"the amount o
+000079d0: 6620 6361 6e64 6c65 7320 7b73 656c 662e  f candles {self.
+000079e0: 6e61 6d65 7d20 7072 6f76 6964 6573 2066  name} provides f
+000079f0: 6f72 207b 7469 6d65 6672 616d 657d 2e22  or {timeframe}."
+00007a00: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
+00007a10: 2020 2020 2020 2069 6620 7265 7175 6972         if requir
+00007a20: 6564 5f63 616e 646c 655f 6361 6c6c 5f63  ed_candle_call_c
+00007a30: 6f75 6e74 203e 2031 3a0a 2020 2020 2020  ount > 1:.      
+00007a40: 2020 2020 2020 6c6f 6767 6572 2e77 6172        logger.war
+00007a50: 6e69 6e67 280a 2020 2020 2020 2020 2020  ning(.          
+00007a60: 2020 2020 2020 6622 5573 696e 6720 7b72        f"Using {r
+00007a70: 6571 7569 7265 645f 6361 6e64 6c65 5f63  equired_candle_c
+00007a80: 616c 6c5f 636f 756e 747d 2063 616c 6c73  all_count} calls
+00007a90: 2074 6f20 6765 7420 4f48 4c43 562e 2022   to get OHLCV. "
+00007aa0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007ab0: 2066 2254 6869 7320 6361 6e20 7265 7375   f"This can resu
+00007ac0: 6c74 2069 6e20 736c 6f77 6572 206f 7065  lt in slower ope
+00007ad0: 7261 7469 6f6e 7320 666f 7220 7468 6520  rations for the 
+00007ae0: 626f 742e 2050 6c65 6173 6520 6368 6563  bot. Please chec
+00007af0: 6b20 220a 2020 2020 2020 2020 2020 2020  k ".            
+00007b00: 2020 2020 6622 6966 2079 6f75 2072 6561      f"if you rea
+00007b10: 6c6c 7920 6e65 6564 207b 7374 6172 7475  lly need {startu
+00007b20: 705f 6361 6e64 6c65 737d 2063 616e 646c  p_candles} candl
+00007b30: 6573 2066 6f72 2079 6f75 7220 7374 7261  es for your stra
+00007b40: 7465 6779 220a 2020 2020 2020 2020 2020  tegy".          
+00007b50: 2020 290a 2020 2020 2020 2020 7265 7475    ).        retu
+00007b60: 726e 2072 6571 7569 7265 645f 6361 6e64  rn required_cand
+00007b70: 6c65 5f63 616c 6c5f 636f 756e 740a 0a20  le_call_count.. 
+00007b80: 2020 2064 6566 2076 616c 6964 6174 655f     def validate_
+00007b90: 7472 6164 696e 675f 6d6f 6465 5f61 6e64  trading_mode_and
+00007ba0: 5f6d 6172 6769 6e5f 6d6f 6465 280a 2020  _margin_mode(.  
+00007bb0: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
+00007bc0: 2020 2020 7472 6164 696e 675f 6d6f 6465      trading_mode
+00007bd0: 3a20 5472 6164 696e 674d 6f64 652c 0a20  : TradingMode,. 
+00007be0: 2020 2020 2020 206d 6172 6769 6e5f 6d6f         margin_mo
+00007bf0: 6465 3a20 4f70 7469 6f6e 616c 5b4d 6172  de: Optional[Mar
+00007c00: 6769 6e4d 6f64 655d 2c20 2023 204f 6e6c  ginMode],  # Onl
+00007c10: 7920 4e6f 6e65 2077 6865 6e20 7472 6164  y None when trad
+00007c20: 696e 675f 6d6f 6465 203d 2054 7261 6469  ing_mode = Tradi
+00007c30: 6e67 4d6f 6465 2e53 504f 540a 2020 2020  ngMode.SPOT.    
+00007c40: 293a 0a20 2020 2020 2020 2022 2222 0a20  ):.        """. 
+00007c50: 2020 2020 2020 2043 6865 636b 7320 6966         Checks if
+00007c60: 2066 7265 7174 7261 6465 2063 616e 2070   freqtrade can p
+00007c70: 6572 666f 726d 2074 7261 6465 7320 7573  erform trades us
+00007c80: 696e 6720 7468 6520 636f 6e66 6967 7572  ing the configur
+00007c90: 6564 0a20 2020 2020 2020 2074 7261 6469  ed.        tradi
+00007ca0: 6e67 206d 6f64 6528 4d61 7267 696e 2c20  ng mode(Margin, 
+00007cb0: 4675 7475 7265 7329 2061 6e64 204d 6172  Futures) and Mar
+00007cc0: 6769 6e4d 6f64 6528 4372 6f73 732c 2049  ginMode(Cross, I
+00007cd0: 736f 6c61 7465 6429 0a20 2020 2020 2020  solated).       
+00007ce0: 2054 6872 6f77 7320 4f70 6572 6174 696f   Throws Operatio
+00007cf0: 6e61 6c45 7863 6570 7469 6f6e 3a0a 2020  nalException:.  
+00007d00: 2020 2020 2020 2020 2020 4966 2074 6865            If the
+00007d10: 2074 7261 6469 6e67 5f6d 6f64 652f 6d61   trading_mode/ma
+00007d20: 7267 696e 5f6d 6f64 6520 7479 7065 2061  rgin_mode type a
+00007d30: 7265 206e 6f74 2073 7570 706f 7274 6564  re not supported
+00007d40: 2062 7920 6672 6571 7472 6164 6520 6f6e   by freqtrade on
+00007d50: 2074 6869 7320 6578 6368 616e 6765 0a20   this exchange. 
+00007d60: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00007d70: 2020 2069 6620 7472 6164 696e 675f 6d6f     if trading_mo
+00007d80: 6465 2021 3d20 5472 6164 696e 674d 6f64  de != TradingMod
+00007d90: 652e 5350 4f54 2061 6e64 2028 0a20 2020  e.SPOT and (.   
+00007da0: 2020 2020 2020 2020 2028 7472 6164 696e           (tradin
+00007db0: 675f 6d6f 6465 2c20 6d61 7267 696e 5f6d  g_mode, margin_m
+00007dc0: 6f64 6529 206e 6f74 2069 6e20 7365 6c66  ode) not in self
+00007dd0: 2e5f 7375 7070 6f72 7465 645f 7472 6164  ._supported_trad
+00007de0: 696e 675f 6d6f 6465 5f6d 6172 6769 6e5f  ing_mode_margin_
+00007df0: 7061 6972 730a 2020 2020 2020 2020 293a  pairs.        ):
+00007e00: 0a20 2020 2020 2020 2020 2020 206d 6d5f  .            mm_
+00007e10: 7661 6c75 6520 3d20 6d61 7267 696e 5f6d  value = margin_m
+00007e20: 6f64 6520 616e 6420 6d61 7267 696e 5f6d  ode and margin_m
+00007e30: 6f64 652e 7661 6c75 650a 2020 2020 2020  ode.value.      
+00007e40: 2020 2020 2020 7261 6973 6520 4f70 6572        raise Oper
+00007e50: 6174 696f 6e61 6c45 7863 6570 7469 6f6e  ationalException
+00007e60: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00007e70: 2020 6622 4672 6571 7472 6164 6520 646f    f"Freqtrade do
+00007e80: 6573 206e 6f74 2073 7570 706f 7274 207b  es not support {
+00007e90: 6d6d 5f76 616c 7565 7d20 7b74 7261 6469  mm_value} {tradi
+00007ea0: 6e67 5f6d 6f64 652e 7661 6c75 657d 206f  ng_mode.value} o
+00007eb0: 6e20 7b73 656c 662e 6e61 6d65 7d22 0a20  n {self.name}". 
+00007ec0: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
+00007ed0: 2020 6465 6620 6765 745f 6f70 7469 6f6e    def get_option
+00007ee0: 2873 656c 662c 2070 6172 616d 3a20 7374  (self, param: st
+00007ef0: 722c 2064 6566 6175 6c74 3a20 4f70 7469  r, default: Opti
+00007f00: 6f6e 616c 5b41 6e79 5d20 3d20 4e6f 6e65  onal[Any] = None
+00007f10: 2920 2d3e 2041 6e79 3a0a 2020 2020 2020  ) -> Any:.      
+00007f20: 2020 2222 220a 2020 2020 2020 2020 4765    """.        Ge
+00007f30: 7420 7061 7261 6d65 7465 7220 7661 6c75  t parameter valu
+00007f40: 6520 6672 6f6d 205f 6674 5f68 6173 0a20  e from _ft_has. 
+00007f50: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00007f60: 2020 2072 6574 7572 6e20 7365 6c66 2e5f     return self._
+00007f70: 6674 5f68 6173 2e67 6574 2870 6172 616d  ft_has.get(param
+00007f80: 2c20 6465 6661 756c 7429 0a0a 2020 2020  , default)..    
+00007f90: 6465 6620 6578 6368 616e 6765 5f68 6173  def exchange_has
+00007fa0: 2873 656c 662c 2065 6e64 706f 696e 743a  (self, endpoint:
+00007fb0: 2073 7472 2920 2d3e 2062 6f6f 6c3a 0a20   str) -> bool:. 
+00007fc0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00007fd0: 2020 2043 6865 636b 7320 6966 2065 7863     Checks if exc
+00007fe0: 6861 6e67 6520 696d 706c 656d 656e 7473  hange implements
+00007ff0: 2061 2073 7065 6369 6669 6320 4150 4920   a specific API 
+00008000: 656e 6470 6f69 6e74 2e0a 2020 2020 2020  endpoint..      
+00008010: 2020 5772 6170 7065 7220 6172 6f75 6e64    Wrapper around
+00008020: 2063 6378 7420 2768 6173 2720 6174 7472   ccxt 'has' attr
+00008030: 6962 7574 650a 2020 2020 2020 2020 3a70  ibute.        :p
+00008040: 6172 616d 2065 6e64 706f 696e 743a 204e  aram endpoint: N
+00008050: 616d 6520 6f66 2065 6e64 706f 696e 7420  ame of endpoint 
+00008060: 2865 2e67 2e20 2766 6574 6368 4f48 4c43  (e.g. 'fetchOHLC
+00008070: 5627 2c20 2766 6574 6368 5469 636b 6572  V', 'fetchTicker
+00008080: 7327 290a 2020 2020 2020 2020 3a72 6574  s').        :ret
+00008090: 7572 6e3a 2062 6f6f 6c0a 2020 2020 2020  urn: bool.      
+000080a0: 2020 2222 220a 2020 2020 2020 2020 6966    """.        if
+000080b0: 2065 6e64 706f 696e 7420 696e 2073 656c   endpoint in sel
+000080c0: 662e 5f66 745f 6861 732e 6765 7428 2265  f._ft_has.get("e
+000080d0: 7863 6861 6e67 655f 6861 735f 6f76 6572  xchange_has_over
+000080e0: 7269 6465 7322 2c20 7b7d 293a 0a20 2020  rides", {}):.   
+000080f0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00008100: 7365 6c66 2e5f 6674 5f68 6173 5b22 6578  self._ft_has["ex
+00008110: 6368 616e 6765 5f68 6173 5f6f 7665 7272  change_has_overr
+00008120: 6964 6573 225d 5b65 6e64 706f 696e 745d  ides"][endpoint]
+00008130: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00008140: 656e 6470 6f69 6e74 2069 6e20 7365 6c66  endpoint in self
+00008150: 2e5f 6170 692e 6861 7320 616e 6420 7365  ._api.has and se
+00008160: 6c66 2e5f 6170 692e 6861 735b 656e 6470  lf._api.has[endp
+00008170: 6f69 6e74 5d0a 0a20 2020 2064 6566 2067  oint]..    def g
+00008180: 6574 5f70 7265 6369 7369 6f6e 5f61 6d6f  et_precision_amo
+00008190: 756e 7428 7365 6c66 2c20 7061 6972 3a20  unt(self, pair: 
+000081a0: 7374 7229 202d 3e20 4f70 7469 6f6e 616c  str) -> Optional
+000081b0: 5b66 6c6f 6174 5d3a 0a20 2020 2020 2020  [float]:.       
+000081c0: 2022 2222 0a20 2020 2020 2020 2052 6574   """.        Ret
+000081d0: 7572 6e73 2074 6865 2061 6d6f 756e 7420  urns the amount 
+000081e0: 7072 6563 6973 696f 6e20 6f66 2074 6865  precision of the
+000081f0: 2065 7863 6861 6e67 652e 0a20 2020 2020   exchange..     
+00008200: 2020 203a 7061 7261 6d20 7061 6972 3a20     :param pair: 
+00008210: 5061 6972 2074 6f20 6765 7420 7072 6563  Pair to get prec
+00008220: 6973 696f 6e20 666f 720a 2020 2020 2020  ision for.      
+00008230: 2020 3a72 6574 7572 6e3a 2070 7265 6369    :return: preci
+00008240: 7369 6f6e 2066 6f72 2061 6d6f 756e 7420  sion for amount 
+00008250: 6f72 204e 6f6e 652e 204d 7573 7420 6265  or None. Must be
+00008260: 2075 7365 6420 696e 2063 6f6d 6269 6e61   used in combina
+00008270: 7469 6f6e 2077 6974 6820 7072 6563 6973  tion with precis
+00008280: 696f 6e4d 6f64 650a 2020 2020 2020 2020  ionMode.        
+00008290: 2222 220a 2020 2020 2020 2020 7265 7475  """.        retu
+000082a0: 726e 2073 656c 662e 6d61 726b 6574 732e  rn self.markets.
+000082b0: 6765 7428 7061 6972 2c20 7b7d 292e 6765  get(pair, {}).ge
+000082c0: 7428 2270 7265 6369 7369 6f6e 222c 207b  t("precision", {
+000082d0: 7d29 2e67 6574 2822 616d 6f75 6e74 222c  }).get("amount",
+000082e0: 204e 6f6e 6529 0a0a 2020 2020 6465 6620   None)..    def 
+000082f0: 6765 745f 7072 6563 6973 696f 6e5f 7072  get_precision_pr
+00008300: 6963 6528 7365 6c66 2c20 7061 6972 3a20  ice(self, pair: 
+00008310: 7374 7229 202d 3e20 4f70 7469 6f6e 616c  str) -> Optional
+00008320: 5b66 6c6f 6174 5d3a 0a20 2020 2020 2020  [float]:.       
+00008330: 2022 2222 0a20 2020 2020 2020 2052 6574   """.        Ret
+00008340: 7572 6e73 2074 6865 2070 7269 6365 2070  urns the price p
+00008350: 7265 6369 7369 6f6e 206f 6620 7468 6520  recision of the 
+00008360: 6578 6368 616e 6765 2e0a 2020 2020 2020  exchange..      
+00008370: 2020 3a70 6172 616d 2070 6169 723a 2050    :param pair: P
+00008380: 6169 7220 746f 2067 6574 2070 7265 6369  air to get preci
+00008390: 7369 6f6e 2066 6f72 0a20 2020 2020 2020  sion for.       
+000083a0: 203a 7265 7475 726e 3a20 7072 6563 6973   :return: precis
+000083b0: 696f 6e20 666f 7220 7072 6963 6520 6f72  ion for price or
+000083c0: 204e 6f6e 652e 204d 7573 7420 6265 2075   None. Must be u
+000083d0: 7365 6420 696e 2063 6f6d 6269 6e61 7469  sed in combinati
+000083e0: 6f6e 2077 6974 6820 7072 6563 6973 696f  on with precisio
+000083f0: 6e4d 6f64 650a 2020 2020 2020 2020 2222  nMode.        ""
+00008400: 220a 2020 2020 2020 2020 7265 7475 726e  ".        return
+00008410: 2073 656c 662e 6d61 726b 6574 732e 6765   self.markets.ge
+00008420: 7428 7061 6972 2c20 7b7d 292e 6765 7428  t(pair, {}).get(
+00008430: 2270 7265 6369 7369 6f6e 222c 207b 7d29  "precision", {})
+00008440: 2e67 6574 2822 7072 6963 6522 2c20 4e6f  .get("price", No
+00008450: 6e65 290a 0a20 2020 2064 6566 2061 6d6f  ne)..    def amo
+00008460: 756e 745f 746f 5f70 7265 6369 7369 6f6e  unt_to_precision
+00008470: 2873 656c 662c 2070 6169 723a 2073 7472  (self, pair: str
+00008480: 2c20 616d 6f75 6e74 3a20 666c 6f61 7429  , amount: float)
+00008490: 202d 3e20 666c 6f61 743a 0a20 2020 2020   -> float:.     
+000084a0: 2020 2022 2222 0a20 2020 2020 2020 2052     """.        R
+000084b0: 6574 7572 6e73 2074 6865 2061 6d6f 756e  eturns the amoun
+000084c0: 7420 746f 2062 7579 206f 7220 7365 6c6c  t to buy or sell
+000084d0: 2074 6f20 6120 7072 6563 6973 696f 6e20   to a precision 
+000084e0: 7468 6520 4578 6368 616e 6765 2061 6363  the Exchange acc
+000084f0: 6570 7473 0a0a 2020 2020 2020 2020 2222  epts..        ""
+00008500: 220a 2020 2020 2020 2020 7265 7475 726e  ".        return
+00008510: 2061 6d6f 756e 745f 746f 5f70 7265 6369   amount_to_preci
+00008520: 7369 6f6e 2861 6d6f 756e 742c 2073 656c  sion(amount, sel
+00008530: 662e 6765 745f 7072 6563 6973 696f 6e5f  f.get_precision_
+00008540: 616d 6f75 6e74 2870 6169 7229 2c20 7365  amount(pair), se
+00008550: 6c66 2e70 7265 6369 7369 6f6e 4d6f 6465  lf.precisionMode
+00008560: 290a 0a20 2020 2064 6566 2070 7269 6365  )..    def price
+00008570: 5f74 6f5f 7072 6563 6973 696f 6e28 7365  _to_precision(se
+00008580: 6c66 2c20 7061 6972 3a20 7374 722c 2070  lf, pair: str, p
+00008590: 7269 6365 3a20 666c 6f61 742c 202a 2c20  rice: float, *, 
+000085a0: 726f 756e 6469 6e67 5f6d 6f64 653a 2069  rounding_mode: i
+000085b0: 6e74 203d 2052 4f55 4e44 2920 2d3e 2066  nt = ROUND) -> f
+000085c0: 6c6f 6174 3a0a 2020 2020 2020 2020 2222  loat:.        ""
+000085d0: 220a 2020 2020 2020 2020 5265 7475 726e  ".        Return
+000085e0: 7320 7468 6520 7072 6963 6520 726f 756e  s the price roun
+000085f0: 6465 6420 746f 2074 6865 2070 7265 6369  ded to the preci
+00008600: 7369 6f6e 2074 6865 2045 7863 6861 6e67  sion the Exchang
+00008610: 6520 6163 6365 7074 732e 0a20 2020 2020  e accepts..     
+00008620: 2020 2054 6865 2064 6566 6175 6c74 2070     The default p
+00008630: 7269 6365 5f72 6f75 6e64 696e 675f 6d6f  rice_rounding_mo
+00008640: 6465 2069 6e20 636f 6e66 2069 7320 524f  de in conf is RO
+00008650: 554e 442e 0a20 2020 2020 2020 2046 6f72  UND..        For
+00008660: 2073 746f 706c 6f73 7320 6361 6c63 756c   stoploss calcul
+00008670: 6174 696f 6e73 2c20 6d75 7374 2075 7365  ations, must use
+00008680: 2052 4f55 4e44 5f55 5020 666f 7220 6c6f   ROUND_UP for lo
+00008690: 6e67 732c 2061 6e64 2052 4f55 4e44 5f44  ngs, and ROUND_D
+000086a0: 4f57 4e20 666f 7220 7368 6f72 7473 2e0a  OWN for shorts..
+000086b0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+000086c0: 2020 2020 7265 7475 726e 2070 7269 6365      return price
+000086d0: 5f74 6f5f 7072 6563 6973 696f 6e28 0a20  _to_precision(. 
+000086e0: 2020 2020 2020 2020 2020 2070 7269 6365             price
+000086f0: 2c20 7365 6c66 2e67 6574 5f70 7265 6369  , self.get_preci
+00008700: 7369 6f6e 5f70 7269 6365 2870 6169 7229  sion_price(pair)
+00008710: 2c20 7365 6c66 2e70 7265 6369 7369 6f6e  , self.precision
+00008720: 4d6f 6465 2c20 726f 756e 6469 6e67 5f6d  Mode, rounding_m
+00008730: 6f64 653d 726f 756e 6469 6e67 5f6d 6f64  ode=rounding_mod
+00008740: 650a 2020 2020 2020 2020 290a 0a20 2020  e.        )..   
+00008750: 2064 6566 2070 7269 6365 5f67 6574 5f6f   def price_get_o
+00008760: 6e65 5f70 6970 2873 656c 662c 2070 6169  ne_pip(self, pai
+00008770: 723a 2073 7472 2c20 7072 6963 653a 2066  r: str, price: f
+00008780: 6c6f 6174 2920 2d3e 2066 6c6f 6174 3a0a  loat) -> float:.
+00008790: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+000087a0: 2020 2020 4765 7473 2074 6865 2022 3120      Gets the "1 
+000087b0: 7069 7022 2076 616c 7565 2066 6f72 2074  pip" value for t
+000087c0: 6869 7320 7061 6972 2e0a 2020 2020 2020  his pair..      
+000087d0: 2020 5573 6564 2069 6e20 5072 6963 6546    Used in PriceF
+000087e0: 696c 7465 7220 746f 2063 616c 6375 6c61  ilter to calcula
+000087f0: 7465 2074 6865 2031 7069 7020 6d6f 7665  te the 1pip move
+00008800: 6d65 6e74 732e 0a20 2020 2020 2020 2022  ments..        "
+00008810: 2222 0a20 2020 2020 2020 2070 7265 6369  "".        preci
+00008820: 7369 6f6e 203d 2073 656c 662e 6d61 726b  sion = self.mark
+00008830: 6574 735b 7061 6972 5d5b 2270 7265 6369  ets[pair]["preci
+00008840: 7369 6f6e 225d 5b22 7072 6963 6522 5d0a  sion"]["price"].
+00008850: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00008860: 7072 6563 6973 696f 6e4d 6f64 6520 3d3d  precisionMode ==
+00008870: 2054 4943 4b5f 5349 5a45 3a0a 2020 2020   TICK_SIZE:.    
+00008880: 2020 2020 2020 2020 7265 7475 726e 2070          return p
+00008890: 7265 6369 7369 6f6e 0a20 2020 2020 2020  recision.       
+000088a0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+000088b0: 2020 2072 6574 7572 6e20 3120 2f20 706f     return 1 / po
+000088c0: 7728 3130 2c20 7072 6563 6973 696f 6e29  w(10, precision)
+000088d0: 0a0a 2020 2020 6465 6620 6765 745f 6d69  ..    def get_mi
+000088e0: 6e5f 7061 6972 5f73 7461 6b65 5f61 6d6f  n_pair_stake_amo
+000088f0: 756e 7428 0a20 2020 2020 2020 2073 656c  unt(.        sel
+00008900: 662c 2070 6169 723a 2073 7472 2c20 7072  f, pair: str, pr
+00008910: 6963 653a 2066 6c6f 6174 2c20 7374 6f70  ice: float, stop
+00008920: 6c6f 7373 3a20 666c 6f61 742c 206c 6576  loss: float, lev
+00008930: 6572 6167 653a 204f 7074 696f 6e61 6c5b  erage: Optional[
+00008940: 666c 6f61 745d 203d 2031 2e30 0a20 2020  float] = 1.0.   
+00008950: 2029 202d 3e20 4f70 7469 6f6e 616c 5b66   ) -> Optional[f
+00008960: 6c6f 6174 5d3a 0a20 2020 2020 2020 2072  loat]:.        r
+00008970: 6574 7572 6e20 7365 6c66 2e5f 6765 745f  eturn self._get_
+00008980: 7374 616b 655f 616d 6f75 6e74 5f6c 696d  stake_amount_lim
+00008990: 6974 2870 6169 722c 2070 7269 6365 2c20  it(pair, price, 
+000089a0: 7374 6f70 6c6f 7373 2c20 226d 696e 222c  stoploss, "min",
+000089b0: 206c 6576 6572 6167 6529 0a0a 2020 2020   leverage)..    
+000089c0: 6465 6620 6765 745f 6d61 785f 7061 6972  def get_max_pair
+000089d0: 5f73 7461 6b65 5f61 6d6f 756e 7428 7365  _stake_amount(se
+000089e0: 6c66 2c20 7061 6972 3a20 7374 722c 2070  lf, pair: str, p
+000089f0: 7269 6365 3a20 666c 6f61 742c 206c 6576  rice: float, lev
+00008a00: 6572 6167 653a 2066 6c6f 6174 203d 2031  erage: float = 1
+00008a10: 2e30 2920 2d3e 2066 6c6f 6174 3a0a 2020  .0) -> float:.  
+00008a20: 2020 2020 2020 6d61 785f 7374 616b 655f        max_stake_
+00008a30: 616d 6f75 6e74 203d 2073 656c 662e 5f67  amount = self._g
+00008a40: 6574 5f73 7461 6b65 5f61 6d6f 756e 745f  et_stake_amount_
+00008a50: 6c69 6d69 7428 7061 6972 2c20 7072 6963  limit(pair, pric
+00008a60: 652c 2030 2e30 2c20 226d 6178 222c 206c  e, 0.0, "max", l
+00008a70: 6576 6572 6167 6529 0a20 2020 2020 2020  everage).       
+00008a80: 2069 6620 6d61 785f 7374 616b 655f 616d   if max_stake_am
+00008a90: 6f75 6e74 2069 7320 4e6f 6e65 3a0a 2020  ount is None:.  
+00008aa0: 2020 2020 2020 2020 2020 2320 2a20 5368            # * Sh
+00008ab0: 6f75 6c64 206e 6576 6572 2062 6520 6578  ould never be ex
+00008ac0: 6563 7574 6564 0a20 2020 2020 2020 2020  ecuted.         
+00008ad0: 2020 2072 6169 7365 204f 7065 7261 7469     raise Operati
+00008ae0: 6f6e 616c 4578 6365 7074 696f 6e28 0a20  onalException(. 
+00008af0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00008b00: 227b 7365 6c66 2e6e 616d 657d 2e67 6574  "{self.name}.get
+00008b10: 5f6d 6178 5f70 6169 725f 7374 616b 655f  _max_pair_stake_
+00008b20: 616d 6f75 6e74 2073 686f 756c 6420 6e65  amount should ne
+00008b30: 7665 7220 7365 7420 6d61 785f 7374 616b  ver set max_stak
+00008b40: 655f 616d 6f75 6e74 2074 6f20 4e6f 6e65  e_amount to None
+00008b50: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
+00008b60: 2020 2020 2020 2020 7265 7475 726e 206d          return m
+00008b70: 6178 5f73 7461 6b65 5f61 6d6f 756e 740a  ax_stake_amount.
+00008b80: 0a20 2020 2064 6566 205f 6765 745f 7374  .    def _get_st
+00008b90: 616b 655f 616d 6f75 6e74 5f6c 696d 6974  ake_amount_limit
+00008ba0: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
+00008bb0: 2020 2020 2020 2020 7061 6972 3a20 7374          pair: st
+00008bc0: 722c 0a20 2020 2020 2020 2070 7269 6365  r,.        price
+00008bd0: 3a20 666c 6f61 742c 0a20 2020 2020 2020  : float,.       
+00008be0: 2073 746f 706c 6f73 733a 2066 6c6f 6174   stoploss: float
+00008bf0: 2c0a 2020 2020 2020 2020 6c69 6d69 743a  ,.        limit:
+00008c00: 204c 6974 6572 616c 5b22 6d69 6e22 2c20   Literal["min", 
+00008c10: 226d 6178 225d 2c0a 2020 2020 2020 2020  "max"],.        
+00008c20: 6c65 7665 7261 6765 3a20 4f70 7469 6f6e  leverage: Option
+00008c30: 616c 5b66 6c6f 6174 5d20 3d20 312e 302c  al[float] = 1.0,
+00008c40: 0a20 2020 2029 202d 3e20 4f70 7469 6f6e  .    ) -> Option
+00008c50: 616c 5b66 6c6f 6174 5d3a 0a20 2020 2020  al[float]:.     
+00008c60: 2020 2069 734d 696e 203d 206c 696d 6974     isMin = limit
+00008c70: 203d 3d20 226d 696e 220a 0a20 2020 2020   == "min"..     
+00008c80: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+00008c90: 2020 2020 6d61 726b 6574 203d 2073 656c      market = sel
+00008ca0: 662e 6d61 726b 6574 735b 7061 6972 5d0a  f.markets[pair].
+00008cb0: 2020 2020 2020 2020 6578 6365 7074 204b          except K
+00008cc0: 6579 4572 726f 723a 0a20 2020 2020 2020  eyError:.       
+00008cd0: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+00008ce0: 4572 726f 7228 6622 4361 6e27 7420 6765  Error(f"Can't ge
+00008cf0: 7420 6d61 726b 6574 2069 6e66 6f72 6d61  t market informa
+00008d00: 7469 6f6e 2066 6f72 2073 796d 626f 6c20  tion for symbol 
+00008d10: 7b70 6169 727d 2229 0a0a 2020 2020 2020  {pair}")..      
+00008d20: 2020 6966 2069 734d 696e 3a0a 2020 2020    if isMin:.    
+00008d30: 2020 2020 2020 2020 2320 7265 7365 7276          # reserv
+00008d40: 6520 736f 6d65 2070 6572 6365 6e74 2064  e some percent d
+00008d50: 6566 696e 6564 2069 6e20 636f 6e66 6967  efined in config
+00008d60: 2028 3525 2064 6566 6175 6c74 2920 2b20   (5% default) + 
+00008d70: 7374 6f70 6c6f 7373 0a20 2020 2020 2020  stoploss.       
+00008d80: 2020 2020 206d 6172 6769 6e5f 7265 7365       margin_rese
+00008d90: 7276 653a 2066 6c6f 6174 203d 2031 2e30  rve: float = 1.0
+00008da0: 202b 2073 656c 662e 5f63 6f6e 6669 672e   + self._config.
+00008db0: 6765 7428 0a20 2020 2020 2020 2020 2020  get(.           
+00008dc0: 2020 2020 2022 616d 6f75 6e74 5f72 6573       "amount_res
+00008dd0: 6572 7665 5f70 6572 6365 6e74 222c 2044  erve_percent", D
+00008de0: 4546 4155 4c54 5f41 4d4f 554e 545f 5245  EFAULT_AMOUNT_RE
+00008df0: 5345 5256 455f 5045 5243 454e 540a 2020  SERVE_PERCENT.  
+00008e00: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00008e10: 2020 2020 2020 2020 7374 6f70 6c6f 7373          stoploss
+00008e20: 5f72 6573 6572 7665 203d 206d 6172 6769  _reserve = margi
+00008e30: 6e5f 7265 7365 7276 6520 2f20 2831 202d  n_reserve / (1 -
+00008e40: 2061 6273 2873 746f 706c 6f73 7329 2920   abs(stoploss)) 
+00008e50: 6966 2061 6273 2873 746f 706c 6f73 7329  if abs(stoploss)
+00008e60: 2021 3d20 3120 656c 7365 2031 2e35 0a20   != 1 else 1.5. 
+00008e70: 2020 2020 2020 2020 2020 2023 2069 7420             # it 
+00008e80: 7368 6f75 6c64 206e 6f74 2062 6520 6d6f  should not be mo
+00008e90: 7265 2074 6861 6e20 3530 250a 2020 2020  re than 50%.    
+00008ea0: 2020 2020 2020 2020 7374 6f70 6c6f 7373          stoploss
+00008eb0: 5f72 6573 6572 7665 203d 206d 6178 286d  _reserve = max(m
+00008ec0: 696e 2873 746f 706c 6f73 735f 7265 7365  in(stoploss_rese
+00008ed0: 7276 652c 2031 2e35 292c 2031 290a 2020  rve, 1.5), 1).  
+00008ee0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00008ef0: 2020 2020 2020 2020 6d61 7267 696e 5f72          margin_r
+00008f00: 6573 6572 7665 203d 2031 2e30 0a20 2020  eserve = 1.0.   
+00008f10: 2020 2020 2020 2020 2073 746f 706c 6f73           stoplos
+00008f20: 735f 7265 7365 7276 6520 3d20 312e 300a  s_reserve = 1.0.
+00008f30: 0a20 2020 2020 2020 2073 7461 6b65 5f6c  .        stake_l
+00008f40: 696d 6974 7320 3d20 5b5d 0a20 2020 2020  imits = [].     
+00008f50: 2020 206c 696d 6974 7320 3d20 6d61 726b     limits = mark
+00008f60: 6574 5b22 6c69 6d69 7473 225d 0a20 2020  et["limits"].   
+00008f70: 2020 2020 2069 6620 6c69 6d69 7473 5b22       if limits["
+00008f80: 636f 7374 225d 5b6c 696d 6974 5d20 6973  cost"][limit] is
+00008f90: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+00008fa0: 2020 2020 2020 2073 7461 6b65 5f6c 696d         stake_lim
+00008fb0: 6974 732e 6170 7065 6e64 280a 2020 2020  its.append(.    
+00008fc0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00008fd0: 2e5f 636f 6e74 7261 6374 735f 746f 5f61  ._contracts_to_a
+00008fe0: 6d6f 756e 7428 7061 6972 2c20 6c69 6d69  mount(pair, limi
+00008ff0: 7473 5b22 636f 7374 225d 5b6c 696d 6974  ts["cost"][limit
+00009000: 5d29 202a 2073 746f 706c 6f73 735f 7265  ]) * stoploss_re
+00009010: 7365 7276 650a 2020 2020 2020 2020 2020  serve.          
+00009020: 2020 290a 0a20 2020 2020 2020 2069 6620    )..        if 
+00009030: 6c69 6d69 7473 5b22 616d 6f75 6e74 225d  limits["amount"]
+00009040: 5b6c 696d 6974 5d20 6973 206e 6f74 204e  [limit] is not N
+00009050: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+00009060: 2073 7461 6b65 5f6c 696d 6974 732e 6170   stake_limits.ap
+00009070: 7065 6e64 280a 2020 2020 2020 2020 2020  pend(.          
+00009080: 2020 2020 2020 7365 6c66 2e5f 636f 6e74        self._cont
+00009090: 7261 6374 735f 746f 5f61 6d6f 756e 7428  racts_to_amount(
+000090a0: 7061 6972 2c20 6c69 6d69 7473 5b22 616d  pair, limits["am
+000090b0: 6f75 6e74 225d 5b6c 696d 6974 5d29 202a  ount"][limit]) *
+000090c0: 2070 7269 6365 202a 206d 6172 6769 6e5f   price * margin_
+000090d0: 7265 7365 7276 650a 2020 2020 2020 2020  reserve.        
+000090e0: 2020 2020 290a 0a20 2020 2020 2020 2069      )..        i
+000090f0: 6620 6e6f 7420 7374 616b 655f 6c69 6d69  f not stake_limi
+00009100: 7473 3a0a 2020 2020 2020 2020 2020 2020  ts:.            
+00009110: 7265 7475 726e 204e 6f6e 6520 6966 2069  return None if i
+00009120: 734d 696e 2065 6c73 6520 666c 6f61 7428  sMin else float(
+00009130: 2269 6e66 2229 0a0a 2020 2020 2020 2020  "inf")..        
+00009140: 2320 5468 6520 7661 6c75 6520 7265 7475  # The value retu
+00009150: 726e 6564 2073 686f 756c 6420 7361 7469  rned should sati
+00009160: 7366 7920 626f 7468 206c 696d 6974 733a  sfy both limits:
+00009170: 2066 6f72 2061 6d6f 756e 7420 2862 6173   for amount (bas
+00009180: 6520 6375 7272 656e 6379 2920 616e 640a  e currency) and.
+00009190: 2020 2020 2020 2020 2320 666f 7220 636f          # for co
+000091a0: 7374 2028 7175 6f74 652c 2073 7461 6b65  st (quote, stake
+000091b0: 2063 7572 7265 6e63 7929 2c20 736f 206d   currency), so m
+000091c0: 6178 2829 2069 7320 7573 6564 2068 6572  ax() is used her
+000091d0: 652e 0a20 2020 2020 2020 2023 2053 6565  e..        # See
+000091e0: 2061 6c73 6f20 2332 3537 3520 6174 2067   also #2575 at g
+000091f0: 6974 6875 622e 0a20 2020 2020 2020 2072  ithub..        r
+00009200: 6574 7572 6e20 7365 6c66 2e5f 6765 745f  eturn self._get_
+00009210: 7374 616b 655f 616d 6f75 6e74 5f63 6f6e  stake_amount_con
+00009220: 7369 6465 7269 6e67 5f6c 6576 6572 6167  sidering_leverag
+00009230: 6528 0a20 2020 2020 2020 2020 2020 206d  e(.            m
+00009240: 6178 2873 7461 6b65 5f6c 696d 6974 7329  ax(stake_limits)
+00009250: 2069 6620 6973 4d69 6e20 656c 7365 206d   if isMin else m
+00009260: 696e 2873 7461 6b65 5f6c 696d 6974 7329  in(stake_limits)
+00009270: 2c20 6c65 7665 7261 6765 206f 7220 312e  , leverage or 1.
+00009280: 300a 2020 2020 2020 2020 290a 0a20 2020  0.        )..   
+00009290: 2064 6566 205f 6765 745f 7374 616b 655f   def _get_stake_
+000092a0: 616d 6f75 6e74 5f63 6f6e 7369 6465 7269  amount_consideri
+000092b0: 6e67 5f6c 6576 6572 6167 6528 7365 6c66  ng_leverage(self
+000092c0: 2c20 7374 616b 655f 616d 6f75 6e74 3a20  , stake_amount: 
+000092d0: 666c 6f61 742c 206c 6576 6572 6167 653a  float, leverage:
+000092e0: 2066 6c6f 6174 2920 2d3e 2066 6c6f 6174   float) -> float
+000092f0: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
+00009300: 2020 2020 2020 5461 6b65 7320 7468 6520        Takes the 
+00009310: 6d69 6e69 6d75 6d20 7374 616b 6520 616d  minimum stake am
+00009320: 6f75 6e74 2066 6f72 2061 2070 6169 7220  ount for a pair 
+00009330: 7769 7468 206e 6f20 6c65 7665 7261 6765  with no leverage
+00009340: 2061 6e64 2072 6574 7572 6e73 2074 6865   and returns the
+00009350: 206d 696e 696d 756d 0a20 2020 2020 2020   minimum.       
+00009360: 2073 7461 6b65 2061 6d6f 756e 7420 7768   stake amount wh
+00009370: 656e 206c 6576 6572 6167 6520 6973 2063  en leverage is c
+00009380: 6f6e 7369 6465 7265 640a 2020 2020 2020  onsidered.      
+00009390: 2020 3a70 6172 616d 2073 7461 6b65 5f61    :param stake_a
+000093a0: 6d6f 756e 743a 2054 6865 2073 7461 6b65  mount: The stake
+000093b0: 2061 6d6f 756e 7420 666f 7220 6120 7061   amount for a pa
+000093c0: 6972 2062 6566 6f72 6520 6c65 7665 7261  ir before levera
+000093d0: 6765 2069 7320 636f 6e73 6964 6572 6564  ge is considered
+000093e0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+000093f0: 6c65 7665 7261 6765 3a20 5468 6520 616d  leverage: The am
+00009400: 6f75 6e74 206f 6620 6c65 7665 7261 6765  ount of leverage
+00009410: 2062 6569 6e67 2075 7365 6420 6f6e 2074   being used on t
+00009420: 6865 2063 7572 7265 6e74 2074 7261 6465  he current trade
+00009430: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00009440: 2020 2020 2072 6574 7572 6e20 7374 616b       return stak
+00009450: 655f 616d 6f75 6e74 202f 206c 6576 6572  e_amount / lever
+00009460: 6167 650a 0a20 2020 2023 2044 7279 2d72  age..    # Dry-r
+00009470: 756e 206d 6574 686f 6473 0a0a 2020 2020  un methods..    
+00009480: 6465 6620 6372 6561 7465 5f64 7279 5f72  def create_dry_r
+00009490: 756e 5f6f 7264 6572 280a 2020 2020 2020  un_order(.      
+000094a0: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
+000094b0: 7061 6972 3a20 7374 722c 0a20 2020 2020  pair: str,.     
+000094c0: 2020 206f 7264 6572 7479 7065 3a20 7374     ordertype: st
+000094d0: 722c 0a20 2020 2020 2020 2073 6964 653a  r,.        side:
+000094e0: 2073 7472 2c0a 2020 2020 2020 2020 616d   str,.        am
+000094f0: 6f75 6e74 3a20 666c 6f61 742c 0a20 2020  ount: float,.   
+00009500: 2020 2020 2072 6174 653a 2066 6c6f 6174       rate: float
+00009510: 2c0a 2020 2020 2020 2020 6c65 7665 7261  ,.        levera
+00009520: 6765 3a20 666c 6f61 742c 0a20 2020 2020  ge: float,.     
+00009530: 2020 2070 6172 616d 733a 204f 7074 696f     params: Optio
+00009540: 6e61 6c5b 4469 6374 5d20 3d20 4e6f 6e65  nal[Dict] = None
+00009550: 2c0a 2020 2020 2020 2020 7374 6f70 5f6c  ,.        stop_l
+00009560: 6f73 733a 2062 6f6f 6c20 3d20 4661 6c73  oss: bool = Fals
+00009570: 652c 0a20 2020 2029 202d 3e20 4469 6374  e,.    ) -> Dict
+00009580: 5b73 7472 2c20 416e 795d 3a0a 2020 2020  [str, Any]:.    
+00009590: 2020 2020 6e6f 7720 3d20 6474 5f6e 6f77      now = dt_now
+000095a0: 2829 0a20 2020 2020 2020 206f 7264 6572  ().        order
+000095b0: 5f69 6420 3d20 6622 6472 795f 7275 6e5f  _id = f"dry_run_
+000095c0: 7b73 6964 657d 5f7b 7061 6972 7d5f 7b6e  {side}_{pair}_{n
+000095d0: 6f77 2e74 696d 6573 7461 6d70 2829 7d22  ow.timestamp()}"
+000095e0: 0a20 2020 2020 2020 2023 2052 6f75 6e64  .        # Round
+000095f0: 696e 6720 6865 7265 206d 7573 7420 7265  ing here must re
+00009600: 7370 6563 7420 746f 2063 6f6e 7472 6163  spect to contrac
+00009610: 7420 7369 7a65 730a 2020 2020 2020 2020  t sizes.        
+00009620: 5f61 6d6f 756e 7420 3d20 7365 6c66 2e5f  _amount = self._
+00009630: 636f 6e74 7261 6374 735f 746f 5f61 6d6f  contracts_to_amo
+00009640: 756e 7428 0a20 2020 2020 2020 2020 2020  unt(.           
+00009650: 2070 6169 722c 2073 656c 662e 616d 6f75   pair, self.amou
+00009660: 6e74 5f74 6f5f 7072 6563 6973 696f 6e28  nt_to_precision(
+00009670: 7061 6972 2c20 7365 6c66 2e5f 616d 6f75  pair, self._amou
+00009680: 6e74 5f74 6f5f 636f 6e74 7261 6374 7328  nt_to_contracts(
+00009690: 7061 6972 2c20 616d 6f75 6e74 2929 0a20  pair, amount)). 
+000096a0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+000096b0: 2064 7279 5f6f 7264 6572 3a20 4469 6374   dry_order: Dict
+000096c0: 5b73 7472 2c20 416e 795d 203d 207b 0a20  [str, Any] = {. 
+000096d0: 2020 2020 2020 2020 2020 2022 6964 223a             "id":
+000096e0: 206f 7264 6572 5f69 642c 0a20 2020 2020   order_id,.     
+000096f0: 2020 2020 2020 2022 7379 6d62 6f6c 223a         "symbol":
+00009700: 2070 6169 722c 0a20 2020 2020 2020 2020   pair,.         
+00009710: 2020 2022 7072 6963 6522 3a20 7261 7465     "price": rate
+00009720: 2c0a 2020 2020 2020 2020 2020 2020 2261  ,.            "a
+00009730: 7665 7261 6765 223a 2072 6174 652c 0a20  verage": rate,. 
+00009740: 2020 2020 2020 2020 2020 2022 616d 6f75             "amou
+00009750: 6e74 223a 205f 616d 6f75 6e74 2c0a 2020  nt": _amount,.  
+00009760: 2020 2020 2020 2020 2020 2263 6f73 7422            "cost"
+00009770: 3a20 5f61 6d6f 756e 7420 2a20 7261 7465  : _amount * rate
+00009780: 2c0a 2020 2020 2020 2020 2020 2020 2274  ,.            "t
+00009790: 7970 6522 3a20 6f72 6465 7274 7970 652c  ype": ordertype,
+000097a0: 0a20 2020 2020 2020 2020 2020 2022 7369  .            "si
+000097b0: 6465 223a 2073 6964 652c 0a20 2020 2020  de": side,.     
+000097c0: 2020 2020 2020 2022 6669 6c6c 6564 223a         "filled":
+000097d0: 2030 2c0a 2020 2020 2020 2020 2020 2020   0,.            
+000097e0: 2272 656d 6169 6e69 6e67 223a 205f 616d  "remaining": _am
+000097f0: 6f75 6e74 2c0a 2020 2020 2020 2020 2020  ount,.          
+00009800: 2020 2264 6174 6574 696d 6522 3a20 6e6f    "datetime": no
+00009810: 772e 7374 7266 7469 6d65 2822 2559 2d25  w.strftime("%Y-%
+00009820: 6d2d 2564 5425 483a 254d 3a25 532e 2566  m-%dT%H:%M:%S.%f
+00009830: 5a22 292c 0a20 2020 2020 2020 2020 2020  Z"),.           
+00009840: 2022 7469 6d65 7374 616d 7022 3a20 6474   "timestamp": dt
+00009850: 5f74 7328 6e6f 7729 2c0a 2020 2020 2020  _ts(now),.      
+00009860: 2020 2020 2020 2273 7461 7475 7322 3a20        "status": 
+00009870: 226f 7065 6e22 2c0a 2020 2020 2020 2020  "open",.        
+00009880: 2020 2020 2266 6565 223a 204e 6f6e 652c      "fee": None,
+00009890: 0a20 2020 2020 2020 2020 2020 2022 696e  .            "in
+000098a0: 666f 223a 207b 7d2c 0a20 2020 2020 2020  fo": {},.       
+000098b0: 2020 2020 2022 6c65 7665 7261 6765 223a       "leverage":
+000098c0: 206c 6576 6572 6167 652c 0a20 2020 2020   leverage,.     
+000098d0: 2020 207d 0a20 2020 2020 2020 2069 6620     }.        if 
+000098e0: 7374 6f70 5f6c 6f73 733a 0a20 2020 2020  stop_loss:.     
+000098f0: 2020 2020 2020 2064 7279 5f6f 7264 6572         dry_order
+00009900: 5b22 696e 666f 225d 203d 207b 2273 746f  ["info"] = {"sto
+00009910: 7050 7269 6365 223a 2064 7279 5f6f 7264  pPrice": dry_ord
+00009920: 6572 5b22 7072 6963 6522 5d7d 0a20 2020  er["price"]}.   
+00009930: 2020 2020 2020 2020 2064 7279 5f6f 7264           dry_ord
+00009940: 6572 5b73 656c 662e 5f66 745f 6861 735b  er[self._ft_has[
+00009950: 2273 746f 705f 7072 6963 655f 7072 6f70  "stop_price_prop
+00009960: 225d 5d20 3d20 6472 795f 6f72 6465 725b  "]] = dry_order[
+00009970: 2270 7269 6365 225d 0a20 2020 2020 2020  "price"].       
+00009980: 2020 2020 2023 2057 6f72 6b61 726f 756e       # Workaroun
+00009990: 6420 746f 2061 766f 6964 2066 696c 6c69  d to avoid filli
+000099a0: 6e67 2073 746f 706c 6f73 7320 6f72 6465  ng stoploss orde
+000099b0: 7273 2069 6d6d 6564 6961 7465 6c79 0a20  rs immediately. 
+000099c0: 2020 2020 2020 2020 2020 2064 7279 5f6f             dry_o
+000099d0: 7264 6572 5b22 6674 5f6f 7264 6572 5f74  rder["ft_order_t
+000099e0: 7970 6522 5d20 3d20 2273 746f 706c 6f73  ype"] = "stoplos
+000099f0: 7322 0a20 2020 2020 2020 206f 7264 6572  s".        order
+00009a00: 626f 6f6b 3a20 4f70 7469 6f6e 616c 5b4f  book: Optional[O
+00009a10: 7264 6572 426f 6f6b 5d20 3d20 4e6f 6e65  rderBook] = None
+00009a20: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00009a30: 2e65 7863 6861 6e67 655f 6861 7328 2266  .exchange_has("f
+00009a40: 6574 6368 4c32 4f72 6465 7242 6f6f 6b22  etchL2OrderBook"
+00009a50: 293a 0a20 2020 2020 2020 2020 2020 206f  ):.            o
+00009a60: 7264 6572 626f 6f6b 203d 2073 656c 662e  rderbook = self.
+00009a70: 6665 7463 685f 6c32 5f6f 7264 6572 5f62  fetch_l2_order_b
+00009a80: 6f6f 6b28 7061 6972 2c20 3230 290a 2020  ook(pair, 20).  
+00009a90: 2020 2020 2020 6966 206f 7264 6572 7479        if orderty
+00009aa0: 7065 203d 3d20 226c 696d 6974 2220 616e  pe == "limit" an
+00009ab0: 6420 6f72 6465 7262 6f6f 6b3a 0a20 2020  d orderbook:.   
+00009ac0: 2020 2020 2020 2020 2023 2041 6c6c 6f77           # Allow
+00009ad0: 2061 2031 2520 7072 6963 6520 6469 6666   a 1% price diff
+00009ae0: 6572 656e 6365 0a20 2020 2020 2020 2020  erence.         
+00009af0: 2020 2061 6c6c 6f77 6564 5f64 6966 6620     allowed_diff 
+00009b00: 3d20 302e 3031 0a20 2020 2020 2020 2020  = 0.01.         
+00009b10: 2020 2069 6620 7365 6c66 2e5f 6472 795f     if self._dry_
+00009b20: 6973 5f70 7269 6365 5f63 726f 7373 6564  is_price_crossed
+00009b30: 2870 6169 722c 2073 6964 652c 2072 6174  (pair, side, rat
+00009b40: 652c 206f 7264 6572 626f 6f6b 2c20 616c  e, orderbook, al
+00009b50: 6c6f 7765 645f 6469 6666 293a 0a20 2020  lowed_diff):.   
+00009b60: 2020 2020 2020 2020 2020 2020 206c 6f67               log
+00009b70: 6765 722e 696e 666f 280a 2020 2020 2020  ger.info(.      
+00009b80: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+00009b90: 436f 6e76 6572 7465 6420 6f72 6465 7220  Converted order 
+00009ba0: 7b70 6169 727d 2074 6f20 6d61 726b 6574  {pair} to market
+00009bb0: 206f 7264 6572 2064 7565 2074 6f20 7072   order due to pr
+00009bc0: 6963 6520 7b72 6174 657d 2063 726f 7373  ice {rate} cross
+00009bd0: 696e 6720 7370 7265 6164 2022 0a20 2020  ing spread ".   
+00009be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009bf0: 2066 2262 7920 6d6f 7265 2074 6861 6e20   f"by more than 
+00009c00: 7b61 6c6c 6f77 6564 5f64 6966 663a 2e32  {allowed_diff:.2
+00009c10: 257d 2e22 0a20 2020 2020 2020 2020 2020  %}.".           
+00009c20: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00009c30: 2020 2020 2020 2064 7279 5f6f 7264 6572         dry_order
+00009c40: 5b22 7479 7065 225d 203d 2022 6d61 726b  ["type"] = "mark
+00009c50: 6574 220a 0a20 2020 2020 2020 2069 6620  et"..        if 
+00009c60: 6472 795f 6f72 6465 725b 2274 7970 6522  dry_order["type"
+00009c70: 5d20 3d3d 2022 6d61 726b 6574 2220 616e  ] == "market" an
+00009c80: 6420 6e6f 7420 6472 795f 6f72 6465 722e  d not dry_order.
+00009c90: 6765 7428 2266 745f 6f72 6465 725f 7479  get("ft_order_ty
+00009ca0: 7065 2229 3a0a 2020 2020 2020 2020 2020  pe"):.          
+00009cb0: 2020 2320 5570 6461 7465 206d 6172 6b65    # Update marke
+00009cc0: 7420 6f72 6465 7220 7072 6963 696e 670a  t order pricing.
+00009cd0: 2020 2020 2020 2020 2020 2020 6176 6572              aver
+00009ce0: 6167 6520 3d20 7365 6c66 2e67 6574 5f64  age = self.get_d
+00009cf0: 7279 5f6d 6172 6b65 745f 6669 6c6c 5f70  ry_market_fill_p
+00009d00: 7269 6365 2870 6169 722c 2073 6964 652c  rice(pair, side,
+00009d10: 2061 6d6f 756e 742c 2072 6174 652c 206f   amount, rate, o
+00009d20: 7264 6572 626f 6f6b 290a 2020 2020 2020  rderbook).      
+00009d30: 2020 2020 2020 6472 795f 6f72 6465 722e        dry_order.
+00009d40: 7570 6461 7465 280a 2020 2020 2020 2020  update(.        
+00009d50: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00009d60: 2020 2020 2020 2020 2020 2020 2020 2261                "a
+00009d70: 7665 7261 6765 223a 2061 7665 7261 6765  verage": average
+00009d80: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00009d90: 2020 2020 2020 2266 696c 6c65 6422 3a20        "filled": 
+00009da0: 5f61 6d6f 756e 742c 0a20 2020 2020 2020  _amount,.       
+00009db0: 2020 2020 2020 2020 2020 2020 2022 7265               "re
+00009dc0: 6d61 696e 696e 6722 3a20 302e 302c 0a20  maining": 0.0,. 
+00009dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009de0: 2020 2022 7374 6174 7573 223a 2022 636c     "status": "cl
+00009df0: 6f73 6564 222c 0a20 2020 2020 2020 2020  osed",.         
+00009e00: 2020 2020 2020 2020 2020 2022 636f 7374             "cost
+00009e10: 223a 2028 6472 795f 6f72 6465 725b 2261  ": (dry_order["a
+00009e20: 6d6f 756e 7422 5d20 2a20 6176 6572 6167  mount"] * averag
+00009e30: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
+00009e40: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
+00009e50: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00009e60: 2320 6d61 726b 6574 206f 7264 6572 7320  # market orders 
+00009e70: 7769 6c6c 2061 6c77 6179 7320 696e 6375  will always incu
+00009e80: 7272 2074 616b 6572 2066 6565 730a 2020  rr taker fees.  
+00009e90: 2020 2020 2020 2020 2020 6472 795f 6f72            dry_or
+00009ea0: 6465 7220 3d20 7365 6c66 2e61 6464 5f64  der = self.add_d
+00009eb0: 7279 5f6f 7264 6572 5f66 6565 2870 6169  ry_order_fee(pai
+00009ec0: 722c 2064 7279 5f6f 7264 6572 2c20 2274  r, dry_order, "t
+00009ed0: 616b 6572 2229 0a0a 2020 2020 2020 2020  aker")..        
+00009ee0: 6472 795f 6f72 6465 7220 3d20 7365 6c66  dry_order = self
+00009ef0: 2e63 6865 636b 5f64 7279 5f6c 696d 6974  .check_dry_limit
+00009f00: 5f6f 7264 6572 5f66 696c 6c65 6428 0a20  _order_filled(. 
+00009f10: 2020 2020 2020 2020 2020 2064 7279 5f6f             dry_o
+00009f20: 7264 6572 2c20 696d 6d65 6469 6174 653d  rder, immediate=
+00009f30: 5472 7565 2c20 6f72 6465 7262 6f6f 6b3d  True, orderbook=
+00009f40: 6f72 6465 7262 6f6f 6b0a 2020 2020 2020  orderbook.      
+00009f50: 2020 290a 0a20 2020 2020 2020 2073 656c    )..        sel
+00009f60: 662e 5f64 7279 5f72 756e 5f6f 7065 6e5f  f._dry_run_open_
+00009f70: 6f72 6465 7273 5b64 7279 5f6f 7264 6572  orders[dry_order
+00009f80: 5b22 6964 225d 5d20 3d20 6472 795f 6f72  ["id"]] = dry_or
+00009f90: 6465 720a 2020 2020 2020 2020 2320 436f  der.        # Co
+00009fa0: 7079 206f 7264 6572 2061 6e64 2063 6c6f  py order and clo
+00009fb0: 7365 2069 7420 2d20 736f 2074 6865 2072  se it - so the r
+00009fc0: 6574 7572 6e65 6420 6f72 6465 7220 6973  eturned order is
+00009fd0: 206f 7065 6e20 756e 6c65 7373 2069 7427   open unless it'
+00009fe0: 7320 6120 6d61 726b 6574 206f 7264 6572  s a market order
+00009ff0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000a000: 6472 795f 6f72 6465 720a 0a20 2020 2064  dry_order..    d
+0000a010: 6566 2061 6464 5f64 7279 5f6f 7264 6572  ef add_dry_order
+0000a020: 5f66 6565 280a 2020 2020 2020 2020 7365  _fee(.        se
+0000a030: 6c66 2c0a 2020 2020 2020 2020 7061 6972  lf,.        pair
+0000a040: 3a20 7374 722c 0a20 2020 2020 2020 2064  : str,.        d
+0000a050: 7279 5f6f 7264 6572 3a20 4469 6374 5b73  ry_order: Dict[s
+0000a060: 7472 2c20 416e 795d 2c0a 2020 2020 2020  tr, Any],.      
+0000a070: 2020 7461 6b65 725f 6f72 5f6d 616b 6572    taker_or_maker
+0000a080: 3a20 4d61 6b65 7254 616b 6572 2c0a 2020  : MakerTaker,.  
+0000a090: 2020 2920 2d3e 2044 6963 745b 7374 722c    ) -> Dict[str,
+0000a0a0: 2041 6e79 5d3a 0a20 2020 2020 2020 2066   Any]:.        f
+0000a0b0: 6565 203d 2073 656c 662e 6765 745f 6665  ee = self.get_fe
+0000a0c0: 6528 7061 6972 2c20 7461 6b65 725f 6f72  e(pair, taker_or
+0000a0d0: 5f6d 616b 6572 3d74 616b 6572 5f6f 725f  _maker=taker_or_
+0000a0e0: 6d61 6b65 7229 0a20 2020 2020 2020 2064  maker).        d
+0000a0f0: 7279 5f6f 7264 6572 2e75 7064 6174 6528  ry_order.update(
+0000a100: 0a20 2020 2020 2020 2020 2020 207b 0a20  .            {. 
+0000a110: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000a120: 6665 6522 3a20 7b0a 2020 2020 2020 2020  fee": {.        
+0000a130: 2020 2020 2020 2020 2020 2020 2263 7572              "cur
+0000a140: 7265 6e63 7922 3a20 7365 6c66 2e67 6574  rency": self.get
+0000a150: 5f70 6169 725f 7175 6f74 655f 6375 7272  _pair_quote_curr
+0000a160: 656e 6379 2870 6169 7229 2c0a 2020 2020  ency(pair),.    
+0000a170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a180: 2263 6f73 7422 3a20 6472 795f 6f72 6465  "cost": dry_orde
+0000a190: 725b 2263 6f73 7422 5d20 2a20 6665 652c  r["cost"] * fee,
+0000a1a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a1b0: 2020 2020 2022 7261 7465 223a 2066 6565       "rate": fee
+0000a1c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a1d0: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
+0000a1e0: 7d0a 2020 2020 2020 2020 290a 2020 2020  }.        ).    
+0000a1f0: 2020 2020 7265 7475 726e 2064 7279 5f6f      return dry_o
+0000a200: 7264 6572 0a0a 2020 2020 6465 6620 6765  rder..    def ge
+0000a210: 745f 6472 795f 6d61 726b 6574 5f66 696c  t_dry_market_fil
+0000a220: 6c5f 7072 6963 6528 0a20 2020 2020 2020  l_price(.       
+0000a230: 2073 656c 662c 2070 6169 723a 2073 7472   self, pair: str
+0000a240: 2c20 7369 6465 3a20 7374 722c 2061 6d6f  , side: str, amo
+0000a250: 756e 743a 2066 6c6f 6174 2c20 7261 7465  unt: float, rate
+0000a260: 3a20 666c 6f61 742c 206f 7264 6572 626f  : float, orderbo
+0000a270: 6f6b 3a20 4f70 7469 6f6e 616c 5b4f 7264  ok: Optional[Ord
+0000a280: 6572 426f 6f6b 5d0a 2020 2020 2920 2d3e  erBook].    ) ->
+0000a290: 2066 6c6f 6174 3a0a 2020 2020 2020 2020   float:.        
+0000a2a0: 2222 220a 2020 2020 2020 2020 4765 7420  """.        Get 
+0000a2b0: 7468 6520 6d61 726b 6574 206f 7264 6572  the market order
+0000a2c0: 2066 696c 6c20 7072 6963 6520 6261 7365   fill price base
+0000a2d0: 6420 6f6e 206f 7264 6572 626f 6f6b 2069  d on orderbook i
+0000a2e0: 6e74 6572 706f 6c61 7469 6f6e 0a20 2020  nterpolation.   
+0000a2f0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+0000a300: 2069 6620 7365 6c66 2e65 7863 6861 6e67   if self.exchang
+0000a310: 655f 6861 7328 2266 6574 6368 4c32 4f72  e_has("fetchL2Or
+0000a320: 6465 7242 6f6f 6b22 293a 0a20 2020 2020  derBook"):.     
+0000a330: 2020 2020 2020 2069 6620 6e6f 7420 6f72         if not or
+0000a340: 6465 7262 6f6f 6b3a 0a20 2020 2020 2020  derbook:.       
+0000a350: 2020 2020 2020 2020 206f 7264 6572 626f           orderbo
+0000a360: 6f6b 203d 2073 656c 662e 6665 7463 685f  ok = self.fetch_
+0000a370: 6c32 5f6f 7264 6572 5f62 6f6f 6b28 7061  l2_order_book(pa
+0000a380: 6972 2c20 3230 290a 2020 2020 2020 2020  ir, 20).        
+0000a390: 2020 2020 6f62 5f74 7970 653a 204f 424c      ob_type: OBL
+0000a3a0: 6974 6572 616c 203d 2022 6173 6b73 2220  iteral = "asks" 
+0000a3b0: 6966 2073 6964 6520 3d3d 2022 6275 7922  if side == "buy"
+0000a3c0: 2065 6c73 6520 2262 6964 7322 0a20 2020   else "bids".   
+0000a3d0: 2020 2020 2020 2020 2073 6c69 7070 6167           slippag
+0000a3e0: 6520 3d20 302e 3035 0a20 2020 2020 2020  e = 0.05.       
+0000a3f0: 2020 2020 206d 6178 5f73 6c69 7070 6167       max_slippag
+0000a400: 655f 7661 6c20 3d20 7261 7465 202a 2028  e_val = rate * (
+0000a410: 2831 202b 2073 6c69 7070 6167 6529 2069  (1 + slippage) i
+0000a420: 6620 7369 6465 203d 3d20 2262 7579 2220  f side == "buy" 
+0000a430: 656c 7365 2028 3120 2d20 736c 6970 7061  else (1 - slippa
+0000a440: 6765 2929 0a0a 2020 2020 2020 2020 2020  ge))..          
+0000a450: 2020 7265 6d61 696e 696e 675f 616d 6f75    remaining_amou
+0000a460: 6e74 203d 2061 6d6f 756e 740a 2020 2020  nt = amount.    
+0000a470: 2020 2020 2020 2020 6669 6c6c 6564 5f76          filled_v
+0000a480: 616c 7565 203d 2030 2e30 0a20 2020 2020  alue = 0.0.     
+0000a490: 2020 2020 2020 2062 6f6f 6b5f 656e 7472         book_entr
+0000a4a0: 795f 7072 6963 6520 3d20 302e 300a 2020  y_price = 0.0.  
+0000a4b0: 2020 2020 2020 2020 2020 666f 7220 626f            for bo
+0000a4c0: 6f6b 5f65 6e74 7279 2069 6e20 6f72 6465  ok_entry in orde
+0000a4d0: 7262 6f6f 6b5b 6f62 5f74 7970 655d 3a0a  rbook[ob_type]:.
+0000a4e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a4f0: 626f 6f6b 5f65 6e74 7279 5f70 7269 6365  book_entry_price
+0000a500: 203d 2062 6f6f 6b5f 656e 7472 795b 305d   = book_entry[0]
+0000a510: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a520: 2062 6f6f 6b5f 656e 7472 795f 636f 696e   book_entry_coin
+0000a530: 5f76 6f6c 756d 6520 3d20 626f 6f6b 5f65  _volume = book_e
+0000a540: 6e74 7279 5b31 5d0a 2020 2020 2020 2020  ntry[1].        
+0000a550: 2020 2020 2020 2020 6966 2072 656d 6169          if remai
+0000a560: 6e69 6e67 5f61 6d6f 756e 7420 3e20 303a  ning_amount > 0:
+0000a570: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a580: 2020 2020 2069 6620 7265 6d61 696e 696e       if remainin
+0000a590: 675f 616d 6f75 6e74 203c 2062 6f6f 6b5f  g_amount < book_
+0000a5a0: 656e 7472 795f 636f 696e 5f76 6f6c 756d  entry_coin_volum
+0000a5b0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+0000a5c0: 2020 2020 2020 2020 2020 2023 204f 7264             # Ord
+0000a5d0: 6572 626f 6f6b 2061 7420 7468 6973 2073  erbook at this s
+0000a5e0: 6c6f 7420 6269 6767 6572 2074 6861 6e20  lot bigger than 
+0000a5f0: 7265 6d61 696e 696e 6720 616d 6f75 6e74  remaining amount
+0000a600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a610: 2020 2020 2020 2020 2066 696c 6c65 645f           filled_
+0000a620: 7661 6c75 6520 2b3d 2072 656d 6169 6e69  value += remaini
+0000a630: 6e67 5f61 6d6f 756e 7420 2a20 626f 6f6b  ng_amount * book
+0000a640: 5f65 6e74 7279 5f70 7269 6365 0a20 2020  _entry_price.   
+0000a650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a660: 2020 2020 2062 7265 616b 0a20 2020 2020       break.     
+0000a670: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0000a680: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0000a690: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+0000a6a0: 6c65 645f 7661 6c75 6520 2b3d 2062 6f6f  led_value += boo
+0000a6b0: 6b5f 656e 7472 795f 636f 696e 5f76 6f6c  k_entry_coin_vol
+0000a6c0: 756d 6520 2a20 626f 6f6b 5f65 6e74 7279  ume * book_entry
+0000a6d0: 5f70 7269 6365 0a20 2020 2020 2020 2020  _price.         
+0000a6e0: 2020 2020 2020 2020 2020 2072 656d 6169             remai
+0000a6f0: 6e69 6e67 5f61 6d6f 756e 7420 2d3d 2062  ning_amount -= b
+0000a700: 6f6f 6b5f 656e 7472 795f 636f 696e 5f76  ook_entry_coin_v
+0000a710: 6f6c 756d 650a 2020 2020 2020 2020 2020  olume.          
+0000a720: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0000a730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a740: 6272 6561 6b0a 2020 2020 2020 2020 2020  break.          
+0000a750: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0000a760: 2020 2020 2020 2020 2320 4966 2072 656d          # If rem
+0000a770: 6169 6e69 6e67 5f61 6d6f 756e 7420 7761  aining_amount wa
+0000a780: 736e 2774 2063 6f6e 7375 6d65 6420 636f  sn't consumed co
+0000a790: 6d70 6c65 7465 6c79 2028 6272 6561 6b20  mpletely (break 
+0000a7a0: 7761 7320 6e6f 7420 6361 6c6c 6564 290a  was not called).
+0000a7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a7c0: 6669 6c6c 6564 5f76 616c 7565 202b 3d20  filled_value += 
+0000a7d0: 7265 6d61 696e 696e 675f 616d 6f75 6e74  remaining_amount
+0000a7e0: 202a 2062 6f6f 6b5f 656e 7472 795f 7072   * book_entry_pr
+0000a7f0: 6963 650a 2020 2020 2020 2020 2020 2020  ice.            
+0000a800: 666f 7265 6361 7374 5f61 7667 5f66 696c  forecast_avg_fil
+0000a810: 6c65 645f 7072 6963 6520 3d20 6d61 7828  led_price = max(
+0000a820: 6669 6c6c 6564 5f76 616c 7565 2c20 3029  filled_value, 0)
+0000a830: 202f 2061 6d6f 756e 740a 2020 2020 2020   / amount.      
+0000a840: 2020 2020 2020 2320 4c69 6d69 7420 6d61        # Limit ma
+0000a850: 782e 2073 6c69 7070 6167 6520 746f 2073  x. slippage to s
+0000a860: 7065 6369 6669 6564 2076 616c 7565 0a20  pecified value. 
+0000a870: 2020 2020 2020 2020 2020 2069 6620 7369             if si
+0000a880: 6465 203d 3d20 2262 7579 223a 0a20 2020  de == "buy":.   
+0000a890: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+0000a8a0: 6563 6173 745f 6176 675f 6669 6c6c 6564  ecast_avg_filled
+0000a8b0: 5f70 7269 6365 203d 206d 696e 2866 6f72  _price = min(for
+0000a8c0: 6563 6173 745f 6176 675f 6669 6c6c 6564  ecast_avg_filled
+0000a8d0: 5f70 7269 6365 2c20 6d61 785f 736c 6970  _price, max_slip
+0000a8e0: 7061 6765 5f76 616c 290a 0a20 2020 2020  page_val)..     
+0000a8f0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0000a900: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+0000a910: 6563 6173 745f 6176 675f 6669 6c6c 6564  ecast_avg_filled
+0000a920: 5f70 7269 6365 203d 206d 6178 2866 6f72  _price = max(for
+0000a930: 6563 6173 745f 6176 675f 6669 6c6c 6564  ecast_avg_filled
+0000a940: 5f70 7269 6365 2c20 6d61 785f 736c 6970  _price, max_slip
+0000a950: 7061 6765 5f76 616c 290a 0a20 2020 2020  page_val)..     
+0000a960: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+0000a970: 6c66 2e70 7269 6365 5f74 6f5f 7072 6563  lf.price_to_prec
+0000a980: 6973 696f 6e28 7061 6972 2c20 666f 7265  ision(pair, fore
+0000a990: 6361 7374 5f61 7667 5f66 696c 6c65 645f  cast_avg_filled_
+0000a9a0: 7072 6963 6529 0a0a 2020 2020 2020 2020  price)..        
+0000a9b0: 7265 7475 726e 2072 6174 650a 0a20 2020  return rate..   
+0000a9c0: 2064 6566 205f 6472 795f 6973 5f70 7269   def _dry_is_pri
+0000a9d0: 6365 5f63 726f 7373 6564 280a 2020 2020  ce_crossed(.    
+0000a9e0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+0000a9f0: 2020 7061 6972 3a20 7374 722c 0a20 2020    pair: str,.   
+0000aa00: 2020 2020 2073 6964 653a 2073 7472 2c0a       side: str,.
+0000aa10: 2020 2020 2020 2020 6c69 6d69 743a 2066          limit: f
+0000aa20: 6c6f 6174 2c0a 2020 2020 2020 2020 6f72  loat,.        or
+0000aa30: 6465 7262 6f6f 6b3a 204f 7074 696f 6e61  derbook: Optiona
+0000aa40: 6c5b 4f72 6465 7242 6f6f 6b5d 203d 204e  l[OrderBook] = N
+0000aa50: 6f6e 652c 0a20 2020 2020 2020 206f 6666  one,.        off
+0000aa60: 7365 743a 2066 6c6f 6174 203d 2030 2e30  set: float = 0.0
+0000aa70: 2c0a 2020 2020 2920 2d3e 2062 6f6f 6c3a  ,.    ) -> bool:
+0000aa80: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+0000aa90: 7365 6c66 2e65 7863 6861 6e67 655f 6861  self.exchange_ha
+0000aaa0: 7328 2266 6574 6368 4c32 4f72 6465 7242  s("fetchL2OrderB
+0000aab0: 6f6f 6b22 293a 0a20 2020 2020 2020 2020  ook"):.         
+0000aac0: 2020 2072 6574 7572 6e20 5472 7565 0a20     return True. 
+0000aad0: 2020 2020 2020 2069 6620 6e6f 7420 6f72         if not or
+0000aae0: 6465 7262 6f6f 6b3a 0a20 2020 2020 2020  derbook:.       
+0000aaf0: 2020 2020 206f 7264 6572 626f 6f6b 203d       orderbook =
+0000ab00: 2073 656c 662e 6665 7463 685f 6c32 5f6f   self.fetch_l2_o
+0000ab10: 7264 6572 5f62 6f6f 6b28 7061 6972 2c20  rder_book(pair, 
+0000ab20: 3129 0a20 2020 2020 2020 2074 7279 3a0a  1).        try:.
+0000ab30: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+0000ab40: 6964 6520 3d3d 2022 6275 7922 3a0a 2020  ide == "buy":.  
+0000ab50: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+0000ab60: 6963 6520 3d20 6f72 6465 7262 6f6f 6b5b  ice = orderbook[
+0000ab70: 2261 736b 7322 5d5b 305d 5b30 5d0a 2020  "asks"][0][0].  
+0000ab80: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000ab90: 206c 696d 6974 202a 2028 3120 2d20 6f66   limit * (1 - of
+0000aba0: 6673 6574 2920 3e3d 2070 7269 6365 3a0a  fset) >= price:.
+0000abb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000abc0: 2020 2020 7265 7475 726e 2054 7275 650a      return True.
+0000abd0: 2020 2020 2020 2020 2020 2020 656c 7365              else
+0000abe0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000abf0: 2020 7072 6963 6520 3d20 6f72 6465 7262    price = orderb
+0000ac00: 6f6f 6b5b 2262 6964 7322 5d5b 305d 5b30  ook["bids"][0][0
+0000ac10: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+0000ac20: 2020 6966 206c 696d 6974 202a 2028 3120    if limit * (1 
+0000ac30: 2b20 6f66 6673 6574 2920 3c3d 2070 7269  + offset) <= pri
+0000ac40: 6365 3a0a 2020 2020 2020 2020 2020 2020  ce:.            
+0000ac50: 2020 2020 2020 2020 7265 7475 726e 2054          return T
+0000ac60: 7275 650a 2020 2020 2020 2020 6578 6365  rue.        exce
+0000ac70: 7074 2049 6e64 6578 4572 726f 723a 0a20  pt IndexError:. 
+0000ac80: 2020 2020 2020 2020 2020 2023 2049 676e             # Ign
+0000ac90: 6f72 6520 656d 7074 7920 6f72 6465 7262  ore empty orderb
+0000aca0: 6f6f 6b73 2077 6865 6e20 6669 6c6c 696e  ooks when fillin
+0000acb0: 6720 2d20 6361 6e20 6265 2066 696c 6c65  g - can be fille
+0000acc0: 6420 7769 7468 2074 6865 206e 6578 7420  d with the next 
+0000acd0: 6974 6572 6174 696f 6e2e 0a20 2020 2020  iteration..     
+0000ace0: 2020 2020 2020 2070 6173 730a 2020 2020         pass.    
+0000acf0: 2020 2020 7265 7475 726e 2046 616c 7365      return False
+0000ad00: 0a0a 2020 2020 6465 6620 6368 6563 6b5f  ..    def check_
+0000ad10: 6472 795f 6c69 6d69 745f 6f72 6465 725f  dry_limit_order_
+0000ad20: 6669 6c6c 6564 280a 2020 2020 2020 2020  filled(.        
+0000ad30: 7365 6c66 2c20 6f72 6465 723a 2044 6963  self, order: Dic
+0000ad40: 745b 7374 722c 2041 6e79 5d2c 2069 6d6d  t[str, Any], imm
+0000ad50: 6564 6961 7465 3a20 626f 6f6c 203d 2046  ediate: bool = F
+0000ad60: 616c 7365 2c20 6f72 6465 7262 6f6f 6b3a  alse, orderbook:
+0000ad70: 204f 7074 696f 6e61 6c5b 4f72 6465 7242   Optional[OrderB
+0000ad80: 6f6f 6b5d 203d 204e 6f6e 650a 2020 2020  ook] = None.    
+0000ad90: 2920 2d3e 2044 6963 745b 7374 722c 2041  ) -> Dict[str, A
+0000ada0: 6e79 5d3a 0a20 2020 2020 2020 2022 2222  ny]:.        """
+0000adb0: 0a20 2020 2020 2020 2043 6865 636b 2064  .        Check d
+0000adc0: 7279 2d72 756e 206c 696d 6974 206f 7264  ry-run limit ord
+0000add0: 6572 2066 696c 6c20 616e 6420 7570 6461  er fill and upda
+0000ade0: 7465 2066 6565 2028 6966 2069 7420 6669  te fee (if it fi
+0000adf0: 6c6c 6564 292e 0a20 2020 2020 2020 2022  lled)..        "
+0000ae00: 2222 0a20 2020 2020 2020 2069 6620 280a  "".        if (.
+0000ae10: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
+0000ae20: 725b 2273 7461 7475 7322 5d20 213d 2022  r["status"] != "
+0000ae30: 636c 6f73 6564 220a 2020 2020 2020 2020  closed".        
+0000ae40: 2020 2020 616e 6420 6f72 6465 725b 2274      and order["t
+0000ae50: 7970 6522 5d20 696e 205b 226c 696d 6974  ype"] in ["limit
+0000ae60: 225d 0a20 2020 2020 2020 2020 2020 2061  "].            a
+0000ae70: 6e64 206e 6f74 206f 7264 6572 2e67 6574  nd not order.get
+0000ae80: 2822 6674 5f6f 7264 6572 5f74 7970 6522  ("ft_order_type"
+0000ae90: 290a 2020 2020 2020 2020 293a 0a20 2020  ).        ):.   
+0000aea0: 2020 2020 2020 2020 2070 6169 7220 3d20           pair = 
+0000aeb0: 6f72 6465 725b 2273 796d 626f 6c22 5d0a  order["symbol"].
+0000aec0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+0000aed0: 656c 662e 5f64 7279 5f69 735f 7072 6963  elf._dry_is_pric
+0000aee0: 655f 6372 6f73 7365 6428 7061 6972 2c20  e_crossed(pair, 
+0000aef0: 6f72 6465 725b 2273 6964 6522 5d2c 206f  order["side"], o
+0000af00: 7264 6572 5b22 7072 6963 6522 5d2c 206f  rder["price"], o
+0000af10: 7264 6572 626f 6f6b 293a 0a20 2020 2020  rderbook):.     
+0000af20: 2020 2020 2020 2020 2020 206f 7264 6572             order
+0000af30: 2e75 7064 6174 6528 0a20 2020 2020 2020  .update(.       
+0000af40: 2020 2020 2020 2020 2020 2020 207b 0a20               {. 
+0000af50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000af60: 2020 2020 2020 2022 7374 6174 7573 223a         "status":
+0000af70: 2022 636c 6f73 6564 222c 0a20 2020 2020   "closed",.     
+0000af80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000af90: 2020 2022 6669 6c6c 6564 223a 206f 7264     "filled": ord
+0000afa0: 6572 5b22 616d 6f75 6e74 225d 2c0a 2020  er["amount"],.  
+0000afb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000afc0: 2020 2020 2020 2272 656d 6169 6e69 6e67        "remaining
+0000afd0: 223a 2030 2c0a 2020 2020 2020 2020 2020  ": 0,.          
+0000afe0: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+0000aff0: 2020 2020 2020 2020 2020 2020 290a 0a20              ).. 
+0000b000: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0000b010: 656c 662e 6164 645f 6472 795f 6f72 6465  elf.add_dry_orde
+0000b020: 725f 6665 6528 0a20 2020 2020 2020 2020  r_fee(.         
+0000b030: 2020 2020 2020 2020 2020 2070 6169 722c             pair,
+0000b040: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000b050: 2020 2020 206f 7264 6572 2c0a 2020 2020       order,.    
+0000b060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b070: 2274 616b 6572 2220 6966 2069 6d6d 6564  "taker" if immed
+0000b080: 6961 7465 2065 6c73 6520 226d 616b 6572  iate else "maker
+0000b090: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+0000b0a0: 2020 2029 0a0a 2020 2020 2020 2020 7265     )..        re
+0000b0b0: 7475 726e 206f 7264 6572 0a0a 2020 2020  turn order..    
+0000b0c0: 6465 6620 6665 7463 685f 6472 795f 7275  def fetch_dry_ru
+0000b0d0: 6e5f 6f72 6465 7228 7365 6c66 2c20 6f72  n_order(self, or
+0000b0e0: 6465 725f 6964 2920 2d3e 2044 6963 745b  der_id) -> Dict[
+0000b0f0: 7374 722c 2041 6e79 5d3a 0a20 2020 2020  str, Any]:.     
+0000b100: 2020 2022 2222 0a20 2020 2020 2020 2052     """.        R
+0000b110: 6574 7572 6e20 6472 792d 7275 6e20 6f72  eturn dry-run or
+0000b120: 6465 720a 2020 2020 2020 2020 4f6e 6c79  der.        Only
+0000b130: 2063 616c 6c20 6966 2072 756e 6e69 6e67   call if running
+0000b140: 2069 6e20 6472 792d 7275 6e20 6d6f 6465   in dry-run mode
+0000b150: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+0000b160: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+0000b170: 2020 2020 2020 206f 7264 6572 203d 2073         order = s
+0000b180: 656c 662e 5f64 7279 5f72 756e 5f6f 7065  elf._dry_run_ope
+0000b190: 6e5f 6f72 6465 7273 5b6f 7264 6572 5f69  n_orders[order_i
+0000b1a0: 645d 0a20 2020 2020 2020 2020 2020 206f  d].            o
+0000b1b0: 7264 6572 203d 2073 656c 662e 6368 6563  rder = self.chec
+0000b1c0: 6b5f 6472 795f 6c69 6d69 745f 6f72 6465  k_dry_limit_orde
+0000b1d0: 725f 6669 6c6c 6564 286f 7264 6572 290a  r_filled(order).
+0000b1e0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000b1f0: 726e 206f 7264 6572 0a20 2020 2020 2020  rn order.       
+0000b200: 2065 7863 6570 7420 4b65 7945 7272 6f72   except KeyError
+0000b210: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
+0000b220: 2020 2066 726f 6d20 6672 6571 7472 6164     from freqtrad
+0000b230: 652e 7065 7273 6973 7465 6e63 6520 696d  e.persistence im
+0000b240: 706f 7274 204f 7264 6572 0a0a 2020 2020  port Order..    
+0000b250: 2020 2020 2020 2020 6f72 6465 7220 3d20          order = 
+0000b260: 4f72 6465 722e 6f72 6465 725f 6279 5f69  Order.order_by_i
+0000b270: 6428 6f72 6465 725f 6964 290a 2020 2020  d(order_id).    
+0000b280: 2020 2020 2020 2020 6966 206f 7264 6572          if order
+0000b290: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000b2a0: 2020 6363 7874 5f6f 7264 6572 203d 206f    ccxt_order = o
+0000b2b0: 7264 6572 2e74 6f5f 6363 7874 5f6f 626a  rder.to_ccxt_obj
+0000b2c0: 6563 7428 7365 6c66 2e5f 6674 5f68 6173  ect(self._ft_has
+0000b2d0: 5b22 7374 6f70 5f70 7269 6365 5f70 726f  ["stop_price_pro
+0000b2e0: 7022 5d29 0a20 2020 2020 2020 2020 2020  p"]).           
+0000b2f0: 2020 2020 2073 656c 662e 5f64 7279 5f72       self._dry_r
+0000b300: 756e 5f6f 7065 6e5f 6f72 6465 7273 5b6f  un_open_orders[o
+0000b310: 7264 6572 5f69 645d 203d 2063 6378 745f  rder_id] = ccxt_
+0000b320: 6f72 6465 720a 2020 2020 2020 2020 2020  order.          
+0000b330: 2020 2020 2020 7265 7475 726e 2063 6378        return ccx
+0000b340: 745f 6f72 6465 720a 2020 2020 2020 2020  t_order.        
+0000b350: 2020 2020 2320 4772 6163 6566 756c 6c79      # Gracefully
+0000b360: 2068 616e 646c 6520 6572 726f 7273 2077   handle errors w
+0000b370: 6974 6820 6472 792d 7275 6e20 6f72 6465  ith dry-run orde
+0000b380: 7273 2e0a 2020 2020 2020 2020 2020 2020  rs..            
+0000b390: 7261 6973 6520 496e 7661 6c69 644f 7264  raise InvalidOrd
+0000b3a0: 6572 4578 6365 7074 696f 6e28 0a20 2020  erException(.   
+0000b3b0: 2020 2020 2020 2020 2020 2020 2066 2254               f"T
+0000b3c0: 7269 6564 2074 6f20 6765 7420 616e 2069  ried to get an i
+0000b3d0: 6e76 616c 6964 2064 7279 2d72 756e 2d6f  nvalid dry-run-o
+0000b3e0: 7264 6572 2028 6964 3a20 7b6f 7264 6572  rder (id: {order
+0000b3f0: 5f69 647d 292e 204d 6573 7361 6765 3a20  _id}). Message: 
+0000b400: 7b65 7d22 0a20 2020 2020 2020 2020 2020  {e}".           
+0000b410: 2029 2066 726f 6d20 650a 0a20 2020 2023   ) from e..    #
+0000b420: 204f 7264 6572 2068 616e 646c 696e 670a   Order handling.
+0000b430: 0a20 2020 2064 6566 205f 6c65 765f 7072  .    def _lev_pr
+0000b440: 6570 2873 656c 662c 2070 6169 723a 2073  ep(self, pair: s
+0000b450: 7472 2c20 6c65 7665 7261 6765 3a20 666c  tr, leverage: fl
+0000b460: 6f61 742c 2073 6964 653a 2042 7579 5365  oat, side: BuySe
+0000b470: 6c6c 2c20 6163 6365 7074 5f66 6169 6c3a  ll, accept_fail:
+0000b480: 2062 6f6f 6c20 3d20 4661 6c73 6529 3a0a   bool = False):.
+0000b490: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+0000b4a0: 7472 6164 696e 675f 6d6f 6465 2021 3d20  trading_mode != 
+0000b4b0: 5472 6164 696e 674d 6f64 652e 5350 4f54  TradingMode.SPOT
+0000b4c0: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+0000b4d0: 6c66 2e73 6574 5f6d 6172 6769 6e5f 6d6f  lf.set_margin_mo
+0000b4e0: 6465 2870 6169 722c 2073 656c 662e 6d61  de(pair, self.ma
+0000b4f0: 7267 696e 5f6d 6f64 652c 2061 6363 6570  rgin_mode, accep
+0000b500: 745f 6661 696c 290a 2020 2020 2020 2020  t_fail).        
+0000b510: 2020 2020 7365 6c66 2e5f 7365 745f 6c65      self._set_le
+0000b520: 7665 7261 6765 286c 6576 6572 6167 652c  verage(leverage,
+0000b530: 2070 6169 722c 2061 6363 6570 745f 6661   pair, accept_fa
+0000b540: 696c 290a 0a20 2020 2064 6566 205f 6765  il)..    def _ge
+0000b550: 745f 7061 7261 6d73 280a 2020 2020 2020  t_params(.      
+0000b560: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
+0000b570: 7369 6465 3a20 4275 7953 656c 6c2c 0a20  side: BuySell,. 
+0000b580: 2020 2020 2020 206f 7264 6572 7479 7065         ordertype
+0000b590: 3a20 7374 722c 0a20 2020 2020 2020 206c  : str,.        l
+0000b5a0: 6576 6572 6167 653a 2066 6c6f 6174 2c0a  everage: float,.
+0000b5b0: 2020 2020 2020 2020 7265 6475 6365 4f6e          reduceOn
+0000b5c0: 6c79 3a20 626f 6f6c 2c0a 2020 2020 2020  ly: bool,.      
+0000b5d0: 2020 7469 6d65 5f69 6e5f 666f 7263 653a    time_in_force:
+0000b5e0: 2073 7472 203d 2022 4754 4322 2c0a 2020   str = "GTC",.  
+0000b5f0: 2020 2920 2d3e 2044 6963 743a 0a20 2020    ) -> Dict:.   
+0000b600: 2020 2020 2070 6172 616d 7320 3d20 7365       params = se
+0000b610: 6c66 2e5f 7061 7261 6d73 2e63 6f70 7928  lf._params.copy(
+0000b620: 290a 2020 2020 2020 2020 6966 2074 696d  ).        if tim
+0000b630: 655f 696e 5f66 6f72 6365 2021 3d20 2247  e_in_force != "G
+0000b640: 5443 2220 616e 6420 6f72 6465 7274 7970  TC" and ordertyp
+0000b650: 6520 213d 2022 6d61 726b 6574 223a 0a20  e != "market":. 
+0000b660: 2020 2020 2020 2020 2020 2070 6172 616d             param
+0000b670: 732e 7570 6461 7465 287b 2274 696d 6549  s.update({"timeI
+0000b680: 6e46 6f72 6365 223a 2074 696d 655f 696e  nForce": time_in
+0000b690: 5f66 6f72 6365 2e75 7070 6572 2829 7d29  _force.upper()})
+0000b6a0: 0a20 2020 2020 2020 2069 6620 7265 6475  .        if redu
+0000b6b0: 6365 4f6e 6c79 3a0a 2020 2020 2020 2020  ceOnly:.        
+0000b6c0: 2020 2020 7061 7261 6d73 2e75 7064 6174      params.updat
+0000b6d0: 6528 7b22 7265 6475 6365 4f6e 6c79 223a  e({"reduceOnly":
+0000b6e0: 2054 7275 657d 290a 2020 2020 2020 2020   True}).        
+0000b6f0: 7265 7475 726e 2070 6172 616d 730a 0a20  return params.. 
+0000b700: 2020 2064 6566 205f 6f72 6465 725f 6e65     def _order_ne
+0000b710: 6564 735f 7072 6963 6528 7365 6c66 2c20  eds_price(self, 
+0000b720: 6f72 6465 7274 7970 653a 2073 7472 2920  ordertype: str) 
+0000b730: 2d3e 2062 6f6f 6c3a 0a20 2020 2020 2020  -> bool:.       
+0000b740: 2072 6574 7572 6e20 280a 2020 2020 2020   return (.      
+0000b750: 2020 2020 2020 6f72 6465 7274 7970 6520        ordertype 
+0000b760: 213d 2022 6d61 726b 6574 220a 2020 2020  != "market".    
+0000b770: 2020 2020 2020 2020 6f72 2073 656c 662e          or self.
+0000b780: 5f61 7069 2e6f 7074 696f 6e73 2e67 6574  _api.options.get
+0000b790: 2822 6372 6561 7465 4d61 726b 6574 4275  ("createMarketBu
+0000b7a0: 794f 7264 6572 5265 7175 6972 6573 5072  yOrderRequiresPr
+0000b7b0: 6963 6522 2c20 4661 6c73 6529 0a20 2020  ice", False).   
+0000b7c0: 2020 2020 2020 2020 206f 7220 7365 6c66           or self
+0000b7d0: 2e5f 6674 5f68 6173 2e67 6574 2822 6d61  ._ft_has.get("ma
+0000b7e0: 726b 6574 4f72 6465 7252 6571 7569 7265  rketOrderRequire
+0000b7f0: 7350 7269 6365 222c 2046 616c 7365 290a  sPrice", False).
+0000b800: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
+0000b810: 6566 2063 7265 6174 655f 6f72 6465 7228  ef create_order(
+0000b820: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+0000b830: 2020 2020 2020 202a 2c0a 2020 2020 2020         *,.      
+0000b840: 2020 7061 6972 3a20 7374 722c 0a20 2020    pair: str,.   
+0000b850: 2020 2020 206f 7264 6572 7479 7065 3a20       ordertype: 
+0000b860: 7374 722c 0a20 2020 2020 2020 2073 6964  str,.        sid
+0000b870: 653a 2042 7579 5365 6c6c 2c0a 2020 2020  e: BuySell,.    
+0000b880: 2020 2020 616d 6f75 6e74 3a20 666c 6f61      amount: floa
+0000b890: 742c 0a20 2020 2020 2020 2072 6174 653a  t,.        rate:
+0000b8a0: 2066 6c6f 6174 2c0a 2020 2020 2020 2020   float,.        
+0000b8b0: 6c65 7665 7261 6765 3a20 666c 6f61 742c  leverage: float,
+0000b8c0: 0a20 2020 2020 2020 2072 6564 7563 654f  .        reduceO
+0000b8d0: 6e6c 793a 2062 6f6f 6c20 3d20 4661 6c73  nly: bool = Fals
+0000b8e0: 652c 0a20 2020 2020 2020 2074 696d 655f  e,.        time_
+0000b8f0: 696e 5f66 6f72 6365 3a20 7374 7220 3d20  in_force: str = 
+0000b900: 2247 5443 222c 0a20 2020 2029 202d 3e20  "GTC",.    ) -> 
+0000b910: 4469 6374 3a0a 2020 2020 2020 2020 6966  Dict:.        if
+0000b920: 2073 656c 662e 5f63 6f6e 6669 675b 2264   self._config["d
+0000b930: 7279 5f72 756e 225d 3a0a 2020 2020 2020  ry_run"]:.      
+0000b940: 2020 2020 2020 6472 795f 6f72 6465 7220        dry_order 
+0000b950: 3d20 7365 6c66 2e63 7265 6174 655f 6472  = self.create_dr
+0000b960: 795f 7275 6e5f 6f72 6465 7228 0a20 2020  y_run_order(.   
+0000b970: 2020 2020 2020 2020 2020 2020 2070 6169               pai
+0000b980: 722c 206f 7264 6572 7479 7065 2c20 7369  r, ordertype, si
+0000b990: 6465 2c20 616d 6f75 6e74 2c20 7365 6c66  de, amount, self
+0000b9a0: 2e70 7269 6365 5f74 6f5f 7072 6563 6973  .price_to_precis
+0000b9b0: 696f 6e28 7061 6972 2c20 7261 7465 292c  ion(pair, rate),
+0000b9c0: 206c 6576 6572 6167 650a 2020 2020 2020   leverage.      
+0000b9d0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0000b9e0: 2020 2020 7265 7475 726e 2064 7279 5f6f      return dry_o
+0000b9f0: 7264 6572 0a0a 2020 2020 2020 2020 7061  rder..        pa
+0000ba00: 7261 6d73 203d 2073 656c 662e 5f67 6574  rams = self._get
+0000ba10: 5f70 6172 616d 7328 7369 6465 2c20 6f72  _params(side, or
+0000ba20: 6465 7274 7970 652c 206c 6576 6572 6167  dertype, leverag
+0000ba30: 652c 2072 6564 7563 654f 6e6c 792c 2074  e, reduceOnly, t
+0000ba40: 696d 655f 696e 5f66 6f72 6365 290a 0a20  ime_in_force).. 
+0000ba50: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+0000ba60: 2020 2020 2020 2020 2320 5365 7420 7468          # Set th
+0000ba70: 6520 7072 6563 6973 696f 6e20 666f 7220  e precision for 
+0000ba80: 616d 6f75 6e74 2061 6e64 2070 7269 6365  amount and price
+0000ba90: 2872 6174 6529 2061 7320 6163 6365 7074  (rate) as accept
+0000baa0: 6564 2062 7920 7468 6520 6578 6368 616e  ed by the exchan
+0000bab0: 6765 0a20 2020 2020 2020 2020 2020 2061  ge.            a
+0000bac0: 6d6f 756e 7420 3d20 7365 6c66 2e61 6d6f  mount = self.amo
+0000bad0: 756e 745f 746f 5f70 7265 6369 7369 6f6e  unt_to_precision
+0000bae0: 2870 6169 722c 2073 656c 662e 5f61 6d6f  (pair, self._amo
+0000baf0: 756e 745f 746f 5f63 6f6e 7472 6163 7473  unt_to_contracts
+0000bb00: 2870 6169 722c 2061 6d6f 756e 7429 290a  (pair, amount)).
+0000bb10: 2020 2020 2020 2020 2020 2020 6e65 6564              need
+0000bb20: 735f 7072 6963 6520 3d20 7365 6c66 2e5f  s_price = self._
+0000bb30: 6f72 6465 725f 6e65 6564 735f 7072 6963  order_needs_pric
+0000bb40: 6528 6f72 6465 7274 7970 6529 0a20 2020  e(ordertype).   
+0000bb50: 2020 2020 2020 2020 2072 6174 655f 666f           rate_fo
+0000bb60: 725f 6f72 6465 7220 3d20 7365 6c66 2e70  r_order = self.p
+0000bb70: 7269 6365 5f74 6f5f 7072 6563 6973 696f  rice_to_precisio
+0000bb80: 6e28 7061 6972 2c20 7261 7465 2920 6966  n(pair, rate) if
+0000bb90: 206e 6565 6473 5f70 7269 6365 2065 6c73   needs_price els
+0000bba0: 6520 4e6f 6e65 0a0a 2020 2020 2020 2020  e None..        
+0000bbb0: 2020 2020 6966 206e 6f74 2072 6564 7563      if not reduc
+0000bbc0: 654f 6e6c 793a 0a20 2020 2020 2020 2020  eOnly:.         
+0000bbd0: 2020 2020 2020 2073 656c 662e 5f6c 6576         self._lev
+0000bbe0: 5f70 7265 7028 7061 6972 2c20 6c65 7665  _prep(pair, leve
+0000bbf0: 7261 6765 2c20 7369 6465 290a 0a20 2020  rage, side)..   
+0000bc00: 2020 2020 2020 2020 206f 7264 6572 203d           order =
+0000bc10: 2073 656c 662e 5f61 7069 2e63 7265 6174   self._api.creat
+0000bc20: 655f 6f72 6465 7228 0a20 2020 2020 2020  e_order(.       
+0000bc30: 2020 2020 2020 2020 2070 6169 722c 0a20           pair,. 
+0000bc40: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+0000bc50: 7264 6572 7479 7065 2c0a 2020 2020 2020  rdertype,.      
+0000bc60: 2020 2020 2020 2020 2020 7369 6465 2c0a            side,.
+0000bc70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bc80: 616d 6f75 6e74 2c0a 2020 2020 2020 2020  amount,.        
+0000bc90: 2020 2020 2020 2020 7261 7465 5f66 6f72          rate_for
+0000bca0: 5f6f 7264 6572 2c0a 2020 2020 2020 2020  _order,.        
+0000bcb0: 2020 2020 2020 2020 7061 7261 6d73 2c0a          params,.
+0000bcc0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+0000bcd0: 2020 2020 2020 2020 2020 6966 206f 7264            if ord
+0000bce0: 6572 2e67 6574 2822 7374 6174 7573 2229  er.get("status")
+0000bcf0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0000bd00: 2020 2020 2020 2020 2020 2320 4d61 7020            # Map 
+0000bd10: 656d 7074 7920 7374 6174 7573 2074 6f20  empty status to 
+0000bd20: 6f70 656e 2e0a 2020 2020 2020 2020 2020  open..          
+0000bd30: 2020 2020 2020 6f72 6465 725b 2273 7461        order["sta
+0000bd40: 7475 7322 5d20 3d20 226f 7065 6e22 0a0a  tus"] = "open"..
+0000bd50: 2020 2020 2020 2020 2020 2020 6966 206f              if o
+0000bd60: 7264 6572 2e67 6574 2822 7479 7065 2229  rder.get("type")
+0000bd70: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0000bd80: 2020 2020 2020 2020 2020 6f72 6465 725b            order[
+0000bd90: 2274 7970 6522 5d20 3d20 6f72 6465 7274  "type"] = ordert
+0000bda0: 7970 650a 0a20 2020 2020 2020 2020 2020  ype..           
+0000bdb0: 2073 656c 662e 5f6c 6f67 5f65 7863 6861   self._log_excha
+0000bdc0: 6e67 655f 7265 7370 6f6e 7365 2822 6372  nge_response("cr
+0000bdd0: 6561 7465 5f6f 7264 6572 222c 206f 7264  eate_order", ord
+0000bde0: 6572 290a 2020 2020 2020 2020 2020 2020  er).            
+0000bdf0: 6f72 6465 7220 3d20 7365 6c66 2e5f 6f72  order = self._or
+0000be00: 6465 725f 636f 6e74 7261 6374 735f 746f  der_contracts_to
+0000be10: 5f61 6d6f 756e 7428 6f72 6465 7229 0a20  _amount(order). 
+0000be20: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0000be30: 6e20 6f72 6465 720a 0a20 2020 2020 2020  n order..       
+0000be40: 2065 7863 6570 7420 6363 7874 2e49 6e73   except ccxt.Ins
+0000be50: 7566 6669 6369 656e 7446 756e 6473 2061  ufficientFunds a
+0000be60: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
+0000be70: 2072 6169 7365 2049 6e73 7566 6669 6369   raise Insuffici
+0000be80: 656e 7446 756e 6473 4572 726f 7228 0a20  entFundsError(. 
+0000be90: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000bea0: 2249 6e73 7566 6669 6369 656e 7420 6675  "Insufficient fu
+0000beb0: 6e64 7320 746f 2063 7265 6174 6520 7b6f  nds to create {o
+0000bec0: 7264 6572 7479 7065 7d20 7b73 6964 657d  rdertype} {side}
+0000bed0: 206f 7264 6572 206f 6e20 6d61 726b 6574   order on market
+0000bee0: 207b 7061 6972 7d2e 2022 0a20 2020 2020   {pair}. ".     
+0000bef0: 2020 2020 2020 2020 2020 2066 2254 7269             f"Tri
+0000bf00: 6564 2074 6f20 7b73 6964 657d 2061 6d6f  ed to {side} amo
+0000bf10: 756e 7420 7b61 6d6f 756e 747d 2061 7420  unt {amount} at 
+0000bf20: 7261 7465 207b 7261 7465 7d2e 220a 2020  rate {rate}.".  
+0000bf30: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+0000bf40: 4d65 7373 6167 653a 207b 657d 220a 2020  Message: {e}".  
+0000bf50: 2020 2020 2020 2020 2020 2920 6672 6f6d            ) from
+0000bf60: 2065 0a20 2020 2020 2020 2065 7863 6570   e.        excep
+0000bf70: 7420 6363 7874 2e49 6e76 616c 6964 4f72  t ccxt.InvalidOr
+0000bf80: 6465 7220 6173 2065 3a0a 2020 2020 2020  der as e:.      
+0000bf90: 2020 2020 2020 7261 6973 6520 496e 7661        raise Inva
+0000bfa0: 6c69 644f 7264 6572 4578 6365 7074 696f  lidOrderExceptio
+0000bfb0: 6e28 0a20 2020 2020 2020 2020 2020 2020  n(.             
+0000bfc0: 2020 2066 2243 6f75 6c64 206e 6f74 2063     f"Could not c
+0000bfd0: 7265 6174 6520 7b6f 7264 6572 7479 7065  reate {ordertype
+0000bfe0: 7d20 7b73 6964 657d 206f 7264 6572 206f  } {side} order o
+0000bff0: 6e20 6d61 726b 6574 207b 7061 6972 7d2e  n market {pair}.
+0000c000: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
+0000c010: 2020 2066 2254 7269 6564 2074 6f20 7b73     f"Tried to {s
+0000c020: 6964 657d 2061 6d6f 756e 7420 7b61 6d6f  ide} amount {amo
+0000c030: 756e 747d 2061 7420 7261 7465 207b 7261  unt} at rate {ra
+0000c040: 7465 7d2e 2022 0a20 2020 2020 2020 2020  te}. ".         
+0000c050: 2020 2020 2020 2066 224d 6573 7361 6765         f"Message
+0000c060: 3a20 7b65 7d22 0a20 2020 2020 2020 2020  : {e}".         
+0000c070: 2020 2029 2066 726f 6d20 650a 2020 2020     ) from e.    
+0000c080: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
+0000c090: 4444 6f53 5072 6f74 6563 7469 6f6e 2061  DDoSProtection a
+0000c0a0: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
+0000c0b0: 2072 6169 7365 2044 446f 7350 726f 7465   raise DDosProte
+0000c0c0: 6374 696f 6e28 6529 2066 726f 6d20 650a  ction(e) from e.
+0000c0d0: 2020 2020 2020 2020 6578 6365 7074 2028          except (
+0000c0e0: 6363 7874 2e4f 7065 7261 7469 6f6e 4661  ccxt.OperationFa
+0000c0f0: 696c 6564 2c20 6363 7874 2e45 7863 6861  iled, ccxt.Excha
+0000c100: 6e67 6545 7272 6f72 2920 6173 2065 3a0a  ngeError) as e:.
+0000c110: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0000c120: 6520 5465 6d70 6f72 6172 7945 7272 6f72  e TemporaryError
+0000c130: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0000c140: 2020 6622 436f 756c 6420 6e6f 7420 706c    f"Could not pl
+0000c150: 6163 6520 7b73 6964 657d 206f 7264 6572  ace {side} order
+0000c160: 2064 7565 2074 6f20 7b65 2e5f 5f63 6c61   due to {e.__cla
+0000c170: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2e20  ss__.__name__}. 
+0000c180: 4d65 7373 6167 653a 207b 657d 220a 2020  Message: {e}".  
+0000c190: 2020 2020 2020 2020 2020 2920 6672 6f6d            ) from
+0000c1a0: 2065 0a20 2020 2020 2020 2065 7863 6570   e.        excep
+0000c1b0: 7420 6363 7874 2e42 6173 6545 7272 6f72  t ccxt.BaseError
+0000c1c0: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
+0000c1d0: 2020 2072 6169 7365 204f 7065 7261 7469     raise Operati
+0000c1e0: 6f6e 616c 4578 6365 7074 696f 6e28 6529  onalException(e)
+0000c1f0: 2066 726f 6d20 650a 0a20 2020 2064 6566   from e..    def
+0000c200: 2073 746f 706c 6f73 735f 6164 6a75 7374   stoploss_adjust
+0000c210: 2873 656c 662c 2073 746f 705f 6c6f 7373  (self, stop_loss
+0000c220: 3a20 666c 6f61 742c 206f 7264 6572 3a20  : float, order: 
+0000c230: 4469 6374 2c20 7369 6465 3a20 7374 7229  Dict, side: str)
+0000c240: 202d 3e20 626f 6f6c 3a0a 2020 2020 2020   -> bool:.      
+0000c250: 2020 2222 220a 2020 2020 2020 2020 5665    """.        Ve
+0000c260: 7269 6679 2073 746f 705f 6c6f 7373 2061  rify stop_loss a
+0000c270: 6761 696e 7374 2073 746f 706c 6f73 732d  gainst stoploss-
+0000c280: 6f72 6465 7220 7661 6c75 6520 286c 696d  order value (lim
+0000c290: 6974 206f 7220 7072 6963 6529 0a20 2020  it or price).   
+0000c2a0: 2020 2020 2052 6574 7572 6e73 2054 7275       Returns Tru
+0000c2b0: 6520 6966 2061 646a 7573 746d 656e 7420  e if adjustment 
+0000c2c0: 6973 206e 6563 6573 7361 7279 2e0a 2020  is necessary..  
+0000c2d0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0000c2e0: 2020 6966 206e 6f74 2073 656c 662e 5f66    if not self._f
+0000c2f0: 745f 6861 732e 6765 7428 2273 746f 706c  t_has.get("stopl
+0000c300: 6f73 735f 6f6e 5f65 7863 6861 6e67 6522  oss_on_exchange"
+0000c310: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+0000c320: 6169 7365 204f 7065 7261 7469 6f6e 616c  aise Operational
+0000c330: 4578 6365 7074 696f 6e28 6622 7374 6f70  Exception(f"stop
+0000c340: 6c6f 7373 2069 7320 6e6f 7420 696d 706c  loss is not impl
+0000c350: 656d 656e 7465 6420 666f 7220 7b73 656c  emented for {sel
+0000c360: 662e 6e61 6d65 7d2e 2229 0a20 2020 2020  f.name}.").     
+0000c370: 2020 2070 7269 6365 5f70 6172 616d 203d     price_param =
+0000c380: 2073 656c 662e 5f66 745f 6861 735b 2273   self._ft_has["s
+0000c390: 746f 705f 7072 6963 655f 7072 6f70 225d  top_price_prop"]
+0000c3a0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000c3b0: 6f72 6465 722e 6765 7428 7072 6963 655f  order.get(price_
+0000c3c0: 7061 7261 6d2c 204e 6f6e 6529 2069 7320  param, None) is 
+0000c3d0: 4e6f 6e65 206f 7220 280a 2020 2020 2020  None or (.      
+0000c3e0: 2020 2020 2020 2873 6964 6520 3d3d 2022        (side == "
+0000c3f0: 7365 6c6c 2220 616e 6420 7374 6f70 5f6c  sell" and stop_l
+0000c400: 6f73 7320 3e20 666c 6f61 7428 6f72 6465  oss > float(orde
+0000c410: 725b 7072 6963 655f 7061 7261 6d5d 2929  r[price_param]))
+0000c420: 0a20 2020 2020 2020 2020 2020 206f 7220  .            or 
+0000c430: 2873 6964 6520 3d3d 2022 6275 7922 2061  (side == "buy" a
+0000c440: 6e64 2073 746f 705f 6c6f 7373 203c 2066  nd stop_loss < f
+0000c450: 6c6f 6174 286f 7264 6572 5b70 7269 6365  loat(order[price
+0000c460: 5f70 6172 616d 5d29 290a 2020 2020 2020  _param])).      
+0000c470: 2020 290a 0a20 2020 2064 6566 205f 6765    )..    def _ge
+0000c480: 745f 7374 6f70 5f6f 7264 6572 5f74 7970  t_stop_order_typ
+0000c490: 6528 7365 6c66 2c20 7573 6572 5f6f 7264  e(self, user_ord
+0000c4a0: 6572 5f74 7970 6529 202d 3e20 5475 706c  er_type) -> Tupl
+0000c4b0: 655b 7374 722c 2073 7472 5d3a 0a20 2020  e[str, str]:.   
+0000c4c0: 2020 2020 2061 7661 696c 6162 6c65 5f6f       available_o
+0000c4d0: 7264 6572 5f54 7970 6573 3a20 4469 6374  rder_Types: Dict
+0000c4e0: 5b73 7472 2c20 7374 725d 203d 2073 656c  [str, str] = sel
+0000c4f0: 662e 5f66 745f 6861 735b 2273 746f 706c  f._ft_has["stopl
+0000c500: 6f73 735f 6f72 6465 725f 7479 7065 7322  oss_order_types"
+0000c510: 5d0a 0a20 2020 2020 2020 2069 6620 7573  ]..        if us
+0000c520: 6572 5f6f 7264 6572 5f74 7970 6520 696e  er_order_type in
+0000c530: 2061 7661 696c 6162 6c65 5f6f 7264 6572   available_order
+0000c540: 5f54 7970 6573 2e6b 6579 7328 293a 0a20  _Types.keys():. 
+0000c550: 2020 2020 2020 2020 2020 206f 7264 6572             order
+0000c560: 7479 7065 203d 2061 7661 696c 6162 6c65  type = available
+0000c570: 5f6f 7264 6572 5f54 7970 6573 5b75 7365  _order_Types[use
+0000c580: 725f 6f72 6465 725f 7479 7065 5d0a 2020  r_order_type].  
+0000c590: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0000c5a0: 2020 2020 2020 2020 2320 4f74 6865 7277          # Otherw
+0000c5b0: 6973 6520 7069 636b 206f 6e6c 7920 6f6e  ise pick only on
+0000c5c0: 6520 6176 6169 6c61 626c 650a 2020 2020  e available.    
+0000c5d0: 2020 2020 2020 2020 6f72 6465 7274 7970          ordertyp
+0000c5e0: 6520 3d20 6c69 7374 2861 7661 696c 6162  e = list(availab
+0000c5f0: 6c65 5f6f 7264 6572 5f54 7970 6573 2e76  le_order_Types.v
+0000c600: 616c 7565 7328 2929 5b30 5d0a 2020 2020  alues())[0].    
+0000c610: 2020 2020 2020 2020 7573 6572 5f6f 7264          user_ord
+0000c620: 6572 5f74 7970 6520 3d20 6c69 7374 2861  er_type = list(a
+0000c630: 7661 696c 6162 6c65 5f6f 7264 6572 5f54  vailable_order_T
+0000c640: 7970 6573 2e6b 6579 7328 2929 5b30 5d0a  ypes.keys())[0].
+0000c650: 2020 2020 2020 2020 7265 7475 726e 206f          return o
+0000c660: 7264 6572 7479 7065 2c20 7573 6572 5f6f  rdertype, user_o
+0000c670: 7264 6572 5f74 7970 650a 0a20 2020 2064  rder_type..    d
+0000c680: 6566 205f 6765 745f 7374 6f70 5f6c 696d  ef _get_stop_lim
+0000c690: 6974 5f72 6174 6528 7365 6c66 2c20 7374  it_rate(self, st
+0000c6a0: 6f70 5f70 7269 6365 3a20 666c 6f61 742c  op_price: float,
+0000c6b0: 206f 7264 6572 5f74 7970 6573 3a20 4469   order_types: Di
+0000c6c0: 6374 2c20 7369 6465 3a20 7374 7229 202d  ct, side: str) -
+0000c6d0: 3e20 666c 6f61 743a 0a20 2020 2020 2020  > float:.       
+0000c6e0: 2023 204c 696d 6974 2070 7269 6365 2074   # Limit price t
+0000c6f0: 6872 6573 686f 6c64 3a20 4173 206c 696d  hreshold: As lim
+0000c700: 6974 2070 7269 6365 2073 686f 756c 6420  it price should 
+0000c710: 616c 7761 7973 2062 6520 6265 6c6f 7720  always be below 
+0000c720: 7374 6f70 2d70 7269 6365 0a20 2020 2020  stop-price.     
+0000c730: 2020 206c 696d 6974 5f70 7269 6365 5f70     limit_price_p
+0000c740: 6374 203d 206f 7264 6572 5f74 7970 6573  ct = order_types
+0000c750: 2e67 6574 2822 7374 6f70 6c6f 7373 5f6f  .get("stoploss_o
+0000c760: 6e5f 6578 6368 616e 6765 5f6c 696d 6974  n_exchange_limit
+0000c770: 5f72 6174 696f 222c 2030 2e39 3929 0a20  _ratio", 0.99). 
+0000c780: 2020 2020 2020 2069 6620 7369 6465 203d         if side =
+0000c790: 3d20 2273 656c 6c22 3a0a 2020 2020 2020  = "sell":.      
+0000c7a0: 2020 2020 2020 6c69 6d69 745f 7261 7465        limit_rate
+0000c7b0: 203d 2073 746f 705f 7072 6963 6520 2a20   = stop_price * 
+0000c7c0: 6c69 6d69 745f 7072 6963 655f 7063 740a  limit_price_pct.
+0000c7d0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0000c7e0: 2020 2020 2020 2020 2020 6c69 6d69 745f            limit_
+0000c7f0: 7261 7465 203d 2073 746f 705f 7072 6963  rate = stop_pric
+0000c800: 6520 2a20 2832 202d 206c 696d 6974 5f70  e * (2 - limit_p
+0000c810: 7269 6365 5f70 6374 290a 0a20 2020 2020  rice_pct)..     
+0000c820: 2020 2062 6164 5f73 746f 705f 7072 6963     bad_stop_pric
+0000c830: 6520 3d20 2873 746f 705f 7072 6963 6520  e = (stop_price 
+0000c840: 3c20 6c69 6d69 745f 7261 7465 2920 6966  < limit_rate) if
+0000c850: 2073 6964 6520 3d3d 2022 7365 6c6c 2220   side == "sell" 
+0000c860: 656c 7365 2028 7374 6f70 5f70 7269 6365  else (stop_price
+0000c870: 203e 206c 696d 6974 5f72 6174 6529 0a20   > limit_rate). 
+0000c880: 2020 2020 2020 2023 2045 6e73 7572 6520         # Ensure 
+0000c890: 7261 7465 2069 7320 6c65 7373 2074 6861  rate is less tha
+0000c8a0: 6e20 7374 6f70 2070 7269 6365 0a20 2020  n stop price.   
+0000c8b0: 2020 2020 2069 6620 6261 645f 7374 6f70       if bad_stop
+0000c8c0: 5f70 7269 6365 3a0a 2020 2020 2020 2020  _price:.        
+0000c8d0: 2020 2020 2320 5468 6973 2063 616e 2066      # This can f
+0000c8e0: 6f72 2065 7861 6d70 6c65 2068 6170 7065  or example happe
+0000c8f0: 6e20 6966 2074 6865 2073 746f 7020 2f20  n if the stop / 
+0000c900: 6c69 7175 6964 6174 696f 6e20 7072 6963  liquidation pric
+0000c910: 6520 6973 2073 6574 2074 6f20 300a 2020  e is set to 0.  
+0000c920: 2020 2020 2020 2020 2020 2320 5768 6963            # Whic
+0000c930: 6820 6973 2070 6f73 7369 626c 6520 6966  h is possible if
+0000c940: 2061 206d 6172 6b65 742d 6f72 6465 7220   a market-order 
+0000c950: 636c 6f73 6573 2072 6967 6874 2061 7761  closes right awa
+0000c960: 792e 0a20 2020 2020 2020 2020 2020 2023  y..            #
+0000c970: 2054 6865 2049 6e76 616c 6964 4f72 6465   The InvalidOrde
+0000c980: 7245 7863 6570 7469 6f6e 2077 696c 6c20  rException will 
+0000c990: 6275 6262 6c65 2075 7020 746f 2065 7869  bubble up to exi
+0000c9a0: 745f 706f 7369 7469 6f6e 732c 2077 6865  t_positions, whe
+0000c9b0: 7265 2069 7420 7769 6c6c 2062 650a 2020  re it will be.  
+0000c9c0: 2020 2020 2020 2020 2020 2320 6861 6e64            # hand
+0000c9d0: 6c65 6420 6772 6163 6566 756c 6c79 2e0a  led gracefully..
+0000c9e0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0000c9f0: 6520 496e 7661 6c69 644f 7264 6572 4578  e InvalidOrderEx
+0000ca00: 6365 7074 696f 6e28 0a20 2020 2020 2020  ception(.       
+0000ca10: 2020 2020 2020 2020 2022 496e 2073 746f           "In sto
+0000ca20: 706c 6f73 7320 6c69 6d69 7420 6f72 6465  ploss limit orde
+0000ca30: 722c 2073 746f 7020 7072 6963 6520 7368  r, stop price sh
+0000ca40: 6f75 6c64 2062 6520 6d6f 7265 2074 6861  ould be more tha
+0000ca50: 6e20 6c69 6d69 7420 7072 6963 652e 2022  n limit price. "
+0000ca60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ca70: 2066 2253 746f 7020 7072 6963 653a 207b   f"Stop price: {
+0000ca80: 7374 6f70 5f70 7269 6365 7d2c 204c 696d  stop_price}, Lim
+0000ca90: 6974 2070 7269 6365 3a20 7b6c 696d 6974  it price: {limit
+0000caa0: 5f72 6174 657d 2c20 220a 2020 2020 2020  _rate}, ".      
+0000cab0: 2020 2020 2020 2020 2020 6622 4c69 6d69            f"Limi
+0000cac0: 7420 5072 6963 6520 7063 743a 207b 6c69  t Price pct: {li
+0000cad0: 6d69 745f 7072 6963 655f 7063 747d 220a  mit_price_pct}".
+0000cae0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+0000caf0: 2020 2020 2020 7265 7475 726e 206c 696d        return lim
+0000cb00: 6974 5f72 6174 650a 0a20 2020 2064 6566  it_rate..    def
+0000cb10: 205f 6765 745f 7374 6f70 5f70 6172 616d   _get_stop_param
+0000cb20: 7328 7365 6c66 2c20 7369 6465 3a20 4275  s(self, side: Bu
+0000cb30: 7953 656c 6c2c 206f 7264 6572 7479 7065  ySell, ordertype
+0000cb40: 3a20 7374 722c 2073 746f 705f 7072 6963  : str, stop_pric
+0000cb50: 653a 2066 6c6f 6174 2920 2d3e 2044 6963  e: float) -> Dic
+0000cb60: 743a 0a20 2020 2020 2020 2070 6172 616d  t:.        param
+0000cb70: 7320 3d20 7365 6c66 2e5f 7061 7261 6d73  s = self._params
+0000cb80: 2e63 6f70 7928 290a 2020 2020 2020 2020  .copy().        
+0000cb90: 2320 5665 7269 6679 2069 6620 7374 6f70  # Verify if stop
+0000cba0: 5072 6963 6520 776f 726b 7320 666f 7220  Price works for 
+0000cbb0: 796f 7572 2065 7863 6861 6e67 652c 2065  your exchange, e
+0000cbc0: 6c73 6520 636f 6e66 6967 7572 6520 7374  lse configure st
+0000cbd0: 6f70 5f70 7269 6365 5f70 6172 616d 0a20  op_price_param. 
+0000cbe0: 2020 2020 2020 2070 6172 616d 732e 7570         params.up
+0000cbf0: 6461 7465 287b 7365 6c66 2e5f 6674 5f68  date({self._ft_h
+0000cc00: 6173 5b22 7374 6f70 5f70 7269 6365 5f70  as["stop_price_p
+0000cc10: 6172 616d 225d 3a20 7374 6f70 5f70 7269  aram"]: stop_pri
+0000cc20: 6365 7d29 0a20 2020 2020 2020 2072 6574  ce}).        ret
+0000cc30: 7572 6e20 7061 7261 6d73 0a0a 2020 2020  urn params..    
+0000cc40: 4072 6574 7269 6572 2872 6574 7269 6573  @retrier(retries
+0000cc50: 3d30 290a 2020 2020 6465 6620 6372 6561  =0).    def crea
+0000cc60: 7465 5f73 746f 706c 6f73 7328 0a20 2020  te_stoploss(.   
+0000cc70: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+0000cc80: 2020 2070 6169 723a 2073 7472 2c0a 2020     pair: str,.  
+0000cc90: 2020 2020 2020 616d 6f75 6e74 3a20 666c        amount: fl
+0000cca0: 6f61 742c 0a20 2020 2020 2020 2073 746f  oat,.        sto
+0000ccb0: 705f 7072 6963 653a 2066 6c6f 6174 2c0a  p_price: float,.
+0000ccc0: 2020 2020 2020 2020 6f72 6465 725f 7479          order_ty
+0000ccd0: 7065 733a 2044 6963 742c 0a20 2020 2020  pes: Dict,.     
+0000cce0: 2020 2073 6964 653a 2042 7579 5365 6c6c     side: BuySell
+0000ccf0: 2c0a 2020 2020 2020 2020 6c65 7665 7261  ,.        levera
+0000cd00: 6765 3a20 666c 6f61 742c 0a20 2020 2029  ge: float,.    )
+0000cd10: 202d 3e20 4469 6374 3a0a 2020 2020 2020   -> Dict:.      
+0000cd20: 2020 2222 220a 2020 2020 2020 2020 6372    """.        cr
+0000cd30: 6561 7465 7320 6120 7374 6f70 6c6f 7373  eates a stoploss
+0000cd40: 206f 7264 6572 2e0a 2020 2020 2020 2020   order..        
+0000cd50: 7265 7175 6972 6573 2060 5f66 745f 6861  requires `_ft_ha
+0000cd60: 735b 2773 746f 706c 6f73 735f 6f72 6465  s['stoploss_orde
+0000cd70: 725f 7479 7065 7327 5d60 2074 6f20 6265  r_types']` to be
+0000cd80: 2073 6574 2061 7320 6120 6469 6374 206d   set as a dict m
+0000cd90: 6170 7069 6e67 206c 696d 6974 2061 6e64  apping limit and
+0000cda0: 206d 6172 6b65 740a 2020 2020 2020 2020   market.        
+0000cdb0: 2020 2020 746f 2074 6865 2063 6f72 7265      to the corre
+0000cdc0: 7370 6f6e 6469 6e67 2065 7863 6861 6e67  sponding exchang
+0000cdd0: 6520 7479 7065 2e0a 0a20 2020 2020 2020  e type...       
+0000cde0: 2054 6865 2070 7265 6369 7365 206f 7264   The precise ord
+0000cdf0: 6572 7479 7065 2069 7320 6465 7465 726d  ertype is determ
+0000ce00: 696e 6564 2062 7920 7468 6520 6f72 6465  ined by the orde
+0000ce10: 725f 7479 7065 7320 6469 6374 206f 7220  r_types dict or 
+0000ce20: 6578 6368 616e 6765 2064 6566 6175 6c74  exchange default
+0000ce30: 2e0a 0a20 2020 2020 2020 2054 6865 2065  ...        The e
+0000ce40: 7863 6570 7469 6f6e 2062 656c 6f77 2073  xception below s
+0000ce50: 686f 756c 6420 6e65 7665 7220 7261 6973  hould never rais
+0000ce60: 652c 2073 696e 6365 2077 6520 6469 7361  e, since we disa
+0000ce70: 6c6c 6f77 0a20 2020 2020 2020 2073 7461  llow.        sta
+0000ce80: 7274 696e 6720 7468 6520 626f 7420 696e  rting the bot in
+0000ce90: 2076 616c 6964 6174 655f 6f72 6465 7274   validate_ordert
+0000cea0: 7970 6573 2829 0a0a 2020 2020 2020 2020  ypes()..        
+0000ceb0: 5468 6973 206d 6179 2077 6f72 6b20 7769  This may work wi
+0000cec0: 7468 2061 206c 696d 6974 6564 206e 756d  th a limited num
+0000ced0: 6265 7220 6f66 206f 7468 6572 2065 7863  ber of other exc
+0000cee0: 6861 6e67 6573 2c20 6275 7420 636f 7272  hanges, but corr
+0000cef0: 6563 7420 776f 726b 696e 670a 2020 2020  ect working.    
+0000cf00: 2020 2020 2020 2020 6e65 6564 7320 746f          needs to
+0000cf10: 2062 6520 7465 7374 6564 2069 6e64 6976   be tested indiv
+0000cf20: 6964 7561 6c6c 792e 0a20 2020 2020 2020  idually..       
+0000cf30: 2057 4152 4e49 4e47 3a20 7365 7474 696e   WARNING: settin
+0000cf40: 6720 6073 746f 706c 6f73 735f 6f6e 5f65  g `stoploss_on_e
+0000cf50: 7863 6861 6e67 6560 2074 6f20 5472 7565  xchange` to True
+0000cf60: 2077 696c 6c20 4e4f 5420 6175 746f 2d65   will NOT auto-e
+0000cf70: 6e61 626c 6520 7374 6f70 6c6f 7373 206f  nable stoploss o
+0000cf80: 6e20 6578 6368 616e 6765 2e0a 2020 2020  n exchange..    
+0000cf90: 2020 2020 2020 2020 6073 746f 706c 6f73          `stoplos
+0000cfa0: 735f 6164 6a75 7374 6020 6d75 7374 2073  s_adjust` must s
+0000cfb0: 7469 6c6c 2062 6520 696d 706c 656d 656e  till be implemen
+0000cfc0: 7465 6420 666f 7220 7468 6973 2074 6f20  ted for this to 
+0000cfd0: 776f 726b 2e0a 2020 2020 2020 2020 2222  work..        ""
+0000cfe0: 220a 2020 2020 2020 2020 6966 206e 6f74  ".        if not
+0000cff0: 2073 656c 662e 5f66 745f 6861 735b 2273   self._ft_has["s
+0000d000: 746f 706c 6f73 735f 6f6e 5f65 7863 6861  toploss_on_excha
+0000d010: 6e67 6522 5d3a 0a20 2020 2020 2020 2020  nge"]:.         
+0000d020: 2020 2072 6169 7365 204f 7065 7261 7469     raise Operati
+0000d030: 6f6e 616c 4578 6365 7074 696f 6e28 6622  onalException(f"
+0000d040: 7374 6f70 6c6f 7373 2069 7320 6e6f 7420  stoploss is not 
+0000d050: 696d 706c 656d 656e 7465 6420 666f 7220  implemented for 
+0000d060: 7b73 656c 662e 6e61 6d65 7d2e 2229 0a0a  {self.name}.")..
+0000d070: 2020 2020 2020 2020 7573 6572 5f6f 7264          user_ord
+0000d080: 6572 5f74 7970 6520 3d20 6f72 6465 725f  er_type = order_
+0000d090: 7479 7065 732e 6765 7428 2273 746f 706c  types.get("stopl
+0000d0a0: 6f73 7322 2c20 226d 6172 6b65 7422 290a  oss", "market").
+0000d0b0: 2020 2020 2020 2020 6f72 6465 7274 7970          ordertyp
+0000d0c0: 652c 2075 7365 725f 6f72 6465 725f 7479  e, user_order_ty
+0000d0d0: 7065 203d 2073 656c 662e 5f67 6574 5f73  pe = self._get_s
+0000d0e0: 746f 705f 6f72 6465 725f 7479 7065 2875  top_order_type(u
+0000d0f0: 7365 725f 6f72 6465 725f 7479 7065 290a  ser_order_type).
+0000d100: 2020 2020 2020 2020 726f 756e 645f 6d6f          round_mo
+0000d110: 6465 203d 2052 4f55 4e44 5f44 4f57 4e20  de = ROUND_DOWN 
+0000d120: 6966 2073 6964 6520 3d3d 2022 6275 7922  if side == "buy"
+0000d130: 2065 6c73 6520 524f 554e 445f 5550 0a20   else ROUND_UP. 
+0000d140: 2020 2020 2020 2073 746f 705f 7072 6963         stop_pric
+0000d150: 655f 6e6f 726d 203d 2073 656c 662e 7072  e_norm = self.pr
+0000d160: 6963 655f 746f 5f70 7265 6369 7369 6f6e  ice_to_precision
+0000d170: 2870 6169 722c 2073 746f 705f 7072 6963  (pair, stop_pric
+0000d180: 652c 2072 6f75 6e64 696e 675f 6d6f 6465  e, rounding_mode
+0000d190: 3d72 6f75 6e64 5f6d 6f64 6529 0a20 2020  =round_mode).   
+0000d1a0: 2020 2020 206c 696d 6974 5f72 6174 6520       limit_rate 
+0000d1b0: 3d20 4e6f 6e65 0a20 2020 2020 2020 2069  = None.        i
+0000d1c0: 6620 7573 6572 5f6f 7264 6572 5f74 7970  f user_order_typ
+0000d1d0: 6520 3d3d 2022 6c69 6d69 7422 3a0a 2020  e == "limit":.  
+0000d1e0: 2020 2020 2020 2020 2020 6c69 6d69 745f            limit_
+0000d1f0: 7261 7465 203d 2073 656c 662e 5f67 6574  rate = self._get
+0000d200: 5f73 746f 705f 6c69 6d69 745f 7261 7465  _stop_limit_rate
+0000d210: 2873 746f 705f 7072 6963 652c 206f 7264  (stop_price, ord
+0000d220: 6572 5f74 7970 6573 2c20 7369 6465 290a  er_types, side).
+0000d230: 2020 2020 2020 2020 2020 2020 6c69 6d69              limi
+0000d240: 745f 7261 7465 203d 2073 656c 662e 7072  t_rate = self.pr
+0000d250: 6963 655f 746f 5f70 7265 6369 7369 6f6e  ice_to_precision
+0000d260: 2870 6169 722c 206c 696d 6974 5f72 6174  (pair, limit_rat
+0000d270: 652c 2072 6f75 6e64 696e 675f 6d6f 6465  e, rounding_mode
+0000d280: 3d72 6f75 6e64 5f6d 6f64 6529 0a0a 2020  =round_mode)..  
+0000d290: 2020 2020 2020 6966 2073 656c 662e 5f63        if self._c
+0000d2a0: 6f6e 6669 675b 2264 7279 5f72 756e 225d  onfig["dry_run"]
+0000d2b0: 3a0a 2020 2020 2020 2020 2020 2020 6472  :.            dr
+0000d2c0: 795f 6f72 6465 7220 3d20 7365 6c66 2e63  y_order = self.c
+0000d2d0: 7265 6174 655f 6472 795f 7275 6e5f 6f72  reate_dry_run_or
+0000d2e0: 6465 7228 0a20 2020 2020 2020 2020 2020  der(.           
+0000d2f0: 2020 2020 2070 6169 722c 0a20 2020 2020       pair,.     
+0000d300: 2020 2020 2020 2020 2020 206f 7264 6572             order
+0000d310: 7479 7065 2c0a 2020 2020 2020 2020 2020  type,.          
+0000d320: 2020 2020 2020 7369 6465 2c0a 2020 2020        side,.    
+0000d330: 2020 2020 2020 2020 2020 2020 616d 6f75              amou
+0000d340: 6e74 2c0a 2020 2020 2020 2020 2020 2020  nt,.            
+0000d350: 2020 2020 7374 6f70 5f70 7269 6365 5f6e      stop_price_n
+0000d360: 6f72 6d2c 0a20 2020 2020 2020 2020 2020  orm,.           
+0000d370: 2020 2020 2073 746f 705f 6c6f 7373 3d54       stop_loss=T
+0000d380: 7275 652c 0a20 2020 2020 2020 2020 2020  rue,.           
+0000d390: 2020 2020 206c 6576 6572 6167 653d 6c65       leverage=le
+0000d3a0: 7665 7261 6765 2c0a 2020 2020 2020 2020  verage,.        
+0000d3b0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+0000d3c0: 2020 7265 7475 726e 2064 7279 5f6f 7264    return dry_ord
+0000d3d0: 6572 0a0a 2020 2020 2020 2020 7472 793a  er..        try:
+0000d3e0: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
+0000d3f0: 616d 7320 3d20 7365 6c66 2e5f 6765 745f  ams = self._get_
+0000d400: 7374 6f70 5f70 6172 616d 7328 0a20 2020  stop_params(.   
+0000d410: 2020 2020 2020 2020 2020 2020 2073 6964               sid
+0000d420: 653d 7369 6465 2c20 6f72 6465 7274 7970  e=side, ordertyp
+0000d430: 653d 6f72 6465 7274 7970 652c 2073 746f  e=ordertype, sto
+0000d440: 705f 7072 6963 653d 7374 6f70 5f70 7269  p_price=stop_pri
+0000d450: 6365 5f6e 6f72 6d0a 2020 2020 2020 2020  ce_norm.        
+0000d460: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+0000d470: 2020 6966 2073 656c 662e 7472 6164 696e    if self.tradin
+0000d480: 675f 6d6f 6465 203d 3d20 5472 6164 696e  g_mode == Tradin
+0000d490: 674d 6f64 652e 4655 5455 5245 533a 0a20  gMode.FUTURES:. 
+0000d4a0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0000d4b0: 6172 616d 735b 2272 6564 7563 654f 6e6c  arams["reduceOnl
+0000d4c0: 7922 5d20 3d20 5472 7565 0a20 2020 2020  y"] = True.     
+0000d4d0: 2020 2020 2020 2020 2020 2069 6620 2273             if "s
+0000d4e0: 746f 706c 6f73 735f 7072 6963 655f 7479  toploss_price_ty
+0000d4f0: 7065 2220 696e 206f 7264 6572 5f74 7970  pe" in order_typ
+0000d500: 6573 2061 6e64 2022 7374 6f70 5f70 7269  es and "stop_pri
+0000d510: 6365 5f74 7970 655f 6669 656c 6422 2069  ce_type_field" i
+0000d520: 6e20 7365 6c66 2e5f 6674 5f68 6173 3a0a  n self._ft_has:.
+0000d530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d540: 2020 2020 7072 6963 655f 7479 7065 203d      price_type =
+0000d550: 2073 656c 662e 5f66 745f 6861 735b 2273   self._ft_has["s
+0000d560: 746f 705f 7072 6963 655f 7479 7065 5f76  top_price_type_v
+0000d570: 616c 7565 5f6d 6170 7069 6e67 225d 5b0a  alue_mapping"][.
+0000d580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d590: 2020 2020 2020 2020 6f72 6465 725f 7479          order_ty
+0000d5a0: 7065 732e 6765 7428 2273 746f 706c 6f73  pes.get("stoplos
+0000d5b0: 735f 7072 6963 655f 7479 7065 222c 2050  s_price_type", P
+0000d5c0: 7269 6365 5479 7065 2e4c 4153 5429 0a20  riceType.LAST). 
+0000d5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d5e0: 2020 205d 0a20 2020 2020 2020 2020 2020     ].           
+0000d5f0: 2020 2020 2020 2020 2070 6172 616d 735b           params[
+0000d600: 7365 6c66 2e5f 6674 5f68 6173 5b22 7374  self._ft_has["st
+0000d610: 6f70 5f70 7269 6365 5f74 7970 655f 6669  op_price_type_fi
+0000d620: 656c 6422 5d5d 203d 2070 7269 6365 5f74  eld"]] = price_t
+0000d630: 7970 650a 0a20 2020 2020 2020 2020 2020  ype..           
+0000d640: 2061 6d6f 756e 7420 3d20 7365 6c66 2e61   amount = self.a
+0000d650: 6d6f 756e 745f 746f 5f70 7265 6369 7369  mount_to_precisi
+0000d660: 6f6e 2870 6169 722c 2073 656c 662e 5f61  on(pair, self._a
+0000d670: 6d6f 756e 745f 746f 5f63 6f6e 7472 6163  mount_to_contrac
+0000d680: 7473 2870 6169 722c 2061 6d6f 756e 7429  ts(pair, amount)
+0000d690: 290a 0a20 2020 2020 2020 2020 2020 2073  )..            s
+0000d6a0: 656c 662e 5f6c 6576 5f70 7265 7028 7061  elf._lev_prep(pa
+0000d6b0: 6972 2c20 6c65 7665 7261 6765 2c20 7369  ir, leverage, si
+0000d6c0: 6465 2c20 6163 6365 7074 5f66 6169 6c3d  de, accept_fail=
+0000d6d0: 5472 7565 290a 2020 2020 2020 2020 2020  True).          
+0000d6e0: 2020 6f72 6465 7220 3d20 7365 6c66 2e5f    order = self._
+0000d6f0: 6170 692e 6372 6561 7465 5f6f 7264 6572  api.create_order
+0000d700: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0000d710: 2020 7379 6d62 6f6c 3d70 6169 722c 0a20    symbol=pair,. 
+0000d720: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+0000d730: 7970 653d 6f72 6465 7274 7970 652c 0a20  ype=ordertype,. 
+0000d740: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0000d750: 6964 653d 7369 6465 2c0a 2020 2020 2020  ide=side,.      
+0000d760: 2020 2020 2020 2020 2020 616d 6f75 6e74            amount
+0000d770: 3d61 6d6f 756e 742c 0a20 2020 2020 2020  =amount,.       
+0000d780: 2020 2020 2020 2020 2070 7269 6365 3d6c           price=l
+0000d790: 696d 6974 5f72 6174 652c 0a20 2020 2020  imit_rate,.     
+0000d7a0: 2020 2020 2020 2020 2020 2070 6172 616d             param
+0000d7b0: 733d 7061 7261 6d73 2c0a 2020 2020 2020  s=params,.      
+0000d7c0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0000d7d0: 2020 2020 7365 6c66 2e5f 6c6f 675f 6578      self._log_ex
+0000d7e0: 6368 616e 6765 5f72 6573 706f 6e73 6528  change_response(
+0000d7f0: 2263 7265 6174 655f 7374 6f70 6c6f 7373  "create_stoploss
+0000d800: 5f6f 7264 6572 222c 206f 7264 6572 290a  _order", order).
+0000d810: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
+0000d820: 7220 3d20 7365 6c66 2e5f 6f72 6465 725f  r = self._order_
+0000d830: 636f 6e74 7261 6374 735f 746f 5f61 6d6f  contracts_to_amo
+0000d840: 756e 7428 6f72 6465 7229 0a20 2020 2020  unt(order).     
+0000d850: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
+0000d860: 666f 280a 2020 2020 2020 2020 2020 2020  fo(.            
+0000d870: 2020 2020 6622 7374 6f70 6c6f 7373 207b      f"stoploss {
+0000d880: 7573 6572 5f6f 7264 6572 5f74 7970 657d  user_order_type}
+0000d890: 206f 7264 6572 2061 6464 6564 2066 6f72   order added for
+0000d8a0: 207b 7061 6972 7d2e 2022 0a20 2020 2020   {pair}. ".     
+0000d8b0: 2020 2020 2020 2020 2020 2066 2273 746f             f"sto
+0000d8c0: 7020 7072 6963 653a 207b 7374 6f70 5f70  p price: {stop_p
+0000d8d0: 7269 6365 7d2e 206c 696d 6974 3a20 7b6c  rice}. limit: {l
+0000d8e0: 696d 6974 5f72 6174 657d 220a 2020 2020  imit_rate}".    
+0000d8f0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+0000d900: 2020 2020 2020 7265 7475 726e 206f 7264        return ord
+0000d910: 6572 0a20 2020 2020 2020 2065 7863 6570  er.        excep
+0000d920: 7420 6363 7874 2e49 6e73 7566 6669 6369  t ccxt.Insuffici
+0000d930: 656e 7446 756e 6473 2061 7320 653a 0a20  entFunds as e:. 
+0000d940: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000d950: 2049 6e73 7566 6669 6369 656e 7446 756e   InsufficientFun
+0000d960: 6473 4572 726f 7228 0a20 2020 2020 2020  dsError(.       
+0000d970: 2020 2020 2020 2020 2066 2249 6e73 7566           f"Insuf
+0000d980: 6669 6369 656e 7420 6675 6e64 7320 746f  ficient funds to
+0000d990: 2063 7265 6174 6520 7b6f 7264 6572 7479   create {orderty
+0000d9a0: 7065 7d20 7b73 6964 657d 206f 7264 6572  pe} {side} order
+0000d9b0: 206f 6e20 6d61 726b 6574 207b 7061 6972   on market {pair
+0000d9c0: 7d2e 2022 0a20 2020 2020 2020 2020 2020  }. ".           
+0000d9d0: 2020 2020 2066 2254 7269 6564 2074 6f20       f"Tried to 
+0000d9e0: 7b73 6964 657d 2061 6d6f 756e 7420 7b61  {side} amount {a
+0000d9f0: 6d6f 756e 747d 2061 7420 7261 7465 207b  mount} at rate {
+0000da00: 6c69 6d69 745f 7261 7465 7d20 7769 7468  limit_rate} with
+0000da10: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
+0000da20: 2020 2066 2273 746f 702d 7072 6963 6520     f"stop-price 
+0000da30: 7b73 746f 705f 7072 6963 655f 6e6f 726d  {stop_price_norm
+0000da40: 7d2e 204d 6573 7361 6765 3a20 7b65 7d22  }. Message: {e}"
+0000da50: 0a20 2020 2020 2020 2020 2020 2029 2066  .            ) f
+0000da60: 726f 6d20 650a 2020 2020 2020 2020 6578  rom e.        ex
+0000da70: 6365 7074 2028 6363 7874 2e49 6e76 616c  cept (ccxt.Inval
+0000da80: 6964 4f72 6465 722c 2063 6378 742e 4261  idOrder, ccxt.Ba
+0000da90: 6452 6571 7565 7374 2c20 6363 7874 2e4f  dRequest, ccxt.O
+0000daa0: 7065 7261 7469 6f6e 5265 6a65 6374 6564  perationRejected
+0000dab0: 2920 6173 2065 3a0a 2020 2020 2020 2020  ) as e:.        
+0000dac0: 2020 2020 2320 4572 726f 7273 3a0a 2020      # Errors:.  
+0000dad0: 2020 2020 2020 2020 2020 2320 604f 7264            # `Ord
+0000dae0: 6572 2077 6f75 6c64 2074 7269 6767 6572  er would trigger
+0000daf0: 2069 6d6d 6564 6961 7465 6c79 2e60 0a20   immediately.`. 
+0000db00: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000db10: 2049 6e76 616c 6964 4f72 6465 7245 7863   InvalidOrderExc
+0000db20: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
+0000db30: 2020 2020 2020 2020 6622 436f 756c 6420          f"Could 
+0000db40: 6e6f 7420 6372 6561 7465 207b 6f72 6465  not create {orde
+0000db50: 7274 7970 657d 207b 7369 6465 7d20 6f72  rtype} {side} or
+0000db60: 6465 7220 6f6e 206d 6172 6b65 7420 7b70  der on market {p
+0000db70: 6169 727d 2e20 220a 2020 2020 2020 2020  air}. ".        
+0000db80: 2020 2020 2020 2020 6622 5472 6965 6420          f"Tried 
+0000db90: 746f 207b 7369 6465 7d20 616d 6f75 6e74  to {side} amount
+0000dba0: 207b 616d 6f75 6e74 7d20 6174 2072 6174   {amount} at rat
+0000dbb0: 6520 7b6c 696d 6974 5f72 6174 657d 2077  e {limit_rate} w
+0000dbc0: 6974 6820 220a 2020 2020 2020 2020 2020  ith ".          
+0000dbd0: 2020 2020 2020 6622 7374 6f70 2d70 7269        f"stop-pri
+0000dbe0: 6365 207b 7374 6f70 5f70 7269 6365 5f6e  ce {stop_price_n
+0000dbf0: 6f72 6d7d 2e20 4d65 7373 6167 653a 207b  orm}. Message: {
+0000dc00: 657d 220a 2020 2020 2020 2020 2020 2020  e}".            
+0000dc10: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
+0000dc20: 2065 7863 6570 7420 6363 7874 2e44 446f   except ccxt.DDo
+0000dc30: 5350 726f 7465 6374 696f 6e20 6173 2065  SProtection as e
+0000dc40: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+0000dc50: 6973 6520 4444 6f73 5072 6f74 6563 7469  ise DDosProtecti
+0000dc60: 6f6e 2865 2920 6672 6f6d 2065 0a20 2020  on(e) from e.   
+0000dc70: 2020 2020 2065 7863 6570 7420 2863 6378       except (ccx
+0000dc80: 742e 4f70 6572 6174 696f 6e46 6169 6c65  t.OperationFaile
+0000dc90: 642c 2063 6378 742e 4578 6368 616e 6765  d, ccxt.Exchange
+0000dca0: 4572 726f 7229 2061 7320 653a 0a20 2020  Error) as e:.   
+0000dcb0: 2020 2020 2020 2020 2072 6169 7365 2054           raise T
+0000dcc0: 656d 706f 7261 7279 4572 726f 7228 0a20  emporaryError(. 
+0000dcd0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000dce0: 2243 6f75 6c64 206e 6f74 2070 6c61 6365  "Could not place
+0000dcf0: 2073 746f 706c 6f73 7320 6f72 6465 7220   stoploss order 
+0000dd00: 6475 6520 746f 207b 652e 5f5f 636c 6173  due to {e.__clas
+0000dd10: 735f 5f2e 5f5f 6e61 6d65 5f5f 7d2e 204d  s__.__name__}. M
+0000dd20: 6573 7361 6765 3a20 7b65 7d22 0a20 2020  essage: {e}".   
+0000dd30: 2020 2020 2020 2020 2029 2066 726f 6d20           ) from 
+0000dd40: 650a 2020 2020 2020 2020 6578 6365 7074  e.        except
+0000dd50: 2063 6378 742e 4261 7365 4572 726f 7220   ccxt.BaseError 
+0000dd60: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
+0000dd70: 2020 7261 6973 6520 4f70 6572 6174 696f    raise Operatio
+0000dd80: 6e61 6c45 7863 6570 7469 6f6e 2865 2920  nalException(e) 
+0000dd90: 6672 6f6d 2065 0a0a 2020 2020 6465 6620  from e..    def 
+0000dda0: 6665 7463 685f 6f72 6465 725f 656d 756c  fetch_order_emul
+0000ddb0: 6174 6564 2873 656c 662c 206f 7264 6572  ated(self, order
+0000ddc0: 5f69 643a 2073 7472 2c20 7061 6972 3a20  _id: str, pair: 
+0000ddd0: 7374 722c 2070 6172 616d 733a 2044 6963  str, params: Dic
+0000dde0: 7429 202d 3e20 4469 6374 3a0a 2020 2020  t) -> Dict:.    
+0000ddf0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0000de00: 456d 756c 6174 6564 2066 6574 6368 5f6f  Emulated fetch_o
+0000de10: 7264 6572 2069 6620 7468 6520 6578 6368  rder if the exch
+0000de20: 616e 6765 2064 6f65 736e 2774 2073 7570  ange doesn't sup
+0000de30: 706f 7274 2066 6574 6368 5f6f 7264 6572  port fetch_order
+0000de40: 2c20 6275 7420 7265 7175 6972 6573 2073  , but requires s
+0000de50: 6570 6172 6174 650a 2020 2020 2020 2020  eparate.        
+0000de60: 6361 6c6c 7320 666f 7220 6f70 656e 2061  calls for open a
+0000de70: 6e64 2063 6c6f 7365 6420 6f72 6465 7273  nd closed orders
+0000de80: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+0000de90: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+0000dea0: 2020 2020 2020 206f 7264 6572 203d 2073         order = s
+0000deb0: 656c 662e 5f61 7069 2e66 6574 6368 5f6f  elf._api.fetch_o
+0000dec0: 7065 6e5f 6f72 6465 7228 6f72 6465 725f  pen_order(order_
+0000ded0: 6964 2c20 7061 6972 2c20 7061 7261 6d73  id, pair, params
+0000dee0: 3d70 6172 616d 7329 0a20 2020 2020 2020  =params).       
+0000def0: 2020 2020 2073 656c 662e 5f6c 6f67 5f65       self._log_e
+0000df00: 7863 6861 6e67 655f 7265 7370 6f6e 7365  xchange_response
+0000df10: 2822 6665 7463 685f 6f70 656e 5f6f 7264  ("fetch_open_ord
+0000df20: 6572 222c 206f 7264 6572 290a 2020 2020  er", order).    
+0000df30: 2020 2020 2020 2020 6f72 6465 7220 3d20          order = 
+0000df40: 7365 6c66 2e5f 6f72 6465 725f 636f 6e74  self._order_cont
+0000df50: 7261 6374 735f 746f 5f61 6d6f 756e 7428  racts_to_amount(
+0000df60: 6f72 6465 7229 0a20 2020 2020 2020 2020  order).         
+0000df70: 2020 2072 6574 7572 6e20 6f72 6465 720a     return order.
+0000df80: 2020 2020 2020 2020 6578 6365 7074 2063          except c
+0000df90: 6378 742e 4f72 6465 724e 6f74 466f 756e  cxt.OrderNotFoun
+0000dfa0: 643a 0a20 2020 2020 2020 2020 2020 2074  d:.            t
+0000dfb0: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
+0000dfc0: 2020 2020 6f72 6465 7220 3d20 7365 6c66      order = self
+0000dfd0: 2e5f 6170 692e 6665 7463 685f 636c 6f73  ._api.fetch_clos
+0000dfe0: 6564 5f6f 7264 6572 286f 7264 6572 5f69  ed_order(order_i
+0000dff0: 642c 2070 6169 722c 2070 6172 616d 733d  d, pair, params=
+0000e000: 7061 7261 6d73 290a 2020 2020 2020 2020  params).        
+0000e010: 2020 2020 2020 2020 7365 6c66 2e5f 6c6f          self._lo
+0000e020: 675f 6578 6368 616e 6765 5f72 6573 706f  g_exchange_respo
+0000e030: 6e73 6528 2266 6574 6368 5f63 6c6f 7365  nse("fetch_close
+0000e040: 645f 6f72 6465 7222 2c20 6f72 6465 7229  d_order", order)
+0000e050: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e060: 206f 7264 6572 203d 2073 656c 662e 5f6f   order = self._o
+0000e070: 7264 6572 5f63 6f6e 7472 6163 7473 5f74  rder_contracts_t
+0000e080: 6f5f 616d 6f75 6e74 286f 7264 6572 290a  o_amount(order).
+0000e090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e0a0: 7265 7475 726e 206f 7264 6572 0a20 2020  return order.   
+0000e0b0: 2020 2020 2020 2020 2065 7863 6570 7420           except 
+0000e0c0: 6363 7874 2e4f 7264 6572 4e6f 7446 6f75  ccxt.OrderNotFou
+0000e0d0: 6e64 2061 7320 653a 0a20 2020 2020 2020  nd as e:.       
+0000e0e0: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
+0000e0f0: 6574 7279 6162 6c65 4f72 6465 7245 7272  etryableOrderErr
+0000e100: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
+0000e110: 2020 2020 2020 2020 6622 4f72 6465 7220          f"Order 
+0000e120: 6e6f 7420 666f 756e 6420 2870 6169 723a  not found (pair:
+0000e130: 207b 7061 6972 7d20 6964 3a20 7b6f 7264   {pair} id: {ord
+0000e140: 6572 5f69 647d 292e 204d 6573 7361 6765  er_id}). Message
+0000e150: 3a20 7b65 7d22 0a20 2020 2020 2020 2020  : {e}".         
+0000e160: 2020 2020 2020 2029 2066 726f 6d20 650a         ) from e.
+0000e170: 2020 2020 2020 2020 6578 6365 7074 2063          except c
+0000e180: 6378 742e 496e 7661 6c69 644f 7264 6572  cxt.InvalidOrder
+0000e190: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
+0000e1a0: 2020 2072 6169 7365 2049 6e76 616c 6964     raise Invalid
+0000e1b0: 4f72 6465 7245 7863 6570 7469 6f6e 280a  OrderException(.
+0000e1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e1d0: 6622 5472 6965 6420 746f 2067 6574 2061  f"Tried to get a
+0000e1e0: 6e20 696e 7661 6c69 6420 6f72 6465 7220  n invalid order 
+0000e1f0: 2870 6169 723a 207b 7061 6972 7d20 6964  (pair: {pair} id
+0000e200: 3a20 7b6f 7264 6572 5f69 647d 292e 204d  : {order_id}). M
+0000e210: 6573 7361 6765 3a20 7b65 7d22 0a20 2020  essage: {e}".   
+0000e220: 2020 2020 2020 2020 2029 2066 726f 6d20           ) from 
+0000e230: 650a 2020 2020 2020 2020 6578 6365 7074  e.        except
+0000e240: 2063 6378 742e 4444 6f53 5072 6f74 6563   ccxt.DDoSProtec
+0000e250: 7469 6f6e 2061 7320 653a 0a20 2020 2020  tion as e:.     
+0000e260: 2020 2020 2020 2072 6169 7365 2044 446f         raise DDo
+0000e270: 7350 726f 7465 6374 696f 6e28 6529 2066  sProtection(e) f
+0000e280: 726f 6d20 650a 2020 2020 2020 2020 6578  rom e.        ex
+0000e290: 6365 7074 2028 6363 7874 2e4f 7065 7261  cept (ccxt.Opera
+0000e2a0: 7469 6f6e 4661 696c 6564 2c20 6363 7874  tionFailed, ccxt
+0000e2b0: 2e45 7863 6861 6e67 6545 7272 6f72 2920  .ExchangeError) 
+0000e2c0: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
+0000e2d0: 2020 7261 6973 6520 5465 6d70 6f72 6172    raise Temporar
+0000e2e0: 7945 7272 6f72 280a 2020 2020 2020 2020  yError(.        
+0000e2f0: 2020 2020 2020 2020 6622 436f 756c 6420          f"Could 
+0000e300: 6e6f 7420 6765 7420 6f72 6465 7220 6475  not get order du
+0000e310: 6520 746f 207b 652e 5f5f 636c 6173 735f  e to {e.__class_
+0000e320: 5f2e 5f5f 6e61 6d65 5f5f 7d2e 204d 6573  _.__name__}. Mes
+0000e330: 7361 6765 3a20 7b65 7d22 0a20 2020 2020  sage: {e}".     
+0000e340: 2020 2020 2020 2029 2066 726f 6d20 650a         ) from e.
+0000e350: 2020 2020 2020 2020 6578 6365 7074 2063          except c
+0000e360: 6378 742e 4261 7365 4572 726f 7220 6173  cxt.BaseError as
+0000e370: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
+0000e380: 7261 6973 6520 4f70 6572 6174 696f 6e61  raise Operationa
+0000e390: 6c45 7863 6570 7469 6f6e 2865 2920 6672  lException(e) fr
+0000e3a0: 6f6d 2065 0a0a 2020 2020 4072 6574 7269  om e..    @retri
+0000e3b0: 6572 2872 6574 7269 6573 3d41 5049 5f46  er(retries=API_F
+0000e3c0: 4554 4348 5f4f 5244 4552 5f52 4554 5259  ETCH_ORDER_RETRY
+0000e3d0: 5f43 4f55 4e54 290a 2020 2020 6465 6620  _COUNT).    def 
+0000e3e0: 6665 7463 685f 6f72 6465 7228 7365 6c66  fetch_order(self
+0000e3f0: 2c20 6f72 6465 725f 6964 3a20 7374 722c  , order_id: str,
+0000e400: 2070 6169 723a 2073 7472 2c20 7061 7261   pair: str, para
+0000e410: 6d73 3a20 4f70 7469 6f6e 616c 5b44 6963  ms: Optional[Dic
+0000e420: 745d 203d 204e 6f6e 6529 202d 3e20 4469  t] = None) -> Di
+0000e430: 6374 3a0a 2020 2020 2020 2020 6966 2073  ct:.        if s
+0000e440: 656c 662e 5f63 6f6e 6669 675b 2264 7279  elf._config["dry
+0000e450: 5f72 756e 225d 3a0a 2020 2020 2020 2020  _run"]:.        
+0000e460: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+0000e470: 6665 7463 685f 6472 795f 7275 6e5f 6f72  fetch_dry_run_or
+0000e480: 6465 7228 6f72 6465 725f 6964 290a 2020  der(order_id).  
+0000e490: 2020 2020 2020 6966 2070 6172 616d 7320        if params 
+0000e4a0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+0000e4b0: 2020 2020 2070 6172 616d 7320 3d20 7b7d       params = {}
+0000e4c0: 0a20 2020 2020 2020 2074 7279 3a0a 2020  .        try:.  
+0000e4d0: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
+0000e4e0: 2073 656c 662e 6578 6368 616e 6765 5f68   self.exchange_h
+0000e4f0: 6173 2822 6665 7463 684f 7264 6572 2229  as("fetchOrder")
+0000e500: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000e510: 2020 7265 7475 726e 2073 656c 662e 6665    return self.fe
+0000e520: 7463 685f 6f72 6465 725f 656d 756c 6174  tch_order_emulat
+0000e530: 6564 286f 7264 6572 5f69 642c 2070 6169  ed(order_id, pai
+0000e540: 722c 2070 6172 616d 7329 0a20 2020 2020  r, params).     
+0000e550: 2020 2020 2020 206f 7264 6572 203d 2073         order = s
+0000e560: 656c 662e 5f61 7069 2e66 6574 6368 5f6f  elf._api.fetch_o
+0000e570: 7264 6572 286f 7264 6572 5f69 642c 2070  rder(order_id, p
+0000e580: 6169 722c 2070 6172 616d 733d 7061 7261  air, params=para
+0000e590: 6d73 290a 2020 2020 2020 2020 2020 2020  ms).            
+0000e5a0: 7365 6c66 2e5f 6c6f 675f 6578 6368 616e  self._log_exchan
+0000e5b0: 6765 5f72 6573 706f 6e73 6528 2266 6574  ge_response("fet
+0000e5c0: 6368 5f6f 7264 6572 222c 206f 7264 6572  ch_order", order
+0000e5d0: 290a 2020 2020 2020 2020 2020 2020 6f72  ).            or
+0000e5e0: 6465 7220 3d20 7365 6c66 2e5f 6f72 6465  der = self._orde
+0000e5f0: 725f 636f 6e74 7261 6374 735f 746f 5f61  r_contracts_to_a
+0000e600: 6d6f 756e 7428 6f72 6465 7229 0a20 2020  mount(order).   
+0000e610: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0000e620: 6f72 6465 720a 2020 2020 2020 2020 6578  order.        ex
+0000e630: 6365 7074 2063 6378 742e 4f72 6465 724e  cept ccxt.OrderN
+0000e640: 6f74 466f 756e 6420 6173 2065 3a0a 2020  otFound as e:.  
+0000e650: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000e660: 5265 7472 7961 626c 654f 7264 6572 4572  RetryableOrderEr
+0000e670: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
+0000e680: 2020 2020 2066 224f 7264 6572 206e 6f74       f"Order not
+0000e690: 2066 6f75 6e64 2028 7061 6972 3a20 7b70   found (pair: {p
+0000e6a0: 6169 727d 2069 643a 207b 6f72 6465 725f  air} id: {order_
+0000e6b0: 6964 7d29 2e20 4d65 7373 6167 653a 207b  id}). Message: {
+0000e6c0: 657d 220a 2020 2020 2020 2020 2020 2020  e}".            
+0000e6d0: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
+0000e6e0: 2065 7863 6570 7420 6363 7874 2e49 6e76   except ccxt.Inv
+0000e6f0: 616c 6964 4f72 6465 7220 6173 2065 3a0a  alidOrder as e:.
+0000e700: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0000e710: 6520 496e 7661 6c69 644f 7264 6572 4578  e InvalidOrderEx
+0000e720: 6365 7074 696f 6e28 0a20 2020 2020 2020  ception(.       
+0000e730: 2020 2020 2020 2020 2066 2254 7269 6564           f"Tried
+0000e740: 2074 6f20 6765 7420 616e 2069 6e76 616c   to get an inval
+0000e750: 6964 206f 7264 6572 2028 7061 6972 3a20  id order (pair: 
+0000e760: 7b70 6169 727d 2069 643a 207b 6f72 6465  {pair} id: {orde
+0000e770: 725f 6964 7d29 2e20 4d65 7373 6167 653a  r_id}). Message:
+0000e780: 207b 657d 220a 2020 2020 2020 2020 2020   {e}".          
+0000e790: 2020 2920 6672 6f6d 2065 0a20 2020 2020    ) from e.     
+0000e7a0: 2020 2065 7863 6570 7420 6363 7874 2e44     except ccxt.D
+0000e7b0: 446f 5350 726f 7465 6374 696f 6e20 6173  DoSProtection as
+0000e7c0: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
+0000e7d0: 7261 6973 6520 4444 6f73 5072 6f74 6563  raise DDosProtec
+0000e7e0: 7469 6f6e 2865 2920 6672 6f6d 2065 0a20  tion(e) from e. 
+0000e7f0: 2020 2020 2020 2065 7863 6570 7420 2863         except (c
+0000e800: 6378 742e 4f70 6572 6174 696f 6e46 6169  cxt.OperationFai
+0000e810: 6c65 642c 2063 6378 742e 4578 6368 616e  led, ccxt.Exchan
+0000e820: 6765 4572 726f 7229 2061 7320 653a 0a20  geError) as e:. 
+0000e830: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000e840: 2054 656d 706f 7261 7279 4572 726f 7228   TemporaryError(
+0000e850: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e860: 2066 2243 6f75 6c64 206e 6f74 2067 6574   f"Could not get
+0000e870: 206f 7264 6572 2064 7565 2074 6f20 7b65   order due to {e
+0000e880: 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e 616d  .__class__.__nam
+0000e890: 655f 5f7d 2e20 4d65 7373 6167 653a 207b  e__}. Message: {
+0000e8a0: 657d 220a 2020 2020 2020 2020 2020 2020  e}".            
+0000e8b0: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
+0000e8c0: 2065 7863 6570 7420 6363 7874 2e42 6173   except ccxt.Bas
+0000e8d0: 6545 7272 6f72 2061 7320 653a 0a20 2020  eError as e:.   
+0000e8e0: 2020 2020 2020 2020 2072 6169 7365 204f           raise O
+0000e8f0: 7065 7261 7469 6f6e 616c 4578 6365 7074  perationalExcept
+0000e900: 696f 6e28 6529 2066 726f 6d20 650a 0a20  ion(e) from e.. 
+0000e910: 2020 2064 6566 2066 6574 6368 5f73 746f     def fetch_sto
+0000e920: 706c 6f73 735f 6f72 6465 7228 7365 6c66  ploss_order(self
+0000e930: 2c20 6f72 6465 725f 6964 3a20 7374 722c  , order_id: str,
+0000e940: 2070 6169 723a 2073 7472 2c20 7061 7261   pair: str, para
+0000e950: 6d73 3a20 4f70 7469 6f6e 616c 5b44 6963  ms: Optional[Dic
+0000e960: 745d 203d 204e 6f6e 6529 202d 3e20 4469  t] = None) -> Di
+0000e970: 6374 3a0a 2020 2020 2020 2020 7265 7475  ct:.        retu
+0000e980: 726e 2073 656c 662e 6665 7463 685f 6f72  rn self.fetch_or
+0000e990: 6465 7228 6f72 6465 725f 6964 2c20 7061  der(order_id, pa
+0000e9a0: 6972 2c20 7061 7261 6d73 290a 0a20 2020  ir, params)..   
+0000e9b0: 2064 6566 2066 6574 6368 5f6f 7264 6572   def fetch_order
+0000e9c0: 5f6f 725f 7374 6f70 6c6f 7373 5f6f 7264  _or_stoploss_ord
+0000e9d0: 6572 280a 2020 2020 2020 2020 7365 6c66  er(.        self
+0000e9e0: 2c20 6f72 6465 725f 6964 3a20 7374 722c  , order_id: str,
+0000e9f0: 2070 6169 723a 2073 7472 2c20 7374 6f70   pair: str, stop
+0000ea00: 6c6f 7373 5f6f 7264 6572 3a20 626f 6f6c  loss_order: bool
+0000ea10: 203d 2046 616c 7365 0a20 2020 2029 202d   = False.    ) -
+0000ea20: 3e20 4469 6374 3a0a 2020 2020 2020 2020  > Dict:.        
+0000ea30: 2222 220a 2020 2020 2020 2020 5369 6d70  """.        Simp
+0000ea40: 6c65 2077 7261 7070 6572 2063 616c 6c69  le wrapper calli
+0000ea50: 6e67 2065 6974 6865 7220 6665 7463 685f  ng either fetch_
+0000ea60: 6f72 6465 7220 6f72 2066 6574 6368 5f73  order or fetch_s
+0000ea70: 746f 706c 6f73 735f 6f72 6465 7220 6465  toploss_order de
+0000ea80: 7065 6e64 696e 6720 6f6e 0a20 2020 2020  pending on.     
+0000ea90: 2020 2074 6865 2073 746f 706c 6f73 735f     the stoploss_
+0000eaa0: 6f72 6465 7220 7061 7261 6d65 7465 720a  order parameter.
+0000eab0: 2020 2020 2020 2020 3a70 6172 616d 206f          :param o
+0000eac0: 7264 6572 5f69 643a 204f 7264 6572 4964  rder_id: OrderId
+0000ead0: 2074 6f20 6665 7463 6820 6f72 6465 720a   to fetch order.
+0000eae0: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
+0000eaf0: 6169 723a 2050 6169 7220 636f 7272 6573  air: Pair corres
+0000eb00: 706f 6e64 696e 6720 746f 206f 7264 6572  ponding to order
+0000eb10: 5f69 640a 2020 2020 2020 2020 3a70 6172  _id.        :par
+0000eb20: 616d 2073 746f 706c 6f73 735f 6f72 6465  am stoploss_orde
+0000eb30: 723a 2049 6620 7472 7565 2c20 7573 6573  r: If true, uses
+0000eb40: 2066 6574 6368 5f73 746f 706c 6f73 735f   fetch_stoploss_
+0000eb50: 6f72 6465 722c 206f 7468 6572 7769 7365  order, otherwise
+0000eb60: 2066 6574 6368 5f6f 7264 6572 2e0a 2020   fetch_order..  
+0000eb70: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0000eb80: 2020 6966 2073 746f 706c 6f73 735f 6f72    if stoploss_or
+0000eb90: 6465 723a 0a20 2020 2020 2020 2020 2020  der:.           
+0000eba0: 2072 6574 7572 6e20 7365 6c66 2e66 6574   return self.fet
+0000ebb0: 6368 5f73 746f 706c 6f73 735f 6f72 6465  ch_stoploss_orde
+0000ebc0: 7228 6f72 6465 725f 6964 2c20 7061 6972  r(order_id, pair
+0000ebd0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0000ebe0: 2073 656c 662e 6665 7463 685f 6f72 6465   self.fetch_orde
+0000ebf0: 7228 6f72 6465 725f 6964 2c20 7061 6972  r(order_id, pair
+0000ec00: 290a 0a20 2020 2064 6566 2063 6865 636b  )..    def check
+0000ec10: 5f6f 7264 6572 5f63 616e 6365 6c65 645f  _order_canceled_
+0000ec20: 656d 7074 7928 7365 6c66 2c20 6f72 6465  empty(self, orde
+0000ec30: 723a 2044 6963 7429 202d 3e20 626f 6f6c  r: Dict) -> bool
+0000ec40: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
+0000ec50: 2020 2020 2020 5665 7269 6679 2069 6620        Verify if 
+0000ec60: 616e 206f 7264 6572 2068 6173 2062 6565  an order has bee
+0000ec70: 6e20 6361 6e63 656c 6c65 6420 7769 7468  n cancelled with
+0000ec80: 6f75 7420 6265 696e 6720 7061 7274 6961  out being partia
+0000ec90: 6c6c 7920 6669 6c6c 6564 0a20 2020 2020  lly filled.     
+0000eca0: 2020 203a 7061 7261 6d20 6f72 6465 723a     :param order:
+0000ecb0: 204f 7264 6572 2064 6963 7420 6173 2072   Order dict as r
+0000ecc0: 6574 7572 6e65 6420 6672 6f6d 2066 6574  eturned from fet
+0000ecd0: 6368 5f6f 7264 6572 2829 0a20 2020 2020  ch_order().     
+0000ece0: 2020 203a 7265 7475 726e 3a20 5472 7565     :return: True
+0000ecf0: 2069 6620 6f72 6465 7220 6861 7320 6265   if order has be
+0000ed00: 656e 2063 616e 6365 6c6c 6564 2077 6974  en cancelled wit
+0000ed10: 686f 7574 2062 6569 6e67 2066 696c 6c65  hout being fille
+0000ed20: 642c 2046 616c 7365 206f 7468 6572 7769  d, False otherwi
+0000ed30: 7365 2e0a 2020 2020 2020 2020 2222 220a  se..        """.
+0000ed40: 2020 2020 2020 2020 7265 7475 726e 206f          return o
+0000ed50: 7264 6572 2e67 6574 2822 7374 6174 7573  rder.get("status
+0000ed60: 2229 2069 6e20 4e4f 4e5f 4f50 454e 5f45  ") in NON_OPEN_E
+0000ed70: 5843 4841 4e47 455f 5354 4154 4553 2061  XCHANGE_STATES a
+0000ed80: 6e64 206f 7264 6572 2e67 6574 2822 6669  nd order.get("fi
+0000ed90: 6c6c 6564 2229 203d 3d20 302e 300a 0a20  lled") == 0.0.. 
+0000eda0: 2020 2040 7265 7472 6965 720a 2020 2020     @retrier.    
+0000edb0: 6465 6620 6361 6e63 656c 5f6f 7264 6572  def cancel_order
+0000edc0: 2873 656c 662c 206f 7264 6572 5f69 643a  (self, order_id:
+0000edd0: 2073 7472 2c20 7061 6972 3a20 7374 722c   str, pair: str,
+0000ede0: 2070 6172 616d 733a 204f 7074 696f 6e61   params: Optiona
+0000edf0: 6c5b 4469 6374 5d20 3d20 4e6f 6e65 2920  l[Dict] = None) 
+0000ee00: 2d3e 2044 6963 743a 0a20 2020 2020 2020  -> Dict:.       
+0000ee10: 2069 6620 7365 6c66 2e5f 636f 6e66 6967   if self._config
+0000ee20: 5b22 6472 795f 7275 6e22 5d3a 0a20 2020  ["dry_run"]:.   
+0000ee30: 2020 2020 2020 2020 2074 7279 3a0a 2020           try:.  
+0000ee40: 2020 2020 2020 2020 2020 2020 2020 6f72                or
+0000ee50: 6465 7220 3d20 7365 6c66 2e66 6574 6368  der = self.fetch
+0000ee60: 5f64 7279 5f72 756e 5f6f 7264 6572 286f  _dry_run_order(o
+0000ee70: 7264 6572 5f69 6429 0a0a 2020 2020 2020  rder_id)..      
+0000ee80: 2020 2020 2020 2020 2020 6f72 6465 722e            order.
+0000ee90: 7570 6461 7465 287b 2273 7461 7475 7322  update({"status"
+0000eea0: 3a20 2263 616e 6365 6c65 6422 2c20 2266  : "canceled", "f
+0000eeb0: 696c 6c65 6422 3a20 302e 302c 2022 7265  illed": 0.0, "re
+0000eec0: 6d61 696e 696e 6722 3a20 6f72 6465 725b  maining": order[
+0000eed0: 2261 6d6f 756e 7422 5d7d 290a 2020 2020  "amount"]}).    
+0000eee0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000eef0: 726e 206f 7264 6572 0a20 2020 2020 2020  rn order.       
+0000ef00: 2020 2020 2065 7863 6570 7420 496e 7661       except Inva
+0000ef10: 6c69 644f 7264 6572 4578 6365 7074 696f  lidOrderExceptio
+0000ef20: 6e3a 0a20 2020 2020 2020 2020 2020 2020  n:.             
+0000ef30: 2020 2072 6574 7572 6e20 7b7d 0a0a 2020     return {}..  
+0000ef40: 2020 2020 2020 6966 2070 6172 616d 7320        if params 
+0000ef50: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+0000ef60: 2020 2020 2070 6172 616d 7320 3d20 7b7d       params = {}
+0000ef70: 0a20 2020 2020 2020 2074 7279 3a0a 2020  .        try:.  
+0000ef80: 2020 2020 2020 2020 2020 6f72 6465 7220            order 
+0000ef90: 3d20 7365 6c66 2e5f 6170 692e 6361 6e63  = self._api.canc
+0000efa0: 656c 5f6f 7264 6572 286f 7264 6572 5f69  el_order(order_i
+0000efb0: 642c 2070 6169 722c 2070 6172 616d 733d  d, pair, params=
+0000efc0: 7061 7261 6d73 290a 2020 2020 2020 2020  params).        
+0000efd0: 2020 2020 7365 6c66 2e5f 6c6f 675f 6578      self._log_ex
+0000efe0: 6368 616e 6765 5f72 6573 706f 6e73 6528  change_response(
+0000eff0: 2263 616e 6365 6c5f 6f72 6465 7222 2c20  "cancel_order", 
+0000f000: 6f72 6465 7229 0a20 2020 2020 2020 2020  order).         
+0000f010: 2020 206f 7264 6572 203d 2073 656c 662e     order = self.
+0000f020: 5f6f 7264 6572 5f63 6f6e 7472 6163 7473  _order_contracts
+0000f030: 5f74 6f5f 616d 6f75 6e74 286f 7264 6572  _to_amount(order
+0000f040: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+0000f050: 7475 726e 206f 7264 6572 0a20 2020 2020  turn order.     
+0000f060: 2020 2065 7863 6570 7420 6363 7874 2e49     except ccxt.I
+0000f070: 6e76 616c 6964 4f72 6465 7220 6173 2065  nvalidOrder as e
+0000f080: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+0000f090: 6973 6520 496e 7661 6c69 644f 7264 6572  ise InvalidOrder
+0000f0a0: 4578 6365 7074 696f 6e28 6622 436f 756c  Exception(f"Coul
+0000f0b0: 6420 6e6f 7420 6361 6e63 656c 206f 7264  d not cancel ord
+0000f0c0: 6572 2e20 4d65 7373 6167 653a 207b 657d  er. Message: {e}
+0000f0d0: 2229 2066 726f 6d20 650a 2020 2020 2020  ") from e.      
+0000f0e0: 2020 6578 6365 7074 2063 6378 742e 4444    except ccxt.DD
+0000f0f0: 6f53 5072 6f74 6563 7469 6f6e 2061 7320  oSProtection as 
+0000f100: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+0000f110: 6169 7365 2044 446f 7350 726f 7465 6374  aise DDosProtect
+0000f120: 696f 6e28 6529 2066 726f 6d20 650a 2020  ion(e) from e.  
+0000f130: 2020 2020 2020 6578 6365 7074 2028 6363        except (cc
+0000f140: 7874 2e4f 7065 7261 7469 6f6e 4661 696c  xt.OperationFail
+0000f150: 6564 2c20 6363 7874 2e45 7863 6861 6e67  ed, ccxt.Exchang
+0000f160: 6545 7272 6f72 2920 6173 2065 3a0a 2020  eError) as e:.  
+0000f170: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000f180: 5465 6d70 6f72 6172 7945 7272 6f72 280a  TemporaryError(.
+0000f190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f1a0: 6622 436f 756c 6420 6e6f 7420 6361 6e63  f"Could not canc
+0000f1b0: 656c 206f 7264 6572 2064 7565 2074 6f20  el order due to 
+0000f1c0: 7b65 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e  {e.__class__.__n
+0000f1d0: 616d 655f 5f7d 2e20 4d65 7373 6167 653a  ame__}. Message:
+0000f1e0: 207b 657d 220a 2020 2020 2020 2020 2020   {e}".          
+0000f1f0: 2020 2920 6672 6f6d 2065 0a20 2020 2020    ) from e.     
+0000f200: 2020 2065 7863 6570 7420 6363 7874 2e42     except ccxt.B
+0000f210: 6173 6545 7272 6f72 2061 7320 653a 0a20  aseError as e:. 
+0000f220: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000f230: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
+0000f240: 7074 696f 6e28 6529 2066 726f 6d20 650a  ption(e) from e.
+0000f250: 0a20 2020 2064 6566 2063 616e 6365 6c5f  .    def cancel_
+0000f260: 7374 6f70 6c6f 7373 5f6f 7264 6572 280a  stoploss_order(.
+0000f270: 2020 2020 2020 2020 7365 6c66 2c20 6f72          self, or
+0000f280: 6465 725f 6964 3a20 7374 722c 2070 6169  der_id: str, pai
+0000f290: 723a 2073 7472 2c20 7061 7261 6d73 3a20  r: str, params: 
+0000f2a0: 4f70 7469 6f6e 616c 5b44 6963 745d 203d  Optional[Dict] =
+0000f2b0: 204e 6f6e 650a 2020 2020 2920 2d3e 2044   None.    ) -> D
+0000f2c0: 6963 743a 0a20 2020 2020 2020 2072 6574  ict:.        ret
+0000f2d0: 7572 6e20 7365 6c66 2e63 616e 6365 6c5f  urn self.cancel_
+0000f2e0: 6f72 6465 7228 6f72 6465 725f 6964 2c20  order(order_id, 
+0000f2f0: 7061 6972 2c20 7061 7261 6d73 290a 0a20  pair, params).. 
+0000f300: 2020 2064 6566 2069 735f 6361 6e63 656c     def is_cancel
+0000f310: 5f6f 7264 6572 5f72 6573 756c 745f 7375  _order_result_su
+0000f320: 6974 6162 6c65 2873 656c 662c 2063 6f72  itable(self, cor
+0000f330: 6465 7229 202d 3e20 626f 6f6c 3a0a 2020  der) -> bool:.  
+0000f340: 2020 2020 2020 6966 206e 6f74 2069 7369        if not isi
+0000f350: 6e73 7461 6e63 6528 636f 7264 6572 2c20  nstance(corder, 
+0000f360: 6469 6374 293a 0a20 2020 2020 2020 2020  dict):.         
+0000f370: 2020 2072 6574 7572 6e20 4661 6c73 650a     return False.
+0000f380: 0a20 2020 2020 2020 2072 6571 7569 7265  .        require
+0000f390: 6420 3d20 2822 6665 6522 2c20 2273 7461  d = ("fee", "sta
+0000f3a0: 7475 7322 2c20 2261 6d6f 756e 7422 290a  tus", "amount").
+0000f3b0: 2020 2020 2020 2020 7265 7475 726e 2061          return a
+0000f3c0: 6c6c 2863 6f72 6465 722e 6765 7428 6b2c  ll(corder.get(k,
+0000f3d0: 204e 6f6e 6529 2069 7320 6e6f 7420 4e6f   None) is not No
+0000f3e0: 6e65 2066 6f72 206b 2069 6e20 7265 7175  ne for k in requ
+0000f3f0: 6972 6564 290a 0a20 2020 2064 6566 2063  ired)..    def c
+0000f400: 616e 6365 6c5f 6f72 6465 725f 7769 7468  ancel_order_with
+0000f410: 5f72 6573 756c 7428 7365 6c66 2c20 6f72  _result(self, or
+0000f420: 6465 725f 6964 3a20 7374 722c 2070 6169  der_id: str, pai
+0000f430: 723a 2073 7472 2c20 616d 6f75 6e74 3a20  r: str, amount: 
+0000f440: 666c 6f61 7429 202d 3e20 4469 6374 3a0a  float) -> Dict:.
+0000f450: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+0000f460: 2020 2020 4361 6e63 656c 206f 7264 6572      Cancel order
+0000f470: 2072 6574 7572 6e69 6e67 2061 2072 6573   returning a res
+0000f480: 756c 742e 0a20 2020 2020 2020 2043 7265  ult..        Cre
+0000f490: 6174 6573 2061 2066 616b 6520 7265 7375  ates a fake resu
+0000f4a0: 6c74 2069 6620 6361 6e63 656c 206f 7264  lt if cancel ord
+0000f4b0: 6572 2072 6574 7572 6e73 2061 206e 6f6e  er returns a non
+0000f4c0: 2d75 7361 626c 6520 7265 7375 6c74 0a20  -usable result. 
+0000f4d0: 2020 2020 2020 2061 6e64 2066 6574 6368         and fetch
+0000f4e0: 5f6f 7264 6572 2064 6f65 7320 6e6f 7420  _order does not 
+0000f4f0: 776f 726b 2028 6365 7274 6169 6e20 6578  work (certain ex
+0000f500: 6368 616e 6765 7320 646f 6e27 7420 7265  changes don't re
+0000f510: 7475 726e 2063 616e 6365 6c6c 6564 206f  turn cancelled o
+0000f520: 7264 6572 7329 0a20 2020 2020 2020 203a  rders).        :
+0000f530: 7061 7261 6d20 6f72 6465 725f 6964 3a20  param order_id: 
+0000f540: 4f72 6465 7269 6420 746f 2063 616e 6365  Orderid to cance
+0000f550: 6c0a 2020 2020 2020 2020 3a70 6172 616d  l.        :param
+0000f560: 2070 6169 723a 2050 6169 7220 636f 7272   pair: Pair corr
+0000f570: 6573 706f 6e64 696e 6720 746f 206f 7264  esponding to ord
+0000f580: 6572 5f69 640a 2020 2020 2020 2020 3a70  er_id.        :p
+0000f590: 6172 616d 2061 6d6f 756e 743a 2041 6d6f  aram amount: Amo
+0000f5a0: 756e 7420 746f 2075 7365 2066 6f72 2066  unt to use for f
+0000f5b0: 616b 6520 7265 7370 6f6e 7365 0a20 2020  ake response.   
+0000f5c0: 2020 2020 203a 7265 7475 726e 3a20 5265       :return: Re
+0000f5d0: 7375 6c74 2066 726f 6d20 6569 7468 6572  sult from either
+0000f5e0: 2063 616e 6365 6c5f 6f72 6465 7220 6966   cancel_order if
+0000f5f0: 2075 7361 626c 652c 206f 7220 6665 7463   usable, or fetc
+0000f600: 685f 6f72 6465 720a 2020 2020 2020 2020  h_order.        
+0000f610: 2222 220a 2020 2020 2020 2020 7472 793a  """.        try:
+0000f620: 0a20 2020 2020 2020 2020 2020 2063 6f72  .            cor
+0000f630: 6465 7220 3d20 7365 6c66 2e63 616e 6365  der = self.cance
+0000f640: 6c5f 6f72 6465 7228 6f72 6465 725f 6964  l_order(order_id
+0000f650: 2c20 7061 6972 290a 2020 2020 2020 2020  , pair).        
+0000f660: 2020 2020 6966 2073 656c 662e 6973 5f63      if self.is_c
+0000f670: 616e 6365 6c5f 6f72 6465 725f 7265 7375  ancel_order_resu
+0000f680: 6c74 5f73 7569 7461 626c 6528 636f 7264  lt_suitable(cord
+0000f690: 6572 293a 0a20 2020 2020 2020 2020 2020  er):.           
+0000f6a0: 2020 2020 2072 6574 7572 6e20 636f 7264       return cord
+0000f6b0: 6572 0a20 2020 2020 2020 2065 7863 6570  er.        excep
+0000f6c0: 7420 496e 7661 6c69 644f 7264 6572 4578  t InvalidOrderEx
+0000f6d0: 6365 7074 696f 6e3a 0a20 2020 2020 2020  ception:.       
+0000f6e0: 2020 2020 206c 6f67 6765 722e 7761 726e       logger.warn
+0000f6f0: 696e 6728 6622 436f 756c 6420 6e6f 7420  ing(f"Could not 
+0000f700: 6361 6e63 656c 206f 7264 6572 207b 6f72  cancel order {or
+0000f710: 6465 725f 6964 7d20 666f 7220 7b70 6169  der_id} for {pai
+0000f720: 727d 2e22 290a 2020 2020 2020 2020 7472  r}.").        tr
+0000f730: 793a 0a20 2020 2020 2020 2020 2020 206f  y:.            o
+0000f740: 7264 6572 203d 2073 656c 662e 6665 7463  rder = self.fetc
+0000f750: 685f 6f72 6465 7228 6f72 6465 725f 6964  h_order(order_id
+0000f760: 2c20 7061 6972 290a 2020 2020 2020 2020  , pair).        
+0000f770: 6578 6365 7074 2049 6e76 616c 6964 4f72  except InvalidOr
+0000f780: 6465 7245 7863 6570 7469 6f6e 3a0a 2020  derException:.  
+0000f790: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+0000f7a0: 2e77 6172 6e69 6e67 2866 2243 6f75 6c64  .warning(f"Could
+0000f7b0: 206e 6f74 2066 6574 6368 2063 616e 6365   not fetch cance
+0000f7c0: 6c6c 6564 206f 7264 6572 207b 6f72 6465  lled order {orde
+0000f7d0: 725f 6964 7d2e 2229 0a20 2020 2020 2020  r_id}.").       
+0000f7e0: 2020 2020 206f 7264 6572 203d 207b 0a20       order = {. 
+0000f7f0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000f800: 6964 223a 206f 7264 6572 5f69 642c 0a20  id": order_id,. 
+0000f810: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000f820: 7374 6174 7573 223a 2022 6361 6e63 656c  status": "cancel
+0000f830: 6564 222c 0a20 2020 2020 2020 2020 2020  ed",.           
+0000f840: 2020 2020 2022 616d 6f75 6e74 223a 2061       "amount": a
+0000f850: 6d6f 756e 742c 0a20 2020 2020 2020 2020  mount,.         
+0000f860: 2020 2020 2020 2022 6669 6c6c 6564 223a         "filled":
+0000f870: 2030 2e30 2c0a 2020 2020 2020 2020 2020   0.0,.          
+0000f880: 2020 2020 2020 2266 6565 223a 207b 7d2c        "fee": {},
+0000f890: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f8a0: 2022 696e 666f 223a 207b 7d2c 0a20 2020   "info": {},.   
+0000f8b0: 2020 2020 2020 2020 207d 0a0a 2020 2020           }..    
+0000f8c0: 2020 2020 7265 7475 726e 206f 7264 6572      return order
+0000f8d0: 0a0a 2020 2020 6465 6620 6361 6e63 656c  ..    def cancel
+0000f8e0: 5f73 746f 706c 6f73 735f 6f72 6465 725f  _stoploss_order_
+0000f8f0: 7769 7468 5f72 6573 756c 7428 7365 6c66  with_result(self
+0000f900: 2c20 6f72 6465 725f 6964 3a20 7374 722c  , order_id: str,
+0000f910: 2070 6169 723a 2073 7472 2c20 616d 6f75   pair: str, amou
+0000f920: 6e74 3a20 666c 6f61 7429 202d 3e20 4469  nt: float) -> Di
+0000f930: 6374 3a0a 2020 2020 2020 2020 2222 220a  ct:.        """.
+0000f940: 2020 2020 2020 2020 4361 6e63 656c 2073          Cancel s
+0000f950: 746f 706c 6f73 7320 6f72 6465 7220 7265  toploss order re
+0000f960: 7475 726e 696e 6720 6120 7265 7375 6c74  turning a result
+0000f970: 2e0a 2020 2020 2020 2020 4372 6561 7465  ..        Create
+0000f980: 7320 6120 6661 6b65 2072 6573 756c 7420  s a fake result 
+0000f990: 6966 2063 616e 6365 6c20 6f72 6465 7220  if cancel order 
+0000f9a0: 7265 7475 726e 7320 6120 6e6f 6e2d 7573  returns a non-us
+0000f9b0: 6162 6c65 2072 6573 756c 740a 2020 2020  able result.    
+0000f9c0: 2020 2020 616e 6420 6665 7463 685f 6f72      and fetch_or
+0000f9d0: 6465 7220 646f 6573 206e 6f74 2077 6f72  der does not wor
+0000f9e0: 6b20 2863 6572 7461 696e 2065 7863 6861  k (certain excha
+0000f9f0: 6e67 6573 2064 6f6e 2774 2072 6574 7572  nges don't retur
+0000fa00: 6e20 6361 6e63 656c 6c65 6420 6f72 6465  n cancelled orde
+0000fa10: 7273 290a 2020 2020 2020 2020 3a70 6172  rs).        :par
+0000fa20: 616d 206f 7264 6572 5f69 643a 2073 746f  am order_id: sto
+0000fa30: 706c 6f73 732d 6f72 6465 722d 6964 2074  ploss-order-id t
+0000fa40: 6f20 6361 6e63 656c 0a20 2020 2020 2020  o cancel.       
+0000fa50: 203a 7061 7261 6d20 7061 6972 3a20 5061   :param pair: Pa
+0000fa60: 6972 2063 6f72 7265 7370 6f6e 6469 6e67  ir corresponding
+0000fa70: 2074 6f20 6f72 6465 725f 6964 0a20 2020   to order_id.   
+0000fa80: 2020 2020 203a 7061 7261 6d20 616d 6f75       :param amou
+0000fa90: 6e74 3a20 416d 6f75 6e74 2074 6f20 7573  nt: Amount to us
+0000faa0: 6520 666f 7220 6661 6b65 2072 6573 706f  e for fake respo
+0000fab0: 6e73 650a 2020 2020 2020 2020 3a72 6574  nse.        :ret
+0000fac0: 7572 6e3a 2052 6573 756c 7420 6672 6f6d  urn: Result from
+0000fad0: 2065 6974 6865 7220 6361 6e63 656c 5f6f   either cancel_o
+0000fae0: 7264 6572 2069 6620 7573 6162 6c65 2c20  rder if usable, 
+0000faf0: 6f72 2066 6574 6368 5f6f 7264 6572 0a20  or fetch_order. 
+0000fb00: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+0000fb10: 2020 2063 6f72 6465 7220 3d20 7365 6c66     corder = self
+0000fb20: 2e63 616e 6365 6c5f 7374 6f70 6c6f 7373  .cancel_stoploss
+0000fb30: 5f6f 7264 6572 286f 7264 6572 5f69 642c  _order(order_id,
+0000fb40: 2070 6169 7229 0a20 2020 2020 2020 2069   pair).        i
+0000fb50: 6620 7365 6c66 2e69 735f 6361 6e63 656c  f self.is_cancel
+0000fb60: 5f6f 7264 6572 5f72 6573 756c 745f 7375  _order_result_su
+0000fb70: 6974 6162 6c65 2863 6f72 6465 7229 3a0a  itable(corder):.
+0000fb80: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000fb90: 726e 2063 6f72 6465 720a 2020 2020 2020  rn corder.      
+0000fba0: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
+0000fbb0: 2020 206f 7264 6572 203d 2073 656c 662e     order = self.
+0000fbc0: 6665 7463 685f 7374 6f70 6c6f 7373 5f6f  fetch_stoploss_o
+0000fbd0: 7264 6572 286f 7264 6572 5f69 642c 2070  rder(order_id, p
+0000fbe0: 6169 7229 0a20 2020 2020 2020 2065 7863  air).        exc
+0000fbf0: 6570 7420 496e 7661 6c69 644f 7264 6572  ept InvalidOrder
+0000fc00: 4578 6365 7074 696f 6e3a 0a20 2020 2020  Exception:.     
+0000fc10: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
+0000fc20: 726e 696e 6728 6622 436f 756c 6420 6e6f  rning(f"Could no
+0000fc30: 7420 6665 7463 6820 6361 6e63 656c 6c65  t fetch cancelle
+0000fc40: 6420 7374 6f70 6c6f 7373 206f 7264 6572  d stoploss order
+0000fc50: 207b 6f72 6465 725f 6964 7d2e 2229 0a20   {order_id}."). 
+0000fc60: 2020 2020 2020 2020 2020 206f 7264 6572             order
+0000fc70: 203d 207b 2269 6422 3a20 6f72 6465 725f   = {"id": order_
+0000fc80: 6964 2c20 2266 6565 223a 207b 7d2c 2022  id, "fee": {}, "
+0000fc90: 7374 6174 7573 223a 2022 6361 6e63 656c  status": "cancel
+0000fca0: 6564 222c 2022 616d 6f75 6e74 223a 2061  ed", "amount": a
+0000fcb0: 6d6f 756e 742c 2022 696e 666f 223a 207b  mount, "info": {
+0000fcc0: 7d7d 0a0a 2020 2020 2020 2020 7265 7475  }}..        retu
+0000fcd0: 726e 206f 7264 6572 0a0a 2020 2020 4072  rn order..    @r
+0000fce0: 6574 7269 6572 0a20 2020 2064 6566 2067  etrier.    def g
+0000fcf0: 6574 5f62 616c 616e 6365 7328 7365 6c66  et_balances(self
+0000fd00: 2920 2d3e 2064 6963 743a 0a20 2020 2020  ) -> dict:.     
+0000fd10: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+0000fd20: 2020 2020 6261 6c61 6e63 6573 203d 2073      balances = s
+0000fd30: 656c 662e 5f61 7069 2e66 6574 6368 5f62  elf._api.fetch_b
+0000fd40: 616c 616e 6365 2829 0a20 2020 2020 2020  alance().       
+0000fd50: 2020 2020 2023 2052 656d 6f76 6520 6164       # Remove ad
+0000fd60: 6469 7469 6f6e 616c 2069 6e66 6f20 6672  ditional info fr
+0000fd70: 6f6d 2063 6378 7420 7265 7375 6c74 730a  om ccxt results.
+0000fd80: 2020 2020 2020 2020 2020 2020 6261 6c61              bala
+0000fd90: 6e63 6573 2e70 6f70 2822 696e 666f 222c  nces.pop("info",
+0000fda0: 204e 6f6e 6529 0a20 2020 2020 2020 2020   None).         
+0000fdb0: 2020 2062 616c 616e 6365 732e 706f 7028     balances.pop(
+0000fdc0: 2266 7265 6522 2c20 4e6f 6e65 290a 2020  "free", None).  
+0000fdd0: 2020 2020 2020 2020 2020 6261 6c61 6e63            balanc
+0000fde0: 6573 2e70 6f70 2822 746f 7461 6c22 2c20  es.pop("total", 
+0000fdf0: 4e6f 6e65 290a 2020 2020 2020 2020 2020  None).          
+0000fe00: 2020 6261 6c61 6e63 6573 2e70 6f70 2822    balances.pop("
+0000fe10: 7573 6564 222c 204e 6f6e 6529 0a0a 2020  used", None)..  
+0000fe20: 2020 2020 2020 2020 2020 7265 7475 726e            return
+0000fe30: 2062 616c 616e 6365 730a 2020 2020 2020   balances.      
+0000fe40: 2020 6578 6365 7074 2063 6378 742e 4444    except ccxt.DD
+0000fe50: 6f53 5072 6f74 6563 7469 6f6e 2061 7320  oSProtection as 
+0000fe60: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+0000fe70: 6169 7365 2044 446f 7350 726f 7465 6374  aise DDosProtect
+0000fe80: 696f 6e28 6529 2066 726f 6d20 650a 2020  ion(e) from e.  
+0000fe90: 2020 2020 2020 6578 6365 7074 2028 6363        except (cc
+0000fea0: 7874 2e4f 7065 7261 7469 6f6e 4661 696c  xt.OperationFail
+0000feb0: 6564 2c20 6363 7874 2e45 7863 6861 6e67  ed, ccxt.Exchang
+0000fec0: 6545 7272 6f72 2920 6173 2065 3a0a 2020  eError) as e:.  
+0000fed0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000fee0: 5465 6d70 6f72 6172 7945 7272 6f72 280a  TemporaryError(.
+0000fef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ff00: 6622 436f 756c 6420 6e6f 7420 6765 7420  f"Could not get 
+0000ff10: 6261 6c61 6e63 6520 6475 6520 746f 207b  balance due to {
+0000ff20: 652e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  e.__class__.__na
+0000ff30: 6d65 5f5f 7d2e 204d 6573 7361 6765 3a20  me__}. Message: 
+0000ff40: 7b65 7d22 0a20 2020 2020 2020 2020 2020  {e}".           
+0000ff50: 2029 2066 726f 6d20 650a 2020 2020 2020   ) from e.      
+0000ff60: 2020 6578 6365 7074 2063 6378 742e 4261    except ccxt.Ba
+0000ff70: 7365 4572 726f 7220 6173 2065 3a0a 2020  seError as e:.  
+0000ff80: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000ff90: 4f70 6572 6174 696f 6e61 6c45 7863 6570  OperationalExcep
+0000ffa0: 7469 6f6e 2865 2920 6672 6f6d 2065 0a0a  tion(e) from e..
+0000ffb0: 2020 2020 4072 6574 7269 6572 0a20 2020      @retrier.   
+0000ffc0: 2064 6566 2066 6574 6368 5f70 6f73 6974   def fetch_posit
+0000ffd0: 696f 6e73 2873 656c 662c 2070 6169 723a  ions(self, pair:
+0000ffe0: 204f 7074 696f 6e61 6c5b 7374 725d 203d   Optional[str] =
+0000fff0: 204e 6f6e 6529 202d 3e20 4c69 7374 5b44   None) -> List[D
+00010000: 6963 745d 3a0a 2020 2020 2020 2020 2222  ict]:.        ""
+00010010: 220a 2020 2020 2020 2020 4665 7463 6820  ".        Fetch 
+00010020: 706f 7369 7469 6f6e 7320 6672 6f6d 2074  positions from t
+00010030: 6865 2065 7863 6861 6e67 652e 0a20 2020  he exchange..   
+00010040: 2020 2020 2049 6620 6e6f 2070 6169 7220       If no pair 
+00010050: 6973 2067 6976 656e 2c20 616c 6c20 706f  is given, all po
+00010060: 7369 7469 6f6e 7320 6172 6520 7265 7475  sitions are retu
+00010070: 726e 6564 2e0a 2020 2020 2020 2020 3a70  rned..        :p
+00010080: 6172 616d 2070 6169 723a 2050 6169 7220  aram pair: Pair 
+00010090: 666f 7220 7468 6520 7175 6572 790a 2020  for the query.  
+000100a0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+000100b0: 2020 6966 2073 656c 662e 5f63 6f6e 6669    if self._confi
+000100c0: 675b 2264 7279 5f72 756e 225d 206f 7220  g["dry_run"] or 
+000100d0: 7365 6c66 2e74 7261 6469 6e67 5f6d 6f64  self.trading_mod
+000100e0: 6520 213d 2054 7261 6469 6e67 4d6f 6465  e != TradingMode
+000100f0: 2e46 5554 5552 4553 3a0a 2020 2020 2020  .FUTURES:.      
+00010100: 2020 2020 2020 7265 7475 726e 205b 5d0a        return [].
+00010110: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+00010120: 2020 2020 2020 2020 2073 796d 626f 6c73           symbols
+00010130: 203d 205b 5d0a 2020 2020 2020 2020 2020   = [].          
+00010140: 2020 6966 2070 6169 723a 0a20 2020 2020    if pair:.     
+00010150: 2020 2020 2020 2020 2020 2073 796d 626f             symbo
+00010160: 6c73 2e61 7070 656e 6428 7061 6972 290a  ls.append(pair).
+00010170: 2020 2020 2020 2020 2020 2020 706f 7369              posi
+00010180: 7469 6f6e 733a 204c 6973 745b 4469 6374  tions: List[Dict
+00010190: 5d20 3d20 7365 6c66 2e5f 6170 692e 6665  ] = self._api.fe
+000101a0: 7463 685f 706f 7369 7469 6f6e 7328 7379  tch_positions(sy
+000101b0: 6d62 6f6c 7329 0a20 2020 2020 2020 2020  mbols).         
+000101c0: 2020 2073 656c 662e 5f6c 6f67 5f65 7863     self._log_exc
+000101d0: 6861 6e67 655f 7265 7370 6f6e 7365 2822  hange_response("
+000101e0: 6665 7463 685f 706f 7369 7469 6f6e 7322  fetch_positions"
+000101f0: 2c20 706f 7369 7469 6f6e 7329 0a20 2020  , positions).   
+00010200: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00010210: 706f 7369 7469 6f6e 730a 2020 2020 2020  positions.      
+00010220: 2020 6578 6365 7074 2063 6378 742e 4444    except ccxt.DD
+00010230: 6f53 5072 6f74 6563 7469 6f6e 2061 7320  oSProtection as 
+00010240: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+00010250: 6169 7365 2044 446f 7350 726f 7465 6374  aise DDosProtect
+00010260: 696f 6e28 6529 2066 726f 6d20 650a 2020  ion(e) from e.  
+00010270: 2020 2020 2020 6578 6365 7074 2028 6363        except (cc
+00010280: 7874 2e4f 7065 7261 7469 6f6e 4661 696c  xt.OperationFail
+00010290: 6564 2c20 6363 7874 2e45 7863 6861 6e67  ed, ccxt.Exchang
+000102a0: 6545 7272 6f72 2920 6173 2065 3a0a 2020  eError) as e:.  
+000102b0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+000102c0: 5465 6d70 6f72 6172 7945 7272 6f72 280a  TemporaryError(.
+000102d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000102e0: 6622 436f 756c 6420 6e6f 7420 6765 7420  f"Could not get 
+000102f0: 706f 7369 7469 6f6e 7320 6475 6520 746f  positions due to
+00010300: 207b 652e 5f5f 636c 6173 735f 5f2e 5f5f   {e.__class__.__
+00010310: 6e61 6d65 5f5f 7d2e 204d 6573 7361 6765  name__}. Message
+00010320: 3a20 7b65 7d22 0a20 2020 2020 2020 2020  : {e}".         
+00010330: 2020 2029 2066 726f 6d20 650a 2020 2020     ) from e.    
+00010340: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
+00010350: 4261 7365 4572 726f 7220 6173 2065 3a0a  BaseError as e:.
+00010360: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00010370: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
+00010380: 6570 7469 6f6e 2865 2920 6672 6f6d 2065  eption(e) from e
+00010390: 0a0a 2020 2020 6465 6620 5f66 6574 6368  ..    def _fetch
+000103a0: 5f6f 7264 6572 735f 656d 756c 6174 6528  _orders_emulate(
+000103b0: 7365 6c66 2c20 7061 6972 3a20 7374 722c  self, pair: str,
+000103c0: 2073 696e 6365 5f6d 733a 2069 6e74 2920   since_ms: int) 
+000103d0: 2d3e 204c 6973 745b 4469 6374 5d3a 0a20  -> List[Dict]:. 
+000103e0: 2020 2020 2020 206f 7264 6572 7320 3d20         orders = 
+000103f0: 5b5d 0a20 2020 2020 2020 2069 6620 7365  [].        if se
+00010400: 6c66 2e65 7863 6861 6e67 655f 6861 7328  lf.exchange_has(
+00010410: 2266 6574 6368 436c 6f73 6564 4f72 6465  "fetchClosedOrde
+00010420: 7273 2229 3a0a 2020 2020 2020 2020 2020  rs"):.          
+00010430: 2020 6f72 6465 7273 203d 2073 656c 662e    orders = self.
+00010440: 5f61 7069 2e66 6574 6368 5f63 6c6f 7365  _api.fetch_close
+00010450: 645f 6f72 6465 7273 2870 6169 722c 2073  d_orders(pair, s
+00010460: 696e 6365 3d73 696e 6365 5f6d 7329 0a20  ince=since_ms). 
+00010470: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00010480: 6c66 2e65 7863 6861 6e67 655f 6861 7328  lf.exchange_has(
+00010490: 2266 6574 6368 4f70 656e 4f72 6465 7273  "fetchOpenOrders
+000104a0: 2229 3a0a 2020 2020 2020 2020 2020 2020  "):.            
+000104b0: 2020 2020 6f72 6465 7273 5f6f 7065 6e20      orders_open 
+000104c0: 3d20 7365 6c66 2e5f 6170 692e 6665 7463  = self._api.fetc
+000104d0: 685f 6f70 656e 5f6f 7264 6572 7328 7061  h_open_orders(pa
+000104e0: 6972 2c20 7369 6e63 653d 7369 6e63 655f  ir, since=since_
+000104f0: 6d73 290a 2020 2020 2020 2020 2020 2020  ms).            
+00010500: 2020 2020 6f72 6465 7273 2e65 7874 656e      orders.exten
+00010510: 6428 6f72 6465 7273 5f6f 7065 6e29 0a20  d(orders_open). 
+00010520: 2020 2020 2020 2072 6574 7572 6e20 6f72         return or
+00010530: 6465 7273 0a0a 2020 2020 4072 6574 7269  ders..    @retri
+00010540: 6572 2872 6574 7269 6573 3d30 290a 2020  er(retries=0).  
+00010550: 2020 6465 6620 6665 7463 685f 6f72 6465    def fetch_orde
+00010560: 7273 2873 656c 662c 2070 6169 723a 2073  rs(self, pair: s
+00010570: 7472 2c20 7369 6e63 653a 2064 6174 6574  tr, since: datet
+00010580: 696d 652c 2070 6172 616d 733a 204f 7074  ime, params: Opt
+00010590: 696f 6e61 6c5b 4469 6374 5d20 3d20 4e6f  ional[Dict] = No
+000105a0: 6e65 2920 2d3e 204c 6973 745b 4469 6374  ne) -> List[Dict
+000105b0: 5d3a 0a20 2020 2020 2020 2022 2222 0a20  ]:.        """. 
+000105c0: 2020 2020 2020 2046 6574 6368 2061 6c6c         Fetch all
+000105d0: 206f 7264 6572 7320 666f 7220 6120 7061   orders for a pa
+000105e0: 6972 2022 7369 6e63 6522 0a20 2020 2020  ir "since".     
+000105f0: 2020 203a 7061 7261 6d20 7061 6972 3a20     :param pair: 
+00010600: 5061 6972 2066 6f72 2074 6865 2071 7565  Pair for the que
+00010610: 7279 0a20 2020 2020 2020 203a 7061 7261  ry.        :para
+00010620: 6d20 7369 6e63 653a 2053 7461 7274 696e  m since: Startin
+00010630: 6720 7469 6d65 2066 6f72 2074 6865 2071  g time for the q
+00010640: 7565 7279 0a20 2020 2020 2020 2022 2222  uery.        """
+00010650: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00010660: 2e5f 636f 6e66 6967 5b22 6472 795f 7275  ._config["dry_ru
+00010670: 6e22 5d3a 0a20 2020 2020 2020 2020 2020  n"]:.           
+00010680: 2072 6574 7572 6e20 5b5d 0a0a 2020 2020   return []..    
+00010690: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+000106a0: 2020 2020 2073 696e 6365 5f6d 7320 3d20       since_ms = 
+000106b0: 696e 7428 2873 696e 6365 2e74 696d 6573  int((since.times
+000106c0: 7461 6d70 2829 202d 2031 3029 202a 2031  tamp() - 10) * 1
+000106d0: 3030 3029 0a0a 2020 2020 2020 2020 2020  000)..          
+000106e0: 2020 6966 2073 656c 662e 6578 6368 616e    if self.exchan
+000106f0: 6765 5f68 6173 2822 6665 7463 684f 7264  ge_has("fetchOrd
+00010700: 6572 7322 293a 0a20 2020 2020 2020 2020  ers"):.         
+00010710: 2020 2020 2020 2069 6620 6e6f 7420 7061         if not pa
+00010720: 7261 6d73 3a0a 2020 2020 2020 2020 2020  rams:.          
+00010730: 2020 2020 2020 2020 2020 7061 7261 6d73            params
+00010740: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
+00010750: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+00010760: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00010770: 7264 6572 733a 204c 6973 745b 4469 6374  rders: List[Dict
+00010780: 5d20 3d20 7365 6c66 2e5f 6170 692e 6665  ] = self._api.fe
+00010790: 7463 685f 6f72 6465 7273 2870 6169 722c  tch_orders(pair,
+000107a0: 2073 696e 6365 3d73 696e 6365 5f6d 732c   since=since_ms,
+000107b0: 2070 6172 616d 733d 7061 7261 6d73 290a   params=params).
+000107c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000107d0: 6578 6365 7074 2063 6378 742e 4e6f 7453  except ccxt.NotS
+000107e0: 7570 706f 7274 6564 3a0a 2020 2020 2020  upported:.      
+000107f0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+00010800: 536f 6d65 2065 7863 6861 6e67 6573 2064  Some exchanges d
+00010810: 6f6e 2774 2073 7570 706f 7274 2066 6574  on't support fet
+00010820: 6368 4f72 6465 7273 0a20 2020 2020 2020  chOrders.       
+00010830: 2020 2020 2020 2020 2020 2020 2023 2061               # a
+00010840: 7474 656d 7074 2074 6f20 6665 7463 6820  ttempt to fetch 
+00010850: 6f70 656e 2061 6e64 2063 6c6f 7365 6420  open and closed 
+00010860: 6f72 6465 7273 2073 6570 6172 6174 656c  orders separatel
+00010870: 790a 2020 2020 2020 2020 2020 2020 2020  y.              
+00010880: 2020 2020 2020 6f72 6465 7273 203d 2073        orders = s
+00010890: 656c 662e 5f66 6574 6368 5f6f 7264 6572  elf._fetch_order
+000108a0: 735f 656d 756c 6174 6528 7061 6972 2c20  s_emulate(pair, 
+000108b0: 7369 6e63 655f 6d73 290a 2020 2020 2020  since_ms).      
+000108c0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+000108d0: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
+000108e0: 7273 203d 2073 656c 662e 5f66 6574 6368  rs = self._fetch
+000108f0: 5f6f 7264 6572 735f 656d 756c 6174 6528  _orders_emulate(
+00010900: 7061 6972 2c20 7369 6e63 655f 6d73 290a  pair, since_ms).
+00010910: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00010920: 2e5f 6c6f 675f 6578 6368 616e 6765 5f72  ._log_exchange_r
+00010930: 6573 706f 6e73 6528 2266 6574 6368 5f6f  esponse("fetch_o
+00010940: 7264 6572 7322 2c20 6f72 6465 7273 290a  rders", orders).
+00010950: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
+00010960: 7273 203d 205b 7365 6c66 2e5f 6f72 6465  rs = [self._orde
+00010970: 725f 636f 6e74 7261 6374 735f 746f 5f61  r_contracts_to_a
+00010980: 6d6f 756e 7428 6f29 2066 6f72 206f 2069  mount(o) for o i
+00010990: 6e20 6f72 6465 7273 5d0a 2020 2020 2020  n orders].      
+000109a0: 2020 2020 2020 7265 7475 726e 206f 7264        return ord
+000109b0: 6572 730a 2020 2020 2020 2020 6578 6365  ers.        exce
+000109c0: 7074 2063 6378 742e 4444 6f53 5072 6f74  pt ccxt.DDoSProt
+000109d0: 6563 7469 6f6e 2061 7320 653a 0a20 2020  ection as e:.   
+000109e0: 2020 2020 2020 2020 2072 6169 7365 2044           raise D
+000109f0: 446f 7350 726f 7465 6374 696f 6e28 6529  DosProtection(e)
+00010a00: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
+00010a10: 6578 6365 7074 2028 6363 7874 2e4f 7065  except (ccxt.Ope
+00010a20: 7261 7469 6f6e 4661 696c 6564 2c20 6363  rationFailed, cc
+00010a30: 7874 2e45 7863 6861 6e67 6545 7272 6f72  xt.ExchangeError
+00010a40: 2920 6173 2065 3a0a 2020 2020 2020 2020  ) as e:.        
+00010a50: 2020 2020 7261 6973 6520 5465 6d70 6f72      raise Tempor
+00010a60: 6172 7945 7272 6f72 280a 2020 2020 2020  aryError(.      
+00010a70: 2020 2020 2020 2020 2020 6622 436f 756c            f"Coul
+00010a80: 6420 6e6f 7420 6665 7463 6820 706f 7369  d not fetch posi
+00010a90: 7469 6f6e 7320 6475 6520 746f 207b 652e  tions due to {e.
+00010aa0: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
+00010ab0: 5f5f 7d2e 204d 6573 7361 6765 3a20 7b65  __}. Message: {e
+00010ac0: 7d22 0a20 2020 2020 2020 2020 2020 2029  }".            )
+00010ad0: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
+00010ae0: 6578 6365 7074 2063 6378 742e 4261 7365  except ccxt.Base
+00010af0: 4572 726f 7220 6173 2065 3a0a 2020 2020  Error as e:.    
+00010b00: 2020 2020 2020 2020 7261 6973 6520 4f70          raise Op
+00010b10: 6572 6174 696f 6e61 6c45 7863 6570 7469  erationalExcepti
+00010b20: 6f6e 2865 2920 6672 6f6d 2065 0a0a 2020  on(e) from e..  
+00010b30: 2020 4072 6574 7269 6572 0a20 2020 2064    @retrier.    d
+00010b40: 6566 2066 6574 6368 5f74 7261 6469 6e67  ef fetch_trading
+00010b50: 5f66 6565 7328 7365 6c66 2920 2d3e 2044  _fees(self) -> D
+00010b60: 6963 745b 7374 722c 2041 6e79 5d3a 0a20  ict[str, Any]:. 
+00010b70: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00010b80: 2020 2046 6574 6368 2075 7365 7220 6163     Fetch user ac
+00010b90: 636f 756e 7420 7472 6164 696e 6720 6665  count trading fe
+00010ba0: 6573 0a20 2020 2020 2020 2043 616e 2062  es.        Can b
+00010bb0: 6520 6361 6368 6564 2c20 7368 6f75 6c64  e cached, should
+00010bc0: 206e 6f74 2075 7064 6174 6520 6f66 7465   not update ofte
+00010bd0: 6e2e 0a20 2020 2020 2020 2022 2222 0a20  n..        """. 
+00010be0: 2020 2020 2020 2069 6620 280a 2020 2020         if (.    
+00010bf0: 2020 2020 2020 2020 7365 6c66 2e5f 636f          self._co
+00010c00: 6e66 6967 5b22 6472 795f 7275 6e22 5d0a  nfig["dry_run"].
+00010c10: 2020 2020 2020 2020 2020 2020 6f72 2073              or s
+00010c20: 656c 662e 7472 6164 696e 675f 6d6f 6465  elf.trading_mode
+00010c30: 2021 3d20 5472 6164 696e 674d 6f64 652e   != TradingMode.
+00010c40: 4655 5455 5245 530a 2020 2020 2020 2020  FUTURES.        
+00010c50: 2020 2020 6f72 206e 6f74 2073 656c 662e      or not self.
+00010c60: 6578 6368 616e 6765 5f68 6173 2822 6665  exchange_has("fe
+00010c70: 7463 6854 7261 6469 6e67 4665 6573 2229  tchTradingFees")
+00010c80: 0a20 2020 2020 2020 2029 3a0a 2020 2020  .        ):.    
+00010c90: 2020 2020 2020 2020 7265 7475 726e 207b          return {
+00010ca0: 7d0a 2020 2020 2020 2020 7472 793a 0a20  }.        try:. 
+00010cb0: 2020 2020 2020 2020 2020 2074 7261 6469             tradi
+00010cc0: 6e67 5f66 6565 733a 2044 6963 745b 7374  ng_fees: Dict[st
+00010cd0: 722c 2041 6e79 5d20 3d20 7365 6c66 2e5f  r, Any] = self._
+00010ce0: 6170 692e 6665 7463 685f 7472 6164 696e  api.fetch_tradin
+00010cf0: 675f 6665 6573 2829 0a20 2020 2020 2020  g_fees().       
+00010d00: 2020 2020 2073 656c 662e 5f6c 6f67 5f65       self._log_e
+00010d10: 7863 6861 6e67 655f 7265 7370 6f6e 7365  xchange_response
+00010d20: 2822 6665 7463 685f 7472 6164 696e 675f  ("fetch_trading_
+00010d30: 6665 6573 222c 2074 7261 6469 6e67 5f66  fees", trading_f
+00010d40: 6565 7329 0a20 2020 2020 2020 2020 2020  ees).           
+00010d50: 2072 6574 7572 6e20 7472 6164 696e 675f   return trading_
+00010d60: 6665 6573 0a20 2020 2020 2020 2065 7863  fees.        exc
+00010d70: 6570 7420 6363 7874 2e44 446f 5350 726f  ept ccxt.DDoSPro
+00010d80: 7465 6374 696f 6e20 6173 2065 3a0a 2020  tection as e:.  
+00010d90: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00010da0: 4444 6f73 5072 6f74 6563 7469 6f6e 2865  DDosProtection(e
+00010db0: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
+00010dc0: 2065 7863 6570 7420 2863 6378 742e 4f70   except (ccxt.Op
+00010dd0: 6572 6174 696f 6e46 6169 6c65 642c 2063  erationFailed, c
+00010de0: 6378 742e 4578 6368 616e 6765 4572 726f  cxt.ExchangeErro
+00010df0: 7229 2061 7320 653a 0a20 2020 2020 2020  r) as e:.       
+00010e00: 2020 2020 2072 6169 7365 2054 656d 706f       raise Tempo
+00010e10: 7261 7279 4572 726f 7228 0a20 2020 2020  raryError(.     
+00010e20: 2020 2020 2020 2020 2020 2066 2243 6f75             f"Cou
+00010e30: 6c64 206e 6f74 2066 6574 6368 2074 7261  ld not fetch tra
+00010e40: 6469 6e67 2066 6565 7320 6475 6520 746f  ding fees due to
+00010e50: 207b 652e 5f5f 636c 6173 735f 5f2e 5f5f   {e.__class__.__
+00010e60: 6e61 6d65 5f5f 7d2e 204d 6573 7361 6765  name__}. Message
+00010e70: 3a20 7b65 7d22 0a20 2020 2020 2020 2020  : {e}".         
+00010e80: 2020 2029 2066 726f 6d20 650a 2020 2020     ) from e.    
+00010e90: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
+00010ea0: 4261 7365 4572 726f 7220 6173 2065 3a0a  BaseError as e:.
+00010eb0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00010ec0: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
+00010ed0: 6570 7469 6f6e 2865 2920 6672 6f6d 2065  eption(e) from e
+00010ee0: 0a0a 2020 2020 4072 6574 7269 6572 0a20  ..    @retrier. 
+00010ef0: 2020 2064 6566 2066 6574 6368 5f62 6964     def fetch_bid
+00010f00: 735f 6173 6b73 2873 656c 662c 2073 796d  s_asks(self, sym
+00010f10: 626f 6c73 3a20 4f70 7469 6f6e 616c 5b4c  bols: Optional[L
+00010f20: 6973 745b 7374 725d 5d20 3d20 4e6f 6e65  ist[str]] = None
+00010f30: 2c20 6361 6368 6564 3a20 626f 6f6c 203d  , cached: bool =
+00010f40: 2046 616c 7365 2920 2d3e 2044 6963 743a   False) -> Dict:
+00010f50: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00010f60: 2020 2020 203a 7061 7261 6d20 7379 6d62       :param symb
+00010f70: 6f6c 733a 204c 6973 7420 6f66 2073 796d  ols: List of sym
+00010f80: 626f 6c73 2074 6f20 6665 7463 680a 2020  bols to fetch.  
+00010f90: 2020 2020 2020 3a70 6172 616d 2063 6163        :param cac
+00010fa0: 6865 643a 2041 6c6c 6f77 2063 6163 6865  hed: Allow cache
+00010fb0: 6420 7265 7375 6c74 0a20 2020 2020 2020  d result.       
+00010fc0: 203a 7265 7475 726e 3a20 6665 7463 685f   :return: fetch_
+00010fd0: 6269 6473 5f61 736b 7320 7265 7375 6c74  bids_asks result
+00010fe0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00010ff0: 2020 2020 2069 6620 6e6f 7420 7365 6c66       if not self
+00011000: 2e65 7863 6861 6e67 655f 6861 7328 2266  .exchange_has("f
+00011010: 6574 6368 4269 6473 4173 6b73 2229 3a0a  etchBidsAsks"):.
+00011020: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00011030: 726e 207b 7d0a 2020 2020 2020 2020 6966  rn {}.        if
+00011040: 2063 6163 6865 643a 0a20 2020 2020 2020   cached:.       
+00011050: 2020 2020 2077 6974 6820 7365 6c66 2e5f       with self._
+00011060: 6361 6368 655f 6c6f 636b 3a0a 2020 2020  cache_lock:.    
+00011070: 2020 2020 2020 2020 2020 2020 7469 636b              tick
+00011080: 6572 7320 3d20 7365 6c66 2e5f 6665 7463  ers = self._fetc
+00011090: 685f 7469 636b 6572 735f 6361 6368 652e  h_tickers_cache.
+000110a0: 6765 7428 2266 6574 6368 5f62 6964 735f  get("fetch_bids_
+000110b0: 6173 6b73 2229 0a20 2020 2020 2020 2020  asks").         
+000110c0: 2020 2069 6620 7469 636b 6572 733a 0a20     if tickers:. 
+000110d0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+000110e0: 6574 7572 6e20 7469 636b 6572 730a 2020  eturn tickers.  
+000110f0: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+00011100: 2020 2020 2020 2074 6963 6b65 7273 203d         tickers =
+00011110: 2073 656c 662e 5f61 7069 2e66 6574 6368   self._api.fetch
+00011120: 5f62 6964 735f 6173 6b73 2873 796d 626f  _bids_asks(symbo
+00011130: 6c73 290a 2020 2020 2020 2020 2020 2020  ls).            
+00011140: 7769 7468 2073 656c 662e 5f63 6163 6865  with self._cache
+00011150: 5f6c 6f63 6b3a 0a20 2020 2020 2020 2020  _lock:.         
+00011160: 2020 2020 2020 2073 656c 662e 5f66 6574         self._fet
+00011170: 6368 5f74 6963 6b65 7273 5f63 6163 6865  ch_tickers_cache
+00011180: 5b22 6665 7463 685f 6269 6473 5f61 736b  ["fetch_bids_ask
+00011190: 7322 5d20 3d20 7469 636b 6572 730a 2020  s"] = tickers.  
+000111a0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+000111b0: 2074 6963 6b65 7273 0a20 2020 2020 2020   tickers.       
+000111c0: 2065 7863 6570 7420 6363 7874 2e4e 6f74   except ccxt.Not
+000111d0: 5375 7070 6f72 7465 6420 6173 2065 3a0a  Supported as e:.
+000111e0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+000111f0: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
+00011200: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
+00011210: 2020 2020 2020 2020 6622 4578 6368 616e          f"Exchan
+00011220: 6765 207b 7365 6c66 2e5f 6170 692e 6e61  ge {self._api.na
+00011230: 6d65 7d20 646f 6573 206e 6f74 2073 7570  me} does not sup
+00011240: 706f 7274 2066 6574 6368 696e 6720 6269  port fetching bi
+00011250: 6473 2f61 736b 7320 696e 2062 6174 6368  ds/asks in batch
+00011260: 2e20 220a 2020 2020 2020 2020 2020 2020  . ".            
+00011270: 2020 2020 6622 4d65 7373 6167 653a 207b      f"Message: {
+00011280: 657d 220a 2020 2020 2020 2020 2020 2020  e}".            
+00011290: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
+000112a0: 2065 7863 6570 7420 6363 7874 2e44 446f   except ccxt.DDo
+000112b0: 5350 726f 7465 6374 696f 6e20 6173 2065  SProtection as e
+000112c0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+000112d0: 6973 6520 4444 6f73 5072 6f74 6563 7469  ise DDosProtecti
+000112e0: 6f6e 2865 2920 6672 6f6d 2065 0a20 2020  on(e) from e.   
+000112f0: 2020 2020 2065 7863 6570 7420 2863 6378       except (ccx
+00011300: 742e 4f70 6572 6174 696f 6e46 6169 6c65  t.OperationFaile
+00011310: 642c 2063 6378 742e 4578 6368 616e 6765  d, ccxt.Exchange
+00011320: 4572 726f 7229 2061 7320 653a 0a20 2020  Error) as e:.   
+00011330: 2020 2020 2020 2020 2072 6169 7365 2054           raise T
+00011340: 656d 706f 7261 7279 4572 726f 7228 0a20  emporaryError(. 
+00011350: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00011360: 2243 6f75 6c64 206e 6f74 206c 6f61 6420  "Could not load 
+00011370: 6269 6473 2f61 736b 7320 6475 6520 746f  bids/asks due to
+00011380: 207b 652e 5f5f 636c 6173 735f 5f2e 5f5f   {e.__class__.__
+00011390: 6e61 6d65 5f5f 7d2e 204d 6573 7361 6765  name__}. Message
+000113a0: 3a20 7b65 7d22 0a20 2020 2020 2020 2020  : {e}".         
+000113b0: 2020 2029 2066 726f 6d20 650a 2020 2020     ) from e.    
+000113c0: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
+000113d0: 4261 7365 4572 726f 7220 6173 2065 3a0a  BaseError as e:.
+000113e0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+000113f0: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
+00011400: 6570 7469 6f6e 2865 2920 6672 6f6d 2065  eption(e) from e
+00011410: 0a0a 2020 2020 4072 6574 7269 6572 0a20  ..    @retrier. 
+00011420: 2020 2064 6566 2067 6574 5f74 6963 6b65     def get_ticke
+00011430: 7273 2873 656c 662c 2073 796d 626f 6c73  rs(self, symbols
+00011440: 3a20 4f70 7469 6f6e 616c 5b4c 6973 745b  : Optional[List[
+00011450: 7374 725d 5d20 3d20 4e6f 6e65 2c20 6361  str]] = None, ca
+00011460: 6368 6564 3a20 626f 6f6c 203d 2046 616c  ched: bool = Fal
+00011470: 7365 2920 2d3e 2054 6963 6b65 7273 3a0a  se) -> Tickers:.
+00011480: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+00011490: 2020 2020 3a70 6172 616d 2063 6163 6865      :param cache
+000114a0: 643a 2041 6c6c 6f77 2063 6163 6865 6420  d: Allow cached 
+000114b0: 7265 7375 6c74 0a20 2020 2020 2020 203a  result.        :
+000114c0: 7265 7475 726e 3a20 6665 7463 685f 7469  return: fetch_ti
+000114d0: 636b 6572 7320 7265 7375 6c74 0a20 2020  ckers result.   
+000114e0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+000114f0: 2074 6963 6b65 7273 3a20 5469 636b 6572   tickers: Ticker
+00011500: 730a 2020 2020 2020 2020 6966 206e 6f74  s.        if not
+00011510: 2073 656c 662e 6578 6368 616e 6765 5f68   self.exchange_h
+00011520: 6173 2822 6665 7463 6854 6963 6b65 7273  as("fetchTickers
+00011530: 2229 3a0a 2020 2020 2020 2020 2020 2020  "):.            
+00011540: 7265 7475 726e 207b 7d0a 2020 2020 2020  return {}.      
+00011550: 2020 6966 2063 6163 6865 643a 0a20 2020    if cached:.   
+00011560: 2020 2020 2020 2020 2077 6974 6820 7365           with se
+00011570: 6c66 2e5f 6361 6368 655f 6c6f 636b 3a0a  lf._cache_lock:.
+00011580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011590: 7469 636b 6572 7320 3d20 7365 6c66 2e5f  tickers = self._
+000115a0: 6665 7463 685f 7469 636b 6572 735f 6361  fetch_tickers_ca
+000115b0: 6368 652e 6765 7428 2266 6574 6368 5f74  che.get("fetch_t
+000115c0: 6963 6b65 7273 2229 2020 2320 7479 7065  ickers")  # type
+000115d0: 3a20 6967 6e6f 7265 0a20 2020 2020 2020  : ignore.       
+000115e0: 2020 2020 2069 6620 7469 636b 6572 733a       if tickers:
+000115f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011600: 2072 6574 7572 6e20 7469 636b 6572 730a   return tickers.
+00011610: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+00011620: 2020 2020 2020 2020 2074 6963 6b65 7273           tickers
+00011630: 203d 2073 656c 662e 5f61 7069 2e66 6574   = self._api.fet
+00011640: 6368 5f74 6963 6b65 7273 2873 796d 626f  ch_tickers(symbo
+00011650: 6c73 290a 2020 2020 2020 2020 2020 2020  ls).            
+00011660: 7769 7468 2073 656c 662e 5f63 6163 6865  with self._cache
+00011670: 5f6c 6f63 6b3a 0a20 2020 2020 2020 2020  _lock:.         
+00011680: 2020 2020 2020 2073 656c 662e 5f66 6574         self._fet
+00011690: 6368 5f74 6963 6b65 7273 5f63 6163 6865  ch_tickers_cache
+000116a0: 5b22 6665 7463 685f 7469 636b 6572 7322  ["fetch_tickers"
+000116b0: 5d20 3d20 7469 636b 6572 730a 2020 2020  ] = tickers.    
+000116c0: 2020 2020 2020 2020 7265 7475 726e 2074          return t
+000116d0: 6963 6b65 7273 0a20 2020 2020 2020 2065  ickers.        e
+000116e0: 7863 6570 7420 6363 7874 2e4e 6f74 5375  xcept ccxt.NotSu
+000116f0: 7070 6f72 7465 6420 6173 2065 3a0a 2020  pported as e:.  
+00011700: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00011710: 4f70 6572 6174 696f 6e61 6c45 7863 6570  OperationalExcep
+00011720: 7469 6f6e 280a 2020 2020 2020 2020 2020  tion(.          
+00011730: 2020 2020 2020 6622 4578 6368 616e 6765        f"Exchange
+00011740: 207b 7365 6c66 2e5f 6170 692e 6e61 6d65   {self._api.name
+00011750: 7d20 646f 6573 206e 6f74 2073 7570 706f  } does not suppo
+00011760: 7274 2066 6574 6368 696e 6720 7469 636b  rt fetching tick
+00011770: 6572 7320 696e 2062 6174 6368 2e20 220a  ers in batch. ".
+00011780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011790: 6622 4d65 7373 6167 653a 207b 657d 220a  f"Message: {e}".
+000117a0: 2020 2020 2020 2020 2020 2020 2920 6672              ) fr
+000117b0: 6f6d 2065 0a20 2020 2020 2020 2065 7863  om e.        exc
+000117c0: 6570 7420 6363 7874 2e42 6164 5379 6d62  ept ccxt.BadSymb
+000117d0: 6f6c 2061 7320 653a 0a20 2020 2020 2020  ol as e:.       
+000117e0: 2020 2020 206c 6f67 6765 722e 7761 726e       logger.warn
+000117f0: 696e 6728 0a20 2020 2020 2020 2020 2020  ing(.           
+00011800: 2020 2020 2066 2243 6f75 6c64 206e 6f74       f"Could not
+00011810: 206c 6f61 6420 7469 636b 6572 7320 6475   load tickers du
+00011820: 6520 746f 207b 652e 5f5f 636c 6173 735f  e to {e.__class_
+00011830: 5f2e 5f5f 6e61 6d65 5f5f 7d2e 204d 6573  _.__name__}. Mes
+00011840: 7361 6765 3a20 7b65 7d20 2e22 0a20 2020  sage: {e} .".   
+00011850: 2020 2020 2020 2020 2020 2020 2022 5265               "Re
+00011860: 6c6f 6164 696e 6720 6d61 726b 6574 732e  loading markets.
+00011870: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
+00011880: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00011890: 2e72 656c 6f61 645f 6d61 726b 6574 7328  .reload_markets(
+000118a0: 5472 7565 290a 2020 2020 2020 2020 2020  True).          
+000118b0: 2020 2320 5265 2d72 6169 7365 2065 7863    # Re-raise exc
+000118c0: 6570 7469 6f6e 2074 6f20 7265 7065 6174  eption to repeat
+000118d0: 2074 6865 2063 616c 6c2e 0a20 2020 2020   the call..     
+000118e0: 2020 2020 2020 2072 6169 7365 2054 656d         raise Tem
+000118f0: 706f 7261 7279 4572 726f 7220 6672 6f6d  poraryError from
+00011900: 2065 0a20 2020 2020 2020 2065 7863 6570   e.        excep
+00011910: 7420 6363 7874 2e44 446f 5350 726f 7465  t ccxt.DDoSProte
+00011920: 6374 696f 6e20 6173 2065 3a0a 2020 2020  ction as e:.    
+00011930: 2020 2020 2020 2020 7261 6973 6520 4444          raise DD
+00011940: 6f73 5072 6f74 6563 7469 6f6e 2865 2920  osProtection(e) 
+00011950: 6672 6f6d 2065 0a20 2020 2020 2020 2065  from e.        e
+00011960: 7863 6570 7420 2863 6378 742e 4f70 6572  xcept (ccxt.Oper
+00011970: 6174 696f 6e46 6169 6c65 642c 2063 6378  ationFailed, ccx
+00011980: 742e 4578 6368 616e 6765 4572 726f 7229  t.ExchangeError)
+00011990: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
+000119a0: 2020 2072 6169 7365 2054 656d 706f 7261     raise Tempora
+000119b0: 7279 4572 726f 7228 0a20 2020 2020 2020  ryError(.       
+000119c0: 2020 2020 2020 2020 2066 2243 6f75 6c64           f"Could
+000119d0: 206e 6f74 206c 6f61 6420 7469 636b 6572   not load ticker
+000119e0: 7320 6475 6520 746f 207b 652e 5f5f 636c  s due to {e.__cl
+000119f0: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 7d2e  ass__.__name__}.
+00011a00: 204d 6573 7361 6765 3a20 7b65 7d22 0a20   Message: {e}". 
+00011a10: 2020 2020 2020 2020 2020 2029 2066 726f             ) fro
+00011a20: 6d20 650a 2020 2020 2020 2020 6578 6365  m e.        exce
+00011a30: 7074 2063 6378 742e 4261 7365 4572 726f  pt ccxt.BaseErro
+00011a40: 7220 6173 2065 3a0a 2020 2020 2020 2020  r as e:.        
+00011a50: 2020 2020 7261 6973 6520 4f70 6572 6174      raise Operat
+00011a60: 696f 6e61 6c45 7863 6570 7469 6f6e 2865  ionalException(e
+00011a70: 2920 6672 6f6d 2065 0a0a 2020 2020 2320  ) from e..    # 
+00011a80: 5072 6963 696e 6720 696e 666f 0a0a 2020  Pricing info..  
+00011a90: 2020 4072 6574 7269 6572 0a20 2020 2064    @retrier.    d
+00011aa0: 6566 2066 6574 6368 5f74 6963 6b65 7228  ef fetch_ticker(
+00011ab0: 7365 6c66 2c20 7061 6972 3a20 7374 7229  self, pair: str)
+00011ac0: 202d 3e20 5469 636b 6572 3a0a 2020 2020   -> Ticker:.    
+00011ad0: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+00011ae0: 2020 2020 2069 6620 7061 6972 206e 6f74       if pair not
+00011af0: 2069 6e20 7365 6c66 2e6d 6172 6b65 7473   in self.markets
+00011b00: 206f 7220 7365 6c66 2e6d 6172 6b65 7473   or self.markets
+00011b10: 5b70 6169 725d 2e67 6574 2822 6163 7469  [pair].get("acti
+00011b20: 7665 222c 2046 616c 7365 2920 6973 2046  ve", False) is F
+00011b30: 616c 7365 3a0a 2020 2020 2020 2020 2020  alse:.          
+00011b40: 2020 2020 2020 7261 6973 6520 4578 6368        raise Exch
+00011b50: 616e 6765 4572 726f 7228 6622 5061 6972  angeError(f"Pair
+00011b60: 207b 7061 6972 7d20 6e6f 7420 6176 6169   {pair} not avai
+00011b70: 6c61 626c 6522 290a 2020 2020 2020 2020  lable").        
+00011b80: 2020 2020 6461 7461 3a20 5469 636b 6572      data: Ticker
+00011b90: 203d 2073 656c 662e 5f61 7069 2e66 6574   = self._api.fet
+00011ba0: 6368 5f74 6963 6b65 7228 7061 6972 290a  ch_ticker(pair).
+00011bb0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00011bc0: 726e 2064 6174 610a 2020 2020 2020 2020  rn data.        
+00011bd0: 6578 6365 7074 2063 6378 742e 4444 6f53  except ccxt.DDoS
+00011be0: 5072 6f74 6563 7469 6f6e 2061 7320 653a  Protection as e:
+00011bf0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00011c00: 7365 2044 446f 7350 726f 7465 6374 696f  se DDosProtectio
+00011c10: 6e28 6529 2066 726f 6d20 650a 2020 2020  n(e) from e.    
+00011c20: 2020 2020 6578 6365 7074 2028 6363 7874      except (ccxt
+00011c30: 2e4f 7065 7261 7469 6f6e 4661 696c 6564  .OperationFailed
+00011c40: 2c20 6363 7874 2e45 7863 6861 6e67 6545  , ccxt.ExchangeE
+00011c50: 7272 6f72 2920 6173 2065 3a0a 2020 2020  rror) as e:.    
+00011c60: 2020 2020 2020 2020 7261 6973 6520 5465          raise Te
+00011c70: 6d70 6f72 6172 7945 7272 6f72 280a 2020  mporaryError(.  
+00011c80: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+00011c90: 436f 756c 6420 6e6f 7420 6c6f 6164 2074  Could not load t
+00011ca0: 6963 6b65 7220 6475 6520 746f 207b 652e  icker due to {e.
+00011cb0: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
+00011cc0: 5f5f 7d2e 204d 6573 7361 6765 3a20 7b65  __}. Message: {e
+00011cd0: 7d22 0a20 2020 2020 2020 2020 2020 2029  }".            )
+00011ce0: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
+00011cf0: 6578 6365 7074 2063 6378 742e 4261 7365  except ccxt.Base
+00011d00: 4572 726f 7220 6173 2065 3a0a 2020 2020  Error as e:.    
+00011d10: 2020 2020 2020 2020 7261 6973 6520 4f70          raise Op
+00011d20: 6572 6174 696f 6e61 6c45 7863 6570 7469  erationalExcepti
+00011d30: 6f6e 2865 2920 6672 6f6d 2065 0a0a 2020  on(e) from e..  
+00011d40: 2020 4073 7461 7469 636d 6574 686f 640a    @staticmethod.
+00011d50: 2020 2020 6465 6620 6765 745f 6e65 7874      def get_next
+00011d60: 5f6c 696d 6974 5f69 6e5f 6c69 7374 280a  _limit_in_list(.
+00011d70: 2020 2020 2020 2020 6c69 6d69 743a 2069          limit: i
+00011d80: 6e74 2c20 6c69 6d69 745f 7261 6e67 653a  nt, limit_range:
+00011d90: 204f 7074 696f 6e61 6c5b 4c69 7374 5b69   Optional[List[i
+00011da0: 6e74 5d5d 2c20 7261 6e67 655f 7265 7175  nt]], range_requ
+00011db0: 6972 6564 3a20 626f 6f6c 203d 2054 7275  ired: bool = Tru
+00011dc0: 650a 2020 2020 293a 0a20 2020 2020 2020  e.    ):.       
+00011dd0: 2022 2222 0a20 2020 2020 2020 2047 6574   """.        Get
+00011de0: 206e 6578 7420 6772 6561 7465 7220 7661   next greater va
+00011df0: 6c75 6520 696e 2074 6865 206c 6973 742e  lue in the list.
+00011e00: 0a20 2020 2020 2020 2055 7365 6420 6279  .        Used by
+00011e10: 2066 6574 6368 5f6c 325f 6f72 6465 725f   fetch_l2_order_
+00011e20: 626f 6f6b 2069 6620 7468 6520 6170 6920  book if the api 
+00011e30: 6f6e 6c79 2073 7570 706f 7274 7320 6120  only supports a 
+00011e40: 6c69 6d69 7465 6420 7261 6e67 650a 2020  limited range.  
+00011e50: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00011e60: 2020 6966 206e 6f74 206c 696d 6974 5f72    if not limit_r
+00011e70: 616e 6765 3a0a 2020 2020 2020 2020 2020  ange:.          
+00011e80: 2020 7265 7475 726e 206c 696d 6974 0a0a    return limit..
+00011e90: 2020 2020 2020 2020 7265 7375 6c74 203d          result =
+00011ea0: 206d 696e 285b 7820 666f 7220 7820 696e   min([x for x in
+00011eb0: 206c 696d 6974 5f72 616e 6765 2069 6620   limit_range if 
+00011ec0: 6c69 6d69 7420 3c3d 2078 5d20 2b20 5b6d  limit <= x] + [m
+00011ed0: 6178 286c 696d 6974 5f72 616e 6765 295d  ax(limit_range)]
+00011ee0: 290a 2020 2020 2020 2020 6966 206e 6f74  ).        if not
+00011ef0: 2072 616e 6765 5f72 6571 7569 7265 6420   range_required 
+00011f00: 616e 6420 6c69 6d69 7420 3e20 7265 7375  and limit > resu
+00011f10: 6c74 3a0a 2020 2020 2020 2020 2020 2020  lt:.            
+00011f20: 2320 5261 6e67 6520 6973 206e 6f74 2072  # Range is not r
+00011f30: 6571 7569 7265 6420 2d20 7765 2063 616e  equired - we can
+00011f40: 2075 7365 204e 6f6e 6520 6173 2070 6172   use None as par
+00011f50: 616d 6574 6572 2e0a 2020 2020 2020 2020  ameter..        
+00011f60: 2020 2020 7265 7475 726e 204e 6f6e 650a      return None.
+00011f70: 2020 2020 2020 2020 7265 7475 726e 2072          return r
+00011f80: 6573 756c 740a 0a20 2020 2040 7265 7472  esult..    @retr
+00011f90: 6965 720a 2020 2020 6465 6620 6665 7463  ier.    def fetc
+00011fa0: 685f 6c32 5f6f 7264 6572 5f62 6f6f 6b28  h_l2_order_book(
+00011fb0: 7365 6c66 2c20 7061 6972 3a20 7374 722c  self, pair: str,
+00011fc0: 206c 696d 6974 3a20 696e 7420 3d20 3130   limit: int = 10
+00011fd0: 3029 202d 3e20 4f72 6465 7242 6f6f 6b3a  0) -> OrderBook:
+00011fe0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00011ff0: 2020 2020 2047 6574 204c 3220 6f72 6465       Get L2 orde
+00012000: 7220 626f 6f6b 2066 726f 6d20 6578 6368  r book from exch
+00012010: 616e 6765 2e0a 2020 2020 2020 2020 4361  ange..        Ca
+00012020: 6e20 6265 206c 696d 6974 6564 2074 6f20  n be limited to 
+00012030: 6120 6365 7274 6169 6e20 616d 6f75 6e74  a certain amount
+00012040: 2028 6966 2073 7570 706f 7274 6564 292e   (if supported).
+00012050: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+00012060: 2061 2064 6963 7420 696e 2074 6865 2066   a dict in the f
+00012070: 6f72 6d61 740a 2020 2020 2020 2020 7b27  ormat.        {'
+00012080: 6173 6b73 273a 205b 7072 6963 652c 2076  asks': [price, v
+00012090: 6f6c 756d 655d 2c20 2762 6964 7327 3a20  olume], 'bids': 
+000120a0: 5b70 7269 6365 2c20 766f 6c75 6d65 5d7d  [price, volume]}
+000120b0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+000120c0: 2020 2020 206c 696d 6974 3120 3d20 7365       limit1 = se
+000120d0: 6c66 2e67 6574 5f6e 6578 745f 6c69 6d69  lf.get_next_limi
+000120e0: 745f 696e 5f6c 6973 7428 0a20 2020 2020  t_in_list(.     
+000120f0: 2020 2020 2020 206c 696d 6974 2c20 7365         limit, se
+00012100: 6c66 2e5f 6674 5f68 6173 5b22 6c32 5f6c  lf._ft_has["l2_l
+00012110: 696d 6974 5f72 616e 6765 225d 2c20 7365  imit_range"], se
+00012120: 6c66 2e5f 6674 5f68 6173 5b22 6c32 5f6c  lf._ft_has["l2_l
+00012130: 696d 6974 5f72 616e 6765 5f72 6571 7569  imit_range_requi
+00012140: 7265 6422 5d0a 2020 2020 2020 2020 290a  red"].        ).
+00012150: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+00012160: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00012170: 7365 6c66 2e5f 6170 692e 6665 7463 685f  self._api.fetch_
+00012180: 6c32 5f6f 7264 6572 5f62 6f6f 6b28 7061  l2_order_book(pa
+00012190: 6972 2c20 6c69 6d69 7431 290a 2020 2020  ir, limit1).    
+000121a0: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
+000121b0: 4e6f 7453 7570 706f 7274 6564 2061 7320  NotSupported as 
+000121c0: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+000121d0: 6169 7365 204f 7065 7261 7469 6f6e 616c  aise Operational
+000121e0: 4578 6365 7074 696f 6e28 0a20 2020 2020  Exception(.     
+000121f0: 2020 2020 2020 2020 2020 2066 2245 7863             f"Exc
+00012200: 6861 6e67 6520 7b73 656c 662e 5f61 7069  hange {self._api
+00012210: 2e6e 616d 657d 2064 6f65 7320 6e6f 7420  .name} does not 
+00012220: 7375 7070 6f72 7420 6665 7463 6869 6e67  support fetching
+00012230: 206f 7264 6572 2062 6f6f 6b2e 204d 6573   order book. Mes
+00012240: 7361 6765 3a20 7b65 7d22 0a20 2020 2020  sage: {e}".     
+00012250: 2020 2020 2020 2029 2066 726f 6d20 650a         ) from e.
+00012260: 2020 2020 2020 2020 6578 6365 7074 2063          except c
+00012270: 6378 742e 4444 6f53 5072 6f74 6563 7469  cxt.DDoSProtecti
+00012280: 6f6e 2061 7320 653a 0a20 2020 2020 2020  on as e:.       
+00012290: 2020 2020 2072 6169 7365 2044 446f 7350       raise DDosP
+000122a0: 726f 7465 6374 696f 6e28 6529 2066 726f  rotection(e) fro
+000122b0: 6d20 650a 2020 2020 2020 2020 6578 6365  m e.        exce
+000122c0: 7074 2028 6363 7874 2e4f 7065 7261 7469  pt (ccxt.Operati
+000122d0: 6f6e 4661 696c 6564 2c20 6363 7874 2e45  onFailed, ccxt.E
+000122e0: 7863 6861 6e67 6545 7272 6f72 2920 6173  xchangeError) as
+000122f0: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
+00012300: 7261 6973 6520 5465 6d70 6f72 6172 7945  raise TemporaryE
+00012310: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
+00012320: 2020 2020 2020 6622 436f 756c 6420 6e6f        f"Could no
+00012330: 7420 6765 7420 6f72 6465 7220 626f 6f6b  t get order book
+00012340: 2064 7565 2074 6f20 7b65 2e5f 5f63 6c61   due to {e.__cla
+00012350: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2e20  ss__.__name__}. 
+00012360: 4d65 7373 6167 653a 207b 657d 220a 2020  Message: {e}".  
+00012370: 2020 2020 2020 2020 2020 2920 6672 6f6d            ) from
+00012380: 2065 0a20 2020 2020 2020 2065 7863 6570   e.        excep
+00012390: 7420 6363 7874 2e42 6173 6545 7272 6f72  t ccxt.BaseError
+000123a0: 2061 7320 653a 0a20 2020 2020 2020 2020   as e:.         
+000123b0: 2020 2072 6169 7365 204f 7065 7261 7469     raise Operati
+000123c0: 6f6e 616c 4578 6365 7074 696f 6e28 6529  onalException(e)
+000123d0: 2066 726f 6d20 650a 0a20 2020 2064 6566   from e..    def
+000123e0: 205f 6765 745f 7072 6963 655f 7369 6465   _get_price_side
+000123f0: 2873 656c 662c 2073 6964 653a 2073 7472  (self, side: str
+00012400: 2c20 6973 5f73 686f 7274 3a20 626f 6f6c  , is_short: bool
+00012410: 2c20 636f 6e66 5f73 7472 6174 6567 793a  , conf_strategy:
+00012420: 2044 6963 7429 202d 3e20 4269 6441 736b   Dict) -> BidAsk
+00012430: 3a0a 2020 2020 2020 2020 7072 6963 655f  :.        price_
+00012440: 7369 6465 203d 2063 6f6e 665f 7374 7261  side = conf_stra
+00012450: 7465 6779 5b22 7072 6963 655f 7369 6465  tegy["price_side
+00012460: 225d 0a0a 2020 2020 2020 2020 6966 2070  "]..        if p
+00012470: 7269 6365 5f73 6964 6520 696e 2028 2273  rice_side in ("s
+00012480: 616d 6522 2c20 226f 7468 6572 2229 3a0a  ame", "other"):.
+00012490: 2020 2020 2020 2020 2020 2020 7072 6963              pric
+000124a0: 655f 6d61 7020 3d20 7b0a 2020 2020 2020  e_map = {.      
+000124b0: 2020 2020 2020 2020 2020 2822 656e 7472            ("entr
+000124c0: 7922 2c20 226c 6f6e 6722 2c20 2273 616d  y", "long", "sam
+000124d0: 6522 293a 2022 6269 6422 2c0a 2020 2020  e"): "bid",.    
+000124e0: 2020 2020 2020 2020 2020 2020 2822 656e              ("en
+000124f0: 7472 7922 2c20 226c 6f6e 6722 2c20 226f  try", "long", "o
+00012500: 7468 6572 2229 3a20 2261 736b 222c 0a20  ther"): "ask",. 
+00012510: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+00012520: 2265 6e74 7279 222c 2022 7368 6f72 7422  "entry", "short"
+00012530: 2c20 2273 616d 6522 293a 2022 6173 6b22  , "same"): "ask"
+00012540: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00012550: 2020 2822 656e 7472 7922 2c20 2273 686f    ("entry", "sho
+00012560: 7274 222c 2022 6f74 6865 7222 293a 2022  rt", "other"): "
+00012570: 6269 6422 2c0a 2020 2020 2020 2020 2020  bid",.          
+00012580: 2020 2020 2020 2822 6578 6974 222c 2022        ("exit", "
+00012590: 6c6f 6e67 222c 2022 7361 6d65 2229 3a20  long", "same"): 
+000125a0: 2261 736b 222c 0a20 2020 2020 2020 2020  "ask",.         
+000125b0: 2020 2020 2020 2028 2265 7869 7422 2c20         ("exit", 
+000125c0: 226c 6f6e 6722 2c20 226f 7468 6572 2229  "long", "other")
+000125d0: 3a20 2262 6964 222c 0a20 2020 2020 2020  : "bid",.       
+000125e0: 2020 2020 2020 2020 2028 2265 7869 7422           ("exit"
+000125f0: 2c20 2273 686f 7274 222c 2022 7361 6d65  , "short", "same
+00012600: 2229 3a20 2262 6964 222c 0a20 2020 2020  "): "bid",.     
+00012610: 2020 2020 2020 2020 2020 2028 2265 7869             ("exi
+00012620: 7422 2c20 2273 686f 7274 222c 2022 6f74  t", "short", "ot
+00012630: 6865 7222 293a 2022 6173 6b22 2c0a 2020  her"): "ask",.  
+00012640: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00012650: 2020 2020 2020 2020 7072 6963 655f 7369          price_si
+00012660: 6465 203d 2070 7269 6365 5f6d 6170 5b28  de = price_map[(
+00012670: 7369 6465 2c20 2273 686f 7274 2220 6966  side, "short" if
+00012680: 2069 735f 7368 6f72 7420 656c 7365 2022   is_short else "
+00012690: 6c6f 6e67 222c 2070 7269 6365 5f73 6964  long", price_sid
+000126a0: 6529 5d0a 2020 2020 2020 2020 7265 7475  e)].        retu
+000126b0: 726e 2070 7269 6365 5f73 6964 650a 0a20  rn price_side.. 
+000126c0: 2020 2064 6566 2067 6574 5f72 6174 6528     def get_rate(
+000126d0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+000126e0: 2020 2020 2020 2070 6169 723a 2073 7472         pair: str
+000126f0: 2c0a 2020 2020 2020 2020 7265 6672 6573  ,.        refres
+00012700: 683a 2062 6f6f 6c2c 0a20 2020 2020 2020  h: bool,.       
+00012710: 2073 6964 653a 2045 6e74 7279 4578 6974   side: EntryExit
+00012720: 2c0a 2020 2020 2020 2020 6973 5f73 686f  ,.        is_sho
+00012730: 7274 3a20 626f 6f6c 2c0a 2020 2020 2020  rt: bool,.      
+00012740: 2020 6f72 6465 725f 626f 6f6b 3a20 4f70    order_book: Op
+00012750: 7469 6f6e 616c 5b4f 7264 6572 426f 6f6b  tional[OrderBook
+00012760: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+00012770: 2020 7469 636b 6572 3a20 4f70 7469 6f6e    ticker: Option
+00012780: 616c 5b54 6963 6b65 725d 203d 204e 6f6e  al[Ticker] = Non
+00012790: 652c 0a20 2020 2029 202d 3e20 666c 6f61  e,.    ) -> floa
+000127a0: 743a 0a20 2020 2020 2020 2022 2222 0a20  t:.        """. 
+000127b0: 2020 2020 2020 2043 616c 6375 6c61 7465         Calculate
+000127c0: 7320 6269 642f 6173 6b20 7461 7267 6574  s bid/ask target
+000127d0: 0a20 2020 2020 2020 2062 6964 2072 6174  .        bid rat
+000127e0: 6520 2d20 6265 7477 6565 6e20 6375 7272  e - between curr
+000127f0: 656e 7420 6173 6b20 7072 6963 6520 616e  ent ask price an
+00012800: 6420 6c61 7374 2070 7269 6365 0a20 2020  d last price.   
+00012810: 2020 2020 2061 736b 2072 6174 6520 2d20       ask rate - 
+00012820: 6569 7468 6572 2075 7369 6e67 2074 6963  either using tic
+00012830: 6b65 7220 6269 6420 6f72 2066 6972 7374  ker bid or first
+00012840: 2062 6964 2062 6173 6564 206f 6e20 6f72   bid based on or
+00012850: 6465 7262 6f6f 6b0a 2020 2020 2020 2020  derbook.        
+00012860: 6f72 2072 656d 6169 6e20 7374 6174 6963  or remain static
+00012870: 2069 6e20 616e 7920 6f74 6865 7220 6361   in any other ca
+00012880: 7365 2073 696e 6365 2069 7427 7320 6e6f  se since it's no
+00012890: 7420 7570 6461 7469 6e67 2e0a 2020 2020  t updating..    
+000128a0: 2020 2020 3a70 6172 616d 2070 6169 723a      :param pair:
+000128b0: 2050 6169 7220 746f 2067 6574 2072 6174   Pair to get rat
+000128c0: 6520 666f 720a 2020 2020 2020 2020 3a70  e for.        :p
+000128d0: 6172 616d 2072 6566 7265 7368 3a20 616c  aram refresh: al
+000128e0: 6c6f 7720 6361 6368 6564 2064 6174 610a  low cached data.
+000128f0: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
+00012900: 6964 653a 2022 6275 7922 206f 7220 2273  ide: "buy" or "s
+00012910: 656c 6c22 0a20 2020 2020 2020 203a 7265  ell".        :re
+00012920: 7475 726e 3a20 666c 6f61 743a 2050 7269  turn: float: Pri
+00012930: 6365 0a20 2020 2020 2020 203a 7261 6973  ce.        :rais
+00012940: 6573 2050 7269 6369 6e67 4572 726f 7220  es PricingError 
+00012950: 6966 206f 7264 6572 626f 6f6b 2070 7269  if orderbook pri
+00012960: 6365 2063 6f75 6c64 206e 6f74 2062 6520  ce could not be 
+00012970: 6465 7465 726d 696e 6564 2e0a 2020 2020  determined..    
+00012980: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00012990: 6e61 6d65 203d 2073 6964 652e 6361 7069  name = side.capi
+000129a0: 7461 6c69 7a65 2829 0a20 2020 2020 2020  talize().       
+000129b0: 2073 7472 6174 5f6e 616d 6520 3d20 2265   strat_name = "e
+000129c0: 6e74 7279 5f70 7269 6369 6e67 2220 6966  ntry_pricing" if
+000129d0: 2073 6964 6520 3d3d 2022 656e 7472 7922   side == "entry"
+000129e0: 2065 6c73 6520 2265 7869 745f 7072 6963   else "exit_pric
+000129f0: 696e 6722 0a0a 2020 2020 2020 2020 6361  ing"..        ca
+00012a00: 6368 655f 7261 7465 3a20 5454 4c43 6163  che_rate: TTLCac
+00012a10: 6865 203d 2073 656c 662e 5f65 6e74 7279  he = self._entry
+00012a20: 5f72 6174 655f 6361 6368 6520 6966 2073  _rate_cache if s
+00012a30: 6964 6520 3d3d 2022 656e 7472 7922 2065  ide == "entry" e
+00012a40: 6c73 6520 7365 6c66 2e5f 6578 6974 5f72  lse self._exit_r
+00012a50: 6174 655f 6361 6368 650a 2020 2020 2020  ate_cache.      
+00012a60: 2020 6966 206e 6f74 2072 6566 7265 7368    if not refresh
+00012a70: 3a0a 2020 2020 2020 2020 2020 2020 7769  :.            wi
+00012a80: 7468 2073 656c 662e 5f63 6163 6865 5f6c  th self._cache_l
+00012a90: 6f63 6b3a 0a20 2020 2020 2020 2020 2020  ock:.           
+00012aa0: 2020 2020 2072 6174 6520 3d20 6361 6368       rate = cach
+00012ab0: 655f 7261 7465 2e67 6574 2870 6169 7229  e_rate.get(pair)
+00012ac0: 0a20 2020 2020 2020 2020 2020 2023 2043  .            # C
+00012ad0: 6865 636b 2069 6620 6361 6368 6520 6861  heck if cache ha
+00012ae0: 7320 6265 656e 2069 6e76 616c 6964 6174  s been invalidat
+00012af0: 6564 0a20 2020 2020 2020 2020 2020 2069  ed.            i
+00012b00: 6620 7261 7465 3a0a 2020 2020 2020 2020  f rate:.        
+00012b10: 2020 2020 2020 2020 6c6f 6767 6572 2e64          logger.d
+00012b20: 6562 7567 2866 2255 7369 6e67 2063 6163  ebug(f"Using cac
+00012b30: 6865 6420 7b73 6964 657d 2072 6174 6520  hed {side} rate 
+00012b40: 666f 7220 7b70 6169 727d 2e22 290a 2020  for {pair}.").  
+00012b50: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00012b60: 7475 726e 2072 6174 650a 0a20 2020 2020  turn rate..     
+00012b70: 2020 2063 6f6e 665f 7374 7261 7465 6779     conf_strategy
+00012b80: 203d 2073 656c 662e 5f63 6f6e 6669 672e   = self._config.
+00012b90: 6765 7428 7374 7261 745f 6e61 6d65 2c20  get(strat_name, 
+00012ba0: 7b7d 290a 0a20 2020 2020 2020 2070 7269  {})..        pri
+00012bb0: 6365 5f73 6964 6520 3d20 7365 6c66 2e5f  ce_side = self._
+00012bc0: 6765 745f 7072 6963 655f 7369 6465 2873  get_price_side(s
+00012bd0: 6964 652c 2069 735f 7368 6f72 742c 2063  ide, is_short, c
+00012be0: 6f6e 665f 7374 7261 7465 6779 290a 0a20  onf_strategy).. 
+00012bf0: 2020 2020 2020 2069 6620 636f 6e66 5f73         if conf_s
+00012c00: 7472 6174 6567 792e 6765 7428 2275 7365  trategy.get("use
+00012c10: 5f6f 7264 6572 5f62 6f6f 6b22 2c20 4661  _order_book", Fa
+00012c20: 6c73 6529 3a0a 2020 2020 2020 2020 2020  lse):.          
+00012c30: 2020 6f72 6465 725f 626f 6f6b 5f74 6f70    order_book_top
+00012c40: 203d 2063 6f6e 665f 7374 7261 7465 6779   = conf_strategy
+00012c50: 2e67 6574 2822 6f72 6465 725f 626f 6f6b  .get("order_book
+00012c60: 5f74 6f70 222c 2031 290a 2020 2020 2020  _top", 1).      
+00012c70: 2020 2020 2020 6966 206f 7264 6572 5f62        if order_b
+00012c80: 6f6f 6b20 6973 204e 6f6e 653a 0a20 2020  ook is None:.   
+00012c90: 2020 2020 2020 2020 2020 2020 206f 7264               ord
+00012ca0: 6572 5f62 6f6f 6b20 3d20 7365 6c66 2e66  er_book = self.f
+00012cb0: 6574 6368 5f6c 325f 6f72 6465 725f 626f  etch_l2_order_bo
+00012cc0: 6f6b 2870 6169 722c 206f 7264 6572 5f62  ok(pair, order_b
+00012cd0: 6f6f 6b5f 746f 7029 0a20 2020 2020 2020  ook_top).       
+00012ce0: 2020 2020 2072 6174 6520 3d20 7365 6c66       rate = self
+00012cf0: 2e5f 6765 745f 7261 7465 5f66 726f 6d5f  ._get_rate_from_
+00012d00: 6f62 2870 6169 722c 2073 6964 652c 206f  ob(pair, side, o
+00012d10: 7264 6572 5f62 6f6f 6b2c 206e 616d 652c  rder_book, name,
+00012d20: 2070 7269 6365 5f73 6964 652c 206f 7264   price_side, ord
+00012d30: 6572 5f62 6f6f 6b5f 746f 7029 0a20 2020  er_book_top).   
+00012d40: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00012d50: 2020 2020 2020 206c 6f67 6765 722e 6465         logger.de
+00012d60: 6275 6728 6622 5573 696e 6720 4c61 7374  bug(f"Using Last
+00012d70: 207b 7072 6963 655f 7369 6465 2e63 6170   {price_side.cap
+00012d80: 6974 616c 697a 6528 297d 202f 204c 6173  italize()} / Las
+00012d90: 7420 5072 6963 6522 290a 2020 2020 2020  t Price").      
+00012da0: 2020 2020 2020 6966 2074 6963 6b65 7220        if ticker 
+00012db0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+00012dc0: 2020 2020 2020 2020 2074 6963 6b65 7220           ticker 
+00012dd0: 3d20 7365 6c66 2e66 6574 6368 5f74 6963  = self.fetch_tic
+00012de0: 6b65 7228 7061 6972 290a 2020 2020 2020  ker(pair).      
+00012df0: 2020 2020 2020 7261 7465 203d 2073 656c        rate = sel
+00012e00: 662e 5f67 6574 5f72 6174 655f 6672 6f6d  f._get_rate_from
+00012e10: 5f74 6963 6b65 7228 7369 6465 2c20 7469  _ticker(side, ti
+00012e20: 636b 6572 2c20 636f 6e66 5f73 7472 6174  cker, conf_strat
+00012e30: 6567 792c 2070 7269 6365 5f73 6964 6529  egy, price_side)
+00012e40: 0a0a 2020 2020 2020 2020 6966 2072 6174  ..        if rat
+00012e50: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
+00012e60: 2020 2020 2020 2072 6169 7365 2050 7269         raise Pri
+00012e70: 6369 6e67 4572 726f 7228 6622 7b6e 616d  cingError(f"{nam
+00012e80: 657d 2d52 6174 6520 666f 7220 7b70 6169  e}-Rate for {pai
+00012e90: 727d 2077 6173 2065 6d70 7479 2e22 290a  r} was empty.").
+00012ea0: 2020 2020 2020 2020 7769 7468 2073 656c          with sel
+00012eb0: 662e 5f63 6163 6865 5f6c 6f63 6b3a 0a20  f._cache_lock:. 
+00012ec0: 2020 2020 2020 2020 2020 2063 6163 6865             cache
+00012ed0: 5f72 6174 655b 7061 6972 5d20 3d20 7261  _rate[pair] = ra
+00012ee0: 7465 0a0a 2020 2020 2020 2020 7265 7475  te..        retu
+00012ef0: 726e 2072 6174 650a 0a20 2020 2064 6566  rn rate..    def
+00012f00: 205f 6765 745f 7261 7465 5f66 726f 6d5f   _get_rate_from_
+00012f10: 7469 636b 6572 280a 2020 2020 2020 2020  ticker(.        
+00012f20: 7365 6c66 2c20 7369 6465 3a20 456e 7472  self, side: Entr
+00012f30: 7945 7869 742c 2074 6963 6b65 723a 2054  yExit, ticker: T
+00012f40: 6963 6b65 722c 2063 6f6e 665f 7374 7261  icker, conf_stra
+00012f50: 7465 6779 3a20 4469 6374 5b73 7472 2c20  tegy: Dict[str, 
+00012f60: 416e 795d 2c20 7072 6963 655f 7369 6465  Any], price_side
+00012f70: 3a20 4269 6441 736b 0a20 2020 2029 202d  : BidAsk.    ) -
+00012f80: 3e20 4f70 7469 6f6e 616c 5b66 6c6f 6174  > Optional[float
+00012f90: 5d3a 0a20 2020 2020 2020 2022 2222 0a20  ]:.        """. 
+00012fa0: 2020 2020 2020 2047 6574 2072 6174 6520         Get rate 
+00012fb0: 6672 6f6d 2074 6963 6b65 722e 0a20 2020  from ticker..   
+00012fc0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00012fd0: 2074 6963 6b65 725f 7261 7465 203d 2074   ticker_rate = t
+00012fe0: 6963 6b65 725b 7072 6963 655f 7369 6465  icker[price_side
+00012ff0: 5d0a 2020 2020 2020 2020 6966 2074 6963  ].        if tic
+00013000: 6b65 725b 226c 6173 7422 5d20 616e 6420  ker["last"] and 
+00013010: 7469 636b 6572 5f72 6174 653a 0a20 2020  ticker_rate:.   
+00013020: 2020 2020 2020 2020 2069 6620 7369 6465           if side
+00013030: 203d 3d20 2265 6e74 7279 2220 616e 6420   == "entry" and 
+00013040: 7469 636b 6572 5f72 6174 6520 3e20 7469  ticker_rate > ti
+00013050: 636b 6572 5b22 6c61 7374 225d 3a0a 2020  cker["last"]:.  
+00013060: 2020 2020 2020 2020 2020 2020 2020 6261                ba
+00013070: 6c61 6e63 6520 3d20 636f 6e66 5f73 7472  lance = conf_str
+00013080: 6174 6567 792e 6765 7428 2270 7269 6365  ategy.get("price
+00013090: 5f6c 6173 745f 6261 6c61 6e63 6522 2c20  _last_balance", 
+000130a0: 302e 3029 0a20 2020 2020 2020 2020 2020  0.0).           
+000130b0: 2020 2020 2074 6963 6b65 725f 7261 7465       ticker_rate
+000130c0: 203d 2074 6963 6b65 725f 7261 7465 202b   = ticker_rate +
+000130d0: 2062 616c 616e 6365 202a 2028 7469 636b   balance * (tick
+000130e0: 6572 5b22 6c61 7374 225d 202d 2074 6963  er["last"] - tic
+000130f0: 6b65 725f 7261 7465 290a 2020 2020 2020  ker_rate).      
+00013100: 2020 2020 2020 656c 6966 2073 6964 6520        elif side 
+00013110: 3d3d 2022 6578 6974 2220 616e 6420 7469  == "exit" and ti
+00013120: 636b 6572 5f72 6174 6520 3c20 7469 636b  cker_rate < tick
+00013130: 6572 5b22 6c61 7374 225d 3a0a 2020 2020  er["last"]:.    
+00013140: 2020 2020 2020 2020 2020 2020 6261 6c61              bala
+00013150: 6e63 6520 3d20 636f 6e66 5f73 7472 6174  nce = conf_strat
+00013160: 6567 792e 6765 7428 2270 7269 6365 5f6c  egy.get("price_l
+00013170: 6173 745f 6261 6c61 6e63 6522 2c20 302e  ast_balance", 0.
+00013180: 3029 0a20 2020 2020 2020 2020 2020 2020  0).             
+00013190: 2020 2074 6963 6b65 725f 7261 7465 203d     ticker_rate =
+000131a0: 2074 6963 6b65 725f 7261 7465 202d 2062   ticker_rate - b
+000131b0: 616c 616e 6365 202a 2028 7469 636b 6572  alance * (ticker
+000131c0: 5f72 6174 6520 2d20 7469 636b 6572 5b22  _rate - ticker["
+000131d0: 6c61 7374 225d 290a 2020 2020 2020 2020  last"]).        
+000131e0: 7261 7465 203d 2074 6963 6b65 725f 7261  rate = ticker_ra
+000131f0: 7465 0a20 2020 2020 2020 2072 6574 7572  te.        retur
+00013200: 6e20 7261 7465 0a0a 2020 2020 6465 6620  n rate..    def 
+00013210: 5f67 6574 5f72 6174 655f 6672 6f6d 5f6f  _get_rate_from_o
+00013220: 6228 0a20 2020 2020 2020 2073 656c 662c  b(.        self,
+00013230: 0a20 2020 2020 2020 2070 6169 723a 2073  .        pair: s
+00013240: 7472 2c0a 2020 2020 2020 2020 7369 6465  tr,.        side
+00013250: 3a20 456e 7472 7945 7869 742c 0a20 2020  : EntryExit,.   
+00013260: 2020 2020 206f 7264 6572 5f62 6f6f 6b3a       order_book:
+00013270: 204f 7264 6572 426f 6f6b 2c0a 2020 2020   OrderBook,.    
+00013280: 2020 2020 6e61 6d65 3a20 7374 722c 0a20      name: str,. 
+00013290: 2020 2020 2020 2070 7269 6365 5f73 6964         price_sid
+000132a0: 653a 2042 6964 4173 6b2c 0a20 2020 2020  e: BidAsk,.     
+000132b0: 2020 206f 7264 6572 5f62 6f6f 6b5f 746f     order_book_to
+000132c0: 703a 2069 6e74 2c0a 2020 2020 2920 2d3e  p: int,.    ) ->
+000132d0: 2066 6c6f 6174 3a0a 2020 2020 2020 2020   float:.        
+000132e0: 2222 220a 2020 2020 2020 2020 4765 7420  """.        Get 
+000132f0: 7261 7465 2066 726f 6d20 6f72 6465 7262  rate from orderb
+00013300: 6f6f 6b0a 2020 2020 2020 2020 3a72 6169  ook.        :rai
+00013310: 7365 733a 2050 7269 6369 6e67 4572 726f  ses: PricingErro
+00013320: 7220 6966 2072 6174 6520 636f 756c 6420  r if rate could 
+00013330: 6e6f 7420 6265 2064 6574 6572 6d69 6e65  not be determine
+00013340: 642e 0a20 2020 2020 2020 2022 2222 0a20  d..        """. 
+00013350: 2020 2020 2020 206c 6f67 6765 722e 6465         logger.de
+00013360: 6275 6728 226f 7264 6572 5f62 6f6f 6b20  bug("order_book 
+00013370: 2573 222c 206f 7264 6572 5f62 6f6f 6b29  %s", order_book)
+00013380: 0a20 2020 2020 2020 2023 2074 6f70 2031  .        # top 1
+00013390: 203d 2069 6e64 6578 2030 0a20 2020 2020   = index 0.     
+000133a0: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+000133b0: 2020 2020 6f62 7369 6465 3a20 4f42 4c69      obside: OBLi
+000133c0: 7465 7261 6c20 3d20 2262 6964 7322 2069  teral = "bids" i
+000133d0: 6620 7072 6963 655f 7369 6465 203d 3d20  f price_side == 
+000133e0: 2262 6964 2220 656c 7365 2022 6173 6b73  "bid" else "asks
+000133f0: 220a 2020 2020 2020 2020 2020 2020 7261  ".            ra
+00013400: 7465 203d 206f 7264 6572 5f62 6f6f 6b5b  te = order_book[
+00013410: 6f62 7369 6465 5d5b 6f72 6465 725f 626f  obside][order_bo
+00013420: 6f6b 5f74 6f70 202d 2031 5d5b 305d 0a20  ok_top - 1][0]. 
+00013430: 2020 2020 2020 2065 7863 6570 7420 2849         except (I
+00013440: 6e64 6578 4572 726f 722c 204b 6579 4572  ndexError, KeyEr
+00013450: 726f 7229 2061 7320 653a 0a20 2020 2020  ror) as e:.     
+00013460: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
+00013470: 726e 696e 6728 0a20 2020 2020 2020 2020  rning(.         
+00013480: 2020 2020 2020 2066 227b 7061 6972 7d20         f"{pair} 
+00013490: 2d20 7b6e 616d 657d 2050 7269 6365 2061  - {name} Price a
+000134a0: 7420 6c6f 6361 7469 6f6e 207b 6f72 6465  t location {orde
+000134b0: 725f 626f 6f6b 5f74 6f70 7d20 6672 6f6d  r_book_top} from
+000134c0: 206f 7264 6572 626f 6f6b 2022 0a20 2020   orderbook ".   
+000134d0: 2020 2020 2020 2020 2020 2020 2066 2263               f"c
+000134e0: 6f75 6c64 206e 6f74 2062 6520 6465 7465  ould not be dete
+000134f0: 726d 696e 6564 2e20 4f72 6465 7262 6f6f  rmined. Orderboo
+00013500: 6b3a 207b 6f72 6465 725f 626f 6f6b 7d22  k: {order_book}"
+00013510: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
+00013520: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00013530: 2050 7269 6369 6e67 4572 726f 7220 6672   PricingError fr
+00013540: 6f6d 2065 0a20 2020 2020 2020 206c 6f67  om e.        log
+00013550: 6765 722e 6465 6275 6728 0a20 2020 2020  ger.debug(.     
+00013560: 2020 2020 2020 2066 227b 7061 6972 7d20         f"{pair} 
+00013570: 2d20 7b6e 616d 657d 2070 7269 6365 2066  - {name} price f
+00013580: 726f 6d20 6f72 6465 7262 6f6f 6b20 7b70  rom orderbook {p
+00013590: 7269 6365 5f73 6964 652e 6361 7069 7461  rice_side.capita
+000135a0: 6c69 7a65 2829 7d22 0a20 2020 2020 2020  lize()}".       
+000135b0: 2020 2020 2066 2273 6964 6520 2d20 746f       f"side - to
+000135c0: 7020 7b6f 7264 6572 5f62 6f6f 6b5f 746f  p {order_book_to
+000135d0: 707d 206f 7264 6572 2062 6f6f 6b20 7b73  p} order book {s
+000135e0: 6964 657d 2072 6174 6520 7b72 6174 653a  ide} rate {rate:
+000135f0: 2e38 667d 220a 2020 2020 2020 2020 290a  .8f}".        ).
+00013600: 2020 2020 2020 2020 7265 7475 726e 2072          return r
+00013610: 6174 650a 0a20 2020 2064 6566 2067 6574  ate..    def get
+00013620: 5f72 6174 6573 2873 656c 662c 2070 6169  _rates(self, pai
+00013630: 723a 2073 7472 2c20 7265 6672 6573 683a  r: str, refresh:
+00013640: 2062 6f6f 6c2c 2069 735f 7368 6f72 743a   bool, is_short:
+00013650: 2062 6f6f 6c29 202d 3e20 5475 706c 655b   bool) -> Tuple[
+00013660: 666c 6f61 742c 2066 6c6f 6174 5d3a 0a20  float, float]:. 
+00013670: 2020 2020 2020 2065 6e74 7279 5f72 6174         entry_rat
+00013680: 6520 3d20 4e6f 6e65 0a20 2020 2020 2020  e = None.       
+00013690: 2065 7869 745f 7261 7465 203d 204e 6f6e   exit_rate = Non
+000136a0: 650a 2020 2020 2020 2020 6966 206e 6f74  e.        if not
+000136b0: 2072 6566 7265 7368 3a0a 2020 2020 2020   refresh:.      
+000136c0: 2020 2020 2020 7769 7468 2073 656c 662e        with self.
+000136d0: 5f63 6163 6865 5f6c 6f63 6b3a 0a20 2020  _cache_lock:.   
+000136e0: 2020 2020 2020 2020 2020 2020 2065 6e74               ent
+000136f0: 7279 5f72 6174 6520 3d20 7365 6c66 2e5f  ry_rate = self._
+00013700: 656e 7472 795f 7261 7465 5f63 6163 6865  entry_rate_cache
+00013710: 2e67 6574 2870 6169 7229 0a20 2020 2020  .get(pair).     
+00013720: 2020 2020 2020 2020 2020 2065 7869 745f             exit_
+00013730: 7261 7465 203d 2073 656c 662e 5f65 7869  rate = self._exi
+00013740: 745f 7261 7465 5f63 6163 6865 2e67 6574  t_rate_cache.get
+00013750: 2870 6169 7229 0a20 2020 2020 2020 2020  (pair).         
+00013760: 2020 2069 6620 656e 7472 795f 7261 7465     if entry_rate
+00013770: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00013780: 2020 6c6f 6767 6572 2e64 6562 7567 2866    logger.debug(f
+00013790: 2255 7369 6e67 2063 6163 6865 6420 6275  "Using cached bu
+000137a0: 7920 7261 7465 2066 6f72 207b 7061 6972  y rate for {pair
+000137b0: 7d2e 2229 0a20 2020 2020 2020 2020 2020  }.").           
+000137c0: 2069 6620 6578 6974 5f72 6174 653a 0a20   if exit_rate:. 
+000137d0: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+000137e0: 6f67 6765 722e 6465 6275 6728 6622 5573  ogger.debug(f"Us
+000137f0: 696e 6720 6361 6368 6564 2073 656c 6c20  ing cached sell 
+00013800: 7261 7465 2066 6f72 207b 7061 6972 7d2e  rate for {pair}.
+00013810: 2229 0a0a 2020 2020 2020 2020 656e 7472  ")..        entr
+00013820: 795f 7072 6963 696e 6720 3d20 7365 6c66  y_pricing = self
+00013830: 2e5f 636f 6e66 6967 2e67 6574 2822 656e  ._config.get("en
+00013840: 7472 795f 7072 6963 696e 6722 2c20 7b7d  try_pricing", {}
+00013850: 290a 2020 2020 2020 2020 6578 6974 5f70  ).        exit_p
+00013860: 7269 6369 6e67 203d 2073 656c 662e 5f63  ricing = self._c
+00013870: 6f6e 6669 672e 6765 7428 2265 7869 745f  onfig.get("exit_
+00013880: 7072 6963 696e 6722 2c20 7b7d 290a 2020  pricing", {}).  
+00013890: 2020 2020 2020 6f72 6465 725f 626f 6f6b        order_book
+000138a0: 203d 2074 6963 6b65 7220 3d20 4e6f 6e65   = ticker = None
+000138b0: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+000138c0: 656e 7472 795f 7261 7465 2061 6e64 2065  entry_rate and e
+000138d0: 6e74 7279 5f70 7269 6369 6e67 2e67 6574  ntry_pricing.get
+000138e0: 2822 7573 655f 6f72 6465 725f 626f 6f6b  ("use_order_book
+000138f0: 222c 2046 616c 7365 293a 0a20 2020 2020  ", False):.     
+00013900: 2020 2020 2020 206f 7264 6572 5f62 6f6f         order_boo
+00013910: 6b5f 746f 7020 3d20 6d61 7828 0a20 2020  k_top = max(.   
+00013920: 2020 2020 2020 2020 2020 2020 2065 6e74               ent
+00013930: 7279 5f70 7269 6369 6e67 2e67 6574 2822  ry_pricing.get("
+00013940: 6f72 6465 725f 626f 6f6b 5f74 6f70 222c  order_book_top",
+00013950: 2031 292c 2065 7869 745f 7072 6963 696e   1), exit_pricin
+00013960: 672e 6765 7428 226f 7264 6572 5f62 6f6f  g.get("order_boo
+00013970: 6b5f 746f 7022 2c20 3129 0a20 2020 2020  k_top", 1).     
+00013980: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00013990: 2020 2020 206f 7264 6572 5f62 6f6f 6b20       order_book 
+000139a0: 3d20 7365 6c66 2e66 6574 6368 5f6c 325f  = self.fetch_l2_
+000139b0: 6f72 6465 725f 626f 6f6b 2870 6169 722c  order_book(pair,
+000139c0: 206f 7264 6572 5f62 6f6f 6b5f 746f 7029   order_book_top)
+000139d0: 0a20 2020 2020 2020 2020 2020 2065 6e74  .            ent
+000139e0: 7279 5f72 6174 6520 3d20 7365 6c66 2e67  ry_rate = self.g
+000139f0: 6574 5f72 6174 6528 7061 6972 2c20 7265  et_rate(pair, re
+00013a00: 6672 6573 682c 2022 656e 7472 7922 2c20  fresh, "entry", 
+00013a10: 6973 5f73 686f 7274 2c20 6f72 6465 725f  is_short, order_
+00013a20: 626f 6f6b 3d6f 7264 6572 5f62 6f6f 6b29  book=order_book)
+00013a30: 0a20 2020 2020 2020 2065 6c69 6620 6e6f  .        elif no
+00013a40: 7420 656e 7472 795f 7261 7465 3a0a 2020  t entry_rate:.  
+00013a50: 2020 2020 2020 2020 2020 7469 636b 6572            ticker
+00013a60: 203d 2073 656c 662e 6665 7463 685f 7469   = self.fetch_ti
+00013a70: 636b 6572 2870 6169 7229 0a20 2020 2020  cker(pair).     
+00013a80: 2020 2020 2020 2065 6e74 7279 5f72 6174         entry_rat
+00013a90: 6520 3d20 7365 6c66 2e67 6574 5f72 6174  e = self.get_rat
+00013aa0: 6528 7061 6972 2c20 7265 6672 6573 682c  e(pair, refresh,
+00013ab0: 2022 656e 7472 7922 2c20 6973 5f73 686f   "entry", is_sho
+00013ac0: 7274 2c20 7469 636b 6572 3d74 6963 6b65  rt, ticker=ticke
+00013ad0: 7229 0a20 2020 2020 2020 2069 6620 6e6f  r).        if no
+00013ae0: 7420 6578 6974 5f72 6174 653a 0a20 2020  t exit_rate:.   
+00013af0: 2020 2020 2020 2020 2065 7869 745f 7261           exit_ra
+00013b00: 7465 203d 2073 656c 662e 6765 745f 7261  te = self.get_ra
+00013b10: 7465 280a 2020 2020 2020 2020 2020 2020  te(.            
+00013b20: 2020 2020 7061 6972 2c20 7265 6672 6573      pair, refres
+00013b30: 682c 2022 6578 6974 222c 2069 735f 7368  h, "exit", is_sh
+00013b40: 6f72 742c 206f 7264 6572 5f62 6f6f 6b3d  ort, order_book=
+00013b50: 6f72 6465 725f 626f 6f6b 2c20 7469 636b  order_book, tick
+00013b60: 6572 3d74 6963 6b65 720a 2020 2020 2020  er=ticker.      
+00013b70: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00013b80: 7265 7475 726e 2065 6e74 7279 5f72 6174  return entry_rat
+00013b90: 652c 2065 7869 745f 7261 7465 0a0a 2020  e, exit_rate..  
+00013ba0: 2020 2320 4665 6520 6861 6e64 6c69 6e67    # Fee handling
+00013bb0: 0a0a 2020 2020 4072 6574 7269 6572 0a20  ..    @retrier. 
+00013bc0: 2020 2064 6566 2067 6574 5f74 7261 6465     def get_trade
+00013bd0: 735f 666f 725f 6f72 6465 7228 0a20 2020  s_for_order(.   
+00013be0: 2020 2020 2073 656c 662c 206f 7264 6572       self, order
+00013bf0: 5f69 643a 2073 7472 2c20 7061 6972 3a20  _id: str, pair: 
+00013c00: 7374 722c 2073 696e 6365 3a20 6461 7465  str, since: date
+00013c10: 7469 6d65 2c20 7061 7261 6d73 3a20 4f70  time, params: Op
+00013c20: 7469 6f6e 616c 5b44 6963 745d 203d 204e  tional[Dict] = N
+00013c30: 6f6e 650a 2020 2020 2920 2d3e 204c 6973  one.    ) -> Lis
+00013c40: 743a 0a20 2020 2020 2020 2022 2222 0a20  t:.        """. 
+00013c50: 2020 2020 2020 2046 6574 6368 204f 7264         Fetch Ord
+00013c60: 6572 7320 7573 696e 6720 7468 6520 2266  ers using the "f
+00013c70: 6574 6368 5f6d 795f 7472 6164 6573 2220  etch_my_trades" 
+00013c80: 656e 6470 6f69 6e74 2061 6e64 2066 696c  endpoint and fil
+00013c90: 7465 7220 7468 656d 2062 7920 6f72 6465  ter them by orde
+00013ca0: 722d 6964 2e0a 2020 2020 2020 2020 5468  r-id..        Th
+00013cb0: 6520 2273 696e 6365 2220 6172 6775 6d65  e "since" argume
+00013cc0: 6e74 2070 6173 7365 6420 696e 2069 7320  nt passed in is 
+00013cd0: 636f 6d69 6e67 2066 726f 6d20 7468 6520  coming from the 
+00013ce0: 6461 7461 6261 7365 2061 6e64 2069 7320  database and is 
+00013cf0: 696e 2055 5443 2c0a 2020 2020 2020 2020  in UTC,.        
+00013d00: 6173 2074 696d 657a 6f6e 652d 6e61 7469  as timezone-nati
+00013d10: 7665 2064 6174 6574 696d 6520 6f62 6a65  ve datetime obje
+00013d20: 6374 2e0a 2020 2020 2020 2020 4672 6f6d  ct..        From
+00013d30: 2074 6865 2070 7974 686f 6e20 646f 6375   the python docu
+00013d40: 6d65 6e74 6174 696f 6e3a 0a20 2020 2020  mentation:.     
+00013d50: 2020 2020 2020 203e 204e 6169 7665 2064         > Naive d
+00013d60: 6174 6574 696d 6520 696e 7374 616e 6365  atetime instance
+00013d70: 7320 6172 6520 6173 7375 6d65 6420 746f  s are assumed to
+00013d80: 2072 6570 7265 7365 6e74 206c 6f63 616c   represent local
+00013d90: 2074 696d 650a 2020 2020 2020 2020 5468   time.        Th
+00013da0: 6572 6566 6f72 652c 2063 616c 6c69 6e67  erefore, calling
+00013db0: 2022 7369 6e63 652e 7469 6d65 7374 616d   "since.timestam
+00013dc0: 7028 2922 2077 696c 6c20 6765 7420 7468  p()" will get th
+00013dd0: 6520 5554 4320 7469 6d65 7374 616d 702c  e UTC timestamp,
+00013de0: 2061 6674 6572 2061 7070 6c79 696e 6720   after applying 
+00013df0: 7468 650a 2020 2020 2020 2020 7472 616e  the.        tran
+00013e00: 7366 6f72 6d61 7469 6f6e 2066 726f 6d20  sformation from 
+00013e10: 6c6f 6361 6c20 7469 6d65 7a6f 6e65 2074  local timezone t
+00013e20: 6f20 5554 432e 0a20 2020 2020 2020 2054  o UTC..        T
+00013e30: 6869 7320 776f 726b 7320 666f 7220 7469  his works for ti
+00013e40: 6d65 7a6f 6e65 7320 5554 432b 2073 696e  mezones UTC+ sin
+00013e50: 6365 2074 6865 6e20 7468 6520 7265 7375  ce then the resu
+00013e60: 6c74 2077 696c 6c20 636f 6e74 6169 6e20  lt will contain 
+00013e70: 7472 6164 6573 2066 726f 6d20 6120 6665  trades from a fe
+00013e80: 7720 686f 7572 730a 2020 2020 2020 2020  w hours.        
+00013e90: 696e 7374 6561 6420 6f66 2066 726f 6d20  instead of from 
+00013ea0: 7468 6520 6c61 7374 2035 2073 6563 6f6e  the last 5 secon
+00013eb0: 6473 2c20 686f 7765 7665 7220 6661 696c  ds, however fail
+00013ec0: 7320 666f 7220 5554 432d 2074 696d 657a  s for UTC- timez
+00013ed0: 6f6e 6573 2c0a 2020 2020 2020 2020 7369  ones,.        si
+00013ee0: 6e63 6520 7765 2772 6520 7468 656e 2061  nce we're then a
+00013ef0: 736b 696e 6720 666f 7220 7472 6164 6573  sking for trades
+00013f00: 2077 6974 6820 6120 2273 696e 6365 2220   with a "since" 
+00013f10: 6172 6775 6d65 6e74 2069 6e20 7468 6520  argument in the 
+00013f20: 6675 7475 7265 2e0a 0a20 2020 2020 2020  future...       
+00013f30: 203a 7061 7261 6d20 6f72 6465 725f 6964   :param order_id
+00013f40: 206f 7264 6572 5f69 643a 204f 7264 6572   order_id: Order
+00013f50: 2d69 6420 6173 2067 6976 656e 2077 6865  -id as given whe
+00013f60: 6e20 6372 6561 7469 6e67 2074 6865 206f  n creating the o
+00013f70: 7264 6572 0a20 2020 2020 2020 203a 7061  rder.        :pa
+00013f80: 7261 6d20 7061 6972 3a20 5061 6972 2074  ram pair: Pair t
+00013f90: 6865 206f 7264 6572 2069 7320 666f 720a  he order is for.
+00013fa0: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
+00013fb0: 696e 6365 3a20 6461 7465 7469 6d65 206f  ince: datetime o
+00013fc0: 626a 6563 7420 6f66 2074 6865 206f 7264  bject of the ord
+00013fd0: 6572 2063 7265 6174 696f 6e20 7469 6d65  er creation time
+00013fe0: 2e20 4173 7375 6d65 7320 6f62 6a65 6374  . Assumes object
+00013ff0: 2069 7320 696e 2055 5443 2e0a 2020 2020   is in UTC..    
+00014000: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00014010: 6966 2073 656c 662e 5f63 6f6e 6669 675b  if self._config[
+00014020: 2264 7279 5f72 756e 225d 3a0a 2020 2020  "dry_run"]:.    
+00014030: 2020 2020 2020 2020 7265 7475 726e 205b          return [
+00014040: 5d0a 2020 2020 2020 2020 6966 206e 6f74  ].        if not
+00014050: 2073 656c 662e 6578 6368 616e 6765 5f68   self.exchange_h
+00014060: 6173 2822 6665 7463 684d 7954 7261 6465  as("fetchMyTrade
+00014070: 7322 293a 0a20 2020 2020 2020 2020 2020  s"):.           
+00014080: 2072 6574 7572 6e20 5b5d 0a20 2020 2020   return [].     
+00014090: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+000140a0: 2020 2020 2320 416c 6c6f 7720 3573 206f      # Allow 5s o
+000140b0: 6666 7365 7420 746f 2063 6174 6368 2073  ffset to catch s
+000140c0: 6c69 6768 7420 7469 6d65 206f 6666 7365  light time offse
+000140d0: 7473 2028 6469 7363 6f76 6572 6564 2069  ts (discovered i
+000140e0: 6e20 2331 3138 3529 0a20 2020 2020 2020  n #1185).       
+000140f0: 2020 2020 2023 2073 696e 6365 206e 6565       # since nee
+00014100: 6473 2074 6f20 6265 2069 6e74 2069 6e20  ds to be int in 
+00014110: 6d69 6c6c 6973 6563 6f6e 6473 0a20 2020  milliseconds.   
+00014120: 2020 2020 2020 2020 205f 7061 7261 6d73           _params
+00014130: 203d 2070 6172 616d 7320 6966 2070 6172   = params if par
+00014140: 616d 7320 656c 7365 207b 7d0a 2020 2020  ams else {}.    
+00014150: 2020 2020 2020 2020 6d79 5f74 7261 6465          my_trade
+00014160: 7320 3d20 7365 6c66 2e5f 6170 692e 6665  s = self._api.fe
+00014170: 7463 685f 6d79 5f74 7261 6465 7328 0a20  tch_my_trades(. 
+00014180: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00014190: 6169 722c 0a20 2020 2020 2020 2020 2020  air,.           
+000141a0: 2020 2020 2069 6e74 2828 7369 6e63 652e       int((since.
+000141b0: 7265 706c 6163 6528 747a 696e 666f 3d74  replace(tzinfo=t
+000141c0: 696d 657a 6f6e 652e 7574 6329 2e74 696d  imezone.utc).tim
+000141d0: 6573 7461 6d70 2829 202d 2035 2920 2a20  estamp() - 5) * 
+000141e0: 3130 3030 292c 0a20 2020 2020 2020 2020  1000),.         
+000141f0: 2020 2020 2020 2070 6172 616d 733d 5f70         params=_p
+00014200: 6172 616d 732c 0a20 2020 2020 2020 2020  arams,.         
+00014210: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00014220: 206d 6174 6368 6564 5f74 7261 6465 7320   matched_trades 
+00014230: 3d20 5b74 7261 6465 2066 6f72 2074 7261  = [trade for tra
+00014240: 6465 2069 6e20 6d79 5f74 7261 6465 7320  de in my_trades 
+00014250: 6966 2074 7261 6465 5b22 6f72 6465 7222  if trade["order"
+00014260: 5d20 3d3d 206f 7264 6572 5f69 645d 0a0a  ] == order_id]..
+00014270: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00014280: 2e5f 6c6f 675f 6578 6368 616e 6765 5f72  ._log_exchange_r
+00014290: 6573 706f 6e73 6528 2267 6574 5f74 7261  esponse("get_tra
+000142a0: 6465 735f 666f 725f 6f72 6465 7222 2c20  des_for_order", 
+000142b0: 6d61 7463 6865 645f 7472 6164 6573 290a  matched_trades).
+000142c0: 0a20 2020 2020 2020 2020 2020 206d 6174  .            mat
+000142d0: 6368 6564 5f74 7261 6465 7320 3d20 7365  ched_trades = se
+000142e0: 6c66 2e5f 7472 6164 6573 5f63 6f6e 7472  lf._trades_contr
+000142f0: 6163 7473 5f74 6f5f 616d 6f75 6e74 286d  acts_to_amount(m
+00014300: 6174 6368 6564 5f74 7261 6465 7329 0a0a  atched_trades)..
+00014310: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00014320: 726e 206d 6174 6368 6564 5f74 7261 6465  rn matched_trade
+00014330: 730a 2020 2020 2020 2020 6578 6365 7074  s.        except
+00014340: 2063 6378 742e 4444 6f53 5072 6f74 6563   ccxt.DDoSProtec
+00014350: 7469 6f6e 2061 7320 653a 0a20 2020 2020  tion as e:.     
+00014360: 2020 2020 2020 2072 6169 7365 2044 446f         raise DDo
+00014370: 7350 726f 7465 6374 696f 6e28 6529 2066  sProtection(e) f
+00014380: 726f 6d20 650a 2020 2020 2020 2020 6578  rom e.        ex
+00014390: 6365 7074 2028 6363 7874 2e4f 7065 7261  cept (ccxt.Opera
+000143a0: 7469 6f6e 4661 696c 6564 2c20 6363 7874  tionFailed, ccxt
+000143b0: 2e45 7863 6861 6e67 6545 7272 6f72 2920  .ExchangeError) 
+000143c0: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
+000143d0: 2020 7261 6973 6520 5465 6d70 6f72 6172    raise Temporar
+000143e0: 7945 7272 6f72 280a 2020 2020 2020 2020  yError(.        
+000143f0: 2020 2020 2020 2020 6622 436f 756c 6420          f"Could 
+00014400: 6e6f 7420 6765 7420 7472 6164 6573 2064  not get trades d
+00014410: 7565 2074 6f20 7b65 2e5f 5f63 6c61 7373  ue to {e.__class
+00014420: 5f5f 2e5f 5f6e 616d 655f 5f7d 2e20 4d65  __.__name__}. Me
+00014430: 7373 6167 653a 207b 657d 220a 2020 2020  ssage: {e}".    
+00014440: 2020 2020 2020 2020 2920 6672 6f6d 2065          ) from e
+00014450: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
+00014460: 6363 7874 2e42 6173 6545 7272 6f72 2061  ccxt.BaseError a
+00014470: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
+00014480: 2072 6169 7365 204f 7065 7261 7469 6f6e   raise Operation
+00014490: 616c 4578 6365 7074 696f 6e28 6529 2066  alException(e) f
+000144a0: 726f 6d20 650a 0a20 2020 2064 6566 2067  rom e..    def g
+000144b0: 6574 5f6f 7264 6572 5f69 645f 636f 6e64  et_order_id_cond
+000144c0: 6974 696f 6e61 6c28 7365 6c66 2c20 6f72  itional(self, or
+000144d0: 6465 723a 2044 6963 745b 7374 722c 2041  der: Dict[str, A
+000144e0: 6e79 5d29 202d 3e20 7374 723a 0a20 2020  ny]) -> str:.   
+000144f0: 2020 2020 2072 6574 7572 6e20 6f72 6465       return orde
+00014500: 725b 2269 6422 5d0a 0a20 2020 2040 7265  r["id"]..    @re
+00014510: 7472 6965 720a 2020 2020 6465 6620 6765  trier.    def ge
+00014520: 745f 6665 6528 0a20 2020 2020 2020 2073  t_fee(.        s
+00014530: 656c 662c 0a20 2020 2020 2020 2073 796d  elf,.        sym
+00014540: 626f 6c3a 2073 7472 2c0a 2020 2020 2020  bol: str,.      
+00014550: 2020 7479 7065 3a20 7374 7220 3d20 2222    type: str = ""
+00014560: 2c0a 2020 2020 2020 2020 7369 6465 3a20  ,.        side: 
+00014570: 7374 7220 3d20 2222 2c0a 2020 2020 2020  str = "",.      
+00014580: 2020 616d 6f75 6e74 3a20 666c 6f61 7420    amount: float 
+00014590: 3d20 312c 0a20 2020 2020 2020 2070 7269  = 1,.        pri
+000145a0: 6365 3a20 666c 6f61 7420 3d20 312c 0a20  ce: float = 1,. 
+000145b0: 2020 2020 2020 2074 616b 6572 5f6f 725f         taker_or_
+000145c0: 6d61 6b65 723a 204d 616b 6572 5461 6b65  maker: MakerTake
+000145d0: 7220 3d20 226d 616b 6572 222c 0a20 2020  r = "maker",.   
+000145e0: 2029 202d 3e20 666c 6f61 743a 0a20 2020   ) -> float:.   
+000145f0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00014600: 2052 6574 7269 6576 6520 6665 6520 6672   Retrieve fee fr
+00014610: 6f6d 2065 7863 6861 6e67 650a 2020 2020  om exchange.    
+00014620: 2020 2020 3a70 6172 616d 2073 796d 626f      :param symbo
+00014630: 6c3a 2050 6169 720a 2020 2020 2020 2020  l: Pair.        
+00014640: 3a70 6172 616d 2074 7970 653a 2054 7970  :param type: Typ
+00014650: 6520 6f66 206f 7264 6572 2028 6d61 726b  e of order (mark
+00014660: 6574 2c20 6c69 6d69 742c 202e 2e2e 290a  et, limit, ...).
+00014670: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
+00014680: 6964 653a 2053 6964 6520 6f66 206f 7264  ide: Side of ord
+00014690: 6572 2028 6275 792c 2073 656c 6c29 0a20  er (buy, sell). 
+000146a0: 2020 2020 2020 203a 7061 7261 6d20 616d         :param am
+000146b0: 6f75 6e74 3a20 416d 6f75 6e74 206f 6620  ount: Amount of 
+000146c0: 6f72 6465 720a 2020 2020 2020 2020 3a70  order.        :p
+000146d0: 6172 616d 2070 7269 6365 3a20 5072 6963  aram price: Pric
+000146e0: 6520 6f66 206f 7264 6572 0a20 2020 2020  e of order.     
+000146f0: 2020 203a 7061 7261 6d20 7461 6b65 725f     :param taker_
+00014700: 6f72 5f6d 616b 6572 3a20 276d 616b 6572  or_maker: 'maker
+00014710: 2720 6f72 2027 7461 6b65 7227 2028 6967  ' or 'taker' (ig
+00014720: 6e6f 7265 6420 6966 2022 7479 7065 2220  nored if "type" 
+00014730: 6973 2070 726f 7669 6465 6429 0a20 2020  is provided).   
+00014740: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00014750: 2069 6620 7479 7065 2061 6e64 2074 7970   if type and typ
+00014760: 6520 3d3d 2022 6d61 726b 6574 223a 0a20  e == "market":. 
+00014770: 2020 2020 2020 2020 2020 2074 616b 6572             taker
+00014780: 5f6f 725f 6d61 6b65 7220 3d20 2274 616b  _or_maker = "tak
+00014790: 6572 220a 2020 2020 2020 2020 7472 793a  er".        try:
+000147a0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+000147b0: 7365 6c66 2e5f 636f 6e66 6967 5b22 6472  self._config["dr
+000147c0: 795f 7275 6e22 5d20 616e 6420 7365 6c66  y_run"] and self
+000147d0: 2e5f 636f 6e66 6967 2e67 6574 2822 6665  ._config.get("fe
+000147e0: 6522 2c20 4e6f 6e65 2920 6973 206e 6f74  e", None) is not
+000147f0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00014800: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+00014810: 6c66 2e5f 636f 6e66 6967 5b22 6665 6522  lf._config["fee"
+00014820: 5d0a 2020 2020 2020 2020 2020 2020 2320  ].            # 
+00014830: 7661 6c69 6461 7465 2074 6861 7420 6d61  validate that ma
+00014840: 726b 6574 7320 6172 6520 6c6f 6164 6564  rkets are loaded
+00014850: 2062 6566 6f72 6520 7472 7969 6e67 2074   before trying t
+00014860: 6f20 6765 7420 6665 650a 2020 2020 2020  o get fee.      
+00014870: 2020 2020 2020 6966 2073 656c 662e 5f61        if self._a
+00014880: 7069 2e6d 6172 6b65 7473 2069 7320 4e6f  pi.markets is No
+00014890: 6e65 206f 7220 6c65 6e28 7365 6c66 2e5f  ne or len(self._
+000148a0: 6170 692e 6d61 726b 6574 7329 203d 3d20  api.markets) == 
+000148b0: 303a 0a20 2020 2020 2020 2020 2020 2020  0:.             
+000148c0: 2020 2073 656c 662e 5f61 7069 2e6c 6f61     self._api.loa
+000148d0: 645f 6d61 726b 6574 7328 7061 7261 6d73  d_markets(params
+000148e0: 3d7b 7d29 0a0a 2020 2020 2020 2020 2020  ={})..          
+000148f0: 2020 7265 7475 726e 2073 656c 662e 5f61    return self._a
+00014900: 7069 2e63 616c 6375 6c61 7465 5f66 6565  pi.calculate_fee
+00014910: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00014920: 2020 7379 6d62 6f6c 3d73 796d 626f 6c2c    symbol=symbol,
+00014930: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014940: 2074 7970 653d 7479 7065 2c0a 2020 2020   type=type,.    
+00014950: 2020 2020 2020 2020 2020 2020 7369 6465              side
+00014960: 3d73 6964 652c 0a20 2020 2020 2020 2020  =side,.         
+00014970: 2020 2020 2020 2061 6d6f 756e 743d 616d         amount=am
+00014980: 6f75 6e74 2c0a 2020 2020 2020 2020 2020  ount,.          
+00014990: 2020 2020 2020 7072 6963 653d 7072 6963        price=pric
+000149a0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+000149b0: 2020 2074 616b 6572 4f72 4d61 6b65 723d     takerOrMaker=
+000149c0: 7461 6b65 725f 6f72 5f6d 616b 6572 2c0a  taker_or_maker,.
+000149d0: 2020 2020 2020 2020 2020 2020 295b 2272              )["r
+000149e0: 6174 6522 5d0a 2020 2020 2020 2020 6578  ate"].        ex
+000149f0: 6365 7074 2063 6378 742e 4444 6f53 5072  cept ccxt.DDoSPr
+00014a00: 6f74 6563 7469 6f6e 2061 7320 653a 0a20  otection as e:. 
+00014a10: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00014a20: 2044 446f 7350 726f 7465 6374 696f 6e28   DDosProtection(
+00014a30: 6529 2066 726f 6d20 650a 2020 2020 2020  e) from e.      
+00014a40: 2020 6578 6365 7074 2028 6363 7874 2e4f    except (ccxt.O
+00014a50: 7065 7261 7469 6f6e 4661 696c 6564 2c20  perationFailed, 
+00014a60: 6363 7874 2e45 7863 6861 6e67 6545 7272  ccxt.ExchangeErr
+00014a70: 6f72 2920 6173 2065 3a0a 2020 2020 2020  or) as e:.      
+00014a80: 2020 2020 2020 7261 6973 6520 5465 6d70        raise Temp
+00014a90: 6f72 6172 7945 7272 6f72 280a 2020 2020  oraryError(.    
+00014aa0: 2020 2020 2020 2020 2020 2020 6622 436f              f"Co
+00014ab0: 756c 6420 6e6f 7420 6765 7420 6665 6520  uld not get fee 
+00014ac0: 696e 666f 2064 7565 2074 6f20 7b65 2e5f  info due to {e._
+00014ad0: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
+00014ae0: 5f7d 2e20 4d65 7373 6167 653a 207b 657d  _}. Message: {e}
+00014af0: 220a 2020 2020 2020 2020 2020 2020 2920  ".            ) 
+00014b00: 6672 6f6d 2065 0a20 2020 2020 2020 2065  from e.        e
+00014b10: 7863 6570 7420 6363 7874 2e42 6173 6545  xcept ccxt.BaseE
+00014b20: 7272 6f72 2061 7320 653a 0a20 2020 2020  rror as e:.     
+00014b30: 2020 2020 2020 2072 6169 7365 204f 7065         raise Ope
+00014b40: 7261 7469 6f6e 616c 4578 6365 7074 696f  rationalExceptio
+00014b50: 6e28 6529 2066 726f 6d20 650a 0a20 2020  n(e) from e..   
+00014b60: 2040 7374 6174 6963 6d65 7468 6f64 0a20   @staticmethod. 
+00014b70: 2020 2064 6566 206f 7264 6572 5f68 6173     def order_has
+00014b80: 5f66 6565 286f 7264 6572 3a20 4469 6374  _fee(order: Dict
+00014b90: 2920 2d3e 2062 6f6f 6c3a 0a20 2020 2020  ) -> bool:.     
+00014ba0: 2020 2022 2222 0a20 2020 2020 2020 2056     """.        V
+00014bb0: 6572 6966 6965 7320 6966 2074 6865 2070  erifies if the p
+00014bc0: 6173 7365 6420 696e 206f 7264 6572 2064  assed in order d
+00014bd0: 6963 7420 6861 7320 7468 6520 6e65 6564  ict has the need
+00014be0: 6564 206b 6579 7320 746f 2065 7874 7261  ed keys to extra
+00014bf0: 6374 2066 6565 732c 0a20 2020 2020 2020  ct fees,.       
+00014c00: 2061 6e64 2074 6861 7420 7468 6573 6520   and that these 
+00014c10: 6b65 7973 2028 6375 7272 656e 6379 2c20  keys (currency, 
+00014c20: 636f 7374 2920 6172 6520 6e6f 7420 656d  cost) are not em
+00014c30: 7074 792e 0a20 2020 2020 2020 203a 7061  pty..        :pa
+00014c40: 7261 6d20 6f72 6465 723a 204f 7264 6572  ram order: Order
+00014c50: 206f 7220 7472 6164 6520 286f 6e65 2074   or trade (one t
+00014c60: 7261 6465 2920 6469 6374 0a20 2020 2020  rade) dict.     
+00014c70: 2020 203a 7265 7475 726e 3a20 5472 7565     :return: True
+00014c80: 2069 6620 7468 6520 6665 6520 7375 6273   if the fee subs
+00014c90: 7472 7563 7475 7265 2063 6f6e 7461 696e  tructure contain
+00014ca0: 7320 6375 7272 656e 6379 2061 6e64 2063  s currency and c
+00014cb0: 6f73 742c 2066 616c 7365 206f 7468 6572  ost, false other
+00014cc0: 7769 7365 0a20 2020 2020 2020 2022 2222  wise.        """
+00014cd0: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+00014ce0: 6973 696e 7374 616e 6365 286f 7264 6572  isinstance(order
+00014cf0: 2c20 6469 6374 293a 0a20 2020 2020 2020  , dict):.       
+00014d00: 2020 2020 2072 6574 7572 6e20 4661 6c73       return Fals
+00014d10: 650a 2020 2020 2020 2020 7265 7475 726e  e.        return
+00014d20: 2028 0a20 2020 2020 2020 2020 2020 2022   (.            "
+00014d30: 6665 6522 2069 6e20 6f72 6465 720a 2020  fee" in order.  
+00014d40: 2020 2020 2020 2020 2020 616e 6420 6f72            and or
+00014d50: 6465 725b 2266 6565 225d 2069 7320 6e6f  der["fee"] is no
+00014d60: 7420 4e6f 6e65 0a20 2020 2020 2020 2020  t None.         
+00014d70: 2020 2061 6e64 2028 6f72 6465 725b 2266     and (order["f
+00014d80: 6565 225d 2e6b 6579 7328 2920 3e3d 207b  ee"].keys() >= {
+00014d90: 2263 7572 7265 6e63 7922 2c20 2263 6f73  "currency", "cos
+00014da0: 7422 7d29 0a20 2020 2020 2020 2020 2020  t"}).           
+00014db0: 2061 6e64 206f 7264 6572 5b22 6665 6522   and order["fee"
+00014dc0: 5d5b 2263 7572 7265 6e63 7922 5d20 6973  ]["currency"] is
+00014dd0: 206e 6f74 204e 6f6e 650a 2020 2020 2020   not None.      
+00014de0: 2020 2020 2020 616e 6420 6f72 6465 725b        and order[
+00014df0: 2266 6565 225d 5b22 636f 7374 225d 2069  "fee"]["cost"] i
+00014e00: 7320 6e6f 7420 4e6f 6e65 0a20 2020 2020  s not None.     
+00014e10: 2020 2029 0a0a 2020 2020 6465 6620 6361     )..    def ca
+00014e20: 6c63 756c 6174 655f 6665 655f 7261 7465  lculate_fee_rate
+00014e30: 280a 2020 2020 2020 2020 7365 6c66 2c20  (.        self, 
+00014e40: 6665 653a 2044 6963 742c 2073 796d 626f  fee: Dict, symbo
+00014e50: 6c3a 2073 7472 2c20 636f 7374 3a20 666c  l: str, cost: fl
+00014e60: 6f61 742c 2061 6d6f 756e 743a 2066 6c6f  oat, amount: flo
+00014e70: 6174 0a20 2020 2029 202d 3e20 4f70 7469  at.    ) -> Opti
+00014e80: 6f6e 616c 5b66 6c6f 6174 5d3a 0a20 2020  onal[float]:.   
+00014e90: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00014ea0: 2043 616c 6375 6c61 7465 2066 6565 2072   Calculate fee r
+00014eb0: 6174 6520 6966 2069 7427 7320 6e6f 7420  ate if it's not 
+00014ec0: 6769 7665 6e20 6279 2074 6865 2065 7863  given by the exc
+00014ed0: 6861 6e67 652e 0a20 2020 2020 2020 203a  hange..        :
+00014ee0: 7061 7261 6d20 6665 653a 2063 6378 7420  param fee: ccxt 
+00014ef0: 4665 6520 6469 6374 202d 206d 7573 7420  Fee dict - must 
+00014f00: 636f 6e74 6169 6e20 636f 7374 202f 2063  contain cost / c
+00014f10: 7572 7265 6e63 7920 2f20 7261 7465 0a20  urrency / rate. 
+00014f20: 2020 2020 2020 203a 7061 7261 6d20 7379         :param sy
+00014f30: 6d62 6f6c 3a20 5379 6d62 6f6c 206f 6620  mbol: Symbol of 
+00014f40: 7468 6520 6f72 6465 720a 2020 2020 2020  the order.      
+00014f50: 2020 3a70 6172 616d 2063 6f73 743a 2054    :param cost: T
+00014f60: 6f74 616c 2063 6f73 7420 6f66 2074 6865  otal cost of the
+00014f70: 206f 7264 6572 0a20 2020 2020 2020 203a   order.        :
+00014f80: 7061 7261 6d20 616d 6f75 6e74 3a20 416d  param amount: Am
+00014f90: 6f75 6e74 206f 6620 7468 6520 6f72 6465  ount of the orde
+00014fa0: 720a 2020 2020 2020 2020 2222 220a 2020  r.        """.  
+00014fb0: 2020 2020 2020 6966 2066 6565 2e67 6574        if fee.get
+00014fc0: 2822 7261 7465 2229 2069 7320 6e6f 7420  ("rate") is not 
+00014fd0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00014fe0: 2020 7265 7475 726e 2066 6565 2e67 6574    return fee.get
+00014ff0: 2822 7261 7465 2229 0a20 2020 2020 2020  ("rate").       
+00015000: 2066 6565 5f63 7572 7220 3d20 6665 652e   fee_curr = fee.
+00015010: 6765 7428 2263 7572 7265 6e63 7922 290a  get("currency").
+00015020: 2020 2020 2020 2020 6966 2066 6565 5f63          if fee_c
+00015030: 7572 7220 6973 204e 6f6e 653a 0a20 2020  urr is None:.   
+00015040: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00015050: 4e6f 6e65 0a20 2020 2020 2020 2066 6565  None.        fee
+00015060: 5f63 6f73 7420 3d20 666c 6f61 7428 6665  _cost = float(fe
+00015070: 655b 2263 6f73 7422 5d29 0a0a 2020 2020  e["cost"])..    
+00015080: 2020 2020 2320 4361 6c63 756c 6174 6520      # Calculate 
+00015090: 6665 6520 6261 7365 6420 6f6e 206f 7264  fee based on ord
+000150a0: 6572 2064 6574 6169 6c73 0a20 2020 2020  er details.     
+000150b0: 2020 2069 6620 6665 655f 6375 7272 203d     if fee_curr =
+000150c0: 3d20 7365 6c66 2e67 6574 5f70 6169 725f  = self.get_pair_
+000150d0: 6261 7365 5f63 7572 7265 6e63 7928 7379  base_currency(sy
+000150e0: 6d62 6f6c 293a 0a20 2020 2020 2020 2020  mbol):.         
+000150f0: 2020 2023 2042 6173 6520 6375 7272 656e     # Base curren
+00015100: 6379 202d 2064 6976 6964 6520 6279 2061  cy - divide by a
+00015110: 6d6f 756e 740a 2020 2020 2020 2020 2020  mount.          
+00015120: 2020 7265 7475 726e 2072 6f75 6e64 2866    return round(f
+00015130: 6565 5f63 6f73 7420 2f20 616d 6f75 6e74  ee_cost / amount
+00015140: 2c20 3829 0a20 2020 2020 2020 2065 6c69  , 8).        eli
+00015150: 6620 6665 655f 6375 7272 203d 3d20 7365  f fee_curr == se
+00015160: 6c66 2e67 6574 5f70 6169 725f 7175 6f74  lf.get_pair_quot
+00015170: 655f 6375 7272 656e 6379 2873 796d 626f  e_currency(symbo
+00015180: 6c29 3a0a 2020 2020 2020 2020 2020 2020  l):.            
+00015190: 2320 5175 6f74 6520 6375 7272 656e 6379  # Quote currency
+000151a0: 202d 2064 6976 6964 6520 6279 2063 6f73   - divide by cos
+000151b0: 740a 2020 2020 2020 2020 2020 2020 7265  t.            re
+000151c0: 7475 726e 2072 6f75 6e64 2866 6565 5f63  turn round(fee_c
+000151d0: 6f73 7420 2f20 636f 7374 2c20 3829 2069  ost / cost, 8) i
+000151e0: 6620 636f 7374 2065 6c73 6520 4e6f 6e65  f cost else None
+000151f0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00015200: 2020 2020 2020 2020 2020 2023 2049 6620             # If 
+00015210: 4665 6520 6375 7272 656e 6379 2069 7320  Fee currency is 
+00015220: 6120 6469 6666 6572 656e 7420 6375 7272  a different curr
+00015230: 656e 6379 0a20 2020 2020 2020 2020 2020  ency.           
+00015240: 2069 6620 6e6f 7420 636f 7374 3a0a 2020   if not cost:.  
+00015250: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+00015260: 4966 2063 6f73 7420 6973 204e 6f6e 6520  If cost is None 
+00015270: 6f72 2030 2e30 202d 3e20 6661 6c73 792c  or 0.0 -> falsy,
+00015280: 2072 6574 7572 6e20 4e6f 6e65 0a20 2020   return None.   
+00015290: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+000152a0: 7572 6e20 4e6f 6e65 0a20 2020 2020 2020  urn None.       
+000152b0: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
+000152c0: 2020 2020 2020 2020 2020 636f 6d62 203d            comb =
+000152d0: 2073 656c 662e 6765 745f 7661 6c69 645f   self.get_valid_
+000152e0: 7061 6972 5f63 6f6d 6269 6e61 7469 6f6e  pair_combination
+000152f0: 2866 6565 5f63 7572 722c 2073 656c 662e  (fee_curr, self.
+00015300: 5f63 6f6e 6669 675b 2273 7461 6b65 5f63  _config["stake_c
+00015310: 7572 7265 6e63 7922 5d29 0a20 2020 2020  urrency"]).     
+00015320: 2020 2020 2020 2020 2020 2074 6963 6b20             tick 
+00015330: 3d20 7365 6c66 2e66 6574 6368 5f74 6963  = self.fetch_tic
+00015340: 6b65 7228 636f 6d62 290a 0a20 2020 2020  ker(comb)..     
+00015350: 2020 2020 2020 2020 2020 2066 6565 5f74             fee_t
+00015360: 6f5f 7175 6f74 655f 7261 7465 203d 2073  o_quote_rate = s
+00015370: 6166 655f 7661 6c75 655f 6661 6c6c 6261  afe_value_fallba
+00015380: 636b 3228 7469 636b 2c20 7469 636b 2c20  ck2(tick, tick, 
+00015390: 226c 6173 7422 2c20 2261 736b 2229 0a20  "last", "ask"). 
+000153a0: 2020 2020 2020 2020 2020 2065 7863 6570             excep
+000153b0: 7420 2856 616c 7565 4572 726f 722c 2045  t (ValueError, E
+000153c0: 7863 6861 6e67 6545 7272 6f72 293a 0a20  xchangeError):. 
+000153d0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+000153e0: 6565 5f74 6f5f 7175 6f74 655f 7261 7465  ee_to_quote_rate
+000153f0: 203d 2073 656c 662e 5f63 6f6e 6669 675b   = self._config[
+00015400: 2265 7863 6861 6e67 6522 5d2e 6765 7428  "exchange"].get(
+00015410: 2275 6e6b 6e6f 776e 5f66 6565 5f72 6174  "unknown_fee_rat
+00015420: 6522 2c20 4e6f 6e65 290a 2020 2020 2020  e", None).      
+00015430: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
+00015440: 2066 6565 5f74 6f5f 7175 6f74 655f 7261   fee_to_quote_ra
+00015450: 7465 3a0a 2020 2020 2020 2020 2020 2020  te:.            
+00015460: 2020 2020 2020 2020 7265 7475 726e 204e          return N
+00015470: 6f6e 650a 2020 2020 2020 2020 2020 2020  one.            
+00015480: 7265 7475 726e 2072 6f75 6e64 2828 6665  return round((fe
+00015490: 655f 636f 7374 202a 2066 6565 5f74 6f5f  e_cost * fee_to_
+000154a0: 7175 6f74 655f 7261 7465 2920 2f20 636f  quote_rate) / co
+000154b0: 7374 2c20 3829 0a0a 2020 2020 6465 6620  st, 8)..    def 
+000154c0: 6578 7472 6163 745f 636f 7374 5f63 7572  extract_cost_cur
+000154d0: 725f 7261 7465 280a 2020 2020 2020 2020  r_rate(.        
+000154e0: 7365 6c66 2c20 6665 653a 2044 6963 742c  self, fee: Dict,
+000154f0: 2073 796d 626f 6c3a 2073 7472 2c20 636f   symbol: str, co
+00015500: 7374 3a20 666c 6f61 742c 2061 6d6f 756e  st: float, amoun
+00015510: 743a 2066 6c6f 6174 0a20 2020 2029 202d  t: float.    ) -
+00015520: 3e20 5475 706c 655b 666c 6f61 742c 2073  > Tuple[float, s
+00015530: 7472 2c20 4f70 7469 6f6e 616c 5b66 6c6f  tr, Optional[flo
+00015540: 6174 5d5d 3a0a 2020 2020 2020 2020 2222  at]]:.        ""
+00015550: 220a 2020 2020 2020 2020 4578 7472 6163  ".        Extrac
+00015560: 7420 7475 706c 6520 6f66 2063 6f73 742c  t tuple of cost,
+00015570: 2063 7572 7265 6e63 792c 2072 6174 652e   currency, rate.
+00015580: 0a20 2020 2020 2020 2052 6571 7569 7265  .        Require
+00015590: 7320 6f72 6465 725f 6861 735f 6665 6520  s order_has_fee 
+000155a0: 746f 2072 756e 2066 6972 7374 210a 2020  to run first!.  
+000155b0: 2020 2020 2020 3a70 6172 616d 2066 6565        :param fee
+000155c0: 3a20 6363 7874 2046 6565 2064 6963 7420  : ccxt Fee dict 
+000155d0: 2d20 6d75 7374 2063 6f6e 7461 696e 2063  - must contain c
+000155e0: 6f73 7420 2f20 6375 7272 656e 6379 202f  ost / currency /
+000155f0: 2072 6174 650a 2020 2020 2020 2020 3a70   rate.        :p
+00015600: 6172 616d 2073 796d 626f 6c3a 2053 796d  aram symbol: Sym
+00015610: 626f 6c20 6f66 2074 6865 206f 7264 6572  bol of the order
+00015620: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00015630: 636f 7374 3a20 546f 7461 6c20 636f 7374  cost: Total cost
+00015640: 206f 6620 7468 6520 6f72 6465 720a 2020   of the order.  
+00015650: 2020 2020 2020 3a70 6172 616d 2061 6d6f        :param amo
+00015660: 756e 743a 2041 6d6f 756e 7420 6f66 2074  unt: Amount of t
+00015670: 6865 206f 7264 6572 0a20 2020 2020 2020  he order.       
+00015680: 203a 7265 7475 726e 3a20 5475 706c 6520   :return: Tuple 
+00015690: 7769 7468 2063 6f73 742c 2063 7572 7265  with cost, curre
+000156a0: 6e63 792c 2072 6174 6520 6f66 2074 6865  ncy, rate of the
+000156b0: 2067 6976 656e 2066 6565 2064 6963 740a   given fee dict.
+000156c0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+000156d0: 2020 2020 7265 7475 726e 2028 0a20 2020      return (.   
+000156e0: 2020 2020 2020 2020 2066 6c6f 6174 2866           float(f
+000156f0: 6565 5b22 636f 7374 225d 292c 0a20 2020  ee["cost"]),.   
+00015700: 2020 2020 2020 2020 2066 6565 5b22 6375           fee["cu
+00015710: 7272 656e 6379 225d 2c0a 2020 2020 2020  rrency"],.      
+00015720: 2020 2020 2020 7365 6c66 2e63 616c 6375        self.calcu
+00015730: 6c61 7465 5f66 6565 5f72 6174 6528 6665  late_fee_rate(fe
+00015740: 652c 2073 796d 626f 6c2c 2063 6f73 742c  e, symbol, cost,
+00015750: 2061 6d6f 756e 7429 2c0a 2020 2020 2020   amount),.      
+00015760: 2020 290a 0a20 2020 2023 2048 6973 746f    )..    # Histo
+00015770: 7269 6320 6461 7461 0a0a 2020 2020 6465  ric data..    de
+00015780: 6620 6765 745f 6869 7374 6f72 6963 5f6f  f get_historic_o
+00015790: 686c 6376 280a 2020 2020 2020 2020 7365  hlcv(.        se
+000157a0: 6c66 2c0a 2020 2020 2020 2020 7061 6972  lf,.        pair
+000157b0: 3a20 7374 722c 0a20 2020 2020 2020 2074  : str,.        t
+000157c0: 696d 6566 7261 6d65 3a20 7374 722c 0a20  imeframe: str,. 
+000157d0: 2020 2020 2020 2073 696e 6365 5f6d 733a         since_ms:
+000157e0: 2069 6e74 2c0a 2020 2020 2020 2020 6361   int,.        ca
+000157f0: 6e64 6c65 5f74 7970 653a 2043 616e 646c  ndle_type: Candl
+00015800: 6554 7970 652c 0a20 2020 2020 2020 2069  eType,.        i
+00015810: 735f 6e65 775f 7061 6972 3a20 626f 6f6c  s_new_pair: bool
+00015820: 203d 2046 616c 7365 2c0a 2020 2020 2020   = False,.      
+00015830: 2020 756e 7469 6c5f 6d73 3a20 4f70 7469    until_ms: Opti
+00015840: 6f6e 616c 5b69 6e74 5d20 3d20 4e6f 6e65  onal[int] = None
+00015850: 2c0a 2020 2020 2920 2d3e 204c 6973 743a  ,.    ) -> List:
+00015860: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00015870: 2020 2020 2047 6574 2063 616e 646c 6520       Get candle 
+00015880: 6869 7374 6f72 7920 7573 696e 6720 6173  history using as
+00015890: 796e 6369 6f20 616e 6420 7265 7475 726e  yncio and return
+000158a0: 7320 7468 6520 6c69 7374 206f 6620 6361  s the list of ca
+000158b0: 6e64 6c65 732e 0a20 2020 2020 2020 2048  ndles..        H
+000158c0: 616e 646c 6573 2061 6c6c 2061 7379 6e63  andles all async
+000158d0: 2077 6f72 6b20 666f 7220 7468 6973 2e0a   work for this..
+000158e0: 2020 2020 2020 2020 4173 796e 6320 6f76          Async ov
+000158f0: 6572 206f 6e65 2070 6169 722c 2061 7373  er one pair, ass
+00015900: 756d 696e 6720 7765 2067 6574 2060 7365  uming we get `se
+00015910: 6c66 2e6f 686c 6376 5f63 616e 646c 655f  lf.ohlcv_candle_
+00015920: 6c69 6d69 7428 2960 2063 616e 646c 6573  limit()` candles
+00015930: 2070 6572 2063 616c 6c2e 0a20 2020 2020   per call..     
+00015940: 2020 203a 7061 7261 6d20 7061 6972 3a20     :param pair: 
+00015950: 5061 6972 2074 6f20 646f 776e 6c6f 6164  Pair to download
+00015960: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00015970: 7469 6d65 6672 616d 653a 2054 696d 6566  timeframe: Timef
+00015980: 7261 6d65 2074 6f20 6765 7420 6461 7461  rame to get data
+00015990: 2066 6f72 0a20 2020 2020 2020 203a 7061   for.        :pa
+000159a0: 7261 6d20 7369 6e63 655f 6d73 3a20 5469  ram since_ms: Ti
+000159b0: 6d65 7374 616d 7020 696e 206d 696c 6c69  mestamp in milli
+000159c0: 7365 636f 6e64 7320 746f 2067 6574 2068  seconds to get h
+000159d0: 6973 746f 7279 2066 726f 6d0a 2020 2020  istory from.    
+000159e0: 2020 2020 3a70 6172 616d 2075 6e74 696c      :param until
+000159f0: 5f6d 733a 2054 696d 6573 7461 6d70 2069  _ms: Timestamp i
+00015a00: 6e20 6d69 6c6c 6973 6563 6f6e 6473 2074  n milliseconds t
+00015a10: 6f20 6765 7420 6869 7374 6f72 7920 7570  o get history up
+00015a20: 2074 6f0a 2020 2020 2020 2020 3a70 6172   to.        :par
+00015a30: 616d 2063 616e 646c 655f 7479 7065 3a20  am candle_type: 
+00015a40: 2727 2c20 6d61 726b 2c20 696e 6465 782c  '', mark, index,
+00015a50: 2070 7265 6d69 756d 496e 6465 782c 206f   premiumIndex, o
+00015a60: 7220 6675 6e64 696e 675f 7261 7465 0a20  r funding_rate. 
+00015a70: 2020 2020 2020 203a 7265 7475 726e 3a20         :return: 
+00015a80: 4c69 7374 2077 6974 6820 6361 6e64 6c65  List with candle
+00015a90: 2028 4f48 4c43 5629 2064 6174 610a 2020   (OHLCV) data.  
+00015aa0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00015ab0: 2020 7061 6972 2c20 5f2c 205f 2c20 6461    pair, _, _, da
+00015ac0: 7461 2c20 5f20 3d20 7365 6c66 2e6c 6f6f  ta, _ = self.loo
+00015ad0: 702e 7275 6e5f 756e 7469 6c5f 636f 6d70  p.run_until_comp
+00015ae0: 6c65 7465 280a 2020 2020 2020 2020 2020  lete(.          
+00015af0: 2020 7365 6c66 2e5f 6173 796e 635f 6765    self._async_ge
+00015b00: 745f 6869 7374 6f72 6963 5f6f 686c 6376  t_historic_ohlcv
+00015b10: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00015b20: 2020 7061 6972 3d70 6169 722c 0a20 2020    pair=pair,.   
+00015b30: 2020 2020 2020 2020 2020 2020 2074 696d               tim
+00015b40: 6566 7261 6d65 3d74 696d 6566 7261 6d65  eframe=timeframe
+00015b50: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00015b60: 2020 7369 6e63 655f 6d73 3d73 696e 6365    since_ms=since
+00015b70: 5f6d 732c 0a20 2020 2020 2020 2020 2020  _ms,.           
+00015b80: 2020 2020 2075 6e74 696c 5f6d 733d 756e       until_ms=un
+00015b90: 7469 6c5f 6d73 2c0a 2020 2020 2020 2020  til_ms,.        
+00015ba0: 2020 2020 2020 2020 6973 5f6e 6577 5f70          is_new_p
+00015bb0: 6169 723d 6973 5f6e 6577 5f70 6169 722c  air=is_new_pair,
+00015bc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015bd0: 2063 616e 646c 655f 7479 7065 3d63 616e   candle_type=can
+00015be0: 646c 655f 7479 7065 2c0a 2020 2020 2020  dle_type,.      
+00015bf0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00015c00: 290a 2020 2020 2020 2020 6c6f 6767 6572  ).        logger
+00015c10: 2e69 6e66 6f28 6622 446f 776e 6c6f 6164  .info(f"Download
+00015c20: 6564 2064 6174 6120 666f 7220 7b70 6169  ed data for {pai
+00015c30: 727d 2077 6974 6820 6c65 6e67 7468 207b  r} with length {
+00015c40: 6c65 6e28 6461 7461 297d 2e22 290a 2020  len(data)}.").  
+00015c50: 2020 2020 2020 7265 7475 726e 2064 6174        return dat
+00015c60: 610a 0a20 2020 2061 7379 6e63 2064 6566  a..    async def
+00015c70: 205f 6173 796e 635f 6765 745f 6869 7374   _async_get_hist
+00015c80: 6f72 6963 5f6f 686c 6376 280a 2020 2020  oric_ohlcv(.    
+00015c90: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+00015ca0: 2020 7061 6972 3a20 7374 722c 0a20 2020    pair: str,.   
+00015cb0: 2020 2020 2074 696d 6566 7261 6d65 3a20       timeframe: 
+00015cc0: 7374 722c 0a20 2020 2020 2020 2073 696e  str,.        sin
+00015cd0: 6365 5f6d 733a 2069 6e74 2c0a 2020 2020  ce_ms: int,.    
+00015ce0: 2020 2020 6361 6e64 6c65 5f74 7970 653a      candle_type:
+00015cf0: 2043 616e 646c 6554 7970 652c 0a20 2020   CandleType,.   
+00015d00: 2020 2020 2069 735f 6e65 775f 7061 6972       is_new_pair
+00015d10: 3a20 626f 6f6c 203d 2046 616c 7365 2c0a  : bool = False,.
+00015d20: 2020 2020 2020 2020 7261 6973 655f 3a20          raise_: 
+00015d30: 626f 6f6c 203d 2046 616c 7365 2c0a 2020  bool = False,.  
+00015d40: 2020 2020 2020 756e 7469 6c5f 6d73 3a20        until_ms: 
+00015d50: 4f70 7469 6f6e 616c 5b69 6e74 5d20 3d20  Optional[int] = 
+00015d60: 4e6f 6e65 2c0a 2020 2020 2920 2d3e 204f  None,.    ) -> O
+00015d70: 484c 4356 5265 7370 6f6e 7365 3a0a 2020  HLCVResponse:.  
+00015d80: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00015d90: 2020 446f 776e 6c6f 6164 2068 6973 746f    Download histo
+00015da0: 7269 6320 6f68 6c63 760a 2020 2020 2020  ric ohlcv.      
+00015db0: 2020 3a70 6172 616d 2069 735f 6e65 775f    :param is_new_
+00015dc0: 7061 6972 3a20 7573 6564 2062 7920 6269  pair: used by bi
+00015dd0: 6e61 6e63 6520 7375 6263 6c61 7373 2074  nance subclass t
+00015de0: 6f20 616c 6c6f 7720 2266 6173 7422 206e  o allow "fast" n
+00015df0: 6577 2070 6169 7220 646f 776e 6c6f 6164  ew pair download
+00015e00: 696e 670a 2020 2020 2020 2020 3a70 6172  ing.        :par
+00015e10: 616d 2063 616e 646c 655f 7479 7065 3a20  am candle_type: 
+00015e20: 416e 7920 6f66 2074 6865 2065 6e75 6d20  Any of the enum 
+00015e30: 4361 6e64 6c65 5479 7065 2028 6d75 7374  CandleType (must
+00015e40: 206d 6174 6368 2074 7261 6469 6e67 206d   match trading m
+00015e50: 6f64 6521 290a 2020 2020 2020 2020 2222  ode!).        ""
+00015e60: 220a 0a20 2020 2020 2020 206f 6e65 5f63  "..        one_c
+00015e70: 616c 6c20 3d20 7469 6d65 6672 616d 655f  all = timeframe_
+00015e80: 746f 5f6d 7365 6373 2874 696d 6566 7261  to_msecs(timefra
+00015e90: 6d65 2920 2a20 7365 6c66 2e6f 686c 6376  me) * self.ohlcv
+00015ea0: 5f63 616e 646c 655f 6c69 6d69 7428 0a20  _candle_limit(. 
+00015eb0: 2020 2020 2020 2020 2020 2074 696d 6566             timef
+00015ec0: 7261 6d65 2c20 6361 6e64 6c65 5f74 7970  rame, candle_typ
+00015ed0: 652c 2073 696e 6365 5f6d 730a 2020 2020  e, since_ms.    
+00015ee0: 2020 2020 290a 2020 2020 2020 2020 6c6f      ).        lo
+00015ef0: 6767 6572 2e64 6562 7567 280a 2020 2020  gger.debug(.    
+00015f00: 2020 2020 2020 2020 226f 6e65 5f63 616c          "one_cal
+00015f10: 6c3a 2025 7320 6d73 6563 7320 2825 7329  l: %s msecs (%s)
+00015f20: 222c 0a20 2020 2020 2020 2020 2020 206f  ",.            o
+00015f30: 6e65 5f63 616c 6c2c 0a20 2020 2020 2020  ne_call,.       
+00015f40: 2020 2020 2064 745f 6875 6d61 6e69 7a65       dt_humanize
+00015f50: 5f64 656c 7461 2864 745f 6e6f 7728 2920  _delta(dt_now() 
+00015f60: 2d20 7469 6d65 6465 6c74 6128 6d69 6c6c  - timedelta(mill
+00015f70: 6973 6563 6f6e 6473 3d6f 6e65 5f63 616c  iseconds=one_cal
+00015f80: 6c29 292c 0a20 2020 2020 2020 2029 0a20  l)),.        ). 
+00015f90: 2020 2020 2020 2069 6e70 7574 5f63 6f72         input_cor
+00015fa0: 6f75 7469 6e65 7320 3d20 5b0a 2020 2020  outines = [.    
+00015fb0: 2020 2020 2020 2020 7365 6c66 2e5f 6173          self._as
+00015fc0: 796e 635f 6765 745f 6361 6e64 6c65 5f68  ync_get_candle_h
+00015fd0: 6973 746f 7279 2870 6169 722c 2074 696d  istory(pair, tim
+00015fe0: 6566 7261 6d65 2c20 6361 6e64 6c65 5f74  eframe, candle_t
+00015ff0: 7970 652c 2073 696e 6365 290a 2020 2020  ype, since).    
+00016000: 2020 2020 2020 2020 666f 7220 7369 6e63          for sinc
+00016010: 6520 696e 2072 616e 6765 2873 696e 6365  e in range(since
+00016020: 5f6d 732c 2075 6e74 696c 5f6d 7320 6f72  _ms, until_ms or
+00016030: 2064 745f 7473 2829 2c20 6f6e 655f 6361   dt_ts(), one_ca
+00016040: 6c6c 290a 2020 2020 2020 2020 5d0a 0a20  ll).        ].. 
+00016050: 2020 2020 2020 2064 6174 613a 204c 6973         data: Lis
+00016060: 7420 3d20 5b5d 0a20 2020 2020 2020 2023  t = [].        #
+00016070: 2043 6875 6e6b 2072 6571 7565 7374 7320   Chunk requests 
+00016080: 696e 746f 2062 6174 6368 6573 206f 6620  into batches of 
+00016090: 3130 3020 746f 2061 766f 6964 206f 7665  100 to avoid ove
+000160a0: 7277 6865 6c6d 696e 6720 6363 7874 2054  rwhelming ccxt T
+000160b0: 6872 6f74 746c 696e 670a 2020 2020 2020  hrottling.      
+000160c0: 2020 666f 7220 696e 7075 745f 636f 726f    for input_coro
+000160d0: 2069 6e20 6368 756e 6b73 2869 6e70 7574   in chunks(input
+000160e0: 5f63 6f72 6f75 7469 6e65 732c 2031 3030  _coroutines, 100
+000160f0: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+00016100: 6573 756c 7473 203d 2061 7761 6974 2061  esults = await a
+00016110: 7379 6e63 696f 2e67 6174 6865 7228 2a69  syncio.gather(*i
+00016120: 6e70 7574 5f63 6f72 6f2c 2072 6574 7572  nput_coro, retur
+00016130: 6e5f 6578 6365 7074 696f 6e73 3d54 7275  n_exceptions=Tru
+00016140: 6529 0a20 2020 2020 2020 2020 2020 2066  e).            f
+00016150: 6f72 2072 6573 2069 6e20 7265 7375 6c74  or res in result
+00016160: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
+00016170: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+00016180: 2872 6573 2c20 4261 7365 4578 6365 7074  (res, BaseExcept
+00016190: 696f 6e29 3a0a 2020 2020 2020 2020 2020  ion):.          
+000161a0: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+000161b0: 2e77 6172 6e69 6e67 2866 2241 7379 6e63  .warning(f"Async
+000161c0: 2063 6f64 6520 7261 6973 6564 2061 6e20   code raised an 
+000161d0: 6578 6365 7074 696f 6e3a 207b 7265 7072  exception: {repr
+000161e0: 2872 6573 297d 2229 0a20 2020 2020 2020  (res)}").       
+000161f0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00016200: 7261 6973 655f 3a0a 2020 2020 2020 2020  raise_:.        
+00016210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016220: 7261 6973 650a 2020 2020 2020 2020 2020  raise.          
+00016230: 2020 2020 2020 2020 2020 636f 6e74 696e            contin
+00016240: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
+00016250: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00016260: 2020 2020 2020 2020 2020 2020 2023 2044               # D
+00016270: 6563 6f6e 7374 7275 6374 2074 7570 6c65  econstruct tuple
+00016280: 2069 6620 6974 2773 206e 6f74 2061 6e20   if it's not an 
+00016290: 6578 6365 7074 696f 6e0a 2020 2020 2020  exception.      
+000162a0: 2020 2020 2020 2020 2020 2020 2020 702c                p,
+000162b0: 205f 2c20 632c 206e 6577 5f64 6174 612c   _, c, new_data,
+000162c0: 205f 203d 2072 6573 0a20 2020 2020 2020   _ = res.       
+000162d0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000162e0: 7020 3d3d 2070 6169 7220 616e 6420 6320  p == pair and c 
+000162f0: 3d3d 2063 616e 646c 655f 7479 7065 3a0a  == candle_type:.
+00016300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016310: 2020 2020 2020 2020 6461 7461 2e65 7874          data.ext
+00016320: 656e 6428 6e65 775f 6461 7461 290a 2020  end(new_data).  
+00016330: 2020 2020 2020 2320 536f 7274 2064 6174        # Sort dat
+00016340: 6120 6167 6169 6e20 6166 7465 7220 6578  a again after ex
+00016350: 7465 6e64 696e 6720 7468 6520 7265 7375  tending the resu
+00016360: 6c74 202d 2061 626f 7665 2063 616c 6c73  lt - above calls
+00016370: 2072 6574 7572 6e20 696e 2022 6173 796e   return in "asyn
+00016380: 6320 6f72 6465 7222 0a20 2020 2020 2020  c order".       
+00016390: 2064 6174 6120 3d20 736f 7274 6564 2864   data = sorted(d
+000163a0: 6174 612c 206b 6579 3d6c 616d 6264 6120  ata, key=lambda 
+000163b0: 783a 2078 5b30 5d29 0a20 2020 2020 2020  x: x[0]).       
+000163c0: 2072 6574 7572 6e20 7061 6972 2c20 7469   return pair, ti
+000163d0: 6d65 6672 616d 652c 2063 616e 646c 655f  meframe, candle_
+000163e0: 7479 7065 2c20 6461 7461 2c20 7365 6c66  type, data, self
+000163f0: 2e5f 6f68 6c63 765f 7061 7274 6961 6c5f  ._ohlcv_partial_
+00016400: 6361 6e64 6c65 0a0a 2020 2020 6465 6620  candle..    def 
+00016410: 5f62 7569 6c64 5f63 6f72 6f75 7469 6e65  _build_coroutine
+00016420: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
+00016430: 2020 2020 2020 2020 7061 6972 3a20 7374          pair: st
+00016440: 722c 0a20 2020 2020 2020 2074 696d 6566  r,.        timef
+00016450: 7261 6d65 3a20 7374 722c 0a20 2020 2020  rame: str,.     
+00016460: 2020 2063 616e 646c 655f 7479 7065 3a20     candle_type: 
+00016470: 4361 6e64 6c65 5479 7065 2c0a 2020 2020  CandleType,.    
+00016480: 2020 2020 7369 6e63 655f 6d73 3a20 4f70      since_ms: Op
+00016490: 7469 6f6e 616c 5b69 6e74 5d2c 0a20 2020  tional[int],.   
+000164a0: 2020 2020 2063 6163 6865 3a20 626f 6f6c       cache: bool
+000164b0: 2c0a 2020 2020 2920 2d3e 2043 6f72 6f75  ,.    ) -> Corou
+000164c0: 7469 6e65 5b41 6e79 2c20 416e 792c 204f  tine[Any, Any, O
+000164d0: 484c 4356 5265 7370 6f6e 7365 5d3a 0a20  HLCVResponse]:. 
+000164e0: 2020 2020 2020 206e 6f74 5f61 6c6c 5f64         not_all_d
+000164f0: 6174 6120 3d20 6361 6368 6520 616e 6420  ata = cache and 
+00016500: 7365 6c66 2e72 6571 7569 7265 645f 6361  self.required_ca
+00016510: 6e64 6c65 5f63 616c 6c5f 636f 756e 7420  ndle_call_count 
+00016520: 3e20 310a 2020 2020 2020 2020 6966 2063  > 1.        if c
+00016530: 6163 6865 2061 6e64 2028 7061 6972 2c20  ache and (pair, 
+00016540: 7469 6d65 6672 616d 652c 2063 616e 646c  timeframe, candl
+00016550: 655f 7479 7065 2920 696e 2073 656c 662e  e_type) in self.
+00016560: 5f6b 6c69 6e65 733a 0a20 2020 2020 2020  _klines:.       
+00016570: 2020 2020 2063 616e 646c 655f 6c69 6d69       candle_limi
+00016580: 7420 3d20 7365 6c66 2e6f 686c 6376 5f63  t = self.ohlcv_c
+00016590: 616e 646c 655f 6c69 6d69 7428 7469 6d65  andle_limit(time
+000165a0: 6672 616d 652c 2063 616e 646c 655f 7479  frame, candle_ty
+000165b0: 7065 290a 2020 2020 2020 2020 2020 2020  pe).            
+000165c0: 6d69 6e5f 6461 7465 203d 2064 6174 655f  min_date = date_
+000165d0: 6d69 6e75 735f 6361 6e64 6c65 7328 7469  minus_candles(ti
+000165e0: 6d65 6672 616d 652c 2063 616e 646c 655f  meframe, candle_
+000165f0: 6c69 6d69 7420 2d20 3529 2e74 696d 6573  limit - 5).times
+00016600: 7461 6d70 2829 0a20 2020 2020 2020 2020  tamp().         
+00016610: 2020 2023 2043 6865 636b 2069 6620 3120     # Check if 1 
+00016620: 6361 6c6c 2063 616e 2067 6574 2075 7320  call can get us 
+00016630: 7570 6461 7465 6420 6361 6e64 6c65 7320  updated candles 
+00016640: 7769 7468 6f75 7420 686f 6c65 2069 6e20  without hole in 
+00016650: 7468 6520 6461 7461 2e0a 2020 2020 2020  the data..      
+00016660: 2020 2020 2020 6966 206d 696e 5f64 6174        if min_dat
+00016670: 6520 3c20 7365 6c66 2e5f 7061 6972 735f  e < self._pairs_
+00016680: 6c61 7374 5f72 6566 7265 7368 5f74 696d  last_refresh_tim
+00016690: 652e 6765 7428 2870 6169 722c 2074 696d  e.get((pair, tim
+000166a0: 6566 7261 6d65 2c20 6361 6e64 6c65 5f74  eframe, candle_t
+000166b0: 7970 6529 2c20 3029 3a0a 2020 2020 2020  ype), 0):.      
+000166c0: 2020 2020 2020 2020 2020 2320 4361 6368            # Cach
+000166d0: 6520 6361 6e20 6265 2075 7365 6420 2d20  e can be used - 
+000166e0: 646f 206f 6e65 2d6f 6666 2063 616c 6c2e  do one-off call.
+000166f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016700: 206e 6f74 5f61 6c6c 5f64 6174 6120 3d20   not_all_data = 
+00016710: 4661 6c73 650a 2020 2020 2020 2020 2020  False.          
+00016720: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00016730: 2020 2020 2020 2020 2320 5469 6d65 206a          # Time j
+00016740: 756d 7020 6465 7465 6374 6564 2c20 6576  ump detected, ev
+00016750: 6963 7420 6361 6368 650a 2020 2020 2020  ict cache.      
+00016760: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+00016770: 2e69 6e66 6f28 0a20 2020 2020 2020 2020  .info(.         
+00016780: 2020 2020 2020 2020 2020 2066 2254 696d             f"Tim
+00016790: 6520 6a75 6d70 2064 6574 6563 7465 642e  e jump detected.
+000167a0: 2045 7669 6374 696e 6720 6361 6368 6520   Evicting cache 
+000167b0: 666f 7220 7b70 6169 727d 2c20 7b74 696d  for {pair}, {tim
+000167c0: 6566 7261 6d65 7d2c 207b 6361 6e64 6c65  eframe}, {candle
+000167d0: 5f74 7970 657d 220a 2020 2020 2020 2020  _type}".        
+000167e0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+000167f0: 2020 2020 2020 2020 2020 6465 6c20 7365            del se
+00016800: 6c66 2e5f 6b6c 696e 6573 5b28 7061 6972  lf._klines[(pair
+00016810: 2c20 7469 6d65 6672 616d 652c 2063 616e  , timeframe, can
+00016820: 646c 655f 7479 7065 295d 0a0a 2020 2020  dle_type)]..    
+00016830: 2020 2020 6966 206e 6f74 2073 696e 6365      if not since
+00016840: 5f6d 7320 616e 6420 2873 656c 662e 5f66  _ms and (self._f
+00016850: 745f 6861 735b 226f 686c 6376 5f72 6571  t_has["ohlcv_req
+00016860: 7569 7265 5f73 696e 6365 225d 206f 7220  uire_since"] or 
+00016870: 6e6f 745f 616c 6c5f 6461 7461 293a 0a20  not_all_data):. 
+00016880: 2020 2020 2020 2020 2020 2023 204d 756c             # Mul
+00016890: 7469 706c 6520 6361 6c6c 7320 666f 7220  tiple calls for 
+000168a0: 6f6e 6520 7061 6972 202d 2074 6f20 6765  one pair - to ge
+000168b0: 7420 6d6f 7265 2068 6973 746f 7279 0a20  t more history. 
+000168c0: 2020 2020 2020 2020 2020 206f 6e65 5f63             one_c
+000168d0: 616c 6c20 3d20 7469 6d65 6672 616d 655f  all = timeframe_
+000168e0: 746f 5f6d 7365 6373 2874 696d 6566 7261  to_msecs(timefra
+000168f0: 6d65 2920 2a20 7365 6c66 2e6f 686c 6376  me) * self.ohlcv
+00016900: 5f63 616e 646c 655f 6c69 6d69 7428 0a20  _candle_limit(. 
+00016910: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+00016920: 696d 6566 7261 6d65 2c20 6361 6e64 6c65  imeframe, candle
+00016930: 5f74 7970 652c 2073 696e 6365 5f6d 730a  _type, since_ms.
+00016940: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00016950: 2020 2020 2020 2020 2020 6d6f 7665 5f74            move_t
+00016960: 6f20 3d20 6f6e 655f 6361 6c6c 202a 2073  o = one_call * s
+00016970: 656c 662e 7265 7175 6972 6564 5f63 616e  elf.required_can
+00016980: 646c 655f 6361 6c6c 5f63 6f75 6e74 0a20  dle_call_count. 
+00016990: 2020 2020 2020 2020 2020 206e 6f77 203d             now =
+000169a0: 2074 696d 6566 7261 6d65 5f74 6f5f 6e65   timeframe_to_ne
+000169b0: 7874 5f64 6174 6528 7469 6d65 6672 616d  xt_date(timefram
+000169c0: 6529 0a20 2020 2020 2020 2020 2020 2073  e).            s
+000169d0: 696e 6365 5f6d 7320 3d20 6474 5f74 7328  ince_ms = dt_ts(
+000169e0: 6e6f 7720 2d20 7469 6d65 6465 6c74 6128  now - timedelta(
+000169f0: 7365 636f 6e64 733d 6d6f 7665 5f74 6f20  seconds=move_to 
+00016a00: 2f2f 2031 3030 3029 290a 0a20 2020 2020  // 1000))..     
+00016a10: 2020 2069 6620 7369 6e63 655f 6d73 3a0a     if since_ms:.
+00016a20: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00016a30: 726e 2073 656c 662e 5f61 7379 6e63 5f67  rn self._async_g
+00016a40: 6574 5f68 6973 746f 7269 635f 6f68 6c63  et_historic_ohlc
+00016a50: 7628 0a20 2020 2020 2020 2020 2020 2020  v(.             
+00016a60: 2020 2070 6169 722c 2074 696d 6566 7261     pair, timefra
+00016a70: 6d65 2c20 7369 6e63 655f 6d73 3d73 696e  me, since_ms=sin
+00016a80: 6365 5f6d 732c 2072 6169 7365 5f3d 5472  ce_ms, raise_=Tr
+00016a90: 7565 2c20 6361 6e64 6c65 5f74 7970 653d  ue, candle_type=
+00016aa0: 6361 6e64 6c65 5f74 7970 650a 2020 2020  candle_type.    
+00016ab0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00016ac0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00016ad0: 2020 2020 2320 4f6e 6520 6361 6c6c 202e      # One call .
+00016ae0: 2e2e 2022 7265 6775 6c61 7222 2072 6566  .. "regular" ref
+00016af0: 7265 7368 0a20 2020 2020 2020 2020 2020  resh.           
+00016b00: 2072 6574 7572 6e20 7365 6c66 2e5f 6173   return self._as
+00016b10: 796e 635f 6765 745f 6361 6e64 6c65 5f68  ync_get_candle_h
+00016b20: 6973 746f 7279 280a 2020 2020 2020 2020  istory(.        
+00016b30: 2020 2020 2020 2020 7061 6972 2c20 7469          pair, ti
+00016b40: 6d65 6672 616d 652c 2073 696e 6365 5f6d  meframe, since_m
+00016b50: 733d 7369 6e63 655f 6d73 2c20 6361 6e64  s=since_ms, cand
+00016b60: 6c65 5f74 7970 653d 6361 6e64 6c65 5f74  le_type=candle_t
+00016b70: 7970 650a 2020 2020 2020 2020 2020 2020  ype.            
+00016b80: 290a 0a20 2020 2064 6566 205f 6275 696c  )..    def _buil
+00016b90: 645f 6f68 6c63 765f 646c 5f6a 6f62 7328  d_ohlcv_dl_jobs(
+00016ba0: 0a20 2020 2020 2020 2073 656c 662c 2070  .        self, p
+00016bb0: 6169 725f 6c69 7374 3a20 4c69 7374 5061  air_list: ListPa
+00016bc0: 6972 7357 6974 6854 696d 6566 7261 6d65  irsWithTimeframe
+00016bd0: 732c 2073 696e 6365 5f6d 733a 204f 7074  s, since_ms: Opt
+00016be0: 696f 6e61 6c5b 696e 745d 2c20 6361 6368  ional[int], cach
+00016bf0: 653a 2062 6f6f 6c0a 2020 2020 2920 2d3e  e: bool.    ) ->
+00016c00: 2054 7570 6c65 5b4c 6973 745b 436f 726f   Tuple[List[Coro
+00016c10: 7574 696e 655d 2c20 4c69 7374 5b54 7570  utine], List[Tup
+00016c20: 6c65 5b73 7472 2c20 7374 722c 2043 616e  le[str, str, Can
+00016c30: 646c 6554 7970 655d 5d5d 3a0a 2020 2020  dleType]]]:.    
+00016c40: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00016c50: 4275 696c 6420 436f 726f 7574 696e 6573  Build Coroutines
+00016c60: 2074 6f20 6578 6563 7574 6520 6173 2070   to execute as p
+00016c70: 6172 7420 6f66 2072 6566 7265 7368 5f6c  art of refresh_l
+00016c80: 6174 6573 745f 6f68 6c63 760a 2020 2020  atest_ohlcv.    
+00016c90: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00016ca0: 696e 7075 745f 636f 726f 7574 696e 6573  input_coroutines
+00016cb0: 3a20 4c69 7374 5b43 6f72 6f75 7469 6e65  : List[Coroutine
+00016cc0: 5b41 6e79 2c20 416e 792c 204f 484c 4356  [Any, Any, OHLCV
+00016cd0: 5265 7370 6f6e 7365 5d5d 203d 205b 5d0a  Response]] = [].
+00016ce0: 2020 2020 2020 2020 6361 6368 6564 5f70          cached_p
+00016cf0: 6169 7273 203d 205b 5d0a 2020 2020 2020  airs = [].      
+00016d00: 2020 666f 7220 7061 6972 2c20 7469 6d65    for pair, time
+00016d10: 6672 616d 652c 2063 616e 646c 655f 7479  frame, candle_ty
+00016d20: 7065 2069 6e20 7365 7428 7061 6972 5f6c  pe in set(pair_l
+00016d30: 6973 7429 3a0a 2020 2020 2020 2020 2020  ist):.          
+00016d40: 2020 6966 2074 696d 6566 7261 6d65 206e    if timeframe n
+00016d50: 6f74 2069 6e20 7365 6c66 2e74 696d 6566  ot in self.timef
+00016d60: 7261 6d65 7320 616e 6420 6361 6e64 6c65  rames and candle
+00016d70: 5f74 7970 6520 696e 2028 0a20 2020 2020  _type in (.     
+00016d80: 2020 2020 2020 2020 2020 2043 616e 646c             Candl
+00016d90: 6554 7970 652e 5350 4f54 2c0a 2020 2020  eType.SPOT,.    
+00016da0: 2020 2020 2020 2020 2020 2020 4361 6e64              Cand
+00016db0: 6c65 5479 7065 2e46 5554 5552 4553 2c0a  leType.FUTURES,.
+00016dc0: 2020 2020 2020 2020 2020 2020 293a 0a20              ):. 
+00016dd0: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+00016de0: 6f67 6765 722e 7761 726e 696e 6728 0a20  ogger.warning(. 
+00016df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016e00: 2020 2066 2243 616e 6e6f 7420 646f 776e     f"Cannot down
+00016e10: 6c6f 6164 2028 7b70 6169 727d 2c20 7b74  load ({pair}, {t
+00016e20: 696d 6566 7261 6d65 7d29 2063 6f6d 6269  imeframe}) combi
+00016e30: 6e61 7469 6f6e 2061 7320 7468 6973 2074  nation as this t
+00016e40: 696d 6566 7261 6d65 2069 7320 220a 2020  imeframe is ".  
+00016e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016e60: 2020 6622 6e6f 7420 6176 6169 6c61 626c    f"not availabl
+00016e70: 6520 6f6e 207b 7365 6c66 2e6e 616d 657d  e on {self.name}
+00016e80: 2e20 4176 6169 6c61 626c 6520 7469 6d65  . Available time
+00016e90: 6672 616d 6573 2061 7265 2022 0a20 2020  frames are ".   
+00016ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016eb0: 2066 227b 272c 2027 2e6a 6f69 6e28 7365   f"{', '.join(se
+00016ec0: 6c66 2e74 696d 6566 7261 6d65 7329 7d2e  lf.timeframes)}.
+00016ed0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00016ee0: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00016ef0: 2020 2020 636f 6e74 696e 7565 0a0a 2020      continue..  
+00016f00: 2020 2020 2020 2020 2020 6966 2028 0a20            if (. 
+00016f10: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+00016f20: 7061 6972 2c20 7469 6d65 6672 616d 652c  pair, timeframe,
+00016f30: 2063 616e 646c 655f 7479 7065 2920 6e6f   candle_type) no
+00016f40: 7420 696e 2073 656c 662e 5f6b 6c69 6e65  t in self._kline
+00016f50: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
+00016f60: 2020 6f72 206e 6f74 2063 6163 6865 0a20    or not cache. 
+00016f70: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00016f80: 7220 7365 6c66 2e5f 6e6f 775f 6973 5f74  r self._now_is_t
+00016f90: 696d 655f 746f 5f72 6566 7265 7368 2870  ime_to_refresh(p
+00016fa0: 6169 722c 2074 696d 6566 7261 6d65 2c20  air, timeframe, 
+00016fb0: 6361 6e64 6c65 5f74 7970 6529 0a20 2020  candle_type).   
+00016fc0: 2020 2020 2020 2020 2029 3a0a 2020 2020           ):.    
+00016fd0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00016fe0: 745f 636f 726f 7574 696e 6573 2e61 7070  t_coroutines.app
+00016ff0: 656e 6428 0a20 2020 2020 2020 2020 2020  end(.           
+00017000: 2020 2020 2020 2020 2073 656c 662e 5f62           self._b
+00017010: 7569 6c64 5f63 6f72 6f75 7469 6e65 2870  uild_coroutine(p
+00017020: 6169 722c 2074 696d 6566 7261 6d65 2c20  air, timeframe, 
+00017030: 6361 6e64 6c65 5f74 7970 652c 2073 696e  candle_type, sin
+00017040: 6365 5f6d 732c 2063 6163 6865 290a 2020  ce_ms, cache).  
+00017050: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00017060: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+00017070: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00017080: 2020 206c 6f67 6765 722e 6465 6275 6728     logger.debug(
+00017090: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000170a0: 2020 2020 2066 2255 7369 6e67 2063 6163       f"Using cac
+000170b0: 6865 6420 6361 6e64 6c65 2028 4f48 4c43  hed candle (OHLC
+000170c0: 5629 2064 6174 6120 666f 7220 7b70 6169  V) data for {pai
+000170d0: 727d 2c20 7b74 696d 6566 7261 6d65 7d2c  r}, {timeframe},
+000170e0: 207b 6361 6e64 6c65 5f74 7970 657d 202e   {candle_type} .
+000170f0: 2e2e 220a 2020 2020 2020 2020 2020 2020  ..".            
+00017100: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+00017110: 2020 2020 2020 6361 6368 6564 5f70 6169        cached_pai
+00017120: 7273 2e61 7070 656e 6428 2870 6169 722c  rs.append((pair,
+00017130: 2074 696d 6566 7261 6d65 2c20 6361 6e64   timeframe, cand
+00017140: 6c65 5f74 7970 6529 290a 0a20 2020 2020  le_type))..     
+00017150: 2020 2072 6574 7572 6e20 696e 7075 745f     return input_
+00017160: 636f 726f 7574 696e 6573 2c20 6361 6368  coroutines, cach
+00017170: 6564 5f70 6169 7273 0a0a 2020 2020 6465  ed_pairs..    de
+00017180: 6620 5f70 726f 6365 7373 5f6f 686c 6376  f _process_ohlcv
+00017190: 5f64 6628 0a20 2020 2020 2020 2073 656c  _df(.        sel
+000171a0: 662c 0a20 2020 2020 2020 2070 6169 723a  f,.        pair:
+000171b0: 2073 7472 2c0a 2020 2020 2020 2020 7469   str,.        ti
+000171c0: 6d65 6672 616d 653a 2073 7472 2c0a 2020  meframe: str,.  
+000171d0: 2020 2020 2020 635f 7479 7065 3a20 4361        c_type: Ca
+000171e0: 6e64 6c65 5479 7065 2c0a 2020 2020 2020  ndleType,.      
+000171f0: 2020 7469 636b 733a 204c 6973 745b 4c69    ticks: List[Li
+00017200: 7374 5d2c 0a20 2020 2020 2020 2063 6163  st],.        cac
+00017210: 6865 3a20 626f 6f6c 2c0a 2020 2020 2020  he: bool,.      
+00017220: 2020 6472 6f70 5f69 6e63 6f6d 706c 6574    drop_incomplet
+00017230: 653a 2062 6f6f 6c2c 0a20 2020 2029 202d  e: bool,.    ) -
+00017240: 3e20 4461 7461 4672 616d 653a 0a20 2020  > DataFrame:.   
+00017250: 2020 2020 2023 206b 6565 7069 6e67 206c       # keeping l
+00017260: 6173 7420 6361 6e64 6c65 2074 696d 6520  ast candle time 
+00017270: 6173 206c 6173 7420 7265 6672 6573 6865  as last refreshe
+00017280: 6420 7469 6d65 206f 6620 7468 6520 7061  d time of the pa
+00017290: 6972 0a20 2020 2020 2020 2069 6620 7469  ir.        if ti
+000172a0: 636b 7320 616e 6420 6361 6368 653a 0a20  cks and cache:. 
+000172b0: 2020 2020 2020 2020 2020 2069 6478 203d             idx =
+000172c0: 202d 3220 6966 2064 726f 705f 696e 636f   -2 if drop_inco
+000172d0: 6d70 6c65 7465 2061 6e64 206c 656e 2874  mplete and len(t
+000172e0: 6963 6b73 2920 3e20 3120 656c 7365 202d  icks) > 1 else -
+000172f0: 310a 2020 2020 2020 2020 2020 2020 7365  1.            se
+00017300: 6c66 2e5f 7061 6972 735f 6c61 7374 5f72  lf._pairs_last_r
+00017310: 6566 7265 7368 5f74 696d 655b 2870 6169  efresh_time[(pai
+00017320: 722c 2074 696d 6566 7261 6d65 2c20 635f  r, timeframe, c_
+00017330: 7479 7065 295d 203d 2074 6963 6b73 5b69  type)] = ticks[i
+00017340: 6478 5d5b 305d 202f 2f20 3130 3030 0a20  dx][0] // 1000. 
+00017350: 2020 2020 2020 2023 206b 6565 7069 6e67         # keeping
+00017360: 2070 6172 7365 6420 6461 7461 6672 616d   parsed datafram
+00017370: 6520 696e 2063 6163 6865 0a20 2020 2020  e in cache.     
+00017380: 2020 206f 686c 6376 5f64 6620 3d20 6f68     ohlcv_df = oh
+00017390: 6c63 765f 746f 5f64 6174 6166 7261 6d65  lcv_to_dataframe
+000173a0: 280a 2020 2020 2020 2020 2020 2020 7469  (.            ti
+000173b0: 636b 732c 2074 696d 6566 7261 6d65 2c20  cks, timeframe, 
+000173c0: 7061 6972 3d70 6169 722c 2066 696c 6c5f  pair=pair, fill_
+000173d0: 6d69 7373 696e 673d 5472 7565 2c20 6472  missing=True, dr
+000173e0: 6f70 5f69 6e63 6f6d 706c 6574 653d 6472  op_incomplete=dr
+000173f0: 6f70 5f69 6e63 6f6d 706c 6574 650a 2020  op_incomplete.  
+00017400: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00017410: 6966 2063 6163 6865 3a0a 2020 2020 2020  if cache:.      
+00017420: 2020 2020 2020 6966 2028 7061 6972 2c20        if (pair, 
+00017430: 7469 6d65 6672 616d 652c 2063 5f74 7970  timeframe, c_typ
+00017440: 6529 2069 6e20 7365 6c66 2e5f 6b6c 696e  e) in self._klin
+00017450: 6573 3a0a 2020 2020 2020 2020 2020 2020  es:.            
+00017460: 2020 2020 6f6c 6420 3d20 7365 6c66 2e5f      old = self._
+00017470: 6b6c 696e 6573 5b28 7061 6972 2c20 7469  klines[(pair, ti
+00017480: 6d65 6672 616d 652c 2063 5f74 7970 6529  meframe, c_type)
+00017490: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+000174a0: 2020 2320 5265 6173 7369 676e 2073 6f20    # Reassign so 
+000174b0: 7765 2072 6574 7572 6e20 7468 6520 7570  we return the up
+000174c0: 6461 7465 642c 2063 6f6d 6269 6e65 6420  dated, combined 
+000174d0: 6466 0a20 2020 2020 2020 2020 2020 2020  df.             
+000174e0: 2020 206f 686c 6376 5f64 6620 3d20 636c     ohlcv_df = cl
+000174f0: 6561 6e5f 6f68 6c63 765f 6461 7461 6672  ean_ohlcv_datafr
+00017500: 616d 6528 0a20 2020 2020 2020 2020 2020  ame(.           
+00017510: 2020 2020 2020 2020 2063 6f6e 6361 7428           concat(
+00017520: 5b6f 6c64 2c20 6f68 6c63 765f 6466 5d2c  [old, ohlcv_df],
+00017530: 2061 7869 733d 3029 2c0a 2020 2020 2020   axis=0),.      
+00017540: 2020 2020 2020 2020 2020 2020 2020 7469                ti
+00017550: 6d65 6672 616d 652c 0a20 2020 2020 2020  meframe,.       
+00017560: 2020 2020 2020 2020 2020 2020 2070 6169               pai
+00017570: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
+00017580: 2020 2020 2020 2066 696c 6c5f 6d69 7373         fill_miss
+00017590: 696e 673d 5472 7565 2c0a 2020 2020 2020  ing=True,.      
+000175a0: 2020 2020 2020 2020 2020 2020 2020 6472                dr
+000175b0: 6f70 5f69 6e63 6f6d 706c 6574 653d 4661  op_incomplete=Fa
+000175c0: 6c73 652c 0a20 2020 2020 2020 2020 2020  lse,.           
+000175d0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+000175e0: 2020 2020 2020 2063 616e 646c 655f 6c69         candle_li
+000175f0: 6d69 7420 3d20 7365 6c66 2e6f 686c 6376  mit = self.ohlcv
+00017600: 5f63 616e 646c 655f 6c69 6d69 7428 7469  _candle_limit(ti
+00017610: 6d65 6672 616d 652c 2073 656c 662e 5f63  meframe, self._c
+00017620: 6f6e 6669 675b 2263 616e 646c 655f 7479  onfig["candle_ty
+00017630: 7065 5f64 6566 225d 290a 2020 2020 2020  pe_def"]).      
+00017640: 2020 2020 2020 2020 2020 2320 4167 6520            # Age 
+00017650: 6f75 7420 6f6c 6420 6361 6e64 6c65 730a  out old candles.
+00017660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017670: 6f68 6c63 765f 6466 203d 206f 686c 6376  ohlcv_df = ohlcv
+00017680: 5f64 662e 7461 696c 2863 616e 646c 655f  _df.tail(candle_
+00017690: 6c69 6d69 7420 2b20 7365 6c66 2e5f 7374  limit + self._st
+000176a0: 6172 7475 705f 6361 6e64 6c65 5f63 6f75  artup_candle_cou
+000176b0: 6e74 290a 2020 2020 2020 2020 2020 2020  nt).            
+000176c0: 2020 2020 6f68 6c63 765f 6466 203d 206f      ohlcv_df = o
+000176d0: 686c 6376 5f64 662e 7265 7365 745f 696e  hlcv_df.reset_in
+000176e0: 6465 7828 6472 6f70 3d54 7275 6529 0a20  dex(drop=True). 
+000176f0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00017700: 656c 662e 5f6b 6c69 6e65 735b 2870 6169  elf._klines[(pai
+00017710: 722c 2074 696d 6566 7261 6d65 2c20 635f  r, timeframe, c_
+00017720: 7479 7065 295d 203d 206f 686c 6376 5f64  type)] = ohlcv_d
+00017730: 660a 2020 2020 2020 2020 2020 2020 656c  f.            el
+00017740: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00017750: 2020 2020 7365 6c66 2e5f 6b6c 696e 6573      self._klines
+00017760: 5b28 7061 6972 2c20 7469 6d65 6672 616d  [(pair, timefram
+00017770: 652c 2063 5f74 7970 6529 5d20 3d20 6f68  e, c_type)] = oh
+00017780: 6c63 765f 6466 0a20 2020 2020 2020 2072  lcv_df.        r
+00017790: 6574 7572 6e20 6f68 6c63 765f 6466 0a0a  eturn ohlcv_df..
+000177a0: 2020 2020 6465 6620 7265 6672 6573 685f      def refresh_
+000177b0: 6c61 7465 7374 5f6f 686c 6376 280a 2020  latest_ohlcv(.  
+000177c0: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
+000177d0: 2020 2020 7061 6972 5f6c 6973 743a 204c      pair_list: L
+000177e0: 6973 7450 6169 7273 5769 7468 5469 6d65  istPairsWithTime
+000177f0: 6672 616d 6573 2c0a 2020 2020 2020 2020  frames,.        
+00017800: 2a2c 0a20 2020 2020 2020 2073 696e 6365  *,.        since
+00017810: 5f6d 733a 204f 7074 696f 6e61 6c5b 696e  _ms: Optional[in
+00017820: 745d 203d 204e 6f6e 652c 0a20 2020 2020  t] = None,.     
+00017830: 2020 2063 6163 6865 3a20 626f 6f6c 203d     cache: bool =
+00017840: 2054 7275 652c 0a20 2020 2020 2020 2064   True,.        d
+00017850: 726f 705f 696e 636f 6d70 6c65 7465 3a20  rop_incomplete: 
+00017860: 4f70 7469 6f6e 616c 5b62 6f6f 6c5d 203d  Optional[bool] =
+00017870: 204e 6f6e 652c 0a20 2020 2029 202d 3e20   None,.    ) -> 
+00017880: 4469 6374 5b50 6169 7257 6974 6854 696d  Dict[PairWithTim
+00017890: 6566 7261 6d65 2c20 4461 7461 4672 616d  eframe, DataFram
+000178a0: 655d 3a0a 2020 2020 2020 2020 2222 220a  e]:.        """.
+000178b0: 2020 2020 2020 2020 5265 6672 6573 6820          Refresh 
+000178c0: 696e 2d6d 656d 6f72 7920 4f48 4c43 5620  in-memory OHLCV 
+000178d0: 6173 796e 6368 726f 6e6f 7573 6c79 2061  asynchronously a
+000178e0: 6e64 2073 6574 2060 5f6b 6c69 6e65 7360  nd set `_klines`
+000178f0: 2077 6974 6820 7468 6520 7265 7375 6c74   with the result
+00017900: 0a20 2020 2020 2020 204c 6f6f 7073 2061  .        Loops a
+00017910: 7379 6e63 6872 6f6e 6f75 736c 7920 6f76  synchronously ov
+00017920: 6572 2070 6169 725f 6c69 7374 2061 6e64  er pair_list and
+00017930: 2064 6f77 6e6c 6f61 6473 2061 6c6c 2070   downloads all p
+00017940: 6169 7273 2061 7379 6e63 2028 7365 6d69  airs async (semi
+00017950: 2d70 6172 616c 6c65 6c29 2e0a 2020 2020  -parallel)..    
+00017960: 2020 2020 4f6e 6c79 2075 7365 6420 696e      Only used in
+00017970: 2074 6865 2064 6174 6170 726f 7669 6465   the dataprovide
+00017980: 722e 7265 6672 6573 6828 2920 6d65 7468  r.refresh() meth
+00017990: 6f64 2e0a 2020 2020 2020 2020 3a70 6172  od..        :par
+000179a0: 616d 2070 6169 725f 6c69 7374 3a20 4c69  am pair_list: Li
+000179b0: 7374 206f 6620 3220 656c 656d 656e 7420  st of 2 element 
+000179c0: 7475 706c 6573 2063 6f6e 7461 696e 696e  tuples containin
+000179d0: 6720 7061 6972 2c20 696e 7465 7276 616c  g pair, interval
+000179e0: 2074 6f20 7265 6672 6573 680a 2020 2020   to refresh.    
+000179f0: 2020 2020 3a70 6172 616d 2073 696e 6365      :param since
+00017a00: 5f6d 733a 2074 696d 6520 7369 6e63 6520  _ms: time since 
+00017a10: 7768 656e 2074 6f20 646f 776e 6c6f 6164  when to download
+00017a20: 2c20 696e 206d 696c 6c69 7365 636f 6e64  , in millisecond
+00017a30: 730a 2020 2020 2020 2020 3a70 6172 616d  s.        :param
+00017a40: 2063 6163 6865 3a20 4173 7369 676e 2072   cache: Assign r
+00017a50: 6573 756c 7420 746f 205f 6b6c 696e 6573  esult to _klines
+00017a60: 2e20 5573 6566 756c 2066 6f72 206f 6e65  . Useful for one
+00017a70: 2d6f 6666 2064 6f77 6e6c 6f61 6473 206c  -off downloads l
+00017a80: 696b 6520 666f 7220 7061 6972 6c69 7374  ike for pairlist
+00017a90: 730a 2020 2020 2020 2020 3a70 6172 616d  s.        :param
+00017aa0: 2064 726f 705f 696e 636f 6d70 6c65 7465   drop_incomplete
+00017ab0: 3a20 436f 6e74 726f 6c20 6361 6e64 6c65  : Control candle
+00017ac0: 2064 726f 7070 696e 672e 0a20 2020 2020   dropping..     
+00017ad0: 2020 2020 2020 2053 7065 6369 6679 696e         Specifyin
+00017ae0: 6720 4e6f 6e65 2064 6566 6175 6c74 7320  g None defaults 
+00017af0: 746f 205f 6f68 6c63 765f 7061 7274 6961  to _ohlcv_partia
+00017b00: 6c5f 6361 6e64 6c65 0a20 2020 2020 2020  l_candle.       
+00017b10: 203a 7265 7475 726e 3a20 4469 6374 206f   :return: Dict o
+00017b20: 6620 5b7b 2870 6169 722c 2074 696d 6566  f [{(pair, timef
+00017b30: 7261 6d65 293a 2044 6174 6166 7261 6d65  rame): Dataframe
+00017b40: 7d5d 0a20 2020 2020 2020 2022 2222 0a20  }].        """. 
+00017b50: 2020 2020 2020 206c 6f67 6765 722e 6465         logger.de
+00017b60: 6275 6728 2252 6566 7265 7368 696e 6720  bug("Refreshing 
+00017b70: 6361 6e64 6c65 2028 4f48 4c43 5629 2064  candle (OHLCV) d
+00017b80: 6174 6120 666f 7220 2564 2070 6169 7273  ata for %d pairs
+00017b90: 222c 206c 656e 2870 6169 725f 6c69 7374  ", len(pair_list
+00017ba0: 2929 0a0a 2020 2020 2020 2020 2320 4761  ))..        # Ga
+00017bb0: 7468 6572 2063 6f72 6f75 7469 6e65 7320  ther coroutines 
+00017bc0: 746f 2072 756e 0a20 2020 2020 2020 2069  to run.        i
+00017bd0: 6e70 7574 5f63 6f72 6f75 7469 6e65 732c  nput_coroutines,
+00017be0: 2063 6163 6865 645f 7061 6972 7320 3d20   cached_pairs = 
+00017bf0: 7365 6c66 2e5f 6275 696c 645f 6f68 6c63  self._build_ohlc
+00017c00: 765f 646c 5f6a 6f62 7328 7061 6972 5f6c  v_dl_jobs(pair_l
+00017c10: 6973 742c 2073 696e 6365 5f6d 732c 2063  ist, since_ms, c
+00017c20: 6163 6865 290a 0a20 2020 2020 2020 2072  ache)..        r
+00017c30: 6573 756c 7473 5f64 6620 3d20 7b7d 0a20  esults_df = {}. 
+00017c40: 2020 2020 2020 2023 2043 6875 6e6b 2072         # Chunk r
+00017c50: 6571 7565 7374 7320 696e 746f 2062 6174  equests into bat
+00017c60: 6368 6573 206f 6620 3130 3020 746f 2061  ches of 100 to a
+00017c70: 766f 6964 206f 7665 7277 6865 6c6d 696e  void overwhelmin
+00017c80: 6720 6363 7874 2054 6872 6f74 746c 696e  g ccxt Throttlin
+00017c90: 670a 2020 2020 2020 2020 666f 7220 696e  g.        for in
+00017ca0: 7075 745f 636f 726f 2069 6e20 6368 756e  put_coro in chun
+00017cb0: 6b73 2869 6e70 7574 5f63 6f72 6f75 7469  ks(input_corouti
+00017cc0: 6e65 732c 2031 3030 293a 0a0a 2020 2020  nes, 100):..    
+00017cd0: 2020 2020 2020 2020 6173 796e 6320 6465          async de
+00017ce0: 6620 6761 7468 6572 5f73 7475 6666 2863  f gather_stuff(c
+00017cf0: 6f72 6f29 3a0a 2020 2020 2020 2020 2020  oro):.          
+00017d00: 2020 2020 2020 7265 7475 726e 2061 7761        return awa
+00017d10: 6974 2061 7379 6e63 696f 2e67 6174 6865  it asyncio.gathe
+00017d20: 7228 2a63 6f72 6f2c 2072 6574 7572 6e5f  r(*coro, return_
+00017d30: 6578 6365 7074 696f 6e73 3d54 7275 6529  exceptions=True)
+00017d40: 0a0a 2020 2020 2020 2020 2020 2020 7769  ..            wi
+00017d50: 7468 2073 656c 662e 5f6c 6f6f 705f 6c6f  th self._loop_lo
+00017d60: 636b 3a0a 2020 2020 2020 2020 2020 2020  ck:.            
+00017d70: 2020 2020 7265 7375 6c74 7320 3d20 7365      results = se
+00017d80: 6c66 2e6c 6f6f 702e 7275 6e5f 756e 7469  lf.loop.run_unti
+00017d90: 6c5f 636f 6d70 6c65 7465 2867 6174 6865  l_complete(gathe
+00017da0: 725f 7374 7566 6628 696e 7075 745f 636f  r_stuff(input_co
+00017db0: 726f 2929 0a0a 2020 2020 2020 2020 2020  ro))..          
+00017dc0: 2020 666f 7220 7265 7320 696e 2072 6573    for res in res
+00017dd0: 756c 7473 3a0a 2020 2020 2020 2020 2020  ults:.          
+00017de0: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+00017df0: 6e63 6528 7265 732c 2045 7863 6570 7469  nce(res, Excepti
+00017e00: 6f6e 293a 0a20 2020 2020 2020 2020 2020  on):.           
+00017e10: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+00017e20: 7761 726e 696e 6728 6622 4173 796e 6320  warning(f"Async 
+00017e30: 636f 6465 2072 6169 7365 6420 616e 2065  code raised an e
+00017e40: 7863 6570 7469 6f6e 3a20 7b72 6570 7228  xception: {repr(
+00017e50: 7265 7329 7d22 290a 2020 2020 2020 2020  res)}").        
+00017e60: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+00017e70: 696e 7565 0a20 2020 2020 2020 2020 2020  inue.           
+00017e80: 2020 2020 2023 2044 6563 6f6e 7374 7275       # Deconstru
+00017e90: 6374 2074 7570 6c65 2028 6861 7320 3520  ct tuple (has 5 
+00017ea0: 656c 656d 656e 7473 290a 2020 2020 2020  elements).      
+00017eb0: 2020 2020 2020 2020 2020 7061 6972 2c20            pair, 
+00017ec0: 7469 6d65 6672 616d 652c 2063 5f74 7970  timeframe, c_typ
+00017ed0: 652c 2074 6963 6b73 2c20 6472 6f70 5f68  e, ticks, drop_h
+00017ee0: 696e 7420 3d20 7265 730a 2020 2020 2020  int = res.      
+00017ef0: 2020 2020 2020 2020 2020 6472 6f70 5f69            drop_i
+00017f00: 6e63 6f6d 706c 6574 655f 203d 2064 726f  ncomplete_ = dro
+00017f10: 705f 6869 6e74 2069 6620 6472 6f70 5f69  p_hint if drop_i
+00017f20: 6e63 6f6d 706c 6574 6520 6973 204e 6f6e  ncomplete is Non
+00017f30: 6520 656c 7365 2064 726f 705f 696e 636f  e else drop_inco
+00017f40: 6d70 6c65 7465 0a20 2020 2020 2020 2020  mplete.         
+00017f50: 2020 2020 2020 206f 686c 6376 5f64 6620         ohlcv_df 
+00017f60: 3d20 7365 6c66 2e5f 7072 6f63 6573 735f  = self._process_
+00017f70: 6f68 6c63 765f 6466 280a 2020 2020 2020  ohlcv_df(.      
+00017f80: 2020 2020 2020 2020 2020 2020 2020 7061                pa
+00017f90: 6972 2c20 7469 6d65 6672 616d 652c 2063  ir, timeframe, c
+00017fa0: 5f74 7970 652c 2074 6963 6b73 2c20 6361  _type, ticks, ca
+00017fb0: 6368 652c 2064 726f 705f 696e 636f 6d70  che, drop_incomp
+00017fc0: 6c65 7465 5f0a 2020 2020 2020 2020 2020  lete_.          
 00017fd0: 2020 2020 2020 290a 0a20 2020 2020 2020        )..       
-00017fe0: 2072 6574 7572 6e20 7265 7375 6c74 735f   return results_
-00017ff0: 6466 0a0a 2020 2020 6465 6620 7265 6672  df..    def refr
-00018000: 6573 685f 6f68 6c63 765f 7769 7468 5f63  esh_ohlcv_with_c
-00018010: 6163 6865 280a 2020 2020 2020 2020 7365  ache(.        se
-00018020: 6c66 2c0a 2020 2020 2020 2020 7061 6972  lf,.        pair
-00018030: 733a 204c 6973 745b 5061 6972 5769 7468  s: List[PairWith
-00018040: 5469 6d65 6672 616d 655d 2c0a 2020 2020  Timeframe],.    
-00018050: 2020 2020 7369 6e63 655f 6d73 3a20 696e      since_ms: in
-00018060: 740a 2020 2020 2920 2d3e 2044 6963 745b  t.    ) -> Dict[
-00018070: 5061 6972 5769 7468 5469 6d65 6672 616d  PairWithTimefram
-00018080: 652c 2044 6174 6146 7261 6d65 5d3a 0a20  e, DataFrame]:. 
-00018090: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-000180a0: 2020 2052 6566 7265 7368 206f 686c 6376     Refresh ohlcv
-000180b0: 2064 6174 6120 666f 7220 616c 6c20 7061   data for all pa
-000180c0: 6972 7320 696e 206e 6565 6465 645f 7061  irs in needed_pa
-000180d0: 6972 7320 6966 206e 6563 6573 7361 7279  irs if necessary
-000180e0: 2e0a 2020 2020 2020 2020 4361 6368 6573  ..        Caches
-000180f0: 2064 6174 6120 7769 7468 2065 7870 6972   data with expir
-00018100: 696e 6720 7065 7220 7469 6d65 6672 616d  ing per timefram
-00018110: 652e 0a20 2020 2020 2020 2053 686f 756c  e..        Shoul
-00018120: 6420 6f6e 6c79 2062 6520 7573 6564 2066  d only be used f
-00018130: 6f72 2070 6169 726c 6973 7473 2077 6869  or pairlists whi
-00018140: 6368 206e 6565 6420 226f 6e20 7469 6d65  ch need "on time
-00018150: 2220 6578 7069 7261 7269 6f6e 2c20 616e  " expirarion, an
-00018160: 6420 6e6f 206c 6f6e 6765 7220 6361 6368  d no longer cach
-00018170: 652e 0a20 2020 2020 2020 2022 2222 0a0a  e..        """..
-00018180: 2020 2020 2020 2020 7469 6d65 6672 616d          timefram
-00018190: 6573 203d 207b 705b 315d 2066 6f72 2070  es = {p[1] for p
-000181a0: 2069 6e20 7061 6972 737d 0a20 2020 2020   in pairs}.     
-000181b0: 2020 2066 6f72 2074 696d 6566 7261 6d65     for timeframe
-000181c0: 2069 6e20 7469 6d65 6672 616d 6573 3a0a   in timeframes:.
-000181d0: 2020 2020 2020 2020 2020 2020 6966 2028              if (
-000181e0: 7469 6d65 6672 616d 652c 2073 696e 6365  timeframe, since
-000181f0: 5f6d 7329 206e 6f74 2069 6e20 7365 6c66  _ms) not in self
-00018200: 2e5f 6578 7069 7269 6e67 5f63 616e 646c  ._expiring_candl
-00018210: 655f 6361 6368 653a 0a20 2020 2020 2020  e_cache:.       
-00018220: 2020 2020 2020 2020 2074 696d 6566 7261           timefra
-00018230: 6d65 5f69 6e5f 7365 6320 3d20 7469 6d65  me_in_sec = time
-00018240: 6672 616d 655f 746f 5f73 6563 6f6e 6473  frame_to_seconds
-00018250: 2874 696d 6566 7261 6d65 290a 2020 2020  (timeframe).    
-00018260: 2020 2020 2020 2020 2020 2020 2320 496e              # In
-00018270: 6974 6961 6c69 7365 2063 6163 6865 0a20  itialise cache. 
-00018280: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00018290: 656c 662e 5f65 7870 6972 696e 675f 6361  elf._expiring_ca
-000182a0: 6e64 6c65 5f63 6163 6865 5b28 7469 6d65  ndle_cache[(time
-000182b0: 6672 616d 652c 2073 696e 6365 5f6d 7329  frame, since_ms)
-000182c0: 5d20 3d20 5065 7269 6f64 6963 4361 6368  ] = PeriodicCach
-000182d0: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
-000182e0: 2020 2020 2020 2074 746c 3d74 696d 6566         ttl=timef
-000182f0: 7261 6d65 5f69 6e5f 7365 632c 206d 6178  rame_in_sec, max
-00018300: 7369 7a65 3d31 3030 3029 0a0a 2020 2020  size=1000)..    
-00018310: 2020 2020 2320 4765 7420 6361 6e64 6c65      # Get candle
-00018320: 7320 6672 6f6d 2063 6163 6865 0a20 2020  s from cache.   
-00018330: 2020 2020 2063 616e 646c 6573 203d 207b       candles = {
-00018340: 0a20 2020 2020 2020 2020 2020 2063 3a20  .            c: 
-00018350: 7365 6c66 2e5f 6578 7069 7269 6e67 5f63  self._expiring_c
-00018360: 616e 646c 655f 6361 6368 655b 2863 5b31  andle_cache[(c[1
-00018370: 5d2c 2073 696e 6365 5f6d 7329 5d2e 6765  ], since_ms)].ge
-00018380: 7428 632c 204e 6f6e 6529 2066 6f72 2063  t(c, None) for c
-00018390: 2069 6e20 7061 6972 730a 2020 2020 2020   in pairs.      
-000183a0: 2020 2020 2020 6966 2063 2069 6e20 7365        if c in se
-000183b0: 6c66 2e5f 6578 7069 7269 6e67 5f63 616e  lf._expiring_can
-000183c0: 646c 655f 6361 6368 655b 2863 5b31 5d2c  dle_cache[(c[1],
-000183d0: 2073 696e 6365 5f6d 7329 5d0a 2020 2020   since_ms)].    
-000183e0: 2020 2020 7d0a 2020 2020 2020 2020 7061      }.        pa
-000183f0: 6972 735f 746f 5f64 6f77 6e6c 6f61 6420  irs_to_download 
-00018400: 3d20 5b70 2066 6f72 2070 2069 6e20 7061  = [p for p in pa
-00018410: 6972 7320 6966 2070 206e 6f74 2069 6e20  irs if p not in 
-00018420: 6361 6e64 6c65 735d 0a20 2020 2020 2020  candles].       
-00018430: 2069 6620 7061 6972 735f 746f 5f64 6f77   if pairs_to_dow
-00018440: 6e6c 6f61 643a 0a20 2020 2020 2020 2020  nload:.         
-00018450: 2020 2063 616e 646c 6573 203d 2073 656c     candles = sel
-00018460: 662e 7265 6672 6573 685f 6c61 7465 7374  f.refresh_latest
-00018470: 5f6f 686c 6376 280a 2020 2020 2020 2020  _ohlcv(.        
-00018480: 2020 2020 2020 2020 7061 6972 735f 746f          pairs_to
-00018490: 5f64 6f77 6e6c 6f61 642c 2073 696e 6365  _download, since
-000184a0: 5f6d 733d 7369 6e63 655f 6d73 2c20 6361  _ms=since_ms, ca
-000184b0: 6368 653d 4661 6c73 650a 2020 2020 2020  che=False.      
-000184c0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-000184d0: 2020 2020 666f 7220 632c 2076 616c 2069      for c, val i
-000184e0: 6e20 6361 6e64 6c65 732e 6974 656d 7328  n candles.items(
-000184f0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00018500: 2020 2073 656c 662e 5f65 7870 6972 696e     self._expirin
-00018510: 675f 6361 6e64 6c65 5f63 6163 6865 5b28  g_candle_cache[(
-00018520: 635b 315d 2c20 7369 6e63 655f 6d73 295d  c[1], since_ms)]
-00018530: 5b63 5d20 3d20 7661 6c0a 2020 2020 2020  [c] = val.      
-00018540: 2020 7265 7475 726e 2063 616e 646c 6573    return candles
-00018550: 0a0a 2020 2020 6465 6620 5f6e 6f77 5f69  ..    def _now_i
-00018560: 735f 7469 6d65 5f74 6f5f 7265 6672 6573  s_time_to_refres
-00018570: 6828 7365 6c66 2c20 7061 6972 3a20 7374  h(self, pair: st
-00018580: 722c 2074 696d 6566 7261 6d65 3a20 7374  r, timeframe: st
-00018590: 722c 2063 616e 646c 655f 7479 7065 3a20  r, candle_type: 
-000185a0: 4361 6e64 6c65 5479 7065 2920 2d3e 2062  CandleType) -> b
-000185b0: 6f6f 6c3a 0a20 2020 2020 2020 2023 2054  ool:.        # T
-000185c0: 696d 6566 7261 6d65 2069 6e20 7365 636f  imeframe in seco
-000185d0: 6e64 730a 2020 2020 2020 2020 696e 7465  nds.        inte
-000185e0: 7276 616c 5f69 6e5f 7365 6320 3d20 7469  rval_in_sec = ti
-000185f0: 6d65 6672 616d 655f 746f 5f73 6563 6f6e  meframe_to_secon
-00018600: 6473 2874 696d 6566 7261 6d65 290a 2020  ds(timeframe).  
-00018610: 2020 2020 2020 706c 7220 3d20 7365 6c66        plr = self
-00018620: 2e5f 7061 6972 735f 6c61 7374 5f72 6566  ._pairs_last_ref
-00018630: 7265 7368 5f74 696d 652e 6765 7428 2870  resh_time.get((p
-00018640: 6169 722c 2074 696d 6566 7261 6d65 2c20  air, timeframe, 
-00018650: 6361 6e64 6c65 5f74 7970 6529 2c20 3029  candle_type), 0)
-00018660: 202b 2069 6e74 6572 7661 6c5f 696e 5f73   + interval_in_s
-00018670: 6563 0a20 2020 2020 2020 2023 2063 7572  ec.        # cur
-00018680: 7265 6e74 2c61 6374 6976 6520 6361 6e64  rent,active cand
-00018690: 6c65 206f 7065 6e20 6461 7465 0a20 2020  le open date.   
-000186a0: 2020 2020 206e 6f77 203d 2069 6e74 2874       now = int(t
-000186b0: 696d 6566 7261 6d65 5f74 6f5f 7072 6576  imeframe_to_prev
-000186c0: 5f64 6174 6528 7469 6d65 6672 616d 6529  _date(timeframe)
-000186d0: 2e74 696d 6573 7461 6d70 2829 290a 2020  .timestamp()).  
-000186e0: 2020 2020 2020 7265 7475 726e 2070 6c72        return plr
-000186f0: 203c 206e 6f77 0a0a 2020 2020 4072 6574   < now..    @ret
-00018700: 7269 6572 5f61 7379 6e63 0a20 2020 2061  rier_async.    a
-00018710: 7379 6e63 2064 6566 205f 6173 796e 635f  sync def _async_
-00018720: 6765 745f 6361 6e64 6c65 5f68 6973 746f  get_candle_histo
-00018730: 7279 280a 2020 2020 2020 2020 7365 6c66  ry(.        self
-00018740: 2c0a 2020 2020 2020 2020 7061 6972 3a20  ,.        pair: 
-00018750: 7374 722c 0a20 2020 2020 2020 2074 696d  str,.        tim
-00018760: 6566 7261 6d65 3a20 7374 722c 0a20 2020  eframe: str,.   
-00018770: 2020 2020 2063 616e 646c 655f 7479 7065       candle_type
-00018780: 3a20 4361 6e64 6c65 5479 7065 2c0a 2020  : CandleType,.  
-00018790: 2020 2020 2020 7369 6e63 655f 6d73 3a20        since_ms: 
-000187a0: 4f70 7469 6f6e 616c 5b69 6e74 5d20 3d20  Optional[int] = 
-000187b0: 4e6f 6e65 2c0a 2020 2020 2920 2d3e 204f  None,.    ) -> O
-000187c0: 484c 4356 5265 7370 6f6e 7365 3a0a 2020  HLCVResponse:.  
-000187d0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-000187e0: 2020 4173 796e 6368 726f 6e6f 7573 6c79    Asynchronously
-000187f0: 2067 6574 2063 616e 646c 6520 6869 7374   get candle hist
-00018800: 6f72 7920 6461 7461 2075 7369 6e67 2066  ory data using f
-00018810: 6574 6368 5f6f 686c 6376 0a20 2020 2020  etch_ohlcv.     
-00018820: 2020 203a 7061 7261 6d20 6361 6e64 6c65     :param candle
-00018830: 5f74 7970 653a 2027 272c 206d 6172 6b2c  _type: '', mark,
-00018840: 2069 6e64 6578 2c20 7072 656d 6975 6d49   index, premiumI
-00018850: 6e64 6578 2c20 6f72 2066 756e 6469 6e67  ndex, or funding
-00018860: 5f72 6174 650a 2020 2020 2020 2020 7265  _rate.        re
-00018870: 7475 726e 7320 7475 706c 653a 2028 7061  turns tuple: (pa
-00018880: 6972 2c20 7469 6d65 6672 616d 652c 206f  ir, timeframe, o
-00018890: 686c 6376 5f6c 6973 7429 0a20 2020 2020  hlcv_list).     
-000188a0: 2020 2022 2222 0a20 2020 2020 2020 2074     """.        t
-000188b0: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
-000188c0: 2320 4665 7463 6820 4f48 4c43 5620 6173  # Fetch OHLCV as
-000188d0: 796e 6368 726f 6e6f 7573 6c79 0a20 2020  ynchronously.   
-000188e0: 2020 2020 2020 2020 2073 203d 2027 2827           s = '('
-000188f0: 202b 2064 745f 6672 6f6d 5f74 7328 7369   + dt_from_ts(si
-00018900: 6e63 655f 6d73 292e 6973 6f66 6f72 6d61  nce_ms).isoforma
-00018910: 7428 2920 2b20 2729 2027 2069 6620 7369  t() + ') ' if si
-00018920: 6e63 655f 6d73 2069 7320 6e6f 7420 4e6f  nce_ms is not No
-00018930: 6e65 2065 6c73 6520 2727 0a20 2020 2020  ne else ''.     
-00018940: 2020 2020 2020 206c 6f67 6765 722e 6465         logger.de
-00018950: 6275 6728 0a20 2020 2020 2020 2020 2020  bug(.           
-00018960: 2020 2020 2022 4665 7463 6869 6e67 2070       "Fetching p
-00018970: 6169 7220 2573 2c20 2573 2c20 696e 7465  air %s, %s, inte
-00018980: 7276 616c 2025 732c 2073 696e 6365 2025  rval %s, since %
-00018990: 7320 2573 2e2e 2e22 2c0a 2020 2020 2020  s %s...",.      
-000189a0: 2020 2020 2020 2020 2020 7061 6972 2c20            pair, 
-000189b0: 6361 6e64 6c65 5f74 7970 652c 2074 696d  candle_type, tim
-000189c0: 6566 7261 6d65 2c20 7369 6e63 655f 6d73  eframe, since_ms
-000189d0: 2c20 730a 2020 2020 2020 2020 2020 2020  , s.            
-000189e0: 290a 2020 2020 2020 2020 2020 2020 7061  ).            pa
-000189f0: 7261 6d73 203d 2064 6565 7063 6f70 7928  rams = deepcopy(
-00018a00: 7365 6c66 2e5f 6674 5f68 6173 2e67 6574  self._ft_has.get
-00018a10: 2827 6f68 6c63 765f 7061 7261 6d73 272c  ('ohlcv_params',
-00018a20: 207b 7d29 290a 2020 2020 2020 2020 2020   {})).          
-00018a30: 2020 6361 6e64 6c65 5f6c 696d 6974 203d    candle_limit =
-00018a40: 2073 656c 662e 6f68 6c63 765f 6361 6e64   self.ohlcv_cand
-00018a50: 6c65 5f6c 696d 6974 280a 2020 2020 2020  le_limit(.      
-00018a60: 2020 2020 2020 2020 2020 7469 6d65 6672            timefr
-00018a70: 616d 652c 2063 616e 646c 655f 7479 7065  ame, candle_type
-00018a80: 3d63 616e 646c 655f 7479 7065 2c20 7369  =candle_type, si
-00018a90: 6e63 655f 6d73 3d73 696e 6365 5f6d 7329  nce_ms=since_ms)
-00018aa0: 0a0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00018ab0: 2063 616e 646c 655f 7479 7065 2061 6e64   candle_type and
-00018ac0: 2063 616e 646c 655f 7479 7065 2021 3d20   candle_type != 
-00018ad0: 4361 6e64 6c65 5479 7065 2e53 504f 543a  CandleType.SPOT:
-00018ae0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018af0: 2070 6172 616d 732e 7570 6461 7465 287b   params.update({
-00018b00: 2770 7269 6365 273a 2063 616e 646c 655f  'price': candle_
-00018b10: 7479 7065 2e76 616c 7565 7d29 0a20 2020  type.value}).   
-00018b20: 2020 2020 2020 2020 2069 6620 6361 6e64           if cand
-00018b30: 6c65 5f74 7970 6520 213d 2043 616e 646c  le_type != Candl
-00018b40: 6554 7970 652e 4655 4e44 494e 475f 5241  eType.FUNDING_RA
-00018b50: 5445 3a0a 2020 2020 2020 2020 2020 2020  TE:.            
-00018b60: 2020 2020 6461 7461 203d 2061 7761 6974      data = await
-00018b70: 2073 656c 662e 5f61 7069 5f61 7379 6e63   self._api_async
-00018b80: 2e66 6574 6368 5f6f 686c 6376 280a 2020  .fetch_ohlcv(.  
-00018b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018ba0: 2020 7061 6972 2c20 7469 6d65 6672 616d    pair, timefram
-00018bb0: 653d 7469 6d65 6672 616d 652c 2073 696e  e=timeframe, sin
-00018bc0: 6365 3d73 696e 6365 5f6d 732c 0a20 2020  ce=since_ms,.   
-00018bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018be0: 206c 696d 6974 3d63 616e 646c 655f 6c69   limit=candle_li
-00018bf0: 6d69 742c 2070 6172 616d 733d 7061 7261  mit, params=para
-00018c00: 6d73 290a 2020 2020 2020 2020 2020 2020  ms).            
-00018c10: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00018c20: 2020 2020 2020 2320 4675 6e64 696e 6720        # Funding 
-00018c30: 7261 7465 0a20 2020 2020 2020 2020 2020  rate.           
-00018c40: 2020 2020 2064 6174 6120 3d20 6177 6169       data = awai
-00018c50: 7420 7365 6c66 2e5f 6665 7463 685f 6675  t self._fetch_fu
-00018c60: 6e64 696e 675f 7261 7465 5f68 6973 746f  nding_rate_histo
-00018c70: 7279 280a 2020 2020 2020 2020 2020 2020  ry(.            
-00018c80: 2020 2020 2020 2020 7061 6972 3d70 6169          pair=pai
-00018c90: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
-00018ca0: 2020 2020 2020 2074 696d 6566 7261 6d65         timeframe
-00018cb0: 3d74 696d 6566 7261 6d65 2c0a 2020 2020  =timeframe,.    
-00018cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018cd0: 6c69 6d69 743d 6361 6e64 6c65 5f6c 696d  limit=candle_lim
-00018ce0: 6974 2c0a 2020 2020 2020 2020 2020 2020  it,.            
-00018cf0: 2020 2020 2020 2020 7369 6e63 655f 6d73          since_ms
-00018d00: 3d73 696e 6365 5f6d 732c 0a20 2020 2020  =since_ms,.     
-00018d10: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
-00018d20: 2020 2020 2020 2020 2023 2053 6f6d 6520           # Some 
-00018d30: 6578 6368 616e 6765 7320 736f 7274 204f  exchanges sort O
-00018d40: 484c 4356 2069 6e20 4153 4320 6f72 6465  HLCV in ASC orde
-00018d50: 7220 616e 6420 6f74 6865 7273 2069 6e20  r and others in 
-00018d60: 4445 5343 2e0a 2020 2020 2020 2020 2020  DESC..          
-00018d70: 2020 2320 4578 3a20 4269 7474 7265 7820    # Ex: Bittrex 
-00018d80: 7265 7475 726e 7320 7468 6520 6c69 7374  returns the list
-00018d90: 206f 6620 4f48 4c43 5620 696e 2041 5343   of OHLCV in ASC
-00018da0: 206f 7264 6572 2028 6f6c 6465 7374 2066   order (oldest f
-00018db0: 6972 7374 2c20 6e65 7765 7374 206c 6173  irst, newest las
-00018dc0: 7429 0a20 2020 2020 2020 2020 2020 2023  t).            #
-00018dd0: 2077 6869 6c65 2047 4441 5820 7265 7475   while GDAX retu
-00018de0: 726e 7320 7468 6520 6c69 7374 206f 6620  rns the list of 
-00018df0: 4f48 4c43 5620 696e 2044 4553 4320 6f72  OHLCV in DESC or
-00018e00: 6465 7220 286e 6577 6573 7420 6669 7273  der (newest firs
-00018e10: 742c 206f 6c64 6573 7420 6c61 7374 290a  t, oldest last).
-00018e20: 2020 2020 2020 2020 2020 2020 2320 4f6e              # On
-00018e30: 6c79 2073 6f72 7420 6966 206e 6563 6573  ly sort if neces
-00018e40: 7361 7279 2074 6f20 7361 7665 2063 6f6d  sary to save com
-00018e50: 7075 7469 6e67 2074 696d 650a 2020 2020  puting time.    
-00018e60: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
-00018e70: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00018e80: 6461 7461 2061 6e64 2064 6174 615b 305d  data and data[0]
-00018e90: 5b30 5d20 3e20 6461 7461 5b2d 315d 5b30  [0] > data[-1][0
-00018ea0: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
-00018eb0: 2020 2020 2020 2064 6174 6120 3d20 736f         data = so
-00018ec0: 7274 6564 2864 6174 612c 206b 6579 3d6c  rted(data, key=l
-00018ed0: 616d 6264 6120 783a 2078 5b30 5d29 0a20  ambda x: x[0]). 
-00018ee0: 2020 2020 2020 2020 2020 2065 7863 6570             excep
-00018ef0: 7420 496e 6465 7845 7272 6f72 3a0a 2020  t IndexError:.  
-00018f00: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-00018f10: 6767 6572 2e65 7863 6570 7469 6f6e 2822  gger.exception("
-00018f20: 4572 726f 7220 6c6f 6164 696e 6720 2573  Error loading %s
-00018f30: 2e20 5265 7375 6c74 2077 6173 2025 732e  . Result was %s.
-00018f40: 222c 2070 6169 722c 2064 6174 6129 0a20  ", pair, data). 
-00018f50: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00018f60: 6574 7572 6e20 7061 6972 2c20 7469 6d65  eturn pair, time
-00018f70: 6672 616d 652c 2063 616e 646c 655f 7479  frame, candle_ty
-00018f80: 7065 2c20 5b5d 2c20 7365 6c66 2e5f 6f68  pe, [], self._oh
-00018f90: 6c63 765f 7061 7274 6961 6c5f 6361 6e64  lcv_partial_cand
-00018fa0: 6c65 0a20 2020 2020 2020 2020 2020 206c  le.            l
-00018fb0: 6f67 6765 722e 6465 6275 6728 2244 6f6e  ogger.debug("Don
-00018fc0: 6520 6665 7463 6869 6e67 2070 6169 7220  e fetching pair 
-00018fd0: 2573 2c20 2573 2069 6e74 6572 7661 6c20  %s, %s interval 
-00018fe0: 2573 2e2e 2e22 2c20 7061 6972 2c20 6361  %s...", pair, ca
-00018ff0: 6e64 6c65 5f74 7970 652c 2074 696d 6566  ndle_type, timef
-00019000: 7261 6d65 290a 2020 2020 2020 2020 2020  rame).          
-00019010: 2020 7265 7475 726e 2070 6169 722c 2074    return pair, t
-00019020: 696d 6566 7261 6d65 2c20 6361 6e64 6c65  imeframe, candle
-00019030: 5f74 7970 652c 2064 6174 612c 2073 656c  _type, data, sel
-00019040: 662e 5f6f 686c 6376 5f70 6172 7469 616c  f._ohlcv_partial
-00019050: 5f63 616e 646c 650a 0a20 2020 2020 2020  _candle..       
-00019060: 2065 7863 6570 7420 6363 7874 2e4e 6f74   except ccxt.Not
-00019070: 5375 7070 6f72 7465 6420 6173 2065 3a0a  Supported as e:.
-00019080: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00019090: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
-000190a0: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
-000190b0: 2020 2020 2020 2020 6627 4578 6368 616e          f'Exchan
-000190c0: 6765 207b 7365 6c66 2e5f 6170 692e 6e61  ge {self._api.na
-000190d0: 6d65 7d20 646f 6573 206e 6f74 2073 7570  me} does not sup
-000190e0: 706f 7274 2066 6574 6368 696e 6720 6869  port fetching hi
-000190f0: 7374 6f72 6963 616c 2027 0a20 2020 2020  storical '.     
-00019100: 2020 2020 2020 2020 2020 2066 2763 616e             f'can
-00019110: 646c 6520 284f 484c 4356 2920 6461 7461  dle (OHLCV) data
-00019120: 2e20 4d65 7373 6167 653a 207b 657d 2729  . Message: {e}')
-00019130: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
-00019140: 6578 6365 7074 2063 6378 742e 4444 6f53  except ccxt.DDoS
-00019150: 5072 6f74 6563 7469 6f6e 2061 7320 653a  Protection as e:
-00019160: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-00019170: 7365 2044 446f 7350 726f 7465 6374 696f  se DDosProtectio
-00019180: 6e28 6529 2066 726f 6d20 650a 2020 2020  n(e) from e.    
-00019190: 2020 2020 6578 6365 7074 2028 6363 7874      except (ccxt
-000191a0: 2e4f 7065 7261 7469 6f6e 4661 696c 6564  .OperationFailed
-000191b0: 2c20 6363 7874 2e45 7863 6861 6e67 6545  , ccxt.ExchangeE
-000191c0: 7272 6f72 2920 6173 2065 3a0a 2020 2020  rror) as e:.    
-000191d0: 2020 2020 2020 2020 7261 6973 6520 5465          raise Te
-000191e0: 6d70 6f72 6172 7945 7272 6f72 2866 2743  mporaryError(f'C
-000191f0: 6f75 6c64 206e 6f74 2066 6574 6368 2068  ould not fetch h
-00019200: 6973 746f 7269 6361 6c20 6361 6e64 6c65  istorical candle
-00019210: 2028 4f48 4c43 5629 2064 6174 6120 270a   (OHLCV) data '.
-00019220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019240: 2066 2766 6f72 2070 6169 7220 7b70 6169   f'for pair {pai
-00019250: 727d 2064 7565 2074 6f20 7b65 2e5f 5f63  r} due to {e.__c
-00019260: 6c61 7373 5f5f 2e5f 5f6e 616d 655f 5f7d  lass__.__name__}
-00019270: 2e20 270a 2020 2020 2020 2020 2020 2020  . '.            
-00019280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019290: 2020 2020 2066 274d 6573 7361 6765 3a20       f'Message: 
-000192a0: 7b65 7d27 2920 6672 6f6d 2065 0a20 2020  {e}') from e.   
-000192b0: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
-000192c0: 2e42 6173 6545 7272 6f72 2061 7320 653a  .BaseError as e:
-000192d0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-000192e0: 7365 204f 7065 7261 7469 6f6e 616c 4578  se OperationalEx
-000192f0: 6365 7074 696f 6e28 6627 436f 756c 6420  ception(f'Could 
-00019300: 6e6f 7420 6665 7463 6820 6869 7374 6f72  not fetch histor
-00019310: 6963 616c 2063 616e 646c 6520 284f 484c  ical candle (OHL
-00019320: 4356 2920 6461 7461 2027 0a20 2020 2020  CV) data '.     
-00019330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019350: 2020 6627 666f 7220 7061 6972 207b 7061    f'for pair {pa
-00019360: 6972 7d2e 204d 6573 7361 6765 3a20 7b65  ir}. Message: {e
-00019370: 7d27 2920 6672 6f6d 2065 0a0a 2020 2020  }') from e..    
-00019380: 6173 796e 6320 6465 6620 5f66 6574 6368  async def _fetch
-00019390: 5f66 756e 6469 6e67 5f72 6174 655f 6869  _funding_rate_hi
-000193a0: 7374 6f72 7928 0a20 2020 2020 2020 2073  story(.        s
-000193b0: 656c 662c 0a20 2020 2020 2020 2070 6169  elf,.        pai
-000193c0: 723a 2073 7472 2c0a 2020 2020 2020 2020  r: str,.        
-000193d0: 7469 6d65 6672 616d 653a 2073 7472 2c0a  timeframe: str,.
-000193e0: 2020 2020 2020 2020 6c69 6d69 743a 2069          limit: i
-000193f0: 6e74 2c0a 2020 2020 2020 2020 7369 6e63  nt,.        sinc
-00019400: 655f 6d73 3a20 4f70 7469 6f6e 616c 5b69  e_ms: Optional[i
-00019410: 6e74 5d20 3d20 4e6f 6e65 2c0a 2020 2020  nt] = None,.    
-00019420: 2920 2d3e 204c 6973 745b 4c69 7374 5d3a  ) -> List[List]:
-00019430: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00019440: 2020 2020 2046 6574 6368 2066 756e 6469       Fetch fundi
-00019450: 6e67 2072 6174 6520 6869 7374 6f72 7920  ng rate history 
-00019460: 2d20 7573 6564 2074 6f20 7365 6c65 6374  - used to select
-00019470: 6976 656c 7920 6f76 6572 7269 6465 2074  ively override t
-00019480: 6869 7320 6279 2073 7562 636c 6173 7365  his by subclasse
-00019490: 732e 0a20 2020 2020 2020 2022 2222 0a20  s..        """. 
-000194a0: 2020 2020 2020 2023 2046 756e 6469 6e67         # Funding
-000194b0: 2072 6174 650a 2020 2020 2020 2020 6461   rate.        da
-000194c0: 7461 203d 2061 7761 6974 2073 656c 662e  ta = await self.
-000194d0: 5f61 7069 5f61 7379 6e63 2e66 6574 6368  _api_async.fetch
-000194e0: 5f66 756e 6469 6e67 5f72 6174 655f 6869  _funding_rate_hi
-000194f0: 7374 6f72 7928 0a20 2020 2020 2020 2020  story(.         
-00019500: 2020 2070 6169 722c 2073 696e 6365 3d73     pair, since=s
-00019510: 696e 6365 5f6d 732c 0a20 2020 2020 2020  ince_ms,.       
-00019520: 2020 2020 206c 696d 6974 3d6c 696d 6974       limit=limit
-00019530: 290a 2020 2020 2020 2020 2320 436f 6e76  ).        # Conv
-00019540: 6572 7420 6675 6e64 696e 6720 7261 7465  ert funding rate
-00019550: 2074 6f20 6361 6e64 6c65 2070 6174 7465   to candle patte
-00019560: 726e 0a20 2020 2020 2020 2064 6174 6120  rn.        data 
-00019570: 3d20 5b5b 785b 2774 696d 6573 7461 6d70  = [[x['timestamp
-00019580: 275d 2c20 785b 2766 756e 6469 6e67 5261  '], x['fundingRa
-00019590: 7465 275d 2c20 302c 2030 2c20 302c 2030  te'], 0, 0, 0, 0
-000195a0: 5d20 666f 7220 7820 696e 2064 6174 615d  ] for x in data]
-000195b0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000195c0: 6461 7461 0a0a 2020 2020 2320 4665 7463  data..    # Fetc
-000195d0: 6820 6869 7374 6f72 6963 2074 7261 6465  h historic trade
-000195e0: 730a 0a20 2020 2040 7265 7472 6965 725f  s..    @retrier_
-000195f0: 6173 796e 630a 2020 2020 6173 796e 6320  async.    async 
-00019600: 6465 6620 5f61 7379 6e63 5f66 6574 6368  def _async_fetch
-00019610: 5f74 7261 6465 7328 7365 6c66 2c20 7061  _trades(self, pa
-00019620: 6972 3a20 7374 722c 0a20 2020 2020 2020  ir: str,.       
-00019630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019640: 2020 2020 2020 2020 2020 2073 696e 6365             since
-00019650: 3a20 4f70 7469 6f6e 616c 5b69 6e74 5d20  : Optional[int] 
-00019660: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-00019670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019680: 2020 2020 2020 2020 2020 7061 7261 6d73            params
-00019690: 3a20 4f70 7469 6f6e 616c 5b64 6963 745d  : Optional[dict]
-000196a0: 203d 204e 6f6e 6529 202d 3e20 5475 706c   = None) -> Tupl
-000196b0: 655b 4c69 7374 5b4c 6973 745d 2c20 416e  e[List[List], An
-000196c0: 795d 3a0a 2020 2020 2020 2020 2222 220a  y]:.        """.
-000196d0: 2020 2020 2020 2020 4173 796e 6368 726f          Asynchro
-000196e0: 6e6f 7573 6c79 2067 6574 7320 7472 6164  nously gets trad
-000196f0: 6520 6869 7374 6f72 7920 7573 696e 6720  e history using 
-00019700: 6665 7463 685f 7472 6164 6573 2e0a 2020  fetch_trades..  
-00019710: 2020 2020 2020 4861 6e64 6c65 7320 6578        Handles ex
-00019720: 6368 616e 6765 2065 7272 6f72 732c 2064  change errors, d
-00019730: 6f65 7320 6f6e 6520 6361 6c6c 2074 6f20  oes one call to 
-00019740: 7468 6520 6578 6368 616e 6765 2e0a 2020  the exchange..  
-00019750: 2020 2020 2020 3a70 6172 616d 2070 6169        :param pai
-00019760: 723a 2050 6169 7220 746f 2066 6574 6368  r: Pair to fetch
-00019770: 2074 7261 6465 2064 6174 6120 666f 720a   trade data for.
-00019780: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
-00019790: 696e 6365 3a20 5369 6e63 6520 6173 2069  ince: Since as i
-000197a0: 6e74 6567 6572 2074 696d 6573 7461 6d70  nteger timestamp
-000197b0: 2069 6e20 6d69 6c6c 6973 6563 6f6e 6473   in milliseconds
-000197c0: 0a20 2020 2020 2020 2072 6574 7572 6e73  .        returns
-000197d0: 3a20 4c69 7374 206f 6620 6469 6374 7320  : List of dicts 
-000197e0: 636f 6e74 6169 6e69 6e67 2074 7261 6465  containing trade
-000197f0: 732c 2074 6865 206e 6578 7420 6974 6572  s, the next iter
-00019800: 6174 696f 6e20 7661 6c75 6520 286e 6577  ation value (new
-00019810: 2022 7369 6e63 6522 206f 7220 7472 6164   "since" or trad
-00019820: 655f 6964 290a 2020 2020 2020 2020 2222  e_id).        ""
-00019830: 220a 2020 2020 2020 2020 7472 793a 0a20  ".        try:. 
-00019840: 2020 2020 2020 2020 2020 2023 2066 6574             # fet
-00019850: 6368 2074 7261 6465 7320 6173 796e 6368  ch trades asynch
-00019860: 726f 6e6f 7573 6c79 0a20 2020 2020 2020  ronously.       
-00019870: 2020 2020 2069 6620 7061 7261 6d73 3a0a       if params:.
-00019880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019890: 6c6f 6767 6572 2e64 6562 7567 2822 4665  logger.debug("Fe
-000198a0: 7463 6869 6e67 2074 7261 6465 7320 666f  tching trades fo
-000198b0: 7220 7061 6972 2025 732c 2070 6172 616d  r pair %s, param
-000198c0: 733a 2025 7320 222c 2070 6169 722c 2070  s: %s ", pair, p
-000198d0: 6172 616d 7329 0a20 2020 2020 2020 2020  arams).         
-000198e0: 2020 2020 2020 2074 7261 6465 7320 3d20         trades = 
-000198f0: 6177 6169 7420 7365 6c66 2e5f 6170 695f  await self._api_
-00019900: 6173 796e 632e 6665 7463 685f 7472 6164  async.fetch_trad
-00019910: 6573 2870 6169 722c 2070 6172 616d 733d  es(pair, params=
-00019920: 7061 7261 6d73 2c20 6c69 6d69 743d 3130  params, limit=10
-00019930: 3030 290a 2020 2020 2020 2020 2020 2020  00).            
-00019940: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00019950: 2020 2020 2020 6c6f 6767 6572 2e64 6562        logger.deb
-00019960: 7567 280a 2020 2020 2020 2020 2020 2020  ug(.            
-00019970: 2020 2020 2020 2020 2246 6574 6368 696e          "Fetchin
-00019980: 6720 7472 6164 6573 2066 6f72 2070 6169  g trades for pai
-00019990: 7220 2573 2c20 7369 6e63 6520 2573 2025  r %s, since %s %
-000199a0: 732e 2e2e 222c 0a20 2020 2020 2020 2020  s...",.         
-000199b0: 2020 2020 2020 2020 2020 2070 6169 722c             pair,
-000199c0: 2073 696e 6365 2c0a 2020 2020 2020 2020   since,.        
-000199d0: 2020 2020 2020 2020 2020 2020 2728 2720              '(' 
-000199e0: 2b20 6474 5f66 726f 6d5f 7473 2873 696e  + dt_from_ts(sin
-000199f0: 6365 292e 6973 6f66 6f72 6d61 7428 2920  ce).isoformat() 
-00019a00: 2b20 2729 2027 2069 6620 7369 6e63 6520  + ') ' if since 
-00019a10: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
-00019a20: 2027 270a 2020 2020 2020 2020 2020 2020   ''.            
-00019a30: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-00019a40: 2020 2020 2020 7472 6164 6573 203d 2061        trades = a
-00019a50: 7761 6974 2073 656c 662e 5f61 7069 5f61  wait self._api_a
-00019a60: 7379 6e63 2e66 6574 6368 5f74 7261 6465  sync.fetch_trade
-00019a70: 7328 7061 6972 2c20 7369 6e63 653d 7369  s(pair, since=si
-00019a80: 6e63 652c 206c 696d 6974 3d31 3030 3029  nce, limit=1000)
-00019a90: 0a20 2020 2020 2020 2020 2020 2074 7261  .            tra
-00019aa0: 6465 7320 3d20 7365 6c66 2e5f 7472 6164  des = self._trad
-00019ab0: 6573 5f63 6f6e 7472 6163 7473 5f74 6f5f  es_contracts_to_
-00019ac0: 616d 6f75 6e74 2874 7261 6465 7329 0a20  amount(trades). 
-00019ad0: 2020 2020 2020 2020 2020 2070 6167 696e             pagin
-00019ae0: 6174 696f 6e5f 7661 6c75 6520 3d20 7365  ation_value = se
-00019af0: 6c66 2e5f 6765 745f 7472 6164 655f 7061  lf._get_trade_pa
-00019b00: 6769 6e61 7469 6f6e 5f6e 6578 745f 7661  gination_next_va
-00019b10: 6c75 6528 7472 6164 6573 290a 2020 2020  lue(trades).    
-00019b20: 2020 2020 2020 2020 7265 7475 726e 2074          return t
-00019b30: 7261 6465 735f 6469 6374 5f74 6f5f 6c69  rades_dict_to_li
-00019b40: 7374 2874 7261 6465 7329 2c20 7061 6769  st(trades), pagi
-00019b50: 6e61 7469 6f6e 5f76 616c 7565 0a20 2020  nation_value.   
-00019b60: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
-00019b70: 2e4e 6f74 5375 7070 6f72 7465 6420 6173  .NotSupported as
-00019b80: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-00019b90: 7261 6973 6520 4f70 6572 6174 696f 6e61  raise Operationa
-00019ba0: 6c45 7863 6570 7469 6f6e 280a 2020 2020  lException(.    
-00019bb0: 2020 2020 2020 2020 2020 2020 6627 4578              f'Ex
-00019bc0: 6368 616e 6765 207b 7365 6c66 2e5f 6170  change {self._ap
-00019bd0: 692e 6e61 6d65 7d20 646f 6573 206e 6f74  i.name} does not
-00019be0: 2073 7570 706f 7274 2066 6574 6368 696e   support fetchin
-00019bf0: 6720 6869 7374 6f72 6963 616c 2074 7261  g historical tra
-00019c00: 6465 2064 6174 612e 270a 2020 2020 2020  de data.'.      
-00019c10: 2020 2020 2020 2020 2020 6627 4d65 7373            f'Mess
-00019c20: 6167 653a 207b 657d 2729 2066 726f 6d20  age: {e}') from 
-00019c30: 650a 2020 2020 2020 2020 6578 6365 7074  e.        except
-00019c40: 2063 6378 742e 4444 6f53 5072 6f74 6563   ccxt.DDoSProtec
-00019c50: 7469 6f6e 2061 7320 653a 0a20 2020 2020  tion as e:.     
-00019c60: 2020 2020 2020 2072 6169 7365 2044 446f         raise DDo
-00019c70: 7350 726f 7465 6374 696f 6e28 6529 2066  sProtection(e) f
-00019c80: 726f 6d20 650a 2020 2020 2020 2020 6578  rom e.        ex
-00019c90: 6365 7074 2028 6363 7874 2e4f 7065 7261  cept (ccxt.Opera
-00019ca0: 7469 6f6e 4661 696c 6564 2c20 6363 7874  tionFailed, ccxt
-00019cb0: 2e45 7863 6861 6e67 6545 7272 6f72 2920  .ExchangeError) 
-00019cc0: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
-00019cd0: 2020 7261 6973 6520 5465 6d70 6f72 6172    raise Temporar
-00019ce0: 7945 7272 6f72 2866 2743 6f75 6c64 206e  yError(f'Could n
-00019cf0: 6f74 206c 6f61 6420 7472 6164 6520 6869  ot load trade hi
-00019d00: 7374 6f72 7920 6475 6520 746f 207b 652e  story due to {e.
-00019d10: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
-00019d20: 5f5f 7d2e 2027 0a20 2020 2020 2020 2020  __}. '.         
-00019d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019d40: 2020 2020 2020 2020 6627 4d65 7373 6167          f'Messag
-00019d50: 653a 207b 657d 2729 2066 726f 6d20 650a  e: {e}') from e.
-00019d60: 2020 2020 2020 2020 6578 6365 7074 2063          except c
-00019d70: 6378 742e 4261 7365 4572 726f 7220 6173  cxt.BaseError as
-00019d80: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-00019d90: 7261 6973 6520 4f70 6572 6174 696f 6e61  raise Operationa
-00019da0: 6c45 7863 6570 7469 6f6e 2866 2743 6f75  lException(f'Cou
-00019db0: 6c64 206e 6f74 2066 6574 6368 2074 7261  ld not fetch tra
-00019dc0: 6465 2064 6174 612e 204d 7367 3a20 7b65  de data. Msg: {e
-00019dd0: 7d27 2920 6672 6f6d 2065 0a0a 2020 2020  }') from e..    
-00019de0: 6465 6620 5f76 616c 6964 5f74 7261 6465  def _valid_trade
-00019df0: 5f70 6167 696e 6174 696f 6e5f 6964 2873  _pagination_id(s
-00019e00: 656c 662c 2070 6169 723a 2073 7472 2c20  elf, pair: str, 
-00019e10: 6672 6f6d 5f69 643a 2073 7472 2920 2d3e  from_id: str) ->
-00019e20: 2062 6f6f 6c3a 0a20 2020 2020 2020 2022   bool:.        "
-00019e30: 2222 0a20 2020 2020 2020 2056 6572 6966  "".        Verif
-00019e40: 7920 7472 6164 652d 7061 6769 6e61 7469  y trade-paginati
-00019e50: 6f6e 2069 6420 6973 2076 616c 6964 2e0a  on id is valid..
-00019e60: 2020 2020 2020 2020 576f 726b 6172 6f75          Workarou
-00019e70: 6e64 2066 6f72 206f 6464 204b 7261 6b65  nd for odd Krake
-00019e80: 6e20 6973 7375 6520 7768 6572 6520 4944  n issue where ID
-00019e90: 2069 7320 736f 6d65 7469 6d65 7320 7772   is sometimes wr
-00019ea0: 6f6e 672e 0a20 2020 2020 2020 2022 2222  ong..        """
-00019eb0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00019ec0: 5472 7565 0a0a 2020 2020 6465 6620 5f67  True..    def _g
-00019ed0: 6574 5f74 7261 6465 5f70 6167 696e 6174  et_trade_paginat
-00019ee0: 696f 6e5f 6e65 7874 5f76 616c 7565 2873  ion_next_value(s
-00019ef0: 656c 662c 2074 7261 6465 733a 204c 6973  elf, trades: Lis
-00019f00: 745b 4469 6374 5d29 3a0a 2020 2020 2020  t[Dict]):.      
-00019f10: 2020 2222 220a 2020 2020 2020 2020 4578    """.        Ex
-00019f20: 7472 6163 7420 7061 6769 6e61 7469 6f6e  tract pagination
-00019f30: 2069 6420 666f 7220 7468 6520 6e65 7874   id for the next
-00019f40: 2022 6672 6f6d 5f69 6422 2076 616c 7565   "from_id" value
-00019f50: 0a20 2020 2020 2020 2041 7070 6c69 6573  .        Applies
-00019f60: 206f 6e6c 7920 746f 2066 6574 6368 5f74   only to fetch_t
-00019f70: 7261 6465 5f68 6973 746f 7279 2062 7920  rade_history by 
-00019f80: 6964 2e0a 2020 2020 2020 2020 2222 220a  id..        """.
-00019f90: 2020 2020 2020 2020 6966 206e 6f74 2074          if not t
-00019fa0: 7261 6465 733a 0a20 2020 2020 2020 2020  rades:.         
-00019fb0: 2020 2072 6574 7572 6e20 4e6f 6e65 0a20     return None. 
-00019fc0: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
-00019fd0: 7472 6164 6573 5f70 6167 696e 6174 696f  trades_paginatio
-00019fe0: 6e20 3d3d 2027 6964 273a 0a20 2020 2020  n == 'id':.     
-00019ff0: 2020 2020 2020 2072 6574 7572 6e20 7472         return tr
-0001a000: 6164 6573 5b2d 315d 2e67 6574 2827 6964  ades[-1].get('id
-0001a010: 2729 0a20 2020 2020 2020 2065 6c73 653a  ').        else:
-0001a020: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0001a030: 7572 6e20 7472 6164 6573 5b2d 315d 2e67  urn trades[-1].g
-0001a040: 6574 2827 7469 6d65 7374 616d 7027 290a  et('timestamp').
-0001a050: 0a20 2020 2061 7379 6e63 2064 6566 205f  .    async def _
-0001a060: 6173 796e 635f 6765 745f 7472 6164 655f  async_get_trade_
-0001a070: 6869 7374 6f72 795f 6964 2873 656c 662c  history_id(self,
-0001a080: 2070 6169 723a 2073 7472 2c0a 2020 2020   pair: str,.    
-0001a090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a0b0: 2020 2020 2020 756e 7469 6c3a 2069 6e74        until: int
-0001a0c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0001a0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a0e0: 2020 2020 2020 2020 2020 2020 7369 6e63              sinc
-0001a0f0: 653a 204f 7074 696f 6e61 6c5b 696e 745d  e: Optional[int]
-0001a100: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0001a110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a130: 2020 2066 726f 6d5f 6964 3a20 4f70 7469     from_id: Opti
-0001a140: 6f6e 616c 5b73 7472 5d20 3d20 4e6f 6e65  onal[str] = None
-0001a150: 2920 2d3e 2054 7570 6c65 5b73 7472 2c20  ) -> Tuple[str, 
-0001a160: 4c69 7374 5b4c 6973 745d 5d3a 0a20 2020  List[List]]:.   
-0001a170: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0001a180: 2041 7379 6e63 6872 6f6e 6f75 736c 7920   Asynchronously 
-0001a190: 6765 7473 2074 7261 6465 2068 6973 746f  gets trade histo
-0001a1a0: 7279 2075 7369 6e67 2066 6574 6368 5f74  ry using fetch_t
-0001a1b0: 7261 6465 730a 2020 2020 2020 2020 7573  rades.        us
-0001a1c0: 6520 7468 6973 2077 6865 6e20 6578 6368  e this when exch
-0001a1d0: 616e 6765 2075 7365 7320 6964 2d62 6173  ange uses id-bas
-0001a1e0: 6564 2069 7465 7261 7469 6f6e 2028 6368  ed iteration (ch
-0001a1f0: 6563 6b20 6073 656c 662e 5f74 7261 6465  eck `self._trade
-0001a200: 735f 7061 6769 6e61 7469 6f6e 6029 0a20  s_pagination`). 
-0001a210: 2020 2020 2020 203a 7061 7261 6d20 7061         :param pa
-0001a220: 6972 3a20 5061 6972 2074 6f20 6665 7463  ir: Pair to fetc
-0001a230: 6820 7472 6164 6520 6461 7461 2066 6f72  h trade data for
-0001a240: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0001a250: 7369 6e63 653a 2053 696e 6365 2061 7320  since: Since as 
-0001a260: 696e 7465 6765 7220 7469 6d65 7374 616d  integer timestam
-0001a270: 7020 696e 206d 696c 6c69 7365 636f 6e64  p in millisecond
-0001a280: 730a 2020 2020 2020 2020 3a70 6172 616d  s.        :param
-0001a290: 2075 6e74 696c 3a20 556e 7469 6c20 6173   until: Until as
-0001a2a0: 2069 6e74 6567 6572 2074 696d 6573 7461   integer timesta
-0001a2b0: 6d70 2069 6e20 6d69 6c6c 6973 6563 6f6e  mp in millisecon
-0001a2c0: 6473 0a20 2020 2020 2020 203a 7061 7261  ds.        :para
-0001a2d0: 6d20 6672 6f6d 5f69 643a 2044 6f77 6e6c  m from_id: Downl
-0001a2e0: 6f61 6420 6461 7461 2073 7461 7274 696e  oad data startin
-0001a2f0: 6720 7769 7468 2049 4420 2869 6620 6964  g with ID (if id
-0001a300: 2069 7320 6b6e 6f77 6e29 2e20 4967 6e6f   is known). Igno
-0001a310: 7265 7320 2273 696e 6365 2220 6966 2073  res "since" if s
-0001a320: 6574 2e0a 2020 2020 2020 2020 7265 7475  et..        retu
-0001a330: 726e 7320 7475 706c 653a 2028 7061 6972  rns tuple: (pair
-0001a340: 2c20 7472 6164 6573 2d6c 6973 7429 0a20  , trades-list). 
-0001a350: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-0001a360: 2020 2020 7472 6164 6573 3a20 4c69 7374      trades: List
-0001a370: 5b4c 6973 745d 203d 205b 5d0a 2020 2020  [List] = [].    
-0001a380: 2020 2020 2320 4445 4641 554c 545f 5452      # DEFAULT_TR
-0001a390: 4144 4553 5f43 4f4c 554d 4e53 3a20 3020  ADES_COLUMNS: 0 
-0001a3a0: 2d3e 2074 696d 6573 7461 6d70 0a20 2020  -> timestamp.   
-0001a3b0: 2020 2020 2023 2044 4546 4155 4c54 5f54       # DEFAULT_T
-0001a3c0: 5241 4445 535f 434f 4c55 4d4e 533a 2031  RADES_COLUMNS: 1
-0001a3d0: 202d 3e20 6964 0a20 2020 2020 2020 2068   -> id.        h
-0001a3e0: 6173 5f6f 7665 726c 6170 203d 2073 656c  as_overlap = sel
-0001a3f0: 662e 5f66 745f 6861 732e 6765 7428 2774  f._ft_has.get('t
-0001a400: 7261 6465 735f 7061 6769 6e61 7469 6f6e  rades_pagination
-0001a410: 5f6f 7665 726c 6170 272c 2054 7275 6529  _overlap', True)
-0001a420: 0a20 2020 2020 2020 2023 2053 6b69 7020  .        # Skip 
-0001a430: 6c61 7374 2074 7261 6465 2062 7920 6465  last trade by de
-0001a440: 6661 756c 7420 7369 6e63 6520 6974 7320  fault since its 
-0001a450: 7468 6520 6b65 7920 666f 7220 7468 6520  the key for the 
-0001a460: 6e65 7874 2063 616c 6c0a 2020 2020 2020  next call.      
-0001a470: 2020 7820 3d20 736c 6963 6528 4e6f 6e65    x = slice(None
-0001a480: 2c20 2d31 2920 6966 2068 6173 5f6f 7665  , -1) if has_ove
-0001a490: 726c 6170 2065 6c73 6520 736c 6963 6528  rlap else slice(
-0001a4a0: 4e6f 6e65 290a 0a20 2020 2020 2020 2069  None)..        i
-0001a4b0: 6620 6e6f 7420 6672 6f6d 5f69 6420 6f72  f not from_id or
-0001a4c0: 206e 6f74 2073 656c 662e 5f76 616c 6964   not self._valid
-0001a4d0: 5f74 7261 6465 5f70 6167 696e 6174 696f  _trade_paginatio
-0001a4e0: 6e5f 6964 2870 6169 722c 2066 726f 6d5f  n_id(pair, from_
-0001a4f0: 6964 293a 0a20 2020 2020 2020 2020 2020  id):.           
-0001a500: 2023 2046 6574 6368 2066 6972 7374 2065   # Fetch first e
-0001a510: 6c65 6d65 6e74 7320 7573 696e 6720 7469  lements using ti
-0001a520: 6d65 6261 7365 6420 6d65 7468 6f64 2074  mebased method t
-0001a530: 6f20 6765 7420 616e 2049 4420 746f 2070  o get an ID to p
-0001a540: 6167 696e 6174 6520 6f6e 0a20 2020 2020  aginate on.     
-0001a550: 2020 2020 2020 2023 2044 6570 656e 6469         # Dependi
-0001a560: 6e67 206f 6e20 7468 6520 4578 6368 616e  ng on the Exchan
-0001a570: 6765 2c20 7468 6973 2063 616e 2069 6e74  ge, this can int
-0001a580: 726f 6475 6365 2061 2064 7269 6674 2061  roduce a drift a
-0001a590: 7420 7468 6520 7374 6172 7420 6f66 2074  t the start of t
-0001a5a0: 6865 2069 6e74 6572 7661 6c0a 2020 2020  he interval.    
-0001a5b0: 2020 2020 2020 2020 2320 6f66 2075 7020          # of up 
-0001a5c0: 746f 2061 6e20 686f 7572 2e0a 2020 2020  to an hour..    
-0001a5d0: 2020 2020 2020 2020 2320 652e 672e 2042          # e.g. B
-0001a5e0: 696e 616e 6365 2072 6574 7572 6e73 2074  inance returns t
-0001a5f0: 6865 2022 6c61 7374 2031 3030 3022 2063  he "last 1000" c
-0001a600: 616e 646c 6573 2077 6974 6869 6e20 6120  andles within a 
-0001a610: 3168 2074 696d 6520 696e 7465 7276 616c  1h time interval
-0001a620: 0a20 2020 2020 2020 2020 2020 2023 202d  .            # -
-0001a630: 2073 6f20 7765 2077 696c 6c20 6d69 7373   so we will miss
-0001a640: 2074 6865 2066 6972 7374 2074 7261 6465   the first trade
-0001a650: 732e 0a20 2020 2020 2020 2020 2020 2074  s..            t
-0001a660: 2c20 6672 6f6d 5f69 6420 3d20 6177 6169  , from_id = awai
-0001a670: 7420 7365 6c66 2e5f 6173 796e 635f 6665  t self._async_fe
-0001a680: 7463 685f 7472 6164 6573 2870 6169 722c  tch_trades(pair,
-0001a690: 2073 696e 6365 3d73 696e 6365 290a 2020   since=since).  
-0001a6a0: 2020 2020 2020 2020 2020 7472 6164 6573            trades
-0001a6b0: 2e65 7874 656e 6428 745b 785d 290a 2020  .extend(t[x]).  
-0001a6c0: 2020 2020 2020 7768 696c 6520 5472 7565        while True
-0001a6d0: 3a0a 2020 2020 2020 2020 2020 2020 7472  :.            tr
-0001a6e0: 793a 0a20 2020 2020 2020 2020 2020 2020  y:.             
-0001a6f0: 2020 2074 2c20 6672 6f6d 5f69 645f 6e65     t, from_id_ne
-0001a700: 7874 203d 2061 7761 6974 2073 656c 662e  xt = await self.
-0001a710: 5f61 7379 6e63 5f66 6574 6368 5f74 7261  _async_fetch_tra
-0001a720: 6465 7328 0a20 2020 2020 2020 2020 2020  des(.           
-0001a730: 2020 2020 2020 2020 2070 6169 722c 2070           pair, p
-0001a740: 6172 616d 733d 7b73 656c 662e 5f74 7261  arams={self._tra
-0001a750: 6465 735f 7061 6769 6e61 7469 6f6e 5f61  des_pagination_a
-0001a760: 7267 3a20 6672 6f6d 5f69 647d 290a 2020  rg: from_id}).  
-0001a770: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0001a780: 2074 3a0a 2020 2020 2020 2020 2020 2020   t:.            
-0001a790: 2020 2020 2020 2020 7472 6164 6573 2e65          trades.e
-0001a7a0: 7874 656e 6428 745b 785d 290a 2020 2020  xtend(t[x]).    
-0001a7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a7c0: 6966 2066 726f 6d5f 6964 203d 3d20 6672  if from_id == fr
-0001a7d0: 6f6d 5f69 645f 6e65 7874 206f 7220 745b  om_id_next or t[
-0001a7e0: 2d31 5d5b 305d 203e 2075 6e74 696c 3a0a  -1][0] > until:.
-0001a7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a800: 2020 2020 2020 2020 6c6f 6767 6572 2e64          logger.d
-0001a810: 6562 7567 2866 2253 746f 7070 696e 6720  ebug(f"Stopping 
-0001a820: 6265 6361 7573 6520 6672 6f6d 5f69 6420  because from_id 
-0001a830: 6469 6420 6e6f 7420 6368 616e 6765 2e20  did not change. 
-0001a840: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0001a850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a860: 2020 2020 2020 2066 2252 6561 6368 6564         f"Reached
-0001a870: 207b 745b 2d31 5d5b 305d 7d20 3e20 7b75   {t[-1][0]} > {u
-0001a880: 6e74 696c 7d22 290a 2020 2020 2020 2020  ntil}").        
-0001a890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a8a0: 2320 5265 6163 6865 6420 7468 6520 656e  # Reached the en
-0001a8b0: 6420 6f66 2074 6865 2064 6566 696e 6564  d of the defined
-0001a8c0: 2d64 6f77 6e6c 6f61 6420 7065 7269 6f64  -download period
-0001a8d0: 202d 2061 6464 206c 6173 7420 7472 6164   - add last trad
-0001a8e0: 6520 6173 2077 656c 6c2e 0a20 2020 2020  e as well..     
-0001a8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a900: 2020 2069 6620 6861 735f 6f76 6572 6c61     if has_overla
-0001a910: 703a 0a20 2020 2020 2020 2020 2020 2020  p:.             
-0001a920: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-0001a930: 7261 6465 732e 6578 7465 6e64 2874 5b2d  rades.extend(t[-
-0001a940: 313a 5d29 0a20 2020 2020 2020 2020 2020  1:]).           
-0001a950: 2020 2020 2020 2020 2020 2020 2062 7265               bre
-0001a960: 616b 0a0a 2020 2020 2020 2020 2020 2020  ak..            
-0001a970: 2020 2020 2020 2020 6672 6f6d 5f69 6420          from_id 
-0001a980: 3d20 6672 6f6d 5f69 645f 6e65 7874 0a20  = from_id_next. 
-0001a990: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0001a9a0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0001a9b0: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
-0001a9c0: 6465 6275 6728 2253 746f 7070 696e 6720  debug("Stopping 
-0001a9d0: 6173 206e 6f20 6d6f 7265 2074 7261 6465  as no more trade
-0001a9e0: 7320 7765 7265 2072 6574 7572 6e65 642e  s were returned.
-0001a9f0: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
-0001aa00: 2020 2020 2020 2062 7265 616b 0a20 2020         break.   
-0001aa10: 2020 2020 2020 2020 2065 7863 6570 7420           except 
-0001aa20: 6173 796e 6369 6f2e 4361 6e63 656c 6c65  asyncio.Cancelle
-0001aa30: 6445 7272 6f72 3a0a 2020 2020 2020 2020  dError:.        
-0001aa40: 2020 2020 2020 2020 6c6f 6767 6572 2e64          logger.d
-0001aa50: 6562 7567 2822 4173 796e 6320 6f70 6572  ebug("Async oper
-0001aa60: 6174 696f 6e20 496e 7465 7272 7570 7465  ation Interrupte
-0001aa70: 642c 2062 7265 616b 696e 6720 7472 6164  d, breaking trad
-0001aa80: 6573 2044 4c20 6c6f 6f70 2e22 290a 2020  es DL loop.").  
-0001aa90: 2020 2020 2020 2020 2020 2020 2020 6272                br
-0001aaa0: 6561 6b0a 0a20 2020 2020 2020 2072 6574  eak..        ret
-0001aab0: 7572 6e20 2870 6169 722c 2074 7261 6465  urn (pair, trade
-0001aac0: 7329 0a0a 2020 2020 6173 796e 6320 6465  s)..    async de
-0001aad0: 6620 5f61 7379 6e63 5f67 6574 5f74 7261  f _async_get_tra
-0001aae0: 6465 5f68 6973 746f 7279 5f74 696d 6528  de_history_time(
-0001aaf0: 7365 6c66 2c20 7061 6972 3a20 7374 722c  self, pair: str,
-0001ab00: 2075 6e74 696c 3a20 696e 742c 0a20 2020   until: int,.   
-0001ab10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ab20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ab30: 2020 2020 2020 2020 2073 696e 6365 3a20           since: 
-0001ab40: 4f70 7469 6f6e 616c 5b69 6e74 5d20 3d20  Optional[int] = 
-0001ab50: 4e6f 6e65 2920 2d3e 2054 7570 6c65 5b73  None) -> Tuple[s
-0001ab60: 7472 2c20 4c69 7374 5b4c 6973 745d 5d3a  tr, List[List]]:
-0001ab70: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-0001ab80: 2020 2020 2041 7379 6e63 6872 6f6e 6f75       Asynchronou
-0001ab90: 736c 7920 6765 7473 2074 7261 6465 2068  sly gets trade h
-0001aba0: 6973 746f 7279 2075 7369 6e67 2066 6574  istory using fet
-0001abb0: 6368 5f74 7261 6465 732c 0a20 2020 2020  ch_trades,.     
-0001abc0: 2020 2077 6865 6e20 7468 6520 6578 6368     when the exch
-0001abd0: 616e 6765 2075 7365 7320 7469 6d65 2d62  ange uses time-b
-0001abe0: 6173 6564 2069 7465 7261 7469 6f6e 2028  ased iteration (
-0001abf0: 6368 6563 6b20 6073 656c 662e 5f74 7261  check `self._tra
-0001ac00: 6465 735f 7061 6769 6e61 7469 6f6e 6029  des_pagination`)
-0001ac10: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0001ac20: 7061 6972 3a20 5061 6972 2074 6f20 6665  pair: Pair to fe
-0001ac30: 7463 6820 7472 6164 6520 6461 7461 2066  tch trade data f
-0001ac40: 6f72 0a20 2020 2020 2020 203a 7061 7261  or.        :para
-0001ac50: 6d20 7369 6e63 653a 2053 696e 6365 2061  m since: Since a
-0001ac60: 7320 696e 7465 6765 7220 7469 6d65 7374  s integer timest
-0001ac70: 616d 7020 696e 206d 696c 6c69 7365 636f  amp in milliseco
-0001ac80: 6e64 730a 2020 2020 2020 2020 3a70 6172  nds.        :par
-0001ac90: 616d 2075 6e74 696c 3a20 556e 7469 6c20  am until: Until 
-0001aca0: 6173 2069 6e74 6567 6572 2074 696d 6573  as integer times
-0001acb0: 7461 6d70 2069 6e20 6d69 6c6c 6973 6563  tamp in millisec
-0001acc0: 6f6e 6473 0a20 2020 2020 2020 2072 6574  onds.        ret
-0001acd0: 7572 6e73 2074 7570 6c65 3a20 2870 6169  urns tuple: (pai
-0001ace0: 722c 2074 7261 6465 732d 6c69 7374 290a  r, trades-list).
-0001acf0: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
-0001ad00: 2020 2020 2074 7261 6465 733a 204c 6973       trades: Lis
-0001ad10: 745b 4c69 7374 5d20 3d20 5b5d 0a20 2020  t[List] = [].   
-0001ad20: 2020 2020 2023 2044 4546 4155 4c54 5f54       # DEFAULT_T
-0001ad30: 5241 4445 535f 434f 4c55 4d4e 533a 2030  RADES_COLUMNS: 0
-0001ad40: 202d 3e20 7469 6d65 7374 616d 700a 2020   -> timestamp.  
-0001ad50: 2020 2020 2020 2320 4445 4641 554c 545f        # DEFAULT_
-0001ad60: 5452 4144 4553 5f43 4f4c 554d 4e53 3a20  TRADES_COLUMNS: 
-0001ad70: 3120 2d3e 2069 640a 2020 2020 2020 2020  1 -> id.        
-0001ad80: 7768 696c 6520 5472 7565 3a0a 2020 2020  while True:.    
-0001ad90: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
-0001ada0: 2020 2020 2020 2020 2020 2020 2074 2c20               t, 
-0001adb0: 7369 6e63 655f 6e65 7874 203d 2061 7761  since_next = awa
-0001adc0: 6974 2073 656c 662e 5f61 7379 6e63 5f66  it self._async_f
-0001add0: 6574 6368 5f74 7261 6465 7328 7061 6972  etch_trades(pair
-0001ade0: 2c20 7369 6e63 653d 7369 6e63 6529 0a20  , since=since). 
-0001adf0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0001ae00: 6620 743a 0a20 2020 2020 2020 2020 2020  f t:.           
-0001ae10: 2020 2020 2020 2020 2023 204e 6f20 6d6f           # No mo
-0001ae20: 7265 2074 7261 6465 7320 746f 2064 6f77  re trades to dow
-0001ae30: 6e6c 6f61 6420 6176 6169 6c61 626c 6520  nload available 
-0001ae40: 6174 2074 6865 2065 7863 6861 6e67 652c  at the exchange,
-0001ae50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001ae60: 2020 2020 2023 2053 6f20 7765 2072 6570       # So we rep
-0001ae70: 6561 7465 646c 7920 6765 7420 7468 6520  eatedly get the 
-0001ae80: 7361 6d65 2074 7261 6465 206f 7665 7220  same trade over 
-0001ae90: 616e 6420 6f76 6572 2061 6761 696e 2e0a  and over again..
-0001aea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aeb0: 2020 2020 6966 2073 696e 6365 203d 3d20      if since == 
-0001aec0: 7369 6e63 655f 6e65 7874 2061 6e64 206c  since_next and l
-0001aed0: 656e 2874 2920 3d3d 2031 3a0a 2020 2020  en(t) == 1:.    
-0001aee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aef0: 2020 2020 6c6f 6767 6572 2e64 6562 7567      logger.debug
-0001af00: 2822 5374 6f70 7069 6e67 2062 6563 6175  ("Stopping becau
-0001af10: 7365 206e 6f20 6d6f 7265 2074 7261 6465  se no more trade
-0001af20: 7320 6172 6520 6176 6169 6c61 626c 652e  s are available.
-0001af30: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
-0001af40: 2020 2020 2020 2020 2020 2062 7265 616b             break
-0001af50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001af60: 2020 2020 2073 696e 6365 203d 2073 696e       since = sin
-0001af70: 6365 5f6e 6578 740a 2020 2020 2020 2020  ce_next.        
-0001af80: 2020 2020 2020 2020 2020 2020 7472 6164              trad
-0001af90: 6573 2e65 7874 656e 6428 7429 0a20 2020  es.extend(t).   
-0001afa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001afb0: 2023 2052 6561 6368 6564 2074 6865 2065   # Reached the e
-0001afc0: 6e64 206f 6620 7468 6520 6465 6669 6e65  nd of the define
-0001afd0: 642d 646f 776e 6c6f 6164 2070 6572 696f  d-download perio
-0001afe0: 640a 2020 2020 2020 2020 2020 2020 2020  d.              
-0001aff0: 2020 2020 2020 6966 2075 6e74 696c 2061        if until a
-0001b000: 6e64 2073 696e 6365 5f6e 6578 7420 3e20  nd since_next > 
-0001b010: 756e 7469 6c3a 0a20 2020 2020 2020 2020  until:.         
-0001b020: 2020 2020 2020 2020 2020 2020 2020 206c                 l
-0001b030: 6f67 6765 722e 6465 6275 6728 0a20 2020  ogger.debug(.   
-0001b040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b050: 2020 2020 2020 2020 2066 2253 746f 7070           f"Stopp
-0001b060: 696e 6720 6265 6361 7573 6520 756e 7469  ing because unti
-0001b070: 6c20 7761 7320 7265 6163 6865 642e 207b  l was reached. {
-0001b080: 7369 6e63 655f 6e65 7874 7d20 3e20 7b75  since_next} > {u
-0001b090: 6e74 696c 7d22 290a 2020 2020 2020 2020  ntil}").        
-0001b0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b0b0: 6272 6561 6b0a 2020 2020 2020 2020 2020  break.          
-0001b0c0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-0001b0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b0e0: 6c6f 6767 6572 2e64 6562 7567 2822 5374  logger.debug("St
-0001b0f0: 6f70 7069 6e67 2061 7320 6e6f 206d 6f72  opping as no mor
-0001b100: 6520 7472 6164 6573 2077 6572 6520 7265  e trades were re
-0001b110: 7475 726e 6564 2e22 290a 2020 2020 2020  turned.").      
-0001b120: 2020 2020 2020 2020 2020 2020 2020 6272                br
-0001b130: 6561 6b0a 2020 2020 2020 2020 2020 2020  eak.            
-0001b140: 6578 6365 7074 2061 7379 6e63 696f 2e43  except asyncio.C
-0001b150: 616e 6365 6c6c 6564 4572 726f 723a 0a20  ancelledError:. 
-0001b160: 2020 2020 2020 2020 2020 2020 2020 206c                 l
-0001b170: 6f67 6765 722e 6465 6275 6728 2241 7379  ogger.debug("Asy
-0001b180: 6e63 206f 7065 7261 7469 6f6e 2049 6e74  nc operation Int
-0001b190: 6572 7275 7074 6564 2c20 6272 6561 6b69  errupted, breaki
-0001b1a0: 6e67 2074 7261 6465 7320 444c 206c 6f6f  ng trades DL loo
-0001b1b0: 702e 2229 0a20 2020 2020 2020 2020 2020  p.").           
-0001b1c0: 2020 2020 2062 7265 616b 0a0a 2020 2020       break..    
-0001b1d0: 2020 2020 7265 7475 726e 2028 7061 6972      return (pair
-0001b1e0: 2c20 7472 6164 6573 290a 0a20 2020 2061  , trades)..    a
-0001b1f0: 7379 6e63 2064 6566 205f 6173 796e 635f  sync def _async_
-0001b200: 6765 745f 7472 6164 655f 6869 7374 6f72  get_trade_histor
-0001b210: 7928 7365 6c66 2c20 7061 6972 3a20 7374  y(self, pair: st
-0001b220: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
-0001b230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b240: 2020 2020 2020 2020 2020 7369 6e63 653a            since:
-0001b250: 204f 7074 696f 6e61 6c5b 696e 745d 203d   Optional[int] =
-0001b260: 204e 6f6e 652c 0a20 2020 2020 2020 2020   None,.         
-0001b270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b280: 2020 2020 2020 2020 2020 2020 2020 756e                un
-0001b290: 7469 6c3a 204f 7074 696f 6e61 6c5b 696e  til: Optional[in
-0001b2a0: 745d 203d 204e 6f6e 652c 0a20 2020 2020  t] = None,.     
-0001b2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b2c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b2d0: 2020 6672 6f6d 5f69 643a 204f 7074 696f    from_id: Optio
-0001b2e0: 6e61 6c5b 7374 725d 203d 204e 6f6e 6529  nal[str] = None)
-0001b2f0: 202d 3e20 5475 706c 655b 7374 722c 204c   -> Tuple[str, L
-0001b300: 6973 745b 4c69 7374 5d5d 3a0a 2020 2020  ist[List]]:.    
-0001b310: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-0001b320: 4173 796e 6320 7772 6170 7065 7220 6861  Async wrapper ha
-0001b330: 6e64 6c69 6e67 2064 6f77 6e6c 6f61 6469  ndling downloadi
-0001b340: 6e67 2074 7261 6465 7320 7573 696e 6720  ng trades using 
-0001b350: 6569 7468 6572 2074 696d 6520 6f72 2069  either time or i
-0001b360: 6420 6261 7365 6420 6d65 7468 6f64 732e  d based methods.
-0001b370: 0a20 2020 2020 2020 2022 2222 0a0a 2020  .        """..  
-0001b380: 2020 2020 2020 6c6f 6767 6572 2e64 6562        logger.deb
-0001b390: 7567 2866 225f 6173 796e 635f 6765 745f  ug(f"_async_get_
-0001b3a0: 7472 6164 655f 6869 7374 6f72 7928 292c  trade_history(),
-0001b3b0: 2070 6169 723a 207b 7061 6972 7d2c 2022   pair: {pair}, "
-0001b3c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b3d0: 2020 2020 2020 6622 7369 6e63 653a 207b        f"since: {
-0001b3e0: 7369 6e63 657d 2c20 756e 7469 6c3a 207b  since}, until: {
-0001b3f0: 756e 7469 6c7d 2c20 6672 6f6d 5f69 643a  until}, from_id:
-0001b400: 207b 6672 6f6d 5f69 647d 2229 0a0a 2020   {from_id}")..  
-0001b410: 2020 2020 2020 6966 2075 6e74 696c 2069        if until i
-0001b420: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-0001b430: 2020 2020 756e 7469 6c20 3d20 6363 7874      until = ccxt
-0001b440: 2e45 7863 6861 6e67 652e 6d69 6c6c 6973  .Exchange.millis
-0001b450: 6563 6f6e 6473 2829 0a20 2020 2020 2020  econds().       
-0001b460: 2020 2020 206c 6f67 6765 722e 6465 6275       logger.debu
-0001b470: 6728 6622 4578 6368 616e 6765 206d 696c  g(f"Exchange mil
-0001b480: 6c69 7365 636f 6e64 733a 207b 756e 7469  liseconds: {unti
-0001b490: 6c7d 2229 0a0a 2020 2020 2020 2020 6966  l}")..        if
-0001b4a0: 2073 656c 662e 5f74 7261 6465 735f 7061   self._trades_pa
-0001b4b0: 6769 6e61 7469 6f6e 203d 3d20 2774 696d  gination == 'tim
-0001b4c0: 6527 3a0a 2020 2020 2020 2020 2020 2020  e':.            
-0001b4d0: 7265 7475 726e 2061 7761 6974 2073 656c  return await sel
-0001b4e0: 662e 5f61 7379 6e63 5f67 6574 5f74 7261  f._async_get_tra
-0001b4f0: 6465 5f68 6973 746f 7279 5f74 696d 6528  de_history_time(
-0001b500: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b510: 2070 6169 723d 7061 6972 2c20 7369 6e63   pair=pair, sinc
-0001b520: 653d 7369 6e63 652c 2075 6e74 696c 3d75  e=since, until=u
-0001b530: 6e74 696c 290a 2020 2020 2020 2020 656c  ntil).        el
-0001b540: 6966 2073 656c 662e 5f74 7261 6465 735f  if self._trades_
-0001b550: 7061 6769 6e61 7469 6f6e 203d 3d20 2769  pagination == 'i
-0001b560: 6427 3a0a 2020 2020 2020 2020 2020 2020  d':.            
-0001b570: 7265 7475 726e 2061 7761 6974 2073 656c  return await sel
-0001b580: 662e 5f61 7379 6e63 5f67 6574 5f74 7261  f._async_get_tra
-0001b590: 6465 5f68 6973 746f 7279 5f69 6428 0a20  de_history_id(. 
-0001b5a0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-0001b5b0: 6169 723d 7061 6972 2c20 7369 6e63 653d  air=pair, since=
-0001b5c0: 7369 6e63 652c 2075 6e74 696c 3d75 6e74  since, until=unt
-0001b5d0: 696c 2c20 6672 6f6d 5f69 643d 6672 6f6d  il, from_id=from
-0001b5e0: 5f69 640a 2020 2020 2020 2020 2020 2020  _id.            
-0001b5f0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-0001b600: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0001b610: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
-0001b620: 6570 7469 6f6e 2866 2245 7863 6861 6e67  eption(f"Exchang
-0001b630: 6520 7b73 656c 662e 6e61 6d65 7d20 646f  e {self.name} do
-0001b640: 6573 2075 7365 206e 6569 7468 6572 2074  es use neither t
-0001b650: 696d 652c 2022 0a20 2020 2020 2020 2020  ime, ".         
-0001b660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b670: 2020 2020 2020 2020 2020 2020 2020 6622                f"
-0001b680: 6e6f 7220 6964 2062 6173 6564 2070 6167  nor id based pag
-0001b690: 696e 6174 696f 6e22 290a 0a20 2020 2064  ination")..    d
-0001b6a0: 6566 2067 6574 5f68 6973 746f 7269 635f  ef get_historic_
-0001b6b0: 7472 6164 6573 2873 656c 662c 2070 6169  trades(self, pai
-0001b6c0: 723a 2073 7472 2c0a 2020 2020 2020 2020  r: str,.        
-0001b6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b6e0: 2020 2020 7369 6e63 653a 204f 7074 696f      since: Optio
-0001b6f0: 6e61 6c5b 696e 745d 203d 204e 6f6e 652c  nal[int] = None,
-0001b700: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b710: 2020 2020 2020 2020 2020 2020 2075 6e74               unt
-0001b720: 696c 3a20 4f70 7469 6f6e 616c 5b69 6e74  il: Optional[int
-0001b730: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
-0001b740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b750: 2020 2020 2020 6672 6f6d 5f69 643a 204f        from_id: O
-0001b760: 7074 696f 6e61 6c5b 7374 725d 203d 204e  ptional[str] = N
-0001b770: 6f6e 6529 202d 3e20 5475 706c 655b 7374  one) -> Tuple[st
-0001b780: 722c 204c 6973 745d 3a0a 2020 2020 2020  r, List]:.      
-0001b790: 2020 2222 220a 2020 2020 2020 2020 4765    """.        Ge
-0001b7a0: 7420 7472 6164 6520 6869 7374 6f72 7920  t trade history 
-0001b7b0: 6461 7461 2075 7369 6e67 2061 7379 6e63  data using async
-0001b7c0: 696f 2e0a 2020 2020 2020 2020 4861 6e64  io..        Hand
-0001b7d0: 6c65 7320 616c 6c20 6173 796e 6320 776f  les all async wo
-0001b7e0: 726b 2061 6e64 2072 6574 7572 6e73 2074  rk and returns t
-0001b7f0: 6865 206c 6973 7420 6f66 2063 616e 646c  he list of candl
-0001b800: 6573 2e0a 2020 2020 2020 2020 4173 796e  es..        Asyn
-0001b810: 6320 6f76 6572 206f 6e65 2070 6169 722c  c over one pair,
-0001b820: 2061 7373 756d 696e 6720 7765 2067 6574   assuming we get
-0001b830: 2060 7365 6c66 2e6f 686c 6376 5f63 616e   `self.ohlcv_can
-0001b840: 646c 655f 6c69 6d69 7428 2960 2063 616e  dle_limit()` can
-0001b850: 646c 6573 2070 6572 2063 616c 6c2e 0a20  dles per call.. 
-0001b860: 2020 2020 2020 203a 7061 7261 6d20 7061         :param pa
-0001b870: 6972 3a20 5061 6972 2074 6f20 646f 776e  ir: Pair to down
-0001b880: 6c6f 6164 0a20 2020 2020 2020 203a 7061  load.        :pa
-0001b890: 7261 6d20 7369 6e63 653a 2054 696d 6573  ram since: Times
-0001b8a0: 7461 6d70 2069 6e20 6d69 6c6c 6973 6563  tamp in millisec
-0001b8b0: 6f6e 6473 2074 6f20 6765 7420 6869 7374  onds to get hist
-0001b8c0: 6f72 7920 6672 6f6d 0a20 2020 2020 2020  ory from.       
-0001b8d0: 203a 7061 7261 6d20 756e 7469 6c3a 2054   :param until: T
-0001b8e0: 696d 6573 7461 6d70 2069 6e20 6d69 6c6c  imestamp in mill
-0001b8f0: 6973 6563 6f6e 6473 2e20 4465 6661 756c  iseconds. Defaul
-0001b900: 7473 2074 6f20 6375 7272 656e 7420 7469  ts to current ti
-0001b910: 6d65 7374 616d 7020 6966 206e 6f74 2064  mestamp if not d
-0001b920: 6566 696e 6564 2e0a 2020 2020 2020 2020  efined..        
-0001b930: 3a70 6172 616d 2066 726f 6d5f 6964 3a20  :param from_id: 
-0001b940: 446f 776e 6c6f 6164 2064 6174 6120 7374  Download data st
-0001b950: 6172 7469 6e67 2077 6974 6820 4944 2028  arting with ID (
-0001b960: 6966 2069 6420 6973 206b 6e6f 776e 290a  if id is known).
-0001b970: 2020 2020 2020 2020 3a72 6574 7572 6e73          :returns
-0001b980: 204c 6973 7420 6f66 2074 7261 6465 2064   List of trade d
-0001b990: 6174 610a 2020 2020 2020 2020 2222 220a  ata.        """.
-0001b9a0: 2020 2020 2020 2020 6966 206e 6f74 2073          if not s
-0001b9b0: 656c 662e 6578 6368 616e 6765 5f68 6173  elf.exchange_has
-0001b9c0: 2822 6665 7463 6854 7261 6465 7322 293a  ("fetchTrades"):
-0001b9d0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0001b9e0: 7365 204f 7065 7261 7469 6f6e 616c 4578  se OperationalEx
-0001b9f0: 6365 7074 696f 6e28 2254 6869 7320 6578  ception("This ex
-0001ba00: 6368 616e 6765 2064 6f65 7320 6e6f 7420  change does not 
-0001ba10: 7375 7070 6f72 7420 646f 776e 6c6f 6164  support download
-0001ba20: 696e 6720 5472 6164 6573 2e22 290a 0a20  ing Trades.").. 
-0001ba30: 2020 2020 2020 2077 6974 6820 7365 6c66         with self
-0001ba40: 2e5f 6c6f 6f70 5f6c 6f63 6b3a 0a20 2020  ._loop_lock:.   
-0001ba50: 2020 2020 2020 2020 2074 6173 6b20 3d20           task = 
-0001ba60: 6173 796e 6369 6f2e 656e 7375 7265 5f66  asyncio.ensure_f
-0001ba70: 7574 7572 6528 7365 6c66 2e5f 6173 796e  uture(self._asyn
-0001ba80: 635f 6765 745f 7472 6164 655f 6869 7374  c_get_trade_hist
-0001ba90: 6f72 7928 0a20 2020 2020 2020 2020 2020  ory(.           
-0001baa0: 2020 2020 2070 6169 723d 7061 6972 2c20       pair=pair, 
-0001bab0: 7369 6e63 653d 7369 6e63 652c 2075 6e74  since=since, unt
-0001bac0: 696c 3d75 6e74 696c 2c20 6672 6f6d 5f69  il=until, from_i
-0001bad0: 643d 6672 6f6d 5f69 6429 290a 0a20 2020  d=from_id))..   
-0001bae0: 2020 2020 2020 2020 2066 6f72 2073 6967           for sig
-0001baf0: 2069 6e20 5b73 6967 6e61 6c2e 5349 4749   in [signal.SIGI
-0001bb00: 4e54 2c20 7369 676e 616c 2e53 4947 5445  NT, signal.SIGTE
-0001bb10: 524d 5d3a 0a20 2020 2020 2020 2020 2020  RM]:.           
-0001bb20: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
-0001bb30: 2020 2020 2020 2020 2020 2020 2020 7365                se
-0001bb40: 6c66 2e6c 6f6f 702e 6164 645f 7369 676e  lf.loop.add_sign
-0001bb50: 616c 5f68 616e 646c 6572 2873 6967 2c20  al_handler(sig, 
-0001bb60: 7461 736b 2e63 616e 6365 6c29 0a20 2020  task.cancel).   
-0001bb70: 2020 2020 2020 2020 2020 2020 2065 7863               exc
-0001bb80: 6570 7420 4e6f 7449 6d70 6c65 6d65 6e74  ept NotImplement
-0001bb90: 6564 4572 726f 723a 0a20 2020 2020 2020  edError:.       
-0001bba0: 2020 2020 2020 2020 2020 2020 2023 204e               # N
-0001bbb0: 6f74 2061 6c6c 2070 6c61 7466 6f72 6d73  ot all platforms
-0001bbc0: 2069 6d70 6c65 6d65 6e74 2073 6967 6e61   implement signa
-0001bbd0: 6c73 2028 652e 672e 2077 696e 646f 7773  ls (e.g. windows
-0001bbe0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0001bbf0: 2020 2020 2020 7061 7373 0a20 2020 2020        pass.     
-0001bc00: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-0001bc10: 6c66 2e6c 6f6f 702e 7275 6e5f 756e 7469  lf.loop.run_unti
-0001bc20: 6c5f 636f 6d70 6c65 7465 2874 6173 6b29  l_complete(task)
-0001bc30: 0a0a 2020 2020 4072 6574 7269 6572 0a20  ..    @retrier. 
-0001bc40: 2020 2064 6566 205f 6765 745f 6675 6e64     def _get_fund
-0001bc50: 696e 675f 6665 6573 5f66 726f 6d5f 6578  ing_fees_from_ex
-0001bc60: 6368 616e 6765 2873 656c 662c 2070 6169  change(self, pai
-0001bc70: 723a 2073 7472 2c20 7369 6e63 653a 2055  r: str, since: U
-0001bc80: 6e69 6f6e 5b64 6174 6574 696d 652c 2069  nion[datetime, i
-0001bc90: 6e74 5d29 202d 3e20 666c 6f61 743a 0a20  nt]) -> float:. 
-0001bca0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-0001bcb0: 2020 2052 6574 7572 6e73 2074 6865 2073     Returns the s
-0001bcc0: 756d 206f 6620 616c 6c20 6675 6e64 696e  um of all fundin
-0001bcd0: 6720 6665 6573 2074 6861 7420 7765 7265  g fees that were
-0001bce0: 2065 7863 6861 6e67 6564 2066 6f72 2061   exchanged for a
-0001bcf0: 2070 6169 7220 7769 7468 696e 2061 2074   pair within a t
-0001bd00: 696d 6566 7261 6d65 0a20 2020 2020 2020  imeframe.       
-0001bd10: 2044 7279 2d72 756e 2068 616e 646c 696e   Dry-run handlin
-0001bd20: 6720 6861 7070 656e 7320 6173 2070 6172  g happens as par
-0001bd30: 7420 6f66 205f 6361 6c63 756c 6174 655f  t of _calculate_
-0001bd40: 6675 6e64 696e 675f 6665 6573 2e0a 2020  funding_fees..  
-0001bd50: 2020 2020 2020 3a70 6172 616d 2070 6169        :param pai
-0001bd60: 723a 2028 652e 672e 2041 4441 2f55 5344  r: (e.g. ADA/USD
-0001bd70: 5429 0a20 2020 2020 2020 203a 7061 7261  T).        :para
-0001bd80: 6d20 7369 6e63 653a 2054 6865 2065 6172  m since: The ear
-0001bd90: 6c69 6573 7420 7469 6d65 206f 6620 636f  liest time of co
-0001bda0: 6e73 6964 6572 6174 696f 6e20 666f 7220  nsideration for 
-0001bdb0: 6361 6c63 756c 6174 696e 6720 6675 6e64  calculating fund
-0001bdc0: 696e 6720 6665 6573 2c0a 2020 2020 2020  ing fees,.      
-0001bdd0: 2020 2020 2020 696e 2075 6e69 7820 7469        in unix ti
-0001bde0: 6d65 206f 7220 6173 2061 2064 6174 6574  me or as a datet
-0001bdf0: 696d 650a 2020 2020 2020 2020 2222 220a  ime.        """.
-0001be00: 2020 2020 2020 2020 6966 206e 6f74 2073          if not s
-0001be10: 656c 662e 6578 6368 616e 6765 5f68 6173  elf.exchange_has
-0001be20: 2822 6665 7463 6846 756e 6469 6e67 4869  ("fetchFundingHi
-0001be30: 7374 6f72 7922 293a 0a20 2020 2020 2020  story"):.       
-0001be40: 2020 2020 2072 6169 7365 204f 7065 7261       raise Opera
-0001be50: 7469 6f6e 616c 4578 6365 7074 696f 6e28  tionalException(
-0001be60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001be70: 2066 2266 6574 6368 5f66 756e 6469 6e67   f"fetch_funding
-0001be80: 5f68 6973 746f 7279 2829 2069 7320 6e6f  _history() is no
-0001be90: 7420 6176 6169 6c61 626c 6520 7573 696e  t available usin
-0001bea0: 6720 7b73 656c 662e 6e61 6d65 7d22 0a20  g {self.name}". 
-0001beb0: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
-0001bec0: 2020 2020 2020 6966 2074 7970 6528 7369        if type(si
-0001bed0: 6e63 6529 2069 7320 6461 7465 7469 6d65  nce) is datetime
-0001bee0: 3a0a 2020 2020 2020 2020 2020 2020 7369  :.            si
-0001bef0: 6e63 6520 3d20 6474 5f74 7328 7369 6e63  nce = dt_ts(sinc
-0001bf00: 6529 0a0a 2020 2020 2020 2020 7472 793a  e)..        try:
-0001bf10: 0a20 2020 2020 2020 2020 2020 2066 756e  .            fun
-0001bf20: 6469 6e67 5f68 6973 746f 7279 203d 2073  ding_history = s
-0001bf30: 656c 662e 5f61 7069 2e66 6574 6368 5f66  elf._api.fetch_f
-0001bf40: 756e 6469 6e67 5f68 6973 746f 7279 280a  unding_history(.
-0001bf50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bf60: 7379 6d62 6f6c 3d70 6169 722c 0a20 2020  symbol=pair,.   
-0001bf70: 2020 2020 2020 2020 2020 2020 2073 696e               sin
-0001bf80: 6365 3d73 696e 6365 0a20 2020 2020 2020  ce=since.       
-0001bf90: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
-0001bfa0: 2020 2073 656c 662e 5f6c 6f67 5f65 7863     self._log_exc
-0001bfb0: 6861 6e67 655f 7265 7370 6f6e 7365 2827  hange_response('
-0001bfc0: 6675 6e64 696e 675f 6869 7374 6f72 7927  funding_history'
-0001bfd0: 2c20 6675 6e64 696e 675f 6869 7374 6f72  , funding_histor
-0001bfe0: 792c 0a20 2020 2020 2020 2020 2020 2020  y,.             
-0001bff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c000: 2020 2020 2020 2020 2020 2061 6464 5f69             add_i
-0001c010: 6e66 6f3d 6622 7061 6972 3a20 7b70 6169  nfo=f"pair: {pai
-0001c020: 727d 2c20 7369 6e63 653a 207b 7369 6e63  r}, since: {sinc
-0001c030: 657d 2229 0a20 2020 2020 2020 2020 2020  e}").           
-0001c040: 2072 6574 7572 6e20 7375 6d28 6665 655b   return sum(fee[
-0001c050: 2761 6d6f 756e 7427 5d20 666f 7220 6665  'amount'] for fe
-0001c060: 6520 696e 2066 756e 6469 6e67 5f68 6973  e in funding_his
-0001c070: 746f 7279 290a 2020 2020 2020 2020 6578  tory).        ex
-0001c080: 6365 7074 2063 6378 742e 4444 6f53 5072  cept ccxt.DDoSPr
-0001c090: 6f74 6563 7469 6f6e 2061 7320 653a 0a20  otection as e:. 
-0001c0a0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0001c0b0: 2044 446f 7350 726f 7465 6374 696f 6e28   DDosProtection(
-0001c0c0: 6529 2066 726f 6d20 650a 2020 2020 2020  e) from e.      
-0001c0d0: 2020 6578 6365 7074 2028 6363 7874 2e4f    except (ccxt.O
-0001c0e0: 7065 7261 7469 6f6e 4661 696c 6564 2c20  perationFailed, 
-0001c0f0: 6363 7874 2e45 7863 6861 6e67 6545 7272  ccxt.ExchangeErr
-0001c100: 6f72 2920 6173 2065 3a0a 2020 2020 2020  or) as e:.      
-0001c110: 2020 2020 2020 7261 6973 6520 5465 6d70        raise Temp
-0001c120: 6f72 6172 7945 7272 6f72 280a 2020 2020  oraryError(.    
-0001c130: 2020 2020 2020 2020 2020 2020 6627 436f              f'Co
-0001c140: 756c 6420 6e6f 7420 6765 7420 6675 6e64  uld not get fund
-0001c150: 696e 6720 6665 6573 2064 7565 2074 6f20  ing fees due to 
-0001c160: 7b65 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e  {e.__class__.__n
-0001c170: 616d 655f 5f7d 2e20 4d65 7373 6167 653a  ame__}. Message:
-0001c180: 207b 657d 2729 2066 726f 6d20 650a 2020   {e}') from e.  
-0001c190: 2020 2020 2020 6578 6365 7074 2063 6378        except ccx
-0001c1a0: 742e 4261 7365 4572 726f 7220 6173 2065  t.BaseError as e
-0001c1b0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0001c1c0: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
-0001c1d0: 7863 6570 7469 6f6e 2865 2920 6672 6f6d  xception(e) from
-0001c1e0: 2065 0a0a 2020 2020 4072 6574 7269 6572   e..    @retrier
-0001c1f0: 0a20 2020 2064 6566 2067 6574 5f6c 6576  .    def get_lev
-0001c200: 6572 6167 655f 7469 6572 7328 7365 6c66  erage_tiers(self
-0001c210: 2920 2d3e 2044 6963 745b 7374 722c 204c  ) -> Dict[str, L
-0001c220: 6973 745b 4469 6374 5d5d 3a0a 2020 2020  ist[Dict]]:.    
-0001c230: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0001c240: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-0001c250: 2e5f 6170 692e 6665 7463 685f 6c65 7665  ._api.fetch_leve
-0001c260: 7261 6765 5f74 6965 7273 2829 0a20 2020  rage_tiers().   
-0001c270: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
-0001c280: 2e44 446f 5350 726f 7465 6374 696f 6e20  .DDoSProtection 
-0001c290: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
-0001c2a0: 2020 7261 6973 6520 4444 6f73 5072 6f74    raise DDosProt
-0001c2b0: 6563 7469 6f6e 2865 2920 6672 6f6d 2065  ection(e) from e
-0001c2c0: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-0001c2d0: 2863 6378 742e 4f70 6572 6174 696f 6e46  (ccxt.OperationF
-0001c2e0: 6169 6c65 642c 2063 6378 742e 4578 6368  ailed, ccxt.Exch
-0001c2f0: 616e 6765 4572 726f 7229 2061 7320 653a  angeError) as e:
-0001c300: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0001c310: 7365 2054 656d 706f 7261 7279 4572 726f  se TemporaryErro
-0001c320: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
-0001c330: 2020 2066 2743 6f75 6c64 206e 6f74 206c     f'Could not l
-0001c340: 6f61 6420 6c65 7665 7261 6765 2074 6965  oad leverage tie
-0001c350: 7273 2064 7565 2074 6f20 7b65 2e5f 5f63  rs due to {e.__c
-0001c360: 6c61 7373 5f5f 2e5f 5f6e 616d 655f 5f7d  lass__.__name__}
-0001c370: 2e20 4d65 7373 6167 653a 207b 657d 270a  . Message: {e}'.
-0001c380: 2020 2020 2020 2020 2020 2020 2920 6672              ) fr
-0001c390: 6f6d 2065 0a20 2020 2020 2020 2065 7863  om e.        exc
-0001c3a0: 6570 7420 6363 7874 2e42 6173 6545 7272  ept ccxt.BaseErr
-0001c3b0: 6f72 2061 7320 653a 0a20 2020 2020 2020  or as e:.       
-0001c3c0: 2020 2020 2072 6169 7365 204f 7065 7261       raise Opera
-0001c3d0: 7469 6f6e 616c 4578 6365 7074 696f 6e28  tionalException(
-0001c3e0: 6529 2066 726f 6d20 650a 0a20 2020 2040  e) from e..    @
-0001c3f0: 7265 7472 6965 725f 6173 796e 630a 2020  retrier_async.  
-0001c400: 2020 6173 796e 6320 6465 6620 6765 745f    async def get_
-0001c410: 6d61 726b 6574 5f6c 6576 6572 6167 655f  market_leverage_
-0001c420: 7469 6572 7328 7365 6c66 2c20 7379 6d62  tiers(self, symb
-0001c430: 6f6c 3a20 7374 7229 202d 3e20 5475 706c  ol: str) -> Tupl
-0001c440: 655b 7374 722c 204c 6973 745b 4469 6374  e[str, List[Dict
-0001c450: 5d5d 3a0a 2020 2020 2020 2020 2222 2220  ]]:.        """ 
-0001c460: 4c65 7665 7261 6765 2074 6965 7273 2070  Leverage tiers p
-0001c470: 6572 2073 796d 626f 6c20 2222 220a 2020  er symbol """.  
-0001c480: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
-0001c490: 2020 2020 2020 2074 6965 7220 3d20 6177         tier = aw
-0001c4a0: 6169 7420 7365 6c66 2e5f 6170 695f 6173  ait self._api_as
-0001c4b0: 796e 632e 6665 7463 685f 6d61 726b 6574  ync.fetch_market
-0001c4c0: 5f6c 6576 6572 6167 655f 7469 6572 7328  _leverage_tiers(
-0001c4d0: 7379 6d62 6f6c 290a 2020 2020 2020 2020  symbol).        
-0001c4e0: 2020 2020 7265 7475 726e 2073 796d 626f      return symbo
-0001c4f0: 6c2c 2074 6965 720a 2020 2020 2020 2020  l, tier.        
-0001c500: 6578 6365 7074 2063 6378 742e 4444 6f53  except ccxt.DDoS
-0001c510: 5072 6f74 6563 7469 6f6e 2061 7320 653a  Protection as e:
-0001c520: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0001c530: 7365 2044 446f 7350 726f 7465 6374 696f  se DDosProtectio
-0001c540: 6e28 6529 2066 726f 6d20 650a 2020 2020  n(e) from e.    
-0001c550: 2020 2020 6578 6365 7074 2028 6363 7874      except (ccxt
-0001c560: 2e4f 7065 7261 7469 6f6e 4661 696c 6564  .OperationFailed
-0001c570: 2c20 6363 7874 2e45 7863 6861 6e67 6545  , ccxt.ExchangeE
-0001c580: 7272 6f72 2920 6173 2065 3a0a 2020 2020  rror) as e:.    
-0001c590: 2020 2020 2020 2020 7261 6973 6520 5465          raise Te
-0001c5a0: 6d70 6f72 6172 7945 7272 6f72 280a 2020  mporaryError(.  
-0001c5b0: 2020 2020 2020 2020 2020 2020 2020 6627                f'
-0001c5c0: 436f 756c 6420 6e6f 7420 6c6f 6164 206c  Could not load l
-0001c5d0: 6576 6572 6167 6520 7469 6572 7320 666f  everage tiers fo
-0001c5e0: 7220 7b73 796d 626f 6c7d 270a 2020 2020  r {symbol}'.    
-0001c5f0: 2020 2020 2020 2020 2020 2020 6627 2064              f' d
-0001c600: 7565 2074 6f20 7b65 2e5f 5f63 6c61 7373  ue to {e.__class
-0001c610: 5f5f 2e5f 5f6e 616d 655f 5f7d 2e20 4d65  __.__name__}. Me
-0001c620: 7373 6167 653a 207b 657d 270a 2020 2020  ssage: {e}'.    
-0001c630: 2020 2020 2020 2020 2920 6672 6f6d 2065          ) from e
-0001c640: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-0001c650: 6363 7874 2e42 6173 6545 7272 6f72 2061  ccxt.BaseError a
-0001c660: 7320 653a 0a20 2020 2020 2020 2020 2020  s e:.           
-0001c670: 2072 6169 7365 204f 7065 7261 7469 6f6e   raise Operation
-0001c680: 616c 4578 6365 7074 696f 6e28 6529 2066  alException(e) f
-0001c690: 726f 6d20 650a 0a20 2020 2064 6566 206c  rom e..    def l
-0001c6a0: 6f61 645f 6c65 7665 7261 6765 5f74 6965  oad_leverage_tie
-0001c6b0: 7273 2873 656c 6629 202d 3e20 4469 6374  rs(self) -> Dict
-0001c6c0: 5b73 7472 2c20 4c69 7374 5b44 6963 745d  [str, List[Dict]
-0001c6d0: 5d3a 0a20 2020 2020 2020 2069 6620 7365  ]:.        if se
-0001c6e0: 6c66 2e74 7261 6469 6e67 5f6d 6f64 6520  lf.trading_mode 
-0001c6f0: 3d3d 2054 7261 6469 6e67 4d6f 6465 2e46  == TradingMode.F
-0001c700: 5554 5552 4553 3a0a 2020 2020 2020 2020  UTURES:.        
-0001c710: 2020 2020 6966 2073 656c 662e 6578 6368      if self.exch
-0001c720: 616e 6765 5f68 6173 2827 6665 7463 684c  ange_has('fetchL
-0001c730: 6576 6572 6167 6554 6965 7273 2729 3a0a  everageTiers'):.
-0001c740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c750: 2320 4665 7463 6820 616c 6c20 6c65 7665  # Fetch all leve
-0001c760: 7261 6765 2074 6965 7273 2061 7420 6f6e  rage tiers at on
-0001c770: 6365 0a20 2020 2020 2020 2020 2020 2020  ce.             
-0001c780: 2020 2072 6574 7572 6e20 7365 6c66 2e67     return self.g
-0001c790: 6574 5f6c 6576 6572 6167 655f 7469 6572  et_leverage_tier
-0001c7a0: 7328 290a 2020 2020 2020 2020 2020 2020  s().            
-0001c7b0: 656c 6966 2073 656c 662e 6578 6368 616e  elif self.exchan
-0001c7c0: 6765 5f68 6173 2827 6665 7463 684d 6172  ge_has('fetchMar
-0001c7d0: 6b65 744c 6576 6572 6167 6554 6965 7273  ketLeverageTiers
-0001c7e0: 2729 3a0a 2020 2020 2020 2020 2020 2020  '):.            
-0001c7f0: 2020 2020 2320 4d75 7374 2066 6574 6368      # Must fetch
-0001c800: 2074 6865 206c 6576 6572 6167 6520 7469   the leverage ti
-0001c810: 6572 7320 666f 7220 6561 6368 206d 6172  ers for each mar
-0001c820: 6b65 7420 7365 7061 7261 7465 6c79 0a20  ket separately. 
-0001c830: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-0001c840: 202a 2054 6869 7320 6973 2073 6c6f 7728   * This is slow(
-0001c850: 7e34 3573 2920 6f6e 204f 6b78 2c20 6d61  ~45s) on Okx, ma
-0001c860: 6b65 7320 7e39 3020 6170 6920 6361 6c6c  kes ~90 api call
-0001c870: 7320 746f 206c 6f61 6420 616c 6c20 6c69  s to load all li
-0001c880: 6e65 6172 2073 7761 7020 6d61 726b 6574  near swap market
-0001c890: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
-0001c8a0: 2020 6d61 726b 6574 7320 3d20 7365 6c66    markets = self
-0001c8b0: 2e6d 6172 6b65 7473 0a0a 2020 2020 2020  .markets..      
-0001c8c0: 2020 2020 2020 2020 2020 7379 6d62 6f6c            symbol
-0001c8d0: 7320 3d20 5b0a 2020 2020 2020 2020 2020  s = [.          
-0001c8e0: 2020 2020 2020 2020 2020 7379 6d62 6f6c            symbol
-0001c8f0: 2066 6f72 2073 796d 626f 6c2c 206d 6172   for symbol, mar
-0001c900: 6b65 7420 696e 206d 6172 6b65 7473 2e69  ket in markets.i
-0001c910: 7465 6d73 2829 0a20 2020 2020 2020 2020  tems().         
-0001c920: 2020 2020 2020 2020 2020 2069 6620 2873             if (s
-0001c930: 656c 662e 6d61 726b 6574 5f69 735f 6675  elf.market_is_fu
-0001c940: 7475 7265 286d 6172 6b65 7429 0a20 2020  ture(market).   
-0001c950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c960: 2020 2020 2061 6e64 206d 6172 6b65 745b       and market[
-0001c970: 2771 756f 7465 275d 203d 3d20 7365 6c66  'quote'] == self
-0001c980: 2e5f 636f 6e66 6967 5b27 7374 616b 655f  ._config['stake_
-0001c990: 6375 7272 656e 6379 275d 290a 2020 2020  currency']).    
-0001c9a0: 2020 2020 2020 2020 2020 2020 5d0a 0a20              ].. 
-0001c9b0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-0001c9c0: 6965 7273 3a20 4469 6374 5b73 7472 2c20  iers: Dict[str, 
-0001c9d0: 4c69 7374 5b44 6963 745d 5d20 3d20 7b7d  List[Dict]] = {}
-0001c9e0: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001c9f0: 2020 7469 6572 735f 6361 6368 6564 203d    tiers_cached =
-0001ca00: 2073 656c 662e 6c6f 6164 5f63 6163 6865   self.load_cache
-0001ca10: 645f 6c65 7665 7261 6765 5f74 6965 7273  d_leverage_tiers
-0001ca20: 2873 656c 662e 5f63 6f6e 6669 675b 2773  (self._config['s
-0001ca30: 7461 6b65 5f63 7572 7265 6e63 7927 5d29  take_currency'])
-0001ca40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001ca50: 2069 6620 7469 6572 735f 6361 6368 6564   if tiers_cached
-0001ca60: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001ca70: 2020 2020 2020 7469 6572 7320 3d20 7469        tiers = ti
-0001ca80: 6572 735f 6361 6368 6564 0a0a 2020 2020  ers_cached..    
-0001ca90: 2020 2020 2020 2020 2020 2020 636f 726f              coro
-0001caa0: 7320 3d20 5b0a 2020 2020 2020 2020 2020  s = [.          
-0001cab0: 2020 2020 2020 2020 2020 7365 6c66 2e67            self.g
-0001cac0: 6574 5f6d 6172 6b65 745f 6c65 7665 7261  et_market_levera
-0001cad0: 6765 5f74 6965 7273 2873 796d 626f 6c29  ge_tiers(symbol)
-0001cae0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001caf0: 2020 2020 2066 6f72 2073 796d 626f 6c20       for symbol 
-0001cb00: 696e 2073 6f72 7465 6428 7379 6d62 6f6c  in sorted(symbol
-0001cb10: 7329 2069 6620 7379 6d62 6f6c 206e 6f74  s) if symbol not
-0001cb20: 2069 6e20 7469 6572 735d 0a0a 2020 2020   in tiers]..    
-0001cb30: 2020 2020 2020 2020 2020 2020 2320 4265              # Be
-0001cb40: 2076 6572 626f 7365 2068 6572 652c 2061   verbose here, a
-0001cb50: 7320 7468 6973 2064 656c 6179 7320 7374  s this delays st
-0001cb60: 6172 7475 7020 6279 207e 3120 6d69 6e75  artup by ~1 minu
-0001cb70: 7465 2e0a 2020 2020 2020 2020 2020 2020  te..            
-0001cb80: 2020 2020 6966 2063 6f72 6f73 3a0a 2020      if coros:.  
-0001cb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cba0: 2020 6c6f 6767 6572 2e69 6e66 6f28 0a20    logger.info(. 
-0001cbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cbc0: 2020 2020 2020 2066 2249 6e69 7469 616c         f"Initial
-0001cbd0: 697a 696e 6720 6c65 7665 7261 6765 5f74  izing leverage_t
-0001cbe0: 6965 7273 2066 6f72 207b 6c65 6e28 7379  iers for {len(sy
-0001cbf0: 6d62 6f6c 7329 7d20 6d61 726b 6574 732e  mbols)} markets.
-0001cc00: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
-0001cc10: 2020 2020 2020 2020 2020 2022 5468 6973             "This
-0001cc20: 2077 696c 6c20 7461 6b65 2061 626f 7574   will take about
-0001cc30: 2061 206d 696e 7574 652e 2229 0a20 2020   a minute.").   
-0001cc40: 2020 2020 2020 2020 2020 2020 2065 6c73               els
-0001cc50: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-0001cc60: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
-0001cc70: 666f 2822 5573 696e 6720 6361 6368 6564  fo("Using cached
-0001cc80: 206c 6576 6572 6167 655f 7469 6572 732e   leverage_tiers.
-0001cc90: 2229 0a0a 2020 2020 2020 2020 2020 2020  ")..            
-0001cca0: 2020 2020 6173 796e 6320 6465 6620 6761      async def ga
-0001ccb0: 7468 6572 5f72 6573 756c 7473 2869 6e70  ther_results(inp
-0001ccc0: 7574 5f63 6f72 6f29 3a0a 2020 2020 2020  ut_coro):.      
-0001ccd0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-0001cce0: 7475 726e 2061 7761 6974 2061 7379 6e63  turn await async
-0001ccf0: 696f 2e67 6174 6865 7228 2a69 6e70 7574  io.gather(*input
-0001cd00: 5f63 6f72 6f2c 2072 6574 7572 6e5f 6578  _coro, return_ex
-0001cd10: 6365 7074 696f 6e73 3d54 7275 6529 0a0a  ceptions=True)..
-0001cd20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cd30: 666f 7220 696e 7075 745f 636f 726f 2069  for input_coro i
-0001cd40: 6e20 6368 756e 6b73 2863 6f72 6f73 2c20  n chunks(coros, 
-0001cd50: 3130 3029 3a0a 0a20 2020 2020 2020 2020  100):..         
-0001cd60: 2020 2020 2020 2020 2020 2077 6974 6820             with 
-0001cd70: 7365 6c66 2e5f 6c6f 6f70 5f6c 6f63 6b3a  self._loop_lock:
-0001cd80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001cd90: 2020 2020 2020 2020 2072 6573 756c 7473           results
-0001cda0: 203d 2073 656c 662e 6c6f 6f70 2e72 756e   = self.loop.run
-0001cdb0: 5f75 6e74 696c 5f63 6f6d 706c 6574 6528  _until_complete(
-0001cdc0: 6761 7468 6572 5f72 6573 756c 7473 2869  gather_results(i
-0001cdd0: 6e70 7574 5f63 6f72 6f29 290a 0a20 2020  nput_coro))..   
-0001cde0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cdf0: 2066 6f72 2072 6573 2069 6e20 7265 7375   for res in resu
-0001ce00: 6c74 733a 0a20 2020 2020 2020 2020 2020  lts:.           
-0001ce10: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-0001ce20: 6973 696e 7374 616e 6365 2872 6573 2c20  isinstance(res, 
-0001ce30: 4578 6365 7074 696f 6e29 3a0a 2020 2020  Exception):.    
-0001ce40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ce50: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
-0001ce60: 6172 6e69 6e67 2866 224c 6576 6572 6167  arning(f"Leverag
-0001ce70: 6520 7469 6572 2065 7863 6570 7469 6f6e  e tier exception
-0001ce80: 3a20 7b72 6570 7228 7265 7329 7d22 290a  : {repr(res)}").
-0001ce90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cea0: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-0001ceb0: 696e 7565 0a20 2020 2020 2020 2020 2020  inue.           
-0001cec0: 2020 2020 2020 2020 2020 2020 2073 796d               sym
-0001ced0: 626f 6c2c 2074 6965 7220 3d20 7265 730a  bol, tier = res.
-0001cee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cef0: 2020 2020 2020 2020 7469 6572 735b 7379          tiers[sy
-0001cf00: 6d62 6f6c 5d20 3d20 7469 6572 0a20 2020  mbol] = tier.   
-0001cf10: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-0001cf20: 6c65 6e28 636f 726f 7329 203e 2030 3a0a  len(coros) > 0:.
-0001cf30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cf40: 2020 2020 7365 6c66 2e63 6163 6865 5f6c      self.cache_l
-0001cf50: 6576 6572 6167 655f 7469 6572 7328 7469  everage_tiers(ti
-0001cf60: 6572 732c 2073 656c 662e 5f63 6f6e 6669  ers, self._confi
-0001cf70: 675b 2773 7461 6b65 5f63 7572 7265 6e63  g['stake_currenc
-0001cf80: 7927 5d29 0a20 2020 2020 2020 2020 2020  y']).           
-0001cf90: 2020 2020 206c 6f67 6765 722e 696e 666f       logger.info
-0001cfa0: 2866 2244 6f6e 6520 696e 6974 6961 6c69  (f"Done initiali
-0001cfb0: 7a69 6e67 207b 6c65 6e28 7379 6d62 6f6c  zing {len(symbol
-0001cfc0: 7329 7d20 6d61 726b 6574 732e 2229 0a0a  s)} markets.")..
-0001cfd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cfe0: 7265 7475 726e 2074 6965 7273 0a20 2020  return tiers.   
-0001cff0: 2020 2020 2072 6574 7572 6e20 7b7d 0a0a       return {}..
-0001d000: 2020 2020 6465 6620 6361 6368 655f 6c65      def cache_le
-0001d010: 7665 7261 6765 5f74 6965 7273 2873 656c  verage_tiers(sel
-0001d020: 662c 2074 6965 7273 3a20 4469 6374 5b73  f, tiers: Dict[s
-0001d030: 7472 2c20 4c69 7374 5b44 6963 745d 5d2c  tr, List[Dict]],
-0001d040: 2073 7461 6b65 5f63 7572 7265 6e63 793a   stake_currency:
-0001d050: 2073 7472 2920 2d3e 204e 6f6e 653a 0a0a   str) -> None:..
-0001d060: 2020 2020 2020 2020 6669 6c65 6e61 6d65          filename
-0001d070: 203d 2073 656c 662e 5f63 6f6e 6669 675b   = self._config[
-0001d080: 2764 6174 6164 6972 275d 202f 2022 6675  'datadir'] / "fu
-0001d090: 7475 7265 7322 202f 2066 226c 6576 6572  tures" / f"lever
-0001d0a0: 6167 655f 7469 6572 735f 7b73 7461 6b65  age_tiers_{stake
-0001d0b0: 5f63 7572 7265 6e63 797d 2e6a 736f 6e22  _currency}.json"
-0001d0c0: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-0001d0d0: 6669 6c65 6e61 6d65 2e70 6172 656e 742e  filename.parent.
-0001d0e0: 6973 5f64 6972 2829 3a0a 2020 2020 2020  is_dir():.      
-0001d0f0: 2020 2020 2020 6669 6c65 6e61 6d65 2e70        filename.p
-0001d100: 6172 656e 742e 6d6b 6469 7228 7061 7265  arent.mkdir(pare
-0001d110: 6e74 733d 5472 7565 290a 2020 2020 2020  nts=True).      
-0001d120: 2020 6461 7461 203d 207b 0a20 2020 2020    data = {.     
-0001d130: 2020 2020 2020 2022 7570 6461 7465 6422         "updated"
-0001d140: 3a20 6461 7465 7469 6d65 2e6e 6f77 2874  : datetime.now(t
-0001d150: 696d 657a 6f6e 652e 7574 6329 2c0a 2020  imezone.utc),.  
-0001d160: 2020 2020 2020 2020 2020 2264 6174 6122            "data"
-0001d170: 3a20 7469 6572 732c 0a20 2020 2020 2020  : tiers,.       
-0001d180: 207d 0a20 2020 2020 2020 2066 696c 655f   }.        file_
-0001d190: 6475 6d70 5f6a 736f 6e28 6669 6c65 6e61  dump_json(filena
-0001d1a0: 6d65 2c20 6461 7461 290a 0a20 2020 2064  me, data)..    d
-0001d1b0: 6566 206c 6f61 645f 6361 6368 6564 5f6c  ef load_cached_l
-0001d1c0: 6576 6572 6167 655f 7469 6572 7328 7365  everage_tiers(se
-0001d1d0: 6c66 2c20 7374 616b 655f 6375 7272 656e  lf, stake_curren
-0001d1e0: 6379 3a20 7374 7229 202d 3e20 4f70 7469  cy: str) -> Opti
-0001d1f0: 6f6e 616c 5b44 6963 745b 7374 722c 204c  onal[Dict[str, L
-0001d200: 6973 745b 4469 6374 5d5d 5d3a 0a20 2020  ist[Dict]]]:.   
-0001d210: 2020 2020 2066 696c 656e 616d 6520 3d20       filename = 
-0001d220: 7365 6c66 2e5f 636f 6e66 6967 5b27 6461  self._config['da
-0001d230: 7461 6469 7227 5d20 2f20 2266 7574 7572  tadir'] / "futur
-0001d240: 6573 2220 2f20 6622 6c65 7665 7261 6765  es" / f"leverage
-0001d250: 5f74 6965 7273 5f7b 7374 616b 655f 6375  _tiers_{stake_cu
-0001d260: 7272 656e 6379 7d2e 6a73 6f6e 220a 2020  rrency}.json".  
-0001d270: 2020 2020 2020 6966 2066 696c 656e 616d        if filenam
-0001d280: 652e 6973 5f66 696c 6528 293a 0a20 2020  e.is_file():.   
-0001d290: 2020 2020 2020 2020 2074 7279 3a0a 2020           try:.  
-0001d2a0: 2020 2020 2020 2020 2020 2020 2020 7469                ti
-0001d2b0: 6572 7320 3d20 6669 6c65 5f6c 6f61 645f  ers = file_load_
-0001d2c0: 6a73 6f6e 2866 696c 656e 616d 6529 0a20  json(filename). 
-0001d2d0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0001d2e0: 7064 6174 6564 203d 2074 6965 7273 2e67  pdated = tiers.g
-0001d2f0: 6574 2827 7570 6461 7465 6427 290a 2020  et('updated').  
-0001d300: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0001d310: 2075 7064 6174 6564 3a0a 2020 2020 2020   updated:.      
-0001d320: 2020 2020 2020 2020 2020 2020 2020 7570                up
-0001d330: 6461 7465 645f 6474 203d 2070 6172 7365  dated_dt = parse
-0001d340: 722e 7061 7273 6528 7570 6461 7465 6429  r.parse(updated)
-0001d350: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001d360: 2020 2020 2069 6620 7570 6461 7465 645f       if updated_
-0001d370: 6474 203c 2064 6174 6574 696d 652e 6e6f  dt < datetime.no
-0001d380: 7728 7469 6d65 7a6f 6e65 2e75 7463 2920  w(timezone.utc) 
-0001d390: 2d20 7469 6d65 6465 6c74 6128 7765 656b  - timedelta(week
-0001d3a0: 733d 3429 3a0a 2020 2020 2020 2020 2020  s=4):.          
-0001d3b0: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-0001d3c0: 6767 6572 2e69 6e66 6f28 2243 6163 6865  gger.info("Cache
-0001d3d0: 6420 6c65 7665 7261 6765 2074 6965 7273  d leverage tiers
-0001d3e0: 2061 7265 206f 7574 6461 7465 642e 2057   are outdated. W
-0001d3f0: 696c 6c20 7570 6461 7465 2e22 290a 2020  ill update.").  
-0001d400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d410: 2020 2020 2020 7265 7475 726e 204e 6f6e        return Non
-0001d420: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-0001d430: 2020 7265 7475 726e 2074 6965 7273 5b27    return tiers['
-0001d440: 6461 7461 275d 0a20 2020 2020 2020 2020  data'].         
-0001d450: 2020 2065 7863 6570 7420 4578 6365 7074     except Except
-0001d460: 696f 6e3a 0a20 2020 2020 2020 2020 2020  ion:.           
-0001d470: 2020 2020 206c 6f67 6765 722e 6578 6365       logger.exce
-0001d480: 7074 696f 6e28 2245 7272 6f72 206c 6f61  ption("Error loa
-0001d490: 6469 6e67 2063 6163 6865 6420 6c65 7665  ding cached leve
-0001d4a0: 7261 6765 2074 6965 7273 2e20 5265 6672  rage tiers. Refr
-0001d4b0: 6573 6869 6e67 2e22 290a 2020 2020 2020  eshing.").      
-0001d4c0: 2020 7265 7475 726e 204e 6f6e 650a 0a20    return None.. 
-0001d4d0: 2020 2064 6566 2066 696c 6c5f 6c65 7665     def fill_leve
-0001d4e0: 7261 6765 5f74 6965 7273 2873 656c 6629  rage_tiers(self)
-0001d4f0: 202d 3e20 4e6f 6e65 3a0a 2020 2020 2020   -> None:.      
-0001d500: 2020 2222 220a 2020 2020 2020 2020 4173    """.        As
-0001d510: 7369 676e 7320 7072 6f70 6572 7479 205f  signs property _
-0001d520: 6c65 7665 7261 6765 5f74 6965 7273 2074  leverage_tiers t
-0001d530: 6f20 6120 6469 6374 696f 6e61 7279 206f  o a dictionary o
-0001d540: 6620 696e 666f 726d 6174 696f 6e20 6162  f information ab
-0001d550: 6f75 7420 7468 6520 6c65 7665 7261 6765  out the leverage
-0001d560: 0a20 2020 2020 2020 2061 6c6c 6f77 6564  .        allowed
-0001d570: 206f 6e20 6561 6368 2070 6169 720a 2020   on each pair.  
-0001d580: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-0001d590: 2020 6c65 7665 7261 6765 5f74 6965 7273    leverage_tiers
-0001d5a0: 203d 2073 656c 662e 6c6f 6164 5f6c 6576   = self.load_lev
-0001d5b0: 6572 6167 655f 7469 6572 7328 290a 2020  erage_tiers().  
-0001d5c0: 2020 2020 2020 666f 7220 7061 6972 2c20        for pair, 
-0001d5d0: 7469 6572 7320 696e 206c 6576 6572 6167  tiers in leverag
-0001d5e0: 655f 7469 6572 732e 6974 656d 7328 293a  e_tiers.items():
-0001d5f0: 0a20 2020 2020 2020 2020 2020 2070 6169  .            pai
-0001d600: 725f 7469 6572 7320 3d20 5b5d 0a20 2020  r_tiers = [].   
-0001d610: 2020 2020 2020 2020 2066 6f72 2074 6965           for tie
-0001d620: 7220 696e 2074 6965 7273 3a0a 2020 2020  r in tiers:.    
-0001d630: 2020 2020 2020 2020 2020 2020 7061 6972              pair
-0001d640: 5f74 6965 7273 2e61 7070 656e 6428 7365  _tiers.append(se
-0001d650: 6c66 2e70 6172 7365 5f6c 6576 6572 6167  lf.parse_leverag
-0001d660: 655f 7469 6572 2874 6965 7229 290a 2020  e_tier(tier)).  
-0001d670: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-0001d680: 6c65 7665 7261 6765 5f74 6965 7273 5b70  leverage_tiers[p
-0001d690: 6169 725d 203d 2070 6169 725f 7469 6572  air] = pair_tier
-0001d6a0: 730a 0a20 2020 2064 6566 2070 6172 7365  s..    def parse
-0001d6b0: 5f6c 6576 6572 6167 655f 7469 6572 2873  _leverage_tier(s
-0001d6c0: 656c 662c 2074 6965 7229 202d 3e20 4469  elf, tier) -> Di
-0001d6d0: 6374 3a0a 2020 2020 2020 2020 696e 666f  ct:.        info
-0001d6e0: 203d 2074 6965 722e 6765 7428 2769 6e66   = tier.get('inf
-0001d6f0: 6f27 2c20 7b7d 290a 2020 2020 2020 2020  o', {}).        
-0001d700: 7265 7475 726e 207b 0a20 2020 2020 2020  return {.       
-0001d710: 2020 2020 2027 6d69 6e4e 6f74 696f 6e61       'minNotiona
-0001d720: 6c27 3a20 7469 6572 5b27 6d69 6e4e 6f74  l': tier['minNot
-0001d730: 696f 6e61 6c27 5d2c 0a20 2020 2020 2020  ional'],.       
-0001d740: 2020 2020 2027 6d61 784e 6f74 696f 6e61       'maxNotiona
-0001d750: 6c27 3a20 7469 6572 5b27 6d61 784e 6f74  l': tier['maxNot
-0001d760: 696f 6e61 6c27 5d2c 0a20 2020 2020 2020  ional'],.       
-0001d770: 2020 2020 2027 6d61 696e 7465 6e61 6e63       'maintenanc
-0001d780: 654d 6172 6769 6e52 6174 6527 3a20 7469  eMarginRate': ti
-0001d790: 6572 5b27 6d61 696e 7465 6e61 6e63 654d  er['maintenanceM
-0001d7a0: 6172 6769 6e52 6174 6527 5d2c 0a20 2020  arginRate'],.   
-0001d7b0: 2020 2020 2020 2020 2027 6d61 784c 6576           'maxLev
-0001d7c0: 6572 6167 6527 3a20 7469 6572 5b27 6d61  erage': tier['ma
-0001d7d0: 784c 6576 6572 6167 6527 5d2c 0a20 2020  xLeverage'],.   
-0001d7e0: 2020 2020 2020 2020 2027 6d61 696e 7441           'maintA
-0001d7f0: 6d74 273a 2066 6c6f 6174 2869 6e66 6f5b  mt': float(info[
-0001d800: 2763 756d 275d 2920 6966 2027 6375 6d27  'cum']) if 'cum'
-0001d810: 2069 6e20 696e 666f 2065 6c73 6520 4e6f   in info else No
-0001d820: 6e65 2c0a 2020 2020 2020 2020 7d0a 0a20  ne,.        }.. 
-0001d830: 2020 2064 6566 2067 6574 5f6d 6178 5f6c     def get_max_l
-0001d840: 6576 6572 6167 6528 7365 6c66 2c20 7061  everage(self, pa
-0001d850: 6972 3a20 7374 722c 2073 7461 6b65 5f61  ir: str, stake_a
-0001d860: 6d6f 756e 743a 204f 7074 696f 6e61 6c5b  mount: Optional[
-0001d870: 666c 6f61 745d 2920 2d3e 2066 6c6f 6174  float]) -> float
-0001d880: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-0001d890: 2020 2020 2020 5265 7475 726e 7320 7468        Returns th
-0001d8a0: 6520 6d61 7869 6d75 6d20 6c65 7665 7261  e maximum levera
-0001d8b0: 6765 2074 6861 7420 6120 7061 6972 2063  ge that a pair c
-0001d8c0: 616e 2062 6520 7472 6164 6564 2061 740a  an be traded at.
-0001d8d0: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
-0001d8e0: 6169 723a 2054 6865 2062 6173 652f 7175  air: The base/qu
-0001d8f0: 6f74 6520 6375 7272 656e 6379 2070 6169  ote currency pai
-0001d900: 7220 6265 696e 6720 7472 6164 6564 0a20  r being traded. 
-0001d910: 2020 2020 2020 203a 7374 616b 655f 616d         :stake_am
-0001d920: 6f75 6e74 3a20 5468 6520 746f 7461 6c20  ount: The total 
-0001d930: 7661 6c75 6520 6f66 2074 6865 2074 7261  value of the tra
-0001d940: 6465 7273 206d 6172 6769 6e5f 6d6f 6465  ders margin_mode
-0001d950: 2069 6e20 7175 6f74 6520 6375 7272 656e   in quote curren
-0001d960: 6379 0a20 2020 2020 2020 2022 2222 0a0a  cy.        """..
-0001d970: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-0001d980: 7472 6164 696e 675f 6d6f 6465 203d 3d20  trading_mode == 
-0001d990: 5472 6164 696e 674d 6f64 652e 5350 4f54  TradingMode.SPOT
-0001d9a0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-0001d9b0: 7475 726e 2031 2e30 0a0a 2020 2020 2020  turn 1.0..      
-0001d9c0: 2020 6966 2073 656c 662e 7472 6164 696e    if self.tradin
-0001d9d0: 675f 6d6f 6465 203d 3d20 5472 6164 696e  g_mode == Tradin
-0001d9e0: 674d 6f64 652e 4655 5455 5245 533a 0a0a  gMode.FUTURES:..
-0001d9f0: 2020 2020 2020 2020 2020 2020 2320 4368              # Ch
-0001da00: 6563 6b73 2061 6e64 2065 6467 6520 6361  ecks and edge ca
-0001da10: 7365 730a 2020 2020 2020 2020 2020 2020  ses.            
-0001da20: 6966 2073 7461 6b65 5f61 6d6f 756e 7420  if stake_amount 
-0001da30: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-0001da40: 2020 2020 2020 2020 2072 6169 7365 204f           raise O
-0001da50: 7065 7261 7469 6f6e 616c 4578 6365 7074  perationalExcept
-0001da60: 696f 6e28 0a20 2020 2020 2020 2020 2020  ion(.           
-0001da70: 2020 2020 2020 2020 2066 277b 7365 6c66           f'{self
-0001da80: 2e6e 616d 657d 2e67 6574 5f6d 6178 5f6c  .name}.get_max_l
-0001da90: 6576 6572 6167 6520 7265 7175 6972 6573  everage requires
-0001daa0: 2061 7267 756d 656e 7420 7374 616b 655f   argument stake_
-0001dab0: 616d 6f75 6e74 270a 2020 2020 2020 2020  amount'.        
-0001dac0: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
-0001dad0: 2020 2020 2020 2069 6620 7061 6972 206e         if pair n
-0001dae0: 6f74 2069 6e20 7365 6c66 2e5f 6c65 7665  ot in self._leve
-0001daf0: 7261 6765 5f74 6965 7273 3a0a 2020 2020  rage_tiers:.    
-0001db00: 2020 2020 2020 2020 2020 2020 2320 4d61              # Ma
-0001db10: 7962 6520 7261 6973 6520 6578 6365 7074  ybe raise except
-0001db20: 696f 6e20 6265 6361 7573 6520 6974 2063  ion because it c
-0001db30: 616e 2774 2062 6520 7472 6164 6564 206f  an't be traded o
-0001db40: 6e20 6675 7475 7265 733f 0a20 2020 2020  n futures?.     
-0001db50: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0001db60: 6e20 312e 300a 0a20 2020 2020 2020 2020  n 1.0..         
-0001db70: 2020 2070 6169 725f 7469 6572 7320 3d20     pair_tiers = 
-0001db80: 7365 6c66 2e5f 6c65 7665 7261 6765 5f74  self._leverage_t
-0001db90: 6965 7273 5b70 6169 725d 0a0a 2020 2020  iers[pair]..    
-0001dba0: 2020 2020 2020 2020 6966 2073 7461 6b65          if stake
-0001dbb0: 5f61 6d6f 756e 7420 3d3d 2030 3a0a 2020  _amount == 0:.  
-0001dbc0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-0001dbd0: 7475 726e 2073 656c 662e 5f6c 6576 6572  turn self._lever
-0001dbe0: 6167 655f 7469 6572 735b 7061 6972 5d5b  age_tiers[pair][
-0001dbf0: 305d 5b27 6d61 784c 6576 6572 6167 6527  0]['maxLeverage'
-0001dc00: 5d20 2023 204d 6178 206c 6576 2066 6f72  ]  # Max lev for
-0001dc10: 206c 6f77 6573 7420 616d 6f75 6e74 0a0a   lowest amount..
-0001dc20: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-0001dc30: 7469 6572 5f69 6e64 6578 2069 6e20 7261  tier_index in ra
-0001dc40: 6e67 6528 6c65 6e28 7061 6972 5f74 6965  nge(len(pair_tie
-0001dc50: 7273 2929 3a0a 0a20 2020 2020 2020 2020  rs)):..         
-0001dc60: 2020 2020 2020 2074 6965 7220 3d20 7061         tier = pa
-0001dc70: 6972 5f74 6965 7273 5b74 6965 725f 696e  ir_tiers[tier_in
-0001dc80: 6465 785d 0a20 2020 2020 2020 2020 2020  dex].           
-0001dc90: 2020 2020 206c 6576 203d 2074 6965 725b       lev = tier[
-0001dca0: 276d 6178 4c65 7665 7261 6765 275d 0a0a  'maxLeverage']..
-0001dcb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dcc0: 6966 2074 6965 725f 696e 6465 7820 3c20  if tier_index < 
-0001dcd0: 6c65 6e28 7061 6972 5f74 6965 7273 2920  len(pair_tiers) 
-0001dce0: 2d20 313a 0a20 2020 2020 2020 2020 2020  - 1:.           
-0001dcf0: 2020 2020 2020 2020 206e 6578 745f 7469           next_ti
-0001dd00: 6572 203d 2070 6169 725f 7469 6572 735b  er = pair_tiers[
-0001dd10: 7469 6572 5f69 6e64 6578 202b 2031 5d0a  tier_index + 1].
-0001dd20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dd30: 2020 2020 6e65 7874 5f66 6c6f 6f72 203d      next_floor =
-0001dd40: 206e 6578 745f 7469 6572 5b27 6d69 6e4e   next_tier['minN
-0001dd50: 6f74 696f 6e61 6c27 5d20 2f20 6e65 7874  otional'] / next
-0001dd60: 5f74 6965 725b 276d 6178 4c65 7665 7261  _tier['maxLevera
-0001dd70: 6765 275d 0a20 2020 2020 2020 2020 2020  ge'].           
-0001dd80: 2020 2020 2020 2020 2069 6620 6e65 7874           if next
-0001dd90: 5f66 6c6f 6f72 203e 2073 7461 6b65 5f61  _floor > stake_a
-0001dda0: 6d6f 756e 743a 2020 2320 4e65 7874 2074  mount:  # Next t
-0001ddb0: 6965 7220 6d69 6e20 746f 6f20 6869 6768  ier min too high
-0001ddc0: 2066 6f72 2073 7461 6b65 2061 6d6f 756e   for stake amoun
-0001ddd0: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-0001dde0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0001ddf0: 206d 696e 2828 7469 6572 5b27 6d61 784e   min((tier['maxN
-0001de00: 6f74 696f 6e61 6c27 5d20 2f20 7374 616b  otional'] / stak
-0001de10: 655f 616d 6f75 6e74 292c 206c 6576 290a  e_amount), lev).
-0001de20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001de30: 2020 2020 2020 2020 230a 2020 2020 2020          #.      
-0001de40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001de50: 2020 2320 5769 7468 2074 6865 2074 776f    # With the two
-0001de60: 206c 6576 6572 6167 6520 7469 6572 7320   leverage tiers 
-0001de70: 6265 6c6f 772c 0a20 2020 2020 2020 2020  below,.         
-0001de80: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-0001de90: 202d 2061 2073 7461 6b65 2061 6d6f 756e   - a stake amoun
-0001dea0: 7420 6f66 2031 3530 2077 6f75 6c64 206d  t of 150 would m
-0001deb0: 6561 6e20 6120 6d61 7820 6c65 7665 7261  ean a max levera
-0001dec0: 6765 206f 6620 2831 3030 3030 202f 2031  ge of (10000 / 1
-0001ded0: 3530 2920 3d20 3636 2e36 360a 2020 2020  50) = 66.66.    
-0001dee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001def0: 2020 2020 2320 2d20 7374 616b 6573 2062      # - stakes b
-0001df00: 656c 6f77 2031 3333 2e33 3320 3d20 6d61  elow 133.33 = ma
-0001df10: 785f 6c65 7620 6f66 2037 350a 2020 2020  x_lev of 75.    
-0001df20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001df30: 2020 2020 2320 2d20 7374 616b 6573 2062      # - stakes b
-0001df40: 6574 7765 656e 2031 3333 2e33 332d 3230  etween 133.33-20
-0001df50: 3020 3d20 6d61 785f 6c65 7620 6f66 2031  0 = max_lev of 1
-0001df60: 3030 3030 2f73 7461 6b65 203d 2035 302e  0000/stake = 50.
-0001df70: 3031 2d37 342e 3939 0a20 2020 2020 2020  01-74.99.       
-0001df80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001df90: 2023 202d 2073 7461 6b65 7320 6672 6f6d   # - stakes from
-0001dfa0: 2032 3030 202b 2031 3030 3020 3d20 6d61   200 + 1000 = ma
-0001dfb0: 785f 6c65 7620 6f66 2035 300a 2020 2020  x_lev of 50.    
-0001dfc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dfd0: 2020 2020 230a 2020 2020 2020 2020 2020      #.          
-0001dfe0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0001dff0: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
-0001e000: 2020 2020 2020 2020 2020 2320 2020 2020            #     
-0001e010: 226d 696e 223a 2030 2c20 2020 2020 2023  "min": 0,      #
-0001e020: 2073 7461 6b65 203d 2030 2e30 0a20 2020   stake = 0.0.   
-0001e030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e040: 2020 2020 2023 2020 2020 2022 6d61 7822       #     "max"
-0001e050: 3a20 3130 3030 302c 2020 2320 6d61 785f  : 10000,  # max_
-0001e060: 7374 616b 6540 3735 203d 2031 3030 3030  stake@75 = 10000
-0001e070: 2f37 3520 3d20 3133 332e 3333 3333 3333  /75 = 133.333333
-0001e080: 3333 3333 3333 3334 0a20 2020 2020 2020  33333334.       
-0001e090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e0a0: 2023 2020 2020 2022 6c65 7622 3a20 3735   #     "lev": 75
-0001e0b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0001e0c0: 2020 2020 2020 2020 2020 2320 7d2c 0a20            # },. 
-0001e0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e0e0: 2020 2020 2020 2023 207b 0a20 2020 2020         # {.     
-0001e0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e100: 2020 2023 2020 2020 2022 6d69 6e22 3a20     #     "min": 
-0001e110: 3130 3030 302c 2020 2320 7374 616b 6520  10000,  # stake 
-0001e120: 3d20 3230 302e 300a 2020 2020 2020 2020  = 200.0.        
-0001e130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e140: 2320 2020 2020 226d 6178 223a 2035 3030  #     "max": 500
-0001e150: 3030 2c20 2023 206d 6178 5f73 7461 6b65  00,  # max_stake
-0001e160: 4035 3020 3d20 3530 3030 302f 3530 203d  @50 = 50000/50 =
-0001e170: 2031 3030 302e 300a 2020 2020 2020 2020   1000.0.        
+00017fe0: 2020 2020 2020 2020 2072 6573 756c 7473           results
+00017ff0: 5f64 665b 2870 6169 722c 2074 696d 6566  _df[(pair, timef
+00018000: 7261 6d65 2c20 635f 7479 7065 295d 203d  rame, c_type)] =
+00018010: 206f 686c 6376 5f64 660a 0a20 2020 2020   ohlcv_df..     
+00018020: 2020 2023 2052 6574 7572 6e20 6361 6368     # Return cach
+00018030: 6564 206b 6c69 6e65 730a 2020 2020 2020  ed klines.      
+00018040: 2020 666f 7220 7061 6972 2c20 7469 6d65    for pair, time
+00018050: 6672 616d 652c 2063 5f74 7970 6520 696e  frame, c_type in
+00018060: 2063 6163 6865 645f 7061 6972 733a 0a20   cached_pairs:. 
+00018070: 2020 2020 2020 2020 2020 2072 6573 756c             resul
+00018080: 7473 5f64 665b 2870 6169 722c 2074 696d  ts_df[(pair, tim
+00018090: 6566 7261 6d65 2c20 635f 7479 7065 295d  eframe, c_type)]
+000180a0: 203d 2073 656c 662e 6b6c 696e 6573 280a   = self.klines(.
+000180b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000180c0: 2870 6169 722c 2074 696d 6566 7261 6d65  (pair, timeframe
+000180d0: 2c20 635f 7479 7065 292c 2063 6f70 793d  , c_type), copy=
+000180e0: 4661 6c73 650a 2020 2020 2020 2020 2020  False.          
+000180f0: 2020 290a 0a20 2020 2020 2020 2072 6574    )..        ret
+00018100: 7572 6e20 7265 7375 6c74 735f 6466 0a0a  urn results_df..
+00018110: 2020 2020 6465 6620 7265 6672 6573 685f      def refresh_
+00018120: 6f68 6c63 765f 7769 7468 5f63 6163 6865  ohlcv_with_cache
+00018130: 280a 2020 2020 2020 2020 7365 6c66 2c20  (.        self, 
+00018140: 7061 6972 733a 204c 6973 745b 5061 6972  pairs: List[Pair
+00018150: 5769 7468 5469 6d65 6672 616d 655d 2c20  WithTimeframe], 
+00018160: 7369 6e63 655f 6d73 3a20 696e 740a 2020  since_ms: int.  
+00018170: 2020 2920 2d3e 2044 6963 745b 5061 6972    ) -> Dict[Pair
+00018180: 5769 7468 5469 6d65 6672 616d 652c 2044  WithTimeframe, D
+00018190: 6174 6146 7261 6d65 5d3a 0a20 2020 2020  ataFrame]:.     
+000181a0: 2020 2022 2222 0a20 2020 2020 2020 2052     """.        R
+000181b0: 6566 7265 7368 206f 686c 6376 2064 6174  efresh ohlcv dat
+000181c0: 6120 666f 7220 616c 6c20 7061 6972 7320  a for all pairs 
+000181d0: 696e 206e 6565 6465 645f 7061 6972 7320  in needed_pairs 
+000181e0: 6966 206e 6563 6573 7361 7279 2e0a 2020  if necessary..  
+000181f0: 2020 2020 2020 4361 6368 6573 2064 6174        Caches dat
+00018200: 6120 7769 7468 2065 7870 6972 696e 6720  a with expiring 
+00018210: 7065 7220 7469 6d65 6672 616d 652e 0a20  per timeframe.. 
+00018220: 2020 2020 2020 2053 686f 756c 6420 6f6e         Should on
+00018230: 6c79 2062 6520 7573 6564 2066 6f72 2070  ly be used for p
+00018240: 6169 726c 6973 7473 2077 6869 6368 206e  airlists which n
+00018250: 6565 6420 226f 6e20 7469 6d65 2220 6578  eed "on time" ex
+00018260: 7069 7261 7269 6f6e 2c20 616e 6420 6e6f  pirarion, and no
+00018270: 206c 6f6e 6765 7220 6361 6368 652e 0a20   longer cache.. 
+00018280: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
+00018290: 2020 2020 7469 6d65 6672 616d 6573 203d      timeframes =
+000182a0: 207b 705b 315d 2066 6f72 2070 2069 6e20   {p[1] for p in 
+000182b0: 7061 6972 737d 0a20 2020 2020 2020 2066  pairs}.        f
+000182c0: 6f72 2074 696d 6566 7261 6d65 2069 6e20  or timeframe in 
+000182d0: 7469 6d65 6672 616d 6573 3a0a 2020 2020  timeframes:.    
+000182e0: 2020 2020 2020 2020 6966 2028 7469 6d65          if (time
+000182f0: 6672 616d 652c 2073 696e 6365 5f6d 7329  frame, since_ms)
+00018300: 206e 6f74 2069 6e20 7365 6c66 2e5f 6578   not in self._ex
+00018310: 7069 7269 6e67 5f63 616e 646c 655f 6361  piring_candle_ca
+00018320: 6368 653a 0a20 2020 2020 2020 2020 2020  che:.           
+00018330: 2020 2020 2074 696d 6566 7261 6d65 5f69       timeframe_i
+00018340: 6e5f 7365 6320 3d20 7469 6d65 6672 616d  n_sec = timefram
+00018350: 655f 746f 5f73 6563 6f6e 6473 2874 696d  e_to_seconds(tim
+00018360: 6566 7261 6d65 290a 2020 2020 2020 2020  eframe).        
+00018370: 2020 2020 2020 2020 2320 496e 6974 6961          # Initia
+00018380: 6c69 7365 2063 6163 6865 0a20 2020 2020  lise cache.     
+00018390: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000183a0: 5f65 7870 6972 696e 675f 6361 6e64 6c65  _expiring_candle
+000183b0: 5f63 6163 6865 5b28 7469 6d65 6672 616d  _cache[(timefram
+000183c0: 652c 2073 696e 6365 5f6d 7329 5d20 3d20  e, since_ms)] = 
+000183d0: 5065 7269 6f64 6963 4361 6368 6528 0a20  PeriodicCache(. 
+000183e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000183f0: 2020 2074 746c 3d74 696d 6566 7261 6d65     ttl=timeframe
+00018400: 5f69 6e5f 7365 632c 206d 6178 7369 7a65  _in_sec, maxsize
+00018410: 3d31 3030 300a 2020 2020 2020 2020 2020  =1000.          
+00018420: 2020 2020 2020 290a 0a20 2020 2020 2020        )..       
+00018430: 2023 2047 6574 2063 616e 646c 6573 2066   # Get candles f
+00018440: 726f 6d20 6361 6368 650a 2020 2020 2020  rom cache.      
+00018450: 2020 6361 6e64 6c65 7320 3d20 7b0a 2020    candles = {.  
+00018460: 2020 2020 2020 2020 2020 633a 2073 656c            c: sel
+00018470: 662e 5f65 7870 6972 696e 675f 6361 6e64  f._expiring_cand
+00018480: 6c65 5f63 6163 6865 5b28 635b 315d 2c20  le_cache[(c[1], 
+00018490: 7369 6e63 655f 6d73 295d 2e67 6574 2863  since_ms)].get(c
+000184a0: 2c20 4e6f 6e65 290a 2020 2020 2020 2020  , None).        
+000184b0: 2020 2020 666f 7220 6320 696e 2070 6169      for c in pai
+000184c0: 7273 0a20 2020 2020 2020 2020 2020 2069  rs.            i
+000184d0: 6620 6320 696e 2073 656c 662e 5f65 7870  f c in self._exp
+000184e0: 6972 696e 675f 6361 6e64 6c65 5f63 6163  iring_candle_cac
+000184f0: 6865 5b28 635b 315d 2c20 7369 6e63 655f  he[(c[1], since_
+00018500: 6d73 295d 0a20 2020 2020 2020 207d 0a20  ms)].        }. 
+00018510: 2020 2020 2020 2070 6169 7273 5f74 6f5f         pairs_to_
+00018520: 646f 776e 6c6f 6164 203d 205b 7020 666f  download = [p fo
+00018530: 7220 7020 696e 2070 6169 7273 2069 6620  r p in pairs if 
+00018540: 7020 6e6f 7420 696e 2063 616e 646c 6573  p not in candles
+00018550: 5d0a 2020 2020 2020 2020 6966 2070 6169  ].        if pai
+00018560: 7273 5f74 6f5f 646f 776e 6c6f 6164 3a0a  rs_to_download:.
+00018570: 2020 2020 2020 2020 2020 2020 6361 6e64              cand
+00018580: 6c65 7320 3d20 7365 6c66 2e72 6566 7265  les = self.refre
+00018590: 7368 5f6c 6174 6573 745f 6f68 6c63 7628  sh_latest_ohlcv(
+000185a0: 7061 6972 735f 746f 5f64 6f77 6e6c 6f61  pairs_to_downloa
+000185b0: 642c 2073 696e 6365 5f6d 733d 7369 6e63  d, since_ms=sinc
+000185c0: 655f 6d73 2c20 6361 6368 653d 4661 6c73  e_ms, cache=Fals
+000185d0: 6529 0a20 2020 2020 2020 2020 2020 2066  e).            f
+000185e0: 6f72 2063 2c20 7661 6c20 696e 2063 616e  or c, val in can
+000185f0: 646c 6573 2e69 7465 6d73 2829 3a0a 2020  dles.items():.  
+00018600: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00018610: 6c66 2e5f 6578 7069 7269 6e67 5f63 616e  lf._expiring_can
+00018620: 646c 655f 6361 6368 655b 2863 5b31 5d2c  dle_cache[(c[1],
+00018630: 2073 696e 6365 5f6d 7329 5d5b 635d 203d   since_ms)][c] =
+00018640: 2076 616c 0a20 2020 2020 2020 2072 6574   val.        ret
+00018650: 7572 6e20 6361 6e64 6c65 730a 0a20 2020  urn candles..   
+00018660: 2064 6566 205f 6e6f 775f 6973 5f74 696d   def _now_is_tim
+00018670: 655f 746f 5f72 6566 7265 7368 2873 656c  e_to_refresh(sel
+00018680: 662c 2070 6169 723a 2073 7472 2c20 7469  f, pair: str, ti
+00018690: 6d65 6672 616d 653a 2073 7472 2c20 6361  meframe: str, ca
+000186a0: 6e64 6c65 5f74 7970 653a 2043 616e 646c  ndle_type: Candl
+000186b0: 6554 7970 6529 202d 3e20 626f 6f6c 3a0a  eType) -> bool:.
+000186c0: 2020 2020 2020 2020 2320 5469 6d65 6672          # Timefr
+000186d0: 616d 6520 696e 2073 6563 6f6e 6473 0a20  ame in seconds. 
+000186e0: 2020 2020 2020 2069 6e74 6572 7661 6c5f         interval_
+000186f0: 696e 5f73 6563 203d 2074 696d 6566 7261  in_sec = timefra
+00018700: 6d65 5f74 6f5f 7365 636f 6e64 7328 7469  me_to_seconds(ti
+00018710: 6d65 6672 616d 6529 0a20 2020 2020 2020  meframe).       
+00018720: 2070 6c72 203d 2073 656c 662e 5f70 6169   plr = self._pai
+00018730: 7273 5f6c 6173 745f 7265 6672 6573 685f  rs_last_refresh_
+00018740: 7469 6d65 2e67 6574 2828 7061 6972 2c20  time.get((pair, 
+00018750: 7469 6d65 6672 616d 652c 2063 616e 646c  timeframe, candl
+00018760: 655f 7479 7065 292c 2030 2920 2b20 696e  e_type), 0) + in
+00018770: 7465 7276 616c 5f69 6e5f 7365 630a 2020  terval_in_sec.  
+00018780: 2020 2020 2020 2320 6375 7272 656e 742c        # current,
+00018790: 6163 7469 7665 2063 616e 646c 6520 6f70  active candle op
+000187a0: 656e 2064 6174 650a 2020 2020 2020 2020  en date.        
+000187b0: 6e6f 7720 3d20 696e 7428 7469 6d65 6672  now = int(timefr
+000187c0: 616d 655f 746f 5f70 7265 765f 6461 7465  ame_to_prev_date
+000187d0: 2874 696d 6566 7261 6d65 292e 7469 6d65  (timeframe).time
+000187e0: 7374 616d 7028 2929 0a20 2020 2020 2020  stamp()).       
+000187f0: 2072 6574 7572 6e20 706c 7220 3c20 6e6f   return plr < no
+00018800: 770a 0a20 2020 2040 7265 7472 6965 725f  w..    @retrier_
+00018810: 6173 796e 630a 2020 2020 6173 796e 6320  async.    async 
+00018820: 6465 6620 5f61 7379 6e63 5f67 6574 5f63  def _async_get_c
+00018830: 616e 646c 655f 6869 7374 6f72 7928 0a20  andle_history(. 
+00018840: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
+00018850: 2020 2020 2070 6169 723a 2073 7472 2c0a       pair: str,.
+00018860: 2020 2020 2020 2020 7469 6d65 6672 616d          timefram
+00018870: 653a 2073 7472 2c0a 2020 2020 2020 2020  e: str,.        
+00018880: 6361 6e64 6c65 5f74 7970 653a 2043 616e  candle_type: Can
+00018890: 646c 6554 7970 652c 0a20 2020 2020 2020  dleType,.       
+000188a0: 2073 696e 6365 5f6d 733a 204f 7074 696f   since_ms: Optio
+000188b0: 6e61 6c5b 696e 745d 203d 204e 6f6e 652c  nal[int] = None,
+000188c0: 0a20 2020 2029 202d 3e20 4f48 4c43 5652  .    ) -> OHLCVR
+000188d0: 6573 706f 6e73 653a 0a20 2020 2020 2020  esponse:.       
+000188e0: 2022 2222 0a20 2020 2020 2020 2041 7379   """.        Asy
+000188f0: 6e63 6872 6f6e 6f75 736c 7920 6765 7420  nchronously get 
+00018900: 6361 6e64 6c65 2068 6973 746f 7279 2064  candle history d
+00018910: 6174 6120 7573 696e 6720 6665 7463 685f  ata using fetch_
+00018920: 6f68 6c63 760a 2020 2020 2020 2020 3a70  ohlcv.        :p
+00018930: 6172 616d 2063 616e 646c 655f 7479 7065  aram candle_type
+00018940: 3a20 2727 2c20 6d61 726b 2c20 696e 6465  : '', mark, inde
+00018950: 782c 2070 7265 6d69 756d 496e 6465 782c  x, premiumIndex,
+00018960: 206f 7220 6675 6e64 696e 675f 7261 7465   or funding_rate
+00018970: 0a20 2020 2020 2020 2072 6574 7572 6e73  .        returns
+00018980: 2074 7570 6c65 3a20 2870 6169 722c 2074   tuple: (pair, t
+00018990: 696d 6566 7261 6d65 2c20 6f68 6c63 765f  imeframe, ohlcv_
+000189a0: 6c69 7374 290a 2020 2020 2020 2020 2222  list).        ""
+000189b0: 220a 2020 2020 2020 2020 7472 793a 0a20  ".        try:. 
+000189c0: 2020 2020 2020 2020 2020 2023 2046 6574             # Fet
+000189d0: 6368 204f 484c 4356 2061 7379 6e63 6872  ch OHLCV asynchr
+000189e0: 6f6e 6f75 736c 790a 2020 2020 2020 2020  onously.        
+000189f0: 2020 2020 7320 3d20 2228 2220 2b20 6474      s = "(" + dt
+00018a00: 5f66 726f 6d5f 7473 2873 696e 6365 5f6d  _from_ts(since_m
+00018a10: 7329 2e69 736f 666f 726d 6174 2829 202b  s).isoformat() +
+00018a20: 2022 2920 2220 6966 2073 696e 6365 5f6d   ") " if since_m
+00018a30: 7320 6973 206e 6f74 204e 6f6e 6520 656c  s is not None el
+00018a40: 7365 2022 220a 2020 2020 2020 2020 2020  se "".          
+00018a50: 2020 6c6f 6767 6572 2e64 6562 7567 280a    logger.debug(.
+00018a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018a70: 2246 6574 6368 696e 6720 7061 6972 2025  "Fetching pair %
+00018a80: 732c 2025 732c 2069 6e74 6572 7661 6c20  s, %s, interval 
+00018a90: 2573 2c20 7369 6e63 6520 2573 2025 732e  %s, since %s %s.
+00018aa0: 2e2e 222c 0a20 2020 2020 2020 2020 2020  ..",.           
+00018ab0: 2020 2020 2070 6169 722c 0a20 2020 2020       pair,.     
+00018ac0: 2020 2020 2020 2020 2020 2063 616e 646c             candl
+00018ad0: 655f 7479 7065 2c0a 2020 2020 2020 2020  e_type,.        
+00018ae0: 2020 2020 2020 2020 7469 6d65 6672 616d          timefram
+00018af0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00018b00: 2020 2073 696e 6365 5f6d 732c 0a20 2020     since_ms,.   
+00018b10: 2020 2020 2020 2020 2020 2020 2073 2c0a               s,.
+00018b20: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00018b30: 2020 2020 2020 2020 2020 7061 7261 6d73            params
+00018b40: 203d 2064 6565 7063 6f70 7928 7365 6c66   = deepcopy(self
+00018b50: 2e5f 6674 5f68 6173 2e67 6574 2822 6f68  ._ft_has.get("oh
+00018b60: 6c63 765f 7061 7261 6d73 222c 207b 7d29  lcv_params", {})
+00018b70: 290a 2020 2020 2020 2020 2020 2020 6361  ).            ca
+00018b80: 6e64 6c65 5f6c 696d 6974 203d 2073 656c  ndle_limit = sel
+00018b90: 662e 6f68 6c63 765f 6361 6e64 6c65 5f6c  f.ohlcv_candle_l
+00018ba0: 696d 6974 280a 2020 2020 2020 2020 2020  imit(.          
+00018bb0: 2020 2020 2020 7469 6d65 6672 616d 652c        timeframe,
+00018bc0: 2063 616e 646c 655f 7479 7065 3d63 616e   candle_type=can
+00018bd0: 646c 655f 7479 7065 2c20 7369 6e63 655f  dle_type, since_
+00018be0: 6d73 3d73 696e 6365 5f6d 730a 2020 2020  ms=since_ms.    
+00018bf0: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
+00018c00: 2020 2020 2020 2069 6620 6361 6e64 6c65         if candle
+00018c10: 5f74 7970 6520 616e 6420 6361 6e64 6c65  _type and candle
+00018c20: 5f74 7970 6520 213d 2043 616e 646c 6554  _type != CandleT
+00018c30: 7970 652e 5350 4f54 3a0a 2020 2020 2020  ype.SPOT:.      
+00018c40: 2020 2020 2020 2020 2020 7061 7261 6d73            params
+00018c50: 2e75 7064 6174 6528 7b22 7072 6963 6522  .update({"price"
+00018c60: 3a20 6361 6e64 6c65 5f74 7970 652e 7661  : candle_type.va
+00018c70: 6c75 657d 290a 2020 2020 2020 2020 2020  lue}).          
+00018c80: 2020 6966 2063 616e 646c 655f 7479 7065    if candle_type
+00018c90: 2021 3d20 4361 6e64 6c65 5479 7065 2e46   != CandleType.F
+00018ca0: 554e 4449 4e47 5f52 4154 453a 0a20 2020  UNDING_RATE:.   
+00018cb0: 2020 2020 2020 2020 2020 2020 2064 6174               dat
+00018cc0: 6120 3d20 6177 6169 7420 7365 6c66 2e5f  a = await self._
+00018cd0: 6170 695f 6173 796e 632e 6665 7463 685f  api_async.fetch_
+00018ce0: 6f68 6c63 7628 0a20 2020 2020 2020 2020  ohlcv(.         
+00018cf0: 2020 2020 2020 2020 2020 2070 6169 722c             pair,
+00018d00: 2074 696d 6566 7261 6d65 3d74 696d 6566   timeframe=timef
+00018d10: 7261 6d65 2c20 7369 6e63 653d 7369 6e63  rame, since=sinc
+00018d20: 655f 6d73 2c20 6c69 6d69 743d 6361 6e64  e_ms, limit=cand
+00018d30: 6c65 5f6c 696d 6974 2c20 7061 7261 6d73  le_limit, params
+00018d40: 3d70 6172 616d 730a 2020 2020 2020 2020  =params.        
+00018d50: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00018d60: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00018d70: 2020 2020 2020 2020 2020 2020 2320 4675              # Fu
+00018d80: 6e64 696e 6720 7261 7465 0a20 2020 2020  nding rate.     
+00018d90: 2020 2020 2020 2020 2020 2064 6174 6120             data 
+00018da0: 3d20 6177 6169 7420 7365 6c66 2e5f 6665  = await self._fe
+00018db0: 7463 685f 6675 6e64 696e 675f 7261 7465  tch_funding_rate
+00018dc0: 5f68 6973 746f 7279 280a 2020 2020 2020  _history(.      
+00018dd0: 2020 2020 2020 2020 2020 2020 2020 7061                pa
+00018de0: 6972 3d70 6169 722c 0a20 2020 2020 2020  ir=pair,.       
+00018df0: 2020 2020 2020 2020 2020 2020 2074 696d               tim
+00018e00: 6566 7261 6d65 3d74 696d 6566 7261 6d65  eframe=timeframe
+00018e10: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00018e20: 2020 2020 2020 6c69 6d69 743d 6361 6e64        limit=cand
+00018e30: 6c65 5f6c 696d 6974 2c0a 2020 2020 2020  le_limit,.      
+00018e40: 2020 2020 2020 2020 2020 2020 2020 7369                si
+00018e50: 6e63 655f 6d73 3d73 696e 6365 5f6d 732c  nce_ms=since_ms,
+00018e60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018e70: 2029 0a20 2020 2020 2020 2020 2020 2023   ).            #
+00018e80: 2053 6f6d 6520 6578 6368 616e 6765 7320   Some exchanges 
+00018e90: 736f 7274 204f 484c 4356 2069 6e20 4153  sort OHLCV in AS
+00018ea0: 4320 6f72 6465 7220 616e 6420 6f74 6865  C order and othe
+00018eb0: 7273 2069 6e20 4445 5343 2e0a 2020 2020  rs in DESC..    
+00018ec0: 2020 2020 2020 2020 2320 4578 3a20 4269          # Ex: Bi
+00018ed0: 7474 7265 7820 7265 7475 726e 7320 7468  ttrex returns th
+00018ee0: 6520 6c69 7374 206f 6620 4f48 4c43 5620  e list of OHLCV 
+00018ef0: 696e 2041 5343 206f 7264 6572 2028 6f6c  in ASC order (ol
+00018f00: 6465 7374 2066 6972 7374 2c20 6e65 7765  dest first, newe
+00018f10: 7374 206c 6173 7429 0a20 2020 2020 2020  st last).       
+00018f20: 2020 2020 2023 2077 6869 6c65 2047 4441       # while GDA
+00018f30: 5820 7265 7475 726e 7320 7468 6520 6c69  X returns the li
+00018f40: 7374 206f 6620 4f48 4c43 5620 696e 2044  st of OHLCV in D
+00018f50: 4553 4320 6f72 6465 7220 286e 6577 6573  ESC order (newes
+00018f60: 7420 6669 7273 742c 206f 6c64 6573 7420  t first, oldest 
+00018f70: 6c61 7374 290a 2020 2020 2020 2020 2020  last).          
+00018f80: 2020 2320 4f6e 6c79 2073 6f72 7420 6966    # Only sort if
+00018f90: 206e 6563 6573 7361 7279 2074 6f20 7361   necessary to sa
+00018fa0: 7665 2063 6f6d 7075 7469 6e67 2074 696d  ve computing tim
+00018fb0: 650a 2020 2020 2020 2020 2020 2020 7472  e.            tr
+00018fc0: 793a 0a20 2020 2020 2020 2020 2020 2020  y:.             
+00018fd0: 2020 2069 6620 6461 7461 2061 6e64 2064     if data and d
+00018fe0: 6174 615b 305d 5b30 5d20 3e20 6461 7461  ata[0][0] > data
+00018ff0: 5b2d 315d 5b30 5d3a 0a20 2020 2020 2020  [-1][0]:.       
+00019000: 2020 2020 2020 2020 2020 2020 2064 6174               dat
+00019010: 6120 3d20 736f 7274 6564 2864 6174 612c  a = sorted(data,
+00019020: 206b 6579 3d6c 616d 6264 6120 783a 2078   key=lambda x: x
+00019030: 5b30 5d29 0a20 2020 2020 2020 2020 2020  [0]).           
+00019040: 2065 7863 6570 7420 496e 6465 7845 7272   except IndexErr
+00019050: 6f72 3a0a 2020 2020 2020 2020 2020 2020  or:.            
+00019060: 2020 2020 6c6f 6767 6572 2e65 7863 6570      logger.excep
+00019070: 7469 6f6e 2822 4572 726f 7220 6c6f 6164  tion("Error load
+00019080: 696e 6720 2573 2e20 5265 7375 6c74 2077  ing %s. Result w
+00019090: 6173 2025 732e 222c 2070 6169 722c 2064  as %s.", pair, d
+000190a0: 6174 6129 0a20 2020 2020 2020 2020 2020  ata).           
+000190b0: 2020 2020 2072 6574 7572 6e20 7061 6972       return pair
+000190c0: 2c20 7469 6d65 6672 616d 652c 2063 616e  , timeframe, can
+000190d0: 646c 655f 7479 7065 2c20 5b5d 2c20 7365  dle_type, [], se
+000190e0: 6c66 2e5f 6f68 6c63 765f 7061 7274 6961  lf._ohlcv_partia
+000190f0: 6c5f 6361 6e64 6c65 0a20 2020 2020 2020  l_candle.       
+00019100: 2020 2020 206c 6f67 6765 722e 6465 6275       logger.debu
+00019110: 6728 2244 6f6e 6520 6665 7463 6869 6e67  g("Done fetching
+00019120: 2070 6169 7220 2573 2c20 2573 2069 6e74   pair %s, %s int
+00019130: 6572 7661 6c20 2573 2e2e 2e22 2c20 7061  erval %s...", pa
+00019140: 6972 2c20 6361 6e64 6c65 5f74 7970 652c  ir, candle_type,
+00019150: 2074 696d 6566 7261 6d65 290a 2020 2020   timeframe).    
+00019160: 2020 2020 2020 2020 7265 7475 726e 2070          return p
+00019170: 6169 722c 2074 696d 6566 7261 6d65 2c20  air, timeframe, 
+00019180: 6361 6e64 6c65 5f74 7970 652c 2064 6174  candle_type, dat
+00019190: 612c 2073 656c 662e 5f6f 686c 6376 5f70  a, self._ohlcv_p
+000191a0: 6172 7469 616c 5f63 616e 646c 650a 0a20  artial_candle.. 
+000191b0: 2020 2020 2020 2065 7863 6570 7420 6363         except cc
+000191c0: 7874 2e4e 6f74 5375 7070 6f72 7465 6420  xt.NotSupported 
+000191d0: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
+000191e0: 2020 7261 6973 6520 4f70 6572 6174 696f    raise Operatio
+000191f0: 6e61 6c45 7863 6570 7469 6f6e 280a 2020  nalException(.  
+00019200: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+00019210: 4578 6368 616e 6765 207b 7365 6c66 2e5f  Exchange {self._
+00019220: 6170 692e 6e61 6d65 7d20 646f 6573 206e  api.name} does n
+00019230: 6f74 2073 7570 706f 7274 2066 6574 6368  ot support fetch
+00019240: 696e 6720 6869 7374 6f72 6963 616c 2022  ing historical "
+00019250: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019260: 2066 2263 616e 646c 6520 284f 484c 4356   f"candle (OHLCV
+00019270: 2920 6461 7461 2e20 4d65 7373 6167 653a  ) data. Message:
+00019280: 207b 657d 220a 2020 2020 2020 2020 2020   {e}".          
+00019290: 2020 2920 6672 6f6d 2065 0a20 2020 2020    ) from e.     
+000192a0: 2020 2065 7863 6570 7420 6363 7874 2e44     except ccxt.D
+000192b0: 446f 5350 726f 7465 6374 696f 6e20 6173  DoSProtection as
+000192c0: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
+000192d0: 7261 6973 6520 4444 6f73 5072 6f74 6563  raise DDosProtec
+000192e0: 7469 6f6e 2865 2920 6672 6f6d 2065 0a20  tion(e) from e. 
+000192f0: 2020 2020 2020 2065 7863 6570 7420 2863         except (c
+00019300: 6378 742e 4f70 6572 6174 696f 6e46 6169  cxt.OperationFai
+00019310: 6c65 642c 2063 6378 742e 4578 6368 616e  led, ccxt.Exchan
+00019320: 6765 4572 726f 7229 2061 7320 653a 0a20  geError) as e:. 
+00019330: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00019340: 2054 656d 706f 7261 7279 4572 726f 7228   TemporaryError(
+00019350: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019360: 2066 2243 6f75 6c64 206e 6f74 2066 6574   f"Could not fet
+00019370: 6368 2068 6973 746f 7269 6361 6c20 6361  ch historical ca
+00019380: 6e64 6c65 2028 4f48 4c43 5629 2064 6174  ndle (OHLCV) dat
+00019390: 6120 220a 2020 2020 2020 2020 2020 2020  a ".            
+000193a0: 2020 2020 6622 666f 7220 7061 6972 207b      f"for pair {
+000193b0: 7061 6972 7d20 6475 6520 746f 207b 652e  pair} due to {e.
+000193c0: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
+000193d0: 5f5f 7d2e 2022 0a20 2020 2020 2020 2020  __}. ".         
+000193e0: 2020 2020 2020 2066 224d 6573 7361 6765         f"Message
+000193f0: 3a20 7b65 7d22 0a20 2020 2020 2020 2020  : {e}".         
+00019400: 2020 2029 2066 726f 6d20 650a 2020 2020     ) from e.    
+00019410: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
+00019420: 4261 7365 4572 726f 7220 6173 2065 3a0a  BaseError as e:.
+00019430: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00019440: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
+00019450: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
+00019460: 2020 2020 2020 2020 6622 436f 756c 6420          f"Could 
+00019470: 6e6f 7420 6665 7463 6820 6869 7374 6f72  not fetch histor
+00019480: 6963 616c 2063 616e 646c 6520 284f 484c  ical candle (OHL
+00019490: 4356 2920 6461 7461 2066 6f72 2070 6169  CV) data for pai
+000194a0: 7220 7b70 6169 727d 2e20 4d65 7373 6167  r {pair}. Messag
+000194b0: 653a 207b 657d 220a 2020 2020 2020 2020  e: {e}".        
+000194c0: 2020 2020 2920 6672 6f6d 2065 0a0a 2020      ) from e..  
+000194d0: 2020 6173 796e 6320 6465 6620 5f66 6574    async def _fet
+000194e0: 6368 5f66 756e 6469 6e67 5f72 6174 655f  ch_funding_rate_
+000194f0: 6869 7374 6f72 7928 0a20 2020 2020 2020  history(.       
+00019500: 2073 656c 662c 0a20 2020 2020 2020 2070   self,.        p
+00019510: 6169 723a 2073 7472 2c0a 2020 2020 2020  air: str,.      
+00019520: 2020 7469 6d65 6672 616d 653a 2073 7472    timeframe: str
+00019530: 2c0a 2020 2020 2020 2020 6c69 6d69 743a  ,.        limit:
+00019540: 2069 6e74 2c0a 2020 2020 2020 2020 7369   int,.        si
+00019550: 6e63 655f 6d73 3a20 4f70 7469 6f6e 616c  nce_ms: Optional
+00019560: 5b69 6e74 5d20 3d20 4e6f 6e65 2c0a 2020  [int] = None,.  
+00019570: 2020 2920 2d3e 204c 6973 745b 4c69 7374    ) -> List[List
+00019580: 5d3a 0a20 2020 2020 2020 2022 2222 0a20  ]:.        """. 
+00019590: 2020 2020 2020 2046 6574 6368 2066 756e         Fetch fun
+000195a0: 6469 6e67 2072 6174 6520 6869 7374 6f72  ding rate histor
+000195b0: 7920 2d20 7573 6564 2074 6f20 7365 6c65  y - used to sele
+000195c0: 6374 6976 656c 7920 6f76 6572 7269 6465  ctively override
+000195d0: 2074 6869 7320 6279 2073 7562 636c 6173   this by subclas
+000195e0: 7365 732e 0a20 2020 2020 2020 2022 2222  ses..        """
+000195f0: 0a20 2020 2020 2020 2023 2046 756e 6469  .        # Fundi
+00019600: 6e67 2072 6174 650a 2020 2020 2020 2020  ng rate.        
+00019610: 6461 7461 203d 2061 7761 6974 2073 656c  data = await sel
+00019620: 662e 5f61 7069 5f61 7379 6e63 2e66 6574  f._api_async.fet
+00019630: 6368 5f66 756e 6469 6e67 5f72 6174 655f  ch_funding_rate_
+00019640: 6869 7374 6f72 7928 7061 6972 2c20 7369  history(pair, si
+00019650: 6e63 653d 7369 6e63 655f 6d73 2c20 6c69  nce=since_ms, li
+00019660: 6d69 743d 6c69 6d69 7429 0a20 2020 2020  mit=limit).     
+00019670: 2020 2023 2043 6f6e 7665 7274 2066 756e     # Convert fun
+00019680: 6469 6e67 2072 6174 6520 746f 2063 616e  ding rate to can
+00019690: 646c 6520 7061 7474 6572 6e0a 2020 2020  dle pattern.    
+000196a0: 2020 2020 6461 7461 203d 205b 5b78 5b22      data = [[x["
+000196b0: 7469 6d65 7374 616d 7022 5d2c 2078 5b22  timestamp"], x["
+000196c0: 6675 6e64 696e 6752 6174 6522 5d2c 2030  fundingRate"], 0
+000196d0: 2c20 302c 2030 2c20 305d 2066 6f72 2078  , 0, 0, 0] for x
+000196e0: 2069 6e20 6461 7461 5d0a 2020 2020 2020   in data].      
+000196f0: 2020 7265 7475 726e 2064 6174 610a 0a20    return data.. 
+00019700: 2020 2023 2046 6574 6368 2068 6973 746f     # Fetch histo
+00019710: 7269 6320 7472 6164 6573 0a0a 2020 2020  ric trades..    
+00019720: 4072 6574 7269 6572 5f61 7379 6e63 0a20  @retrier_async. 
+00019730: 2020 2061 7379 6e63 2064 6566 205f 6173     async def _as
+00019740: 796e 635f 6665 7463 685f 7472 6164 6573  ync_fetch_trades
+00019750: 280a 2020 2020 2020 2020 7365 6c66 2c20  (.        self, 
+00019760: 7061 6972 3a20 7374 722c 2073 696e 6365  pair: str, since
+00019770: 3a20 4f70 7469 6f6e 616c 5b69 6e74 5d20  : Optional[int] 
+00019780: 3d20 4e6f 6e65 2c20 7061 7261 6d73 3a20  = None, params: 
+00019790: 4f70 7469 6f6e 616c 5b64 6963 745d 203d  Optional[dict] =
+000197a0: 204e 6f6e 650a 2020 2020 2920 2d3e 2054   None.    ) -> T
+000197b0: 7570 6c65 5b4c 6973 745b 4c69 7374 5d2c  uple[List[List],
+000197c0: 2041 6e79 5d3a 0a20 2020 2020 2020 2022   Any]:.        "
+000197d0: 2222 0a20 2020 2020 2020 2041 7379 6e63  "".        Async
+000197e0: 6872 6f6e 6f75 736c 7920 6765 7473 2074  hronously gets t
+000197f0: 7261 6465 2068 6973 746f 7279 2075 7369  rade history usi
+00019800: 6e67 2066 6574 6368 5f74 7261 6465 732e  ng fetch_trades.
+00019810: 0a20 2020 2020 2020 2048 616e 646c 6573  .        Handles
+00019820: 2065 7863 6861 6e67 6520 6572 726f 7273   exchange errors
+00019830: 2c20 646f 6573 206f 6e65 2063 616c 6c20  , does one call 
+00019840: 746f 2074 6865 2065 7863 6861 6e67 652e  to the exchange.
+00019850: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00019860: 7061 6972 3a20 5061 6972 2074 6f20 6665  pair: Pair to fe
+00019870: 7463 6820 7472 6164 6520 6461 7461 2066  tch trade data f
+00019880: 6f72 0a20 2020 2020 2020 203a 7061 7261  or.        :para
+00019890: 6d20 7369 6e63 653a 2053 696e 6365 2061  m since: Since a
+000198a0: 7320 696e 7465 6765 7220 7469 6d65 7374  s integer timest
+000198b0: 616d 7020 696e 206d 696c 6c69 7365 636f  amp in milliseco
+000198c0: 6e64 730a 2020 2020 2020 2020 7265 7475  nds.        retu
+000198d0: 726e 733a 204c 6973 7420 6f66 2064 6963  rns: List of dic
+000198e0: 7473 2063 6f6e 7461 696e 696e 6720 7472  ts containing tr
+000198f0: 6164 6573 2c20 7468 6520 6e65 7874 2069  ades, the next i
+00019900: 7465 7261 7469 6f6e 2076 616c 7565 2028  teration value (
+00019910: 6e65 7720 2273 696e 6365 2220 6f72 2074  new "since" or t
+00019920: 7261 6465 5f69 6429 0a20 2020 2020 2020  rade_id).       
+00019930: 2022 2222 0a20 2020 2020 2020 2074 7279   """.        try
+00019940: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
+00019950: 6665 7463 6820 7472 6164 6573 2061 7379  fetch trades asy
+00019960: 6e63 6872 6f6e 6f75 736c 790a 2020 2020  nchronously.    
+00019970: 2020 2020 2020 2020 6966 2070 6172 616d          if param
+00019980: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
+00019990: 2020 206c 6f67 6765 722e 6465 6275 6728     logger.debug(
+000199a0: 2246 6574 6368 696e 6720 7472 6164 6573  "Fetching trades
+000199b0: 2066 6f72 2070 6169 7220 2573 2c20 7061   for pair %s, pa
+000199c0: 7261 6d73 3a20 2573 2022 2c20 7061 6972  rams: %s ", pair
+000199d0: 2c20 7061 7261 6d73 290a 2020 2020 2020  , params).      
+000199e0: 2020 2020 2020 2020 2020 7472 6164 6573            trades
+000199f0: 203d 2061 7761 6974 2073 656c 662e 5f61   = await self._a
+00019a00: 7069 5f61 7379 6e63 2e66 6574 6368 5f74  pi_async.fetch_t
+00019a10: 7261 6465 7328 7061 6972 2c20 7061 7261  rades(pair, para
+00019a20: 6d73 3d70 6172 616d 732c 206c 696d 6974  ms=params, limit
+00019a30: 3d31 3030 3029 0a20 2020 2020 2020 2020  =1000).         
+00019a40: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00019a50: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+00019a60: 6465 6275 6728 0a20 2020 2020 2020 2020  debug(.         
+00019a70: 2020 2020 2020 2020 2020 2022 4665 7463             "Fetc
+00019a80: 6869 6e67 2074 7261 6465 7320 666f 7220  hing trades for 
+00019a90: 7061 6972 2025 732c 2073 696e 6365 2025  pair %s, since %
+00019aa0: 7320 2573 2e2e 2e22 2c0a 2020 2020 2020  s %s...",.      
+00019ab0: 2020 2020 2020 2020 2020 2020 2020 7061                pa
+00019ac0: 6972 2c0a 2020 2020 2020 2020 2020 2020  ir,.            
+00019ad0: 2020 2020 2020 2020 7369 6e63 652c 0a20          since,. 
+00019ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019af0: 2020 2022 2822 202b 2064 745f 6672 6f6d     "(" + dt_from
+00019b00: 5f74 7328 7369 6e63 6529 2e69 736f 666f  _ts(since).isofo
+00019b10: 726d 6174 2829 202b 2022 2920 2220 6966  rmat() + ") " if
+00019b20: 2073 696e 6365 2069 7320 6e6f 7420 4e6f   since is not No
+00019b30: 6e65 2065 6c73 6520 2222 2c0a 2020 2020  ne else "",.    
+00019b40: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00019b50: 2020 2020 2020 2020 2020 2020 2020 7472                tr
+00019b60: 6164 6573 203d 2061 7761 6974 2073 656c  ades = await sel
+00019b70: 662e 5f61 7069 5f61 7379 6e63 2e66 6574  f._api_async.fet
+00019b80: 6368 5f74 7261 6465 7328 7061 6972 2c20  ch_trades(pair, 
+00019b90: 7369 6e63 653d 7369 6e63 652c 206c 696d  since=since, lim
+00019ba0: 6974 3d31 3030 3029 0a20 2020 2020 2020  it=1000).       
+00019bb0: 2020 2020 2074 7261 6465 7320 3d20 7365       trades = se
+00019bc0: 6c66 2e5f 7472 6164 6573 5f63 6f6e 7472  lf._trades_contr
+00019bd0: 6163 7473 5f74 6f5f 616d 6f75 6e74 2874  acts_to_amount(t
+00019be0: 7261 6465 7329 0a20 2020 2020 2020 2020  rades).         
+00019bf0: 2020 2070 6167 696e 6174 696f 6e5f 7661     pagination_va
+00019c00: 6c75 6520 3d20 7365 6c66 2e5f 6765 745f  lue = self._get_
+00019c10: 7472 6164 655f 7061 6769 6e61 7469 6f6e  trade_pagination
+00019c20: 5f6e 6578 745f 7661 6c75 6528 7472 6164  _next_value(trad
+00019c30: 6573 290a 2020 2020 2020 2020 2020 2020  es).            
+00019c40: 7265 7475 726e 2074 7261 6465 735f 6469  return trades_di
+00019c50: 6374 5f74 6f5f 6c69 7374 2874 7261 6465  ct_to_list(trade
+00019c60: 7329 2c20 7061 6769 6e61 7469 6f6e 5f76  s), pagination_v
+00019c70: 616c 7565 0a20 2020 2020 2020 2065 7863  alue.        exc
+00019c80: 6570 7420 6363 7874 2e4e 6f74 5375 7070  ept ccxt.NotSupp
+00019c90: 6f72 7465 6420 6173 2065 3a0a 2020 2020  orted as e:.    
+00019ca0: 2020 2020 2020 2020 7261 6973 6520 4f70          raise Op
+00019cb0: 6572 6174 696f 6e61 6c45 7863 6570 7469  erationalExcepti
+00019cc0: 6f6e 280a 2020 2020 2020 2020 2020 2020  on(.            
+00019cd0: 2020 2020 6622 4578 6368 616e 6765 207b      f"Exchange {
+00019ce0: 7365 6c66 2e5f 6170 692e 6e61 6d65 7d20  self._api.name} 
+00019cf0: 646f 6573 206e 6f74 2073 7570 706f 7274  does not support
+00019d00: 2066 6574 6368 696e 6720 6869 7374 6f72   fetching histor
+00019d10: 6963 616c 2074 7261 6465 2064 6174 612e  ical trade data.
+00019d20: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00019d30: 2020 6622 4d65 7373 6167 653a 207b 657d    f"Message: {e}
+00019d40: 220a 2020 2020 2020 2020 2020 2020 2920  ".            ) 
+00019d50: 6672 6f6d 2065 0a20 2020 2020 2020 2065  from e.        e
+00019d60: 7863 6570 7420 6363 7874 2e44 446f 5350  xcept ccxt.DDoSP
+00019d70: 726f 7465 6374 696f 6e20 6173 2065 3a0a  rotection as e:.
+00019d80: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00019d90: 6520 4444 6f73 5072 6f74 6563 7469 6f6e  e DDosProtection
+00019da0: 2865 2920 6672 6f6d 2065 0a20 2020 2020  (e) from e.     
+00019db0: 2020 2065 7863 6570 7420 2863 6378 742e     except (ccxt.
+00019dc0: 4f70 6572 6174 696f 6e46 6169 6c65 642c  OperationFailed,
+00019dd0: 2063 6378 742e 4578 6368 616e 6765 4572   ccxt.ExchangeEr
+00019de0: 726f 7229 2061 7320 653a 0a20 2020 2020  ror) as e:.     
+00019df0: 2020 2020 2020 2072 6169 7365 2054 656d         raise Tem
+00019e00: 706f 7261 7279 4572 726f 7228 0a20 2020  poraryError(.   
+00019e10: 2020 2020 2020 2020 2020 2020 2066 2243               f"C
+00019e20: 6f75 6c64 206e 6f74 206c 6f61 6420 7472  ould not load tr
+00019e30: 6164 6520 6869 7374 6f72 7920 6475 6520  ade history due 
+00019e40: 746f 207b 652e 5f5f 636c 6173 735f 5f2e  to {e.__class__.
+00019e50: 5f5f 6e61 6d65 5f5f 7d2e 204d 6573 7361  __name__}. Messa
+00019e60: 6765 3a20 7b65 7d22 0a20 2020 2020 2020  ge: {e}".       
+00019e70: 2020 2020 2029 2066 726f 6d20 650a 2020       ) from e.  
+00019e80: 2020 2020 2020 6578 6365 7074 2063 6378        except ccx
+00019e90: 742e 4261 7365 4572 726f 7220 6173 2065  t.BaseError as e
+00019ea0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+00019eb0: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
+00019ec0: 7863 6570 7469 6f6e 2866 2243 6f75 6c64  xception(f"Could
+00019ed0: 206e 6f74 2066 6574 6368 2074 7261 6465   not fetch trade
+00019ee0: 2064 6174 612e 204d 7367 3a20 7b65 7d22   data. Msg: {e}"
+00019ef0: 2920 6672 6f6d 2065 0a0a 2020 2020 6465  ) from e..    de
+00019f00: 6620 5f76 616c 6964 5f74 7261 6465 5f70  f _valid_trade_p
+00019f10: 6167 696e 6174 696f 6e5f 6964 2873 656c  agination_id(sel
+00019f20: 662c 2070 6169 723a 2073 7472 2c20 6672  f, pair: str, fr
+00019f30: 6f6d 5f69 643a 2073 7472 2920 2d3e 2062  om_id: str) -> b
+00019f40: 6f6f 6c3a 0a20 2020 2020 2020 2022 2222  ool:.        """
+00019f50: 0a20 2020 2020 2020 2056 6572 6966 7920  .        Verify 
+00019f60: 7472 6164 652d 7061 6769 6e61 7469 6f6e  trade-pagination
+00019f70: 2069 6420 6973 2076 616c 6964 2e0a 2020   id is valid..  
+00019f80: 2020 2020 2020 576f 726b 6172 6f75 6e64        Workaround
+00019f90: 2066 6f72 206f 6464 204b 7261 6b65 6e20   for odd Kraken 
+00019fa0: 6973 7375 6520 7768 6572 6520 4944 2069  issue where ID i
+00019fb0: 7320 736f 6d65 7469 6d65 7320 7772 6f6e  s sometimes wron
+00019fc0: 672e 0a20 2020 2020 2020 2022 2222 0a20  g..        """. 
+00019fd0: 2020 2020 2020 2072 6574 7572 6e20 5472         return Tr
+00019fe0: 7565 0a0a 2020 2020 6465 6620 5f67 6574  ue..    def _get
+00019ff0: 5f74 7261 6465 5f70 6167 696e 6174 696f  _trade_paginatio
+0001a000: 6e5f 6e65 7874 5f76 616c 7565 2873 656c  n_next_value(sel
+0001a010: 662c 2074 7261 6465 733a 204c 6973 745b  f, trades: List[
+0001a020: 4469 6374 5d29 3a0a 2020 2020 2020 2020  Dict]):.        
+0001a030: 2222 220a 2020 2020 2020 2020 4578 7472  """.        Extr
+0001a040: 6163 7420 7061 6769 6e61 7469 6f6e 2069  act pagination i
+0001a050: 6420 666f 7220 7468 6520 6e65 7874 2022  d for the next "
+0001a060: 6672 6f6d 5f69 6422 2076 616c 7565 0a20  from_id" value. 
+0001a070: 2020 2020 2020 2041 7070 6c69 6573 206f         Applies o
+0001a080: 6e6c 7920 746f 2066 6574 6368 5f74 7261  nly to fetch_tra
+0001a090: 6465 5f68 6973 746f 7279 2062 7920 6964  de_history by id
+0001a0a0: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+0001a0b0: 2020 2020 2020 6966 206e 6f74 2074 7261        if not tra
+0001a0c0: 6465 733a 0a20 2020 2020 2020 2020 2020  des:.           
+0001a0d0: 2072 6574 7572 6e20 4e6f 6e65 0a20 2020   return None.   
+0001a0e0: 2020 2020 2069 6620 7365 6c66 2e5f 7472       if self._tr
+0001a0f0: 6164 6573 5f70 6167 696e 6174 696f 6e20  ades_pagination 
+0001a100: 3d3d 2022 6964 223a 0a20 2020 2020 2020  == "id":.       
+0001a110: 2020 2020 2072 6574 7572 6e20 7472 6164       return trad
+0001a120: 6573 5b2d 315d 2e67 6574 2822 6964 2229  es[-1].get("id")
+0001a130: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+0001a140: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0001a150: 6e20 7472 6164 6573 5b2d 315d 2e67 6574  n trades[-1].get
+0001a160: 2822 7469 6d65 7374 616d 7022 290a 0a20  ("timestamp").. 
+0001a170: 2020 2061 7379 6e63 2064 6566 205f 6173     async def _as
+0001a180: 796e 635f 6765 745f 7472 6164 655f 6869  ync_get_trade_hi
+0001a190: 7374 6f72 795f 6964 280a 2020 2020 2020  story_id(.      
+0001a1a0: 2020 7365 6c66 2c20 7061 6972 3a20 7374    self, pair: st
+0001a1b0: 722c 2075 6e74 696c 3a20 696e 742c 2073  r, until: int, s
+0001a1c0: 696e 6365 3a20 4f70 7469 6f6e 616c 5b69  ince: Optional[i
+0001a1d0: 6e74 5d20 3d20 4e6f 6e65 2c20 6672 6f6d  nt] = None, from
+0001a1e0: 5f69 643a 204f 7074 696f 6e61 6c5b 7374  _id: Optional[st
+0001a1f0: 725d 203d 204e 6f6e 650a 2020 2020 2920  r] = None.    ) 
+0001a200: 2d3e 2054 7570 6c65 5b73 7472 2c20 4c69  -> Tuple[str, Li
+0001a210: 7374 5b4c 6973 745d 5d3a 0a20 2020 2020  st[List]]:.     
+0001a220: 2020 2022 2222 0a20 2020 2020 2020 2041     """.        A
+0001a230: 7379 6e63 6872 6f6e 6f75 736c 7920 6765  synchronously ge
+0001a240: 7473 2074 7261 6465 2068 6973 746f 7279  ts trade history
+0001a250: 2075 7369 6e67 2066 6574 6368 5f74 7261   using fetch_tra
+0001a260: 6465 730a 2020 2020 2020 2020 7573 6520  des.        use 
+0001a270: 7468 6973 2077 6865 6e20 6578 6368 616e  this when exchan
+0001a280: 6765 2075 7365 7320 6964 2d62 6173 6564  ge uses id-based
+0001a290: 2069 7465 7261 7469 6f6e 2028 6368 6563   iteration (chec
+0001a2a0: 6b20 6073 656c 662e 5f74 7261 6465 735f  k `self._trades_
+0001a2b0: 7061 6769 6e61 7469 6f6e 6029 0a20 2020  pagination`).   
+0001a2c0: 2020 2020 203a 7061 7261 6d20 7061 6972       :param pair
+0001a2d0: 3a20 5061 6972 2074 6f20 6665 7463 6820  : Pair to fetch 
+0001a2e0: 7472 6164 6520 6461 7461 2066 6f72 0a20  trade data for. 
+0001a2f0: 2020 2020 2020 203a 7061 7261 6d20 7369         :param si
+0001a300: 6e63 653a 2053 696e 6365 2061 7320 696e  nce: Since as in
+0001a310: 7465 6765 7220 7469 6d65 7374 616d 7020  teger timestamp 
+0001a320: 696e 206d 696c 6c69 7365 636f 6e64 730a  in milliseconds.
+0001a330: 2020 2020 2020 2020 3a70 6172 616d 2075          :param u
+0001a340: 6e74 696c 3a20 556e 7469 6c20 6173 2069  ntil: Until as i
+0001a350: 6e74 6567 6572 2074 696d 6573 7461 6d70  nteger timestamp
+0001a360: 2069 6e20 6d69 6c6c 6973 6563 6f6e 6473   in milliseconds
+0001a370: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0001a380: 6672 6f6d 5f69 643a 2044 6f77 6e6c 6f61  from_id: Downloa
+0001a390: 6420 6461 7461 2073 7461 7274 696e 6720  d data starting 
+0001a3a0: 7769 7468 2049 4420 2869 6620 6964 2069  with ID (if id i
+0001a3b0: 7320 6b6e 6f77 6e29 2e20 4967 6e6f 7265  s known). Ignore
+0001a3c0: 7320 2273 696e 6365 2220 6966 2073 6574  s "since" if set
+0001a3d0: 2e0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0001a3e0: 7320 7475 706c 653a 2028 7061 6972 2c20  s tuple: (pair, 
+0001a3f0: 7472 6164 6573 2d6c 6973 7429 0a20 2020  trades-list).   
+0001a400: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
+0001a410: 2020 7472 6164 6573 3a20 4c69 7374 5b4c    trades: List[L
+0001a420: 6973 745d 203d 205b 5d0a 2020 2020 2020  ist] = [].      
+0001a430: 2020 2320 4445 4641 554c 545f 5452 4144    # DEFAULT_TRAD
+0001a440: 4553 5f43 4f4c 554d 4e53 3a20 3020 2d3e  ES_COLUMNS: 0 ->
+0001a450: 2074 696d 6573 7461 6d70 0a20 2020 2020   timestamp.     
+0001a460: 2020 2023 2044 4546 4155 4c54 5f54 5241     # DEFAULT_TRA
+0001a470: 4445 535f 434f 4c55 4d4e 533a 2031 202d  DES_COLUMNS: 1 -
+0001a480: 3e20 6964 0a20 2020 2020 2020 2068 6173  > id.        has
+0001a490: 5f6f 7665 726c 6170 203d 2073 656c 662e  _overlap = self.
+0001a4a0: 5f66 745f 6861 732e 6765 7428 2274 7261  _ft_has.get("tra
+0001a4b0: 6465 735f 7061 6769 6e61 7469 6f6e 5f6f  des_pagination_o
+0001a4c0: 7665 726c 6170 222c 2054 7275 6529 0a20  verlap", True). 
+0001a4d0: 2020 2020 2020 2023 2053 6b69 7020 6c61         # Skip la
+0001a4e0: 7374 2074 7261 6465 2062 7920 6465 6661  st trade by defa
+0001a4f0: 756c 7420 7369 6e63 6520 6974 7320 7468  ult since its th
+0001a500: 6520 6b65 7920 666f 7220 7468 6520 6e65  e key for the ne
+0001a510: 7874 2063 616c 6c0a 2020 2020 2020 2020  xt call.        
+0001a520: 7820 3d20 736c 6963 6528 4e6f 6e65 2c20  x = slice(None, 
+0001a530: 2d31 2920 6966 2068 6173 5f6f 7665 726c  -1) if has_overl
+0001a540: 6170 2065 6c73 6520 736c 6963 6528 4e6f  ap else slice(No
+0001a550: 6e65 290a 0a20 2020 2020 2020 2069 6620  ne)..        if 
+0001a560: 6e6f 7420 6672 6f6d 5f69 6420 6f72 206e  not from_id or n
+0001a570: 6f74 2073 656c 662e 5f76 616c 6964 5f74  ot self._valid_t
+0001a580: 7261 6465 5f70 6167 696e 6174 696f 6e5f  rade_pagination_
+0001a590: 6964 2870 6169 722c 2066 726f 6d5f 6964  id(pair, from_id
+0001a5a0: 293a 0a20 2020 2020 2020 2020 2020 2023  ):.            #
+0001a5b0: 2046 6574 6368 2066 6972 7374 2065 6c65   Fetch first ele
+0001a5c0: 6d65 6e74 7320 7573 696e 6720 7469 6d65  ments using time
+0001a5d0: 6261 7365 6420 6d65 7468 6f64 2074 6f20  based method to 
+0001a5e0: 6765 7420 616e 2049 4420 746f 2070 6167  get an ID to pag
+0001a5f0: 696e 6174 6520 6f6e 0a20 2020 2020 2020  inate on.       
+0001a600: 2020 2020 2023 2044 6570 656e 6469 6e67       # Depending
+0001a610: 206f 6e20 7468 6520 4578 6368 616e 6765   on the Exchange
+0001a620: 2c20 7468 6973 2063 616e 2069 6e74 726f  , this can intro
+0001a630: 6475 6365 2061 2064 7269 6674 2061 7420  duce a drift at 
+0001a640: 7468 6520 7374 6172 7420 6f66 2074 6865  the start of the
+0001a650: 2069 6e74 6572 7661 6c0a 2020 2020 2020   interval.      
+0001a660: 2020 2020 2020 2320 6f66 2075 7020 746f        # of up to
+0001a670: 2061 6e20 686f 7572 2e0a 2020 2020 2020   an hour..      
+0001a680: 2020 2020 2020 2320 652e 672e 2042 696e        # e.g. Bin
+0001a690: 616e 6365 2072 6574 7572 6e73 2074 6865  ance returns the
+0001a6a0: 2022 6c61 7374 2031 3030 3022 2063 616e   "last 1000" can
+0001a6b0: 646c 6573 2077 6974 6869 6e20 6120 3168  dles within a 1h
+0001a6c0: 2074 696d 6520 696e 7465 7276 616c 0a20   time interval. 
+0001a6d0: 2020 2020 2020 2020 2020 2023 202d 2073             # - s
+0001a6e0: 6f20 7765 2077 696c 6c20 6d69 7373 2074  o we will miss t
+0001a6f0: 6865 2066 6972 7374 2074 7261 6465 732e  he first trades.
+0001a700: 0a20 2020 2020 2020 2020 2020 2074 2c20  .            t, 
+0001a710: 6672 6f6d 5f69 6420 3d20 6177 6169 7420  from_id = await 
+0001a720: 7365 6c66 2e5f 6173 796e 635f 6665 7463  self._async_fetc
+0001a730: 685f 7472 6164 6573 2870 6169 722c 2073  h_trades(pair, s
+0001a740: 696e 6365 3d73 696e 6365 290a 2020 2020  ince=since).    
+0001a750: 2020 2020 2020 2020 7472 6164 6573 2e65          trades.e
+0001a760: 7874 656e 6428 745b 785d 290a 2020 2020  xtend(t[x]).    
+0001a770: 2020 2020 7768 696c 6520 5472 7565 3a0a      while True:.
+0001a780: 2020 2020 2020 2020 2020 2020 7472 793a              try:
+0001a790: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001a7a0: 2074 2c20 6672 6f6d 5f69 645f 6e65 7874   t, from_id_next
+0001a7b0: 203d 2061 7761 6974 2073 656c 662e 5f61   = await self._a
+0001a7c0: 7379 6e63 5f66 6574 6368 5f74 7261 6465  sync_fetch_trade
+0001a7d0: 7328 0a20 2020 2020 2020 2020 2020 2020  s(.             
+0001a7e0: 2020 2020 2020 2070 6169 722c 2070 6172         pair, par
+0001a7f0: 616d 733d 7b73 656c 662e 5f74 7261 6465  ams={self._trade
+0001a800: 735f 7061 6769 6e61 7469 6f6e 5f61 7267  s_pagination_arg
+0001a810: 3a20 6672 6f6d 5f69 647d 0a20 2020 2020  : from_id}.     
+0001a820: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+0001a830: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0001a840: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+0001a850: 2020 2020 2020 2074 7261 6465 732e 6578         trades.ex
+0001a860: 7465 6e64 2874 5b78 5d29 0a20 2020 2020  tend(t[x]).     
+0001a870: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0001a880: 6620 6672 6f6d 5f69 6420 3d3d 2066 726f  f from_id == fro
+0001a890: 6d5f 6964 5f6e 6578 7420 6f72 2074 5b2d  m_id_next or t[-
+0001a8a0: 315d 5b30 5d20 3e20 756e 7469 6c3a 0a20  1][0] > until:. 
+0001a8b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a8c0: 2020 2020 2020 206c 6f67 6765 722e 6465         logger.de
+0001a8d0: 6275 6728 0a20 2020 2020 2020 2020 2020  bug(.           
+0001a8e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a8f0: 2066 2253 746f 7070 696e 6720 6265 6361   f"Stopping beca
+0001a900: 7573 6520 6672 6f6d 5f69 6420 6469 6420  use from_id did 
+0001a910: 6e6f 7420 6368 616e 6765 2e20 220a 2020  not change. ".  
+0001a920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a930: 2020 2020 2020 2020 2020 6622 5265 6163            f"Reac
+0001a940: 6865 6420 7b74 5b2d 315d 5b30 5d7d 203e  hed {t[-1][0]} >
+0001a950: 207b 756e 7469 6c7d 220a 2020 2020 2020   {until}".      
+0001a960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a970: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+0001a980: 2020 2020 2020 2020 2020 2020 2320 5265              # Re
+0001a990: 6163 6865 6420 7468 6520 656e 6420 6f66  ached the end of
+0001a9a0: 2074 6865 2064 6566 696e 6564 2d64 6f77   the defined-dow
+0001a9b0: 6e6c 6f61 6420 7065 7269 6f64 202d 2061  nload period - a
+0001a9c0: 6464 206c 6173 7420 7472 6164 6520 6173  dd last trade as
+0001a9d0: 2077 656c 6c2e 0a20 2020 2020 2020 2020   well..         
+0001a9e0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0001a9f0: 6620 6861 735f 6f76 6572 6c61 703a 0a20  f has_overlap:. 
+0001aa00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001aa10: 2020 2020 2020 2020 2020 2074 7261 6465             trade
+0001aa20: 732e 6578 7465 6e64 2874 5b2d 313a 5d29  s.extend(t[-1:])
+0001aa30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001aa40: 2020 2020 2020 2020 2062 7265 616b 0a0a           break..
+0001aa50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001aa60: 2020 2020 6672 6f6d 5f69 6420 3d20 6672      from_id = fr
+0001aa70: 6f6d 5f69 645f 6e65 7874 0a20 2020 2020  om_id_next.     
+0001aa80: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+0001aa90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001aaa0: 2020 2020 206c 6f67 6765 722e 6465 6275       logger.debu
+0001aab0: 6728 2253 746f 7070 696e 6720 6173 206e  g("Stopping as n
+0001aac0: 6f20 6d6f 7265 2074 7261 6465 7320 7765  o more trades we
+0001aad0: 7265 2072 6574 7572 6e65 642e 2229 0a20  re returned."). 
+0001aae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001aaf0: 2020 2062 7265 616b 0a20 2020 2020 2020     break.       
+0001ab00: 2020 2020 2065 7863 6570 7420 6173 796e       except asyn
+0001ab10: 6369 6f2e 4361 6e63 656c 6c65 6445 7272  cio.CancelledErr
+0001ab20: 6f72 3a0a 2020 2020 2020 2020 2020 2020  or:.            
+0001ab30: 2020 2020 6c6f 6767 6572 2e64 6562 7567      logger.debug
+0001ab40: 2822 4173 796e 6320 6f70 6572 6174 696f  ("Async operatio
+0001ab50: 6e20 496e 7465 7272 7570 7465 642c 2062  n Interrupted, b
+0001ab60: 7265 616b 696e 6720 7472 6164 6573 2044  reaking trades D
+0001ab70: 4c20 6c6f 6f70 2e22 290a 2020 2020 2020  L loop.").      
+0001ab80: 2020 2020 2020 2020 2020 6272 6561 6b0a            break.
+0001ab90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001aba0: 2870 6169 722c 2074 7261 6465 7329 0a0a  (pair, trades)..
+0001abb0: 2020 2020 6173 796e 6320 6465 6620 5f61      async def _a
+0001abc0: 7379 6e63 5f67 6574 5f74 7261 6465 5f68  sync_get_trade_h
+0001abd0: 6973 746f 7279 5f74 696d 6528 0a20 2020  istory_time(.   
+0001abe0: 2020 2020 2073 656c 662c 2070 6169 723a       self, pair:
+0001abf0: 2073 7472 2c20 756e 7469 6c3a 2069 6e74   str, until: int
+0001ac00: 2c20 7369 6e63 653a 204f 7074 696f 6e61  , since: Optiona
+0001ac10: 6c5b 696e 745d 203d 204e 6f6e 650a 2020  l[int] = None.  
+0001ac20: 2020 2920 2d3e 2054 7570 6c65 5b73 7472    ) -> Tuple[str
+0001ac30: 2c20 4c69 7374 5b4c 6973 745d 5d3a 0a20  , List[List]]:. 
+0001ac40: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+0001ac50: 2020 2041 7379 6e63 6872 6f6e 6f75 736c     Asynchronousl
+0001ac60: 7920 6765 7473 2074 7261 6465 2068 6973  y gets trade his
+0001ac70: 746f 7279 2075 7369 6e67 2066 6574 6368  tory using fetch
+0001ac80: 5f74 7261 6465 732c 0a20 2020 2020 2020  _trades,.       
+0001ac90: 2077 6865 6e20 7468 6520 6578 6368 616e   when the exchan
+0001aca0: 6765 2075 7365 7320 7469 6d65 2d62 6173  ge uses time-bas
+0001acb0: 6564 2069 7465 7261 7469 6f6e 2028 6368  ed iteration (ch
+0001acc0: 6563 6b20 6073 656c 662e 5f74 7261 6465  eck `self._trade
+0001acd0: 735f 7061 6769 6e61 7469 6f6e 6029 0a20  s_pagination`). 
+0001ace0: 2020 2020 2020 203a 7061 7261 6d20 7061         :param pa
+0001acf0: 6972 3a20 5061 6972 2074 6f20 6665 7463  ir: Pair to fetc
+0001ad00: 6820 7472 6164 6520 6461 7461 2066 6f72  h trade data for
+0001ad10: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0001ad20: 7369 6e63 653a 2053 696e 6365 2061 7320  since: Since as 
+0001ad30: 696e 7465 6765 7220 7469 6d65 7374 616d  integer timestam
+0001ad40: 7020 696e 206d 696c 6c69 7365 636f 6e64  p in millisecond
+0001ad50: 730a 2020 2020 2020 2020 3a70 6172 616d  s.        :param
+0001ad60: 2075 6e74 696c 3a20 556e 7469 6c20 6173   until: Until as
+0001ad70: 2069 6e74 6567 6572 2074 696d 6573 7461   integer timesta
+0001ad80: 6d70 2069 6e20 6d69 6c6c 6973 6563 6f6e  mp in millisecon
+0001ad90: 6473 0a20 2020 2020 2020 2072 6574 7572  ds.        retur
+0001ada0: 6e73 2074 7570 6c65 3a20 2870 6169 722c  ns tuple: (pair,
+0001adb0: 2074 7261 6465 732d 6c69 7374 290a 2020   trades-list).  
+0001adc0: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
+0001add0: 2020 2074 7261 6465 733a 204c 6973 745b     trades: List[
+0001ade0: 4c69 7374 5d20 3d20 5b5d 0a20 2020 2020  List] = [].     
+0001adf0: 2020 2023 2044 4546 4155 4c54 5f54 5241     # DEFAULT_TRA
+0001ae00: 4445 535f 434f 4c55 4d4e 533a 2030 202d  DES_COLUMNS: 0 -
+0001ae10: 3e20 7469 6d65 7374 616d 700a 2020 2020  > timestamp.    
+0001ae20: 2020 2020 2320 4445 4641 554c 545f 5452      # DEFAULT_TR
+0001ae30: 4144 4553 5f43 4f4c 554d 4e53 3a20 3120  ADES_COLUMNS: 1 
+0001ae40: 2d3e 2069 640a 2020 2020 2020 2020 7768  -> id.        wh
+0001ae50: 696c 6520 5472 7565 3a0a 2020 2020 2020  ile True:.      
+0001ae60: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+0001ae70: 2020 2020 2020 2020 2020 2074 2c20 7369             t, si
+0001ae80: 6e63 655f 6e65 7874 203d 2061 7761 6974  nce_next = await
+0001ae90: 2073 656c 662e 5f61 7379 6e63 5f66 6574   self._async_fet
+0001aea0: 6368 5f74 7261 6465 7328 7061 6972 2c20  ch_trades(pair, 
+0001aeb0: 7369 6e63 653d 7369 6e63 6529 0a20 2020  since=since).   
+0001aec0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0001aed0: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+0001aee0: 2020 2020 2020 2023 204e 6f20 6d6f 7265         # No more
+0001aef0: 2074 7261 6465 7320 746f 2064 6f77 6e6c   trades to downl
+0001af00: 6f61 6420 6176 6169 6c61 626c 6520 6174  oad available at
+0001af10: 2074 6865 2065 7863 6861 6e67 652c 0a20   the exchange,. 
+0001af20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001af30: 2020 2023 2053 6f20 7765 2072 6570 6561     # So we repea
+0001af40: 7465 646c 7920 6765 7420 7468 6520 7361  tedly get the sa
+0001af50: 6d65 2074 7261 6465 206f 7665 7220 616e  me trade over an
+0001af60: 6420 6f76 6572 2061 6761 696e 2e0a 2020  d over again..  
+0001af70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001af80: 2020 6966 2073 696e 6365 203d 3d20 7369    if since == si
+0001af90: 6e63 655f 6e65 7874 2061 6e64 206c 656e  nce_next and len
+0001afa0: 2874 2920 3d3d 2031 3a0a 2020 2020 2020  (t) == 1:.      
+0001afb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001afc0: 2020 6c6f 6767 6572 2e64 6562 7567 2822    logger.debug("
+0001afd0: 5374 6f70 7069 6e67 2062 6563 6175 7365  Stopping because
+0001afe0: 206e 6f20 6d6f 7265 2074 7261 6465 7320   no more trades 
+0001aff0: 6172 6520 6176 6169 6c61 626c 652e 2229  are available.")
+0001b000: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001b010: 2020 2020 2020 2020 2062 7265 616b 0a20           break. 
+0001b020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b030: 2020 2073 696e 6365 203d 2073 696e 6365     since = since
+0001b040: 5f6e 6578 740a 2020 2020 2020 2020 2020  _next.          
+0001b050: 2020 2020 2020 2020 2020 7472 6164 6573            trades
+0001b060: 2e65 7874 656e 6428 7429 0a20 2020 2020  .extend(t).     
+0001b070: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0001b080: 2052 6561 6368 6564 2074 6865 2065 6e64   Reached the end
+0001b090: 206f 6620 7468 6520 6465 6669 6e65 642d   of the defined-
+0001b0a0: 646f 776e 6c6f 6164 2070 6572 696f 640a  download period.
+0001b0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b0c0: 2020 2020 6966 2075 6e74 696c 2061 6e64      if until and
+0001b0d0: 2073 696e 6365 5f6e 6578 7420 3e20 756e   since_next > un
+0001b0e0: 7469 6c3a 0a20 2020 2020 2020 2020 2020  til:.           
+0001b0f0: 2020 2020 2020 2020 2020 2020 206c 6f67               log
+0001b100: 6765 722e 6465 6275 6728 6622 5374 6f70  ger.debug(f"Stop
+0001b110: 7069 6e67 2062 6563 6175 7365 2075 6e74  ping because unt
+0001b120: 696c 2077 6173 2072 6561 6368 6564 2e20  il was reached. 
+0001b130: 7b73 696e 6365 5f6e 6578 747d 203e 207b  {since_next} > {
+0001b140: 756e 7469 6c7d 2229 0a20 2020 2020 2020  until}").       
+0001b150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b160: 2062 7265 616b 0a20 2020 2020 2020 2020   break.         
+0001b170: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0001b180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b190: 206c 6f67 6765 722e 6465 6275 6728 2253   logger.debug("S
+0001b1a0: 746f 7070 696e 6720 6173 206e 6f20 6d6f  topping as no mo
+0001b1b0: 7265 2074 7261 6465 7320 7765 7265 2072  re trades were r
+0001b1c0: 6574 7572 6e65 642e 2229 0a20 2020 2020  eturned.").     
+0001b1d0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+0001b1e0: 7265 616b 0a20 2020 2020 2020 2020 2020  reak.           
+0001b1f0: 2065 7863 6570 7420 6173 796e 6369 6f2e   except asyncio.
+0001b200: 4361 6e63 656c 6c65 6445 7272 6f72 3a0a  CancelledError:.
+0001b210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b220: 6c6f 6767 6572 2e64 6562 7567 2822 4173  logger.debug("As
+0001b230: 796e 6320 6f70 6572 6174 696f 6e20 496e  ync operation In
+0001b240: 7465 7272 7570 7465 642c 2062 7265 616b  terrupted, break
+0001b250: 696e 6720 7472 6164 6573 2044 4c20 6c6f  ing trades DL lo
+0001b260: 6f70 2e22 290a 2020 2020 2020 2020 2020  op.").          
+0001b270: 2020 2020 2020 6272 6561 6b0a 0a20 2020        break..   
+0001b280: 2020 2020 2072 6574 7572 6e20 2870 6169       return (pai
+0001b290: 722c 2074 7261 6465 7329 0a0a 2020 2020  r, trades)..    
+0001b2a0: 6173 796e 6320 6465 6620 5f61 7379 6e63  async def _async
+0001b2b0: 5f67 6574 5f74 7261 6465 5f68 6973 746f  _get_trade_histo
+0001b2c0: 7279 280a 2020 2020 2020 2020 7365 6c66  ry(.        self
+0001b2d0: 2c0a 2020 2020 2020 2020 7061 6972 3a20  ,.        pair: 
+0001b2e0: 7374 722c 0a20 2020 2020 2020 2073 696e  str,.        sin
+0001b2f0: 6365 3a20 4f70 7469 6f6e 616c 5b69 6e74  ce: Optional[int
+0001b300: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+0001b310: 2020 756e 7469 6c3a 204f 7074 696f 6e61    until: Optiona
+0001b320: 6c5b 696e 745d 203d 204e 6f6e 652c 0a20  l[int] = None,. 
+0001b330: 2020 2020 2020 2066 726f 6d5f 6964 3a20         from_id: 
+0001b340: 4f70 7469 6f6e 616c 5b73 7472 5d20 3d20  Optional[str] = 
+0001b350: 4e6f 6e65 2c0a 2020 2020 2920 2d3e 2054  None,.    ) -> T
+0001b360: 7570 6c65 5b73 7472 2c20 4c69 7374 5b4c  uple[str, List[L
+0001b370: 6973 745d 5d3a 0a20 2020 2020 2020 2022  ist]]:.        "
+0001b380: 2222 0a20 2020 2020 2020 2041 7379 6e63  "".        Async
+0001b390: 2077 7261 7070 6572 2068 616e 646c 696e   wrapper handlin
+0001b3a0: 6720 646f 776e 6c6f 6164 696e 6720 7472  g downloading tr
+0001b3b0: 6164 6573 2075 7369 6e67 2065 6974 6865  ades using eithe
+0001b3c0: 7220 7469 6d65 206f 7220 6964 2062 6173  r time or id bas
+0001b3d0: 6564 206d 6574 686f 6473 2e0a 2020 2020  ed methods..    
+0001b3e0: 2020 2020 2222 220a 0a20 2020 2020 2020      """..       
+0001b3f0: 206c 6f67 6765 722e 6465 6275 6728 0a20   logger.debug(. 
+0001b400: 2020 2020 2020 2020 2020 2066 225f 6173             f"_as
+0001b410: 796e 635f 6765 745f 7472 6164 655f 6869  ync_get_trade_hi
+0001b420: 7374 6f72 7928 292c 2070 6169 723a 207b  story(), pair: {
+0001b430: 7061 6972 7d2c 2022 0a20 2020 2020 2020  pair}, ".       
+0001b440: 2020 2020 2066 2273 696e 6365 3a20 7b73       f"since: {s
+0001b450: 696e 6365 7d2c 2075 6e74 696c 3a20 7b75  ince}, until: {u
+0001b460: 6e74 696c 7d2c 2066 726f 6d5f 6964 3a20  ntil}, from_id: 
+0001b470: 7b66 726f 6d5f 6964 7d22 0a20 2020 2020  {from_id}".     
+0001b480: 2020 2029 0a0a 2020 2020 2020 2020 6966     )..        if
+0001b490: 2075 6e74 696c 2069 7320 4e6f 6e65 3a0a   until is None:.
+0001b4a0: 2020 2020 2020 2020 2020 2020 756e 7469              unti
+0001b4b0: 6c20 3d20 6363 7874 2e45 7863 6861 6e67  l = ccxt.Exchang
+0001b4c0: 652e 6d69 6c6c 6973 6563 6f6e 6473 2829  e.milliseconds()
+0001b4d0: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
+0001b4e0: 6765 722e 6465 6275 6728 6622 4578 6368  ger.debug(f"Exch
+0001b4f0: 616e 6765 206d 696c 6c69 7365 636f 6e64  ange millisecond
+0001b500: 733a 207b 756e 7469 6c7d 2229 0a0a 2020  s: {until}")..  
+0001b510: 2020 2020 2020 6966 2073 656c 662e 5f74        if self._t
+0001b520: 7261 6465 735f 7061 6769 6e61 7469 6f6e  rades_pagination
+0001b530: 203d 3d20 2274 696d 6522 3a0a 2020 2020   == "time":.    
+0001b540: 2020 2020 2020 2020 7265 7475 726e 2061          return a
+0001b550: 7761 6974 2073 656c 662e 5f61 7379 6e63  wait self._async
+0001b560: 5f67 6574 5f74 7261 6465 5f68 6973 746f  _get_trade_histo
+0001b570: 7279 5f74 696d 6528 7061 6972 3d70 6169  ry_time(pair=pai
+0001b580: 722c 2073 696e 6365 3d73 696e 6365 2c20  r, since=since, 
+0001b590: 756e 7469 6c3d 756e 7469 6c29 0a20 2020  until=until).   
+0001b5a0: 2020 2020 2065 6c69 6620 7365 6c66 2e5f       elif self._
+0001b5b0: 7472 6164 6573 5f70 6167 696e 6174 696f  trades_paginatio
+0001b5c0: 6e20 3d3d 2022 6964 223a 0a20 2020 2020  n == "id":.     
+0001b5d0: 2020 2020 2020 2072 6574 7572 6e20 6177         return aw
+0001b5e0: 6169 7420 7365 6c66 2e5f 6173 796e 635f  ait self._async_
+0001b5f0: 6765 745f 7472 6164 655f 6869 7374 6f72  get_trade_histor
+0001b600: 795f 6964 280a 2020 2020 2020 2020 2020  y_id(.          
+0001b610: 2020 2020 2020 7061 6972 3d70 6169 722c        pair=pair,
+0001b620: 2073 696e 6365 3d73 696e 6365 2c20 756e   since=since, un
+0001b630: 7469 6c3d 756e 7469 6c2c 2066 726f 6d5f  til=until, from_
+0001b640: 6964 3d66 726f 6d5f 6964 0a20 2020 2020  id=from_id.     
+0001b650: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0001b660: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0001b670: 2020 2072 6169 7365 204f 7065 7261 7469     raise Operati
+0001b680: 6f6e 616c 4578 6365 7074 696f 6e28 0a20  onalException(. 
+0001b690: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0001b6a0: 2245 7863 6861 6e67 6520 7b73 656c 662e  "Exchange {self.
+0001b6b0: 6e61 6d65 7d20 646f 6573 2075 7365 206e  name} does use n
+0001b6c0: 6569 7468 6572 2074 696d 652c 206e 6f72  either time, nor
+0001b6d0: 2069 6420 6261 7365 6420 7061 6769 6e61   id based pagina
+0001b6e0: 7469 6f6e 220a 2020 2020 2020 2020 2020  tion".          
+0001b6f0: 2020 290a 0a20 2020 2064 6566 2067 6574    )..    def get
+0001b700: 5f68 6973 746f 7269 635f 7472 6164 6573  _historic_trades
+0001b710: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
+0001b720: 2020 2020 2020 2020 7061 6972 3a20 7374          pair: st
+0001b730: 722c 0a20 2020 2020 2020 2073 696e 6365  r,.        since
+0001b740: 3a20 4f70 7469 6f6e 616c 5b69 6e74 5d20  : Optional[int] 
+0001b750: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+0001b760: 756e 7469 6c3a 204f 7074 696f 6e61 6c5b  until: Optional[
+0001b770: 696e 745d 203d 204e 6f6e 652c 0a20 2020  int] = None,.   
+0001b780: 2020 2020 2066 726f 6d5f 6964 3a20 4f70       from_id: Op
+0001b790: 7469 6f6e 616c 5b73 7472 5d20 3d20 4e6f  tional[str] = No
+0001b7a0: 6e65 2c0a 2020 2020 2920 2d3e 2054 7570  ne,.    ) -> Tup
+0001b7b0: 6c65 5b73 7472 2c20 4c69 7374 5d3a 0a20  le[str, List]:. 
+0001b7c0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+0001b7d0: 2020 2047 6574 2074 7261 6465 2068 6973     Get trade his
+0001b7e0: 746f 7279 2064 6174 6120 7573 696e 6720  tory data using 
+0001b7f0: 6173 796e 6369 6f2e 0a20 2020 2020 2020  asyncio..       
+0001b800: 2048 616e 646c 6573 2061 6c6c 2061 7379   Handles all asy
+0001b810: 6e63 2077 6f72 6b20 616e 6420 7265 7475  nc work and retu
+0001b820: 726e 7320 7468 6520 6c69 7374 206f 6620  rns the list of 
+0001b830: 6361 6e64 6c65 732e 0a20 2020 2020 2020  candles..       
+0001b840: 2041 7379 6e63 206f 7665 7220 6f6e 6520   Async over one 
+0001b850: 7061 6972 2c20 6173 7375 6d69 6e67 2077  pair, assuming w
+0001b860: 6520 6765 7420 6073 656c 662e 6f68 6c63  e get `self.ohlc
+0001b870: 765f 6361 6e64 6c65 5f6c 696d 6974 2829  v_candle_limit()
+0001b880: 6020 6361 6e64 6c65 7320 7065 7220 6361  ` candles per ca
+0001b890: 6c6c 2e0a 2020 2020 2020 2020 3a70 6172  ll..        :par
+0001b8a0: 616d 2070 6169 723a 2050 6169 7220 746f  am pair: Pair to
+0001b8b0: 2064 6f77 6e6c 6f61 640a 2020 2020 2020   download.      
+0001b8c0: 2020 3a70 6172 616d 2073 696e 6365 3a20    :param since: 
+0001b8d0: 5469 6d65 7374 616d 7020 696e 206d 696c  Timestamp in mil
+0001b8e0: 6c69 7365 636f 6e64 7320 746f 2067 6574  liseconds to get
+0001b8f0: 2068 6973 746f 7279 2066 726f 6d0a 2020   history from.  
+0001b900: 2020 2020 2020 3a70 6172 616d 2075 6e74        :param unt
+0001b910: 696c 3a20 5469 6d65 7374 616d 7020 696e  il: Timestamp in
+0001b920: 206d 696c 6c69 7365 636f 6e64 732e 2044   milliseconds. D
+0001b930: 6566 6175 6c74 7320 746f 2063 7572 7265  efaults to curre
+0001b940: 6e74 2074 696d 6573 7461 6d70 2069 6620  nt timestamp if 
+0001b950: 6e6f 7420 6465 6669 6e65 642e 0a20 2020  not defined..   
+0001b960: 2020 2020 203a 7061 7261 6d20 6672 6f6d       :param from
+0001b970: 5f69 643a 2044 6f77 6e6c 6f61 6420 6461  _id: Download da
+0001b980: 7461 2073 7461 7274 696e 6720 7769 7468  ta starting with
+0001b990: 2049 4420 2869 6620 6964 2069 7320 6b6e   ID (if id is kn
+0001b9a0: 6f77 6e29 0a20 2020 2020 2020 203a 7265  own).        :re
+0001b9b0: 7475 726e 7320 4c69 7374 206f 6620 7472  turns List of tr
+0001b9c0: 6164 6520 6461 7461 0a20 2020 2020 2020  ade data.       
+0001b9d0: 2022 2222 0a20 2020 2020 2020 2069 6620   """.        if 
+0001b9e0: 6e6f 7420 7365 6c66 2e65 7863 6861 6e67  not self.exchang
+0001b9f0: 655f 6861 7328 2266 6574 6368 5472 6164  e_has("fetchTrad
+0001ba00: 6573 2229 3a0a 2020 2020 2020 2020 2020  es"):.          
+0001ba10: 2020 7261 6973 6520 4f70 6572 6174 696f    raise Operatio
+0001ba20: 6e61 6c45 7863 6570 7469 6f6e 2822 5468  nalException("Th
+0001ba30: 6973 2065 7863 6861 6e67 6520 646f 6573  is exchange does
+0001ba40: 206e 6f74 2073 7570 706f 7274 2064 6f77   not support dow
+0001ba50: 6e6c 6f61 6469 6e67 2054 7261 6465 732e  nloading Trades.
+0001ba60: 2229 0a0a 2020 2020 2020 2020 7769 7468  ")..        with
+0001ba70: 2073 656c 662e 5f6c 6f6f 705f 6c6f 636b   self._loop_lock
+0001ba80: 3a0a 2020 2020 2020 2020 2020 2020 7461  :.            ta
+0001ba90: 736b 203d 2061 7379 6e63 696f 2e65 6e73  sk = asyncio.ens
+0001baa0: 7572 655f 6675 7475 7265 280a 2020 2020  ure_future(.    
+0001bab0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0001bac0: 2e5f 6173 796e 635f 6765 745f 7472 6164  ._async_get_trad
+0001bad0: 655f 6869 7374 6f72 7928 7061 6972 3d70  e_history(pair=p
+0001bae0: 6169 722c 2073 696e 6365 3d73 696e 6365  air, since=since
+0001baf0: 2c20 756e 7469 6c3d 756e 7469 6c2c 2066  , until=until, f
+0001bb00: 726f 6d5f 6964 3d66 726f 6d5f 6964 290a  rom_id=from_id).
+0001bb10: 2020 2020 2020 2020 2020 2020 290a 0a20              ).. 
+0001bb20: 2020 2020 2020 2020 2020 2066 6f72 2073             for s
+0001bb30: 6967 2069 6e20 5b73 6967 6e61 6c2e 5349  ig in [signal.SI
+0001bb40: 4749 4e54 2c20 7369 676e 616c 2e53 4947  GINT, signal.SIG
+0001bb50: 5445 524d 5d3a 0a20 2020 2020 2020 2020  TERM]:.         
+0001bb60: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+0001bb70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001bb80: 7365 6c66 2e6c 6f6f 702e 6164 645f 7369  self.loop.add_si
+0001bb90: 676e 616c 5f68 616e 646c 6572 2873 6967  gnal_handler(sig
+0001bba0: 2c20 7461 736b 2e63 616e 6365 6c29 0a20  , task.cancel). 
+0001bbb0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0001bbc0: 7863 6570 7420 4e6f 7449 6d70 6c65 6d65  xcept NotImpleme
+0001bbd0: 6e74 6564 4572 726f 723a 0a20 2020 2020  ntedError:.     
+0001bbe0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0001bbf0: 204e 6f74 2061 6c6c 2070 6c61 7466 6f72   Not all platfor
+0001bc00: 6d73 2069 6d70 6c65 6d65 6e74 2073 6967  ms implement sig
+0001bc10: 6e61 6c73 2028 652e 672e 2077 696e 646f  nals (e.g. windo
+0001bc20: 7773 290a 2020 2020 2020 2020 2020 2020  ws).            
+0001bc30: 2020 2020 2020 2020 7061 7373 0a20 2020          pass.   
+0001bc40: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0001bc50: 7365 6c66 2e6c 6f6f 702e 7275 6e5f 756e  self.loop.run_un
+0001bc60: 7469 6c5f 636f 6d70 6c65 7465 2874 6173  til_complete(tas
+0001bc70: 6b29 0a0a 2020 2020 4072 6574 7269 6572  k)..    @retrier
+0001bc80: 0a20 2020 2064 6566 205f 6765 745f 6675  .    def _get_fu
+0001bc90: 6e64 696e 675f 6665 6573 5f66 726f 6d5f  nding_fees_from_
+0001bca0: 6578 6368 616e 6765 2873 656c 662c 2070  exchange(self, p
+0001bcb0: 6169 723a 2073 7472 2c20 7369 6e63 653a  air: str, since:
+0001bcc0: 2055 6e69 6f6e 5b64 6174 6574 696d 652c   Union[datetime,
+0001bcd0: 2069 6e74 5d29 202d 3e20 666c 6f61 743a   int]) -> float:
+0001bce0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+0001bcf0: 2020 2020 2052 6574 7572 6e73 2074 6865       Returns the
+0001bd00: 2073 756d 206f 6620 616c 6c20 6675 6e64   sum of all fund
+0001bd10: 696e 6720 6665 6573 2074 6861 7420 7765  ing fees that we
+0001bd20: 7265 2065 7863 6861 6e67 6564 2066 6f72  re exchanged for
+0001bd30: 2061 2070 6169 7220 7769 7468 696e 2061   a pair within a
+0001bd40: 2074 696d 6566 7261 6d65 0a20 2020 2020   timeframe.     
+0001bd50: 2020 2044 7279 2d72 756e 2068 616e 646c     Dry-run handl
+0001bd60: 696e 6720 6861 7070 656e 7320 6173 2070  ing happens as p
+0001bd70: 6172 7420 6f66 205f 6361 6c63 756c 6174  art of _calculat
+0001bd80: 655f 6675 6e64 696e 675f 6665 6573 2e0a  e_funding_fees..
+0001bd90: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
+0001bda0: 6169 723a 2028 652e 672e 2041 4441 2f55  air: (e.g. ADA/U
+0001bdb0: 5344 5429 0a20 2020 2020 2020 203a 7061  SDT).        :pa
+0001bdc0: 7261 6d20 7369 6e63 653a 2054 6865 2065  ram since: The e
+0001bdd0: 6172 6c69 6573 7420 7469 6d65 206f 6620  arliest time of 
+0001bde0: 636f 6e73 6964 6572 6174 696f 6e20 666f  consideration fo
+0001bdf0: 7220 6361 6c63 756c 6174 696e 6720 6675  r calculating fu
+0001be00: 6e64 696e 6720 6665 6573 2c0a 2020 2020  nding fees,.    
+0001be10: 2020 2020 2020 2020 696e 2075 6e69 7820          in unix 
+0001be20: 7469 6d65 206f 7220 6173 2061 2064 6174  time or as a dat
+0001be30: 6574 696d 650a 2020 2020 2020 2020 2222  etime.        ""
+0001be40: 220a 2020 2020 2020 2020 6966 206e 6f74  ".        if not
+0001be50: 2073 656c 662e 6578 6368 616e 6765 5f68   self.exchange_h
+0001be60: 6173 2822 6665 7463 6846 756e 6469 6e67  as("fetchFunding
+0001be70: 4869 7374 6f72 7922 293a 0a20 2020 2020  History"):.     
+0001be80: 2020 2020 2020 2072 6169 7365 204f 7065         raise Ope
+0001be90: 7261 7469 6f6e 616c 4578 6365 7074 696f  rationalExceptio
+0001bea0: 6e28 0a20 2020 2020 2020 2020 2020 2020  n(.             
+0001beb0: 2020 2066 2266 6574 6368 5f66 756e 6469     f"fetch_fundi
+0001bec0: 6e67 5f68 6973 746f 7279 2829 2069 7320  ng_history() is 
+0001bed0: 6e6f 7420 6176 6169 6c61 626c 6520 7573  not available us
+0001bee0: 696e 6720 7b73 656c 662e 6e61 6d65 7d22  ing {self.name}"
+0001bef0: 0a20 2020 2020 2020 2020 2020 2029 0a0a  .            )..
+0001bf00: 2020 2020 2020 2020 6966 2074 7970 6528          if type(
+0001bf10: 7369 6e63 6529 2069 7320 6461 7465 7469  since) is dateti
+0001bf20: 6d65 3a0a 2020 2020 2020 2020 2020 2020  me:.            
+0001bf30: 7369 6e63 6520 3d20 6474 5f74 7328 7369  since = dt_ts(si
+0001bf40: 6e63 6529 0a0a 2020 2020 2020 2020 7472  nce)..        tr
+0001bf50: 793a 0a20 2020 2020 2020 2020 2020 2066  y:.            f
+0001bf60: 756e 6469 6e67 5f68 6973 746f 7279 203d  unding_history =
+0001bf70: 2073 656c 662e 5f61 7069 2e66 6574 6368   self._api.fetch
+0001bf80: 5f66 756e 6469 6e67 5f68 6973 746f 7279  _funding_history
+0001bf90: 2873 796d 626f 6c3d 7061 6972 2c20 7369  (symbol=pair, si
+0001bfa0: 6e63 653d 7369 6e63 6529 0a20 2020 2020  nce=since).     
+0001bfb0: 2020 2020 2020 2073 656c 662e 5f6c 6f67         self._log
+0001bfc0: 5f65 7863 6861 6e67 655f 7265 7370 6f6e  _exchange_respon
+0001bfd0: 7365 280a 2020 2020 2020 2020 2020 2020  se(.            
+0001bfe0: 2020 2020 2266 756e 6469 6e67 5f68 6973      "funding_his
+0001bff0: 746f 7279 222c 2066 756e 6469 6e67 5f68  tory", funding_h
+0001c000: 6973 746f 7279 2c20 6164 645f 696e 666f  istory, add_info
+0001c010: 3d66 2270 6169 723a 207b 7061 6972 7d2c  =f"pair: {pair},
+0001c020: 2073 696e 6365 3a20 7b73 696e 6365 7d22   since: {since}"
+0001c030: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
+0001c040: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0001c050: 6e20 7375 6d28 6665 655b 2261 6d6f 756e  n sum(fee["amoun
+0001c060: 7422 5d20 666f 7220 6665 6520 696e 2066  t"] for fee in f
+0001c070: 756e 6469 6e67 5f68 6973 746f 7279 290a  unding_history).
+0001c080: 2020 2020 2020 2020 6578 6365 7074 2063          except c
+0001c090: 6378 742e 4444 6f53 5072 6f74 6563 7469  cxt.DDoSProtecti
+0001c0a0: 6f6e 2061 7320 653a 0a20 2020 2020 2020  on as e:.       
+0001c0b0: 2020 2020 2072 6169 7365 2044 446f 7350       raise DDosP
+0001c0c0: 726f 7465 6374 696f 6e28 6529 2066 726f  rotection(e) fro
+0001c0d0: 6d20 650a 2020 2020 2020 2020 6578 6365  m e.        exce
+0001c0e0: 7074 2028 6363 7874 2e4f 7065 7261 7469  pt (ccxt.Operati
+0001c0f0: 6f6e 4661 696c 6564 2c20 6363 7874 2e45  onFailed, ccxt.E
+0001c100: 7863 6861 6e67 6545 7272 6f72 2920 6173  xchangeError) as
+0001c110: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
+0001c120: 7261 6973 6520 5465 6d70 6f72 6172 7945  raise TemporaryE
+0001c130: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
+0001c140: 2020 2020 2020 6622 436f 756c 6420 6e6f        f"Could no
+0001c150: 7420 6765 7420 6675 6e64 696e 6720 6665  t get funding fe
+0001c160: 6573 2064 7565 2074 6f20 7b65 2e5f 5f63  es due to {e.__c
+0001c170: 6c61 7373 5f5f 2e5f 5f6e 616d 655f 5f7d  lass__.__name__}
+0001c180: 2e20 4d65 7373 6167 653a 207b 657d 220a  . Message: {e}".
+0001c190: 2020 2020 2020 2020 2020 2020 2920 6672              ) fr
+0001c1a0: 6f6d 2065 0a20 2020 2020 2020 2065 7863  om e.        exc
+0001c1b0: 6570 7420 6363 7874 2e42 6173 6545 7272  ept ccxt.BaseErr
+0001c1c0: 6f72 2061 7320 653a 0a20 2020 2020 2020  or as e:.       
+0001c1d0: 2020 2020 2072 6169 7365 204f 7065 7261       raise Opera
+0001c1e0: 7469 6f6e 616c 4578 6365 7074 696f 6e28  tionalException(
+0001c1f0: 6529 2066 726f 6d20 650a 0a20 2020 2040  e) from e..    @
+0001c200: 7265 7472 6965 720a 2020 2020 6465 6620  retrier.    def 
+0001c210: 6765 745f 6c65 7665 7261 6765 5f74 6965  get_leverage_tie
+0001c220: 7273 2873 656c 6629 202d 3e20 4469 6374  rs(self) -> Dict
+0001c230: 5b73 7472 2c20 4c69 7374 5b44 6963 745d  [str, List[Dict]
+0001c240: 5d3a 0a20 2020 2020 2020 2074 7279 3a0a  ]:.        try:.
+0001c250: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0001c260: 726e 2073 656c 662e 5f61 7069 2e66 6574  rn self._api.fet
+0001c270: 6368 5f6c 6576 6572 6167 655f 7469 6572  ch_leverage_tier
+0001c280: 7328 290a 2020 2020 2020 2020 6578 6365  s().        exce
+0001c290: 7074 2063 6378 742e 4444 6f53 5072 6f74  pt ccxt.DDoSProt
+0001c2a0: 6563 7469 6f6e 2061 7320 653a 0a20 2020  ection as e:.   
+0001c2b0: 2020 2020 2020 2020 2072 6169 7365 2044           raise D
+0001c2c0: 446f 7350 726f 7465 6374 696f 6e28 6529  DosProtection(e)
+0001c2d0: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
+0001c2e0: 6578 6365 7074 2028 6363 7874 2e4f 7065  except (ccxt.Ope
+0001c2f0: 7261 7469 6f6e 4661 696c 6564 2c20 6363  rationFailed, cc
+0001c300: 7874 2e45 7863 6861 6e67 6545 7272 6f72  xt.ExchangeError
+0001c310: 2920 6173 2065 3a0a 2020 2020 2020 2020  ) as e:.        
+0001c320: 2020 2020 7261 6973 6520 5465 6d70 6f72      raise Tempor
+0001c330: 6172 7945 7272 6f72 280a 2020 2020 2020  aryError(.      
+0001c340: 2020 2020 2020 2020 2020 6622 436f 756c            f"Coul
+0001c350: 6420 6e6f 7420 6c6f 6164 206c 6576 6572  d not load lever
+0001c360: 6167 6520 7469 6572 7320 6475 6520 746f  age tiers due to
+0001c370: 207b 652e 5f5f 636c 6173 735f 5f2e 5f5f   {e.__class__.__
+0001c380: 6e61 6d65 5f5f 7d2e 204d 6573 7361 6765  name__}. Message
+0001c390: 3a20 7b65 7d22 0a20 2020 2020 2020 2020  : {e}".         
+0001c3a0: 2020 2029 2066 726f 6d20 650a 2020 2020     ) from e.    
+0001c3b0: 2020 2020 6578 6365 7074 2063 6378 742e      except ccxt.
+0001c3c0: 4261 7365 4572 726f 7220 6173 2065 3a0a  BaseError as e:.
+0001c3d0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0001c3e0: 6520 4f70 6572 6174 696f 6e61 6c45 7863  e OperationalExc
+0001c3f0: 6570 7469 6f6e 2865 2920 6672 6f6d 2065  eption(e) from e
+0001c400: 0a0a 2020 2020 4072 6574 7269 6572 5f61  ..    @retrier_a
+0001c410: 7379 6e63 0a20 2020 2061 7379 6e63 2064  sync.    async d
+0001c420: 6566 2067 6574 5f6d 6172 6b65 745f 6c65  ef get_market_le
+0001c430: 7665 7261 6765 5f74 6965 7273 2873 656c  verage_tiers(sel
+0001c440: 662c 2073 796d 626f 6c3a 2073 7472 2920  f, symbol: str) 
+0001c450: 2d3e 2054 7570 6c65 5b73 7472 2c20 4c69  -> Tuple[str, Li
+0001c460: 7374 5b44 6963 745d 5d3a 0a20 2020 2020  st[Dict]]:.     
+0001c470: 2020 2022 2222 4c65 7665 7261 6765 2074     """Leverage t
+0001c480: 6965 7273 2070 6572 2073 796d 626f 6c22  iers per symbol"
+0001c490: 2222 0a20 2020 2020 2020 2074 7279 3a0a  "".        try:.
+0001c4a0: 2020 2020 2020 2020 2020 2020 7469 6572              tier
+0001c4b0: 203d 2061 7761 6974 2073 656c 662e 5f61   = await self._a
+0001c4c0: 7069 5f61 7379 6e63 2e66 6574 6368 5f6d  pi_async.fetch_m
+0001c4d0: 6172 6b65 745f 6c65 7665 7261 6765 5f74  arket_leverage_t
+0001c4e0: 6965 7273 2873 796d 626f 6c29 0a20 2020  iers(symbol).   
+0001c4f0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0001c500: 7379 6d62 6f6c 2c20 7469 6572 0a20 2020  symbol, tier.   
+0001c510: 2020 2020 2065 7863 6570 7420 6363 7874       except ccxt
+0001c520: 2e44 446f 5350 726f 7465 6374 696f 6e20  .DDoSProtection 
+0001c530: 6173 2065 3a0a 2020 2020 2020 2020 2020  as e:.          
+0001c540: 2020 7261 6973 6520 4444 6f73 5072 6f74    raise DDosProt
+0001c550: 6563 7469 6f6e 2865 2920 6672 6f6d 2065  ection(e) from e
+0001c560: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
+0001c570: 2863 6378 742e 4f70 6572 6174 696f 6e46  (ccxt.OperationF
+0001c580: 6169 6c65 642c 2063 6378 742e 4578 6368  ailed, ccxt.Exch
+0001c590: 616e 6765 4572 726f 7229 2061 7320 653a  angeError) as e:
+0001c5a0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+0001c5b0: 7365 2054 656d 706f 7261 7279 4572 726f  se TemporaryErro
+0001c5c0: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
+0001c5d0: 2020 2066 2243 6f75 6c64 206e 6f74 206c     f"Could not l
+0001c5e0: 6f61 6420 6c65 7665 7261 6765 2074 6965  oad leverage tie
+0001c5f0: 7273 2066 6f72 207b 7379 6d62 6f6c 7d22  rs for {symbol}"
+0001c600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c610: 2066 2220 6475 6520 746f 207b 652e 5f5f   f" due to {e.__
+0001c620: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
+0001c630: 7d2e 204d 6573 7361 6765 3a20 7b65 7d22  }. Message: {e}"
+0001c640: 0a20 2020 2020 2020 2020 2020 2029 2066  .            ) f
+0001c650: 726f 6d20 650a 2020 2020 2020 2020 6578  rom e.        ex
+0001c660: 6365 7074 2063 6378 742e 4261 7365 4572  cept ccxt.BaseEr
+0001c670: 726f 7220 6173 2065 3a0a 2020 2020 2020  ror as e:.      
+0001c680: 2020 2020 2020 7261 6973 6520 4f70 6572        raise Oper
+0001c690: 6174 696f 6e61 6c45 7863 6570 7469 6f6e  ationalException
+0001c6a0: 2865 2920 6672 6f6d 2065 0a0a 2020 2020  (e) from e..    
+0001c6b0: 6465 6620 6c6f 6164 5f6c 6576 6572 6167  def load_leverag
+0001c6c0: 655f 7469 6572 7328 7365 6c66 2920 2d3e  e_tiers(self) ->
+0001c6d0: 2044 6963 745b 7374 722c 204c 6973 745b   Dict[str, List[
+0001c6e0: 4469 6374 5d5d 3a0a 2020 2020 2020 2020  Dict]]:.        
+0001c6f0: 6966 2073 656c 662e 7472 6164 696e 675f  if self.trading_
+0001c700: 6d6f 6465 203d 3d20 5472 6164 696e 674d  mode == TradingM
+0001c710: 6f64 652e 4655 5455 5245 533a 0a20 2020  ode.FUTURES:.   
+0001c720: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+0001c730: 2e65 7863 6861 6e67 655f 6861 7328 2266  .exchange_has("f
+0001c740: 6574 6368 4c65 7665 7261 6765 5469 6572  etchLeverageTier
+0001c750: 7322 293a 0a20 2020 2020 2020 2020 2020  s"):.           
+0001c760: 2020 2020 2023 2046 6574 6368 2061 6c6c       # Fetch all
+0001c770: 206c 6576 6572 6167 6520 7469 6572 7320   leverage tiers 
+0001c780: 6174 206f 6e63 650a 2020 2020 2020 2020  at once.        
+0001c790: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0001c7a0: 656c 662e 6765 745f 6c65 7665 7261 6765  elf.get_leverage
+0001c7b0: 5f74 6965 7273 2829 0a20 2020 2020 2020  _tiers().       
+0001c7c0: 2020 2020 2065 6c69 6620 7365 6c66 2e65       elif self.e
+0001c7d0: 7863 6861 6e67 655f 6861 7328 2266 6574  xchange_has("fet
+0001c7e0: 6368 4d61 726b 6574 4c65 7665 7261 6765  chMarketLeverage
+0001c7f0: 5469 6572 7322 293a 0a20 2020 2020 2020  Tiers"):.       
+0001c800: 2020 2020 2020 2020 2023 204d 7573 7420           # Must 
+0001c810: 6665 7463 6820 7468 6520 6c65 7665 7261  fetch the levera
+0001c820: 6765 2074 6965 7273 2066 6f72 2065 6163  ge tiers for eac
+0001c830: 6820 6d61 726b 6574 2073 6570 6172 6174  h market separat
+0001c840: 656c 790a 2020 2020 2020 2020 2020 2020  ely.            
+0001c850: 2020 2020 2320 2a20 5468 6973 2069 7320      # * This is 
+0001c860: 736c 6f77 287e 3435 7329 206f 6e20 4f6b  slow(~45s) on Ok
+0001c870: 782c 206d 616b 6573 207e 3930 2061 7069  x, makes ~90 api
+0001c880: 2063 616c 6c73 2074 6f20 6c6f 6164 2061   calls to load a
+0001c890: 6c6c 206c 696e 6561 7220 7377 6170 206d  ll linear swap m
+0001c8a0: 6172 6b65 7473 0a20 2020 2020 2020 2020  arkets.         
+0001c8b0: 2020 2020 2020 206d 6172 6b65 7473 203d         markets =
+0001c8c0: 2073 656c 662e 6d61 726b 6574 730a 0a20   self.markets.. 
+0001c8d0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0001c8e0: 796d 626f 6c73 203d 205b 0a20 2020 2020  ymbols = [.     
+0001c8f0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0001c900: 796d 626f 6c0a 2020 2020 2020 2020 2020  ymbol.          
+0001c910: 2020 2020 2020 2020 2020 666f 7220 7379            for sy
+0001c920: 6d62 6f6c 2c20 6d61 726b 6574 2069 6e20  mbol, market in 
+0001c930: 6d61 726b 6574 732e 6974 656d 7328 290a  markets.items().
+0001c940: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c950: 2020 2020 6966 2028 0a20 2020 2020 2020      if (.       
+0001c960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c970: 2073 656c 662e 6d61 726b 6574 5f69 735f   self.market_is_
+0001c980: 6675 7475 7265 286d 6172 6b65 7429 0a20  future(market). 
+0001c990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c9a0: 2020 2020 2020 2061 6e64 206d 6172 6b65         and marke
+0001c9b0: 745b 2271 756f 7465 225d 203d 3d20 7365  t["quote"] == se
+0001c9c0: 6c66 2e5f 636f 6e66 6967 5b22 7374 616b  lf._config["stak
+0001c9d0: 655f 6375 7272 656e 6379 225d 0a20 2020  e_currency"].   
+0001c9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c9f0: 2029 0a20 2020 2020 2020 2020 2020 2020   ).             
+0001ca00: 2020 205d 0a0a 2020 2020 2020 2020 2020     ]..          
+0001ca10: 2020 2020 2020 7469 6572 733a 2044 6963        tiers: Dic
+0001ca20: 745b 7374 722c 204c 6973 745b 4469 6374  t[str, List[Dict
+0001ca30: 5d5d 203d 207b 7d0a 0a20 2020 2020 2020  ]] = {}..       
+0001ca40: 2020 2020 2020 2020 2074 6965 7273 5f63           tiers_c
+0001ca50: 6163 6865 6420 3d20 7365 6c66 2e6c 6f61  ached = self.loa
+0001ca60: 645f 6361 6368 6564 5f6c 6576 6572 6167  d_cached_leverag
+0001ca70: 655f 7469 6572 7328 7365 6c66 2e5f 636f  e_tiers(self._co
+0001ca80: 6e66 6967 5b22 7374 616b 655f 6375 7272  nfig["stake_curr
+0001ca90: 656e 6379 225d 290a 2020 2020 2020 2020  ency"]).        
+0001caa0: 2020 2020 2020 2020 6966 2074 6965 7273          if tiers
+0001cab0: 5f63 6163 6865 643a 0a20 2020 2020 2020  _cached:.       
+0001cac0: 2020 2020 2020 2020 2020 2020 2074 6965               tie
+0001cad0: 7273 203d 2074 6965 7273 5f63 6163 6865  rs = tiers_cache
+0001cae0: 640a 0a20 2020 2020 2020 2020 2020 2020  d..             
+0001caf0: 2020 2063 6f72 6f73 203d 205b 0a20 2020     coros = [.   
+0001cb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cb10: 2073 656c 662e 6765 745f 6d61 726b 6574   self.get_market
+0001cb20: 5f6c 6576 6572 6167 655f 7469 6572 7328  _leverage_tiers(
+0001cb30: 7379 6d62 6f6c 290a 2020 2020 2020 2020  symbol).        
+0001cb40: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+0001cb50: 7379 6d62 6f6c 2069 6e20 736f 7274 6564  symbol in sorted
+0001cb60: 2873 796d 626f 6c73 290a 2020 2020 2020  (symbols).      
+0001cb70: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0001cb80: 2073 796d 626f 6c20 6e6f 7420 696e 2074   symbol not in t
+0001cb90: 6965 7273 0a20 2020 2020 2020 2020 2020  iers.           
+0001cba0: 2020 2020 205d 0a0a 2020 2020 2020 2020       ]..        
+0001cbb0: 2020 2020 2020 2020 2320 4265 2076 6572          # Be ver
+0001cbc0: 626f 7365 2068 6572 652c 2061 7320 7468  bose here, as th
+0001cbd0: 6973 2064 656c 6179 7320 7374 6172 7475  is delays startu
+0001cbe0: 7020 6279 207e 3120 6d69 6e75 7465 2e0a  p by ~1 minute..
+0001cbf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc00: 6966 2063 6f72 6f73 3a0a 2020 2020 2020  if coros:.      
+0001cc10: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
+0001cc20: 6767 6572 2e69 6e66 6f28 0a20 2020 2020  gger.info(.     
+0001cc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc40: 2020 2066 2249 6e69 7469 616c 697a 696e     f"Initializin
+0001cc50: 6720 6c65 7665 7261 6765 5f74 6965 7273  g leverage_tiers
+0001cc60: 2066 6f72 207b 6c65 6e28 7379 6d62 6f6c   for {len(symbol
+0001cc70: 7329 7d20 6d61 726b 6574 732e 2022 0a20  s)} markets. ". 
+0001cc80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc90: 2020 2020 2020 2022 5468 6973 2077 696c         "This wil
+0001cca0: 6c20 7461 6b65 2061 626f 7574 2061 206d  l take about a m
+0001ccb0: 696e 7574 652e 220a 2020 2020 2020 2020  inute.".        
+0001ccc0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+0001ccd0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+0001cce0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+0001ccf0: 2020 2020 2020 2020 6c6f 6767 6572 2e69          logger.i
+0001cd00: 6e66 6f28 2255 7369 6e67 2063 6163 6865  nfo("Using cache
+0001cd10: 6420 6c65 7665 7261 6765 5f74 6965 7273  d leverage_tiers
+0001cd20: 2e22 290a 0a20 2020 2020 2020 2020 2020  .")..           
+0001cd30: 2020 2020 2061 7379 6e63 2064 6566 2067       async def g
+0001cd40: 6174 6865 725f 7265 7375 6c74 7328 696e  ather_results(in
+0001cd50: 7075 745f 636f 726f 293a 0a20 2020 2020  put_coro):.     
+0001cd60: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0001cd70: 6574 7572 6e20 6177 6169 7420 6173 796e  eturn await asyn
+0001cd80: 6369 6f2e 6761 7468 6572 282a 696e 7075  cio.gather(*inpu
+0001cd90: 745f 636f 726f 2c20 7265 7475 726e 5f65  t_coro, return_e
+0001cda0: 7863 6570 7469 6f6e 733d 5472 7565 290a  xceptions=True).
+0001cdb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001cdc0: 2066 6f72 2069 6e70 7574 5f63 6f72 6f20   for input_coro 
+0001cdd0: 696e 2063 6875 6e6b 7328 636f 726f 732c  in chunks(coros,
+0001cde0: 2031 3030 293a 0a20 2020 2020 2020 2020   100):.         
+0001cdf0: 2020 2020 2020 2020 2020 2077 6974 6820             with 
+0001ce00: 7365 6c66 2e5f 6c6f 6f70 5f6c 6f63 6b3a  self._loop_lock:
+0001ce10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ce20: 2020 2020 2020 2020 2072 6573 756c 7473           results
+0001ce30: 203d 2073 656c 662e 6c6f 6f70 2e72 756e   = self.loop.run
+0001ce40: 5f75 6e74 696c 5f63 6f6d 706c 6574 6528  _until_complete(
+0001ce50: 6761 7468 6572 5f72 6573 756c 7473 2869  gather_results(i
+0001ce60: 6e70 7574 5f63 6f72 6f29 290a 0a20 2020  nput_coro))..   
+0001ce70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce80: 2066 6f72 2072 6573 2069 6e20 7265 7375   for res in resu
+0001ce90: 6c74 733a 0a20 2020 2020 2020 2020 2020  lts:.           
+0001cea0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0001ceb0: 6973 696e 7374 616e 6365 2872 6573 2c20  isinstance(res, 
+0001cec0: 4578 6365 7074 696f 6e29 3a0a 2020 2020  Exception):.    
+0001ced0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cee0: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
+0001cef0: 6172 6e69 6e67 2866 224c 6576 6572 6167  arning(f"Leverag
+0001cf00: 6520 7469 6572 2065 7863 6570 7469 6f6e  e tier exception
+0001cf10: 3a20 7b72 6570 7228 7265 7329 7d22 290a  : {repr(res)}").
+0001cf20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cf30: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+0001cf40: 696e 7565 0a20 2020 2020 2020 2020 2020  inue.           
+0001cf50: 2020 2020 2020 2020 2020 2020 2073 796d               sym
+0001cf60: 626f 6c2c 2074 6965 7220 3d20 7265 730a  bol, tier = res.
+0001cf70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cf80: 2020 2020 2020 2020 7469 6572 735b 7379          tiers[sy
+0001cf90: 6d62 6f6c 5d20 3d20 7469 6572 0a20 2020  mbol] = tier.   
+0001cfa0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0001cfb0: 6c65 6e28 636f 726f 7329 203e 2030 3a0a  len(coros) > 0:.
+0001cfc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cfd0: 2020 2020 7365 6c66 2e63 6163 6865 5f6c      self.cache_l
+0001cfe0: 6576 6572 6167 655f 7469 6572 7328 7469  everage_tiers(ti
+0001cff0: 6572 732c 2073 656c 662e 5f63 6f6e 6669  ers, self._confi
+0001d000: 675b 2273 7461 6b65 5f63 7572 7265 6e63  g["stake_currenc
+0001d010: 7922 5d29 0a20 2020 2020 2020 2020 2020  y"]).           
+0001d020: 2020 2020 206c 6f67 6765 722e 696e 666f       logger.info
+0001d030: 2866 2244 6f6e 6520 696e 6974 6961 6c69  (f"Done initiali
+0001d040: 7a69 6e67 207b 6c65 6e28 7379 6d62 6f6c  zing {len(symbol
+0001d050: 7329 7d20 6d61 726b 6574 732e 2229 0a0a  s)} markets.")..
+0001d060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d070: 7265 7475 726e 2074 6965 7273 0a20 2020  return tiers.   
+0001d080: 2020 2020 2072 6574 7572 6e20 7b7d 0a0a       return {}..
+0001d090: 2020 2020 6465 6620 6361 6368 655f 6c65      def cache_le
+0001d0a0: 7665 7261 6765 5f74 6965 7273 2873 656c  verage_tiers(sel
+0001d0b0: 662c 2074 6965 7273 3a20 4469 6374 5b73  f, tiers: Dict[s
+0001d0c0: 7472 2c20 4c69 7374 5b44 6963 745d 5d2c  tr, List[Dict]],
+0001d0d0: 2073 7461 6b65 5f63 7572 7265 6e63 793a   stake_currency:
+0001d0e0: 2073 7472 2920 2d3e 204e 6f6e 653a 0a20   str) -> None:. 
+0001d0f0: 2020 2020 2020 2066 696c 656e 616d 6520         filename 
+0001d100: 3d20 7365 6c66 2e5f 636f 6e66 6967 5b22  = self._config["
+0001d110: 6461 7461 6469 7222 5d20 2f20 2266 7574  datadir"] / "fut
+0001d120: 7572 6573 2220 2f20 6622 6c65 7665 7261  ures" / f"levera
+0001d130: 6765 5f74 6965 7273 5f7b 7374 616b 655f  ge_tiers_{stake_
+0001d140: 6375 7272 656e 6379 7d2e 6a73 6f6e 220a  currency}.json".
+0001d150: 2020 2020 2020 2020 6966 206e 6f74 2066          if not f
+0001d160: 696c 656e 616d 652e 7061 7265 6e74 2e69  ilename.parent.i
+0001d170: 735f 6469 7228 293a 0a20 2020 2020 2020  s_dir():.       
+0001d180: 2020 2020 2066 696c 656e 616d 652e 7061       filename.pa
+0001d190: 7265 6e74 2e6d 6b64 6972 2870 6172 656e  rent.mkdir(paren
+0001d1a0: 7473 3d54 7275 6529 0a20 2020 2020 2020  ts=True).       
+0001d1b0: 2064 6174 6120 3d20 7b0a 2020 2020 2020   data = {.      
+0001d1c0: 2020 2020 2020 2275 7064 6174 6564 223a        "updated":
+0001d1d0: 2064 6174 6574 696d 652e 6e6f 7728 7469   datetime.now(ti
+0001d1e0: 6d65 7a6f 6e65 2e75 7463 292c 0a20 2020  mezone.utc),.   
+0001d1f0: 2020 2020 2020 2020 2022 6461 7461 223a           "data":
+0001d200: 2074 6965 7273 2c0a 2020 2020 2020 2020   tiers,.        
+0001d210: 7d0a 2020 2020 2020 2020 6669 6c65 5f64  }.        file_d
+0001d220: 756d 705f 6a73 6f6e 2866 696c 656e 616d  ump_json(filenam
+0001d230: 652c 2064 6174 6129 0a0a 2020 2020 6465  e, data)..    de
+0001d240: 6620 6c6f 6164 5f63 6163 6865 645f 6c65  f load_cached_le
+0001d250: 7665 7261 6765 5f74 6965 7273 280a 2020  verage_tiers(.  
+0001d260: 2020 2020 2020 7365 6c66 2c20 7374 616b        self, stak
+0001d270: 655f 6375 7272 656e 6379 3a20 7374 722c  e_currency: str,
+0001d280: 2063 6163 6865 5f74 696d 653a 204f 7074   cache_time: Opt
+0001d290: 696f 6e61 6c5b 7469 6d65 6465 6c74 615d  ional[timedelta]
+0001d2a0: 203d 204e 6f6e 650a 2020 2020 2920 2d3e   = None.    ) ->
+0001d2b0: 204f 7074 696f 6e61 6c5b 4469 6374 5b73   Optional[Dict[s
+0001d2c0: 7472 2c20 4c69 7374 5b44 6963 745d 5d5d  tr, List[Dict]]]
+0001d2d0: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
+0001d2e0: 2020 2020 2020 4c6f 6164 2063 6163 6865        Load cache
+0001d2f0: 6420 6c65 7665 7261 6765 2074 6965 7273  d leverage tiers
+0001d300: 2066 726f 6d20 6469 736b 0a20 2020 2020   from disk.     
+0001d310: 2020 203a 7061 7261 6d20 6361 6368 655f     :param cache_
+0001d320: 7469 6d65 3a20 5468 6520 6d61 7869 6d75  time: The maximu
+0001d330: 6d20 6167 6520 6f66 2074 6865 2063 6163  m age of the cac
+0001d340: 6865 2062 6566 6f72 6520 6974 2069 7320  he before it is 
+0001d350: 636f 6e73 6964 6572 6564 206f 7574 6461  considered outda
+0001d360: 7465 640a 2020 2020 2020 2020 2222 220a  ted.        """.
+0001d370: 2020 2020 2020 2020 6966 206e 6f74 2063          if not c
+0001d380: 6163 6865 5f74 696d 653a 0a20 2020 2020  ache_time:.     
+0001d390: 2020 2020 2020 2023 2044 6566 6175 6c74         # Default
+0001d3a0: 2074 6f20 3420 7765 656b 730a 2020 2020   to 4 weeks.    
+0001d3b0: 2020 2020 2020 2020 6361 6368 655f 7469          cache_ti
+0001d3c0: 6d65 203d 2074 696d 6564 656c 7461 2877  me = timedelta(w
+0001d3d0: 6565 6b73 3d34 290a 2020 2020 2020 2020  eeks=4).        
+0001d3e0: 6669 6c65 6e61 6d65 203d 2073 656c 662e  filename = self.
+0001d3f0: 5f63 6f6e 6669 675b 2264 6174 6164 6972  _config["datadir
+0001d400: 225d 202f 2022 6675 7475 7265 7322 202f  "] / "futures" /
+0001d410: 2066 226c 6576 6572 6167 655f 7469 6572   f"leverage_tier
+0001d420: 735f 7b73 7461 6b65 5f63 7572 7265 6e63  s_{stake_currenc
+0001d430: 797d 2e6a 736f 6e22 0a20 2020 2020 2020  y}.json".       
+0001d440: 2069 6620 6669 6c65 6e61 6d65 2e69 735f   if filename.is_
+0001d450: 6669 6c65 2829 3a0a 2020 2020 2020 2020  file():.        
+0001d460: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+0001d470: 2020 2020 2020 2020 2074 6965 7273 203d           tiers =
+0001d480: 2066 696c 655f 6c6f 6164 5f6a 736f 6e28   file_load_json(
+0001d490: 6669 6c65 6e61 6d65 290a 2020 2020 2020  filename).      
+0001d4a0: 2020 2020 2020 2020 2020 7570 6461 7465            update
+0001d4b0: 6420 3d20 7469 6572 732e 6765 7428 2275  d = tiers.get("u
+0001d4c0: 7064 6174 6564 2229 0a20 2020 2020 2020  pdated").       
+0001d4d0: 2020 2020 2020 2020 2069 6620 7570 6461           if upda
+0001d4e0: 7465 643a 0a20 2020 2020 2020 2020 2020  ted:.           
+0001d4f0: 2020 2020 2020 2020 2075 7064 6174 6564           updated
+0001d500: 5f64 7420 3d20 7061 7273 6572 2e70 6172  _dt = parser.par
+0001d510: 7365 2875 7064 6174 6564 290a 2020 2020  se(updated).    
+0001d520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d530: 6966 2075 7064 6174 6564 5f64 7420 3c20  if updated_dt < 
+0001d540: 6461 7465 7469 6d65 2e6e 6f77 2874 696d  datetime.now(tim
+0001d550: 657a 6f6e 652e 7574 6329 202d 2063 6163  ezone.utc) - cac
+0001d560: 6865 5f74 696d 653a 0a20 2020 2020 2020  he_time:.       
+0001d570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d580: 206c 6f67 6765 722e 696e 666f 2822 4361   logger.info("Ca
+0001d590: 6368 6564 206c 6576 6572 6167 6520 7469  ched leverage ti
+0001d5a0: 6572 7320 6172 6520 6f75 7464 6174 6564  ers are outdated
+0001d5b0: 2e20 5769 6c6c 2075 7064 6174 652e 2229  . Will update.")
+0001d5c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001d5d0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0001d5e0: 4e6f 6e65 0a20 2020 2020 2020 2020 2020  None.           
+0001d5f0: 2020 2020 2072 6574 7572 6e20 7469 6572       return tier
+0001d600: 735b 2264 6174 6122 5d0a 2020 2020 2020  s["data"].      
+0001d610: 2020 2020 2020 6578 6365 7074 2045 7863        except Exc
+0001d620: 6570 7469 6f6e 3a0a 2020 2020 2020 2020  eption:.        
+0001d630: 2020 2020 2020 2020 6c6f 6767 6572 2e65          logger.e
+0001d640: 7863 6570 7469 6f6e 2822 4572 726f 7220  xception("Error 
+0001d650: 6c6f 6164 696e 6720 6361 6368 6564 206c  loading cached l
+0001d660: 6576 6572 6167 6520 7469 6572 732e 2052  everage tiers. R
+0001d670: 6566 7265 7368 696e 672e 2229 0a20 2020  efreshing.").   
+0001d680: 2020 2020 2072 6574 7572 6e20 4e6f 6e65       return None
+0001d690: 0a0a 2020 2020 6465 6620 6669 6c6c 5f6c  ..    def fill_l
+0001d6a0: 6576 6572 6167 655f 7469 6572 7328 7365  everage_tiers(se
+0001d6b0: 6c66 2920 2d3e 204e 6f6e 653a 0a20 2020  lf) -> None:.   
+0001d6c0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+0001d6d0: 2041 7373 6967 6e73 2070 726f 7065 7274   Assigns propert
+0001d6e0: 7920 5f6c 6576 6572 6167 655f 7469 6572  y _leverage_tier
+0001d6f0: 7320 746f 2061 2064 6963 7469 6f6e 6172  s to a dictionar
+0001d700: 7920 6f66 2069 6e66 6f72 6d61 7469 6f6e  y of information
+0001d710: 2061 626f 7574 2074 6865 206c 6576 6572   about the lever
+0001d720: 6167 650a 2020 2020 2020 2020 616c 6c6f  age.        allo
+0001d730: 7765 6420 6f6e 2065 6163 6820 7061 6972  wed on each pair
+0001d740: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+0001d750: 2020 2020 206c 6576 6572 6167 655f 7469       leverage_ti
+0001d760: 6572 7320 3d20 7365 6c66 2e6c 6f61 645f  ers = self.load_
+0001d770: 6c65 7665 7261 6765 5f74 6965 7273 2829  leverage_tiers()
+0001d780: 0a20 2020 2020 2020 2066 6f72 2070 6169  .        for pai
+0001d790: 722c 2074 6965 7273 2069 6e20 6c65 7665  r, tiers in leve
+0001d7a0: 7261 6765 5f74 6965 7273 2e69 7465 6d73  rage_tiers.items
+0001d7b0: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+0001d7c0: 7061 6972 5f74 6965 7273 203d 205b 5d0a  pair_tiers = [].
+0001d7d0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+0001d7e0: 7469 6572 2069 6e20 7469 6572 733a 0a20  tier in tiers:. 
+0001d7f0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0001d800: 6169 725f 7469 6572 732e 6170 7065 6e64  air_tiers.append
+0001d810: 2873 656c 662e 7061 7273 655f 6c65 7665  (self.parse_leve
+0001d820: 7261 6765 5f74 6965 7228 7469 6572 2929  rage_tier(tier))
+0001d830: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+0001d840: 662e 5f6c 6576 6572 6167 655f 7469 6572  f._leverage_tier
+0001d850: 735b 7061 6972 5d20 3d20 7061 6972 5f74  s[pair] = pair_t
+0001d860: 6965 7273 0a0a 2020 2020 6465 6620 7061  iers..    def pa
+0001d870: 7273 655f 6c65 7665 7261 6765 5f74 6965  rse_leverage_tie
+0001d880: 7228 7365 6c66 2c20 7469 6572 2920 2d3e  r(self, tier) ->
+0001d890: 2044 6963 743a 0a20 2020 2020 2020 2069   Dict:.        i
+0001d8a0: 6e66 6f20 3d20 7469 6572 2e67 6574 2822  nfo = tier.get("
+0001d8b0: 696e 666f 222c 207b 7d29 0a20 2020 2020  info", {}).     
+0001d8c0: 2020 2072 6574 7572 6e20 7b0a 2020 2020     return {.    
+0001d8d0: 2020 2020 2020 2020 226d 696e 4e6f 7469          "minNoti
+0001d8e0: 6f6e 616c 223a 2074 6965 725b 226d 696e  onal": tier["min
+0001d8f0: 4e6f 7469 6f6e 616c 225d 2c0a 2020 2020  Notional"],.    
+0001d900: 2020 2020 2020 2020 226d 6178 4e6f 7469          "maxNoti
+0001d910: 6f6e 616c 223a 2074 6965 725b 226d 6178  onal": tier["max
+0001d920: 4e6f 7469 6f6e 616c 225d 2c0a 2020 2020  Notional"],.    
+0001d930: 2020 2020 2020 2020 226d 6169 6e74 656e          "mainten
+0001d940: 616e 6365 4d61 7267 696e 5261 7465 223a  anceMarginRate":
+0001d950: 2074 6965 725b 226d 6169 6e74 656e 616e   tier["maintenan
+0001d960: 6365 4d61 7267 696e 5261 7465 225d 2c0a  ceMarginRate"],.
+0001d970: 2020 2020 2020 2020 2020 2020 226d 6178              "max
+0001d980: 4c65 7665 7261 6765 223a 2074 6965 725b  Leverage": tier[
+0001d990: 226d 6178 4c65 7665 7261 6765 225d 2c0a  "maxLeverage"],.
+0001d9a0: 2020 2020 2020 2020 2020 2020 226d 6169              "mai
+0001d9b0: 6e74 416d 7422 3a20 666c 6f61 7428 696e  ntAmt": float(in
+0001d9c0: 666f 5b22 6375 6d22 5d29 2069 6620 2263  fo["cum"]) if "c
+0001d9d0: 756d 2220 696e 2069 6e66 6f20 656c 7365  um" in info else
+0001d9e0: 204e 6f6e 652c 0a20 2020 2020 2020 207d   None,.        }
+0001d9f0: 0a0a 2020 2020 6465 6620 6765 745f 6d61  ..    def get_ma
+0001da00: 785f 6c65 7665 7261 6765 2873 656c 662c  x_leverage(self,
+0001da10: 2070 6169 723a 2073 7472 2c20 7374 616b   pair: str, stak
+0001da20: 655f 616d 6f75 6e74 3a20 4f70 7469 6f6e  e_amount: Option
+0001da30: 616c 5b66 6c6f 6174 5d29 202d 3e20 666c  al[float]) -> fl
+0001da40: 6f61 743a 0a20 2020 2020 2020 2022 2222  oat:.        """
+0001da50: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+0001da60: 2074 6865 206d 6178 696d 756d 206c 6576   the maximum lev
+0001da70: 6572 6167 6520 7468 6174 2061 2070 6169  erage that a pai
+0001da80: 7220 6361 6e20 6265 2074 7261 6465 6420  r can be traded 
+0001da90: 6174 0a20 2020 2020 2020 203a 7061 7261  at.        :para
+0001daa0: 6d20 7061 6972 3a20 5468 6520 6261 7365  m pair: The base
+0001dab0: 2f71 756f 7465 2063 7572 7265 6e63 7920  /quote currency 
+0001dac0: 7061 6972 2062 6569 6e67 2074 7261 6465  pair being trade
+0001dad0: 640a 2020 2020 2020 2020 3a73 7461 6b65  d.        :stake
+0001dae0: 5f61 6d6f 756e 743a 2054 6865 2074 6f74  _amount: The tot
+0001daf0: 616c 2076 616c 7565 206f 6620 7468 6520  al value of the 
+0001db00: 7472 6164 6572 7320 6d61 7267 696e 5f6d  traders margin_m
+0001db10: 6f64 6520 696e 2071 756f 7465 2063 7572  ode in quote cur
+0001db20: 7265 6e63 790a 2020 2020 2020 2020 2222  rency.        ""
+0001db30: 220a 0a20 2020 2020 2020 2069 6620 7365  "..        if se
+0001db40: 6c66 2e74 7261 6469 6e67 5f6d 6f64 6520  lf.trading_mode 
+0001db50: 3d3d 2054 7261 6469 6e67 4d6f 6465 2e53  == TradingMode.S
+0001db60: 504f 543a 0a20 2020 2020 2020 2020 2020  POT:.           
+0001db70: 2072 6574 7572 6e20 312e 300a 0a20 2020   return 1.0..   
+0001db80: 2020 2020 2069 6620 7365 6c66 2e74 7261       if self.tra
+0001db90: 6469 6e67 5f6d 6f64 6520 3d3d 2054 7261  ding_mode == Tra
+0001dba0: 6469 6e67 4d6f 6465 2e46 5554 5552 4553  dingMode.FUTURES
+0001dbb0: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
+0001dbc0: 4368 6563 6b73 2061 6e64 2065 6467 6520  Checks and edge 
+0001dbd0: 6361 7365 730a 2020 2020 2020 2020 2020  cases.          
+0001dbe0: 2020 6966 2073 7461 6b65 5f61 6d6f 756e    if stake_amoun
+0001dbf0: 7420 6973 204e 6f6e 653a 0a20 2020 2020  t is None:.     
+0001dc00: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0001dc10: 204f 7065 7261 7469 6f6e 616c 4578 6365   OperationalExce
+0001dc20: 7074 696f 6e28 0a20 2020 2020 2020 2020  ption(.         
+0001dc30: 2020 2020 2020 2020 2020 2066 227b 7365             f"{se
+0001dc40: 6c66 2e6e 616d 657d 2e67 6574 5f6d 6178  lf.name}.get_max
+0001dc50: 5f6c 6576 6572 6167 6520 7265 7175 6972  _leverage requir
+0001dc60: 6573 2061 7267 756d 656e 7420 7374 616b  es argument stak
+0001dc70: 655f 616d 6f75 6e74 220a 2020 2020 2020  e_amount".      
+0001dc80: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+0001dc90: 2020 2020 2020 2020 2069 6620 7061 6972           if pair
+0001dca0: 206e 6f74 2069 6e20 7365 6c66 2e5f 6c65   not in self._le
+0001dcb0: 7665 7261 6765 5f74 6965 7273 3a0a 2020  verage_tiers:.  
+0001dcc0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+0001dcd0: 4d61 7962 6520 7261 6973 6520 6578 6365  Maybe raise exce
+0001dce0: 7074 696f 6e20 6265 6361 7573 6520 6974  ption because it
+0001dcf0: 2063 616e 2774 2062 6520 7472 6164 6564   can't be traded
+0001dd00: 206f 6e20 6675 7475 7265 733f 0a20 2020   on futures?.   
+0001dd10: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+0001dd20: 7572 6e20 312e 300a 0a20 2020 2020 2020  urn 1.0..       
+0001dd30: 2020 2020 2070 6169 725f 7469 6572 7320       pair_tiers 
+0001dd40: 3d20 7365 6c66 2e5f 6c65 7665 7261 6765  = self._leverage
+0001dd50: 5f74 6965 7273 5b70 6169 725d 0a0a 2020  _tiers[pair]..  
+0001dd60: 2020 2020 2020 2020 2020 6966 2073 7461            if sta
+0001dd70: 6b65 5f61 6d6f 756e 7420 3d3d 2030 3a0a  ke_amount == 0:.
+0001dd80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001dd90: 7265 7475 726e 2073 656c 662e 5f6c 6576  return self._lev
+0001dda0: 6572 6167 655f 7469 6572 735b 7061 6972  erage_tiers[pair
+0001ddb0: 5d5b 305d 5b22 6d61 784c 6576 6572 6167  ][0]["maxLeverag
+0001ddc0: 6522 5d20 2023 204d 6178 206c 6576 2066  e"]  # Max lev f
+0001ddd0: 6f72 206c 6f77 6573 7420 616d 6f75 6e74  or lowest amount
+0001dde0: 0a0a 2020 2020 2020 2020 2020 2020 666f  ..            fo
+0001ddf0: 7220 7469 6572 5f69 6e64 6578 2069 6e20  r tier_index in 
+0001de00: 7261 6e67 6528 6c65 6e28 7061 6972 5f74  range(len(pair_t
+0001de10: 6965 7273 2929 3a0a 2020 2020 2020 2020  iers)):.        
+0001de20: 2020 2020 2020 2020 7469 6572 203d 2070          tier = p
+0001de30: 6169 725f 7469 6572 735b 7469 6572 5f69  air_tiers[tier_i
+0001de40: 6e64 6578 5d0a 2020 2020 2020 2020 2020  ndex].          
+0001de50: 2020 2020 2020 6c65 7620 3d20 7469 6572        lev = tier
+0001de60: 5b22 6d61 784c 6576 6572 6167 6522 5d0a  ["maxLeverage"].
+0001de70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001de80: 2069 6620 7469 6572 5f69 6e64 6578 203c   if tier_index <
+0001de90: 206c 656e 2870 6169 725f 7469 6572 7329   len(pair_tiers)
+0001dea0: 202d 2031 3a0a 2020 2020 2020 2020 2020   - 1:.          
+0001deb0: 2020 2020 2020 2020 2020 6e65 7874 5f74            next_t
+0001dec0: 6965 7220 3d20 7061 6972 5f74 6965 7273  ier = pair_tiers
+0001ded0: 5b74 6965 725f 696e 6465 7820 2b20 315d  [tier_index + 1]
+0001dee0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001def0: 2020 2020 206e 6578 745f 666c 6f6f 7220       next_floor 
+0001df00: 3d20 6e65 7874 5f74 6965 725b 226d 696e  = next_tier["min
+0001df10: 4e6f 7469 6f6e 616c 225d 202f 206e 6578  Notional"] / nex
+0001df20: 745f 7469 6572 5b22 6d61 784c 6576 6572  t_tier["maxLever
+0001df30: 6167 6522 5d0a 2020 2020 2020 2020 2020  age"].          
+0001df40: 2020 2020 2020 2020 2020 6966 206e 6578            if nex
+0001df50: 745f 666c 6f6f 7220 3e20 7374 616b 655f  t_floor > stake_
+0001df60: 616d 6f75 6e74 3a20 2023 204e 6578 7420  amount:  # Next 
+0001df70: 7469 6572 206d 696e 2074 6f6f 2068 6967  tier min too hig
+0001df80: 6820 666f 7220 7374 616b 6520 616d 6f75  h for stake amou
+0001df90: 6e74 0a20 2020 2020 2020 2020 2020 2020  nt.             
+0001dfa0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0001dfb0: 6e20 6d69 6e28 2874 6965 725b 226d 6178  n min((tier["max
+0001dfc0: 4e6f 7469 6f6e 616c 225d 202f 2073 7461  Notional"] / sta
+0001dfd0: 6b65 5f61 6d6f 756e 7429 2c20 6c65 7629  ke_amount), lev)
+0001dfe0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001dff0: 2020 2020 2020 2020 2023 0a20 2020 2020           #.     
+0001e000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e010: 2020 2023 2057 6974 6820 7468 6520 7477     # With the tw
+0001e020: 6f20 6c65 7665 7261 6765 2074 6965 7273  o leverage tiers
+0001e030: 2062 656c 6f77 2c0a 2020 2020 2020 2020   below,.        
+0001e040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e050: 2320 2d20 6120 7374 616b 6520 616d 6f75  # - a stake amou
+0001e060: 6e74 206f 6620 3135 3020 776f 756c 6420  nt of 150 would 
+0001e070: 6d65 616e 2061 206d 6178 206c 6576 6572  mean a max lever
+0001e080: 6167 6520 6f66 2028 3130 3030 3020 2f20  age of (10000 / 
+0001e090: 3135 3029 203d 2036 362e 3636 0a20 2020  150) = 66.66.   
+0001e0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e0b0: 2020 2020 2023 202d 2073 7461 6b65 7320       # - stakes 
+0001e0c0: 6265 6c6f 7720 3133 332e 3333 203d 206d  below 133.33 = m
+0001e0d0: 6178 5f6c 6576 206f 6620 3735 0a20 2020  ax_lev of 75.   
+0001e0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e0f0: 2020 2020 2023 202d 2073 7461 6b65 7320       # - stakes 
+0001e100: 6265 7477 6565 6e20 3133 332e 3333 2d32  between 133.33-2
+0001e110: 3030 203d 206d 6178 5f6c 6576 206f 6620  00 = max_lev of 
+0001e120: 3130 3030 302f 7374 616b 6520 3d20 3530  10000/stake = 50
+0001e130: 2e30 312d 3734 2e39 390a 2020 2020 2020  .01-74.99.      
+0001e140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e150: 2020 2320 2d20 7374 616b 6573 2066 726f    # - stakes fro
+0001e160: 6d20 3230 3020 2b20 3130 3030 203d 206d  m 200 + 1000 = m
+0001e170: 6178 5f6c 6576 206f 6620 3530 0a20 2020  ax_lev of 50.   
 0001e180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e190: 2320 2020 2020 226c 6576 223a 2035 302c  #     "lev": 50,
-0001e1a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e1b0: 2020 2020 2020 2020 2023 207d 0a20 2020           # }.   
-0001e1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e1d0: 2020 2020 2023 0a0a 2020 2020 2020 2020       #..        
-0001e1e0: 2020 2020 2020 2020 656c 7365 3a20 2023          else:  #
-0001e1f0: 2069 6620 6f6e 2074 6865 206c 6173 7420   if on the last 
-0001e200: 7469 6572 0a20 2020 2020 2020 2020 2020  tier.           
-0001e210: 2020 2020 2020 2020 2069 6620 7374 616b           if stak
-0001e220: 655f 616d 6f75 6e74 203e 2074 6965 725b  e_amount > tier[
-0001e230: 276d 6178 4e6f 7469 6f6e 616c 275d 3a0a  'maxNotional']:.
-0001e240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e250: 2020 2020 2020 2020 2320 4966 2073 7461          # If sta
-0001e260: 6b65 2069 7320 3e20 7468 616e 206d 6178  ke is > than max
-0001e270: 2074 7261 6465 6162 6c65 2061 6d6f 756e   tradeable amoun
-0001e280: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-0001e290: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0001e2a0: 496e 7661 6c69 644f 7264 6572 4578 6365  InvalidOrderExce
-0001e2b0: 7074 696f 6e28 6627 416d 6f75 6e74 207b  ption(f'Amount {
-0001e2c0: 7374 616b 655f 616d 6f75 6e74 7d20 746f  stake_amount} to
-0001e2d0: 6f20 6869 6768 2066 6f72 207b 7061 6972  o high for {pair
-0001e2e0: 7d27 290a 2020 2020 2020 2020 2020 2020  }').            
-0001e2f0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0001e300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e310: 2020 2020 2020 7265 7475 726e 2074 6965        return tie
-0001e320: 725b 276d 6178 4c65 7665 7261 6765 275d  r['maxLeverage']
-0001e330: 0a0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
-0001e340: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
-0001e350: 7863 6570 7469 6f6e 280a 2020 2020 2020  xception(.      
-0001e360: 2020 2020 2020 2020 2020 274c 6f6f 7065            'Loope
-0001e370: 6420 7468 726f 7567 6820 616c 6c20 7469  d through all ti
-0001e380: 6572 7320 7769 7468 6f75 7420 6669 6e64  ers without find
-0001e390: 696e 6720 6120 6d61 7820 6c65 7665 7261  ing a max levera
-0001e3a0: 6765 2e20 5368 6f75 6c64 206e 6576 6572  ge. Should never
-0001e3b0: 2062 6520 7265 6163 6865 6427 0a20 2020   be reached'.   
-0001e3c0: 2020 2020 2020 2020 2029 0a0a 2020 2020           )..    
-0001e3d0: 2020 2020 656c 6966 2073 656c 662e 7472      elif self.tr
-0001e3e0: 6164 696e 675f 6d6f 6465 203d 3d20 5472  ading_mode == Tr
-0001e3f0: 6164 696e 674d 6f64 652e 4d41 5247 494e  adingMode.MARGIN
-0001e400: 3a20 2023 2053 6561 7263 6820 6d61 726b  :  # Search mark
-0001e410: 6574 732e 6c69 6d69 7473 2066 6f72 206d  ets.limits for m
-0001e420: 6178 206c 6576 0a20 2020 2020 2020 2020  ax lev.         
-0001e430: 2020 206d 6172 6b65 7420 3d20 7365 6c66     market = self
-0001e440: 2e6d 6172 6b65 7473 5b70 6169 725d 0a20  .markets[pair]. 
-0001e450: 2020 2020 2020 2020 2020 2069 6620 6d61             if ma
-0001e460: 726b 6574 5b27 6c69 6d69 7473 275d 5b27  rket['limits']['
-0001e470: 6c65 7665 7261 6765 275d 5b27 6d61 7827  leverage']['max'
-0001e480: 5d20 6973 206e 6f74 204e 6f6e 653a 0a20  ] is not None:. 
-0001e490: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0001e4a0: 6574 7572 6e20 6d61 726b 6574 5b27 6c69  eturn market['li
-0001e4b0: 6d69 7473 275d 5b27 6c65 7665 7261 6765  mits']['leverage
-0001e4c0: 275d 5b27 6d61 7827 5d0a 2020 2020 2020  ']['max'].      
-0001e4d0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-0001e4e0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0001e4f0: 726e 2031 2e30 2020 2320 4465 6661 756c  rn 1.0  # Defaul
-0001e500: 7420 6966 206d 6178 206c 6576 6572 6167  t if max leverag
-0001e510: 6520 6361 6e6e 6f74 2062 6520 666f 756e  e cannot be foun
-0001e520: 640a 2020 2020 2020 2020 656c 7365 3a0a  d.        else:.
-0001e530: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0001e540: 726e 2031 2e30 0a0a 2020 2020 4072 6574  rn 1.0..    @ret
-0001e550: 7269 6572 0a20 2020 2064 6566 205f 7365  rier.    def _se
-0001e560: 745f 6c65 7665 7261 6765 280a 2020 2020  t_leverage(.    
-0001e570: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
-0001e580: 2020 6c65 7665 7261 6765 3a20 666c 6f61    leverage: floa
-0001e590: 742c 0a20 2020 2020 2020 2070 6169 723a  t,.        pair:
-0001e5a0: 204f 7074 696f 6e61 6c5b 7374 725d 203d   Optional[str] =
-0001e5b0: 204e 6f6e 652c 0a20 2020 2020 2020 2061   None,.        a
-0001e5c0: 6363 6570 745f 6661 696c 3a20 626f 6f6c  ccept_fail: bool
-0001e5d0: 203d 2046 616c 7365 2c0a 2020 2020 293a   = False,.    ):
-0001e5e0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-0001e5f0: 2020 2020 2053 6574 2773 2074 6865 206c       Set's the l
-0001e600: 6576 6572 6167 6520 6265 666f 7265 206d  everage before m
-0001e610: 616b 696e 6720 6120 7472 6164 652c 2069  aking a trade, i
-0001e620: 6e20 6f72 6465 7220 746f 206e 6f74 0a20  n order to not. 
-0001e630: 2020 2020 2020 2068 6176 6520 7468 6520         have the 
-0001e640: 7361 6d65 206c 6576 6572 6167 6520 6f6e  same leverage on
-0001e650: 2065 7665 7279 2074 7261 6465 0a20 2020   every trade.   
-0001e660: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0001e670: 2069 6620 7365 6c66 2e5f 636f 6e66 6967   if self._config
-0001e680: 5b27 6472 795f 7275 6e27 5d20 6f72 206e  ['dry_run'] or n
-0001e690: 6f74 2073 656c 662e 6578 6368 616e 6765  ot self.exchange
-0001e6a0: 5f68 6173 2822 7365 744c 6576 6572 6167  _has("setLeverag
-0001e6b0: 6522 293a 0a20 2020 2020 2020 2020 2020  e"):.           
-0001e6c0: 2023 2053 6f6d 6520 6578 6368 616e 6765   # Some exchange
-0001e6d0: 7320 6f6e 6c79 2073 7570 706f 7274 206f  s only support o
-0001e6e0: 6e65 206d 6172 6769 6e5f 6d6f 6465 2074  ne margin_mode t
-0001e6f0: 7970 650a 2020 2020 2020 2020 2020 2020  ype.            
-0001e700: 7265 7475 726e 0a20 2020 2020 2020 2069  return.        i
-0001e710: 6620 7365 6c66 2e5f 6674 5f68 6173 2e67  f self._ft_has.g
-0001e720: 6574 2827 666c 6f6f 725f 6c65 7665 7261  et('floor_levera
-0001e730: 6765 272c 2046 616c 7365 2920 6973 2054  ge', False) is T
-0001e740: 7275 653a 0a20 2020 2020 2020 2020 2020  rue:.           
-0001e750: 2023 2052 6f75 6e64 696e 6720 666f 7220   # Rounding for 
-0001e760: 6269 6e61 6e63 6520 2e2e 2e0a 2020 2020  binance ....    
-0001e770: 2020 2020 2020 2020 6c65 7665 7261 6765          leverage
-0001e780: 203d 2066 6c6f 6f72 286c 6576 6572 6167   = floor(leverag
-0001e790: 6529 0a20 2020 2020 2020 2074 7279 3a0a  e).        try:.
-0001e7a0: 2020 2020 2020 2020 2020 2020 7265 7320              res 
-0001e7b0: 3d20 7365 6c66 2e5f 6170 692e 7365 745f  = self._api.set_
-0001e7c0: 6c65 7665 7261 6765 2873 796d 626f 6c3d  leverage(symbol=
-0001e7d0: 7061 6972 2c20 6c65 7665 7261 6765 3d6c  pair, leverage=l
-0001e7e0: 6576 6572 6167 6529 0a20 2020 2020 2020  everage).       
-0001e7f0: 2020 2020 2073 656c 662e 5f6c 6f67 5f65       self._log_e
-0001e800: 7863 6861 6e67 655f 7265 7370 6f6e 7365  xchange_response
-0001e810: 2827 7365 745f 6c65 7665 7261 6765 272c  ('set_leverage',
-0001e820: 2072 6573 290a 2020 2020 2020 2020 6578   res).        ex
-0001e830: 6365 7074 2063 6378 742e 4444 6f53 5072  cept ccxt.DDoSPr
-0001e840: 6f74 6563 7469 6f6e 2061 7320 653a 0a20  otection as e:. 
-0001e850: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0001e860: 2044 446f 7350 726f 7465 6374 696f 6e28   DDosProtection(
-0001e870: 6529 2066 726f 6d20 650a 2020 2020 2020  e) from e.      
-0001e880: 2020 6578 6365 7074 2028 6363 7874 2e42    except (ccxt.B
-0001e890: 6164 5265 7175 6573 742c 2063 6378 742e  adRequest, ccxt.
-0001e8a0: 4f70 6572 6174 696f 6e52 656a 6563 7465  OperationRejecte
-0001e8b0: 642c 2063 6378 742e 496e 7375 6666 6963  d, ccxt.Insuffic
-0001e8c0: 6965 6e74 4675 6e64 7329 2061 7320 653a  ientFunds) as e:
-0001e8d0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0001e8e0: 6e6f 7420 6163 6365 7074 5f66 6169 6c3a  not accept_fail:
-0001e8f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e900: 2072 6169 7365 2054 656d 706f 7261 7279   raise Temporary
-0001e910: 4572 726f 7228 0a20 2020 2020 2020 2020  Error(.         
-0001e920: 2020 2020 2020 2020 2020 2066 2743 6f75             f'Cou
-0001e930: 6c64 206e 6f74 2073 6574 206c 6576 6572  ld not set lever
-0001e940: 6167 6520 6475 6520 746f 207b 652e 5f5f  age due to {e.__
-0001e950: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
-0001e960: 7d2e 204d 6573 7361 6765 3a20 7b65 7d27  }. Message: {e}'
-0001e970: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
-0001e980: 2065 7863 6570 7420 2863 6378 742e 4f70   except (ccxt.Op
-0001e990: 6572 6174 696f 6e46 6169 6c65 642c 2063  erationFailed, c
-0001e9a0: 6378 742e 4578 6368 616e 6765 4572 726f  cxt.ExchangeErro
-0001e9b0: 7229 2061 7320 653a 0a20 2020 2020 2020  r) as e:.       
-0001e9c0: 2020 2020 2072 6169 7365 2054 656d 706f       raise Tempo
-0001e9d0: 7261 7279 4572 726f 7228 0a20 2020 2020  raryError(.     
-0001e9e0: 2020 2020 2020 2020 2020 2066 2743 6f75             f'Cou
-0001e9f0: 6c64 206e 6f74 2073 6574 206c 6576 6572  ld not set lever
-0001ea00: 6167 6520 6475 6520 746f 207b 652e 5f5f  age due to {e.__
-0001ea10: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
-0001ea20: 7d2e 204d 6573 7361 6765 3a20 7b65 7d27  }. Message: {e}'
-0001ea30: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
-0001ea40: 2065 7863 6570 7420 6363 7874 2e42 6173   except ccxt.Bas
-0001ea50: 6545 7272 6f72 2061 7320 653a 0a20 2020  eError as e:.   
-0001ea60: 2020 2020 2020 2020 2072 6169 7365 204f           raise O
-0001ea70: 7065 7261 7469 6f6e 616c 4578 6365 7074  perationalExcept
-0001ea80: 696f 6e28 6529 2066 726f 6d20 650a 0a20  ion(e) from e.. 
-0001ea90: 2020 2064 6566 2067 6574 5f69 6e74 6572     def get_inter
-0001eaa0: 6573 745f 7261 7465 2873 656c 6629 202d  est_rate(self) -
-0001eab0: 3e20 666c 6f61 743a 0a20 2020 2020 2020  > float:.       
-0001eac0: 2022 2222 0a20 2020 2020 2020 2052 6574   """.        Ret
-0001ead0: 7269 6576 6520 696e 7465 7265 7374 2072  rieve interest r
-0001eae0: 6174 6520 2d20 6e65 6365 7373 6172 7920  ate - necessary 
-0001eaf0: 666f 7220 4d61 7267 696e 2074 7261 6469  for Margin tradi
-0001eb00: 6e67 2e0a 2020 2020 2020 2020 5368 6f75  ng..        Shou
-0001eb10: 6c64 206e 6f74 2063 616c 6c20 7468 6520  ld not call the 
-0001eb20: 6578 6368 616e 6765 2064 6972 6563 746c  exchange directl
-0001eb30: 7920 7768 656e 2075 7365 6420 6672 6f6d  y when used from
-0001eb40: 2062 6163 6b74 6573 7469 6e67 2e0a 2020   backtesting..  
-0001eb50: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-0001eb60: 2020 7265 7475 726e 2030 2e30 0a0a 2020    return 0.0..  
-0001eb70: 2020 6465 6620 6675 6e64 696e 675f 6665    def funding_fe
-0001eb80: 655f 6375 746f 6666 2873 656c 662c 206f  e_cutoff(self, o
-0001eb90: 7065 6e5f 6461 7465 3a20 6461 7465 7469  pen_date: dateti
-0001eba0: 6d65 2920 2d3e 2062 6f6f 6c3a 0a20 2020  me) -> bool:.   
-0001ebb0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0001ebc0: 2046 756e 6469 6e67 2066 6565 7320 6172   Funding fees ar
-0001ebd0: 6520 6f6e 6c79 2063 6861 7267 6564 2061  e only charged a
-0001ebe0: 7420 6675 6c6c 2068 6f75 7273 2028 7573  t full hours (us
-0001ebf0: 7561 6c6c 7920 6576 6572 7920 342d 3868  ually every 4-8h
-0001ec00: 292e 0a20 2020 2020 2020 2054 6865 7265  )..        There
-0001ec10: 666f 7265 2061 2074 7261 6465 206f 7065  fore a trade ope
-0001ec20: 6e69 6e67 2061 7420 3130 3a30 303a 3031  ning at 10:00:01
-0001ec30: 2077 696c 6c20 6e6f 7420 6265 2063 6861   will not be cha
-0001ec40: 7267 6564 2061 2066 756e 6469 6e67 2066  rged a funding f
-0001ec50: 6565 2075 6e74 696c 2074 6865 206e 6578  ee until the nex
-0001ec60: 7420 686f 7572 2e0a 2020 2020 2020 2020  t hour..        
-0001ec70: 3a70 6172 616d 206f 7065 6e5f 6461 7465  :param open_date
-0001ec80: 3a20 5468 6520 6f70 656e 2064 6174 6520  : The open date 
-0001ec90: 666f 7220 6120 7472 6164 650a 2020 2020  for a trade.    
-0001eca0: 2020 2020 3a72 6574 7572 6e3a 2054 7275      :return: Tru
-0001ecb0: 6520 6966 2074 6865 2064 6174 6520 6661  e if the date fa
-0001ecc0: 6c6c 7320 6f6e 2061 2066 756c 6c20 686f  lls on a full ho
-0001ecd0: 7572 2c20 4661 6c73 6520 6f74 6865 7277  ur, False otherw
-0001ece0: 6973 650a 2020 2020 2020 2020 2222 220a  ise.        """.
-0001ecf0: 2020 2020 2020 2020 7265 7475 726e 206f          return o
-0001ed00: 7065 6e5f 6461 7465 2e6d 696e 7574 6520  pen_date.minute 
-0001ed10: 3d3d 2030 2061 6e64 206f 7065 6e5f 6461  == 0 and open_da
-0001ed20: 7465 2e73 6563 6f6e 6420 3d3d 2030 0a0a  te.second == 0..
-0001ed30: 2020 2020 4072 6574 7269 6572 0a20 2020      @retrier.   
-0001ed40: 2064 6566 2073 6574 5f6d 6172 6769 6e5f   def set_margin_
-0001ed50: 6d6f 6465 2873 656c 662c 2070 6169 723a  mode(self, pair:
-0001ed60: 2073 7472 2c20 6d61 7267 696e 5f6d 6f64   str, margin_mod
-0001ed70: 653a 204d 6172 6769 6e4d 6f64 652c 2061  e: MarginMode, a
-0001ed80: 6363 6570 745f 6661 696c 3a20 626f 6f6c  ccept_fail: bool
-0001ed90: 203d 2046 616c 7365 2c0a 2020 2020 2020   = False,.      
-0001eda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001edb0: 2020 7061 7261 6d73 3a20 4f70 7469 6f6e    params: Option
-0001edc0: 616c 5b44 6963 745d 203d 204e 6f6e 6529  al[Dict] = None)
-0001edd0: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-0001ede0: 2020 2020 2020 5365 7427 7320 7468 6520        Set's the 
-0001edf0: 6d61 7267 696e 206d 6f64 6520 6f6e 2074  margin mode on t
-0001ee00: 6865 2065 7863 6861 6e67 6520 746f 2063  he exchange to c
-0001ee10: 726f 7373 206f 7220 6973 6f6c 6174 6564  ross or isolated
-0001ee20: 2066 6f72 2061 2073 7065 6369 6669 6320   for a specific 
-0001ee30: 7061 6972 0a20 2020 2020 2020 203a 7061  pair.        :pa
-0001ee40: 7261 6d20 7061 6972 3a20 6261 7365 2f71  ram pair: base/q
-0001ee50: 756f 7465 2063 7572 7265 6e63 7920 7061  uote currency pa
-0001ee60: 6972 2028 652e 672e 2022 4144 412f 5553  ir (e.g. "ADA/US
-0001ee70: 4454 2229 0a20 2020 2020 2020 2022 2222  DT").        """
-0001ee80: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-0001ee90: 2e5f 636f 6e66 6967 5b27 6472 795f 7275  ._config['dry_ru
-0001eea0: 6e27 5d20 6f72 206e 6f74 2073 656c 662e  n'] or not self.
-0001eeb0: 6578 6368 616e 6765 5f68 6173 2822 7365  exchange_has("se
-0001eec0: 744d 6172 6769 6e4d 6f64 6522 293a 0a20  tMarginMode"):. 
-0001eed0: 2020 2020 2020 2020 2020 2023 2053 6f6d             # Som
-0001eee0: 6520 6578 6368 616e 6765 7320 6f6e 6c79  e exchanges only
-0001eef0: 2073 7570 706f 7274 206f 6e65 206d 6172   support one mar
-0001ef00: 6769 6e5f 6d6f 6465 2074 7970 650a 2020  gin_mode type.  
-0001ef10: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0001ef20: 0a0a 2020 2020 2020 2020 6966 2070 6172  ..        if par
-0001ef30: 616d 7320 6973 204e 6f6e 653a 0a20 2020  ams is None:.   
-0001ef40: 2020 2020 2020 2020 2070 6172 616d 7320           params 
-0001ef50: 3d20 7b7d 0a20 2020 2020 2020 2074 7279  = {}.        try
-0001ef60: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-0001ef70: 7320 3d20 7365 6c66 2e5f 6170 692e 7365  s = self._api.se
-0001ef80: 745f 6d61 7267 696e 5f6d 6f64 6528 6d61  t_margin_mode(ma
-0001ef90: 7267 696e 5f6d 6f64 652e 7661 6c75 652c  rgin_mode.value,
-0001efa0: 2070 6169 722c 2070 6172 616d 7329 0a20   pair, params). 
-0001efb0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0001efc0: 5f6c 6f67 5f65 7863 6861 6e67 655f 7265  _log_exchange_re
-0001efd0: 7370 6f6e 7365 2827 7365 745f 6d61 7267  sponse('set_marg
-0001efe0: 696e 5f6d 6f64 6527 2c20 7265 7329 0a20  in_mode', res). 
-0001eff0: 2020 2020 2020 2065 7863 6570 7420 6363         except cc
-0001f000: 7874 2e44 446f 5350 726f 7465 6374 696f  xt.DDoSProtectio
-0001f010: 6e20 6173 2065 3a0a 2020 2020 2020 2020  n as e:.        
-0001f020: 2020 2020 7261 6973 6520 4444 6f73 5072      raise DDosPr
-0001f030: 6f74 6563 7469 6f6e 2865 2920 6672 6f6d  otection(e) from
-0001f040: 2065 0a20 2020 2020 2020 2065 7863 6570   e.        excep
-0001f050: 7420 2863 6378 742e 4261 6452 6571 7565  t (ccxt.BadReque
-0001f060: 7374 2c20 6363 7874 2e4f 7065 7261 7469  st, ccxt.Operati
-0001f070: 6f6e 5265 6a65 6374 6564 2920 6173 2065  onRejected) as e
-0001f080: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-0001f090: 206e 6f74 2061 6363 6570 745f 6661 696c   not accept_fail
-0001f0a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001f0b0: 2020 7261 6973 6520 5465 6d70 6f72 6172    raise Temporar
-0001f0c0: 7945 7272 6f72 280a 2020 2020 2020 2020  yError(.        
-0001f0d0: 2020 2020 2020 2020 2020 2020 6627 436f              f'Co
-0001f0e0: 756c 6420 6e6f 7420 7365 7420 6d61 7267  uld not set marg
-0001f0f0: 696e 206d 6f64 6520 6475 6520 746f 207b  in mode due to {
-0001f100: 652e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  e.__class__.__na
-0001f110: 6d65 5f5f 7d2e 204d 6573 7361 6765 3a20  me__}. Message: 
-0001f120: 7b65 7d27 2920 6672 6f6d 2065 0a20 2020  {e}') from e.   
-0001f130: 2020 2020 2065 7863 6570 7420 2863 6378       except (ccx
-0001f140: 742e 4f70 6572 6174 696f 6e46 6169 6c65  t.OperationFaile
-0001f150: 642c 2063 6378 742e 4578 6368 616e 6765  d, ccxt.Exchange
-0001f160: 4572 726f 7229 2061 7320 653a 0a20 2020  Error) as e:.   
-0001f170: 2020 2020 2020 2020 2072 6169 7365 2054           raise T
-0001f180: 656d 706f 7261 7279 4572 726f 7228 0a20  emporaryError(. 
-0001f190: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0001f1a0: 2743 6f75 6c64 206e 6f74 2073 6574 206d  'Could not set m
-0001f1b0: 6172 6769 6e20 6d6f 6465 2064 7565 2074  argin mode due t
-0001f1c0: 6f20 7b65 2e5f 5f63 6c61 7373 5f5f 2e5f  o {e.__class__._
-0001f1d0: 5f6e 616d 655f 5f7d 2e20 4d65 7373 6167  _name__}. Messag
-0001f1e0: 653a 207b 657d 2729 2066 726f 6d20 650a  e: {e}') from e.
-0001f1f0: 2020 2020 2020 2020 6578 6365 7074 2063          except c
-0001f200: 6378 742e 4261 7365 4572 726f 7220 6173  cxt.BaseError as
-0001f210: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-0001f220: 7261 6973 6520 4f70 6572 6174 696f 6e61  raise Operationa
-0001f230: 6c45 7863 6570 7469 6f6e 2865 2920 6672  lException(e) fr
-0001f240: 6f6d 2065 0a0a 2020 2020 6465 6620 5f66  om e..    def _f
-0001f250: 6574 6368 5f61 6e64 5f63 616c 6375 6c61  etch_and_calcula
-0001f260: 7465 5f66 756e 6469 6e67 5f66 6565 7328  te_funding_fees(
-0001f270: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
-0001f280: 2020 2020 2020 2070 6169 723a 2073 7472         pair: str
-0001f290: 2c0a 2020 2020 2020 2020 616d 6f75 6e74  ,.        amount
-0001f2a0: 3a20 666c 6f61 742c 0a20 2020 2020 2020  : float,.       
-0001f2b0: 2069 735f 7368 6f72 743a 2062 6f6f 6c2c   is_short: bool,
-0001f2c0: 0a20 2020 2020 2020 206f 7065 6e5f 6461  .        open_da
-0001f2d0: 7465 3a20 6461 7465 7469 6d65 2c0a 2020  te: datetime,.  
-0001f2e0: 2020 2020 2020 636c 6f73 655f 6461 7465        close_date
-0001f2f0: 3a20 4f70 7469 6f6e 616c 5b64 6174 6574  : Optional[datet
-0001f300: 696d 655d 203d 204e 6f6e 650a 2020 2020  ime] = None.    
-0001f310: 2920 2d3e 2066 6c6f 6174 3a0a 2020 2020  ) -> float:.    
-0001f320: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-0001f330: 4665 7463 6865 7320 616e 6420 6361 6c63  Fetches and calc
-0001f340: 756c 6174 6573 2074 6865 2073 756d 206f  ulates the sum o
-0001f350: 6620 616c 6c20 6675 6e64 696e 6720 6665  f all funding fe
-0001f360: 6573 2074 6861 7420 6f63 6375 7272 6564  es that occurred
-0001f370: 2066 6f72 2061 2070 6169 720a 2020 2020   for a pair.    
-0001f380: 2020 2020 6475 7269 6e67 2061 2066 7574      during a fut
-0001f390: 7572 6573 2074 7261 6465 2e0a 2020 2020  ures trade..    
-0001f3a0: 2020 2020 4f6e 6c79 2075 7365 6420 6475      Only used du
-0001f3b0: 7269 6e67 2064 7279 2d72 756e 206f 7220  ring dry-run or 
-0001f3c0: 6966 2074 6865 2065 7863 6861 6e67 6520  if the exchange 
-0001f3d0: 646f 6573 206e 6f74 2070 726f 7669 6465  does not provide
-0001f3e0: 2061 2066 756e 6469 6e67 5f72 6174 6573   a funding_rates
-0001f3f0: 2065 6e64 706f 696e 742e 0a20 2020 2020   endpoint..     
-0001f400: 2020 203a 7061 7261 6d20 7061 6972 3a20     :param pair: 
-0001f410: 5468 6520 7175 6f74 652f 6261 7365 2070  The quote/base p
-0001f420: 6169 7220 6f66 2074 6865 2074 7261 6465  air of the trade
-0001f430: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0001f440: 616d 6f75 6e74 3a20 5468 6520 7175 616e  amount: The quan
-0001f450: 7469 7479 206f 6620 7468 6520 7472 6164  tity of the trad
-0001f460: 650a 2020 2020 2020 2020 3a70 6172 616d  e.        :param
-0001f470: 2069 735f 7368 6f72 743a 2074 7261 6465   is_short: trade
-0001f480: 2064 6972 6563 7469 6f6e 0a20 2020 2020   direction.     
-0001f490: 2020 203a 7061 7261 6d20 6f70 656e 5f64     :param open_d
-0001f4a0: 6174 653a 2054 6865 2064 6174 6520 616e  ate: The date an
-0001f4b0: 6420 7469 6d65 2074 6861 7420 7468 6520  d time that the 
-0001f4c0: 7472 6164 6520 7374 6172 7465 640a 2020  trade started.  
-0001f4d0: 2020 2020 2020 3a70 6172 616d 2063 6c6f        :param clo
-0001f4e0: 7365 5f64 6174 653a 2054 6865 2064 6174  se_date: The dat
-0001f4f0: 6520 616e 6420 7469 6d65 2074 6861 7420  e and time that 
-0001f500: 7468 6520 7472 6164 6520 656e 6465 640a  the trade ended.
-0001f510: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
-0001f520: 2020 2020 2069 6620 7365 6c66 2e66 756e       if self.fun
-0001f530: 6469 6e67 5f66 6565 5f63 7574 6f66 6628  ding_fee_cutoff(
-0001f540: 6f70 656e 5f64 6174 6529 3a0a 2020 2020  open_date):.    
-0001f550: 2020 2020 2020 2020 2320 5368 6966 7420          # Shift 
-0001f560: 6261 636b 2074 6f20 3168 2063 616e 646c  back to 1h candl
-0001f570: 6520 746f 2061 766f 6964 206d 6973 7369  e to avoid missi
-0001f580: 6e67 2066 756e 6469 6e67 2066 6565 730a  ng funding fees.
-0001f590: 2020 2020 2020 2020 2020 2020 2320 4f6e              # On
-0001f5a0: 6c79 2072 6561 6c6c 7920 7265 6c65 7661  ly really releva
-0001f5b0: 6e74 2066 6f72 2074 7261 6465 7320 7665  nt for trades ve
-0001f5c0: 7279 2063 6c6f 7365 2074 6f20 7468 6520  ry close to the 
-0001f5d0: 6675 6c6c 2068 6f75 720a 2020 2020 2020  full hour.      
-0001f5e0: 2020 2020 2020 6f70 656e 5f64 6174 6520        open_date 
-0001f5f0: 3d20 7469 6d65 6672 616d 655f 746f 5f70  = timeframe_to_p
-0001f600: 7265 765f 6461 7465 2827 3168 272c 206f  rev_date('1h', o
-0001f610: 7065 6e5f 6461 7465 290a 2020 2020 2020  pen_date).      
-0001f620: 2020 7469 6d65 6672 616d 6520 3d20 7365    timeframe = se
-0001f630: 6c66 2e5f 6674 5f68 6173 5b27 6d61 726b  lf._ft_has['mark
-0001f640: 5f6f 686c 6376 5f74 696d 6566 7261 6d65  _ohlcv_timeframe
-0001f650: 275d 0a20 2020 2020 2020 2074 696d 6566  '].        timef
-0001f660: 7261 6d65 5f66 6620 3d20 7365 6c66 2e5f  rame_ff = self._
-0001f670: 6674 5f68 6173 5b27 6675 6e64 696e 675f  ft_has['funding_
-0001f680: 6665 655f 7469 6d65 6672 616d 6527 5d0a  fee_timeframe'].
-0001f690: 2020 2020 2020 2020 6d61 726b 5f70 7269          mark_pri
-0001f6a0: 6365 5f74 7970 6520 3d20 4361 6e64 6c65  ce_type = Candle
-0001f6b0: 5479 7065 2e66 726f 6d5f 7374 7269 6e67  Type.from_string
-0001f6c0: 2873 656c 662e 5f66 745f 6861 735b 226d  (self._ft_has["m
-0001f6d0: 6172 6b5f 6f68 6c63 765f 7072 6963 6522  ark_ohlcv_price"
-0001f6e0: 5d29 0a0a 2020 2020 2020 2020 6966 206e  ])..        if n
-0001f6f0: 6f74 2063 6c6f 7365 5f64 6174 653a 0a20  ot close_date:. 
-0001f700: 2020 2020 2020 2020 2020 2063 6c6f 7365             close
-0001f710: 5f64 6174 6520 3d20 6461 7465 7469 6d65  _date = datetime
-0001f720: 2e6e 6f77 2874 696d 657a 6f6e 652e 7574  .now(timezone.ut
-0001f730: 6329 0a20 2020 2020 2020 2073 696e 6365  c).        since
-0001f740: 5f6d 7320 3d20 6474 5f74 7328 7469 6d65  _ms = dt_ts(time
-0001f750: 6672 616d 655f 746f 5f70 7265 765f 6461  frame_to_prev_da
-0001f760: 7465 2874 696d 6566 7261 6d65 2c20 6f70  te(timeframe, op
-0001f770: 656e 5f64 6174 6529 290a 0a20 2020 2020  en_date))..     
-0001f780: 2020 206d 6172 6b5f 636f 6d62 3a20 5061     mark_comb: Pa
-0001f790: 6972 5769 7468 5469 6d65 6672 616d 6520  irWithTimeframe 
-0001f7a0: 3d20 2870 6169 722c 2074 696d 6566 7261  = (pair, timefra
-0001f7b0: 6d65 2c20 6d61 726b 5f70 7269 6365 5f74  me, mark_price_t
-0001f7c0: 7970 6529 0a20 2020 2020 2020 2066 756e  ype).        fun
-0001f7d0: 6469 6e67 5f63 6f6d 623a 2050 6169 7257  ding_comb: PairW
-0001f7e0: 6974 6854 696d 6566 7261 6d65 203d 2028  ithTimeframe = (
-0001f7f0: 7061 6972 2c20 7469 6d65 6672 616d 655f  pair, timeframe_
-0001f800: 6666 2c20 4361 6e64 6c65 5479 7065 2e46  ff, CandleType.F
-0001f810: 554e 4449 4e47 5f52 4154 4529 0a0a 2020  UNDING_RATE)..  
-0001f820: 2020 2020 2020 6361 6e64 6c65 5f68 6973        candle_his
-0001f830: 746f 7269 6573 203d 2073 656c 662e 7265  tories = self.re
-0001f840: 6672 6573 685f 6c61 7465 7374 5f6f 686c  fresh_latest_ohl
-0001f850: 6376 280a 2020 2020 2020 2020 2020 2020  cv(.            
-0001f860: 5b6d 6172 6b5f 636f 6d62 2c20 6675 6e64  [mark_comb, fund
-0001f870: 696e 675f 636f 6d62 5d2c 0a20 2020 2020  ing_comb],.     
-0001f880: 2020 2020 2020 2073 696e 6365 5f6d 733d         since_ms=
-0001f890: 7369 6e63 655f 6d73 2c0a 2020 2020 2020  since_ms,.      
-0001f8a0: 2020 2020 2020 6361 6368 653d 4661 6c73        cache=Fals
-0001f8b0: 652c 0a20 2020 2020 2020 2020 2020 2064  e,.            d
-0001f8c0: 726f 705f 696e 636f 6d70 6c65 7465 3d46  rop_incomplete=F
-0001f8d0: 616c 7365 2c0a 2020 2020 2020 2020 290a  alse,.        ).
-0001f8e0: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
-0001f8f0: 2020 2020 2020 2020 2023 2077 6520 6361           # we ca
-0001f900: 6e27 7420 6173 7375 6d65 2077 6520 616c  n't assume we al
-0001f910: 7761 7973 2067 6574 2068 6973 746f 7269  ways get histori
-0001f920: 6573 202d 2066 6f72 2065 7861 6d70 6c65  es - for example
-0001f930: 2064 7572 696e 6720 6578 6368 616e 6765   during exchange
-0001f940: 2064 6f77 6e74 696d 6573 0a20 2020 2020   downtimes.     
-0001f950: 2020 2020 2020 2066 756e 6469 6e67 5f72         funding_r
-0001f960: 6174 6573 203d 2063 616e 646c 655f 6869  ates = candle_hi
-0001f970: 7374 6f72 6965 735b 6675 6e64 696e 675f  stories[funding_
-0001f980: 636f 6d62 5d0a 2020 2020 2020 2020 2020  comb].          
-0001f990: 2020 6d61 726b 5f72 6174 6573 203d 2063    mark_rates = c
-0001f9a0: 616e 646c 655f 6869 7374 6f72 6965 735b  andle_histories[
-0001f9b0: 6d61 726b 5f63 6f6d 625d 0a20 2020 2020  mark_comb].     
-0001f9c0: 2020 2065 7863 6570 7420 4b65 7945 7272     except KeyErr
-0001f9d0: 6f72 3a0a 2020 2020 2020 2020 2020 2020  or:.            
-0001f9e0: 7261 6973 6520 4578 6368 616e 6765 4572  raise ExchangeEr
-0001f9f0: 726f 7228 2243 6f75 6c64 206e 6f74 2066  ror("Could not f
-0001fa00: 696e 6420 6675 6e64 696e 6720 7261 7465  ind funding rate
-0001fa10: 732e 2229 2066 726f 6d20 4e6f 6e65 0a0a  s.") from None..
-0001fa20: 2020 2020 2020 2020 6675 6e64 696e 675f          funding_
-0001fa30: 6d61 726b 5f72 6174 6573 203d 2073 656c  mark_rates = sel
-0001fa40: 662e 636f 6d62 696e 655f 6675 6e64 696e  f.combine_fundin
-0001fa50: 675f 616e 645f 6d61 726b 2866 756e 6469  g_and_mark(fundi
-0001fa60: 6e67 5f72 6174 6573 2c20 6d61 726b 5f72  ng_rates, mark_r
-0001fa70: 6174 6573 290a 0a20 2020 2020 2020 2072  ates)..        r
-0001fa80: 6574 7572 6e20 7365 6c66 2e63 616c 6375  eturn self.calcu
-0001fa90: 6c61 7465 5f66 756e 6469 6e67 5f66 6565  late_funding_fee
-0001faa0: 7328 0a20 2020 2020 2020 2020 2020 2066  s(.            f
-0001fab0: 756e 6469 6e67 5f6d 6172 6b5f 7261 7465  unding_mark_rate
-0001fac0: 732c 0a20 2020 2020 2020 2020 2020 2061  s,.            a
-0001fad0: 6d6f 756e 743d 616d 6f75 6e74 2c0a 2020  mount=amount,.  
-0001fae0: 2020 2020 2020 2020 2020 6973 5f73 686f            is_sho
-0001faf0: 7274 3d69 735f 7368 6f72 742c 0a20 2020  rt=is_short,.   
-0001fb00: 2020 2020 2020 2020 206f 7065 6e5f 6461           open_da
-0001fb10: 7465 3d6f 7065 6e5f 6461 7465 2c0a 2020  te=open_date,.  
-0001fb20: 2020 2020 2020 2020 2020 636c 6f73 655f            close_
-0001fb30: 6461 7465 3d63 6c6f 7365 5f64 6174 650a  date=close_date.
-0001fb40: 2020 2020 2020 2020 290a 0a20 2020 2040          )..    @
-0001fb50: 7374 6174 6963 6d65 7468 6f64 0a20 2020  staticmethod.   
-0001fb60: 2064 6566 2063 6f6d 6269 6e65 5f66 756e   def combine_fun
-0001fb70: 6469 6e67 5f61 6e64 5f6d 6172 6b28 6675  ding_and_mark(fu
-0001fb80: 6e64 696e 675f 7261 7465 733a 2044 6174  nding_rates: Dat
-0001fb90: 6146 7261 6d65 2c20 6d61 726b 5f72 6174  aFrame, mark_rat
-0001fba0: 6573 3a20 4461 7461 4672 616d 652c 0a20  es: DataFrame,. 
-0001fbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001fbc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001fbd0: 6675 7475 7265 735f 6675 6e64 696e 675f  futures_funding_
-0001fbe0: 7261 7465 3a20 4f70 7469 6f6e 616c 5b69  rate: Optional[i
-0001fbf0: 6e74 5d20 3d20 4e6f 6e65 2920 2d3e 2044  nt] = None) -> D
-0001fc00: 6174 6146 7261 6d65 3a0a 2020 2020 2020  ataFrame:.      
-0001fc10: 2020 2222 220a 2020 2020 2020 2020 436f    """.        Co
-0001fc20: 6d62 696e 6520 6675 6e64 696e 672d 7261  mbine funding-ra
-0001fc30: 7465 7320 616e 6420 6d61 726b 2d72 6174  tes and mark-rat
-0001fc40: 6573 2064 6174 6166 7261 6d65 730a 2020  es dataframes.  
-0001fc50: 2020 2020 2020 3a70 6172 616d 2066 756e        :param fun
-0001fc60: 6469 6e67 5f72 6174 6573 3a20 4461 7461  ding_rates: Data
-0001fc70: 6672 616d 6520 636f 6e74 6169 6e69 6e67  frame containing
-0001fc80: 2046 756e 6469 6e67 2072 6174 6573 2028   Funding rates (
-0001fc90: 5479 7065 2046 554e 4449 4e47 5f52 4154  Type FUNDING_RAT
-0001fca0: 4529 0a20 2020 2020 2020 203a 7061 7261  E).        :para
-0001fcb0: 6d20 6d61 726b 5f72 6174 6573 3a20 4461  m mark_rates: Da
-0001fcc0: 7461 6672 616d 6520 636f 6e74 6169 6e69  taframe containi
-0001fcd0: 6e67 204d 6172 6b20 7261 7465 7320 2854  ng Mark rates (T
-0001fce0: 7970 6520 6d61 726b 5f6f 686c 6376 5f70  ype mark_ohlcv_p
-0001fcf0: 7269 6365 290a 2020 2020 2020 2020 3a70  rice).        :p
-0001fd00: 6172 616d 2066 7574 7572 6573 5f66 756e  aram futures_fun
-0001fd10: 6469 6e67 5f72 6174 653a 2046 616b 6520  ding_rate: Fake 
-0001fd20: 6675 6e64 696e 6720 7261 7465 2074 6f20  funding rate to 
-0001fd30: 7573 6520 6966 2066 756e 6469 6e67 5f72  use if funding_r
-0001fd40: 6174 6573 2061 7265 206e 6f74 2061 7661  ates are not ava
-0001fd50: 696c 6162 6c65 0a20 2020 2020 2020 2022  ilable.        "
-0001fd60: 2222 0a20 2020 2020 2020 2069 6620 6675  "".        if fu
-0001fd70: 7475 7265 735f 6675 6e64 696e 675f 7261  tures_funding_ra
-0001fd80: 7465 2069 7320 4e6f 6e65 3a0a 2020 2020  te is None:.    
-0001fd90: 2020 2020 2020 2020 7265 7475 726e 206d          return m
-0001fda0: 6172 6b5f 7261 7465 732e 6d65 7267 6528  ark_rates.merge(
-0001fdb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001fdc0: 2066 756e 6469 6e67 5f72 6174 6573 2c20   funding_rates, 
-0001fdd0: 6f6e 3d27 6461 7465 272c 2068 6f77 3d22  on='date', how="
-0001fde0: 696e 6e65 7222 2c20 7375 6666 6978 6573  inner", suffixes
-0001fdf0: 3d5b 225f 6d61 726b 222c 2022 5f66 756e  =["_mark", "_fun
-0001fe00: 6422 5d29 0a20 2020 2020 2020 2065 6c73  d"]).        els
-0001fe10: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
-0001fe20: 6620 6c65 6e28 6675 6e64 696e 675f 7261  f len(funding_ra
-0001fe30: 7465 7329 203d 3d20 303a 0a20 2020 2020  tes) == 0:.     
-0001fe40: 2020 2020 2020 2020 2020 2023 204e 6f20             # No 
-0001fe50: 6675 6e64 696e 6720 7261 7465 2063 616e  funding rate can
-0001fe60: 646c 6573 202d 2066 756c 6c20 6669 6c6c  dles - full fill
-0001fe70: 7570 2077 6974 6820 6661 6c6c 6261 636b  up with fallback
-0001fe80: 2076 6172 6961 626c 650a 2020 2020 2020   variable.      
-0001fe90: 2020 2020 2020 2020 2020 6d61 726b 5f72            mark_r
-0001fea0: 6174 6573 5b27 6f70 656e 5f66 756e 6427  ates['open_fund'
-0001feb0: 5d20 3d20 6675 7475 7265 735f 6675 6e64  ] = futures_fund
-0001fec0: 696e 675f 7261 7465 0a20 2020 2020 2020  ing_rate.       
-0001fed0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0001fee0: 6d61 726b 5f72 6174 6573 2e72 656e 616d  mark_rates.renam
-0001fef0: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
-0001ff00: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
-0001ff10: 6e73 3d7b 276f 7065 6e27 3a20 276f 7065  ns={'open': 'ope
-0001ff20: 6e5f 6d61 726b 272c 0a20 2020 2020 2020  n_mark',.       
-0001ff30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ff40: 2020 2020 2020 2020 2020 2763 6c6f 7365            'close
-0001ff50: 273a 2027 636c 6f73 655f 6d61 726b 272c  ': 'close_mark',
-0001ff60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001ff70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ff80: 2020 2768 6967 6827 3a20 2768 6967 685f    'high': 'high_
-0001ff90: 6d61 726b 272c 0a20 2020 2020 2020 2020  mark',.         
-0001ffa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ffb0: 2020 2020 2020 2020 276c 6f77 273a 2027          'low': '
-0001ffc0: 6c6f 775f 6d61 726b 272c 0a20 2020 2020  low_mark',.     
-0001ffd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ffe0: 2020 2020 2020 2020 2020 2020 2776 6f6c              'vol
-0001fff0: 756d 6527 3a20 2776 6f6c 756d 655f 6d61  ume': 'volume_ma
-00020000: 726b 277d 290a 0a20 2020 2020 2020 2020  rk'})..         
-00020010: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00020020: 2020 2020 2020 2020 2023 2046 696c 6c20           # Fill 
-00020030: 7570 206d 6973 7369 6e67 2066 756e 6469  up missing fundi
-00020040: 6e67 5f72 6174 6520 6361 6e64 6c65 7320  ng_rate candles 
-00020050: 7769 7468 2066 616c 6c62 6163 6b20 7661  with fallback va
-00020060: 6c75 650a 2020 2020 2020 2020 2020 2020  lue.            
-00020070: 2020 2020 636f 6d62 696e 6564 203d 206d      combined = m
-00020080: 6172 6b5f 7261 7465 732e 6d65 7267 6528  ark_rates.merge(
-00020090: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000200a0: 2020 2020 2066 756e 6469 6e67 5f72 6174       funding_rat
-000200b0: 6573 2c20 6f6e 3d27 6461 7465 272c 2068  es, on='date', h
-000200c0: 6f77 3d22 6c65 6674 222c 2073 7566 6669  ow="left", suffi
-000200d0: 7865 733d 5b22 5f6d 6172 6b22 2c20 225f  xes=["_mark", "_
-000200e0: 6675 6e64 225d 0a20 2020 2020 2020 2020  fund"].         
-000200f0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
-00020100: 2020 2020 2020 2020 2020 2020 2063 6f6d               com
-00020110: 6269 6e65 645b 276f 7065 6e5f 6675 6e64  bined['open_fund
-00020120: 275d 203d 2063 6f6d 6269 6e65 645b 276f  '] = combined['o
-00020130: 7065 6e5f 6675 6e64 275d 2e66 696c 6c6e  pen_fund'].filln
-00020140: 6128 6675 7475 7265 735f 6675 6e64 696e  a(futures_fundin
-00020150: 675f 7261 7465 290a 2020 2020 2020 2020  g_rate).        
-00020160: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00020170: 6f6d 6269 6e65 640a 0a20 2020 2064 6566  ombined..    def
-00020180: 2063 616c 6375 6c61 7465 5f66 756e 6469   calculate_fundi
-00020190: 6e67 5f66 6565 7328 0a20 2020 2020 2020  ng_fees(.       
-000201a0: 2073 656c 662c 0a20 2020 2020 2020 2064   self,.        d
-000201b0: 663a 2044 6174 6146 7261 6d65 2c0a 2020  f: DataFrame,.  
-000201c0: 2020 2020 2020 616d 6f75 6e74 3a20 666c        amount: fl
-000201d0: 6f61 742c 0a20 2020 2020 2020 2069 735f  oat,.        is_
-000201e0: 7368 6f72 743a 2062 6f6f 6c2c 0a20 2020  short: bool,.   
-000201f0: 2020 2020 206f 7065 6e5f 6461 7465 3a20       open_date: 
-00020200: 6461 7465 7469 6d65 2c0a 2020 2020 2020  datetime,.      
-00020210: 2020 636c 6f73 655f 6461 7465 3a20 6461    close_date: da
-00020220: 7465 7469 6d65 2c0a 2020 2020 2020 2020  tetime,.        
-00020230: 7469 6d65 5f69 6e5f 7261 7469 6f3a 204f  time_in_ratio: O
-00020240: 7074 696f 6e61 6c5b 666c 6f61 745d 203d  ptional[float] =
-00020250: 204e 6f6e 650a 2020 2020 2920 2d3e 2066   None.    ) -> f
-00020260: 6c6f 6174 3a0a 2020 2020 2020 2020 2222  loat:.        ""
-00020270: 220a 2020 2020 2020 2020 6361 6c63 756c  ".        calcul
-00020280: 6174 6573 2074 6865 2073 756d 206f 6620  ates the sum of 
-00020290: 616c 6c20 6675 6e64 696e 6720 6665 6573  all funding fees
-000202a0: 2074 6861 7420 6f63 6375 7272 6564 2066   that occurred f
-000202b0: 6f72 2061 2070 6169 7220 6475 7269 6e67  or a pair during
-000202c0: 2061 2066 7574 7572 6573 2074 7261 6465   a futures trade
-000202d0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-000202e0: 6466 3a20 4461 7461 6672 616d 6520 636f  df: Dataframe co
-000202f0: 6e74 6169 6e69 6e67 2063 6f6d 6269 6e65  ntaining combine
-00020300: 6420 6675 6e64 696e 6720 616e 6420 6d61  d funding and ma
-00020310: 726b 2072 6174 6573 0a20 2020 2020 2020  rk rates.       
-00020320: 2020 2020 2020 2020 2020 2020 6173 2060              as `
-00020330: 6f70 656e 5f66 756e 6460 2061 6e64 2060  open_fund` and `
-00020340: 6f70 656e 5f6d 6172 6b60 2e0a 2020 2020  open_mark`..    
-00020350: 2020 2020 3a70 6172 616d 2061 6d6f 756e      :param amoun
-00020360: 743a 2054 6865 2071 7561 6e74 6974 7920  t: The quantity 
-00020370: 6f66 2074 6865 2074 7261 6465 0a20 2020  of the trade.   
-00020380: 2020 2020 203a 7061 7261 6d20 6973 5f73       :param is_s
-00020390: 686f 7274 3a20 7472 6164 6520 6469 7265  hort: trade dire
-000203a0: 6374 696f 6e0a 2020 2020 2020 2020 3a70  ction.        :p
-000203b0: 6172 616d 206f 7065 6e5f 6461 7465 3a20  aram open_date: 
-000203c0: 5468 6520 6461 7465 2061 6e64 2074 696d  The date and tim
-000203d0: 6520 7468 6174 2074 6865 2074 7261 6465  e that the trade
-000203e0: 2073 7461 7274 6564 0a20 2020 2020 2020   started.       
-000203f0: 203a 7061 7261 6d20 636c 6f73 655f 6461   :param close_da
-00020400: 7465 3a20 5468 6520 6461 7465 2061 6e64  te: The date and
-00020410: 2074 696d 6520 7468 6174 2074 6865 2074   time that the t
-00020420: 7261 6465 2065 6e64 6564 0a20 2020 2020  rade ended.     
-00020430: 2020 203a 7061 7261 6d20 7469 6d65 5f69     :param time_i
-00020440: 6e5f 7261 7469 6f3a 204e 6f74 2075 7365  n_ratio: Not use
-00020450: 6420 6279 206d 6f73 7420 6578 6368 616e  d by most exchan
-00020460: 6765 2063 6c61 7373 6573 0a20 2020 2020  ge classes.     
-00020470: 2020 2022 2222 0a20 2020 2020 2020 2066     """.        f
-00020480: 6565 733a 2066 6c6f 6174 203d 2030 0a0a  ees: float = 0..
-00020490: 2020 2020 2020 2020 6966 206e 6f74 2064          if not d
-000204a0: 662e 656d 7074 793a 0a20 2020 2020 2020  f.empty:.       
-000204b0: 2020 2020 2064 6631 203d 2064 665b 2864       df1 = df[(d
-000204c0: 665b 2764 6174 6527 5d20 3e3d 206f 7065  f['date'] >= ope
-000204d0: 6e5f 6461 7465 2920 2620 2864 665b 2764  n_date) & (df['d
-000204e0: 6174 6527 5d20 3c3d 2063 6c6f 7365 5f64  ate'] <= close_d
-000204f0: 6174 6529 5d0a 2020 2020 2020 2020 2020  ate)].          
-00020500: 2020 6665 6573 203d 2073 756d 2864 6631    fees = sum(df1
-00020510: 5b27 6f70 656e 5f66 756e 6427 5d20 2a20  ['open_fund'] * 
-00020520: 6466 315b 276f 7065 6e5f 6d61 726b 275d  df1['open_mark']
-00020530: 202a 2061 6d6f 756e 7429 0a20 2020 2020   * amount).     
-00020540: 2020 2069 6620 6973 6e61 6e28 6665 6573     if isnan(fees
-00020550: 293a 0a20 2020 2020 2020 2020 2020 2066  ):.            f
-00020560: 6565 7320 3d20 302e 300a 2020 2020 2020  ees = 0.0.      
-00020570: 2020 2320 4e65 6761 7465 2066 6565 7320    # Negate fees 
-00020580: 666f 7220 6c6f 6e67 7320 6173 2066 756e  for longs as fun
-00020590: 6469 6e67 5f66 6565 7320 6578 7065 6374  ding_fees expect
-000205a0: 7320 6974 2074 6869 7320 7761 7920 6261  s it this way ba
-000205b0: 7365 6420 6f6e 206c 6976 6520 656e 6470  sed on live endp
-000205c0: 6f69 6e74 732e 0a20 2020 2020 2020 2072  oints..        r
-000205d0: 6574 7572 6e20 6665 6573 2069 6620 6973  eturn fees if is
-000205e0: 5f73 686f 7274 2065 6c73 6520 2d66 6565  _short else -fee
-000205f0: 730a 0a20 2020 2064 6566 2067 6574 5f66  s..    def get_f
-00020600: 756e 6469 6e67 5f66 6565 7328 0a20 2020  unding_fees(.   
-00020610: 2020 2020 2020 2020 2073 656c 662c 2070           self, p
-00020620: 6169 723a 2073 7472 2c20 616d 6f75 6e74  air: str, amount
-00020630: 3a20 666c 6f61 742c 2069 735f 7368 6f72  : float, is_shor
-00020640: 743a 2062 6f6f 6c2c 206f 7065 6e5f 6461  t: bool, open_da
-00020650: 7465 3a20 6461 7465 7469 6d65 2920 2d3e  te: datetime) ->
-00020660: 2066 6c6f 6174 3a0a 2020 2020 2020 2020   float:.        
-00020670: 2222 220a 2020 2020 2020 2020 4665 7463  """.        Fetc
-00020680: 6820 6675 6e64 696e 6720 6665 6573 2c20  h funding fees, 
-00020690: 6569 7468 6572 2066 726f 6d20 7468 6520  either from the 
-000206a0: 6578 6368 616e 6765 2028 6c69 7665 2920  exchange (live) 
-000206b0: 6f72 2063 616c 6375 6c61 7465 7320 7468  or calculates th
-000206c0: 656d 0a20 2020 2020 2020 2062 6173 6564  em.        based
-000206d0: 206f 6e20 6675 6e64 696e 6720 7261 7465   on funding rate
-000206e0: 2f6d 6172 6b20 7072 6963 6520 6869 7374  /mark price hist
-000206f0: 6f72 790a 2020 2020 2020 2020 3a70 6172  ory.        :par
-00020700: 616d 2070 6169 723a 2054 6865 2071 756f  am pair: The quo
-00020710: 7465 2f62 6173 6520 7061 6972 206f 6620  te/base pair of 
-00020720: 7468 6520 7472 6164 650a 2020 2020 2020  the trade.      
-00020730: 2020 3a70 6172 616d 2069 735f 7368 6f72    :param is_shor
-00020740: 743a 2074 7261 6465 2064 6972 6563 7469  t: trade directi
-00020750: 6f6e 0a20 2020 2020 2020 203a 7061 7261  on.        :para
-00020760: 6d20 616d 6f75 6e74 3a20 5472 6164 6520  m amount: Trade 
-00020770: 616d 6f75 6e74 0a20 2020 2020 2020 203a  amount.        :
-00020780: 7061 7261 6d20 6f70 656e 5f64 6174 653a  param open_date:
-00020790: 204f 7065 6e20 6461 7465 206f 6620 7468   Open date of th
-000207a0: 6520 7472 6164 650a 2020 2020 2020 2020  e trade.        
-000207b0: 3a72 6574 7572 6e3a 2066 756e 6469 6e67  :return: funding
-000207c0: 2066 6565 2073 696e 6365 206f 7065 6e5f   fee since open_
-000207d0: 6461 7465 0a20 2020 2020 2020 2022 2222  date.        """
-000207e0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-000207f0: 2e74 7261 6469 6e67 5f6d 6f64 6520 3d3d  .trading_mode ==
-00020800: 2054 7261 6469 6e67 4d6f 6465 2e46 5554   TradingMode.FUT
-00020810: 5552 4553 3a0a 2020 2020 2020 2020 2020  URES:.          
-00020820: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
-00020830: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
-00020840: 636f 6e66 6967 5b27 6472 795f 7275 6e27  config['dry_run'
-00020850: 5d3a 0a20 2020 2020 2020 2020 2020 2020  ]:.             
-00020860: 2020 2020 2020 2066 756e 6469 6e67 5f66         funding_f
-00020870: 6565 7320 3d20 7365 6c66 2e5f 6665 7463  ees = self._fetc
-00020880: 685f 616e 645f 6361 6c63 756c 6174 655f  h_and_calculate_
-00020890: 6675 6e64 696e 675f 6665 6573 280a 2020  funding_fees(.  
-000208a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000208b0: 2020 2020 2020 7061 6972 2c20 616d 6f75        pair, amou
-000208c0: 6e74 2c20 6973 5f73 686f 7274 2c20 6f70  nt, is_short, op
-000208d0: 656e 5f64 6174 6529 0a20 2020 2020 2020  en_date).       
-000208e0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-000208f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020900: 2020 2066 756e 6469 6e67 5f66 6565 7320     funding_fees 
-00020910: 3d20 7365 6c66 2e5f 6765 745f 6675 6e64  = self._get_fund
-00020920: 696e 675f 6665 6573 5f66 726f 6d5f 6578  ing_fees_from_ex
-00020930: 6368 616e 6765 2870 6169 722c 206f 7065  change(pair, ope
-00020940: 6e5f 6461 7465 290a 2020 2020 2020 2020  n_date).        
-00020950: 2020 2020 2020 2020 7265 7475 726e 2066          return f
-00020960: 756e 6469 6e67 5f66 6565 730a 2020 2020  unding_fees.    
-00020970: 2020 2020 2020 2020 6578 6365 7074 2045          except E
-00020980: 7863 6861 6e67 6545 7272 6f72 3a0a 2020  xchangeError:.  
-00020990: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-000209a0: 6767 6572 2e77 6172 6e69 6e67 2866 2243  gger.warning(f"C
-000209b0: 6f75 6c64 206e 6f74 2075 7064 6174 6520  ould not update 
-000209c0: 6675 6e64 696e 6720 6665 6573 2066 6f72  funding fees for
-000209d0: 207b 7061 6972 7d2e 2229 0a0a 2020 2020   {pair}.")..    
-000209e0: 2020 2020 7265 7475 726e 2030 2e30 0a0a      return 0.0..
-000209f0: 2020 2020 6465 6620 6765 745f 6c69 7175      def get_liqu
-00020a00: 6964 6174 696f 6e5f 7072 6963 6528 0a20  idation_price(. 
-00020a10: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-00020a20: 2020 2020 2070 6169 723a 2073 7472 2c0a       pair: str,.
-00020a30: 2020 2020 2020 2020 2320 4472 792d 7275          # Dry-ru
-00020a40: 6e0a 2020 2020 2020 2020 6f70 656e 5f72  n.        open_r
-00020a50: 6174 653a 2066 6c6f 6174 2c20 2020 2320  ate: float,   # 
-00020a60: 456e 7472 7920 7072 6963 6520 6f66 2070  Entry price of p
-00020a70: 6f73 6974 696f 6e0a 2020 2020 2020 2020  osition.        
-00020a80: 6973 5f73 686f 7274 3a20 626f 6f6c 2c0a  is_short: bool,.
-00020a90: 2020 2020 2020 2020 616d 6f75 6e74 3a20          amount: 
-00020aa0: 666c 6f61 742c 2020 2320 4162 736f 6c75  float,  # Absolu
-00020ab0: 7465 2076 616c 7565 206f 6620 706f 7369  te value of posi
-00020ac0: 7469 6f6e 2073 697a 650a 2020 2020 2020  tion size.      
-00020ad0: 2020 7374 616b 655f 616d 6f75 6e74 3a20    stake_amount: 
-00020ae0: 666c 6f61 742c 0a20 2020 2020 2020 206c  float,.        l
-00020af0: 6576 6572 6167 653a 2066 6c6f 6174 2c0a  everage: float,.
-00020b00: 2020 2020 2020 2020 7761 6c6c 6574 5f62          wallet_b
-00020b10: 616c 616e 6365 3a20 666c 6f61 742c 0a20  alance: float,. 
-00020b20: 2020 2020 2020 206d 6d5f 6578 5f31 3a20         mm_ex_1: 
-00020b30: 666c 6f61 7420 3d20 302e 302c 2020 2320  float = 0.0,  # 
-00020b40: 2842 696e 616e 6365 2920 4372 6f73 7320  (Binance) Cross 
-00020b50: 6f6e 6c79 0a20 2020 2020 2020 2075 706e  only.        upn
-00020b60: 6c5f 6578 5f31 3a20 666c 6f61 7420 3d20  l_ex_1: float = 
-00020b70: 302e 302c 2020 2320 2842 696e 616e 6365  0.0,  # (Binance
-00020b80: 2920 4372 6f73 7320 6f6e 6c79 0a20 2020  ) Cross only.   
-00020b90: 2029 202d 3e20 4f70 7469 6f6e 616c 5b66   ) -> Optional[f
-00020ba0: 6c6f 6174 5d3a 0a20 2020 2020 2020 2022  loat]:.        "
-00020bb0: 2222 0a20 2020 2020 2020 2053 6574 2773  "".        Set's
-00020bc0: 2074 6865 206d 6172 6769 6e20 6d6f 6465   the margin mode
-00020bd0: 206f 6e20 7468 6520 6578 6368 616e 6765   on the exchange
-00020be0: 2074 6f20 6372 6f73 7320 6f72 2069 736f   to cross or iso
-00020bf0: 6c61 7465 6420 666f 7220 6120 7370 6563  lated for a spec
-00020c00: 6966 6963 2070 6169 720a 2020 2020 2020  ific pair.      
-00020c10: 2020 2222 220a 2020 2020 2020 2020 6966    """.        if
-00020c20: 2073 656c 662e 7472 6164 696e 675f 6d6f   self.trading_mo
-00020c30: 6465 203d 3d20 5472 6164 696e 674d 6f64  de == TradingMod
-00020c40: 652e 5350 4f54 3a0a 2020 2020 2020 2020  e.SPOT:.        
-00020c50: 2020 2020 7265 7475 726e 204e 6f6e 650a      return None.
-00020c60: 2020 2020 2020 2020 656c 6966 2028 7365          elif (se
-00020c70: 6c66 2e74 7261 6469 6e67 5f6d 6f64 6520  lf.trading_mode 
-00020c80: 213d 2054 7261 6469 6e67 4d6f 6465 2e46  != TradingMode.F
-00020c90: 5554 5552 4553 293a 0a20 2020 2020 2020  UTURES):.       
-00020ca0: 2020 2020 2072 6169 7365 204f 7065 7261       raise Opera
-00020cb0: 7469 6f6e 616c 4578 6365 7074 696f 6e28  tionalException(
-00020cc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00020cd0: 2066 227b 7365 6c66 2e6e 616d 657d 2064   f"{self.name} d
-00020ce0: 6f65 7320 6e6f 7420 7375 7070 6f72 7420  oes not support 
-00020cf0: 7b73 656c 662e 6d61 7267 696e 5f6d 6f64  {self.margin_mod
-00020d00: 657d 207b 7365 6c66 2e74 7261 6469 6e67  e} {self.trading
-00020d10: 5f6d 6f64 657d 2229 0a0a 2020 2020 2020  _mode}")..      
-00020d20: 2020 6c69 7175 6964 6174 696f 6e5f 7072    liquidation_pr
-00020d30: 6963 6520 3d20 4e6f 6e65 0a20 2020 2020  ice = None.     
-00020d40: 2020 2069 6620 7365 6c66 2e5f 636f 6e66     if self._conf
-00020d50: 6967 5b27 6472 795f 7275 6e27 5d20 6f72  ig['dry_run'] or
-00020d60: 206e 6f74 2073 656c 662e 6578 6368 616e   not self.exchan
-00020d70: 6765 5f68 6173 2822 6665 7463 6850 6f73  ge_has("fetchPos
-00020d80: 6974 696f 6e73 2229 3a0a 0a20 2020 2020  itions"):..     
-00020d90: 2020 2020 2020 206c 6971 7569 6461 7469         liquidati
-00020da0: 6f6e 5f70 7269 6365 203d 2073 656c 662e  on_price = self.
-00020db0: 6472 795f 7275 6e5f 6c69 7175 6964 6174  dry_run_liquidat
-00020dc0: 696f 6e5f 7072 6963 6528 0a20 2020 2020  ion_price(.     
-00020dd0: 2020 2020 2020 2020 2020 2070 6169 723d             pair=
-00020de0: 7061 6972 2c0a 2020 2020 2020 2020 2020  pair,.          
-00020df0: 2020 2020 2020 6f70 656e 5f72 6174 653d        open_rate=
-00020e00: 6f70 656e 5f72 6174 652c 0a20 2020 2020  open_rate,.     
-00020e10: 2020 2020 2020 2020 2020 2069 735f 7368             is_sh
-00020e20: 6f72 743d 6973 5f73 686f 7274 2c0a 2020  ort=is_short,.  
-00020e30: 2020 2020 2020 2020 2020 2020 2020 616d                am
-00020e40: 6f75 6e74 3d61 6d6f 756e 742c 0a20 2020  ount=amount,.   
-00020e50: 2020 2020 2020 2020 2020 2020 206c 6576               lev
-00020e60: 6572 6167 653d 6c65 7665 7261 6765 2c0a  erage=leverage,.
-00020e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020e80: 7374 616b 655f 616d 6f75 6e74 3d73 7461  stake_amount=sta
-00020e90: 6b65 5f61 6d6f 756e 742c 0a20 2020 2020  ke_amount,.     
-00020ea0: 2020 2020 2020 2020 2020 2077 616c 6c65             walle
-00020eb0: 745f 6261 6c61 6e63 653d 7761 6c6c 6574  t_balance=wallet
-00020ec0: 5f62 616c 616e 6365 2c0a 2020 2020 2020  _balance,.      
-00020ed0: 2020 2020 2020 2020 2020 6d6d 5f65 785f            mm_ex_
-00020ee0: 313d 6d6d 5f65 785f 312c 0a20 2020 2020  1=mm_ex_1,.     
-00020ef0: 2020 2020 2020 2020 2020 2075 706e 6c5f             upnl_
-00020f00: 6578 5f31 3d75 706e 6c5f 6578 5f31 0a20  ex_1=upnl_ex_1. 
-00020f10: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
-00020f20: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00020f30: 2020 2020 2020 2070 6f73 6974 696f 6e73         positions
-00020f40: 203d 2073 656c 662e 6665 7463 685f 706f   = self.fetch_po
-00020f50: 7369 7469 6f6e 7328 7061 6972 290a 2020  sitions(pair).  
-00020f60: 2020 2020 2020 2020 2020 6966 206c 656e            if len
-00020f70: 2870 6f73 6974 696f 6e73 2920 3e20 303a  (positions) > 0:
-00020f80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00020f90: 2070 6f73 203d 2070 6f73 6974 696f 6e73   pos = positions
-00020fa0: 5b30 5d0a 2020 2020 2020 2020 2020 2020  [0].            
-00020fb0: 2020 2020 6c69 7175 6964 6174 696f 6e5f      liquidation_
-00020fc0: 7072 6963 6520 3d20 706f 735b 276c 6971  price = pos['liq
-00020fd0: 7569 6461 7469 6f6e 5072 6963 6527 5d0a  uidationPrice'].
-00020fe0: 0a20 2020 2020 2020 2069 6620 6c69 7175  .        if liqu
-00020ff0: 6964 6174 696f 6e5f 7072 6963 6520 6973  idation_price is
-00021000: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-00021010: 2020 2020 2020 2062 7566 6665 725f 616d         buffer_am
-00021020: 6f75 6e74 203d 2061 6273 286f 7065 6e5f  ount = abs(open_
-00021030: 7261 7465 202d 206c 6971 7569 6461 7469  rate - liquidati
-00021040: 6f6e 5f70 7269 6365 2920 2a20 7365 6c66  on_price) * self
-00021050: 2e6c 6971 7569 6461 7469 6f6e 5f62 7566  .liquidation_buf
-00021060: 6665 720a 2020 2020 2020 2020 2020 2020  fer.            
-00021070: 6c69 7175 6964 6174 696f 6e5f 7072 6963  liquidation_pric
-00021080: 655f 6275 6666 6572 203d 2028 0a20 2020  e_buffer = (.   
-00021090: 2020 2020 2020 2020 2020 2020 206c 6971               liq
-000210a0: 7569 6461 7469 6f6e 5f70 7269 6365 202d  uidation_price -
-000210b0: 2062 7566 6665 725f 616d 6f75 6e74 0a20   buffer_amount. 
-000210c0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-000210d0: 6620 6973 5f73 686f 7274 2065 6c73 650a  f is_short else.
-000210e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000210f0: 6c69 7175 6964 6174 696f 6e5f 7072 6963  liquidation_pric
-00021100: 6520 2b20 6275 6666 6572 5f61 6d6f 756e  e + buffer_amoun
-00021110: 740a 2020 2020 2020 2020 2020 2020 290a  t.            ).
-00021120: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00021130: 726e 206d 6178 286c 6971 7569 6461 7469  rn max(liquidati
-00021140: 6f6e 5f70 7269 6365 5f62 7566 6665 722c  on_price_buffer,
-00021150: 2030 2e30 290a 2020 2020 2020 2020 656c   0.0).        el
-00021160: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00021170: 7265 7475 726e 204e 6f6e 650a 0a20 2020  return None..   
-00021180: 2064 6566 2064 7279 5f72 756e 5f6c 6971   def dry_run_liq
-00021190: 7569 6461 7469 6f6e 5f70 7269 6365 280a  uidation_price(.
-000211a0: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-000211b0: 2020 2020 2020 7061 6972 3a20 7374 722c        pair: str,
-000211c0: 0a20 2020 2020 2020 206f 7065 6e5f 7261  .        open_ra
-000211d0: 7465 3a20 666c 6f61 742c 2020 2023 2045  te: float,   # E
-000211e0: 6e74 7279 2070 7269 6365 206f 6620 706f  ntry price of po
-000211f0: 7369 7469 6f6e 0a20 2020 2020 2020 2069  sition.        i
-00021200: 735f 7368 6f72 743a 2062 6f6f 6c2c 0a20  s_short: bool,. 
-00021210: 2020 2020 2020 2061 6d6f 756e 743a 2066         amount: f
-00021220: 6c6f 6174 2c0a 2020 2020 2020 2020 7374  loat,.        st
-00021230: 616b 655f 616d 6f75 6e74 3a20 666c 6f61  ake_amount: floa
-00021240: 742c 0a20 2020 2020 2020 206c 6576 6572  t,.        lever
-00021250: 6167 653a 2066 6c6f 6174 2c0a 2020 2020  age: float,.    
-00021260: 2020 2020 7761 6c6c 6574 5f62 616c 616e      wallet_balan
-00021270: 6365 3a20 666c 6f61 742c 2020 2320 4f72  ce: float,  # Or
-00021280: 206d 6172 6769 6e20 6261 6c61 6e63 650a   margin balance.
-00021290: 2020 2020 2020 2020 6d6d 5f65 785f 313a          mm_ex_1:
-000212a0: 2066 6c6f 6174 203d 2030 2e30 2c20 2023   float = 0.0,  #
-000212b0: 2028 4269 6e61 6e63 6529 2043 726f 7373   (Binance) Cross
-000212c0: 206f 6e6c 790a 2020 2020 2020 2020 7570   only.        up
-000212d0: 6e6c 5f65 785f 313a 2066 6c6f 6174 203d  nl_ex_1: float =
-000212e0: 2030 2e30 2c20 2023 2028 4269 6e61 6e63   0.0,  # (Binanc
-000212f0: 6529 2043 726f 7373 206f 6e6c 790a 2020  e) Cross only.  
-00021300: 2020 2920 2d3e 204f 7074 696f 6e61 6c5b    ) -> Optional[
-00021310: 666c 6f61 745d 3a0a 2020 2020 2020 2020  float]:.        
-00021320: 2222 220a 2020 2020 2020 2020 496d 706f  """.        Impo
-00021330: 7274 616e 743a 204d 7573 7420 6265 2066  rtant: Must be f
-00021340: 6574 6368 696e 6720 6461 7461 2066 726f  etching data fro
-00021350: 6d20 6361 6368 6564 2076 616c 7565 7320  m cached values 
-00021360: 6173 2074 6869 7320 6973 2075 7365 6420  as this is used 
-00021370: 6279 2062 6163 6b74 6573 7469 6e67 210a  by backtesting!.
-00021380: 2020 2020 2020 2020 5045 5250 4554 5541          PERPETUA
-00021390: 4c3a 0a20 2020 2020 2020 2020 6761 7465  L:.         gate
-000213a0: 3a20 6874 7470 733a 2f2f 7777 772e 6761  : https://www.ga
-000213b0: 7465 2e69 6f2f 6865 6c70 2f66 7574 7572  te.io/help/futur
-000213c0: 6573 2f66 7574 7572 6573 2f32 3737 3234  es/futures/27724
-000213d0: 2f6c 6971 7569 6461 7469 6f6e 2d70 7269  /liquidation-pri
-000213e0: 6365 2d62 616e 6b72 7570 7463 792d 7072  ce-bankruptcy-pr
-000213f0: 6963 650a 2020 2020 2020 2020 203e 204c  ice.         > L
-00021400: 6971 7569 6461 7469 6f6e 2050 7269 6365  iquidation Price
-00021410: 203d 2028 456e 7472 7920 5072 6963 6520   = (Entry Price 
-00021420: c2b1 204d 6172 6769 6e20 2f20 436f 6e74  .. Margin / Cont
-00021430: 7261 6374 204d 756c 7469 706c 6965 7220  ract Multiplier 
-00021440: 2f20 5369 7a65 2920 2f0a 2020 2020 2020  / Size) /.      
-00021450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021460: 2020 2020 2020 2020 2020 5b20 3120 c2b1            [ 1 ..
-00021470: 2028 4d61 696e 7465 6e61 6e63 6520 4d61   (Maintenance Ma
-00021480: 7267 696e 2052 6174 696f 202b 2054 616b  rgin Ratio + Tak
-00021490: 6572 2052 6174 6529 5d0a 2020 2020 2020  er Rate)].      
-000214a0: 2020 2020 2020 5768 6572 6569 6e2c 2022        Wherein, "
-000214b0: 2b22 206f 7220 222d 2220 6465 7065 6e64  +" or "-" depend
-000214c0: 7320 6f6e 2077 6865 7468 6572 2074 6865  s on whether the
-000214d0: 2063 6f6e 7472 6163 7420 676f 6573 206c   contract goes l
-000214e0: 6f6e 6720 6f72 2073 686f 7274 3a0a 2020  ong or short:.  
-000214f0: 2020 2020 2020 2020 2020 222d 2220 666f            "-" fo
-00021500: 7220 6c6f 6e67 2c20 616e 6420 222b 2220  r long, and "+" 
-00021510: 666f 7220 7368 6f72 742e 0a0a 2020 2020  for short...    
-00021520: 2020 2020 206f 6b65 783a 2068 7474 7073       okex: https
-00021530: 3a2f 2f77 7777 2e6f 6b65 782e 636f 6d2f  ://www.okex.com/
-00021540: 7375 7070 6f72 742f 6863 2f65 6e2d 7573  support/hc/en-us
-00021550: 2f61 7274 6963 6c65 732f 0a20 2020 2020  /articles/.     
-00021560: 2020 2020 2020 2033 3630 3035 3339 3039         360053909
-00021570: 3539 322d 5649 2d49 6e74 726f 6475 6374  592-VI-Introduct
-00021580: 696f 6e2d 746f 2d74 6865 2d69 736f 6c61  ion-to-the-isola
-00021590: 7465 642d 6d6f 6465 2d6f 662d 5369 6e67  ted-mode-of-Sing
-000215a0: 6c65 2d4d 756c 7469 2d63 7572 7265 6e63  le-Multi-currenc
-000215b0: 792d 506f 7274 666f 6c69 6f2d 6d61 7267  y-Portfolio-marg
-000215c0: 696e 0a0a 2020 2020 2020 2020 3a70 6172  in..        :par
-000215d0: 616d 2070 6169 723a 2050 6169 7220 746f  am pair: Pair to
-000215e0: 2063 616c 6375 6c61 7465 206c 6971 7569   calculate liqui
-000215f0: 6461 7469 6f6e 2070 7269 6365 2066 6f72  dation price for
-00021600: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00021610: 6f70 656e 5f72 6174 653a 2045 6e74 7279  open_rate: Entry
-00021620: 2070 7269 6365 206f 6620 706f 7369 7469   price of positi
-00021630: 6f6e 0a20 2020 2020 2020 203a 7061 7261  on.        :para
-00021640: 6d20 6973 5f73 686f 7274 3a20 5472 7565  m is_short: True
-00021650: 2069 6620 7468 6520 7472 6164 6520 6973   if the trade is
-00021660: 2061 2073 686f 7274 2c20 6661 6c73 6520   a short, false 
-00021670: 6f74 6865 7277 6973 650a 2020 2020 2020  otherwise.      
-00021680: 2020 3a70 6172 616d 2061 6d6f 756e 743a    :param amount:
-00021690: 2041 6273 6f6c 7574 6520 7661 6c75 6520   Absolute value 
-000216a0: 6f66 2070 6f73 6974 696f 6e20 7369 7a65  of position size
-000216b0: 2069 6e63 6c2e 206c 6576 6572 6167 6520   incl. leverage 
-000216c0: 2869 6e20 6261 7365 2063 7572 7265 6e63  (in base currenc
-000216d0: 7929 0a20 2020 2020 2020 203a 7061 7261  y).        :para
-000216e0: 6d20 7374 616b 655f 616d 6f75 6e74 3a20  m stake_amount: 
-000216f0: 5374 616b 6520 616d 6f75 6e74 202d 2043  Stake amount - C
-00021700: 6f6c 6c61 7465 7261 6c20 696e 2073 6574  ollateral in set
-00021710: 746c 6520 6375 7272 656e 6379 2e0a 2020  tle currency..  
-00021720: 2020 2020 2020 3a70 6172 616d 206c 6576        :param lev
-00021730: 6572 6167 653a 204c 6576 6572 6167 6520  erage: Leverage 
-00021740: 7573 6564 2066 6f72 2074 6869 7320 706f  used for this po
-00021750: 7369 7469 6f6e 2e0a 2020 2020 2020 2020  sition..        
-00021760: 3a70 6172 616d 2074 7261 6469 6e67 5f6d  :param trading_m
-00021770: 6f64 653a 2053 504f 542c 204d 4152 4749  ode: SPOT, MARGI
-00021780: 4e2c 2046 5554 5552 4553 2c20 6574 632e  N, FUTURES, etc.
-00021790: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-000217a0: 6d61 7267 696e 5f6d 6f64 653a 2045 6974  margin_mode: Eit
-000217b0: 6865 7220 4953 4f4c 4154 4544 206f 7220  her ISOLATED or 
-000217c0: 4352 4f53 530a 2020 2020 2020 2020 3a70  CROSS.        :p
-000217d0: 6172 616d 2077 616c 6c65 745f 6261 6c61  aram wallet_bala
-000217e0: 6e63 653a 2041 6d6f 756e 7420 6f66 206d  nce: Amount of m
-000217f0: 6172 6769 6e5f 6d6f 6465 2069 6e20 7468  argin_mode in th
-00021800: 6520 7761 6c6c 6574 2062 6569 6e67 2075  e wallet being u
-00021810: 7365 6420 746f 2074 7261 6465 0a20 2020  sed to trade.   
-00021820: 2020 2020 2020 2020 2043 726f 7373 2d4d           Cross-M
-00021830: 6172 6769 6e20 4d6f 6465 3a20 6372 6f73  argin Mode: cros
-00021840: 7357 616c 6c65 7442 616c 616e 6365 0a20  sWalletBalance. 
-00021850: 2020 2020 2020 2020 2020 2049 736f 6c61             Isola
-00021860: 7465 642d 4d61 7267 696e 204d 6f64 653a  ted-Margin Mode:
-00021870: 2069 736f 6c61 7465 6457 616c 6c65 7442   isolatedWalletB
-00021880: 616c 616e 6365 0a0a 2020 2020 2020 2020  alance..        
-00021890: 2320 2a20 4e6f 7420 7265 7175 6972 6564  # * Not required
-000218a0: 2062 7920 4761 7465 206f 7220 4f4b 580a   by Gate or OKX.
-000218b0: 2020 2020 2020 2020 3a70 6172 616d 206d          :param m
-000218c0: 6d5f 6578 5f31 3a0a 2020 2020 2020 2020  m_ex_1:.        
-000218d0: 3a70 6172 616d 2075 706e 6c5f 6578 5f31  :param upnl_ex_1
-000218e0: 3a0a 2020 2020 2020 2020 2222 220a 0a20  :.        """.. 
-000218f0: 2020 2020 2020 206d 6172 6b65 7420 3d20         market = 
-00021900: 7365 6c66 2e6d 6172 6b65 7473 5b70 6169  self.markets[pai
-00021910: 725d 0a20 2020 2020 2020 2074 616b 6572  r].        taker
-00021920: 5f66 6565 5f72 6174 6520 3d20 6d61 726b  _fee_rate = mark
-00021930: 6574 5b27 7461 6b65 7227 5d0a 2020 2020  et['taker'].    
-00021940: 2020 2020 6d6d 5f72 6174 696f 2c20 5f20      mm_ratio, _ 
-00021950: 3d20 7365 6c66 2e67 6574 5f6d 6169 6e74  = self.get_maint
-00021960: 656e 616e 6365 5f72 6174 696f 5f61 6e64  enance_ratio_and
-00021970: 5f61 6d74 2870 6169 722c 2073 7461 6b65  _amt(pair, stake
-00021980: 5f61 6d6f 756e 7429 0a0a 2020 2020 2020  _amount)..      
-00021990: 2020 6966 2073 656c 662e 7472 6164 696e    if self.tradin
-000219a0: 675f 6d6f 6465 203d 3d20 5472 6164 696e  g_mode == Tradin
-000219b0: 674d 6f64 652e 4655 5455 5245 5320 616e  gMode.FUTURES an
-000219c0: 6420 7365 6c66 2e6d 6172 6769 6e5f 6d6f  d self.margin_mo
-000219d0: 6465 203d 3d20 4d61 7267 696e 4d6f 6465  de == MarginMode
-000219e0: 2e49 534f 4c41 5445 443a 0a0a 2020 2020  .ISOLATED:..    
-000219f0: 2020 2020 2020 2020 6966 206d 6172 6b65          if marke
-00021a00: 745b 2769 6e76 6572 7365 275d 3a0a 2020  t['inverse']:.  
-00021a10: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-00021a20: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
-00021a30: 7863 6570 7469 6f6e 280a 2020 2020 2020  xception(.      
-00021a40: 2020 2020 2020 2020 2020 2020 2020 2246                "F
-00021a50: 7265 7174 7261 6465 2064 6f65 7320 6e6f  reqtrade does no
-00021a60: 7420 7965 7420 7375 7070 6f72 7420 696e  t yet support in
-00021a70: 7665 7273 6520 636f 6e74 7261 6374 7322  verse contracts"
-00021a80: 290a 0a20 2020 2020 2020 2020 2020 2076  )..            v
-00021a90: 616c 7565 203d 2077 616c 6c65 745f 6261  alue = wallet_ba
-00021aa0: 6c61 6e63 6520 2f20 616d 6f75 6e74 0a0a  lance / amount..
-00021ab0: 2020 2020 2020 2020 2020 2020 6d6d 5f72              mm_r
-00021ac0: 6174 696f 5f74 616b 6572 203d 2028 6d6d  atio_taker = (mm
-00021ad0: 5f72 6174 696f 202b 2074 616b 6572 5f66  _ratio + taker_f
-00021ae0: 6565 5f72 6174 6529 0a20 2020 2020 2020  ee_rate).       
-00021af0: 2020 2020 2069 6620 6973 5f73 686f 7274       if is_short
-00021b00: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00021b10: 2020 7265 7475 726e 2028 6f70 656e 5f72    return (open_r
-00021b20: 6174 6520 2b20 7661 6c75 6529 202f 2028  ate + value) / (
-00021b30: 3120 2b20 6d6d 5f72 6174 696f 5f74 616b  1 + mm_ratio_tak
-00021b40: 6572 290a 2020 2020 2020 2020 2020 2020  er).            
-00021b50: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00021b60: 2020 2020 2020 7265 7475 726e 2028 6f70        return (op
-00021b70: 656e 5f72 6174 6520 2d20 7661 6c75 6529  en_rate - value)
-00021b80: 202f 2028 3120 2d20 6d6d 5f72 6174 696f   / (1 - mm_ratio
-00021b90: 5f74 616b 6572 290a 2020 2020 2020 2020  _taker).        
-00021ba0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00021bb0: 2020 7261 6973 6520 4f70 6572 6174 696f    raise Operatio
-00021bc0: 6e61 6c45 7863 6570 7469 6f6e 280a 2020  nalException(.  
-00021bd0: 2020 2020 2020 2020 2020 2020 2020 2246                "F
-00021be0: 7265 7174 7261 6465 206f 6e6c 7920 7375  reqtrade only su
-00021bf0: 7070 6f72 7473 2069 736f 6c61 7465 6420  pports isolated 
-00021c00: 6675 7475 7265 7320 666f 7220 6c65 7665  futures for leve
-00021c10: 7261 6765 2074 7261 6469 6e67 2229 0a0a  rage trading")..
-00021c20: 2020 2020 6465 6620 6765 745f 6d61 696e      def get_main
-00021c30: 7465 6e61 6e63 655f 7261 7469 6f5f 616e  tenance_ratio_an
-00021c40: 645f 616d 7428 0a20 2020 2020 2020 2073  d_amt(.        s
-00021c50: 656c 662c 0a20 2020 2020 2020 2070 6169  elf,.        pai
-00021c60: 723a 2073 7472 2c0a 2020 2020 2020 2020  r: str,.        
-00021c70: 6e6f 6d69 6e61 6c5f 7661 6c75 653a 2066  nominal_value: f
-00021c80: 6c6f 6174 2c0a 2020 2020 2920 2d3e 2054  loat,.    ) -> T
-00021c90: 7570 6c65 5b66 6c6f 6174 2c20 4f70 7469  uple[float, Opti
-00021ca0: 6f6e 616c 5b66 6c6f 6174 5d5d 3a0a 2020  onal[float]]:.  
-00021cb0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-00021cc0: 2020 496d 706f 7274 616e 743a 204d 7573    Important: Mus
-00021cd0: 7420 6265 2066 6574 6368 696e 6720 6461  t be fetching da
-00021ce0: 7461 2066 726f 6d20 6361 6368 6564 2076  ta from cached v
-00021cf0: 616c 7565 7320 6173 2074 6869 7320 6973  alues as this is
-00021d00: 2075 7365 6420 6279 2062 6163 6b74 6573   used by backtes
-00021d10: 7469 6e67 210a 2020 2020 2020 2020 3a70  ting!.        :p
-00021d20: 6172 616d 2070 6169 723a 204d 6172 6b65  aram pair: Marke
-00021d30: 7420 7379 6d62 6f6c 0a20 2020 2020 2020  t symbol.       
-00021d40: 203a 7061 7261 6d20 6e6f 6d69 6e61 6c5f   :param nominal_
-00021d50: 7661 6c75 653a 2054 6865 2074 6f74 616c  value: The total
-00021d60: 2074 7261 6465 2061 6d6f 756e 7420 696e   trade amount in
-00021d70: 2071 756f 7465 2063 7572 7265 6e63 7920   quote currency 
-00021d80: 696e 636c 7564 696e 6720 6c65 7665 7261  including levera
-00021d90: 6765 0a20 2020 2020 2020 206d 6169 6e74  ge.        maint
-00021da0: 656e 616e 6365 2061 6d6f 756e 7420 6f6e  enance amount on
-00021db0: 6c79 206f 6e20 4269 6e61 6e63 650a 2020  ly on Binance.  
-00021dc0: 2020 2020 2020 3a72 6574 7572 6e3a 2028        :return: (
-00021dd0: 6d61 696e 7465 6e61 6e63 6520 6d61 7267  maintenance marg
-00021de0: 696e 2072 6174 696f 2c20 6d61 696e 7465  in ratio, mainte
-00021df0: 6e61 6e63 6520 616d 6f75 6e74 290a 2020  nance amount).  
-00021e00: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
-00021e10: 2020 2069 6620 2873 656c 662e 5f63 6f6e     if (self._con
-00021e20: 6669 672e 6765 7428 2772 756e 6d6f 6465  fig.get('runmode
-00021e30: 2729 2069 6e20 4f50 5449 4d49 5a45 5f4d  ') in OPTIMIZE_M
-00021e40: 4f44 4553 0a20 2020 2020 2020 2020 2020  ODES.           
-00021e50: 2020 2020 206f 7220 7365 6c66 2e65 7863       or self.exc
-00021e60: 6861 6e67 655f 6861 7328 2766 6574 6368  hange_has('fetch
-00021e70: 4c65 7665 7261 6765 5469 6572 7327 290a  LeverageTiers').
-00021e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021e90: 6f72 2073 656c 662e 6578 6368 616e 6765  or self.exchange
-00021ea0: 5f68 6173 2827 6665 7463 684d 6172 6b65  _has('fetchMarke
-00021eb0: 744c 6576 6572 6167 6554 6965 7273 2729  tLeverageTiers')
-00021ec0: 293a 0a0a 2020 2020 2020 2020 2020 2020  ):..            
-00021ed0: 6966 2070 6169 7220 6e6f 7420 696e 2073  if pair not in s
-00021ee0: 656c 662e 5f6c 6576 6572 6167 655f 7469  elf._leverage_ti
-00021ef0: 6572 733a 0a20 2020 2020 2020 2020 2020  ers:.           
-00021f00: 2020 2020 2072 6169 7365 2049 6e76 616c       raise Inval
-00021f10: 6964 4f72 6465 7245 7863 6570 7469 6f6e  idOrderException
-00021f20: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00021f30: 2020 2020 2020 6622 4d61 696e 7465 6e61        f"Maintena
-00021f40: 6e63 6520 6d61 7267 696e 2072 6174 6520  nce margin rate 
-00021f50: 666f 7220 7b70 6169 727d 2069 7320 756e  for {pair} is un
-00021f60: 6176 6169 6c61 626c 6520 666f 7220 7b73  available for {s
-00021f70: 656c 662e 6e61 6d65 7d22 0a20 2020 2020  elf.name}".     
-00021f80: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
-00021f90: 2020 2020 2020 2020 2020 7061 6972 5f74            pair_t
-00021fa0: 6965 7273 203d 2073 656c 662e 5f6c 6576  iers = self._lev
-00021fb0: 6572 6167 655f 7469 6572 735b 7061 6972  erage_tiers[pair
-00021fc0: 5d0a 0a20 2020 2020 2020 2020 2020 2066  ]..            f
-00021fd0: 6f72 2074 6965 7220 696e 2072 6576 6572  or tier in rever
-00021fe0: 7365 6428 7061 6972 5f74 6965 7273 293a  sed(pair_tiers):
-00021ff0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00022000: 2069 6620 6e6f 6d69 6e61 6c5f 7661 6c75   if nominal_valu
-00022010: 6520 3e3d 2074 6965 725b 276d 696e 4e6f  e >= tier['minNo
-00022020: 7469 6f6e 616c 275d 3a0a 2020 2020 2020  tional']:.      
-00022030: 2020 2020 2020 2020 2020 2020 2020 7265                re
-00022040: 7475 726e 2028 7469 6572 5b27 6d61 696e  turn (tier['main
-00022050: 7465 6e61 6e63 654d 6172 6769 6e52 6174  tenanceMarginRat
-00022060: 6527 5d2c 2074 6965 725b 276d 6169 6e74  e'], tier['maint
-00022070: 416d 7427 5d29 0a0a 2020 2020 2020 2020  Amt'])..        
-00022080: 2020 2020 7261 6973 6520 4578 6368 616e      raise Exchan
-00022090: 6765 4572 726f 7228 226e 6f6d 696e 616c  geError("nominal
-000220a0: 2076 616c 7565 2063 616e 206e 6f74 2062   value can not b
-000220b0: 6520 6c6f 7765 7220 7468 616e 2030 2229  e lower than 0")
-000220c0: 0a20 2020 2020 2020 2020 2020 2023 2054  .            # T
-000220d0: 6865 206c 6f77 6573 7420 6e6f 7469 6f6e  he lowest notion
-000220e0: 616c 5f66 6c6f 6f72 2066 6f72 2061 6e79  al_floor for any
-000220f0: 2070 6169 7220 696e 2066 6574 6368 5f6c   pair in fetch_l
-00022100: 6576 6572 6167 655f 7469 6572 7320 6973  everage_tiers is
-00022110: 2061 6c77 6179 7320 3020 6265 6361 7573   always 0 becaus
-00022120: 6520 6974 0a20 2020 2020 2020 2020 2020  e it.           
-00022130: 2023 2064 6573 6372 6962 6573 2074 6865   # describes the
-00022140: 206d 696e 2061 6d74 2066 6f72 2061 2074   min amt for a t
-00022150: 6965 722c 2061 6e64 2074 6865 206c 6f77  ier, and the low
-00022160: 6573 7420 7469 6572 2077 696c 6c20 616c  est tier will al
-00022170: 7761 7973 2067 6f20 646f 776e 2074 6f20  ways go down to 
-00022180: 300a 2020 2020 2020 2020 656c 7365 3a0a  0.        else:.
-00022190: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-000221a0: 6520 4578 6368 616e 6765 4572 726f 7228  e ExchangeError(
-000221b0: 6622 4361 6e6e 6f74 2067 6574 206d 6169  f"Cannot get mai
-000221c0: 6e74 656e 616e 6365 2072 6174 696f 2075  ntenance ratio u
-000221d0: 7369 6e67 207b 7365 6c66 2e6e 616d 657d  sing {self.name}
-000221e0: 2229 0a20 2020 2020 2020 2020 2020 2072  ").            r
-000221f0: 6169 7365 2045 7863 6861 6e67 6545 7272  aise ExchangeErr
-00022200: 6f72 2866 2243 616e 6e6f 7420 6765 7420  or(f"Cannot get 
-00022210: 6d61 696e 7465 6e61 6e63 6520 7261 7469  maintenance rati
-00022220: 6f20 7573 696e 6720 7b73 656c 662e 6e61  o using {self.na
-00022230: 6d65 7d22 290a                           me}").
+0001e190: 2020 2020 2023 0a20 2020 2020 2020 2020       #.         
+0001e1a0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0001e1b0: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
+0001e1c0: 2020 2020 2020 2020 2020 2023 2020 2020             #    
+0001e1d0: 2022 6d69 6e22 3a20 302c 2020 2020 2020   "min": 0,      
+0001e1e0: 2320 7374 616b 6520 3d20 302e 300a 2020  # stake = 0.0.  
+0001e1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e200: 2020 2020 2020 2320 2020 2020 226d 6178        #     "max
+0001e210: 223a 2031 3030 3030 2c20 2023 206d 6178  ": 10000,  # max
+0001e220: 5f73 7461 6b65 4037 3520 3d20 3130 3030  _stake@75 = 1000
+0001e230: 302f 3735 203d 2031 3333 2e33 3333 3333  0/75 = 133.33333
+0001e240: 3333 3333 3333 3333 340a 2020 2020 2020  333333334.      
+0001e250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e260: 2020 2320 2020 2020 226c 6576 223a 2037    #     "lev": 7
+0001e270: 352c 0a20 2020 2020 2020 2020 2020 2020  5,.             
+0001e280: 2020 2020 2020 2020 2020 2023 207d 2c0a             # },.
+0001e290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e2a0: 2020 2020 2020 2020 2320 7b0a 2020 2020          # {.    
+0001e2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e2c0: 2020 2020 2320 2020 2020 226d 696e 223a      #     "min":
+0001e2d0: 2031 3030 3030 2c20 2023 2073 7461 6b65   10000,  # stake
+0001e2e0: 203d 2032 3030 2e30 0a20 2020 2020 2020   = 200.0.       
+0001e2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e300: 2023 2020 2020 2022 6d61 7822 3a20 3530   #     "max": 50
+0001e310: 3030 302c 2020 2320 6d61 785f 7374 616b  000,  # max_stak
+0001e320: 6540 3530 203d 2035 3030 3030 2f35 3020  e@50 = 50000/50 
+0001e330: 3d20 3130 3030 2e30 0a20 2020 2020 2020  = 1000.0.       
+0001e340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e350: 2023 2020 2020 2022 6c65 7622 3a20 3530   #     "lev": 50
+0001e360: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0001e370: 2020 2020 2020 2020 2020 2320 7d0a 2020            # }.  
+0001e380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e390: 2020 2020 2020 230a 0a20 2020 2020 2020        #..       
+0001e3a0: 2020 2020 2020 2020 2065 6c73 653a 2020           else:  
+0001e3b0: 2320 6966 206f 6e20 7468 6520 6c61 7374  # if on the last
+0001e3c0: 2074 6965 720a 2020 2020 2020 2020 2020   tier.          
+0001e3d0: 2020 2020 2020 2020 2020 6966 2073 7461            if sta
+0001e3e0: 6b65 5f61 6d6f 756e 7420 3e20 7469 6572  ke_amount > tier
+0001e3f0: 5b22 6d61 784e 6f74 696f 6e61 6c22 5d3a  ["maxNotional"]:
+0001e400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001e410: 2020 2020 2020 2020 2023 2049 6620 7374           # If st
+0001e420: 616b 6520 6973 203e 2074 6861 6e20 6d61  ake is > than ma
+0001e430: 7820 7472 6164 6561 626c 6520 616d 6f75  x tradeable amou
+0001e440: 6e74 0a20 2020 2020 2020 2020 2020 2020  nt.             
+0001e450: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0001e460: 2049 6e76 616c 6964 4f72 6465 7245 7863   InvalidOrderExc
+0001e470: 6570 7469 6f6e 2866 2241 6d6f 756e 7420  eption(f"Amount 
+0001e480: 7b73 7461 6b65 5f61 6d6f 756e 747d 2074  {stake_amount} t
+0001e490: 6f6f 2068 6967 6820 666f 7220 7b70 6169  oo high for {pai
+0001e4a0: 727d 2229 0a20 2020 2020 2020 2020 2020  r}").           
+0001e4b0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+0001e4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e4d0: 2020 2020 2020 2072 6574 7572 6e20 7469         return ti
+0001e4e0: 6572 5b22 6d61 784c 6576 6572 6167 6522  er["maxLeverage"
+0001e4f0: 5d0a 0a20 2020 2020 2020 2020 2020 2072  ]..            r
+0001e500: 6169 7365 204f 7065 7261 7469 6f6e 616c  aise Operational
+0001e510: 4578 6365 7074 696f 6e28 0a20 2020 2020  Exception(.     
+0001e520: 2020 2020 2020 2020 2020 2022 4c6f 6f70             "Loop
+0001e530: 6564 2074 6872 6f75 6768 2061 6c6c 2074  ed through all t
+0001e540: 6965 7273 2077 6974 686f 7574 2066 696e  iers without fin
+0001e550: 6469 6e67 2061 206d 6178 206c 6576 6572  ding a max lever
+0001e560: 6167 652e 2053 686f 756c 6420 6e65 7665  age. Should neve
+0001e570: 7220 6265 2072 6561 6368 6564 220a 2020  r be reached".  
+0001e580: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+0001e590: 2020 2020 2065 6c69 6620 7365 6c66 2e74       elif self.t
+0001e5a0: 7261 6469 6e67 5f6d 6f64 6520 3d3d 2054  rading_mode == T
+0001e5b0: 7261 6469 6e67 4d6f 6465 2e4d 4152 4749  radingMode.MARGI
+0001e5c0: 4e3a 2020 2320 5365 6172 6368 206d 6172  N:  # Search mar
+0001e5d0: 6b65 7473 2e6c 696d 6974 7320 666f 7220  kets.limits for 
+0001e5e0: 6d61 7820 6c65 760a 2020 2020 2020 2020  max lev.        
+0001e5f0: 2020 2020 6d61 726b 6574 203d 2073 656c      market = sel
+0001e600: 662e 6d61 726b 6574 735b 7061 6972 5d0a  f.markets[pair].
+0001e610: 2020 2020 2020 2020 2020 2020 6966 206d              if m
+0001e620: 6172 6b65 745b 226c 696d 6974 7322 5d5b  arket["limits"][
+0001e630: 226c 6576 6572 6167 6522 5d5b 226d 6178  "leverage"]["max
+0001e640: 225d 2069 7320 6e6f 7420 4e6f 6e65 3a0a  "] is not None:.
+0001e650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e660: 7265 7475 726e 206d 6172 6b65 745b 226c  return market["l
+0001e670: 696d 6974 7322 5d5b 226c 6576 6572 6167  imits"]["leverag
+0001e680: 6522 5d5b 226d 6178 225d 0a20 2020 2020  e"]["max"].     
+0001e690: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0001e6a0: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+0001e6b0: 7572 6e20 312e 3020 2023 2044 6566 6175  urn 1.0  # Defau
+0001e6c0: 6c74 2069 6620 6d61 7820 6c65 7665 7261  lt if max levera
+0001e6d0: 6765 2063 616e 6e6f 7420 6265 2066 6f75  ge cannot be fou
+0001e6e0: 6e64 0a20 2020 2020 2020 2065 6c73 653a  nd.        else:
+0001e6f0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0001e700: 7572 6e20 312e 300a 0a20 2020 2040 7265  urn 1.0..    @re
+0001e710: 7472 6965 720a 2020 2020 6465 6620 5f73  trier.    def _s
+0001e720: 6574 5f6c 6576 6572 6167 6528 0a20 2020  et_leverage(.   
+0001e730: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+0001e740: 2020 206c 6576 6572 6167 653a 2066 6c6f     leverage: flo
+0001e750: 6174 2c0a 2020 2020 2020 2020 7061 6972  at,.        pair
+0001e760: 3a20 4f70 7469 6f6e 616c 5b73 7472 5d20  : Optional[str] 
+0001e770: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+0001e780: 6163 6365 7074 5f66 6169 6c3a 2062 6f6f  accept_fail: boo
+0001e790: 6c20 3d20 4661 6c73 652c 0a20 2020 2029  l = False,.    )
+0001e7a0: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
+0001e7b0: 2020 2020 2020 5365 7427 7320 7468 6520        Set's the 
+0001e7c0: 6c65 7665 7261 6765 2062 6566 6f72 6520  leverage before 
+0001e7d0: 6d61 6b69 6e67 2061 2074 7261 6465 2c20  making a trade, 
+0001e7e0: 696e 206f 7264 6572 2074 6f20 6e6f 740a  in order to not.
+0001e7f0: 2020 2020 2020 2020 6861 7665 2074 6865          have the
+0001e800: 2073 616d 6520 6c65 7665 7261 6765 206f   same leverage o
+0001e810: 6e20 6576 6572 7920 7472 6164 650a 2020  n every trade.  
+0001e820: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0001e830: 2020 6966 2073 656c 662e 5f63 6f6e 6669    if self._confi
+0001e840: 675b 2264 7279 5f72 756e 225d 206f 7220  g["dry_run"] or 
+0001e850: 6e6f 7420 7365 6c66 2e65 7863 6861 6e67  not self.exchang
+0001e860: 655f 6861 7328 2273 6574 4c65 7665 7261  e_has("setLevera
+0001e870: 6765 2229 3a0a 2020 2020 2020 2020 2020  ge"):.          
+0001e880: 2020 2320 536f 6d65 2065 7863 6861 6e67    # Some exchang
+0001e890: 6573 206f 6e6c 7920 7375 7070 6f72 7420  es only support 
+0001e8a0: 6f6e 6520 6d61 7267 696e 5f6d 6f64 6520  one margin_mode 
+0001e8b0: 7479 7065 0a20 2020 2020 2020 2020 2020  type.           
+0001e8c0: 2072 6574 7572 6e0a 2020 2020 2020 2020   return.        
+0001e8d0: 6966 2073 656c 662e 5f66 745f 6861 732e  if self._ft_has.
+0001e8e0: 6765 7428 2266 6c6f 6f72 5f6c 6576 6572  get("floor_lever
+0001e8f0: 6167 6522 2c20 4661 6c73 6529 2069 7320  age", False) is 
+0001e900: 5472 7565 3a0a 2020 2020 2020 2020 2020  True:.          
+0001e910: 2020 2320 526f 756e 6469 6e67 2066 6f72    # Rounding for
+0001e920: 2062 696e 616e 6365 202e 2e2e 0a20 2020   binance ....   
+0001e930: 2020 2020 2020 2020 206c 6576 6572 6167           leverag
+0001e940: 6520 3d20 666c 6f6f 7228 6c65 7665 7261  e = floor(levera
+0001e950: 6765 290a 2020 2020 2020 2020 7472 793a  ge).        try:
+0001e960: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
+0001e970: 203d 2073 656c 662e 5f61 7069 2e73 6574   = self._api.set
+0001e980: 5f6c 6576 6572 6167 6528 7379 6d62 6f6c  _leverage(symbol
+0001e990: 3d70 6169 722c 206c 6576 6572 6167 653d  =pair, leverage=
+0001e9a0: 6c65 7665 7261 6765 290a 2020 2020 2020  leverage).      
+0001e9b0: 2020 2020 2020 7365 6c66 2e5f 6c6f 675f        self._log_
+0001e9c0: 6578 6368 616e 6765 5f72 6573 706f 6e73  exchange_respons
+0001e9d0: 6528 2273 6574 5f6c 6576 6572 6167 6522  e("set_leverage"
+0001e9e0: 2c20 7265 7329 0a20 2020 2020 2020 2065  , res).        e
+0001e9f0: 7863 6570 7420 6363 7874 2e44 446f 5350  xcept ccxt.DDoSP
+0001ea00: 726f 7465 6374 696f 6e20 6173 2065 3a0a  rotection as e:.
+0001ea10: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0001ea20: 6520 4444 6f73 5072 6f74 6563 7469 6f6e  e DDosProtection
+0001ea30: 2865 2920 6672 6f6d 2065 0a20 2020 2020  (e) from e.     
+0001ea40: 2020 2065 7863 6570 7420 2863 6378 742e     except (ccxt.
+0001ea50: 4261 6452 6571 7565 7374 2c20 6363 7874  BadRequest, ccxt
+0001ea60: 2e4f 7065 7261 7469 6f6e 5265 6a65 6374  .OperationReject
+0001ea70: 6564 2c20 6363 7874 2e49 6e73 7566 6669  ed, ccxt.Insuffi
+0001ea80: 6369 656e 7446 756e 6473 2920 6173 2065  cientFunds) as e
+0001ea90: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+0001eaa0: 206e 6f74 2061 6363 6570 745f 6661 696c   not accept_fail
+0001eab0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001eac0: 2020 7261 6973 6520 5465 6d70 6f72 6172    raise Temporar
+0001ead0: 7945 7272 6f72 280a 2020 2020 2020 2020  yError(.        
+0001eae0: 2020 2020 2020 2020 2020 2020 6622 436f              f"Co
+0001eaf0: 756c 6420 6e6f 7420 7365 7420 6c65 7665  uld not set leve
+0001eb00: 7261 6765 2064 7565 2074 6f20 7b65 2e5f  rage due to {e._
+0001eb10: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
+0001eb20: 5f7d 2e20 4d65 7373 6167 653a 207b 657d  _}. Message: {e}
+0001eb30: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0001eb40: 2020 2920 6672 6f6d 2065 0a20 2020 2020    ) from e.     
+0001eb50: 2020 2065 7863 6570 7420 2863 6378 742e     except (ccxt.
+0001eb60: 4f70 6572 6174 696f 6e46 6169 6c65 642c  OperationFailed,
+0001eb70: 2063 6378 742e 4578 6368 616e 6765 4572   ccxt.ExchangeEr
+0001eb80: 726f 7229 2061 7320 653a 0a20 2020 2020  ror) as e:.     
+0001eb90: 2020 2020 2020 2072 6169 7365 2054 656d         raise Tem
+0001eba0: 706f 7261 7279 4572 726f 7228 0a20 2020  poraryError(.   
+0001ebb0: 2020 2020 2020 2020 2020 2020 2066 2243               f"C
+0001ebc0: 6f75 6c64 206e 6f74 2073 6574 206c 6576  ould not set lev
+0001ebd0: 6572 6167 6520 6475 6520 746f 207b 652e  erage due to {e.
+0001ebe0: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
+0001ebf0: 5f5f 7d2e 204d 6573 7361 6765 3a20 7b65  __}. Message: {e
+0001ec00: 7d22 0a20 2020 2020 2020 2020 2020 2029  }".            )
+0001ec10: 2066 726f 6d20 650a 2020 2020 2020 2020   from e.        
+0001ec20: 6578 6365 7074 2063 6378 742e 4261 7365  except ccxt.Base
+0001ec30: 4572 726f 7220 6173 2065 3a0a 2020 2020  Error as e:.    
+0001ec40: 2020 2020 2020 2020 7261 6973 6520 4f70          raise Op
+0001ec50: 6572 6174 696f 6e61 6c45 7863 6570 7469  erationalExcepti
+0001ec60: 6f6e 2865 2920 6672 6f6d 2065 0a0a 2020  on(e) from e..  
+0001ec70: 2020 6465 6620 6765 745f 696e 7465 7265    def get_intere
+0001ec80: 7374 5f72 6174 6528 7365 6c66 2920 2d3e  st_rate(self) ->
+0001ec90: 2066 6c6f 6174 3a0a 2020 2020 2020 2020   float:.        
+0001eca0: 2222 220a 2020 2020 2020 2020 5265 7472  """.        Retr
+0001ecb0: 6965 7665 2069 6e74 6572 6573 7420 7261  ieve interest ra
+0001ecc0: 7465 202d 206e 6563 6573 7361 7279 2066  te - necessary f
+0001ecd0: 6f72 204d 6172 6769 6e20 7472 6164 696e  or Margin tradin
+0001ece0: 672e 0a20 2020 2020 2020 2053 686f 756c  g..        Shoul
+0001ecf0: 6420 6e6f 7420 6361 6c6c 2074 6865 2065  d not call the e
+0001ed00: 7863 6861 6e67 6520 6469 7265 6374 6c79  xchange directly
+0001ed10: 2077 6865 6e20 7573 6564 2066 726f 6d20   when used from 
+0001ed20: 6261 636b 7465 7374 696e 672e 0a20 2020  backtesting..   
+0001ed30: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+0001ed40: 2072 6574 7572 6e20 302e 300a 0a20 2020   return 0.0..   
+0001ed50: 2064 6566 2066 756e 6469 6e67 5f66 6565   def funding_fee
+0001ed60: 5f63 7574 6f66 6628 7365 6c66 2c20 6f70  _cutoff(self, op
+0001ed70: 656e 5f64 6174 653a 2064 6174 6574 696d  en_date: datetim
+0001ed80: 6529 202d 3e20 626f 6f6c 3a0a 2020 2020  e) -> bool:.    
+0001ed90: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0001eda0: 4675 6e64 696e 6720 6665 6573 2061 7265  Funding fees are
+0001edb0: 206f 6e6c 7920 6368 6172 6765 6420 6174   only charged at
+0001edc0: 2066 756c 6c20 686f 7572 7320 2875 7375   full hours (usu
+0001edd0: 616c 6c79 2065 7665 7279 2034 2d38 6829  ally every 4-8h)
+0001ede0: 2e0a 2020 2020 2020 2020 5468 6572 6566  ..        Theref
+0001edf0: 6f72 6520 6120 7472 6164 6520 6f70 656e  ore a trade open
+0001ee00: 696e 6720 6174 2031 303a 3030 3a30 3120  ing at 10:00:01 
+0001ee10: 7769 6c6c 206e 6f74 2062 6520 6368 6172  will not be char
+0001ee20: 6765 6420 6120 6675 6e64 696e 6720 6665  ged a funding fe
+0001ee30: 6520 756e 7469 6c20 7468 6520 6e65 7874  e until the next
+0001ee40: 2068 6f75 722e 0a20 2020 2020 2020 203a   hour..        :
+0001ee50: 7061 7261 6d20 6f70 656e 5f64 6174 653a  param open_date:
+0001ee60: 2054 6865 206f 7065 6e20 6461 7465 2066   The open date f
+0001ee70: 6f72 2061 2074 7261 6465 0a20 2020 2020  or a trade.     
+0001ee80: 2020 203a 7265 7475 726e 3a20 5472 7565     :return: True
+0001ee90: 2069 6620 7468 6520 6461 7465 2066 616c   if the date fal
+0001eea0: 6c73 206f 6e20 6120 6675 6c6c 2068 6f75  ls on a full hou
+0001eeb0: 722c 2046 616c 7365 206f 7468 6572 7769  r, False otherwi
+0001eec0: 7365 0a20 2020 2020 2020 2022 2222 0a20  se.        """. 
+0001eed0: 2020 2020 2020 2072 6574 7572 6e20 6f70         return op
+0001eee0: 656e 5f64 6174 652e 6d69 6e75 7465 203d  en_date.minute =
+0001eef0: 3d20 3020 616e 6420 6f70 656e 5f64 6174  = 0 and open_dat
+0001ef00: 652e 7365 636f 6e64 203d 3d20 300a 0a20  e.second == 0.. 
+0001ef10: 2020 2040 7265 7472 6965 720a 2020 2020     @retrier.    
+0001ef20: 6465 6620 7365 745f 6d61 7267 696e 5f6d  def set_margin_m
+0001ef30: 6f64 6528 0a20 2020 2020 2020 2073 656c  ode(.        sel
+0001ef40: 662c 0a20 2020 2020 2020 2070 6169 723a  f,.        pair:
+0001ef50: 2073 7472 2c0a 2020 2020 2020 2020 6d61   str,.        ma
+0001ef60: 7267 696e 5f6d 6f64 653a 204d 6172 6769  rgin_mode: Margi
+0001ef70: 6e4d 6f64 652c 0a20 2020 2020 2020 2061  nMode,.        a
+0001ef80: 6363 6570 745f 6661 696c 3a20 626f 6f6c  ccept_fail: bool
+0001ef90: 203d 2046 616c 7365 2c0a 2020 2020 2020   = False,.      
+0001efa0: 2020 7061 7261 6d73 3a20 4f70 7469 6f6e    params: Option
+0001efb0: 616c 5b44 6963 745d 203d 204e 6f6e 652c  al[Dict] = None,
+0001efc0: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
+0001efd0: 2222 220a 2020 2020 2020 2020 5365 7427  """.        Set'
+0001efe0: 7320 7468 6520 6d61 7267 696e 206d 6f64  s the margin mod
+0001eff0: 6520 6f6e 2074 6865 2065 7863 6861 6e67  e on the exchang
+0001f000: 6520 746f 2063 726f 7373 206f 7220 6973  e to cross or is
+0001f010: 6f6c 6174 6564 2066 6f72 2061 2073 7065  olated for a spe
+0001f020: 6369 6669 6320 7061 6972 0a20 2020 2020  cific pair.     
+0001f030: 2020 203a 7061 7261 6d20 7061 6972 3a20     :param pair: 
+0001f040: 6261 7365 2f71 756f 7465 2063 7572 7265  base/quote curre
+0001f050: 6e63 7920 7061 6972 2028 652e 672e 2022  ncy pair (e.g. "
+0001f060: 4144 412f 5553 4454 2229 0a20 2020 2020  ADA/USDT").     
+0001f070: 2020 2022 2222 0a20 2020 2020 2020 2069     """.        i
+0001f080: 6620 7365 6c66 2e5f 636f 6e66 6967 5b22  f self._config["
+0001f090: 6472 795f 7275 6e22 5d20 6f72 206e 6f74  dry_run"] or not
+0001f0a0: 2073 656c 662e 6578 6368 616e 6765 5f68   self.exchange_h
+0001f0b0: 6173 2822 7365 744d 6172 6769 6e4d 6f64  as("setMarginMod
+0001f0c0: 6522 293a 0a20 2020 2020 2020 2020 2020  e"):.           
+0001f0d0: 2023 2053 6f6d 6520 6578 6368 616e 6765   # Some exchange
+0001f0e0: 7320 6f6e 6c79 2073 7570 706f 7274 206f  s only support o
+0001f0f0: 6e65 206d 6172 6769 6e5f 6d6f 6465 2074  ne margin_mode t
+0001f100: 7970 650a 2020 2020 2020 2020 2020 2020  ype.            
+0001f110: 7265 7475 726e 0a0a 2020 2020 2020 2020  return..        
+0001f120: 6966 2070 6172 616d 7320 6973 204e 6f6e  if params is Non
+0001f130: 653a 0a20 2020 2020 2020 2020 2020 2070  e:.            p
+0001f140: 6172 616d 7320 3d20 7b7d 0a20 2020 2020  arams = {}.     
+0001f150: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+0001f160: 2020 2020 7265 7320 3d20 7365 6c66 2e5f      res = self._
+0001f170: 6170 692e 7365 745f 6d61 7267 696e 5f6d  api.set_margin_m
+0001f180: 6f64 6528 6d61 7267 696e 5f6d 6f64 652e  ode(margin_mode.
+0001f190: 7661 6c75 652c 2070 6169 722c 2070 6172  value, pair, par
+0001f1a0: 616d 7329 0a20 2020 2020 2020 2020 2020  ams).           
+0001f1b0: 2073 656c 662e 5f6c 6f67 5f65 7863 6861   self._log_excha
+0001f1c0: 6e67 655f 7265 7370 6f6e 7365 2822 7365  nge_response("se
+0001f1d0: 745f 6d61 7267 696e 5f6d 6f64 6522 2c20  t_margin_mode", 
+0001f1e0: 7265 7329 0a20 2020 2020 2020 2065 7863  res).        exc
+0001f1f0: 6570 7420 6363 7874 2e44 446f 5350 726f  ept ccxt.DDoSPro
+0001f200: 7465 6374 696f 6e20 6173 2065 3a0a 2020  tection as e:.  
+0001f210: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0001f220: 4444 6f73 5072 6f74 6563 7469 6f6e 2865  DDosProtection(e
+0001f230: 2920 6672 6f6d 2065 0a20 2020 2020 2020  ) from e.       
+0001f240: 2065 7863 6570 7420 2863 6378 742e 4261   except (ccxt.Ba
+0001f250: 6452 6571 7565 7374 2c20 6363 7874 2e4f  dRequest, ccxt.O
+0001f260: 7065 7261 7469 6f6e 5265 6a65 6374 6564  perationRejected
+0001f270: 2920 6173 2065 3a0a 2020 2020 2020 2020  ) as e:.        
+0001f280: 2020 2020 6966 206e 6f74 2061 6363 6570      if not accep
+0001f290: 745f 6661 696c 3a0a 2020 2020 2020 2020  t_fail:.        
+0001f2a0: 2020 2020 2020 2020 7261 6973 6520 5465          raise Te
+0001f2b0: 6d70 6f72 6172 7945 7272 6f72 280a 2020  mporaryError(.  
+0001f2c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f2d0: 2020 6622 436f 756c 6420 6e6f 7420 7365    f"Could not se
+0001f2e0: 7420 6d61 7267 696e 206d 6f64 6520 6475  t margin mode du
+0001f2f0: 6520 746f 207b 652e 5f5f 636c 6173 735f  e to {e.__class_
+0001f300: 5f2e 5f5f 6e61 6d65 5f5f 7d2e 204d 6573  _.__name__}. Mes
+0001f310: 7361 6765 3a20 7b65 7d22 0a20 2020 2020  sage: {e}".     
+0001f320: 2020 2020 2020 2020 2020 2029 2066 726f             ) fro
+0001f330: 6d20 650a 2020 2020 2020 2020 6578 6365  m e.        exce
+0001f340: 7074 2028 6363 7874 2e4f 7065 7261 7469  pt (ccxt.Operati
+0001f350: 6f6e 4661 696c 6564 2c20 6363 7874 2e45  onFailed, ccxt.E
+0001f360: 7863 6861 6e67 6545 7272 6f72 2920 6173  xchangeError) as
+0001f370: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
+0001f380: 7261 6973 6520 5465 6d70 6f72 6172 7945  raise TemporaryE
+0001f390: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
+0001f3a0: 2020 2020 2020 6622 436f 756c 6420 6e6f        f"Could no
+0001f3b0: 7420 7365 7420 6d61 7267 696e 206d 6f64  t set margin mod
+0001f3c0: 6520 6475 6520 746f 207b 652e 5f5f 636c  e due to {e.__cl
+0001f3d0: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 7d2e  ass__.__name__}.
+0001f3e0: 204d 6573 7361 6765 3a20 7b65 7d22 0a20   Message: {e}". 
+0001f3f0: 2020 2020 2020 2020 2020 2029 2066 726f             ) fro
+0001f400: 6d20 650a 2020 2020 2020 2020 6578 6365  m e.        exce
+0001f410: 7074 2063 6378 742e 4261 7365 4572 726f  pt ccxt.BaseErro
+0001f420: 7220 6173 2065 3a0a 2020 2020 2020 2020  r as e:.        
+0001f430: 2020 2020 7261 6973 6520 4f70 6572 6174      raise Operat
+0001f440: 696f 6e61 6c45 7863 6570 7469 6f6e 2865  ionalException(e
+0001f450: 2920 6672 6f6d 2065 0a0a 2020 2020 6465  ) from e..    de
+0001f460: 6620 5f66 6574 6368 5f61 6e64 5f63 616c  f _fetch_and_cal
+0001f470: 6375 6c61 7465 5f66 756e 6469 6e67 5f66  culate_funding_f
+0001f480: 6565 7328 0a20 2020 2020 2020 2073 656c  ees(.        sel
+0001f490: 662c 0a20 2020 2020 2020 2070 6169 723a  f,.        pair:
+0001f4a0: 2073 7472 2c0a 2020 2020 2020 2020 616d   str,.        am
+0001f4b0: 6f75 6e74 3a20 666c 6f61 742c 0a20 2020  ount: float,.   
+0001f4c0: 2020 2020 2069 735f 7368 6f72 743a 2062       is_short: b
+0001f4d0: 6f6f 6c2c 0a20 2020 2020 2020 206f 7065  ool,.        ope
+0001f4e0: 6e5f 6461 7465 3a20 6461 7465 7469 6d65  n_date: datetime
+0001f4f0: 2c0a 2020 2020 2020 2020 636c 6f73 655f  ,.        close_
+0001f500: 6461 7465 3a20 4f70 7469 6f6e 616c 5b64  date: Optional[d
+0001f510: 6174 6574 696d 655d 203d 204e 6f6e 652c  atetime] = None,
+0001f520: 0a20 2020 2029 202d 3e20 666c 6f61 743a  .    ) -> float:
+0001f530: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+0001f540: 2020 2020 2046 6574 6368 6573 2061 6e64       Fetches and
+0001f550: 2063 616c 6375 6c61 7465 7320 7468 6520   calculates the 
+0001f560: 7375 6d20 6f66 2061 6c6c 2066 756e 6469  sum of all fundi
+0001f570: 6e67 2066 6565 7320 7468 6174 206f 6363  ng fees that occ
+0001f580: 7572 7265 6420 666f 7220 6120 7061 6972  urred for a pair
+0001f590: 0a20 2020 2020 2020 2064 7572 696e 6720  .        during 
+0001f5a0: 6120 6675 7475 7265 7320 7472 6164 652e  a futures trade.
+0001f5b0: 0a20 2020 2020 2020 204f 6e6c 7920 7573  .        Only us
+0001f5c0: 6564 2064 7572 696e 6720 6472 792d 7275  ed during dry-ru
+0001f5d0: 6e20 6f72 2069 6620 7468 6520 6578 6368  n or if the exch
+0001f5e0: 616e 6765 2064 6f65 7320 6e6f 7420 7072  ange does not pr
+0001f5f0: 6f76 6964 6520 6120 6675 6e64 696e 675f  ovide a funding_
+0001f600: 7261 7465 7320 656e 6470 6f69 6e74 2e0a  rates endpoint..
+0001f610: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
+0001f620: 6169 723a 2054 6865 2071 756f 7465 2f62  air: The quote/b
+0001f630: 6173 6520 7061 6972 206f 6620 7468 6520  ase pair of the 
+0001f640: 7472 6164 650a 2020 2020 2020 2020 3a70  trade.        :p
+0001f650: 6172 616d 2061 6d6f 756e 743a 2054 6865  aram amount: The
+0001f660: 2071 7561 6e74 6974 7920 6f66 2074 6865   quantity of the
+0001f670: 2074 7261 6465 0a20 2020 2020 2020 203a   trade.        :
+0001f680: 7061 7261 6d20 6973 5f73 686f 7274 3a20  param is_short: 
+0001f690: 7472 6164 6520 6469 7265 6374 696f 6e0a  trade direction.
+0001f6a0: 2020 2020 2020 2020 3a70 6172 616d 206f          :param o
+0001f6b0: 7065 6e5f 6461 7465 3a20 5468 6520 6461  pen_date: The da
+0001f6c0: 7465 2061 6e64 2074 696d 6520 7468 6174  te and time that
+0001f6d0: 2074 6865 2074 7261 6465 2073 7461 7274   the trade start
+0001f6e0: 6564 0a20 2020 2020 2020 203a 7061 7261  ed.        :para
+0001f6f0: 6d20 636c 6f73 655f 6461 7465 3a20 5468  m close_date: Th
+0001f700: 6520 6461 7465 2061 6e64 2074 696d 6520  e date and time 
+0001f710: 7468 6174 2074 6865 2074 7261 6465 2065  that the trade e
+0001f720: 6e64 6564 0a20 2020 2020 2020 2022 2222  nded.        """
+0001f730: 0a0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
+0001f740: 662e 6675 6e64 696e 675f 6665 655f 6375  f.funding_fee_cu
+0001f750: 746f 6666 286f 7065 6e5f 6461 7465 293a  toff(open_date):
+0001f760: 0a20 2020 2020 2020 2020 2020 2023 2053  .            # S
+0001f770: 6869 6674 2062 6163 6b20 746f 2031 6820  hift back to 1h 
+0001f780: 6361 6e64 6c65 2074 6f20 6176 6f69 6420  candle to avoid 
+0001f790: 6d69 7373 696e 6720 6675 6e64 696e 6720  missing funding 
+0001f7a0: 6665 6573 0a20 2020 2020 2020 2020 2020  fees.           
+0001f7b0: 2023 204f 6e6c 7920 7265 616c 6c79 2072   # Only really r
+0001f7c0: 656c 6576 616e 7420 666f 7220 7472 6164  elevant for trad
+0001f7d0: 6573 2076 6572 7920 636c 6f73 6520 746f  es very close to
+0001f7e0: 2074 6865 2066 756c 6c20 686f 7572 0a20   the full hour. 
+0001f7f0: 2020 2020 2020 2020 2020 206f 7065 6e5f             open_
+0001f800: 6461 7465 203d 2074 696d 6566 7261 6d65  date = timeframe
+0001f810: 5f74 6f5f 7072 6576 5f64 6174 6528 2231  _to_prev_date("1
+0001f820: 6822 2c20 6f70 656e 5f64 6174 6529 0a20  h", open_date). 
+0001f830: 2020 2020 2020 2074 696d 6566 7261 6d65         timeframe
+0001f840: 203d 2073 656c 662e 5f66 745f 6861 735b   = self._ft_has[
+0001f850: 226d 6172 6b5f 6f68 6c63 765f 7469 6d65  "mark_ohlcv_time
+0001f860: 6672 616d 6522 5d0a 2020 2020 2020 2020  frame"].        
+0001f870: 7469 6d65 6672 616d 655f 6666 203d 2073  timeframe_ff = s
+0001f880: 656c 662e 5f66 745f 6861 735b 2266 756e  elf._ft_has["fun
+0001f890: 6469 6e67 5f66 6565 5f74 696d 6566 7261  ding_fee_timefra
+0001f8a0: 6d65 225d 0a20 2020 2020 2020 206d 6172  me"].        mar
+0001f8b0: 6b5f 7072 6963 655f 7479 7065 203d 2043  k_price_type = C
+0001f8c0: 616e 646c 6554 7970 652e 6672 6f6d 5f73  andleType.from_s
+0001f8d0: 7472 696e 6728 7365 6c66 2e5f 6674 5f68  tring(self._ft_h
+0001f8e0: 6173 5b22 6d61 726b 5f6f 686c 6376 5f70  as["mark_ohlcv_p
+0001f8f0: 7269 6365 225d 290a 0a20 2020 2020 2020  rice"])..       
+0001f900: 2069 6620 6e6f 7420 636c 6f73 655f 6461   if not close_da
+0001f910: 7465 3a0a 2020 2020 2020 2020 2020 2020  te:.            
+0001f920: 636c 6f73 655f 6461 7465 203d 2064 6174  close_date = dat
+0001f930: 6574 696d 652e 6e6f 7728 7469 6d65 7a6f  etime.now(timezo
+0001f940: 6e65 2e75 7463 290a 2020 2020 2020 2020  ne.utc).        
+0001f950: 7369 6e63 655f 6d73 203d 2064 745f 7473  since_ms = dt_ts
+0001f960: 2874 696d 6566 7261 6d65 5f74 6f5f 7072  (timeframe_to_pr
+0001f970: 6576 5f64 6174 6528 7469 6d65 6672 616d  ev_date(timefram
+0001f980: 652c 206f 7065 6e5f 6461 7465 2929 0a0a  e, open_date))..
+0001f990: 2020 2020 2020 2020 6d61 726b 5f63 6f6d          mark_com
+0001f9a0: 623a 2050 6169 7257 6974 6854 696d 6566  b: PairWithTimef
+0001f9b0: 7261 6d65 203d 2028 7061 6972 2c20 7469  rame = (pair, ti
+0001f9c0: 6d65 6672 616d 652c 206d 6172 6b5f 7072  meframe, mark_pr
+0001f9d0: 6963 655f 7479 7065 290a 2020 2020 2020  ice_type).      
+0001f9e0: 2020 6675 6e64 696e 675f 636f 6d62 3a20    funding_comb: 
+0001f9f0: 5061 6972 5769 7468 5469 6d65 6672 616d  PairWithTimefram
+0001fa00: 6520 3d20 2870 6169 722c 2074 696d 6566  e = (pair, timef
+0001fa10: 7261 6d65 5f66 662c 2043 616e 646c 6554  rame_ff, CandleT
+0001fa20: 7970 652e 4655 4e44 494e 475f 5241 5445  ype.FUNDING_RATE
+0001fa30: 290a 0a20 2020 2020 2020 2063 616e 646c  )..        candl
+0001fa40: 655f 6869 7374 6f72 6965 7320 3d20 7365  e_histories = se
+0001fa50: 6c66 2e72 6566 7265 7368 5f6c 6174 6573  lf.refresh_lates
+0001fa60: 745f 6f68 6c63 7628 0a20 2020 2020 2020  t_ohlcv(.       
+0001fa70: 2020 2020 205b 6d61 726b 5f63 6f6d 622c       [mark_comb,
+0001fa80: 2066 756e 6469 6e67 5f63 6f6d 625d 2c0a   funding_comb],.
+0001fa90: 2020 2020 2020 2020 2020 2020 7369 6e63              sinc
+0001faa0: 655f 6d73 3d73 696e 6365 5f6d 732c 0a20  e_ms=since_ms,. 
+0001fab0: 2020 2020 2020 2020 2020 2063 6163 6865             cache
+0001fac0: 3d46 616c 7365 2c0a 2020 2020 2020 2020  =False,.        
+0001fad0: 2020 2020 6472 6f70 5f69 6e63 6f6d 706c      drop_incompl
+0001fae0: 6574 653d 4661 6c73 652c 0a20 2020 2020  ete=False,.     
+0001faf0: 2020 2029 0a20 2020 2020 2020 2074 7279     ).        try
+0001fb00: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
+0001fb10: 7765 2063 616e 2774 2061 7373 756d 6520  we can't assume 
+0001fb20: 7765 2061 6c77 6179 7320 6765 7420 6869  we always get hi
+0001fb30: 7374 6f72 6965 7320 2d20 666f 7220 6578  stories - for ex
+0001fb40: 616d 706c 6520 6475 7269 6e67 2065 7863  ample during exc
+0001fb50: 6861 6e67 6520 646f 776e 7469 6d65 730a  hange downtimes.
+0001fb60: 2020 2020 2020 2020 2020 2020 6675 6e64              fund
+0001fb70: 696e 675f 7261 7465 7320 3d20 6361 6e64  ing_rates = cand
+0001fb80: 6c65 5f68 6973 746f 7269 6573 5b66 756e  le_histories[fun
+0001fb90: 6469 6e67 5f63 6f6d 625d 0a20 2020 2020  ding_comb].     
+0001fba0: 2020 2020 2020 206d 6172 6b5f 7261 7465         mark_rate
+0001fbb0: 7320 3d20 6361 6e64 6c65 5f68 6973 746f  s = candle_histo
+0001fbc0: 7269 6573 5b6d 6172 6b5f 636f 6d62 5d0a  ries[mark_comb].
+0001fbd0: 2020 2020 2020 2020 6578 6365 7074 204b          except K
+0001fbe0: 6579 4572 726f 723a 0a20 2020 2020 2020  eyError:.       
+0001fbf0: 2020 2020 2072 6169 7365 2045 7863 6861       raise Excha
+0001fc00: 6e67 6545 7272 6f72 2822 436f 756c 6420  ngeError("Could 
+0001fc10: 6e6f 7420 6669 6e64 2066 756e 6469 6e67  not find funding
+0001fc20: 2072 6174 6573 2e22 2920 6672 6f6d 204e   rates.") from N
+0001fc30: 6f6e 650a 0a20 2020 2020 2020 2066 756e  one..        fun
+0001fc40: 6469 6e67 5f6d 6172 6b5f 7261 7465 7320  ding_mark_rates 
+0001fc50: 3d20 7365 6c66 2e63 6f6d 6269 6e65 5f66  = self.combine_f
+0001fc60: 756e 6469 6e67 5f61 6e64 5f6d 6172 6b28  unding_and_mark(
+0001fc70: 6675 6e64 696e 675f 7261 7465 732c 206d  funding_rates, m
+0001fc80: 6172 6b5f 7261 7465 7329 0a0a 2020 2020  ark_rates)..    
+0001fc90: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+0001fca0: 6361 6c63 756c 6174 655f 6675 6e64 696e  calculate_fundin
+0001fcb0: 675f 6665 6573 280a 2020 2020 2020 2020  g_fees(.        
+0001fcc0: 2020 2020 6675 6e64 696e 675f 6d61 726b      funding_mark
+0001fcd0: 5f72 6174 6573 2c0a 2020 2020 2020 2020  _rates,.        
+0001fce0: 2020 2020 616d 6f75 6e74 3d61 6d6f 756e      amount=amoun
+0001fcf0: 742c 0a20 2020 2020 2020 2020 2020 2069  t,.            i
+0001fd00: 735f 7368 6f72 743d 6973 5f73 686f 7274  s_short=is_short
+0001fd10: 2c0a 2020 2020 2020 2020 2020 2020 6f70  ,.            op
+0001fd20: 656e 5f64 6174 653d 6f70 656e 5f64 6174  en_date=open_dat
+0001fd30: 652c 0a20 2020 2020 2020 2020 2020 2063  e,.            c
+0001fd40: 6c6f 7365 5f64 6174 653d 636c 6f73 655f  lose_date=close_
+0001fd50: 6461 7465 2c0a 2020 2020 2020 2020 290a  date,.        ).
+0001fd60: 0a20 2020 2040 7374 6174 6963 6d65 7468  .    @staticmeth
+0001fd70: 6f64 0a20 2020 2064 6566 2063 6f6d 6269  od.    def combi
+0001fd80: 6e65 5f66 756e 6469 6e67 5f61 6e64 5f6d  ne_funding_and_m
+0001fd90: 6172 6b28 0a20 2020 2020 2020 2066 756e  ark(.        fun
+0001fda0: 6469 6e67 5f72 6174 6573 3a20 4461 7461  ding_rates: Data
+0001fdb0: 4672 616d 652c 206d 6172 6b5f 7261 7465  Frame, mark_rate
+0001fdc0: 733a 2044 6174 6146 7261 6d65 2c20 6675  s: DataFrame, fu
+0001fdd0: 7475 7265 735f 6675 6e64 696e 675f 7261  tures_funding_ra
+0001fde0: 7465 3a20 4f70 7469 6f6e 616c 5b69 6e74  te: Optional[int
+0001fdf0: 5d20 3d20 4e6f 6e65 0a20 2020 2029 202d  ] = None.    ) -
+0001fe00: 3e20 4461 7461 4672 616d 653a 0a20 2020  > DataFrame:.   
+0001fe10: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+0001fe20: 2043 6f6d 6269 6e65 2066 756e 6469 6e67   Combine funding
+0001fe30: 2d72 6174 6573 2061 6e64 206d 6172 6b2d  -rates and mark-
+0001fe40: 7261 7465 7320 6461 7461 6672 616d 6573  rates dataframes
+0001fe50: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0001fe60: 6675 6e64 696e 675f 7261 7465 733a 2044  funding_rates: D
+0001fe70: 6174 6166 7261 6d65 2063 6f6e 7461 696e  ataframe contain
+0001fe80: 696e 6720 4675 6e64 696e 6720 7261 7465  ing Funding rate
+0001fe90: 7320 2854 7970 6520 4655 4e44 494e 475f  s (Type FUNDING_
+0001fea0: 5241 5445 290a 2020 2020 2020 2020 3a70  RATE).        :p
+0001feb0: 6172 616d 206d 6172 6b5f 7261 7465 733a  aram mark_rates:
+0001fec0: 2044 6174 6166 7261 6d65 2063 6f6e 7461   Dataframe conta
+0001fed0: 696e 696e 6720 4d61 726b 2072 6174 6573  ining Mark rates
+0001fee0: 2028 5479 7065 206d 6172 6b5f 6f68 6c63   (Type mark_ohlc
+0001fef0: 765f 7072 6963 6529 0a20 2020 2020 2020  v_price).       
+0001ff00: 203a 7061 7261 6d20 6675 7475 7265 735f   :param futures_
+0001ff10: 6675 6e64 696e 675f 7261 7465 3a20 4661  funding_rate: Fa
+0001ff20: 6b65 2066 756e 6469 6e67 2072 6174 6520  ke funding rate 
+0001ff30: 746f 2075 7365 2069 6620 6675 6e64 696e  to use if fundin
+0001ff40: 675f 7261 7465 7320 6172 6520 6e6f 7420  g_rates are not 
+0001ff50: 6176 6169 6c61 626c 650a 2020 2020 2020  available.      
+0001ff60: 2020 2222 220a 2020 2020 2020 2020 6966    """.        if
+0001ff70: 2066 7574 7572 6573 5f66 756e 6469 6e67   futures_funding
+0001ff80: 5f72 6174 6520 6973 204e 6f6e 653a 0a20  _rate is None:. 
+0001ff90: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0001ffa0: 6e20 6d61 726b 5f72 6174 6573 2e6d 6572  n mark_rates.mer
+0001ffb0: 6765 280a 2020 2020 2020 2020 2020 2020  ge(.            
+0001ffc0: 2020 2020 6675 6e64 696e 675f 7261 7465      funding_rate
+0001ffd0: 732c 206f 6e3d 2264 6174 6522 2c20 686f  s, on="date", ho
+0001ffe0: 773d 2269 6e6e 6572 222c 2073 7566 6669  w="inner", suffi
+0001fff0: 7865 733d 5b22 5f6d 6172 6b22 2c20 225f  xes=["_mark", "_
+00020000: 6675 6e64 225d 0a20 2020 2020 2020 2020  fund"].         
+00020010: 2020 2029 0a20 2020 2020 2020 2065 6c73     ).        els
+00020020: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
+00020030: 6620 6c65 6e28 6675 6e64 696e 675f 7261  f len(funding_ra
+00020040: 7465 7329 203d 3d20 303a 0a20 2020 2020  tes) == 0:.     
+00020050: 2020 2020 2020 2020 2020 2023 204e 6f20             # No 
+00020060: 6675 6e64 696e 6720 7261 7465 2063 616e  funding rate can
+00020070: 646c 6573 202d 2066 756c 6c20 6669 6c6c  dles - full fill
+00020080: 7570 2077 6974 6820 6661 6c6c 6261 636b  up with fallback
+00020090: 2076 6172 6961 626c 650a 2020 2020 2020   variable.      
+000200a0: 2020 2020 2020 2020 2020 6d61 726b 5f72            mark_r
+000200b0: 6174 6573 5b22 6f70 656e 5f66 756e 6422  ates["open_fund"
+000200c0: 5d20 3d20 6675 7475 7265 735f 6675 6e64  ] = futures_fund
+000200d0: 696e 675f 7261 7465 0a20 2020 2020 2020  ing_rate.       
+000200e0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+000200f0: 6d61 726b 5f72 6174 6573 2e72 656e 616d  mark_rates.renam
+00020100: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
+00020110: 2020 2020 2020 2063 6f6c 756d 6e73 3d7b         columns={
+00020120: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00020130: 2020 2020 2020 2020 2022 6f70 656e 223a           "open":
+00020140: 2022 6f70 656e 5f6d 6172 6b22 2c0a 2020   "open_mark",.  
+00020150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020160: 2020 2020 2020 2263 6c6f 7365 223a 2022        "close": "
+00020170: 636c 6f73 655f 6d61 726b 222c 0a20 2020  close_mark",.   
+00020180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020190: 2020 2020 2022 6869 6768 223a 2022 6869       "high": "hi
+000201a0: 6768 5f6d 6172 6b22 2c0a 2020 2020 2020  gh_mark",.      
+000201b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000201c0: 2020 226c 6f77 223a 2022 6c6f 775f 6d61    "low": "low_ma
+000201d0: 726b 222c 0a20 2020 2020 2020 2020 2020  rk",.           
+000201e0: 2020 2020 2020 2020 2020 2020 2022 766f               "vo
+000201f0: 6c75 6d65 223a 2022 766f 6c75 6d65 5f6d  lume": "volume_m
+00020200: 6172 6b22 2c0a 2020 2020 2020 2020 2020  ark",.          
+00020210: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00020220: 2020 2020 2020 2020 2020 2020 290a 0a20              ).. 
+00020230: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00020240: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00020250: 2023 2046 696c 6c20 7570 206d 6973 7369   # Fill up missi
+00020260: 6e67 2066 756e 6469 6e67 5f72 6174 6520  ng funding_rate 
+00020270: 6361 6e64 6c65 7320 7769 7468 2066 616c  candles with fal
+00020280: 6c62 6163 6b20 7661 6c75 650a 2020 2020  lback value.    
+00020290: 2020 2020 2020 2020 2020 2020 636f 6d62              comb
+000202a0: 696e 6564 203d 206d 6172 6b5f 7261 7465  ined = mark_rate
+000202b0: 732e 6d65 7267 6528 0a20 2020 2020 2020  s.merge(.       
+000202c0: 2020 2020 2020 2020 2020 2020 2066 756e               fun
+000202d0: 6469 6e67 5f72 6174 6573 2c20 6f6e 3d22  ding_rates, on="
+000202e0: 6461 7465 222c 2068 6f77 3d22 6c65 6674  date", how="left
+000202f0: 222c 2073 7566 6669 7865 733d 5b22 5f6d  ", suffixes=["_m
+00020300: 6172 6b22 2c20 225f 6675 6e64 225d 0a20  ark", "_fund"]. 
+00020310: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00020320: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00020330: 2063 6f6d 6269 6e65 645b 226f 7065 6e5f   combined["open_
+00020340: 6675 6e64 225d 203d 2063 6f6d 6269 6e65  fund"] = combine
+00020350: 645b 226f 7065 6e5f 6675 6e64 225d 2e66  d["open_fund"].f
+00020360: 696c 6c6e 6128 6675 7475 7265 735f 6675  illna(futures_fu
+00020370: 6e64 696e 675f 7261 7465 290a 2020 2020  nding_rate).    
+00020380: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00020390: 726e 2063 6f6d 6269 6e65 640a 0a20 2020  rn combined..   
+000203a0: 2064 6566 2063 616c 6375 6c61 7465 5f66   def calculate_f
+000203b0: 756e 6469 6e67 5f66 6565 7328 0a20 2020  unding_fees(.   
+000203c0: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+000203d0: 2020 2064 663a 2044 6174 6146 7261 6d65     df: DataFrame
+000203e0: 2c0a 2020 2020 2020 2020 616d 6f75 6e74  ,.        amount
+000203f0: 3a20 666c 6f61 742c 0a20 2020 2020 2020  : float,.       
+00020400: 2069 735f 7368 6f72 743a 2062 6f6f 6c2c   is_short: bool,
+00020410: 0a20 2020 2020 2020 206f 7065 6e5f 6461  .        open_da
+00020420: 7465 3a20 6461 7465 7469 6d65 2c0a 2020  te: datetime,.  
+00020430: 2020 2020 2020 636c 6f73 655f 6461 7465        close_date
+00020440: 3a20 6461 7465 7469 6d65 2c0a 2020 2020  : datetime,.    
+00020450: 2020 2020 7469 6d65 5f69 6e5f 7261 7469      time_in_rati
+00020460: 6f3a 204f 7074 696f 6e61 6c5b 666c 6f61  o: Optional[floa
+00020470: 745d 203d 204e 6f6e 652c 0a20 2020 2029  t] = None,.    )
+00020480: 202d 3e20 666c 6f61 743a 0a20 2020 2020   -> float:.     
+00020490: 2020 2022 2222 0a20 2020 2020 2020 2063     """.        c
+000204a0: 616c 6375 6c61 7465 7320 7468 6520 7375  alculates the su
+000204b0: 6d20 6f66 2061 6c6c 2066 756e 6469 6e67  m of all funding
+000204c0: 2066 6565 7320 7468 6174 206f 6363 7572   fees that occur
+000204d0: 7265 6420 666f 7220 6120 7061 6972 2064  red for a pair d
+000204e0: 7572 696e 6720 6120 6675 7475 7265 7320  uring a futures 
+000204f0: 7472 6164 650a 2020 2020 2020 2020 3a70  trade.        :p
+00020500: 6172 616d 2064 663a 2044 6174 6166 7261  aram df: Datafra
+00020510: 6d65 2063 6f6e 7461 696e 696e 6720 636f  me containing co
+00020520: 6d62 696e 6564 2066 756e 6469 6e67 2061  mbined funding a
+00020530: 6e64 206d 6172 6b20 7261 7465 730a 2020  nd mark rates.  
+00020540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020550: 2061 7320 606f 7065 6e5f 6675 6e64 6020   as `open_fund` 
+00020560: 616e 6420 606f 7065 6e5f 6d61 726b 602e  and `open_mark`.
+00020570: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00020580: 616d 6f75 6e74 3a20 5468 6520 7175 616e  amount: The quan
+00020590: 7469 7479 206f 6620 7468 6520 7472 6164  tity of the trad
+000205a0: 650a 2020 2020 2020 2020 3a70 6172 616d  e.        :param
+000205b0: 2069 735f 7368 6f72 743a 2074 7261 6465   is_short: trade
+000205c0: 2064 6972 6563 7469 6f6e 0a20 2020 2020   direction.     
+000205d0: 2020 203a 7061 7261 6d20 6f70 656e 5f64     :param open_d
+000205e0: 6174 653a 2054 6865 2064 6174 6520 616e  ate: The date an
+000205f0: 6420 7469 6d65 2074 6861 7420 7468 6520  d time that the 
+00020600: 7472 6164 6520 7374 6172 7465 640a 2020  trade started.  
+00020610: 2020 2020 2020 3a70 6172 616d 2063 6c6f        :param clo
+00020620: 7365 5f64 6174 653a 2054 6865 2064 6174  se_date: The dat
+00020630: 6520 616e 6420 7469 6d65 2074 6861 7420  e and time that 
+00020640: 7468 6520 7472 6164 6520 656e 6465 640a  the trade ended.
+00020650: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
+00020660: 696d 655f 696e 5f72 6174 696f 3a20 4e6f  ime_in_ratio: No
+00020670: 7420 7573 6564 2062 7920 6d6f 7374 2065  t used by most e
+00020680: 7863 6861 6e67 6520 636c 6173 7365 730a  xchange classes.
+00020690: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+000206a0: 2020 2020 6665 6573 3a20 666c 6f61 7420      fees: float 
+000206b0: 3d20 300a 0a20 2020 2020 2020 2069 6620  = 0..        if 
+000206c0: 6e6f 7420 6466 2e65 6d70 7479 3a0a 2020  not df.empty:.  
+000206d0: 2020 2020 2020 2020 2020 6466 3120 3d20            df1 = 
+000206e0: 6466 5b28 6466 5b22 6461 7465 225d 203e  df[(df["date"] >
+000206f0: 3d20 6f70 656e 5f64 6174 6529 2026 2028  = open_date) & (
+00020700: 6466 5b22 6461 7465 225d 203c 3d20 636c  df["date"] <= cl
+00020710: 6f73 655f 6461 7465 295d 0a20 2020 2020  ose_date)].     
+00020720: 2020 2020 2020 2066 6565 7320 3d20 7375         fees = su
+00020730: 6d28 6466 315b 226f 7065 6e5f 6675 6e64  m(df1["open_fund
+00020740: 225d 202a 2064 6631 5b22 6f70 656e 5f6d  "] * df1["open_m
+00020750: 6172 6b22 5d20 2a20 616d 6f75 6e74 290a  ark"] * amount).
+00020760: 2020 2020 2020 2020 6966 2069 736e 616e          if isnan
+00020770: 2866 6565 7329 3a0a 2020 2020 2020 2020  (fees):.        
+00020780: 2020 2020 6665 6573 203d 2030 2e30 0a20      fees = 0.0. 
+00020790: 2020 2020 2020 2023 204e 6567 6174 6520         # Negate 
+000207a0: 6665 6573 2066 6f72 206c 6f6e 6773 2061  fees for longs a
+000207b0: 7320 6675 6e64 696e 675f 6665 6573 2065  s funding_fees e
+000207c0: 7870 6563 7473 2069 7420 7468 6973 2077  xpects it this w
+000207d0: 6179 2062 6173 6564 206f 6e20 6c69 7665  ay based on live
+000207e0: 2065 6e64 706f 696e 7473 2e0a 2020 2020   endpoints..    
+000207f0: 2020 2020 7265 7475 726e 2066 6565 7320      return fees 
+00020800: 6966 2069 735f 7368 6f72 7420 656c 7365  if is_short else
+00020810: 202d 6665 6573 0a0a 2020 2020 6465 6620   -fees..    def 
+00020820: 6765 745f 6675 6e64 696e 675f 6665 6573  get_funding_fees
+00020830: 280a 2020 2020 2020 2020 7365 6c66 2c20  (.        self, 
+00020840: 7061 6972 3a20 7374 722c 2061 6d6f 756e  pair: str, amoun
+00020850: 743a 2066 6c6f 6174 2c20 6973 5f73 686f  t: float, is_sho
+00020860: 7274 3a20 626f 6f6c 2c20 6f70 656e 5f64  rt: bool, open_d
+00020870: 6174 653a 2064 6174 6574 696d 650a 2020  ate: datetime.  
+00020880: 2020 2920 2d3e 2066 6c6f 6174 3a0a 2020    ) -> float:.  
+00020890: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+000208a0: 2020 4665 7463 6820 6675 6e64 696e 6720    Fetch funding 
+000208b0: 6665 6573 2c20 6569 7468 6572 2066 726f  fees, either fro
+000208c0: 6d20 7468 6520 6578 6368 616e 6765 2028  m the exchange (
+000208d0: 6c69 7665 2920 6f72 2063 616c 6375 6c61  live) or calcula
+000208e0: 7465 7320 7468 656d 0a20 2020 2020 2020  tes them.       
+000208f0: 2062 6173 6564 206f 6e20 6675 6e64 696e   based on fundin
+00020900: 6720 7261 7465 2f6d 6172 6b20 7072 6963  g rate/mark pric
+00020910: 6520 6869 7374 6f72 790a 2020 2020 2020  e history.      
+00020920: 2020 3a70 6172 616d 2070 6169 723a 2054    :param pair: T
+00020930: 6865 2071 756f 7465 2f62 6173 6520 7061  he quote/base pa
+00020940: 6972 206f 6620 7468 6520 7472 6164 650a  ir of the trade.
+00020950: 2020 2020 2020 2020 3a70 6172 616d 2069          :param i
+00020960: 735f 7368 6f72 743a 2074 7261 6465 2064  s_short: trade d
+00020970: 6972 6563 7469 6f6e 0a20 2020 2020 2020  irection.       
+00020980: 203a 7061 7261 6d20 616d 6f75 6e74 3a20   :param amount: 
+00020990: 5472 6164 6520 616d 6f75 6e74 0a20 2020  Trade amount.   
+000209a0: 2020 2020 203a 7061 7261 6d20 6f70 656e       :param open
+000209b0: 5f64 6174 653a 204f 7065 6e20 6461 7465  _date: Open date
+000209c0: 206f 6620 7468 6520 7472 6164 650a 2020   of the trade.  
+000209d0: 2020 2020 2020 3a72 6574 7572 6e3a 2066        :return: f
+000209e0: 756e 6469 6e67 2066 6565 2073 696e 6365  unding fee since
+000209f0: 206f 7065 6e5f 6461 7465 0a20 2020 2020   open_date.     
+00020a00: 2020 2022 2222 0a20 2020 2020 2020 2069     """.        i
+00020a10: 6620 7365 6c66 2e74 7261 6469 6e67 5f6d  f self.trading_m
+00020a20: 6f64 6520 3d3d 2054 7261 6469 6e67 4d6f  ode == TradingMo
+00020a30: 6465 2e46 5554 5552 4553 3a0a 2020 2020  de.FUTURES:.    
+00020a40: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+00020a50: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00020a60: 7365 6c66 2e5f 636f 6e66 6967 5b22 6472  self._config["dr
+00020a70: 795f 7275 6e22 5d3a 0a20 2020 2020 2020  y_run"]:.       
+00020a80: 2020 2020 2020 2020 2020 2020 2066 756e               fun
+00020a90: 6469 6e67 5f66 6565 7320 3d20 7365 6c66  ding_fees = self
+00020aa0: 2e5f 6665 7463 685f 616e 645f 6361 6c63  ._fetch_and_calc
+00020ab0: 756c 6174 655f 6675 6e64 696e 675f 6665  ulate_funding_fe
+00020ac0: 6573 280a 2020 2020 2020 2020 2020 2020  es(.            
+00020ad0: 2020 2020 2020 2020 2020 2020 7061 6972              pair
+00020ae0: 2c20 616d 6f75 6e74 2c20 6973 5f73 686f  , amount, is_sho
+00020af0: 7274 2c20 6f70 656e 5f64 6174 650a 2020  rt, open_date.  
+00020b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020b10: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00020b20: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00020b30: 2020 2020 2020 2020 2020 2020 2020 6675                fu
+00020b40: 6e64 696e 675f 6665 6573 203d 2073 656c  nding_fees = sel
+00020b50: 662e 5f67 6574 5f66 756e 6469 6e67 5f66  f._get_funding_f
+00020b60: 6565 735f 6672 6f6d 5f65 7863 6861 6e67  ees_from_exchang
+00020b70: 6528 7061 6972 2c20 6f70 656e 5f64 6174  e(pair, open_dat
+00020b80: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+00020b90: 2020 2072 6574 7572 6e20 6675 6e64 696e     return fundin
+00020ba0: 675f 6665 6573 0a20 2020 2020 2020 2020  g_fees.         
+00020bb0: 2020 2065 7863 6570 7420 4578 6368 616e     except Exchan
+00020bc0: 6765 4572 726f 723a 0a20 2020 2020 2020  geError:.       
+00020bd0: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+00020be0: 7761 726e 696e 6728 6622 436f 756c 6420  warning(f"Could 
+00020bf0: 6e6f 7420 7570 6461 7465 2066 756e 6469  not update fundi
+00020c00: 6e67 2066 6565 7320 666f 7220 7b70 6169  ng fees for {pai
+00020c10: 727d 2e22 290a 0a20 2020 2020 2020 2072  r}.")..        r
+00020c20: 6574 7572 6e20 302e 300a 0a20 2020 2064  eturn 0.0..    d
+00020c30: 6566 2067 6574 5f6c 6971 7569 6461 7469  ef get_liquidati
+00020c40: 6f6e 5f70 7269 6365 280a 2020 2020 2020  on_price(.      
+00020c50: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
+00020c60: 7061 6972 3a20 7374 722c 0a20 2020 2020  pair: str,.     
+00020c70: 2020 2023 2044 7279 2d72 756e 0a20 2020     # Dry-run.   
+00020c80: 2020 2020 206f 7065 6e5f 7261 7465 3a20       open_rate: 
+00020c90: 666c 6f61 742c 2020 2320 456e 7472 7920  float,  # Entry 
+00020ca0: 7072 6963 6520 6f66 2070 6f73 6974 696f  price of positio
+00020cb0: 6e0a 2020 2020 2020 2020 6973 5f73 686f  n.        is_sho
+00020cc0: 7274 3a20 626f 6f6c 2c0a 2020 2020 2020  rt: bool,.      
+00020cd0: 2020 616d 6f75 6e74 3a20 666c 6f61 742c    amount: float,
+00020ce0: 2020 2320 4162 736f 6c75 7465 2076 616c    # Absolute val
+00020cf0: 7565 206f 6620 706f 7369 7469 6f6e 2073  ue of position s
+00020d00: 697a 650a 2020 2020 2020 2020 7374 616b  ize.        stak
+00020d10: 655f 616d 6f75 6e74 3a20 666c 6f61 742c  e_amount: float,
+00020d20: 0a20 2020 2020 2020 206c 6576 6572 6167  .        leverag
+00020d30: 653a 2066 6c6f 6174 2c0a 2020 2020 2020  e: float,.      
+00020d40: 2020 7761 6c6c 6574 5f62 616c 616e 6365    wallet_balance
+00020d50: 3a20 666c 6f61 742c 0a20 2020 2020 2020  : float,.       
+00020d60: 206d 6d5f 6578 5f31 3a20 666c 6f61 7420   mm_ex_1: float 
+00020d70: 3d20 302e 302c 2020 2320 2842 696e 616e  = 0.0,  # (Binan
+00020d80: 6365 2920 4372 6f73 7320 6f6e 6c79 0a20  ce) Cross only. 
+00020d90: 2020 2020 2020 2075 706e 6c5f 6578 5f31         upnl_ex_1
+00020da0: 3a20 666c 6f61 7420 3d20 302e 302c 2020  : float = 0.0,  
+00020db0: 2320 2842 696e 616e 6365 2920 4372 6f73  # (Binance) Cros
+00020dc0: 7320 6f6e 6c79 0a20 2020 2029 202d 3e20  s only.    ) -> 
+00020dd0: 4f70 7469 6f6e 616c 5b66 6c6f 6174 5d3a  Optional[float]:
+00020de0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00020df0: 2020 2020 2053 6574 2773 2074 6865 206d       Set's the m
+00020e00: 6172 6769 6e20 6d6f 6465 206f 6e20 7468  argin mode on th
+00020e10: 6520 6578 6368 616e 6765 2074 6f20 6372  e exchange to cr
+00020e20: 6f73 7320 6f72 2069 736f 6c61 7465 6420  oss or isolated 
+00020e30: 666f 7220 6120 7370 6563 6966 6963 2070  for a specific p
+00020e40: 6169 720a 2020 2020 2020 2020 2222 220a  air.        """.
+00020e50: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00020e60: 7472 6164 696e 675f 6d6f 6465 203d 3d20  trading_mode == 
+00020e70: 5472 6164 696e 674d 6f64 652e 5350 4f54  TradingMode.SPOT
+00020e80: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
+00020e90: 7475 726e 204e 6f6e 650a 2020 2020 2020  turn None.      
+00020ea0: 2020 656c 6966 2073 656c 662e 7472 6164    elif self.trad
+00020eb0: 696e 675f 6d6f 6465 2021 3d20 5472 6164  ing_mode != Trad
+00020ec0: 696e 674d 6f64 652e 4655 5455 5245 533a  ingMode.FUTURES:
+00020ed0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00020ee0: 7365 204f 7065 7261 7469 6f6e 616c 4578  se OperationalEx
+00020ef0: 6365 7074 696f 6e28 0a20 2020 2020 2020  ception(.       
+00020f00: 2020 2020 2020 2020 2066 227b 7365 6c66           f"{self
+00020f10: 2e6e 616d 657d 2064 6f65 7320 6e6f 7420  .name} does not 
+00020f20: 7375 7070 6f72 7420 7b73 656c 662e 6d61  support {self.ma
+00020f30: 7267 696e 5f6d 6f64 657d 207b 7365 6c66  rgin_mode} {self
+00020f40: 2e74 7261 6469 6e67 5f6d 6f64 657d 220a  .trading_mode}".
+00020f50: 2020 2020 2020 2020 2020 2020 290a 0a20              ).. 
+00020f60: 2020 2020 2020 206c 6971 7569 6461 7469         liquidati
+00020f70: 6f6e 5f70 7269 6365 203d 204e 6f6e 650a  on_price = None.
+00020f80: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00020f90: 5f63 6f6e 6669 675b 2264 7279 5f72 756e  _config["dry_run
+00020fa0: 225d 206f 7220 6e6f 7420 7365 6c66 2e65  "] or not self.e
+00020fb0: 7863 6861 6e67 655f 6861 7328 2266 6574  xchange_has("fet
+00020fc0: 6368 506f 7369 7469 6f6e 7322 293a 0a20  chPositions"):. 
+00020fd0: 2020 2020 2020 2020 2020 206c 6971 7569             liqui
+00020fe0: 6461 7469 6f6e 5f70 7269 6365 203d 2073  dation_price = s
+00020ff0: 656c 662e 6472 795f 7275 6e5f 6c69 7175  elf.dry_run_liqu
+00021000: 6964 6174 696f 6e5f 7072 6963 6528 0a20  idation_price(. 
+00021010: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00021020: 6169 723d 7061 6972 2c0a 2020 2020 2020  air=pair,.      
+00021030: 2020 2020 2020 2020 2020 6f70 656e 5f72            open_r
+00021040: 6174 653d 6f70 656e 5f72 6174 652c 0a20  ate=open_rate,. 
+00021050: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00021060: 735f 7368 6f72 743d 6973 5f73 686f 7274  s_short=is_short
+00021070: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00021080: 2020 616d 6f75 6e74 3d61 6d6f 756e 742c    amount=amount,
+00021090: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000210a0: 206c 6576 6572 6167 653d 6c65 7665 7261   leverage=levera
+000210b0: 6765 2c0a 2020 2020 2020 2020 2020 2020  ge,.            
+000210c0: 2020 2020 7374 616b 655f 616d 6f75 6e74      stake_amount
+000210d0: 3d73 7461 6b65 5f61 6d6f 756e 742c 0a20  =stake_amount,. 
+000210e0: 2020 2020 2020 2020 2020 2020 2020 2077                 w
+000210f0: 616c 6c65 745f 6261 6c61 6e63 653d 7761  allet_balance=wa
+00021100: 6c6c 6574 5f62 616c 616e 6365 2c0a 2020  llet_balance,.  
+00021110: 2020 2020 2020 2020 2020 2020 2020 6d6d                mm
+00021120: 5f65 785f 313d 6d6d 5f65 785f 312c 0a20  _ex_1=mm_ex_1,. 
+00021130: 2020 2020 2020 2020 2020 2020 2020 2075                 u
+00021140: 706e 6c5f 6578 5f31 3d75 706e 6c5f 6578  pnl_ex_1=upnl_ex
+00021150: 5f31 2c0a 2020 2020 2020 2020 2020 2020  _1,.            
+00021160: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
+00021170: 2020 2020 2020 2020 2020 2020 706f 7369              posi
+00021180: 7469 6f6e 7320 3d20 7365 6c66 2e66 6574  tions = self.fet
+00021190: 6368 5f70 6f73 6974 696f 6e73 2870 6169  ch_positions(pai
+000211a0: 7229 0a20 2020 2020 2020 2020 2020 2069  r).            i
+000211b0: 6620 6c65 6e28 706f 7369 7469 6f6e 7329  f len(positions)
+000211c0: 203e 2030 3a0a 2020 2020 2020 2020 2020   > 0:.          
+000211d0: 2020 2020 2020 706f 7320 3d20 706f 7369        pos = posi
+000211e0: 7469 6f6e 735b 305d 0a20 2020 2020 2020  tions[0].       
+000211f0: 2020 2020 2020 2020 206c 6971 7569 6461           liquida
+00021200: 7469 6f6e 5f70 7269 6365 203d 2070 6f73  tion_price = pos
+00021210: 5b22 6c69 7175 6964 6174 696f 6e50 7269  ["liquidationPri
+00021220: 6365 225d 0a0a 2020 2020 2020 2020 6966  ce"]..        if
+00021230: 206c 6971 7569 6461 7469 6f6e 5f70 7269   liquidation_pri
+00021240: 6365 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ce is not None:.
+00021250: 2020 2020 2020 2020 2020 2020 6275 6666              buff
+00021260: 6572 5f61 6d6f 756e 7420 3d20 6162 7328  er_amount = abs(
+00021270: 6f70 656e 5f72 6174 6520 2d20 6c69 7175  open_rate - liqu
+00021280: 6964 6174 696f 6e5f 7072 6963 6529 202a  idation_price) *
+00021290: 2073 656c 662e 6c69 7175 6964 6174 696f   self.liquidatio
+000212a0: 6e5f 6275 6666 6572 0a20 2020 2020 2020  n_buffer.       
+000212b0: 2020 2020 206c 6971 7569 6461 7469 6f6e       liquidation
+000212c0: 5f70 7269 6365 5f62 7566 6665 7220 3d20  _price_buffer = 
+000212d0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+000212e0: 2020 6c69 7175 6964 6174 696f 6e5f 7072    liquidation_pr
+000212f0: 6963 6520 2d20 6275 6666 6572 5f61 6d6f  ice - buffer_amo
+00021300: 756e 7420 6966 2069 735f 7368 6f72 7420  unt if is_short 
+00021310: 656c 7365 206c 6971 7569 6461 7469 6f6e  else liquidation
+00021320: 5f70 7269 6365 202b 2062 7566 6665 725f  _price + buffer_
+00021330: 616d 6f75 6e74 0a20 2020 2020 2020 2020  amount.         
+00021340: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00021350: 2072 6574 7572 6e20 6d61 7828 6c69 7175   return max(liqu
+00021360: 6964 6174 696f 6e5f 7072 6963 655f 6275  idation_price_bu
+00021370: 6666 6572 2c20 302e 3029 0a20 2020 2020  ffer, 0.0).     
+00021380: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00021390: 2020 2020 2072 6574 7572 6e20 4e6f 6e65       return None
+000213a0: 0a0a 2020 2020 6465 6620 6472 795f 7275  ..    def dry_ru
+000213b0: 6e5f 6c69 7175 6964 6174 696f 6e5f 7072  n_liquidation_pr
+000213c0: 6963 6528 0a20 2020 2020 2020 2073 656c  ice(.        sel
+000213d0: 662c 0a20 2020 2020 2020 2070 6169 723a  f,.        pair:
+000213e0: 2073 7472 2c0a 2020 2020 2020 2020 6f70   str,.        op
+000213f0: 656e 5f72 6174 653a 2066 6c6f 6174 2c20  en_rate: float, 
+00021400: 2023 2045 6e74 7279 2070 7269 6365 206f   # Entry price o
+00021410: 6620 706f 7369 7469 6f6e 0a20 2020 2020  f position.     
+00021420: 2020 2069 735f 7368 6f72 743a 2062 6f6f     is_short: boo
+00021430: 6c2c 0a20 2020 2020 2020 2061 6d6f 756e  l,.        amoun
+00021440: 743a 2066 6c6f 6174 2c0a 2020 2020 2020  t: float,.      
+00021450: 2020 7374 616b 655f 616d 6f75 6e74 3a20    stake_amount: 
+00021460: 666c 6f61 742c 0a20 2020 2020 2020 206c  float,.        l
+00021470: 6576 6572 6167 653a 2066 6c6f 6174 2c0a  everage: float,.
+00021480: 2020 2020 2020 2020 7761 6c6c 6574 5f62          wallet_b
+00021490: 616c 616e 6365 3a20 666c 6f61 742c 2020  alance: float,  
+000214a0: 2320 4f72 206d 6172 6769 6e20 6261 6c61  # Or margin bala
+000214b0: 6e63 650a 2020 2020 2020 2020 6d6d 5f65  nce.        mm_e
+000214c0: 785f 313a 2066 6c6f 6174 203d 2030 2e30  x_1: float = 0.0
+000214d0: 2c20 2023 2028 4269 6e61 6e63 6529 2043  ,  # (Binance) C
+000214e0: 726f 7373 206f 6e6c 790a 2020 2020 2020  ross only.      
+000214f0: 2020 7570 6e6c 5f65 785f 313a 2066 6c6f    upnl_ex_1: flo
+00021500: 6174 203d 2030 2e30 2c20 2023 2028 4269  at = 0.0,  # (Bi
+00021510: 6e61 6e63 6529 2043 726f 7373 206f 6e6c  nance) Cross onl
+00021520: 790a 2020 2020 2920 2d3e 204f 7074 696f  y.    ) -> Optio
+00021530: 6e61 6c5b 666c 6f61 745d 3a0a 2020 2020  nal[float]:.    
+00021540: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00021550: 496d 706f 7274 616e 743a 204d 7573 7420  Important: Must 
+00021560: 6265 2066 6574 6368 696e 6720 6461 7461  be fetching data
+00021570: 2066 726f 6d20 6361 6368 6564 2076 616c   from cached val
+00021580: 7565 7320 6173 2074 6869 7320 6973 2075  ues as this is u
+00021590: 7365 6420 6279 2062 6163 6b74 6573 7469  sed by backtesti
+000215a0: 6e67 210a 2020 2020 2020 2020 5045 5250  ng!.        PERP
+000215b0: 4554 5541 4c3a 0a20 2020 2020 2020 2020  ETUAL:.         
+000215c0: 6761 7465 3a20 6874 7470 733a 2f2f 7777  gate: https://ww
+000215d0: 772e 6761 7465 2e69 6f2f 6865 6c70 2f66  w.gate.io/help/f
+000215e0: 7574 7572 6573 2f66 7574 7572 6573 2f32  utures/futures/2
+000215f0: 3737 3234 2f6c 6971 7569 6461 7469 6f6e  7724/liquidation
+00021600: 2d70 7269 6365 2d62 616e 6b72 7570 7463  -price-bankruptc
+00021610: 792d 7072 6963 650a 2020 2020 2020 2020  y-price.        
+00021620: 203e 204c 6971 7569 6461 7469 6f6e 2050   > Liquidation P
+00021630: 7269 6365 203d 2028 456e 7472 7920 5072  rice = (Entry Pr
+00021640: 6963 6520 c2b1 204d 6172 6769 6e20 2f20  ice .. Margin / 
+00021650: 436f 6e74 7261 6374 204d 756c 7469 706c  Contract Multipl
+00021660: 6965 7220 2f20 5369 7a65 2920 2f0a 2020  ier / Size) /.  
+00021670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00021680: 2020 2020 2020 2020 2020 2020 2020 5b20                [ 
+00021690: 3120 c2b1 2028 4d61 696e 7465 6e61 6e63  1 .. (Maintenanc
+000216a0: 6520 4d61 7267 696e 2052 6174 696f 202b  e Margin Ratio +
+000216b0: 2054 616b 6572 2052 6174 6529 5d0a 2020   Taker Rate)].  
+000216c0: 2020 2020 2020 2020 2020 5768 6572 6569            Wherei
+000216d0: 6e2c 2022 2b22 206f 7220 222d 2220 6465  n, "+" or "-" de
+000216e0: 7065 6e64 7320 6f6e 2077 6865 7468 6572  pends on whether
+000216f0: 2074 6865 2063 6f6e 7472 6163 7420 676f   the contract go
+00021700: 6573 206c 6f6e 6720 6f72 2073 686f 7274  es long or short
+00021710: 3a0a 2020 2020 2020 2020 2020 2020 222d  :.            "-
+00021720: 2220 666f 7220 6c6f 6e67 2c20 616e 6420  " for long, and 
+00021730: 222b 2220 666f 7220 7368 6f72 742e 0a0a  "+" for short...
+00021740: 2020 2020 2020 2020 206f 6b65 783a 2068           okex: h
+00021750: 7474 7073 3a2f 2f77 7777 2e6f 6b65 782e  ttps://www.okex.
+00021760: 636f 6d2f 7375 7070 6f72 742f 6863 2f65  com/support/hc/e
+00021770: 6e2d 7573 2f61 7274 6963 6c65 732f 0a20  n-us/articles/. 
+00021780: 2020 2020 2020 2020 2020 2033 3630 3035             36005
+00021790: 3339 3039 3539 322d 5649 2d49 6e74 726f  3909592-VI-Intro
+000217a0: 6475 6374 696f 6e2d 746f 2d74 6865 2d69  duction-to-the-i
+000217b0: 736f 6c61 7465 642d 6d6f 6465 2d6f 662d  solated-mode-of-
+000217c0: 5369 6e67 6c65 2d4d 756c 7469 2d63 7572  Single-Multi-cur
+000217d0: 7265 6e63 792d 506f 7274 666f 6c69 6f2d  rency-Portfolio-
+000217e0: 6d61 7267 696e 0a0a 2020 2020 2020 2020  margin..        
+000217f0: 3a70 6172 616d 2070 6169 723a 2050 6169  :param pair: Pai
+00021800: 7220 746f 2063 616c 6375 6c61 7465 206c  r to calculate l
+00021810: 6971 7569 6461 7469 6f6e 2070 7269 6365  iquidation price
+00021820: 2066 6f72 0a20 2020 2020 2020 203a 7061   for.        :pa
+00021830: 7261 6d20 6f70 656e 5f72 6174 653a 2045  ram open_rate: E
+00021840: 6e74 7279 2070 7269 6365 206f 6620 706f  ntry price of po
+00021850: 7369 7469 6f6e 0a20 2020 2020 2020 203a  sition.        :
+00021860: 7061 7261 6d20 6973 5f73 686f 7274 3a20  param is_short: 
+00021870: 5472 7565 2069 6620 7468 6520 7472 6164  True if the trad
+00021880: 6520 6973 2061 2073 686f 7274 2c20 6661  e is a short, fa
+00021890: 6c73 6520 6f74 6865 7277 6973 650a 2020  lse otherwise.  
+000218a0: 2020 2020 2020 3a70 6172 616d 2061 6d6f        :param amo
+000218b0: 756e 743a 2041 6273 6f6c 7574 6520 7661  unt: Absolute va
+000218c0: 6c75 6520 6f66 2070 6f73 6974 696f 6e20  lue of position 
+000218d0: 7369 7a65 2069 6e63 6c2e 206c 6576 6572  size incl. lever
+000218e0: 6167 6520 2869 6e20 6261 7365 2063 7572  age (in base cur
+000218f0: 7265 6e63 7929 0a20 2020 2020 2020 203a  rency).        :
+00021900: 7061 7261 6d20 7374 616b 655f 616d 6f75  param stake_amou
+00021910: 6e74 3a20 5374 616b 6520 616d 6f75 6e74  nt: Stake amount
+00021920: 202d 2043 6f6c 6c61 7465 7261 6c20 696e   - Collateral in
+00021930: 2073 6574 746c 6520 6375 7272 656e 6379   settle currency
+00021940: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+00021950: 206c 6576 6572 6167 653a 204c 6576 6572   leverage: Lever
+00021960: 6167 6520 7573 6564 2066 6f72 2074 6869  age used for thi
+00021970: 7320 706f 7369 7469 6f6e 2e0a 2020 2020  s position..    
+00021980: 2020 2020 3a70 6172 616d 2074 7261 6469      :param tradi
+00021990: 6e67 5f6d 6f64 653a 2053 504f 542c 204d  ng_mode: SPOT, M
+000219a0: 4152 4749 4e2c 2046 5554 5552 4553 2c20  ARGIN, FUTURES, 
+000219b0: 6574 632e 0a20 2020 2020 2020 203a 7061  etc..        :pa
+000219c0: 7261 6d20 6d61 7267 696e 5f6d 6f64 653a  ram margin_mode:
+000219d0: 2045 6974 6865 7220 4953 4f4c 4154 4544   Either ISOLATED
+000219e0: 206f 7220 4352 4f53 530a 2020 2020 2020   or CROSS.      
+000219f0: 2020 3a70 6172 616d 2077 616c 6c65 745f    :param wallet_
+00021a00: 6261 6c61 6e63 653a 2041 6d6f 756e 7420  balance: Amount 
+00021a10: 6f66 206d 6172 6769 6e5f 6d6f 6465 2069  of margin_mode i
+00021a20: 6e20 7468 6520 7761 6c6c 6574 2062 6569  n the wallet bei
+00021a30: 6e67 2075 7365 6420 746f 2074 7261 6465  ng used to trade
+00021a40: 0a20 2020 2020 2020 2020 2020 2043 726f  .            Cro
+00021a50: 7373 2d4d 6172 6769 6e20 4d6f 6465 3a20  ss-Margin Mode: 
+00021a60: 6372 6f73 7357 616c 6c65 7442 616c 616e  crossWalletBalan
+00021a70: 6365 0a20 2020 2020 2020 2020 2020 2049  ce.            I
+00021a80: 736f 6c61 7465 642d 4d61 7267 696e 204d  solated-Margin M
+00021a90: 6f64 653a 2069 736f 6c61 7465 6457 616c  ode: isolatedWal
+00021aa0: 6c65 7442 616c 616e 6365 0a0a 2020 2020  letBalance..    
+00021ab0: 2020 2020 2320 2a20 4e6f 7420 7265 7175      # * Not requ
+00021ac0: 6972 6564 2062 7920 4761 7465 206f 7220  ired by Gate or 
+00021ad0: 4f4b 580a 2020 2020 2020 2020 3a70 6172  OKX.        :par
+00021ae0: 616d 206d 6d5f 6578 5f31 3a0a 2020 2020  am mm_ex_1:.    
+00021af0: 2020 2020 3a70 6172 616d 2075 706e 6c5f      :param upnl_
+00021b00: 6578 5f31 3a0a 2020 2020 2020 2020 2222  ex_1:.        ""
+00021b10: 220a 0a20 2020 2020 2020 206d 6172 6b65  "..        marke
+00021b20: 7420 3d20 7365 6c66 2e6d 6172 6b65 7473  t = self.markets
+00021b30: 5b70 6169 725d 0a20 2020 2020 2020 2074  [pair].        t
+00021b40: 616b 6572 5f66 6565 5f72 6174 6520 3d20  aker_fee_rate = 
+00021b50: 6d61 726b 6574 5b22 7461 6b65 7222 5d0a  market["taker"].
+00021b60: 2020 2020 2020 2020 6d6d 5f72 6174 696f          mm_ratio
+00021b70: 2c20 5f20 3d20 7365 6c66 2e67 6574 5f6d  , _ = self.get_m
+00021b80: 6169 6e74 656e 616e 6365 5f72 6174 696f  aintenance_ratio
+00021b90: 5f61 6e64 5f61 6d74 2870 6169 722c 2073  _and_amt(pair, s
+00021ba0: 7461 6b65 5f61 6d6f 756e 7429 0a0a 2020  take_amount)..  
+00021bb0: 2020 2020 2020 6966 2073 656c 662e 7472        if self.tr
+00021bc0: 6164 696e 675f 6d6f 6465 203d 3d20 5472  ading_mode == Tr
+00021bd0: 6164 696e 674d 6f64 652e 4655 5455 5245  adingMode.FUTURE
+00021be0: 5320 616e 6420 7365 6c66 2e6d 6172 6769  S and self.margi
+00021bf0: 6e5f 6d6f 6465 203d 3d20 4d61 7267 696e  n_mode == Margin
+00021c00: 4d6f 6465 2e49 534f 4c41 5445 443a 0a20  Mode.ISOLATED:. 
+00021c10: 2020 2020 2020 2020 2020 2069 6620 6d61             if ma
+00021c20: 726b 6574 5b22 696e 7665 7273 6522 5d3a  rket["inverse"]:
+00021c30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00021c40: 2072 6169 7365 204f 7065 7261 7469 6f6e   raise Operation
+00021c50: 616c 4578 6365 7074 696f 6e28 2246 7265  alException("Fre
+00021c60: 7174 7261 6465 2064 6f65 7320 6e6f 7420  qtrade does not 
+00021c70: 7965 7420 7375 7070 6f72 7420 696e 7665  yet support inve
+00021c80: 7273 6520 636f 6e74 7261 6374 7322 290a  rse contracts").
+00021c90: 0a20 2020 2020 2020 2020 2020 2076 616c  .            val
+00021ca0: 7565 203d 2077 616c 6c65 745f 6261 6c61  ue = wallet_bala
+00021cb0: 6e63 6520 2f20 616d 6f75 6e74 0a0a 2020  nce / amount..  
+00021cc0: 2020 2020 2020 2020 2020 6d6d 5f72 6174            mm_rat
+00021cd0: 696f 5f74 616b 6572 203d 206d 6d5f 7261  io_taker = mm_ra
+00021ce0: 7469 6f20 2b20 7461 6b65 725f 6665 655f  tio + taker_fee_
+00021cf0: 7261 7465 0a20 2020 2020 2020 2020 2020  rate.           
+00021d00: 2069 6620 6973 5f73 686f 7274 3a0a 2020   if is_short:.  
+00021d10: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00021d20: 7475 726e 2028 6f70 656e 5f72 6174 6520  turn (open_rate 
+00021d30: 2b20 7661 6c75 6529 202f 2028 3120 2b20  + value) / (1 + 
+00021d40: 6d6d 5f72 6174 696f 5f74 616b 6572 290a  mm_ratio_taker).
+00021d50: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00021d60: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00021d70: 2020 7265 7475 726e 2028 6f70 656e 5f72    return (open_r
+00021d80: 6174 6520 2d20 7661 6c75 6529 202f 2028  ate - value) / (
+00021d90: 3120 2d20 6d6d 5f72 6174 696f 5f74 616b  1 - mm_ratio_tak
+00021da0: 6572 290a 2020 2020 2020 2020 656c 7365  er).        else
+00021db0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+00021dc0: 6973 6520 4f70 6572 6174 696f 6e61 6c45  ise OperationalE
+00021dd0: 7863 6570 7469 6f6e 280a 2020 2020 2020  xception(.      
+00021de0: 2020 2020 2020 2020 2020 2246 7265 7174            "Freqt
+00021df0: 7261 6465 206f 6e6c 7920 7375 7070 6f72  rade only suppor
+00021e00: 7473 2069 736f 6c61 7465 6420 6675 7475  ts isolated futu
+00021e10: 7265 7320 666f 7220 6c65 7665 7261 6765  res for leverage
+00021e20: 2074 7261 6469 6e67 220a 2020 2020 2020   trading".      
+00021e30: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
+00021e40: 2067 6574 5f6d 6169 6e74 656e 616e 6365   get_maintenance
+00021e50: 5f72 6174 696f 5f61 6e64 5f61 6d74 280a  _ratio_and_amt(.
+00021e60: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00021e70: 2020 2020 2020 7061 6972 3a20 7374 722c        pair: str,
+00021e80: 0a20 2020 2020 2020 206e 6f6d 696e 616c  .        nominal
+00021e90: 5f76 616c 7565 3a20 666c 6f61 742c 0a20  _value: float,. 
+00021ea0: 2020 2029 202d 3e20 5475 706c 655b 666c     ) -> Tuple[fl
+00021eb0: 6f61 742c 204f 7074 696f 6e61 6c5b 666c  oat, Optional[fl
+00021ec0: 6f61 745d 5d3a 0a20 2020 2020 2020 2022  oat]]:.        "
+00021ed0: 2222 0a20 2020 2020 2020 2049 6d70 6f72  "".        Impor
+00021ee0: 7461 6e74 3a20 4d75 7374 2062 6520 6665  tant: Must be fe
+00021ef0: 7463 6869 6e67 2064 6174 6120 6672 6f6d  tching data from
+00021f00: 2063 6163 6865 6420 7661 6c75 6573 2061   cached values a
+00021f10: 7320 7468 6973 2069 7320 7573 6564 2062  s this is used b
+00021f20: 7920 6261 636b 7465 7374 696e 6721 0a20  y backtesting!. 
+00021f30: 2020 2020 2020 203a 7061 7261 6d20 7061         :param pa
+00021f40: 6972 3a20 4d61 726b 6574 2073 796d 626f  ir: Market symbo
+00021f50: 6c0a 2020 2020 2020 2020 3a70 6172 616d  l.        :param
+00021f60: 206e 6f6d 696e 616c 5f76 616c 7565 3a20   nominal_value: 
+00021f70: 5468 6520 746f 7461 6c20 7472 6164 6520  The total trade 
+00021f80: 616d 6f75 6e74 2069 6e20 7175 6f74 6520  amount in quote 
+00021f90: 6375 7272 656e 6379 2069 6e63 6c75 6469  currency includi
+00021fa0: 6e67 206c 6576 6572 6167 650a 2020 2020  ng leverage.    
+00021fb0: 2020 2020 6d61 696e 7465 6e61 6e63 6520      maintenance 
+00021fc0: 616d 6f75 6e74 206f 6e6c 7920 6f6e 2042  amount only on B
+00021fd0: 696e 616e 6365 0a20 2020 2020 2020 203a  inance.        :
+00021fe0: 7265 7475 726e 3a20 286d 6169 6e74 656e  return: (mainten
+00021ff0: 616e 6365 206d 6172 6769 6e20 7261 7469  ance margin rati
+00022000: 6f2c 206d 6169 6e74 656e 616e 6365 2061  o, maintenance a
+00022010: 6d6f 756e 7429 0a20 2020 2020 2020 2022  mount).        "
+00022020: 2222 0a0a 2020 2020 2020 2020 6966 2028  ""..        if (
+00022030: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00022040: 662e 5f63 6f6e 6669 672e 6765 7428 2272  f._config.get("r
+00022050: 756e 6d6f 6465 2229 2069 6e20 4f50 5449  unmode") in OPTI
+00022060: 4d49 5a45 5f4d 4f44 4553 0a20 2020 2020  MIZE_MODES.     
+00022070: 2020 2020 2020 206f 7220 7365 6c66 2e65         or self.e
+00022080: 7863 6861 6e67 655f 6861 7328 2266 6574  xchange_has("fet
+00022090: 6368 4c65 7665 7261 6765 5469 6572 7322  chLeverageTiers"
+000220a0: 290a 2020 2020 2020 2020 2020 2020 6f72  ).            or
+000220b0: 2073 656c 662e 6578 6368 616e 6765 5f68   self.exchange_h
+000220c0: 6173 2822 6665 7463 684d 6172 6b65 744c  as("fetchMarketL
+000220d0: 6576 6572 6167 6554 6965 7273 2229 0a20  everageTiers"). 
+000220e0: 2020 2020 2020 2029 3a0a 2020 2020 2020         ):.      
+000220f0: 2020 2020 2020 6966 2070 6169 7220 6e6f        if pair no
+00022100: 7420 696e 2073 656c 662e 5f6c 6576 6572  t in self._lever
+00022110: 6167 655f 7469 6572 733a 0a20 2020 2020  age_tiers:.     
+00022120: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00022130: 2049 6e76 616c 6964 4f72 6465 7245 7863   InvalidOrderExc
+00022140: 6570 7469 6f6e 280a 2020 2020 2020 2020  eption(.        
+00022150: 2020 2020 2020 2020 2020 2020 6622 4d61              f"Ma
+00022160: 696e 7465 6e61 6e63 6520 6d61 7267 696e  intenance margin
+00022170: 2072 6174 6520 666f 7220 7b70 6169 727d   rate for {pair}
+00022180: 2069 7320 756e 6176 6169 6c61 626c 6520   is unavailable 
+00022190: 666f 7220 7b73 656c 662e 6e61 6d65 7d22  for {self.name}"
+000221a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000221b0: 2029 0a0a 2020 2020 2020 2020 2020 2020   )..            
+000221c0: 7061 6972 5f74 6965 7273 203d 2073 656c  pair_tiers = sel
+000221d0: 662e 5f6c 6576 6572 6167 655f 7469 6572  f._leverage_tier
+000221e0: 735b 7061 6972 5d0a 0a20 2020 2020 2020  s[pair]..       
+000221f0: 2020 2020 2066 6f72 2074 6965 7220 696e       for tier in
+00022200: 2072 6576 6572 7365 6428 7061 6972 5f74   reversed(pair_t
+00022210: 6965 7273 293a 0a20 2020 2020 2020 2020  iers):.         
+00022220: 2020 2020 2020 2069 6620 6e6f 6d69 6e61         if nomina
+00022230: 6c5f 7661 6c75 6520 3e3d 2074 6965 725b  l_value >= tier[
+00022240: 226d 696e 4e6f 7469 6f6e 616c 225d 3a0a  "minNotional"]:.
+00022250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022260: 2020 2020 7265 7475 726e 2028 7469 6572      return (tier
+00022270: 5b22 6d61 696e 7465 6e61 6e63 654d 6172  ["maintenanceMar
+00022280: 6769 6e52 6174 6522 5d2c 2074 6965 725b  ginRate"], tier[
+00022290: 226d 6169 6e74 416d 7422 5d29 0a0a 2020  "maintAmt"])..  
+000222a0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+000222b0: 4578 6368 616e 6765 4572 726f 7228 226e  ExchangeError("n
+000222c0: 6f6d 696e 616c 2076 616c 7565 2063 616e  ominal value can
+000222d0: 206e 6f74 2062 6520 6c6f 7765 7220 7468   not be lower th
+000222e0: 616e 2030 2229 0a20 2020 2020 2020 2020  an 0").         
+000222f0: 2020 2023 2054 6865 206c 6f77 6573 7420     # The lowest 
+00022300: 6e6f 7469 6f6e 616c 5f66 6c6f 6f72 2066  notional_floor f
+00022310: 6f72 2061 6e79 2070 6169 7220 696e 2066  or any pair in f
+00022320: 6574 6368 5f6c 6576 6572 6167 655f 7469  etch_leverage_ti
+00022330: 6572 7320 6973 2061 6c77 6179 7320 3020  ers is always 0 
+00022340: 6265 6361 7573 6520 6974 0a20 2020 2020  because it.     
+00022350: 2020 2020 2020 2023 2064 6573 6372 6962         # describ
+00022360: 6573 2074 6865 206d 696e 2061 6d74 2066  es the min amt f
+00022370: 6f72 2061 2074 6965 722c 2061 6e64 2074  or a tier, and t
+00022380: 6865 206c 6f77 6573 7420 7469 6572 2077  he lowest tier w
+00022390: 696c 6c20 616c 7761 7973 2067 6f20 646f  ill always go do
+000223a0: 776e 2074 6f20 300a 2020 2020 2020 2020  wn to 0.        
+000223b0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+000223c0: 2020 7261 6973 6520 4578 6368 616e 6765    raise Exchange
+000223d0: 4572 726f 7228 6622 4361 6e6e 6f74 2067  Error(f"Cannot g
+000223e0: 6574 206d 6169 6e74 656e 616e 6365 2072  et maintenance r
+000223f0: 6174 696f 2075 7369 6e67 207b 7365 6c66  atio using {self
+00022400: 2e6e 616d 657d 2229 0a20 2020 2020 2020  .name}").       
+00022410: 2020 2020 2072 6169 7365 2045 7863 6861       raise Excha
+00022420: 6e67 6545 7272 6f72 2866 2243 616e 6e6f  ngeError(f"Canno
+00022430: 7420 6765 7420 6d61 696e 7465 6e61 6e63  t get maintenanc
+00022440: 6520 7261 7469 6f20 7573 696e 6720 7b73  e ratio using {s
+00022450: 656c 662e 6e61 6d65 7d22 290a            elf.name}").
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/exchange_utils.py` & `freqtrade-2024.5/freqtrade/exchange/exchange_utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,30 +1,44 @@
 """
 Exchange support utils
 """
+
 from datetime import datetime, timedelta, timezone
 from math import ceil, floor
 from typing import Any, Dict, List, Optional, Tuple
 
 import ccxt
-from ccxt import (DECIMAL_PLACES, ROUND, ROUND_DOWN, ROUND_UP, SIGNIFICANT_DIGITS, TICK_SIZE,
-                  TRUNCATE, decimal_to_precision)
-
-from freqtrade.exchange.common import (BAD_EXCHANGES, EXCHANGE_HAS_OPTIONAL, EXCHANGE_HAS_REQUIRED,
-                                       SUPPORTED_EXCHANGES)
+from ccxt import (
+    DECIMAL_PLACES,
+    ROUND,
+    ROUND_DOWN,
+    ROUND_UP,
+    SIGNIFICANT_DIGITS,
+    TICK_SIZE,
+    TRUNCATE,
+    decimal_to_precision,
+)
+
+from freqtrade.exchange.common import (
+    BAD_EXCHANGES,
+    EXCHANGE_HAS_OPTIONAL,
+    EXCHANGE_HAS_REQUIRED,
+    SUPPORTED_EXCHANGES,
+)
 from freqtrade.exchange.exchange_utils_timeframe import timeframe_to_minutes, timeframe_to_prev_date
 from freqtrade.types import ValidExchangesType
 from freqtrade.util import FtPrecise
 
 
 CcxtModuleType = Any
 
 
 def is_exchange_known_ccxt(
-        exchange_name: str, ccxt_module: Optional[CcxtModuleType] = None) -> bool:
+    exchange_name: str, ccxt_module: Optional[CcxtModuleType] = None
+) -> bool:
     return exchange_name in ccxt_exchanges(ccxt_module)
 
 
 def ccxt_exchanges(ccxt_module: Optional[CcxtModuleType] = None) -> List[str]:
     """
     Return the list of all exchanges known to ccxt
     """
@@ -42,78 +56,82 @@
 def validate_exchange(exchange: str) -> Tuple[bool, str]:
     """
     returns: can_use, reason
         with Reason including both missing and missing_opt
     """
     ex_mod = getattr(ccxt, exchange.lower())()
     result = True
-    reason = ''
+    reason = ""
     if not ex_mod or not ex_mod.has:
-        return False, ''
+        return False, ""
     missing = [
-        k for k, v in EXCHANGE_HAS_REQUIRED.items()
-        if ex_mod.has.get(k) is not True
-        and not (all(ex_mod.has.get(x) for x in v))
+        k
+        for k, v in EXCHANGE_HAS_REQUIRED.items()
+        if ex_mod.has.get(k) is not True and not (all(ex_mod.has.get(x) for x in v))
     ]
     if missing:
         result = False
         reason += f"missing: {', '.join(missing)}"
 
     missing_opt = [k for k in EXCHANGE_HAS_OPTIONAL if not ex_mod.has.get(k)]
 
     if exchange.lower() in BAD_EXCHANGES:
         result = False
-        reason = BAD_EXCHANGES.get(exchange.lower(), '')
+        reason = BAD_EXCHANGES.get(exchange.lower(), "")
 
     if missing_opt:
         reason += f"{'. ' if reason else ''}missing opt: {', '.join(missing_opt)}. "
 
     return result, reason
 
 
 def _build_exchange_list_entry(
-        exchange_name: str, exchangeClasses: Dict[str, Any]) -> ValidExchangesType:
+    exchange_name: str, exchangeClasses: Dict[str, Any]
+) -> ValidExchangesType:
     valid, comment = validate_exchange(exchange_name)
     result: ValidExchangesType = {
-        'name': exchange_name,
-        'valid': valid,
-        'supported': exchange_name.lower() in SUPPORTED_EXCHANGES,
-        'comment': comment,
-        'trade_modes': [{'trading_mode': 'spot', 'margin_mode': ''}],
+        "name": exchange_name,
+        "valid": valid,
+        "supported": exchange_name.lower() in SUPPORTED_EXCHANGES,
+        "comment": comment,
+        "trade_modes": [{"trading_mode": "spot", "margin_mode": ""}],
     }
     if resolved := exchangeClasses.get(exchange_name.lower()):
-        supported_modes = [{'trading_mode': 'spot', 'margin_mode': ''}] + [
-            {'trading_mode': tm.value, 'margin_mode': mm.value}
-            for tm, mm in resolved['class']._supported_trading_mode_margin_pairs
+        supported_modes = [{"trading_mode": "spot", "margin_mode": ""}] + [
+            {"trading_mode": tm.value, "margin_mode": mm.value}
+            for tm, mm in resolved["class"]._supported_trading_mode_margin_pairs
         ]
-        result.update({
-            'trade_modes': supported_modes,
-        })
+        result.update(
+            {
+                "trade_modes": supported_modes,
+            }
+        )
 
     return result
 
 
 def list_available_exchanges(all_exchanges: bool) -> List[ValidExchangesType]:
     """
     :return: List of tuples with exchangename, valid, reason.
     """
     exchanges = ccxt_exchanges() if all_exchanges else available_exchanges()
     from freqtrade.resolvers.exchange_resolver import ExchangeResolver
 
-    subclassed = {e['name'].lower(): e for e in ExchangeResolver.search_all_objects({}, False)}
+    subclassed = {e["name"].lower(): e for e in ExchangeResolver.search_all_objects({}, False)}
 
     exchanges_valid: List[ValidExchangesType] = [
         _build_exchange_list_entry(e, subclassed) for e in exchanges
     ]
 
     return exchanges_valid
 
 
 def date_minus_candles(
-        timeframe: str, candle_count: int, date: Optional[datetime] = None) -> datetime:
+    timeframe: str, candle_count: int, date: Optional[datetime] = None
+) -> datetime:
     """
     subtract X candles from a date.
     :param timeframe: timeframe in string format (e.g. "5m")
     :param candle_count: Amount of candles to subtract.
     :param date: date to use. Defaults to now(utc)
 
     """
@@ -129,15 +147,15 @@
     """
     Return True if the market is active.
     """
     # "It's active, if the active flag isn't explicitly set to false. If it's missing or
     # true then it's true. If it's undefined, then it's most likely true, but not 100% )"
     # See https://github.com/ccxt/ccxt/issues/4874,
     # https://github.com/ccxt/ccxt/issues/4075#issuecomment-434760520
-    return market.get('active', True) is not False
+    return market.get("active", True) is not False
 
 
 def amount_to_contracts(amount: float, contract_size: Optional[float]) -> float:
     """
     Convert amount to contracts.
     :param amount: amount to convert
     :param contract_size: contract size - taken from exchange.get_contract_size(pair)
@@ -159,41 +177,49 @@
 
     if contract_size and contract_size != 1:
         return float(FtPrecise(num_contracts) * FtPrecise(contract_size))
     else:
         return num_contracts
 
 
-def amount_to_precision(amount: float, amount_precision: Optional[float],
-                        precisionMode: Optional[int]) -> float:
+def amount_to_precision(
+    amount: float, amount_precision: Optional[float], precisionMode: Optional[int]
+) -> float:
     """
     Returns the amount to buy or sell to a precision the Exchange accepts
     Re-implementation of ccxt internal methods - ensuring we can test the result is correct
     based on our definitions.
     :param amount: amount to truncate
     :param amount_precision: amount precision to use.
                              should be retrieved from markets[pair]['precision']['amount']
     :param precisionMode: precision mode to use. Should be used from precisionMode
                           one of ccxt's DECIMAL_PLACES, SIGNIFICANT_DIGITS, or TICK_SIZE
     :return: truncated amount
     """
     if amount_precision is not None and precisionMode is not None:
         precision = int(amount_precision) if precisionMode != TICK_SIZE else amount_precision
         # precision must be an int for non-ticksize inputs.
-        amount = float(decimal_to_precision(amount, rounding_mode=TRUNCATE,
-                                            precision=precision,
-                                            counting_mode=precisionMode,
-                                            ))
+        amount = float(
+            decimal_to_precision(
+                amount,
+                rounding_mode=TRUNCATE,
+                precision=precision,
+                counting_mode=precisionMode,
+            )
+        )
 
     return amount
 
 
 def amount_to_contract_precision(
-        amount, amount_precision: Optional[float], precisionMode: Optional[int],
-        contract_size: Optional[float]) -> float:
+    amount,
+    amount_precision: Optional[float],
+    precisionMode: Optional[int],
+    contract_size: Optional[float],
+) -> float:
     """
     Returns the amount to buy or sell to a precision the Exchange accepts
     including calculation to and from contracts.
     Re-implementation of ccxt internal methods - ensuring we can test the result is correct
     based on our definitions.
     :param amount: amount to truncate
     :param amount_precision: amount precision to use.
@@ -218,31 +244,33 @@
 ) -> float:
     """
     Implementation of ROUND_UP/Round_down for significant digits mode.
     """
     from decimal import ROUND_DOWN as dec_ROUND_DOWN
     from decimal import ROUND_UP as dec_ROUND_UP
     from decimal import Decimal
+
     dec = Decimal(str(price))
-    string = f'{dec:f}'
+    string = f"{dec:f}"
     precision = round(price_precision)
 
     q = precision - dec.adjusted() - 1
-    sigfig = Decimal('10') ** -q
+    sigfig = Decimal("10") ** -q
     if q < 0:
         string_to_precision = string[:precision]
         # string_to_precision is '' when we have zero precision
-        below = sigfig * Decimal(string_to_precision if string_to_precision else '0')
+        below = sigfig * Decimal(string_to_precision if string_to_precision else "0")
         above = below + sigfig
         res = above if rounding_mode == ROUND_UP else below
-        precise = f'{res:f}'
+        precise = f"{res:f}"
     else:
-        precise = '{:f}'.format(dec.quantize(
-            sigfig,
-            rounding=dec_ROUND_DOWN if rounding_mode == ROUND_DOWN else dec_ROUND_UP)
+        precise = "{:f}".format(
+            dec.quantize(
+                sigfig, rounding=dec_ROUND_DOWN if rounding_mode == ROUND_DOWN else dec_ROUND_UP
+            )
         )
     return float(precise)
 
 
 def price_to_precision(
     price: float,
     price_precision: Optional[float],
@@ -264,32 +292,35 @@
                           one of ccxt's DECIMAL_PLACES, SIGNIFICANT_DIGITS, or TICK_SIZE
     :param rounding_mode: rounding mode to use. Defaults to ROUND
     :return: price rounded up to the precision the Exchange accepts
     """
     if price_precision is not None and precisionMode is not None:
         if rounding_mode not in (ROUND_UP, ROUND_DOWN):
             # Use CCXT code where possible.
-            return float(decimal_to_precision(price, rounding_mode=rounding_mode,
-                                              precision=price_precision,
-                                              counting_mode=precisionMode
-                                              ))
+            return float(
+                decimal_to_precision(
+                    price,
+                    rounding_mode=rounding_mode,
+                    precision=price_precision,
+                    counting_mode=precisionMode,
+                )
+            )
 
         if precisionMode == TICK_SIZE:
             precision = FtPrecise(price_precision)
             price_str = FtPrecise(price)
             missing = price_str % precision
             if not missing == FtPrecise("0"):
                 if rounding_mode == ROUND_UP:
                     res = price_str - missing + precision
                 elif rounding_mode == ROUND_DOWN:
                     res = price_str - missing
                 return round(float(str(res)), 14)
             return price
         elif precisionMode == DECIMAL_PLACES:
-
             ndigits = round(price_precision)
             ticks = price * (10**ndigits)
             if rounding_mode == ROUND_UP:
                 return ceil(ticks) / (10**ndigits)
             if rounding_mode == ROUND_DOWN:
                 return floor(ticks) / (10**ndigits)
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/exchange_utils_timeframe.py` & `freqtrade-2024.5/freqtrade/exchange/exchange_utils_timeframe.py`

 * *Files 4% similar despite different names*

```diff
@@ -32,24 +32,24 @@
 
 def timeframe_to_resample_freq(timeframe: str) -> str:
     """
     Translates the timeframe interval value written in the human readable
     form ('1m', '5m', '1h', '1d', '1w', etc.) to the resample frequency
     used by pandas ('1T', '5T', '1H', '1D', '1W', etc.)
     """
-    if timeframe == '1y':
-        return '1YS'
+    if timeframe == "1y":
+        return "1YS"
     timeframe_seconds = timeframe_to_seconds(timeframe)
     timeframe_minutes = timeframe_seconds // 60
-    resample_interval = f'{timeframe_seconds}s'
+    resample_interval = f"{timeframe_seconds}s"
     if 10000 < timeframe_minutes < 43200:
-        resample_interval = '1W-MON'
+        resample_interval = "1W-MON"
     elif timeframe_minutes >= 43200 and timeframe_minutes < 525600:
         # Monthly candles need special treatment to stick to the 1st of the month
-        resample_interval = f'{timeframe}S'
+        resample_interval = f"{timeframe}S"
     elif timeframe_minutes > 43200:
         resample_interval = timeframe
     return resample_interval
 
 
 def timeframe_to_prev_date(timeframe: str, date: Optional[datetime] = None) -> datetime:
     """
@@ -58,24 +58,22 @@
     :param timeframe: timeframe in string format (e.g. "5m")
     :param date: date to use. Defaults to now(utc)
     :returns: date of previous candle (with utc timezone)
     """
     if not date:
         date = datetime.now(timezone.utc)
 
-    new_timestamp = ccxt.Exchange.round_timeframe(
-        timeframe, dt_ts(date), ROUND_DOWN) // 1000
+    new_timestamp = ccxt.Exchange.round_timeframe(timeframe, dt_ts(date), ROUND_DOWN) // 1000
     return dt_from_ts(new_timestamp)
 
 
 def timeframe_to_next_date(timeframe: str, date: Optional[datetime] = None) -> datetime:
     """
     Use Timeframe and determine next candle.
     :param timeframe: timeframe in string format (e.g. "5m")
     :param date: date to use. Defaults to now(utc)
     :returns: date of next candle (with utc timezone)
     """
     if not date:
         date = datetime.now(timezone.utc)
-    new_timestamp = ccxt.Exchange.round_timeframe(
-        timeframe, dt_ts(date), ROUND_UP) // 1000
+    new_timestamp = ccxt.Exchange.round_timeframe(timeframe, dt_ts(date), ROUND_UP) // 1000
     return dt_from_ts(new_timestamp)
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/gate.py` & `freqtrade-2024.5/freqtrade/exchange/gate.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-""" Gate.io exchange subclass """
+"""Gate.io exchange subclass"""
+
 import logging
 from datetime import datetime
 from typing import Any, Dict, List, Optional, Tuple
 
 from freqtrade.constants import BuySell
 from freqtrade.enums import MarginMode, PriceType, TradingMode
 from freqtrade.exchange import Exchange
@@ -20,15 +21,15 @@
     Please note that this exchange is not included in the list of exchanges
     officially supported by the Freqtrade development team. So some features
     may still not work as expected.
     """
 
     _ft_has: Dict = {
         "ohlcv_candle_limit": 1000,
-        "order_time_in_force": ['GTC', 'IOC'],
+        "order_time_in_force": ["GTC", "IOC"],
         "stoploss_on_exchange": True,
         "stoploss_order_types": {"limit": "limit"},
         "stop_price_param": "stopPrice",
         "stop_price_prop": "stopPrice",
         "marketOrderRequiresPrice": True,
     }
 
@@ -47,82 +48,76 @@
         # TradingMode.SPOT always supported and not required in this list
         # (TradingMode.MARGIN, MarginMode.CROSS),
         # (TradingMode.FUTURES, MarginMode.CROSS),
         (TradingMode.FUTURES, MarginMode.ISOLATED)
     ]
 
     def _get_params(
-            self,
-            side: BuySell,
-            ordertype: str,
-            leverage: float,
-            reduceOnly: bool,
-            time_in_force: str = 'GTC',
-            ) -> Dict:
+        self,
+        side: BuySell,
+        ordertype: str,
+        leverage: float,
+        reduceOnly: bool,
+        time_in_force: str = "GTC",
+    ) -> Dict:
         params = super()._get_params(
             side=side,
             ordertype=ordertype,
             leverage=leverage,
             reduceOnly=reduceOnly,
             time_in_force=time_in_force,
         )
-        if ordertype == 'market' and self.trading_mode == TradingMode.FUTURES:
-            params['type'] = 'market'
-            params.update({'timeInForce': 'IOC'})
+        if ordertype == "market" and self.trading_mode == TradingMode.FUTURES:
+            params["type"] = "market"
+            params.update({"timeInForce": "IOC"})
         return params
 
-    def get_trades_for_order(self, order_id: str, pair: str, since: datetime,
-                             params: Optional[Dict] = None) -> List:
+    def get_trades_for_order(
+        self, order_id: str, pair: str, since: datetime, params: Optional[Dict] = None
+    ) -> List:
         trades = super().get_trades_for_order(order_id, pair, since, params)
 
         if self.trading_mode == TradingMode.FUTURES:
             # Futures usually don't contain fees in the response.
             # As such, futures orders on gate will not contain a fee, which causes
             # a repeated "update fee" cycle and wrong calculations.
             # Therefore we patch the response with fees if it's not available.
             # An alternative also containing fees would be
             # privateFuturesGetSettleAccountBook({"settle": "usdt"})
             pair_fees = self._trading_fees.get(pair, {})
             if pair_fees:
                 for idx, trade in enumerate(trades):
-                    fee = trade.get('fee', {})
-                    if fee and fee.get('cost') is None:
-                        takerOrMaker = trade.get('takerOrMaker', 'taker')
+                    fee = trade.get("fee", {})
+                    if fee and fee.get("cost") is None:
+                        takerOrMaker = trade.get("takerOrMaker", "taker")
                         if pair_fees.get(takerOrMaker) is not None:
-                            trades[idx]['fee'] = {
-                                'currency': self.get_pair_quote_currency(pair),
-                                'cost': trade['cost'] * pair_fees[takerOrMaker],
-                                'rate': pair_fees[takerOrMaker],
+                            trades[idx]["fee"] = {
+                                "currency": self.get_pair_quote_currency(pair),
+                                "cost": trade["cost"] * pair_fees[takerOrMaker],
+                                "rate": pair_fees[takerOrMaker],
                             }
         return trades
 
     def get_order_id_conditional(self, order: Dict[str, Any]) -> str:
-        return safe_value_fallback2(order, order, 'id_stop', 'id')
+        return safe_value_fallback2(order, order, "id_stop", "id")
 
     def fetch_stoploss_order(self, order_id: str, pair: str, params: Optional[Dict] = None) -> Dict:
-        order = self.fetch_order(
-            order_id=order_id,
-            pair=pair,
-            params={'stop': True}
-        )
-        if order.get('status', 'open') == 'closed':
+        order = self.fetch_order(order_id=order_id, pair=pair, params={"stop": True})
+        if order.get("status", "open") == "closed":
             # Places a real order - which we need to fetch explicitly.
-            val = 'trade_id' if self.trading_mode == TradingMode.FUTURES else 'fired_order_id'
+            val = "trade_id" if self.trading_mode == TradingMode.FUTURES else "fired_order_id"
 
-            if new_orderid := order.get('info', {}).get(val):
+            if new_orderid := order.get("info", {}).get(val):
                 order1 = self.fetch_order(order_id=new_orderid, pair=pair, params=params)
-                order1['id_stop'] = order1['id']
-                order1['id'] = order_id
-                order1['type'] = 'stoploss'
-                order1['stopPrice'] = order.get('stopPrice')
-                order1['status_stop'] = 'triggered'
+                order1["id_stop"] = order1["id"]
+                order1["id"] = order_id
+                order1["type"] = "stoploss"
+                order1["stopPrice"] = order.get("stopPrice")
+                order1["status_stop"] = "triggered"
 
                 return order1
         return order
 
     def cancel_stoploss_order(
-            self, order_id: str, pair: str, params: Optional[Dict] = None) -> Dict:
-        return self.cancel_order(
-            order_id=order_id,
-            pair=pair,
-            params={'stop': True}
-        )
+        self, order_id: str, pair: str, params: Optional[Dict] = None
+    ) -> Dict:
+        return self.cancel_order(order_id=order_id, pair=pair, params={"stop": True})
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/hitbtc.py` & `freqtrade-2024.5/freqtrade/exchange/hitbtc.py`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/exchange/htx.py` & `freqtrade-2024.5/freqtrade/exchange/htx.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-""" HTX exchange subclass """
+"""HTX exchange subclass"""
+
 import logging
 from typing import Dict
 
 from freqtrade.constants import BuySell
 from freqtrade.exchange import Exchange
 
 
@@ -19,17 +20,22 @@
         "stoploss_on_exchange": True,
         "stop_price_param": "stopPrice",
         "stop_price_prop": "stopPrice",
         "stoploss_order_types": {"limit": "stop-limit"},
         "ohlcv_candle_limit": 1000,
         "l2_limit_range": [5, 10, 20],
         "l2_limit_range_required": False,
+        "ohlcv_candle_limit_per_timeframe": {
+            "1w": 500,
+            "1M": 500,
+        },
     }
 
     def _get_stop_params(self, side: BuySell, ordertype: str, stop_price: float) -> Dict:
-
         params = self._params.copy()
-        params.update({
-            "stopPrice": stop_price,
-            "operator": "lte",
-        })
+        params.update(
+            {
+                "stopPrice": stop_price,
+                "operator": "lte",
+            }
+        )
         return params
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/kraken.py` & `freqtrade-2024.5/freqtrade/exchange/kraken.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-""" Kraken exchange subclass """
+"""Kraken exchange subclass"""
+
 import logging
 from datetime import datetime
 from typing import Any, Dict, List, Optional, Tuple
 
 import ccxt
 from pandas import DataFrame
 
@@ -14,15 +15,14 @@
 from freqtrade.exchange.types import Tickers
 
 
 logger = logging.getLogger(__name__)
 
 
 class Kraken(Exchange):
-
     _params: Dict = {"trading_agreement": "agree"}
     _ft_has: Dict = {
         "stoploss_on_exchange": True,
         "stop_price_param": "stopLossPrice",
         "stop_price_prop": "stopLossPrice",
         "stoploss_order_types": {"limit": "limit", "market": "market"},
         "order_time_in_force": ["GTC", "IOC", "PO"],
@@ -43,54 +43,58 @@
     def market_is_tradable(self, market: Dict[str, Any]) -> bool:
         """
         Check if the market symbol is tradable by Freqtrade.
         Default checks + check if pair is darkpool pair.
         """
         parent_check = super().market_is_tradable(market)
 
-        return (parent_check and
-                market.get('darkpool', False) is False)
+        return parent_check and market.get("darkpool", False) is False
 
     def get_tickers(self, symbols: Optional[List[str]] = None, cached: bool = False) -> Tickers:
         # Only fetch tickers for current stake currency
         # Otherwise the request for kraken becomes too large.
-        symbols = list(self.get_markets(quote_currencies=[self._config['stake_currency']]))
+        symbols = list(self.get_markets(quote_currencies=[self._config["stake_currency"]]))
         return super().get_tickers(symbols=symbols, cached=cached)
 
     @retrier
     def get_balances(self) -> dict:
-        if self._config['dry_run']:
+        if self._config["dry_run"]:
             return {}
 
         try:
             balances = self._api.fetch_balance()
             # Remove additional info from ccxt results
             balances.pop("info", None)
             balances.pop("free", None)
             balances.pop("total", None)
             balances.pop("used", None)
 
             orders = self._api.fetch_open_orders()
-            order_list = [(x["symbol"].split("/")[0 if x["side"] == "sell" else 1],
-                           x["remaining"] if x["side"] == "sell" else x["remaining"] * x["price"],
-                           # Don't remove the below comment, this can be important for debugging
-                           # x["side"], x["amount"],
-                           ) for x in orders]
+            order_list = [
+                (
+                    x["symbol"].split("/")[0 if x["side"] == "sell" else 1],
+                    x["remaining"] if x["side"] == "sell" else x["remaining"] * x["price"],
+                    # Don't remove the below comment, this can be important for debugging
+                    # x["side"], x["amount"],
+                )
+                for x in orders
+            ]
             for bal in balances:
                 if not isinstance(balances[bal], dict):
                     continue
-                balances[bal]['used'] = sum(order[1] for order in order_list if order[0] == bal)
-                balances[bal]['free'] = balances[bal]['total'] - balances[bal]['used']
+                balances[bal]["used"] = sum(order[1] for order in order_list if order[0] == bal)
+                balances[bal]["free"] = balances[bal]["total"] - balances[bal]["used"]
 
             return balances
         except ccxt.DDoSProtection as e:
             raise DDosProtection(e) from e
         except (ccxt.OperationFailed, ccxt.ExchangeError) as e:
             raise TemporaryError(
-                f'Could not get balance due to {e.__class__.__name__}. Message: {e}') from e
+                f"Could not get balance due to {e.__class__.__name__}. Message: {e}"
+            ) from e
         except ccxt.BaseError as e:
             raise OperationalException(e) from e
 
     def _set_leverage(
         self,
         leverage: float,
         pair: Optional[str] = None,
@@ -104,38 +108,38 @@
 
     def _get_params(
         self,
         side: BuySell,
         ordertype: str,
         leverage: float,
         reduceOnly: bool,
-        time_in_force: str = 'GTC'
+        time_in_force: str = "GTC",
     ) -> Dict:
         params = super()._get_params(
             side=side,
             ordertype=ordertype,
             leverage=leverage,
             reduceOnly=reduceOnly,
             time_in_force=time_in_force,
         )
         if leverage > 1.0:
-            params['leverage'] = round(leverage)
-        if time_in_force == 'PO':
-            params.pop('timeInForce', None)
-            params['postOnly'] = True
+            params["leverage"] = round(leverage)
+        if time_in_force == "PO":
+            params.pop("timeInForce", None)
+            params["postOnly"] = True
         return params
 
     def calculate_funding_fees(
         self,
         df: DataFrame,
         amount: float,
         is_short: bool,
         open_date: datetime,
         close_date: datetime,
-        time_in_ratio: Optional[float] = None
+        time_in_ratio: Optional[float] = None,
     ) -> float:
         """
         # ! This method will always error when run by Freqtrade because time_in_ratio is never
         # ! passed to _get_funding_fee. For kraken futures to work in dry run and backtesting
         # ! functionality must be added that passes the parameter time_in_ratio to
         # ! _get_funding_fee when using Kraken
         calculates the sum of all funding fees that occurred for a pair during a futures trade
@@ -145,37 +149,35 @@
         :param is_short: trade direction
         :param open_date: The date and time that the trade started
         :param close_date: The date and time that the trade ended
         :param time_in_ratio: Not used by most exchange classes
         """
         if not time_in_ratio:
             raise OperationalException(
-                f"time_in_ratio is required for {self.name}._get_funding_fee")
+                f"time_in_ratio is required for {self.name}._get_funding_fee"
+            )
         fees: float = 0
 
         if not df.empty:
-            df = df[(df['date'] >= open_date) & (df['date'] <= close_date)]
-            fees = sum(df['open_fund'] * df['open_mark'] * amount * time_in_ratio)
+            df = df[(df["date"] >= open_date) & (df["date"] <= close_date)]
+            fees = sum(df["open_fund"] * df["open_mark"] * amount * time_in_ratio)
 
         return fees if is_short else -fees
 
     def _get_trade_pagination_next_value(self, trades: List[Dict]):
         """
         Extract pagination id for the next "from_id" value
         Applies only to fetch_trade_history by id.
         """
         if len(trades) > 0:
-            if (
-                isinstance(trades[-1].get('info'), list)
-                and len(trades[-1].get('info', [])) > 7
-            ):
+            if isinstance(trades[-1].get("info"), list) and len(trades[-1].get("info", [])) > 7:
                 # Trade response's "last" value.
-                return trades[-1].get('info', [])[-1]
+                return trades[-1].get("info", [])[-1]
             # Fall back to timestamp if info is somehow empty.
-            return trades[-1].get('timestamp')
+            return trades[-1].get("timestamp")
         return None
 
     def _valid_trade_pagination_id(self, pair: str, from_id: str) -> bool:
         """
         Verify trade-pagination id is valid.
         Workaround for odd Kraken issue where ID is sometimes wrong.
         """
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/kucoin.py` & `freqtrade-2024.5/freqtrade/exchange/kucoin.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 """Kucoin exchange subclass."""
+
 import logging
 from typing import Dict
 
 from freqtrade.constants import BuySell
 from freqtrade.exchange import Exchange
 
 
@@ -22,51 +23,46 @@
     _ft_has: Dict = {
         "stoploss_on_exchange": True,
         "stop_price_param": "stopPrice",
         "stop_price_prop": "stopPrice",
         "stoploss_order_types": {"limit": "limit", "market": "market"},
         "l2_limit_range": [20, 100],
         "l2_limit_range_required": False,
-        "order_time_in_force": ['GTC', 'FOK', 'IOC'],
+        "order_time_in_force": ["GTC", "FOK", "IOC"],
         "ohlcv_candle_limit": 1500,
     }
 
     def _get_stop_params(self, side: BuySell, ordertype: str, stop_price: float) -> Dict:
-
         params = self._params.copy()
-        params.update({
-            'stopPrice': stop_price,
-            'stop': 'loss'
-            })
+        params.update({"stopPrice": stop_price, "stop": "loss"})
         return params
 
     def create_order(
-            self,
-            *,
-            pair: str,
-            ordertype: str,
-            side: BuySell,
-            amount: float,
-            rate: float,
-            leverage: float,
-            reduceOnly: bool = False,
-            time_in_force: str = 'GTC',
-            ) -> Dict:
-
+        self,
+        *,
+        pair: str,
+        ordertype: str,
+        side: BuySell,
+        amount: float,
+        rate: float,
+        leverage: float,
+        reduceOnly: bool = False,
+        time_in_force: str = "GTC",
+    ) -> Dict:
         res = super().create_order(
             pair=pair,
             ordertype=ordertype,
             side=side,
             amount=amount,
             rate=rate,
             leverage=leverage,
             reduceOnly=reduceOnly,
             time_in_force=time_in_force,
         )
         # Kucoin returns only the order-id.
         # ccxt returns status = 'closed' at the moment - which is information ccxt invented.
         # Since we rely on status heavily, we must set it to 'open' here.
         # ref: https://github.com/ccxt/ccxt/pull/16674, (https://github.com/ccxt/ccxt/pull/16553)
-        if not self._config['dry_run']:
-            res['type'] = ordertype
-            res['status'] = 'open'
+        if not self._config["dry_run"]:
+            res["type"] = ordertype
+            res["status"] = "open"
         return res
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/okx.py` & `freqtrade-2024.5/freqtrade/exchange/okx.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,16 +2,20 @@
 from datetime import timedelta
 from typing import Any, Dict, List, Optional, Tuple
 
 import ccxt
 
 from freqtrade.constants import BuySell
 from freqtrade.enums import CandleType, MarginMode, PriceType, TradingMode
-from freqtrade.exceptions import (DDosProtection, OperationalException, RetryableOrderError,
-                                  TemporaryError)
+from freqtrade.exceptions import (
+    DDosProtection,
+    OperationalException,
+    RetryableOrderError,
+    TemporaryError,
+)
 from freqtrade.exchange import Exchange, date_minus_candles
 from freqtrade.exchange.common import retrier
 from freqtrade.misc import safe_value_fallback2
 from freqtrade.util import dt_now, dt_ts
 
 
 logger = logging.getLogger(__name__)
@@ -33,109 +37,112 @@
     _ft_has_futures: Dict = {
         "tickers_have_quoteVolume": False,
         "stop_price_type_field": "slTriggerPxType",
         "stop_price_type_value_mapping": {
             PriceType.LAST: "last",
             PriceType.MARK: "index",
             PriceType.INDEX: "mark",
-            },
+        },
     }
 
     _supported_trading_mode_margin_pairs: List[Tuple[TradingMode, MarginMode]] = [
         # TradingMode.SPOT always supported and not required in this list
         # (TradingMode.MARGIN, MarginMode.CROSS),
         # (TradingMode.FUTURES, MarginMode.CROSS),
         (TradingMode.FUTURES, MarginMode.ISOLATED),
     ]
 
     net_only = True
 
-    _ccxt_params: Dict = {'options': {'brokerId': 'ffb5405ad327SUDE'}}
+    _ccxt_params: Dict = {"options": {"brokerId": "ffb5405ad327SUDE"}}
 
     def ohlcv_candle_limit(
-            self, timeframe: str, candle_type: CandleType, since_ms: Optional[int] = None) -> int:
+        self, timeframe: str, candle_type: CandleType, since_ms: Optional[int] = None
+    ) -> int:
         """
         Exchange ohlcv candle limit
         OKX has the following behaviour:
         * 300 candles for up-to-date data
         * 100 candles for historic data
         * 100 candles for additional candles (not futures or spot).
         :param timeframe: Timeframe to check
         :param candle_type: Candle-type
         :param since_ms: Starting timestamp
         :return: Candle limit as integer
         """
-        if (
-            candle_type in (CandleType.FUTURES, CandleType.SPOT) and
-            (not since_ms or since_ms > (date_minus_candles(timeframe, 300).timestamp() * 1000))
+        if candle_type in (CandleType.FUTURES, CandleType.SPOT) and (
+            not since_ms or since_ms > (date_minus_candles(timeframe, 300).timestamp() * 1000)
         ):
             return 300
 
         return super().ohlcv_candle_limit(timeframe, candle_type, since_ms)
 
     @retrier
     def additional_exchange_init(self) -> None:
         """
         Additional exchange initialization logic.
         .api will be available at this point.
         Must be overridden in child methods if required.
         """
         try:
-            if self.trading_mode == TradingMode.FUTURES and not self._config['dry_run']:
+            if self.trading_mode == TradingMode.FUTURES and not self._config["dry_run"]:
                 accounts = self._api.fetch_accounts()
-                self._log_exchange_response('fetch_accounts', accounts)
+                self._log_exchange_response("fetch_accounts", accounts)
                 if len(accounts) > 0:
-                    self.net_only = accounts[0].get('info', {}).get('posMode') == 'net_mode'
+                    self.net_only = accounts[0].get("info", {}).get("posMode") == "net_mode"
         except ccxt.DDoSProtection as e:
             raise DDosProtection(e) from e
         except (ccxt.OperationFailed, ccxt.ExchangeError) as e:
             raise TemporaryError(
-                f'Error in additional_exchange_init due to {e.__class__.__name__}. Message: {e}'
-                ) from e
+                f"Error in additional_exchange_init due to {e.__class__.__name__}. Message: {e}"
+            ) from e
         except ccxt.BaseError as e:
             raise OperationalException(e) from e
 
     def _get_posSide(self, side: BuySell, reduceOnly: bool):
         if self.net_only:
-            return 'net'
+            return "net"
         if not reduceOnly:
             # Enter
-            return 'long' if side == 'buy' else 'short'
+            return "long" if side == "buy" else "short"
         else:
             # Exit
-            return 'long' if side == 'sell' else 'short'
+            return "long" if side == "sell" else "short"
 
     def _get_params(
         self,
         side: BuySell,
         ordertype: str,
         leverage: float,
         reduceOnly: bool,
-        time_in_force: str = 'GTC',
+        time_in_force: str = "GTC",
     ) -> Dict:
         params = super()._get_params(
             side=side,
             ordertype=ordertype,
             leverage=leverage,
             reduceOnly=reduceOnly,
             time_in_force=time_in_force,
         )
         if self.trading_mode == TradingMode.FUTURES and self.margin_mode:
-            params['tdMode'] = self.margin_mode.value
-            params['posSide'] = self._get_posSide(side, reduceOnly)
+            params["tdMode"] = self.margin_mode.value
+            params["posSide"] = self._get_posSide(side, reduceOnly)
         return params
 
     def __fetch_leverage_already_set(self, pair: str, leverage: float, side: BuySell) -> bool:
         try:
-            res_lev = self._api.fetch_leverage(symbol=pair, params={
+            res_lev = self._api.fetch_leverage(
+                symbol=pair,
+                params={
                     "mgnMode": self.margin_mode.value,
                     "posSide": self._get_posSide(side, False),
-                })
-            self._log_exchange_response('get_leverage', res_lev)
-            already_set = all(float(x['lever']) == leverage for x in res_lev['data'])
+                },
+            )
+            self._log_exchange_response("get_leverage", res_lev)
+            already_set = all(float(x["lever"]) == leverage for x in res_lev["data"])
             return already_set
 
         except ccxt.BaseError:
             # Assume all errors as "not set yet"
             return False
 
     @retrier
@@ -144,116 +151,114 @@
             try:
                 res = self._api.set_leverage(
                     leverage=leverage,
                     symbol=pair,
                     params={
                         "mgnMode": self.margin_mode.value,
                         "posSide": self._get_posSide(side, False),
-                    })
-                self._log_exchange_response('set_leverage', res)
+                    },
+                )
+                self._log_exchange_response("set_leverage", res)
 
             except ccxt.DDoSProtection as e:
                 raise DDosProtection(e) from e
             except (ccxt.OperationFailed, ccxt.ExchangeError) as e:
                 already_set = self.__fetch_leverage_already_set(pair, leverage, side)
                 if not already_set:
                     raise TemporaryError(
-                        f'Could not set leverage due to {e.__class__.__name__}. Message: {e}'
-                        ) from e
+                        f"Could not set leverage due to {e.__class__.__name__}. Message: {e}"
+                    ) from e
             except ccxt.BaseError as e:
                 raise OperationalException(e) from e
 
-    def get_max_pair_stake_amount(
-        self,
-        pair: str,
-        price: float,
-        leverage: float = 1.0
-    ) -> float:
-
+    def get_max_pair_stake_amount(self, pair: str, price: float, leverage: float = 1.0) -> float:
         if self.trading_mode == TradingMode.SPOT:
-            return float('inf')  # Not actually inf, but this probably won't matter for SPOT
+            return float("inf")  # Not actually inf, but this probably won't matter for SPOT
 
         if pair not in self._leverage_tiers:
-            return float('inf')
+            return float("inf")
 
         pair_tiers = self._leverage_tiers[pair]
-        return pair_tiers[-1]['maxNotional'] / leverage
+        return pair_tiers[-1]["maxNotional"] / leverage
 
     def _get_stop_params(self, side: BuySell, ordertype: str, stop_price: float) -> Dict:
         params = super()._get_stop_params(side, ordertype, stop_price)
         if self.trading_mode == TradingMode.FUTURES and self.margin_mode:
-            params['tdMode'] = self.margin_mode.value
-            params['posSide'] = self._get_posSide(side, True)
+            params["tdMode"] = self.margin_mode.value
+            params["posSide"] = self._get_posSide(side, True)
         return params
 
     def _convert_stop_order(self, pair: str, order_id: str, order: Dict) -> Dict:
         if (
-            order.get('status', 'open') == 'closed'
-            and (real_order_id := order.get('info', {}).get('ordId')) is not None
+            order.get("status", "open") == "closed"
+            and (real_order_id := order.get("info", {}).get("ordId")) is not None
         ):
             # Once a order triggered, we fetch the regular followup order.
             order_reg = self.fetch_order(real_order_id, pair)
-            self._log_exchange_response('fetch_stoploss_order1', order_reg)
-            order_reg['id_stop'] = order_reg['id']
-            order_reg['id'] = order_id
-            order_reg['type'] = 'stoploss'
-            order_reg['status_stop'] = 'triggered'
+            self._log_exchange_response("fetch_stoploss_order1", order_reg)
+            order_reg["id_stop"] = order_reg["id"]
+            order_reg["id"] = order_id
+            order_reg["type"] = "stoploss"
+            order_reg["status_stop"] = "triggered"
             return order_reg
         order = self._order_contracts_to_amount(order)
-        order['type'] = 'stoploss'
+        order["type"] = "stoploss"
         return order
 
     def fetch_stoploss_order(self, order_id: str, pair: str, params: Optional[Dict] = None) -> Dict:
-        if self._config['dry_run']:
+        if self._config["dry_run"]:
             return self.fetch_dry_run_order(order_id)
 
         try:
-            params1 = {'stop': True}
+            params1 = {"stop": True}
             order_reg = self._api.fetch_order(order_id, pair, params=params1)
-            self._log_exchange_response('fetch_stoploss_order', order_reg)
+            self._log_exchange_response("fetch_stoploss_order", order_reg)
             return self._convert_stop_order(pair, order_id, order_reg)
         except ccxt.OrderNotFound:
             pass
-        params2 = {'stop': True, 'ordType': 'conditional'}
-        for method in (self._api.fetch_open_orders, self._api.fetch_closed_orders,
-                       self._api.fetch_canceled_orders):
+        params2 = {"stop": True, "ordType": "conditional"}
+        for method in (
+            self._api.fetch_open_orders,
+            self._api.fetch_closed_orders,
+            self._api.fetch_canceled_orders,
+        ):
             try:
                 orders = method(pair, params=params2)
-                orders_f = [order for order in orders if order['id'] == order_id]
+                orders_f = [order for order in orders if order["id"] == order_id]
                 if orders_f:
                     order = orders_f[0]
                     return self._convert_stop_order(pair, order_id, order)
             except ccxt.BaseError:
                 pass
-        raise RetryableOrderError(
-                f'StoplossOrder not found (pair: {pair} id: {order_id}).')
+        raise RetryableOrderError(f"StoplossOrder not found (pair: {pair} id: {order_id}).")
 
     def get_order_id_conditional(self, order: Dict[str, Any]) -> str:
-        if order.get('type', '') == 'stop':
-            return safe_value_fallback2(order, order, 'id_stop', 'id')
-        return order['id']
+        if order.get("type", "") == "stop":
+            return safe_value_fallback2(order, order, "id_stop", "id")
+        return order["id"]
 
     def cancel_stoploss_order(
-            self, order_id: str, pair: str, params: Optional[Dict] = None) -> Dict:
-        params1 = {'stop': True}
+        self, order_id: str, pair: str, params: Optional[Dict] = None
+    ) -> Dict:
+        params1 = {"stop": True}
         # 'ordType': 'conditional'
         #
         return self.cancel_order(
             order_id=order_id,
             pair=pair,
             params=params1,
         )
 
     def _fetch_orders_emulate(self, pair: str, since_ms: int) -> List[Dict]:
         orders = []
 
         orders = self._api.fetch_closed_orders(pair, since=since_ms)
-        if (since_ms < dt_ts(dt_now() - timedelta(days=6, hours=23))):
+        if since_ms < dt_ts(dt_now() - timedelta(days=6, hours=23)):
             # Regular fetch_closed_orders only returns 7 days of data.
             # Force usage of "archive" endpoint, which returns 3 months of data.
-            params = {'method': 'privateGetTradeOrdersHistoryArchive'}
+            params = {"method": "privateGetTradeOrdersHistoryArchive"}
             orders_hist = self._api.fetch_closed_orders(pair, since=since_ms, params=params)
             orders.extend(orders_hist)
 
         orders_open = self._api.fetch_open_orders(pair, since=since_ms)
         orders.extend(orders_open)
         return orders
```

### Comparing `freqtrade-2024.4/freqtrade/exchange/types.py` & `freqtrade-2024.5/freqtrade/exchange/types.py`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/freqai/RL/Base3ActionRLEnv.py` & `freqtrade-2024.5/freqtrade/freqai/RL/Base3ActionRLEnv.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,14 +15,15 @@
     Sell = 2
 
 
 class Base3ActionRLEnv(BaseEnvironment):
     """
     Base class for a 3 action environment
     """
+
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
         self.actions = Actions
 
     def set_action_space(self):
         self.action_space = spaces.Discrete(len(Actions))
 
@@ -69,31 +70,38 @@
                 trade_type = "exit"
                 self._last_trade_tick = None
             else:
                 print("case not defined")
 
             if trade_type is not None:
                 self.trade_history.append(
-                    {'price': self.current_price(), 'index': self._current_tick,
-                     'type': trade_type, 'profit': self.get_unrealized_profit()})
-
-        if (self._total_profit < self.max_drawdown or
-                self._total_unrealized_profit < self.max_drawdown):
+                    {
+                        "price": self.current_price(),
+                        "index": self._current_tick,
+                        "type": trade_type,
+                        "profit": self.get_unrealized_profit(),
+                    }
+                )
+
+        if (
+            self._total_profit < self.max_drawdown
+            or self._total_unrealized_profit < self.max_drawdown
+        ):
             self._done = True
 
         self._position_history.append(self._position)
 
         info = dict(
             tick=self._current_tick,
             action=action,
             total_reward=self.total_reward,
             total_profit=self._total_profit,
             position=self._position.value,
             trade_duration=self.get_trade_duration(),
-            current_profit_pct=self.get_unrealized_profit()
+            current_profit_pct=self.get_unrealized_profit(),
         )
 
         observation = self._get_observation()
 
         # user can play with time if they want
         truncated = False
 
@@ -105,18 +113,22 @@
         """
         Determine if the signal is a trade signal
         e.g.: agent wants a Actions.Buy while it is in a Positions.short
         """
         return (
             (action == Actions.Buy.value and self._position == Positions.Neutral)
             or (action == Actions.Sell.value and self._position == Positions.Long)
-            or (action == Actions.Sell.value and self._position == Positions.Neutral
-                and self.can_short)
-            or (action == Actions.Buy.value and self._position == Positions.Short
-                and self.can_short)
+            or (
+                action == Actions.Sell.value
+                and self._position == Positions.Neutral
+                and self.can_short
+            )
+            or (
+                action == Actions.Buy.value and self._position == Positions.Short and self.can_short
+            )
         )
 
     def _is_valid(self, action: int) -> bool:
         """
         Determine if the signal is valid.
         e.g.: agent wants a Actions.Sell while it is in a Positions.Long
         """
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/RL/Base4ActionRLEnv.py` & `freqtrade-2024.5/freqtrade/freqai/RL/Base4ActionRLEnv.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,14 +16,15 @@
     Short_enter = 3
 
 
 class Base4ActionRLEnv(BaseEnvironment):
     """
     Base class for a 4 action environment
     """
+
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
         self.actions = Actions
 
     def set_action_space(self):
         self.action_space = spaces.Discrete(len(Actions))
 
@@ -48,15 +49,14 @@
         self._update_unrealized_total_profit()
         step_reward = self.calculate_reward(action)
         self.total_reward += step_reward
         self.tensorboard_log(self.actions._member_names_[action], category="actions")
 
         trade_type = None
         if self.is_tradesignal(action):
-
             if action == Actions.Neutral.value:
                 self._position = Positions.Neutral
                 trade_type = "neutral"
                 self._last_trade_tick = None
             elif action == Actions.Long_enter.value:
                 self._position = Positions.Long
                 trade_type = "enter_long"
@@ -71,31 +71,38 @@
                 trade_type = "exit"
                 self._last_trade_tick = None
             else:
                 print("case not defined")
 
             if trade_type is not None:
                 self.trade_history.append(
-                    {'price': self.current_price(), 'index': self._current_tick,
-                     'type': trade_type, 'profit': self.get_unrealized_profit()})
-
-        if (self._total_profit < self.max_drawdown or
-                self._total_unrealized_profit < self.max_drawdown):
+                    {
+                        "price": self.current_price(),
+                        "index": self._current_tick,
+                        "type": trade_type,
+                        "profit": self.get_unrealized_profit(),
+                    }
+                )
+
+        if (
+            self._total_profit < self.max_drawdown
+            or self._total_unrealized_profit < self.max_drawdown
+        ):
             self._done = True
 
         self._position_history.append(self._position)
 
         info = dict(
             tick=self._current_tick,
             action=action,
             total_reward=self.total_reward,
             total_profit=self._total_profit,
             position=self._position.value,
             trade_duration=self.get_trade_duration(),
-            current_profit_pct=self.get_unrealized_profit()
+            current_profit_pct=self.get_unrealized_profit(),
         )
 
         observation = self._get_observation()
 
         # user can play with time if they want
         truncated = False
 
@@ -104,22 +111,24 @@
         return observation, step_reward, self._done, truncated, info
 
     def is_tradesignal(self, action: int) -> bool:
         """
         Determine if the signal is a trade signal
         e.g.: agent wants a Actions.Long_exit while it is in a Positions.short
         """
-        return not ((action == Actions.Neutral.value and self._position == Positions.Neutral) or
-                    (action == Actions.Neutral.value and self._position == Positions.Short) or
-                    (action == Actions.Neutral.value and self._position == Positions.Long) or
-                    (action == Actions.Short_enter.value and self._position == Positions.Short) or
-                    (action == Actions.Short_enter.value and self._position == Positions.Long) or
-                    (action == Actions.Exit.value and self._position == Positions.Neutral) or
-                    (action == Actions.Long_enter.value and self._position == Positions.Long) or
-                    (action == Actions.Long_enter.value and self._position == Positions.Short))
+        return not (
+            (action == Actions.Neutral.value and self._position == Positions.Neutral)
+            or (action == Actions.Neutral.value and self._position == Positions.Short)
+            or (action == Actions.Neutral.value and self._position == Positions.Long)
+            or (action == Actions.Short_enter.value and self._position == Positions.Short)
+            or (action == Actions.Short_enter.value and self._position == Positions.Long)
+            or (action == Actions.Exit.value and self._position == Positions.Neutral)
+            or (action == Actions.Long_enter.value and self._position == Positions.Long)
+            or (action == Actions.Long_enter.value and self._position == Positions.Short)
+        )
 
     def _is_valid(self, action: int) -> bool:
         """
         Determine if the signal is valid.
         e.g.: agent wants a Actions.Long_exit while it is in a Positions.short
         """
         # Agent should only try to exit if it is in position
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/RL/Base5ActionRLEnv.py` & `freqtrade-2024.5/freqtrade/freqai/RL/Base5ActionRLEnv.py`

 * *Files 12% similar despite different names*

```diff
@@ -17,14 +17,15 @@
     Short_exit = 4
 
 
 class Base5ActionRLEnv(BaseEnvironment):
     """
     Base class for a 5 action environment
     """
+
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
         self.actions = Actions
 
     def set_action_space(self):
         self.action_space = spaces.Discrete(len(Actions))
 
@@ -49,15 +50,14 @@
         self._update_unrealized_total_profit()
         step_reward = self.calculate_reward(action)
         self.total_reward += step_reward
         self.tensorboard_log(self.actions._member_names_[action], category="actions")
 
         trade_type = None
         if self.is_tradesignal(action):
-
             if action == Actions.Neutral.value:
                 self._position = Positions.Neutral
                 trade_type = "neutral"
                 self._last_trade_tick = None
             elif action == Actions.Long_enter.value:
                 self._position = Positions.Long
                 trade_type = "enter_long"
@@ -77,31 +77,38 @@
                 trade_type = "exit_short"
                 self._last_trade_tick = None
             else:
                 print("case not defined")
 
             if trade_type is not None:
                 self.trade_history.append(
-                    {'price': self.current_price(), 'index': self._current_tick,
-                     'type': trade_type, 'profit': self.get_unrealized_profit()})
-
-        if (self._total_profit < self.max_drawdown or
-                self._total_unrealized_profit < self.max_drawdown):
+                    {
+                        "price": self.current_price(),
+                        "index": self._current_tick,
+                        "type": trade_type,
+                        "profit": self.get_unrealized_profit(),
+                    }
+                )
+
+        if (
+            self._total_profit < self.max_drawdown
+            or self._total_unrealized_profit < self.max_drawdown
+        ):
             self._done = True
 
         self._position_history.append(self._position)
 
         info = dict(
             tick=self._current_tick,
             action=action,
             total_reward=self.total_reward,
             total_profit=self._total_profit,
             position=self._position.value,
             trade_duration=self.get_trade_duration(),
-            current_profit_pct=self.get_unrealized_profit()
+            current_profit_pct=self.get_unrealized_profit(),
         )
 
         observation = self._get_observation()
         # user can play with time if they want
         truncated = False
 
         self._update_history(info)
@@ -109,25 +116,27 @@
         return observation, step_reward, self._done, truncated, info
 
     def is_tradesignal(self, action: int) -> bool:
         """
         Determine if the signal is a trade signal
         e.g.: agent wants a Actions.Long_exit while it is in a Positions.short
         """
-        return not ((action == Actions.Neutral.value and self._position == Positions.Neutral) or
-                    (action == Actions.Neutral.value and self._position == Positions.Short) or
-                    (action == Actions.Neutral.value and self._position == Positions.Long) or
-                    (action == Actions.Short_enter.value and self._position == Positions.Short) or
-                    (action == Actions.Short_enter.value and self._position == Positions.Long) or
-                    (action == Actions.Short_exit.value and self._position == Positions.Long) or
-                    (action == Actions.Short_exit.value and self._position == Positions.Neutral) or
-                    (action == Actions.Long_enter.value and self._position == Positions.Long) or
-                    (action == Actions.Long_enter.value and self._position == Positions.Short) or
-                    (action == Actions.Long_exit.value and self._position == Positions.Short) or
-                    (action == Actions.Long_exit.value and self._position == Positions.Neutral))
+        return not (
+            (action == Actions.Neutral.value and self._position == Positions.Neutral)
+            or (action == Actions.Neutral.value and self._position == Positions.Short)
+            or (action == Actions.Neutral.value and self._position == Positions.Long)
+            or (action == Actions.Short_enter.value and self._position == Positions.Short)
+            or (action == Actions.Short_enter.value and self._position == Positions.Long)
+            or (action == Actions.Short_exit.value and self._position == Positions.Long)
+            or (action == Actions.Short_exit.value and self._position == Positions.Neutral)
+            or (action == Actions.Long_enter.value and self._position == Positions.Long)
+            or (action == Actions.Long_enter.value and self._position == Positions.Short)
+            or (action == Actions.Long_exit.value and self._position == Positions.Short)
+            or (action == Actions.Long_exit.value and self._position == Positions.Neutral)
+        )
 
     def _is_valid(self, action: int) -> bool:
         # trade signal
         """
         Determine if the signal is valid.
         e.g.: agent wants a Actions.Long_exit while it is in a Positions.short
         """
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/RL/BaseEnvironment.py` & `freqtrade-2024.5/freqtrade/freqai/RL/BaseEnvironment.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 logger = logging.getLogger(__name__)
 
 
 class BaseActions(Enum):
     """
     Default action space, mostly used for type handling.
     """
+
     Neutral = 0
     Long_enter = 1
     Long_exit = 2
     Short_enter = 3
     Short_exit = 4
 
 
@@ -40,19 +41,30 @@
 class BaseEnvironment(gym.Env):
     """
     Base class for environments. This class is agnostic to action count.
     Inherited classes customize this to include varying action counts/types,
     See RL/Base5ActionRLEnv.py and RL/Base4ActionRLEnv.py
     """
 
-    def __init__(self, df: DataFrame = DataFrame(), prices: DataFrame = DataFrame(),
-                 reward_kwargs: dict = {}, window_size=10, starting_point=True,
-                 id: str = 'baseenv-1', seed: int = 1, config: dict = {}, live: bool = False,
-                 fee: float = 0.0015, can_short: bool = False, pair: str = "",
-                 df_raw: DataFrame = DataFrame()):
+    def __init__(
+        self,
+        df: DataFrame = DataFrame(),
+        prices: DataFrame = DataFrame(),
+        reward_kwargs: dict = {},
+        window_size=10,
+        starting_point=True,
+        id: str = "baseenv-1",
+        seed: int = 1,
+        config: dict = {},
+        live: bool = False,
+        fee: float = 0.0015,
+        can_short: bool = False,
+        pair: str = "",
+        df_raw: DataFrame = DataFrame(),
+    ):
         """
         Initializes the training/eval environment.
         :param df: dataframe of features
         :param prices: dataframe of prices to be used in the training environment
         :param window_size: size of window (temporal) to pass to the agent
         :param reward_kwargs: extra config settings assigned by user in `rl_config`
         :param starting_point: start at edge of window or not
@@ -60,40 +72,48 @@
         :param seed: Sets the seed of the environment higher in the gym.Env object
         :param config: Typical user configuration file
         :param live: Whether or not this environment is active in dry/live/backtesting
         :param fee: The fee to use for environmental interactions.
         :param can_short: Whether or not the environment can short
         """
         self.config: dict = config
-        self.rl_config: dict = config['freqai']['rl_config']
-        self.add_state_info: bool = self.rl_config.get('add_state_info', False)
+        self.rl_config: dict = config["freqai"]["rl_config"]
+        self.add_state_info: bool = self.rl_config.get("add_state_info", False)
         self.id: str = id
-        self.max_drawdown: float = 1 - self.rl_config.get('max_training_drawdown_pct', 0.8)
-        self.compound_trades: bool = config['stake_amount'] == 'unlimited'
+        self.max_drawdown: float = 1 - self.rl_config.get("max_training_drawdown_pct", 0.8)
+        self.compound_trades: bool = config["stake_amount"] == "unlimited"
         self.pair: str = pair
         self.raw_features: DataFrame = df_raw
-        if self.config.get('fee', None) is not None:
-            self.fee = self.config['fee']
+        if self.config.get("fee", None) is not None:
+            self.fee = self.config["fee"]
         else:
             self.fee = fee
 
         # set here to default 5Ac, but all children envs can override this
         self.actions: Type[Enum] = BaseActions
         self.tensorboard_metrics: dict = {}
         self.can_short: bool = can_short
         self.live: bool = live
         if not self.live and self.add_state_info:
-            raise OperationalException("`add_state_info` is not available in backtesting. Change "
-                                       "parameter to false in your rl_config. See `add_state_info` "
-                                       "docs for more info.")
+            raise OperationalException(
+                "`add_state_info` is not available in backtesting. Change "
+                "parameter to false in your rl_config. See `add_state_info` "
+                "docs for more info."
+            )
         self.seed(seed)
         self.reset_env(df, prices, window_size, reward_kwargs, starting_point)
 
-    def reset_env(self, df: DataFrame, prices: DataFrame, window_size: int,
-                  reward_kwargs: dict, starting_point=True):
+    def reset_env(
+        self,
+        df: DataFrame,
+        prices: DataFrame,
+        window_size: int,
+        reward_kwargs: dict,
+        starting_point=True,
+    ):
         """
         Resets the environment when the agent fails (in our case, if the drawdown
         exceeds the user set max_training_drawdown_pct)
         :param df: dataframe of features
         :param prices: dataframe of prices to be used in the training environment
         :param window_size: size of window (temporal) to pass to the agent
         :param reward_kwargs: extra config settings assigned by user in `rl_config`
@@ -109,16 +129,15 @@
         # # spaces
         if self.add_state_info:
             self.total_features = self.signal_features.shape[1] + 3
         else:
             self.total_features = self.signal_features.shape[1]
         self.shape = (window_size, self.total_features)
         self.set_action_space()
-        self.observation_space = spaces.Box(
-            low=-1, high=1, shape=self.shape, dtype=np.float32)
+        self.observation_space = spaces.Box(low=-1, high=1, shape=self.shape, dtype=np.float32)
 
         # episode
         self._start_tick: int = self.window_size
         self._end_tick: int = len(self.prices) - 1
         self._done: bool = False
         self._current_tick: int = self._start_tick
         self._last_trade_tick: Optional[int] = None
@@ -147,16 +166,21 @@
     def action_masks(self) -> List[bool]:
         return [self._is_valid(action.value) for action in self.actions]
 
     def seed(self, seed: int = 1):
         self.np_random, seed = seeding.np_random(seed)
         return [seed]
 
-    def tensorboard_log(self, metric: str, value: Optional[Union[int, float]] = None,
-                        inc: Optional[bool] = None, category: str = "custom"):
+    def tensorboard_log(
+        self,
+        metric: str,
+        value: Optional[Union[int, float]] = None,
+        inc: Optional[bool] = None,
+        category: str = "custom",
+    ):
         """
         Function builds the tensorboard_metrics dictionary
         to be parsed by the TensorboardCallback. This
         function is designed for tracking incremented objects,
         events, actions inside the training environment.
         For example, a user can call this to track the
         frequency of occurrence of an `is_valid` call in
@@ -191,28 +215,28 @@
         Reset is called at the beginning of every episode
         """
         self.reset_tensorboard_log()
 
         self._done = False
 
         if self.starting_point is True:
-            if self.rl_config.get('randomize_starting_position', False):
+            if self.rl_config.get("randomize_starting_position", False):
                 length_of_data = int(self._end_tick / 4)
                 start_tick = random.randint(self.window_size + 1, length_of_data)
                 self._start_tick = start_tick
             self._position_history = (self._start_tick * [None]) + [self._position]
         else:
             self._position_history = (self.window_size * [None]) + [self._position]
 
         self._current_tick = self._start_tick
         self._last_trade_tick = None
         self._position = Positions.Neutral
 
-        self.total_reward = 0.
-        self._total_profit = 1.  # unit
+        self.total_reward = 0.0
+        self._total_profit = 1.0  # unit
         self.history = {}
         self.trade_history = []
         self.portfolio_log_returns = np.zeros(len(self.prices))
 
         self._profits = [(self._start_tick, 1)]
         self.close_trade_profit = []
         self._total_unrealized_profit = 1
@@ -227,26 +251,27 @@
         return
 
     def _get_observation(self):
         """
         This may or may not be independent of action types, user can inherit
         this in their custom "MyRLEnv"
         """
-        features_window = self.signal_features[(
-            self._current_tick - self.window_size):self._current_tick]
+        features_window = self.signal_features[
+            (self._current_tick - self.window_size) : self._current_tick
+        ]
         if self.add_state_info:
-            features_and_state = DataFrame(np.zeros((len(features_window), 3)),
-                                           columns=['current_profit_pct',
-                                                    'position',
-                                                    'trade_duration'],
-                                           index=features_window.index)
-
-            features_and_state['current_profit_pct'] = self.get_unrealized_profit()
-            features_and_state['position'] = self._position.value
-            features_and_state['trade_duration'] = self.get_trade_duration()
+            features_and_state = DataFrame(
+                np.zeros((len(features_window), 3)),
+                columns=["current_profit_pct", "position", "trade_duration"],
+                index=features_window.index,
+            )
+
+            features_and_state["current_profit_pct"] = self.get_unrealized_profit()
+            features_and_state["position"] = self._position.value
+            features_and_state["trade_duration"] = self.get_trade_duration()
             features_and_state = pd.concat([features_window, features_and_state], axis=1)
             return features_and_state
         else:
             return features_window
 
     def get_trade_duration(self):
         """
@@ -258,28 +283,28 @@
             return self._current_tick - self._last_trade_tick
 
     def get_unrealized_profit(self):
         """
         Get the unrealized profit if the agent is in a trade
         """
         if self._last_trade_tick is None:
-            return 0.
+            return 0.0
 
         if self._position == Positions.Neutral:
-            return 0.
+            return 0.0
         elif self._position == Positions.Short:
             current_price = self.add_entry_fee(self.prices.iloc[self._current_tick].open)
             last_trade_price = self.add_exit_fee(self.prices.iloc[self._last_trade_tick].open)
             return (last_trade_price - current_price) / last_trade_price
         elif self._position == Positions.Long:
             current_price = self.add_exit_fee(self.prices.iloc[self._current_tick].open)
             last_trade_price = self.add_entry_fee(self.prices.iloc[self._last_trade_tick].open)
             return (current_price - last_trade_price) / last_trade_price
         else:
-            return 0.
+            return 0.0
 
     @abstractmethod
     def is_tradesignal(self, action: int) -> bool:
         """
         Determine if the signal is a trade signal. This is
         unique to the actions in the environment, and therefore must be
         inherited.
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/RL/BaseReinforcementLearningModel.py` & `freqtrade-2024.5/freqtrade/freqai/RL/BaseReinforcementLearningModel.py`

 * *Files 4% similar despite different names*

```diff
@@ -26,134 +26,140 @@
 from freqtrade.freqai.RL.BaseEnvironment import BaseActions, BaseEnvironment, Positions
 from freqtrade.freqai.tensorboard.TensorboardCallback import TensorboardCallback
 from freqtrade.persistence import Trade
 
 
 logger = logging.getLogger(__name__)
 
-torch.multiprocessing.set_sharing_strategy('file_system')
+torch.multiprocessing.set_sharing_strategy("file_system")
 
-SB3_MODELS = ['PPO', 'A2C', 'DQN']
-SB3_CONTRIB_MODELS = ['TRPO', 'ARS', 'RecurrentPPO', 'MaskablePPO', 'QRDQN']
+SB3_MODELS = ["PPO", "A2C", "DQN"]
+SB3_CONTRIB_MODELS = ["TRPO", "ARS", "RecurrentPPO", "MaskablePPO", "QRDQN"]
 
 
 class BaseReinforcementLearningModel(IFreqaiModel):
     """
     User created Reinforcement Learning Model prediction class
     """
 
     def __init__(self, **kwargs) -> None:
-        super().__init__(config=kwargs['config'])
-        self.max_threads = min(self.freqai_info['rl_config'].get(
-            'cpu_count', 1), max(int(self.max_system_threads / 2), 1))
+        super().__init__(config=kwargs["config"])
+        self.max_threads = min(
+            self.freqai_info["rl_config"].get("cpu_count", 1),
+            max(int(self.max_system_threads / 2), 1),
+        )
         th.set_num_threads(self.max_threads)
-        self.reward_params = self.freqai_info['rl_config']['model_reward_parameters']
+        self.reward_params = self.freqai_info["rl_config"]["model_reward_parameters"]
         self.train_env: Union[VecMonitor, SubprocVecEnv, gym.Env] = gym.Env()
         self.eval_env: Union[VecMonitor, SubprocVecEnv, gym.Env] = gym.Env()
         self.eval_callback: Optional[MaskableEvalCallback] = None
-        self.model_type = self.freqai_info['rl_config']['model_type']
-        self.rl_config = self.freqai_info['rl_config']
+        self.model_type = self.freqai_info["rl_config"]["model_type"]
+        self.rl_config = self.freqai_info["rl_config"]
         self.df_raw: DataFrame = DataFrame()
-        self.continual_learning = self.freqai_info.get('continual_learning', False)
+        self.continual_learning = self.freqai_info.get("continual_learning", False)
         if self.model_type in SB3_MODELS:
-            import_str = 'stable_baselines3'
+            import_str = "stable_baselines3"
         elif self.model_type in SB3_CONTRIB_MODELS:
-            import_str = 'sb3_contrib'
+            import_str = "sb3_contrib"
         else:
-            raise OperationalException(f'{self.model_type} not available in stable_baselines3 or '
-                                       f'sb3_contrib. please choose one of {SB3_MODELS} or '
-                                       f'{SB3_CONTRIB_MODELS}')
+            raise OperationalException(
+                f"{self.model_type} not available in stable_baselines3 or "
+                f"sb3_contrib. please choose one of {SB3_MODELS} or "
+                f"{SB3_CONTRIB_MODELS}"
+            )
 
         mod = importlib.import_module(import_str, self.model_type)
         self.MODELCLASS = getattr(mod, self.model_type)
-        self.policy_type = self.freqai_info['rl_config']['policy_type']
+        self.policy_type = self.freqai_info["rl_config"]["policy_type"]
         self.unset_outlier_removal()
-        self.net_arch = self.rl_config.get('net_arch', [128, 128])
+        self.net_arch = self.rl_config.get("net_arch", [128, 128])
         self.dd.model_type = import_str
-        self.tensorboard_callback: TensorboardCallback = \
-            TensorboardCallback(verbose=1, actions=BaseActions)
+        self.tensorboard_callback: TensorboardCallback = TensorboardCallback(
+            verbose=1, actions=BaseActions
+        )
 
     def unset_outlier_removal(self):
         """
         If user has activated any function that may remove training points, this
         function will set them to false and warn them
         """
-        if self.ft_params.get('use_SVM_to_remove_outliers', False):
-            self.ft_params.update({'use_SVM_to_remove_outliers': False})
-            logger.warning('User tried to use SVM with RL. Deactivating SVM.')
-        if self.ft_params.get('use_DBSCAN_to_remove_outliers', False):
-            self.ft_params.update({'use_DBSCAN_to_remove_outliers': False})
-            logger.warning('User tried to use DBSCAN with RL. Deactivating DBSCAN.')
-        if self.ft_params.get('DI_threshold', False):
-            self.ft_params.update({'DI_threshold': False})
-            logger.warning('User tried to use DI_threshold with RL. Deactivating DI_threshold.')
-        if self.freqai_info['data_split_parameters'].get('shuffle', False):
-            self.freqai_info['data_split_parameters'].update({'shuffle': False})
-            logger.warning('User tried to shuffle training data. Setting shuffle to False')
-
-    def train(
-        self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs
-    ) -> Any:
+        if self.ft_params.get("use_SVM_to_remove_outliers", False):
+            self.ft_params.update({"use_SVM_to_remove_outliers": False})
+            logger.warning("User tried to use SVM with RL. Deactivating SVM.")
+        if self.ft_params.get("use_DBSCAN_to_remove_outliers", False):
+            self.ft_params.update({"use_DBSCAN_to_remove_outliers": False})
+            logger.warning("User tried to use DBSCAN with RL. Deactivating DBSCAN.")
+        if self.ft_params.get("DI_threshold", False):
+            self.ft_params.update({"DI_threshold": False})
+            logger.warning("User tried to use DI_threshold with RL. Deactivating DI_threshold.")
+        if self.freqai_info["data_split_parameters"].get("shuffle", False):
+            self.freqai_info["data_split_parameters"].update({"shuffle": False})
+            logger.warning("User tried to shuffle training data. Setting shuffle to False")
+
+    def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         Filter the training data and train a model to it. Train makes heavy use of the datakitchen
         for storing, saving, loading, and analyzing the data.
         :param unfiltered_df: Full dataframe for the current training period
         :param metadata: pair metadata from strategy.
         :returns:
         :model: Trained model which can be used to inference (self.predict)
         """
 
-        logger.info("--------------------Starting training " f"{pair} --------------------")
+        logger.info(f"--------------------Starting training {pair} --------------------")
 
         features_filtered, labels_filtered = dk.filter_features(
             unfiltered_df,
             dk.training_features_list,
             dk.label_list,
             training_filter=True,
         )
 
-        dd: Dict[str, Any] = dk.make_train_test_datasets(
-            features_filtered, labels_filtered)
+        dd: Dict[str, Any] = dk.make_train_test_datasets(features_filtered, labels_filtered)
         self.df_raw = copy.deepcopy(dd["train_features"])
         dk.fit_labels()  # FIXME useless for now, but just satiating append methods
 
         # normalize all data based on train_dataset only
         prices_train, prices_test = self.build_ohlc_price_dataframes(dk.data_dictionary, pair, dk)
 
         dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)
 
-        (dd["train_features"],
-         dd["train_labels"],
-         dd["train_weights"]) = dk.feature_pipeline.fit_transform(dd["train_features"],
-                                                                  dd["train_labels"],
-                                                                  dd["train_weights"])
-
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            (dd["test_features"],
-             dd["test_labels"],
-             dd["test_weights"]) = dk.feature_pipeline.transform(dd["test_features"],
-                                                                 dd["test_labels"],
-                                                                 dd["test_weights"])
+        (dd["train_features"], dd["train_labels"], dd["train_weights"]) = (
+            dk.feature_pipeline.fit_transform(
+                dd["train_features"], dd["train_labels"], dd["train_weights"]
+            )
+        )
+
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            (dd["test_features"], dd["test_labels"], dd["test_weights"]) = (
+                dk.feature_pipeline.transform(
+                    dd["test_features"], dd["test_labels"], dd["test_weights"]
+                )
+            )
 
         logger.info(
             f'Training model on {len(dk.data_dictionary["train_features"].columns)}'
             f' features and {len(dd["train_features"])} data points'
         )
 
         self.set_train_and_eval_environments(dd, prices_train, prices_test, dk)
 
         model = self.fit(dd, dk)
 
         logger.info(f"--------------------done training {pair}--------------------")
 
         return model
 
-    def set_train_and_eval_environments(self, data_dictionary: Dict[str, DataFrame],
-                                        prices_train: DataFrame, prices_test: DataFrame,
-                                        dk: FreqaiDataKitchen):
+    def set_train_and_eval_environments(
+        self,
+        data_dictionary: Dict[str, DataFrame],
+        prices_train: DataFrame,
+        prices_test: DataFrame,
+        dk: FreqaiDataKitchen,
+    ):
         """
         User can override this if they are using a custom MyRLEnv
         :param data_dictionary: dict = common data dictionary containing train and test
             features/labels/weights.
         :param prices_train/test: DataFrame = dataframe comprised of the prices to be used in the
             environment during training or testing
         :param dk: FreqaiDataKitchen = the datakitchen for the current pair
@@ -161,37 +167,43 @@
         train_df = data_dictionary["train_features"]
         test_df = data_dictionary["test_features"]
 
         env_info = self.pack_env_dict(dk.pair)
 
         self.train_env = self.MyRLEnv(df=train_df, prices=prices_train, **env_info)
         self.eval_env = Monitor(self.MyRLEnv(df=test_df, prices=prices_test, **env_info))
-        self.eval_callback = MaskableEvalCallback(self.eval_env, deterministic=True,
-                                                  render=False, eval_freq=len(train_df),
-                                                  best_model_save_path=str(dk.data_path),
-                                                  use_masking=(self.model_type == 'MaskablePPO' and
-                                                               is_masking_supported(self.eval_env)))
+        self.eval_callback = MaskableEvalCallback(
+            self.eval_env,
+            deterministic=True,
+            render=False,
+            eval_freq=len(train_df),
+            best_model_save_path=str(dk.data_path),
+            use_masking=(self.model_type == "MaskablePPO" and is_masking_supported(self.eval_env)),
+        )
 
         actions = self.train_env.get_actions()
         self.tensorboard_callback = TensorboardCallback(verbose=1, actions=actions)
 
     def pack_env_dict(self, pair: str) -> Dict[str, Any]:
         """
         Create dictionary of environment arguments
         """
-        env_info = {"window_size": self.CONV_WIDTH,
-                    "reward_kwargs": self.reward_params,
-                    "config": self.config,
-                    "live": self.live,
-                    "can_short": self.can_short,
-                    "pair": pair,
-                    "df_raw": self.df_raw}
+        env_info = {
+            "window_size": self.CONV_WIDTH,
+            "reward_kwargs": self.reward_params,
+            "config": self.config,
+            "live": self.live,
+            "can_short": self.can_short,
+            "pair": pair,
+            "df_raw": self.df_raw,
+        }
         if self.data_provider:
-            env_info["fee"] = self.data_provider._exchange \
-                .get_fee(symbol=self.data_provider.current_whitelist()[0])  # type: ignore
+            env_info["fee"] = self.data_provider._exchange.get_fee(  # type: ignore
+                symbol=self.data_provider.current_whitelist()[0]
+            )
 
         return env_info
 
     @abstractmethod
     def fit(self, data_dictionary: Dict[str, Any], dk: FreqaiDataKitchen, **kwargs):
         """
         Agent customizations and abstract Reinforcement Learning customizations
@@ -215,19 +227,20 @@
         open_trades = Trade.get_trades_proxy(is_open=True)
         market_side = 0.5
         current_profit: float = 0
         trade_duration = 0
         for trade in open_trades:
             if trade.pair == pair:
                 if self.data_provider._exchange is None:  # type: ignore
-                    logger.error('No exchange available.')
+                    logger.error("No exchange available.")
                     return 0, 0, 0
                 else:
                     current_rate = self.data_provider._exchange.get_rate(  # type: ignore
-                                pair, refresh=False, side="exit", is_short=trade.is_short)
+                        pair, refresh=False, side="exit", is_short=trade.is_short
+                    )
 
                 now = datetime.now(timezone.utc).timestamp()
                 trade_duration = int((now - trade.open_date_utc.timestamp()) / self.base_tf_seconds)
                 current_profit = trade.calc_profit_ratio(current_rate)
                 if trade.is_short:
                     market_side = 0
                 else:
@@ -251,81 +264,94 @@
         filtered_dataframe, _ = dk.filter_features(
             unfiltered_df, dk.training_features_list, training_filter=False
         )
 
         dk.data_dictionary["prediction_features"] = self.drop_ohlc_from_df(filtered_dataframe, dk)
 
         dk.data_dictionary["prediction_features"], _, _ = dk.feature_pipeline.transform(
-            dk.data_dictionary["prediction_features"], outlier_check=True)
+            dk.data_dictionary["prediction_features"], outlier_check=True
+        )
 
-        pred_df = self.rl_model_predict(
-            dk.data_dictionary["prediction_features"], dk, self.model)
+        pred_df = self.rl_model_predict(dk.data_dictionary["prediction_features"], dk, self.model)
         pred_df.fillna(0, inplace=True)
 
         return (pred_df, dk.do_predict)
 
-    def rl_model_predict(self, dataframe: DataFrame,
-                         dk: FreqaiDataKitchen, model: Any) -> DataFrame:
+    def rl_model_predict(
+        self, dataframe: DataFrame, dk: FreqaiDataKitchen, model: Any
+    ) -> DataFrame:
         """
         A helper function to make predictions in the Reinforcement learning module.
         :param dataframe: DataFrame = the dataframe of features to make the predictions on
         :param dk: FreqaiDatakitchen = data kitchen for the current pair
         :param model: Any = the trained model used to inference the features.
         """
         output = pd.DataFrame(np.zeros(len(dataframe)), columns=dk.label_list)
 
         def _predict(window):
             observations = dataframe.iloc[window.index]
-            if self.live and self.rl_config.get('add_state_info', False):
+            if self.live and self.rl_config.get("add_state_info", False):
                 market_side, current_profit, trade_duration = self.get_state_info(dk.pair)
-                observations['current_profit_pct'] = current_profit
-                observations['position'] = market_side
-                observations['trade_duration'] = trade_duration
+                observations["current_profit_pct"] = current_profit
+                observations["position"] = market_side
+                observations["trade_duration"] = trade_duration
             res, _ = model.predict(observations, deterministic=True)
             return res
 
         output = output.rolling(window=self.CONV_WIDTH).apply(_predict)
 
         return output
 
-    def build_ohlc_price_dataframes(self, data_dictionary: dict,
-                                    pair: str, dk: FreqaiDataKitchen) -> Tuple[DataFrame,
-                                                                               DataFrame]:
+    def build_ohlc_price_dataframes(
+        self, data_dictionary: dict, pair: str, dk: FreqaiDataKitchen
+    ) -> Tuple[DataFrame, DataFrame]:
         """
         Builds the train prices and test prices for the environment.
         """
 
-        pair = pair.replace(':', '')
+        pair = pair.replace(":", "")
         train_df = data_dictionary["train_features"]
         test_df = data_dictionary["test_features"]
 
         # price data for model training and evaluation
-        tf = self.config['timeframe']
-        rename_dict = {'%-raw_open': 'open', '%-raw_low': 'low',
-                       '%-raw_high': ' high', '%-raw_close': 'close'}
-        rename_dict_old = {f'%-{pair}raw_open_{tf}': 'open', f'%-{pair}raw_low_{tf}': 'low',
-                           f'%-{pair}raw_high_{tf}': ' high', f'%-{pair}raw_close_{tf}': 'close'}
+        tf = self.config["timeframe"]
+        rename_dict = {
+            "%-raw_open": "open",
+            "%-raw_low": "low",
+            "%-raw_high": " high",
+            "%-raw_close": "close",
+        }
+        rename_dict_old = {
+            f"%-{pair}raw_open_{tf}": "open",
+            f"%-{pair}raw_low_{tf}": "low",
+            f"%-{pair}raw_high_{tf}": " high",
+            f"%-{pair}raw_close_{tf}": "close",
+        }
 
         prices_train = train_df.filter(rename_dict.keys(), axis=1)
         prices_train_old = train_df.filter(rename_dict_old.keys(), axis=1)
         if prices_train.empty or not prices_train_old.empty:
             if not prices_train_old.empty:
                 prices_train = prices_train_old
                 rename_dict = rename_dict_old
-            logger.warning('Reinforcement learning module didn\'t find the correct raw prices '
-                           'assigned in feature_engineering_standard(). '
-                           'Please assign them with:\n'
-                           'dataframe["%-raw_close"] = dataframe["close"]\n'
-                           'dataframe["%-raw_open"] = dataframe["open"]\n'
-                           'dataframe["%-raw_high"] = dataframe["high"]\n'
-                           'dataframe["%-raw_low"] = dataframe["low"]\n'
-                           'inside `feature_engineering_standard()')
+            logger.warning(
+                "Reinforcement learning module didn't find the correct raw prices "
+                "assigned in feature_engineering_standard(). "
+                "Please assign them with:\n"
+                'dataframe["%-raw_close"] = dataframe["close"]\n'
+                'dataframe["%-raw_open"] = dataframe["open"]\n'
+                'dataframe["%-raw_high"] = dataframe["high"]\n'
+                'dataframe["%-raw_low"] = dataframe["low"]\n'
+                "inside `feature_engineering_standard()"
+            )
         elif prices_train.empty:
-            raise OperationalException("No prices found, please follow log warning "
-                                       "instructions to correct the strategy.")
+            raise OperationalException(
+                "No prices found, please follow log warning "
+                "instructions to correct the strategy."
+            )
 
         prices_train.rename(columns=rename_dict, inplace=True)
         prices_train.reset_index(drop=True)
 
         prices_test = test_df.filter(rename_dict.keys(), axis=1)
         prices_test.rename(columns=rename_dict, inplace=True)
         prices_test.reset_index(drop=True)
@@ -335,15 +361,15 @@
 
         return prices_train, prices_test
 
     def drop_ohlc_from_df(self, df: DataFrame, dk: FreqaiDataKitchen):
         """
         Given a dataframe, drop the ohlc data
         """
-        drop_list = ['%-raw_open', '%-raw_low', '%-raw_high', '%-raw_close']
+        drop_list = ["%-raw_open", "%-raw_low", "%-raw_high", "%-raw_close"]
 
         if self.rl_config["drop_ohlc_from_features"]:
             df.drop(drop_list, axis=1, inplace=True)
             feature_list = dk.training_features_list
             dk.training_features_list = [e for e in feature_list if e not in drop_list]
 
         return df
@@ -354,15 +380,15 @@
         perform continual learning.
         For now, this is unused.
         """
         exists = Path(dk.data_path / f"{dk.model_filename}_model").is_file()
         if exists:
             model = self.MODELCLASS.load(dk.data_path / f"{dk.model_filename}_model")
         else:
-            logger.info('No model file on disk to continue learning from.')
+            logger.info("No model file on disk to continue learning from.")
 
         return model
 
     def _on_stop(self):
         """
         Hook called on bot shutdown. Close SubprocVecEnv subprocesses for clean shutdown.
         """
@@ -396,79 +422,89 @@
                 of weights in NN)
             """
             # first, penalize if the action is not valid
             if not self._is_valid(action):
                 return -2
 
             pnl = self.get_unrealized_profit()
-            factor = 100.
+            factor = 100.0
 
             # you can use feature values from dataframe
-            rsi_now = self.raw_features[f"%-rsi-period-10_shift-1_{self.pair}_"
-                                        f"{self.config['timeframe']}"].iloc[self._current_tick]
+            rsi_now = self.raw_features[
+                f"%-rsi-period-10_shift-1_{self.pair}_{self.config['timeframe']}"
+            ].iloc[self._current_tick]
 
             # reward agent for entering trades
-            if (action in (Actions.Long_enter.value, Actions.Short_enter.value)
-                    and self._position == Positions.Neutral):
+            if (
+                action in (Actions.Long_enter.value, Actions.Short_enter.value)
+                and self._position == Positions.Neutral
+            ):
                 if rsi_now < 40:
                     factor = 40 / rsi_now
                 else:
                     factor = 1
                 return 25 * factor
 
             # discourage agent from not entering trades
             if action == Actions.Neutral.value and self._position == Positions.Neutral:
                 return -1
 
-            max_trade_duration = self.rl_config.get('max_trade_duration_candles', 300)
+            max_trade_duration = self.rl_config.get("max_trade_duration_candles", 300)
             if self._last_trade_tick:
                 trade_duration = self._current_tick - self._last_trade_tick
             else:
                 trade_duration = 0
 
             if trade_duration <= max_trade_duration:
                 factor *= 1.5
             elif trade_duration > max_trade_duration:
                 factor *= 0.5
 
             # discourage sitting in position
-            if (self._position in (Positions.Short, Positions.Long) and
-               action == Actions.Neutral.value):
+            if (
+                self._position in (Positions.Short, Positions.Long)
+                and action == Actions.Neutral.value
+            ):
                 return -1 * trade_duration / max_trade_duration
 
             # close long
             if action == Actions.Long_exit.value and self._position == Positions.Long:
                 if pnl > self.profit_aim * self.rr:
-                    factor *= self.rl_config['model_reward_parameters'].get('win_reward_factor', 2)
+                    factor *= self.rl_config["model_reward_parameters"].get("win_reward_factor", 2)
                 return float(pnl * factor)
 
             # close short
             if action == Actions.Short_exit.value and self._position == Positions.Short:
                 if pnl > self.profit_aim * self.rr:
-                    factor *= self.rl_config['model_reward_parameters'].get('win_reward_factor', 2)
+                    factor *= self.rl_config["model_reward_parameters"].get("win_reward_factor", 2)
                 return float(pnl * factor)
 
-            return 0.
+            return 0.0
 
 
-def make_env(MyRLEnv: Type[BaseEnvironment], env_id: str, rank: int,
-             seed: int, train_df: DataFrame, price: DataFrame,
-             env_info: Dict[str, Any] = {}) -> Callable:
+def make_env(
+    MyRLEnv: Type[BaseEnvironment],
+    env_id: str,
+    rank: int,
+    seed: int,
+    train_df: DataFrame,
+    price: DataFrame,
+    env_info: Dict[str, Any] = {},
+) -> Callable:
     """
     Utility function for multiprocessed env.
 
     :param env_id: (str) the environment ID
     :param num_env: (int) the number of environment you wish to have in subprocesses
     :param seed: (int) the initial seed for RNG
     :param rank: (int) index of the subprocess
     :param env_info: (dict) all required arguments to instantiate the environment.
     :return: (Callable)
     """
 
     def _init() -> gym.Env:
-
-        env = MyRLEnv(df=train_df, prices=price, id=env_id, seed=seed + rank,
-                      **env_info)
+        env = MyRLEnv(df=train_df, prices=price, id=env_id, seed=seed + rank, **env_info)
 
         return env
+
     set_random_seed(seed)
     return _init
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/base_models/BaseClassifierModel.py` & `freqtrade-2024.5/freqtrade/freqai/base_models/BaseRegressionModel.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,33 +1,30 @@
 import logging
 from time import time
 from typing import Any, Tuple
 
 import numpy as np
 import numpy.typing as npt
-import pandas as pd
 from pandas import DataFrame
 
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
 from freqtrade.freqai.freqai_interface import IFreqaiModel
 
 
 logger = logging.getLogger(__name__)
 
 
-class BaseClassifierModel(IFreqaiModel):
+class BaseRegressionModel(IFreqaiModel):
     """
     Base class for regression type models (e.g. Catboost, LightGBM, XGboost etc.).
     User *must* inherit from this class and set fit(). See example scripts
-    such as prediction_models/CatboostClassifier.py for guidance.
+    such as prediction_models/CatboostRegressor.py for guidance.
     """
 
-    def train(
-        self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs
-    ) -> Any:
+    def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         Filter the training data and train a model to it. Train makes heavy use of the datakitchen
         for storing, saving, loading, and analyzing the data.
         :param unfiltered_df: Full dataframe for the current training period
         :param metadata: pair metadata from strategy.
         :return:
         :model: Trained model which can be used to inference (self.predict)
@@ -43,46 +40,53 @@
             dk.training_features_list,
             dk.label_list,
             training_filter=True,
         )
 
         start_date = unfiltered_df["date"].iloc[0].strftime("%Y-%m-%d")
         end_date = unfiltered_df["date"].iloc[-1].strftime("%Y-%m-%d")
-        logger.info(f"-------------------- Training on data from {start_date} to "
-                    f"{end_date} --------------------")
+        logger.info(
+            f"-------------------- Training on data from {start_date} to "
+            f"{end_date} --------------------"
+        )
         # split data into train/test data.
         dd = dk.make_train_test_datasets(features_filtered, labels_filtered)
         if not self.freqai_info.get("fit_live_predictions_candles", 0) or not self.live:
             dk.fit_labels()
         dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)
+        dk.label_pipeline = self.define_label_pipeline(threads=dk.thread_count)
+
+        (dd["train_features"], dd["train_labels"], dd["train_weights"]) = (
+            dk.feature_pipeline.fit_transform(
+                dd["train_features"], dd["train_labels"], dd["train_weights"]
+            )
+        )
+        dd["train_labels"], _, _ = dk.label_pipeline.fit_transform(dd["train_labels"])
 
-        (dd["train_features"],
-         dd["train_labels"],
-         dd["train_weights"]) = dk.feature_pipeline.fit_transform(dd["train_features"],
-                                                                  dd["train_labels"],
-                                                                  dd["train_weights"])
-
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            (dd["test_features"],
-             dd["test_labels"],
-             dd["test_weights"]) = dk.feature_pipeline.transform(dd["test_features"],
-                                                                 dd["test_labels"],
-                                                                 dd["test_weights"])
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            (dd["test_features"], dd["test_labels"], dd["test_weights"]) = (
+                dk.feature_pipeline.transform(
+                    dd["test_features"], dd["test_labels"], dd["test_weights"]
+                )
+            )
+            dd["test_labels"], _, _ = dk.label_pipeline.transform(dd["test_labels"])
 
         logger.info(
             f"Training model on {len(dk.data_dictionary['train_features'].columns)} features"
         )
         logger.info(f"Training model on {len(dd['train_features'])} data points")
 
         model = self.fit(dd, dk)
 
         end_time = time()
 
-        logger.info(f"-------------------- Done training {pair} "
-                    f"({end_time - start_time:.2f} secs) --------------------")
+        logger.info(
+            f"-------------------- Done training {pair} "
+            f"({end_time - start_time:.2f} secs) --------------------"
+        )
 
         return model
 
     def predict(
         self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs
     ) -> Tuple[DataFrame, npt.NDArray[np.int_]]:
         """
@@ -91,36 +95,29 @@
         :return:
         :pred_df: dataframe containing the predictions
         :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove
         data (NaNs) or felt uncertain about data (PCA and DI index)
         """
 
         dk.find_features(unfiltered_df)
-        filtered_df, _ = dk.filter_features(
+        dk.data_dictionary["prediction_features"], _ = dk.filter_features(
             unfiltered_df, dk.training_features_list, training_filter=False
         )
 
-        dk.data_dictionary["prediction_features"] = filtered_df
-
         dk.data_dictionary["prediction_features"], outliers, _ = dk.feature_pipeline.transform(
-            dk.data_dictionary["prediction_features"], outlier_check=True)
+            dk.data_dictionary["prediction_features"], outlier_check=True
+        )
 
         predictions = self.model.predict(dk.data_dictionary["prediction_features"])
         if self.CONV_WIDTH == 1:
             predictions = np.reshape(predictions, (-1, len(dk.label_list)))
 
         pred_df = DataFrame(predictions, columns=dk.label_list)
 
-        predictions_prob = self.model.predict_proba(dk.data_dictionary["prediction_features"])
-        if self.CONV_WIDTH == 1:
-            predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))
-        pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)
-
-        pred_df = pd.concat([pred_df, pred_df_prob], axis=1)
-
+        pred_df, _, _ = dk.label_pipeline.inverse_transform(pred_df)
         if dk.feature_pipeline["di"]:
             dk.DI_values = dk.feature_pipeline["di"].di_values
         else:
             dk.DI_values = np.zeros(outliers.shape[0])
         dk.do_predict = outliers
 
         return (pred_df, dk.do_predict)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/base_models/BasePyTorchClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/base_models/BasePyTorchClassifier.py`

 * *Files 4% similar despite different names*

```diff
@@ -55,34 +55,33 @@
         data (NaNs) or felt uncertain about data (PCA and DI index)
         :raises ValueError: if 'class_names' doesn't exist in model meta_data.
         """
 
         class_names = self.model.model_meta_data.get("class_names", None)
         if not class_names:
             raise ValueError(
-                "Missing class names. "
-                "self.model.model_meta_data['class_names'] is None."
+                "Missing class names. self.model.model_meta_data['class_names'] is None."
             )
 
         if not self.class_name_to_index:
             self.init_class_names_to_index_mapping(class_names)
 
         dk.find_features(unfiltered_df)
         filtered_df, _ = dk.filter_features(
             unfiltered_df, dk.training_features_list, training_filter=False
         )
 
         dk.data_dictionary["prediction_features"] = filtered_df
 
         dk.data_dictionary["prediction_features"], outliers, _ = dk.feature_pipeline.transform(
-            dk.data_dictionary["prediction_features"], outlier_check=True)
+            dk.data_dictionary["prediction_features"], outlier_check=True
+        )
 
         x = self.data_convertor.convert_x(
-            dk.data_dictionary["prediction_features"],
-            device=self.device
+            dk.data_dictionary["prediction_features"], device=self.device
         )
         self.model.model.eval()
         logits = self.model.model(x)
         probs = F.softmax(logits, dim=-1)
         predicted_classes = torch.argmax(probs, dim=-1)
         predicted_classes_str = self.decode_class_names(predicted_classes)
         # used .tolist to convert probs into an iterable, in this way Tensors
@@ -96,18 +95,18 @@
         else:
             dk.DI_values = np.zeros(outliers.shape[0])
         dk.do_predict = outliers
 
         return (pred_df, dk.do_predict)
 
     def encode_class_names(
-            self,
-            data_dictionary: Dict[str, pd.DataFrame],
-            dk: FreqaiDataKitchen,
-            class_names: List[str],
+        self,
+        data_dictionary: Dict[str, pd.DataFrame],
+        dk: FreqaiDataKitchen,
+        class_names: List[str],
     ):
         """
         encode class name, str -> int
         assuming first column of *_labels data frame to be the target column
         containing the class names
         """
 
@@ -116,23 +115,20 @@
             label_df = data_dictionary[f"{split}_labels"]
             self.assert_valid_class_names(label_df[target_column_name], class_names)
             label_df[target_column_name] = list(
                 map(lambda x: self.class_name_to_index[x], label_df[target_column_name])
             )
 
     @staticmethod
-    def assert_valid_class_names(
-            target_column: pd.Series,
-            class_names: List[str]
-    ):
+    def assert_valid_class_names(target_column: pd.Series, class_names: List[str]):
         non_defined_labels = set(target_column) - set(class_names)
         if len(non_defined_labels) != 0:
             raise OperationalException(
                 f"Found non defined labels: {non_defined_labels}, ",
-                f"expecting labels: {class_names}"
+                f"expecting labels: {class_names}",
             )
 
     def decode_class_names(self, class_ints: torch.Tensor) -> List[str]:
         """
         decode class name, int -> str
         """
 
@@ -140,35 +136,33 @@
 
     def init_class_names_to_index_mapping(self, class_names):
         self.class_name_to_index = {s: i for i, s in enumerate(class_names)}
         self.index_to_class_name = {i: s for i, s in enumerate(class_names)}
         logger.info(f"encoded class name to index: {self.class_name_to_index}")
 
     def convert_label_column_to_int(
-            self,
-            data_dictionary: Dict[str, pd.DataFrame],
-            dk: FreqaiDataKitchen,
-            class_names: List[str]
+        self,
+        data_dictionary: Dict[str, pd.DataFrame],
+        dk: FreqaiDataKitchen,
+        class_names: List[str],
     ):
         self.init_class_names_to_index_mapping(class_names)
         self.encode_class_names(data_dictionary, dk, class_names)
 
     def get_class_names(self) -> List[str]:
         if not self.class_names:
             raise ValueError(
                 "self.class_names is empty, "
                 "set self.freqai.class_names = ['class a', 'class b', 'class c'] "
                 "inside IStrategy.set_freqai_targets method."
             )
 
         return self.class_names
 
-    def train(
-        self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs
-    ) -> Any:
+    def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         Filter the training data and train a model to it. Train makes heavy use of the datakitchen
         for storing, saving, loading, and analyzing the data.
         :param unfiltered_df: Full dataframe for the current training period
         :return:
         :model: Trained model which can be used to inference (self.predict)
         """
@@ -187,32 +181,34 @@
         # split data into train/test data.
         dd = dk.make_train_test_datasets(features_filtered, labels_filtered)
         if not self.freqai_info.get("fit_live_predictions_candles", 0) or not self.live:
             dk.fit_labels()
 
         dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)
 
-        (dd["train_features"],
-         dd["train_labels"],
-         dd["train_weights"]) = dk.feature_pipeline.fit_transform(dd["train_features"],
-                                                                  dd["train_labels"],
-                                                                  dd["train_weights"])
-
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            (dd["test_features"],
-             dd["test_labels"],
-             dd["test_weights"]) = dk.feature_pipeline.transform(dd["test_features"],
-                                                                 dd["test_labels"],
-                                                                 dd["test_weights"])
+        (dd["train_features"], dd["train_labels"], dd["train_weights"]) = (
+            dk.feature_pipeline.fit_transform(
+                dd["train_features"], dd["train_labels"], dd["train_weights"]
+            )
+        )
+
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            (dd["test_features"], dd["test_labels"], dd["test_weights"]) = (
+                dk.feature_pipeline.transform(
+                    dd["test_features"], dd["test_labels"], dd["test_weights"]
+                )
+            )
 
         logger.info(
             f"Training model on {len(dk.data_dictionary['train_features'].columns)} features"
         )
         logger.info(f"Training model on {len(dd['train_features'])} data points")
 
         model = self.fit(dd, dk)
         end_time = time()
 
-        logger.info(f"-------------------- Done training {pair} "
-                    f"({end_time - start_time:.2f} secs) --------------------")
+        logger.info(
+            f"-------------------- Done training {pair} "
+            f"({end_time - start_time:.2f} secs) --------------------"
+        )
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/base_models/BasePyTorchModel.py` & `freqtrade-2024.5/freqtrade/freqai/base_models/BasePyTorchModel.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     data_convertor property.
     """
 
     def __init__(self, **kwargs):
         super().__init__(config=kwargs["config"])
         self.dd.model_type = "pytorch"
         self.device = "cuda" if torch.cuda.is_available() else "cpu"
-        test_size = self.freqai_info.get('data_split_parameters', {}).get('test_size')
+        test_size = self.freqai_info.get("data_split_parameters", {}).get("test_size")
         self.splits = ["train", "test"] if test_size != 0 else ["train"]
         self.window_size = self.freqai_info.get("conv_width", 1)
 
     @property
     @abstractmethod
     def data_convertor(self) -> PyTorchDataConvertor:
         """
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/base_models/BasePyTorchRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/base_models/BasePyTorchRegressor.py`

 * *Files 5% similar despite different names*

```diff
@@ -37,35 +37,33 @@
         dk.find_features(unfiltered_df)
         filtered_df, _ = dk.filter_features(
             unfiltered_df, dk.training_features_list, training_filter=False
         )
         dk.data_dictionary["prediction_features"] = filtered_df
 
         dk.data_dictionary["prediction_features"], outliers, _ = dk.feature_pipeline.transform(
-            dk.data_dictionary["prediction_features"], outlier_check=True)
+            dk.data_dictionary["prediction_features"], outlier_check=True
+        )
 
         x = self.data_convertor.convert_x(
-            dk.data_dictionary["prediction_features"],
-            device=self.device
+            dk.data_dictionary["prediction_features"], device=self.device
         )
         self.model.model.eval()
         y = self.model.model(x)
         pred_df = DataFrame(y.detach().tolist(), columns=[dk.label_list[0]])
         pred_df, _, _ = dk.label_pipeline.inverse_transform(pred_df)
 
         if dk.feature_pipeline["di"]:
             dk.DI_values = dk.feature_pipeline["di"].di_values
         else:
             dk.DI_values = np.zeros(outliers.shape[0])
         dk.do_predict = outliers
         return (pred_df, dk.do_predict)
 
-    def train(
-        self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs
-    ) -> Any:
+    def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         Filter the training data and train a model to it. Train makes heavy use of the datakitchen
         for storing, saving, loading, and analyzing the data.
         :param unfiltered_df: Full dataframe for the current training period
         :return:
         :model: Trained model which can be used to inference (self.predict)
         """
@@ -87,34 +85,36 @@
             dk.fit_labels()
         dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)
         dk.label_pipeline = self.define_label_pipeline(threads=dk.thread_count)
 
         dd["train_labels"], _, _ = dk.label_pipeline.fit_transform(dd["train_labels"])
         dd["test_labels"], _, _ = dk.label_pipeline.transform(dd["test_labels"])
 
-        (dd["train_features"],
-         dd["train_labels"],
-         dd["train_weights"]) = dk.feature_pipeline.fit_transform(dd["train_features"],
-                                                                  dd["train_labels"],
-                                                                  dd["train_weights"])
+        (dd["train_features"], dd["train_labels"], dd["train_weights"]) = (
+            dk.feature_pipeline.fit_transform(
+                dd["train_features"], dd["train_labels"], dd["train_weights"]
+            )
+        )
         dd["train_labels"], _, _ = dk.label_pipeline.fit_transform(dd["train_labels"])
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            (dd["test_features"],
-             dd["test_labels"],
-             dd["test_weights"]) = dk.feature_pipeline.transform(dd["test_features"],
-                                                                 dd["test_labels"],
-                                                                 dd["test_weights"])
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            (dd["test_features"], dd["test_labels"], dd["test_weights"]) = (
+                dk.feature_pipeline.transform(
+                    dd["test_features"], dd["test_labels"], dd["test_weights"]
+                )
+            )
             dd["test_labels"], _, _ = dk.label_pipeline.transform(dd["test_labels"])
 
         logger.info(
             f"Training model on {len(dk.data_dictionary['train_features'].columns)} features"
         )
         logger.info(f"Training model on {len(dd['train_features'])} data points")
 
         model = self.fit(dd, dk)
         end_time = time()
 
-        logger.info(f"-------------------- Done training {pair} "
-                    f"({end_time - start_time:.2f} secs) --------------------")
+        logger.info(
+            f"-------------------- Done training {pair} "
+            f"({end_time - start_time:.2f} secs) --------------------"
+        )
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/base_models/BaseRegressionModel.py` & `freqtrade-2024.5/freqtrade/freqai/base_models/BaseClassifierModel.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,32 +1,31 @@
 import logging
 from time import time
 from typing import Any, Tuple
 
 import numpy as np
 import numpy.typing as npt
+import pandas as pd
 from pandas import DataFrame
 
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
 from freqtrade.freqai.freqai_interface import IFreqaiModel
 
 
 logger = logging.getLogger(__name__)
 
 
-class BaseRegressionModel(IFreqaiModel):
+class BaseClassifierModel(IFreqaiModel):
     """
     Base class for regression type models (e.g. Catboost, LightGBM, XGboost etc.).
     User *must* inherit from this class and set fit(). See example scripts
-    such as prediction_models/CatboostRegressor.py for guidance.
+    such as prediction_models/CatboostClassifier.py for guidance.
     """
 
-    def train(
-        self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs
-    ) -> Any:
+    def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         Filter the training data and train a model to it. Train makes heavy use of the datakitchen
         for storing, saving, loading, and analyzing the data.
         :param unfiltered_df: Full dataframe for the current training period
         :param metadata: pair metadata from strategy.
         :return:
         :model: Trained model which can be used to inference (self.predict)
@@ -42,49 +41,50 @@
             dk.training_features_list,
             dk.label_list,
             training_filter=True,
         )
 
         start_date = unfiltered_df["date"].iloc[0].strftime("%Y-%m-%d")
         end_date = unfiltered_df["date"].iloc[-1].strftime("%Y-%m-%d")
-        logger.info(f"-------------------- Training on data from {start_date} to "
-                    f"{end_date} --------------------")
+        logger.info(
+            f"-------------------- Training on data from {start_date} to "
+            f"{end_date} --------------------"
+        )
         # split data into train/test data.
         dd = dk.make_train_test_datasets(features_filtered, labels_filtered)
         if not self.freqai_info.get("fit_live_predictions_candles", 0) or not self.live:
             dk.fit_labels()
         dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)
-        dk.label_pipeline = self.define_label_pipeline(threads=dk.thread_count)
 
-        (dd["train_features"],
-         dd["train_labels"],
-         dd["train_weights"]) = dk.feature_pipeline.fit_transform(dd["train_features"],
-                                                                  dd["train_labels"],
-                                                                  dd["train_weights"])
-        dd["train_labels"], _, _ = dk.label_pipeline.fit_transform(dd["train_labels"])
-
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            (dd["test_features"],
-             dd["test_labels"],
-             dd["test_weights"]) = dk.feature_pipeline.transform(dd["test_features"],
-                                                                 dd["test_labels"],
-                                                                 dd["test_weights"])
-            dd["test_labels"], _, _ = dk.label_pipeline.transform(dd["test_labels"])
+        (dd["train_features"], dd["train_labels"], dd["train_weights"]) = (
+            dk.feature_pipeline.fit_transform(
+                dd["train_features"], dd["train_labels"], dd["train_weights"]
+            )
+        )
+
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            (dd["test_features"], dd["test_labels"], dd["test_weights"]) = (
+                dk.feature_pipeline.transform(
+                    dd["test_features"], dd["test_labels"], dd["test_weights"]
+                )
+            )
 
         logger.info(
             f"Training model on {len(dk.data_dictionary['train_features'].columns)} features"
         )
         logger.info(f"Training model on {len(dd['train_features'])} data points")
 
         model = self.fit(dd, dk)
 
         end_time = time()
 
-        logger.info(f"-------------------- Done training {pair} "
-                    f"({end_time - start_time:.2f} secs) --------------------")
+        logger.info(
+            f"-------------------- Done training {pair} "
+            f"({end_time - start_time:.2f} secs) --------------------"
+        )
 
         return model
 
     def predict(
         self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs
     ) -> Tuple[DataFrame, npt.NDArray[np.int_]]:
         """
@@ -93,28 +93,37 @@
         :return:
         :pred_df: dataframe containing the predictions
         :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove
         data (NaNs) or felt uncertain about data (PCA and DI index)
         """
 
         dk.find_features(unfiltered_df)
-        dk.data_dictionary["prediction_features"], _ = dk.filter_features(
+        filtered_df, _ = dk.filter_features(
             unfiltered_df, dk.training_features_list, training_filter=False
         )
 
+        dk.data_dictionary["prediction_features"] = filtered_df
+
         dk.data_dictionary["prediction_features"], outliers, _ = dk.feature_pipeline.transform(
-            dk.data_dictionary["prediction_features"], outlier_check=True)
+            dk.data_dictionary["prediction_features"], outlier_check=True
+        )
 
         predictions = self.model.predict(dk.data_dictionary["prediction_features"])
         if self.CONV_WIDTH == 1:
             predictions = np.reshape(predictions, (-1, len(dk.label_list)))
 
         pred_df = DataFrame(predictions, columns=dk.label_list)
 
-        pred_df, _, _ = dk.label_pipeline.inverse_transform(pred_df)
+        predictions_prob = self.model.predict_proba(dk.data_dictionary["prediction_features"])
+        if self.CONV_WIDTH == 1:
+            predictions_prob = np.reshape(predictions_prob, (-1, len(self.model.classes_)))
+        pred_df_prob = DataFrame(predictions_prob, columns=self.model.classes_)
+
+        pred_df = pd.concat([pred_df, pred_df_prob], axis=1)
+
         if dk.feature_pipeline["di"]:
             dk.DI_values = dk.feature_pipeline["di"].di_values
         else:
             dk.DI_values = np.zeros(outliers.shape[0])
         dk.do_predict = outliers
 
         return (pred_df, dk.do_predict)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/base_models/FreqaiMultiOutputClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/base_models/FreqaiMultiOutputClassifier.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 from sklearn.utils.parallel import Parallel, delayed
 from sklearn.utils.validation import has_fit_parameter
 
 from freqtrade.exceptions import OperationalException
 
 
 class FreqaiMultiOutputClassifier(MultiOutputClassifier):
-
     def fit(self, X, y, sample_weight=None, fit_params=None):
         """Fit the model to data, separately for each output variable.
         Parameters
         ----------
         X : {array-like, sparse matrix} of shape (n_samples, n_features)
             The input data.
         y : {array-like, sparse matrix} of shape (n_samples, n_outputs)
@@ -44,35 +43,32 @@
 
         if y.ndim == 1:
             raise ValueError(
                 "y must have at least two dimensions for "
                 "multi-output regression but has only one."
             )
 
-        if sample_weight is not None and not has_fit_parameter(
-            self.estimator, "sample_weight"
-        ):
+        if sample_weight is not None and not has_fit_parameter(self.estimator, "sample_weight"):
             raise ValueError("Underlying estimator does not support sample weights.")
 
         if not fit_params:
             fit_params = [None] * y.shape[1]
 
         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
-            delayed(_fit_estimator)(
-                self.estimator, X, y[:, i], sample_weight, **fit_params[i]
-            )
+            delayed(_fit_estimator)(self.estimator, X, y[:, i], sample_weight, **fit_params[i])
             for i in range(y.shape[1])
         )
 
         self.classes_ = []
         for estimator in self.estimators_:
             self.classes_.extend(estimator.classes_)
         if len(set(self.classes_)) != len(self.classes_):
-            raise OperationalException(f"Class labels must be unique across targets: "
-                                       f"{self.classes_}")
+            raise OperationalException(
+                f"Class labels must be unique across targets: {self.classes_}"
+            )
 
         if hasattr(self.estimators_[0], "n_features_in_"):
             self.n_features_in_ = self.estimators_[0].n_features_in_
         if hasattr(self.estimators_[0], "feature_names_in_"):
             self.feature_names_in_ = self.estimators_[0].feature_names_in_
 
         return self
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/base_models/FreqaiMultiOutputRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/base_models/FreqaiMultiOutputRegressor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from sklearn.multioutput import MultiOutputRegressor, _fit_estimator
 from sklearn.utils.parallel import Parallel, delayed
 from sklearn.utils.validation import has_fit_parameter
 
 
 class FreqaiMultiOutputRegressor(MultiOutputRegressor):
-
     def fit(self, X, y, sample_weight=None, fit_params=None):
         """Fit the model to data, separately for each output variable.
         Parameters
         ----------
         X : {array-like, sparse matrix} of shape (n_samples, n_features)
             The input data.
         y : {array-like, sparse matrix} of shape (n_samples, n_outputs)
@@ -36,26 +35,22 @@
 
         if y.ndim == 1:
             raise ValueError(
                 "y must have at least two dimensions for "
                 "multi-output regression but has only one."
             )
 
-        if sample_weight is not None and not has_fit_parameter(
-            self.estimator, "sample_weight"
-        ):
+        if sample_weight is not None and not has_fit_parameter(self.estimator, "sample_weight"):
             raise ValueError("Underlying estimator does not support sample weights.")
 
         if not fit_params:
             fit_params = [None] * y.shape[1]
 
         self.estimators_ = Parallel(n_jobs=self.n_jobs)(
-            delayed(_fit_estimator)(
-                self.estimator, X, y[:, i], sample_weight, **fit_params[i]
-            )
+            delayed(_fit_estimator)(self.estimator, X, y[:, i], sample_weight, **fit_params[i])
             for i in range(y.shape[1])
         )
 
         if hasattr(self.estimators_[0], "n_features_in_"):
             self.n_features_in_ = self.estimators_[0].n_features_in_
         if hasattr(self.estimators_[0], "feature_names_in_"):
             self.feature_names_in_ = self.estimators_[0].feature_names_in_
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/data_drawer.py` & `freqtrade-2024.5/freqtrade/freqai/data_drawer.py`

 * *Files 1% similar despite different names*

```diff
@@ -62,73 +62,76 @@
 
     Beta testing and bug reporting:
     @bloodhunter4rc, Salah Lamkadem @ikonx, @ken11o2, @longyu, @paranoidandy, @smidelis, @smarm
     Juha Nyknen @suikula, Wagner Costa @wagnercosta, Johan Vlugt @Jooopieeert
     """
 
     def __init__(self, full_path: Path, config: Config):
-
         self.config = config
         self.freqai_info = config.get("freqai", {})
         # dictionary holding all pair metadata necessary to load in from disk
         self.pair_dict: Dict[str, pair_info] = {}
         # dictionary holding all actively inferenced models in memory given a model filename
         self.model_dictionary: Dict[str, Any] = {}
         # all additional metadata that we want to keep in ram
         self.meta_data_dictionary: Dict[str, Dict[str, Any]] = {}
         self.model_return_values: Dict[str, DataFrame] = {}
         self.historic_data: Dict[str, Dict[str, DataFrame]] = {}
         self.historic_predictions: Dict[str, DataFrame] = {}
         self.full_path = full_path
         self.historic_predictions_path = Path(self.full_path / "historic_predictions.pkl")
         self.historic_predictions_bkp_path = Path(
-            self.full_path / "historic_predictions.backup.pkl")
+            self.full_path / "historic_predictions.backup.pkl"
+        )
         self.pair_dictionary_path = Path(self.full_path / "pair_dictionary.json")
         self.global_metadata_path = Path(self.full_path / "global_metadata.json")
         self.metric_tracker_path = Path(self.full_path / "metric_tracker.json")
         self.load_drawer_from_disk()
         self.load_historic_predictions_from_disk()
         self.metric_tracker: Dict[str, Dict[str, Dict[str, list]]] = {}
         self.load_metric_tracker_from_disk()
         self.training_queue: Dict[str, int] = {}
         self.history_lock = threading.Lock()
         self.save_lock = threading.Lock()
         self.pair_dict_lock = threading.Lock()
         self.metric_tracker_lock = threading.Lock()
         self.old_DBSCAN_eps: Dict[str, float] = {}
         self.empty_pair_dict: pair_info = {
-                "model_filename": "", "trained_timestamp": 0,
-                "data_path": "", "extras": {}}
-        self.model_type = self.freqai_info.get('model_save_type', 'joblib')
+            "model_filename": "",
+            "trained_timestamp": 0,
+            "data_path": "",
+            "extras": {},
+        }
+        self.model_type = self.freqai_info.get("model_save_type", "joblib")
 
     def update_metric_tracker(self, metric: str, value: float, pair: str) -> None:
         """
         General utility for adding and updating custom metrics. Typically used
         for adding training performance, train timings, inferenc timings, cpu loads etc.
         """
         with self.metric_tracker_lock:
             if pair not in self.metric_tracker:
                 self.metric_tracker[pair] = {}
             if metric not in self.metric_tracker[pair]:
-                self.metric_tracker[pair][metric] = {'timestamp': [], 'value': []}
+                self.metric_tracker[pair][metric] = {"timestamp": [], "value": []}
 
             timestamp = int(datetime.now(timezone.utc).timestamp())
-            self.metric_tracker[pair][metric]['value'].append(value)
-            self.metric_tracker[pair][metric]['timestamp'].append(timestamp)
+            self.metric_tracker[pair][metric]["value"].append(value)
+            self.metric_tracker[pair][metric]["timestamp"].append(timestamp)
 
     def collect_metrics(self, time_spent: float, pair: str):
         """
         Add metrics to the metric tracker dictionary
         """
         load1, load5, load15 = psutil.getloadavg()
         cpus = psutil.cpu_count()
-        self.update_metric_tracker('train_time', time_spent, pair)
-        self.update_metric_tracker('cpu_load1min', load1 / cpus, pair)
-        self.update_metric_tracker('cpu_load5min', load5 / cpus, pair)
-        self.update_metric_tracker('cpu_load15min', load15 / cpus, pair)
+        self.update_metric_tracker("train_time", time_spent, pair)
+        self.update_metric_tracker("cpu_load1min", load1 / cpus, pair)
+        self.update_metric_tracker("cpu_load5min", load5 / cpus, pair)
+        self.update_metric_tracker("cpu_load15min", load15 / cpus, pair)
 
     def load_global_metadata_from_disk(self):
         """
         Locate and load a previously saved global metadata in present model folder.
         """
         exists = self.global_metadata_path.is_file()
         if exists:
@@ -151,15 +154,15 @@
             logger.info("Could not find existing datadrawer, starting from scratch")
 
     def load_metric_tracker_from_disk(self):
         """
         Tries to load an existing metrics dictionary if the user
         wants to collect metrics.
         """
-        if self.freqai_info.get('write_metrics_to_disk', False):
+        if self.freqai_info.get("write_metrics_to_disk", False):
             exists = self.metric_tracker_path.is_file()
             if exists:
                 with self.metric_tracker_path.open("r") as fp:
                     self.metric_tracker = rapidjson.load(fp, number_mode=rapidjson.NM_NATIVE)
                 logger.info("Loading existing metric tracker from disk.")
             else:
                 logger.info("Could not find existing metric tracker, starting from scratch")
@@ -177,18 +180,19 @@
                 logger.info(
                     f"Found existing historic predictions at {self.full_path}, but beware "
                     "that statistics may be inaccurate if the bot has been offline for "
                     "an extended period of time."
                 )
             except EOFError:
                 logger.warning(
-                    'Historical prediction file was corrupted. Trying to load backup file.')
+                    "Historical prediction file was corrupted. Trying to load backup file."
+                )
                 with self.historic_predictions_bkp_path.open("rb") as fp:
                     self.historic_predictions = cloudpickle.load(fp)
-                logger.warning('FreqAI successfully loaded the backup historical predictions file.')
+                logger.warning("FreqAI successfully loaded the backup historical predictions file.")
 
         else:
             logger.info("Could not find existing historic_predictions, starting from scratch")
 
         return exists
 
     def save_historic_predictions_to_disk(self):
@@ -202,35 +206,41 @@
         shutil.copy(self.historic_predictions_path, self.historic_predictions_bkp_path)
 
     def save_metric_tracker_to_disk(self):
         """
         Save metric tracker of all pair metrics collected.
         """
         with self.save_lock:
-            with self.metric_tracker_path.open('w') as fp:
-                rapidjson.dump(self.metric_tracker, fp, default=self.np_encoder,
-                               number_mode=rapidjson.NM_NATIVE)
+            with self.metric_tracker_path.open("w") as fp:
+                rapidjson.dump(
+                    self.metric_tracker,
+                    fp,
+                    default=self.np_encoder,
+                    number_mode=rapidjson.NM_NATIVE,
+                )
 
     def save_drawer_to_disk(self) -> None:
         """
         Save data drawer full of all pair model metadata in present model folder.
         """
         with self.save_lock:
-            with self.pair_dictionary_path.open('w') as fp:
-                rapidjson.dump(self.pair_dict, fp, default=self.np_encoder,
-                               number_mode=rapidjson.NM_NATIVE)
+            with self.pair_dictionary_path.open("w") as fp:
+                rapidjson.dump(
+                    self.pair_dict, fp, default=self.np_encoder, number_mode=rapidjson.NM_NATIVE
+                )
 
     def save_global_metadata_to_disk(self, metadata: Dict[str, Any]):
         """
         Save global metadata json to disk
         """
         with self.save_lock:
-            with self.global_metadata_path.open('w') as fp:
-                rapidjson.dump(metadata, fp, default=self.np_encoder,
-                               number_mode=rapidjson.NM_NATIVE)
+            with self.global_metadata_path.open("w") as fp:
+                rapidjson.dump(
+                    metadata, fp, default=self.np_encoder, number_mode=rapidjson.NM_NATIVE
+                )
 
     def np_encoder(self, object):
         if isinstance(object, np.generic):
             return object.item()
 
     def get_pair_dict_info(self, pair: str) -> Tuple[str, int]:
         """
@@ -260,17 +270,15 @@
         if pair_in_dict:
             return
         else:
             self.pair_dict[metadata["pair"]] = self.empty_pair_dict.copy()
             return
 
     def set_initial_return_values(
-        self, pair: str,
-        pred_df: DataFrame,
-        dataframe: DataFrame
+        self, pair: str, pred_df: DataFrame, dataframe: DataFrame
     ) -> None:
         """
         Set the initial return values to the historical predictions dataframe. This avoids needing
         to repredict on historical candles, and also stores historical predictions despite
         retrainings (so stored predictions are true predictions, not just inferencing on trained
         data).
 
@@ -281,77 +289,72 @@
         new_pred = pred_df.copy()
         # set new_pred values to nans (we want to signal to user that there was nothing
         # historically made during downtime. The newest pred will get appended later in
         # append_model_predictions)
 
         new_pred["date_pred"] = dataframe["date"]
         # set everything to nan except date_pred
-        columns_to_nan = new_pred.columns.difference(['date_pred', 'date'])
-        new_pred[columns_to_nan] = new_pred[columns_to_nan].astype(
-            float).values * np.nan
+        columns_to_nan = new_pred.columns.difference(["date_pred", "date"])
+        new_pred[columns_to_nan] = None
 
         hist_preds = self.historic_predictions[pair].copy()
 
         # ensure both dataframes have the same date format so they can be merged
         new_pred["date_pred"] = pd.to_datetime(new_pred["date_pred"])
         hist_preds["date_pred"] = pd.to_datetime(hist_preds["date_pred"])
 
         # find the closest common date between new_pred and historic predictions
         # and cut off the new_pred dataframe at that date
-        common_dates = pd.merge(new_pred, hist_preds,
-                                on="date_pred", how="inner")
+        common_dates = pd.merge(new_pred, hist_preds, on="date_pred", how="inner")
         if len(common_dates.index) > 0:
-            new_pred = new_pred.iloc[len(common_dates):]
+            new_pred = new_pred.iloc[len(common_dates) :]
         else:
-            logger.warning("No common dates found between new predictions and historic "
-                           "predictions. You likely left your FreqAI instance offline "
-                           f"for more than {len(dataframe.index)} candles.")
+            logger.warning(
+                "No common dates found between new predictions and historic "
+                "predictions. You likely left your FreqAI instance offline "
+                f"for more than {len(dataframe.index)} candles."
+            )
 
         # Pandas warns that its keeping dtypes of non NaN columns...
         # yea we know and we already want that behavior. Ignoring.
         with warnings.catch_warnings():
             warnings.filterwarnings("ignore", category=FutureWarning)
             # reindex new_pred columns to match the historic predictions dataframe
             new_pred_reindexed = new_pred.reindex(columns=hist_preds.columns)
-            df_concat = pd.concat(
-                [hist_preds, new_pred_reindexed],
-                ignore_index=True
-            )
+            df_concat = pd.concat([hist_preds, new_pred_reindexed], ignore_index=True)
 
         # any missing values will get zeroed out so users can see the exact
         # downtime in FreqUI
         df_concat = df_concat.fillna(0)
         self.historic_predictions[pair] = df_concat
-        self.model_return_values[pair] = df_concat.tail(
-            len(dataframe.index)).reset_index(drop=True)
+        self.model_return_values[pair] = df_concat.tail(len(dataframe.index)).reset_index(drop=True)
 
-    def append_model_predictions(self, pair: str, predictions: DataFrame,
-                                 do_preds: NDArray[np.int_],
-                                 dk: FreqaiDataKitchen, strat_df: DataFrame) -> None:
+    def append_model_predictions(
+        self,
+        pair: str,
+        predictions: DataFrame,
+        do_preds: NDArray[np.int_],
+        dk: FreqaiDataKitchen,
+        strat_df: DataFrame,
+    ) -> None:
         """
         Append model predictions to historic predictions dataframe, then set the
         strategy return dataframe to the tail of the historic predictions. The length of
         the tail is equivalent to the length of the dataframe that entered FreqAI from
         the strategy originally. Doing this allows FreqUI to always display the correct
         historic predictions.
         """
 
         len_df = len(strat_df)
         index = self.historic_predictions[pair].index[-1:]
         columns = self.historic_predictions[pair].columns
 
-        zeros_df = pd.DataFrame(
-            np.zeros((1, len(columns))),
-            index=index,
-            columns=columns
-        )
+        zeros_df = pd.DataFrame(np.zeros((1, len(columns))), index=index, columns=columns)
         self.historic_predictions[pair] = pd.concat(
-            [self.historic_predictions[pair], zeros_df],
-            ignore_index=True,
-            axis=0
+            [self.historic_predictions[pair], zeros_df], ignore_index=True, axis=0
         )
         df = self.historic_predictions[pair]
 
         # model outputs and associated statistics
         for label in predictions.columns:
             label_loc = df.columns.get_loc(label)
             pred_label_loc = predictions.columns.get_loc(label)
@@ -367,16 +370,16 @@
         do_predict_loc = df.columns.get_loc("do_predict")
         df.iloc[-1, do_predict_loc] = do_preds[-1]
         if self.freqai_info["feature_parameters"].get("DI_threshold", 0) > 0:
             DI_values_loc = df.columns.get_loc("DI_values")
             df.iloc[-1, DI_values_loc] = dk.DI_values[-1]
 
         # extra values the user added within custom prediction model
-        if dk.data['extra_returns_per_train']:
-            rets = dk.data['extra_returns_per_train']
+        if dk.data["extra_returns_per_train"]:
+            rets = dk.data["extra_returns_per_train"]
             for return_str in rets:
                 return_loc = df.columns.get_loc(return_str)
                 df.iloc[-1, return_loc] = rets[return_str]
 
         high_price_loc = df.columns.get_loc("high_price")
         high_loc = strat_df.columns.get_loc("high")
         df.iloc[-1, high_price_loc] = strat_df.iloc[-1, high_loc]
@@ -389,15 +392,16 @@
         date_pred_loc = df.columns.get_loc("date_pred")
         date_loc = strat_df.columns.get_loc("date")
         df.iloc[-1, date_pred_loc] = strat_df.iloc[-1, date_loc]
 
         self.model_return_values[pair] = df.tail(len_df).reset_index(drop=True)
 
     def attach_return_values_to_return_dataframe(
-            self, pair: str, dataframe: DataFrame) -> DataFrame:
+        self, pair: str, dataframe: DataFrame
+    ) -> DataFrame:
         """
         Attach the return values to the strat dataframe
         :param dataframe: DataFrame = strategy dataframe
         :return: DataFrame = strat dataframe with return values attached
         """
         df = self.model_return_values[pair]
         to_keep = [col for col in dataframe.columns if not col.startswith("&")]
@@ -420,23 +424,22 @@
             dataframe[f"{label}_std"] = 0
 
         dataframe["do_predict"] = 0
 
         if self.freqai_info["feature_parameters"].get("DI_threshold", 0) > 0:
             dataframe["DI_values"] = 0
 
-        if dk.data['extra_returns_per_train']:
-            rets = dk.data['extra_returns_per_train']
+        if dk.data["extra_returns_per_train"]:
+            rets = dk.data["extra_returns_per_train"]
             for return_str in rets:
                 dataframe[return_str] = 0
 
         dk.return_dataframe = dataframe
 
     def purge_old_models(self) -> None:
-
         num_keep = self.freqai_info["purge_old_models"]
         if not num_keep:
             return
         elif isinstance(num_keep, bool):
             num_keep = 2
 
         model_folders = [x for x in self.full_path.iterdir() if x.is_dir()]
@@ -505,18 +508,18 @@
 
         if not dk.data_path.is_dir():
             dk.data_path.mkdir(parents=True, exist_ok=True)
 
         save_path = Path(dk.data_path)
 
         # Save the trained model
-        if self.model_type == 'joblib':
+        if self.model_type == "joblib":
             with (save_path / f"{dk.model_filename}_model.joblib").open("wb") as fp:
                 cloudpickle.dump(model, fp)
-        elif self.model_type == 'keras':
+        elif self.model_type == "keras":
             model.save(save_path / f"{dk.model_filename}_model.h5")
         elif self.model_type in ["stable_baselines3", "sb3_contrib", "pytorch"]:
             model.save(save_path / f"{dk.model_filename}_model.zip")
 
         dk.data["data_path"] = str(dk.data_path)
         dk.data["model_filename"] = str(dk.model_filename)
         dk.data["training_features_list"] = dk.training_features_list
@@ -593,31 +596,33 @@
 
         dk.training_features_list = dk.data["training_features_list"]
         dk.label_list = dk.data["label_list"]
 
         # try to access model in memory instead of loading object from disk to save time
         if dk.live and coin in self.model_dictionary:
             model = self.model_dictionary[coin]
-        elif self.model_type == 'joblib':
+        elif self.model_type == "joblib":
             with (dk.data_path / f"{dk.model_filename}_model.joblib").open("rb") as fp:
                 model = cloudpickle.load(fp)
-        elif 'stable_baselines' in self.model_type or 'sb3_contrib' == self.model_type:
+        elif "stable_baselines" in self.model_type or "sb3_contrib" == self.model_type:
             mod = importlib.import_module(
-                self.model_type, self.freqai_info['rl_config']['model_type'])
-            MODELCLASS = getattr(mod, self.freqai_info['rl_config']['model_type'])
+                self.model_type, self.freqai_info["rl_config"]["model_type"]
+            )
+            MODELCLASS = getattr(mod, self.freqai_info["rl_config"]["model_type"])
             model = MODELCLASS.load(dk.data_path / f"{dk.model_filename}_model")
-        elif self.model_type == 'pytorch':
+        elif self.model_type == "pytorch":
             import torch
+
             zip = torch.load(dk.data_path / f"{dk.model_filename}_model.zip")
             model = zip["pytrainer"]
             model = model.load_from_checkpoint(zip)
 
         if not model:
             raise OperationalException(
-                f"Unable to load model, ensure model exists at " f"{dk.data_path} "
+                f"Unable to load model, ensure model exists at {dk.data_path} "
             )
 
         # load it into ram if it was loaded from disk
         if coin not in self.model_dictionary:
             self.model_dictionary[coin] = model
 
         return model
@@ -636,31 +641,26 @@
             for pair in dk.all_pairs:
                 for tf in feat_params.get("include_timeframes"):
                     hist_df = history_data[pair][tf]
                     # check if newest candle is already appended
                     df_dp = strategy.dp.get_pair_dataframe(pair, tf)
                     if len(df_dp.index) == 0:
                         continue
-                    if str(hist_df.iloc[-1]["date"]) == str(
-                        df_dp.iloc[-1:]["date"].iloc[-1]
-                    ):
+                    if str(hist_df.iloc[-1]["date"]) == str(df_dp.iloc[-1:]["date"].iloc[-1]):
                         continue
 
                     try:
-                        index = (
-                            df_dp.loc[
-                                df_dp["date"] == hist_df.iloc[-1]["date"]
-                            ].index[0]
-                            + 1
-                        )
+                        index = df_dp.loc[df_dp["date"] == hist_df.iloc[-1]["date"]].index[0] + 1
                     except IndexError:
-                        if hist_df.iloc[-1]['date'] < df_dp['date'].iloc[0]:
-                            raise OperationalException("In memory historical data is older than "
-                                                       f"oldest DataProvider candle for {pair} on "
-                                                       f"timeframe {tf}")
+                        if hist_df.iloc[-1]["date"] < df_dp["date"].iloc[0]:
+                            raise OperationalException(
+                                "In memory historical data is older than "
+                                f"oldest DataProvider candle for {pair} on "
+                                f"timeframe {tf}"
+                            )
                         else:
                             index = -1
                             logger.warning(
                                 f"No common dates in historical data and dataprovider for {pair}. "
                                 f"Appending latest dataprovider candle to historical data "
                                 "but please be aware that there is likely a gap in the historical "
                                 "data. \n"
@@ -674,15 +674,15 @@
                             hist_df,
                             df_dp.iloc[index:],
                         ],
                         ignore_index=True,
                         axis=0,
                     )
 
-            self.current_candle = history_data[dk.pair][self.config['timeframe']].iloc[-1]['date']
+            self.current_candle = history_data[dk.pair][self.config["timeframe"]].iloc[-1]["date"]
 
     def load_all_pair_histories(self, timerange: TimeRange, dk: FreqaiDataKitchen) -> None:
         """
         Load pair histories for all whitelist and corr_pairlist pairs.
         Only called once upon startup of bot.
         :param timerange: TimeRange = full timerange required to populate all indicators
                           for training according to user defined train_period_days
@@ -712,21 +712,20 @@
                           for training according to user defined train_period_days
         :param metadata: dict = strategy furnished pair metadata
         """
         with self.history_lock:
             corr_dataframes: Dict[Any, Any] = {}
             base_dataframes: Dict[Any, Any] = {}
             historic_data = self.historic_data
-            pairs = self.freqai_info["feature_parameters"].get(
-                "include_corr_pairlist", []
-            )
+            pairs = self.freqai_info["feature_parameters"].get("include_corr_pairlist", [])
 
             for tf in self.freqai_info["feature_parameters"].get("include_timeframes"):
                 base_dataframes[tf] = dk.slice_dataframe(
-                    timerange, historic_data[pair][tf]).reset_index(drop=True)
+                    timerange, historic_data[pair][tf]
+                ).reset_index(drop=True)
                 if pairs:
                     for p in pairs:
                         if pair in p:
                             continue  # dont repeat anything from whitelist
                         if p not in corr_dataframes:
                             corr_dataframes[p] = {}
                         corr_dataframes[p][tf] = dk.slice_dataframe(
@@ -738,16 +737,16 @@
     def get_timerange_from_live_historic_predictions(self) -> TimeRange:
         """
         Returns timerange information based on historic predictions file
         :return: timerange calculated from saved live data
         """
         if not self.historic_predictions_path.is_file():
             raise OperationalException(
-                'Historic predictions not found. Historic predictions data is required '
-                'to run backtest with the freqai-backtest-live-models option '
+                "Historic predictions not found. Historic predictions data is required "
+                "to run backtest with the freqai-backtest-live-models option "
             )
 
         self.load_historic_predictions_from_disk()
 
         all_pairs_end_dates = []
         for pair in self.historic_predictions:
             pair_historic_data = self.historic_predictions[pair]
@@ -755,10 +754,10 @@
 
         global_metadata = self.load_global_metadata_from_disk()
         start_date = datetime.fromtimestamp(int(global_metadata["start_dry_live_date"]))
         end_date = max(all_pairs_end_dates)
         # add 1 day to string timerange to ensure BT module will load all dataframe data
         end_date = end_date + timedelta(days=1)
         backtesting_timerange = TimeRange(
-            'date', 'date', int(start_date.timestamp()), int(end_date.timestamp())
+            "date", "date", int(start_date.timestamp()), int(end_date.timestamp())
         )
         return backtesting_timerange
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/data_kitchen.py` & `freqtrade-2024.5/freqtrade/freqai/data_kitchen.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 from freqtrade.data.converter import reduce_dataframe_footprint
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange import timeframe_to_seconds
 from freqtrade.strategy import merge_informative_pair
 from freqtrade.strategy.interface import IStrategy
 
 
-pd.set_option('future.no_silent_downcasting', True)
+pd.set_option("future.no_silent_downcasting", True)
 
 SECONDS_IN_DAY = 86400
 SECONDS_IN_HOUR = 3600
 
 logger = logging.getLogger(__name__)
 
 
@@ -94,15 +94,15 @@
                 )
                 (self.training_timeranges, self.backtesting_timeranges) = self.split_timerange(
                     self.full_timerange,
                     config["freqai"]["train_period_days"],
                     config["freqai"]["backtest_period_days"],
                 )
 
-        self.data['extra_returns_per_train'] = self.freqai_config.get('extra_returns_per_train', {})
+        self.data["extra_returns_per_train"] = self.freqai_config.get("extra_returns_per_train", {})
         if not self.freqai_config.get("data_kitchen_thread_count", 0):
             self.thread_count = max(int(psutil.cpu_count() * 2 - 2), 1)
         else:
             self.thread_count = self.freqai_config["data_kitchen_thread_count"]
         self.train_dates: DataFrame = pd.DataFrame()
         self.unique_classes: Dict[str, list] = {}
         self.unique_class_list: list = []
@@ -116,16 +116,15 @@
         """
         Set the paths to the data for the present coin/botloop
         :param metadata: dict = strategy furnished pair metadata
         :param trained_timestamp: int = timestamp of most recent training
         """
         self.full_path = self.get_full_models_path(self.config)
         self.data_path = Path(
-            self.full_path
-            / f"sub-train-{pair.split('/')[0]}_{trained_timestamp}"
+            self.full_path / f"sub-train-{pair.split('/')[0]}_{trained_timestamp}"
         )
 
         return
 
     def make_train_test_datasets(
         self, filtered_dataframe: DataFrame, labels: DataFrame
     ) -> Dict[Any, Any]:
@@ -134,24 +133,24 @@
         training and test data according to user specified parameters in configuration
         file.
         :param filtered_dataframe: cleaned dataframe ready to be split.
         :param labels: cleaned labels ready to be split.
         """
         feat_dict = self.freqai_config["feature_parameters"]
 
-        if 'shuffle' not in self.freqai_config['data_split_parameters']:
-            self.freqai_config["data_split_parameters"].update({'shuffle': False})
+        if "shuffle" not in self.freqai_config["data_split_parameters"]:
+            self.freqai_config["data_split_parameters"].update({"shuffle": False})
 
         weights: npt.ArrayLike
         if feat_dict.get("weight_factor", 0) > 0:
             weights = self.set_weights_higher_recent(len(filtered_dataframe))
         else:
             weights = np.ones(len(filtered_dataframe))
 
-        if self.freqai_config.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
+        if self.freqai_config.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
             (
                 train_features,
                 test_features,
                 train_labels,
                 test_labels,
                 train_weights,
                 test_weights,
@@ -168,34 +167,51 @@
             train_features = filtered_dataframe
             train_labels = labels
             train_weights = weights
 
         if feat_dict["shuffle_after_split"]:
             rint1 = random.randint(0, 100)
             rint2 = random.randint(0, 100)
-            train_features = train_features.sample(
-                frac=1, random_state=rint1).reset_index(drop=True)
+            train_features = train_features.sample(frac=1, random_state=rint1).reset_index(
+                drop=True
+            )
             train_labels = train_labels.sample(frac=1, random_state=rint1).reset_index(drop=True)
-            train_weights = pd.DataFrame(train_weights).sample(
-                frac=1, random_state=rint1).reset_index(drop=True).to_numpy()[:, 0]
+            train_weights = (
+                pd.DataFrame(train_weights)
+                .sample(frac=1, random_state=rint1)
+                .reset_index(drop=True)
+                .to_numpy()[:, 0]
+            )
             test_features = test_features.sample(frac=1, random_state=rint2).reset_index(drop=True)
             test_labels = test_labels.sample(frac=1, random_state=rint2).reset_index(drop=True)
-            test_weights = pd.DataFrame(test_weights).sample(
-                frac=1, random_state=rint2).reset_index(drop=True).to_numpy()[:, 0]
+            test_weights = (
+                pd.DataFrame(test_weights)
+                .sample(frac=1, random_state=rint2)
+                .reset_index(drop=True)
+                .to_numpy()[:, 0]
+            )
 
         # Simplest way to reverse the order of training and test data:
-        if self.freqai_config['feature_parameters'].get('reverse_train_test_order', False):
+        if self.freqai_config["feature_parameters"].get("reverse_train_test_order", False):
             return self.build_data_dictionary(
-                test_features, train_features, test_labels,
-                train_labels, test_weights, train_weights
-                )
+                test_features,
+                train_features,
+                test_labels,
+                train_labels,
+                test_weights,
+                train_weights,
+            )
         else:
             return self.build_data_dictionary(
-                train_features, test_features, train_labels,
-                test_labels, train_weights, test_weights
+                train_features,
+                test_features,
+                train_labels,
+                test_labels,
+                train_weights,
+                test_weights,
             )
 
     def filter_features(
         self,
         unfiltered_df: DataFrame,
         training_feature_list: List,
         label_list: List = list(),
@@ -220,34 +236,31 @@
         :labels: labels cleaned of NaNs.
         """
         filtered_df = unfiltered_df.filter(training_feature_list, axis=1)
         filtered_df = filtered_df.replace([np.inf, -np.inf], np.nan)
 
         drop_index = pd.isnull(filtered_df).any(axis=1)  # get the rows that have NaNs,
         drop_index = drop_index.replace(True, 1).replace(False, 0).infer_objects(copy=False)
-        if (training_filter):
-
+        if training_filter:
             # we don't care about total row number (total no. datapoints) in training, we only care
             # about removing any row with NaNs
             # if labels has multiple columns (user wants to train multiple modelEs), we detect here
             labels = unfiltered_df.filter(label_list, axis=1)
             drop_index_labels = pd.isnull(labels).any(axis=1)
-            drop_index_labels = drop_index_labels.replace(
-                True, 1
-            ).replace(False, 0).infer_objects(copy=False)
-            dates = unfiltered_df['date']
+            drop_index_labels = (
+                drop_index_labels.replace(True, 1).replace(False, 0).infer_objects(copy=False)
+            )
+            dates = unfiltered_df["date"]
             filtered_df = filtered_df[
                 (drop_index == 0) & (drop_index_labels == 0)
             ]  # dropping values
             labels = labels[
                 (drop_index == 0) & (drop_index_labels == 0)
             ]  # assuming the labels depend entirely on the dataframe here.
-            self.train_dates = dates[
-                (drop_index == 0) & (drop_index_labels == 0)
-            ]
+            self.train_dates = dates[(drop_index == 0) & (drop_index_labels == 0)]
             logger.info(
                 f"{self.pair}: dropped {len(unfiltered_df) - len(filtered_df)} training points"
                 f" due to NaNs in populated dataset {len(unfiltered_df)}."
             )
             if len(filtered_df) == 0 and not self.live:
                 raise OperationalException(
                     f"{self.pair}: all training data dropped due to NaNs. "
@@ -262,15 +275,14 @@
                     f" {(1 - len(filtered_df) / len(unfiltered_df)) * 100:.0f} percent "
                     " of training data dropped due to NaNs, model may perform inconsistent "
                     f"with expectations. Verify {worst_indicator}"
                 )
             self.data["filter_drop_index_training"] = drop_index
 
         else:
-
             # we are backtesting so we need to preserve row number to send back to strategy,
             # so now we use do_predict to avoid any prediction based on a NaN
             drop_index = pd.isnull(filtered_df).any(axis=1)
             self.data["filter_drop_index_prediction"] = drop_index
             filtered_df.fillna(0, inplace=True)
             # replacing all NaNs with zeros to avoid issues in 'prediction', but any prediction
             # that was based on a single NaN is ultimately protected from buys with do_predict
@@ -291,23 +303,22 @@
         train_df: DataFrame,
         test_df: DataFrame,
         train_labels: DataFrame,
         test_labels: DataFrame,
         train_weights: Any,
         test_weights: Any,
     ) -> Dict:
-
         self.data_dictionary = {
             "train_features": train_df,
             "test_features": test_df,
             "train_labels": train_labels,
             "test_labels": test_labels,
             "train_weights": train_weights,
             "test_weights": test_weights,
-            "train_dates": self.train_dates
+            "train_dates": self.train_dates,
         }
 
         return self.data_dictionary
 
     def split_timerange(
         self, tr: str, train_split: int = 28, bt_split: float = 7
     ) -> Tuple[list, list]:
@@ -326,17 +337,15 @@
             )
         train_period_days = train_split * SECONDS_IN_DAY
         bt_period = bt_split * SECONDS_IN_DAY
 
         full_timerange = TimeRange.parse_timerange(tr)
         config_timerange = TimeRange.parse_timerange(self.config["timerange"])
         if config_timerange.stopts == 0:
-            config_timerange.stopts = int(
-                datetime.now(tz=timezone.utc).timestamp()
-            )
+            config_timerange.stopts = int(datetime.now(tz=timezone.utc).timestamp())
         timerange_train = copy.deepcopy(full_timerange)
         timerange_backtest = copy.deepcopy(full_timerange)
 
         tr_training_list = []
         tr_backtesting_list = []
         tr_training_list_timerange = []
         tr_backtesting_list_timerange = []
@@ -408,17 +417,17 @@
         Set weights so that recent data is more heavily weighted during
         training than older data.
         """
         wfactor = self.config["freqai"]["feature_parameters"]["weight_factor"]
         weights = np.exp(-np.arange(num_weights) / (wfactor * num_weights))[::-1]
         return weights
 
-    def get_predictions_to_append(self, predictions: DataFrame,
-                                  do_predict: npt.ArrayLike,
-                                  dataframe_backtest: DataFrame) -> DataFrame:
+    def get_predictions_to_append(
+        self, predictions: DataFrame, do_predict: npt.ArrayLike, dataframe_backtest: DataFrame
+    ) -> DataFrame:
         """
         Get backtest prediction from current backtest period
         """
 
         append_df = DataFrame()
         for label in predictions.columns:
             append_df[label] = predictions[label]
@@ -455,42 +464,44 @@
             self.full_df = pd.concat([self.full_df, append_df], axis=0, ignore_index=True)
 
     def fill_predictions(self, dataframe):
         """
         Back fill values to before the backtesting range so that the dataframe matches size
         when it goes back to the strategy. These rows are not included in the backtest.
         """
-        to_keep = [col for col in dataframe.columns if
-                   not col.startswith("&") and not col.startswith("%%")]
-        self.return_dataframe = pd.merge(dataframe[to_keep],
-                                         self.full_df, how='left', on='date')
-        self.return_dataframe[self.full_df.columns] = (
-            self.return_dataframe[self.full_df.columns].fillna(value=0))
+        to_keep = [
+            col for col in dataframe.columns if not col.startswith("&") and not col.startswith("%%")
+        ]
+        self.return_dataframe = pd.merge(dataframe[to_keep], self.full_df, how="left", on="date")
+        self.return_dataframe[self.full_df.columns] = self.return_dataframe[
+            self.full_df.columns
+        ].fillna(value=0)
         self.full_df = DataFrame()
 
         return
 
     def create_fulltimerange(self, backtest_tr: str, backtest_period_days: int) -> str:
-
         if not isinstance(backtest_period_days, int):
             raise OperationalException("backtest_period_days must be an integer")
 
         if backtest_period_days < 0:
             raise OperationalException("backtest_period_days must be positive")
 
         backtest_timerange = TimeRange.parse_timerange(backtest_tr)
 
         if backtest_timerange.stopts == 0:
             # typically open ended time ranges do work, however, there are some edge cases where
             # it does not. accommodating these kinds of edge cases just to allow open-ended
             # timerange is not high enough priority to warrant the effort. It is safer for now
             # to simply ask user to add their end date
-            raise OperationalException("FreqAI backtesting does not allow open ended timeranges. "
-                                       "Please indicate the end date of your desired backtesting. "
-                                       "timerange.")
+            raise OperationalException(
+                "FreqAI backtesting does not allow open ended timeranges. "
+                "Please indicate the end date of your desired backtesting. "
+                "timerange."
+            )
             # backtest_timerange.stopts = int(
             #     datetime.now(tz=timezone.utc).timestamp()
             # )
 
         backtest_timerange.startts = (
             backtest_timerange.startts - backtest_period_days * SECONDS_IN_DAY
         )
@@ -521,15 +532,14 @@
             return elapsed_time > max_time
         else:
             return False
 
     def check_if_new_training_required(
         self, trained_timestamp: int
     ) -> Tuple[bool, TimeRange, TimeRange]:
-
         time = datetime.now(tz=timezone.utc).timestamp()
         trained_timerange = TimeRange()
         data_load_timerange = TimeRange()
 
         timeframes = self.freqai_config["feature_parameters"].get("include_timeframes")
 
         max_tf_seconds = 0
@@ -537,15 +547,15 @@
             secs = timeframe_to_seconds(tf)
             if secs > max_tf_seconds:
                 max_tf_seconds = secs
 
         # We notice that users like to use exotic indicators where
         # they do not know the required timeperiod. Here we include a factor
         # of safety by multiplying the user considered "max" by 2.
-        max_period = self.config.get('startup_candle_count', 20) * 2
+        max_period = self.config.get("startup_candle_count", 20) * 2
         additional_seconds = max_period * max_tf_seconds
 
         if trained_timestamp != 0:
             elapsed_time = (time - trained_timestamp) / SECONDS_IN_HOUR
             retrain = elapsed_time > self.freqai_config.get("live_retrain_hours", 0)
             if retrain:
                 trained_timerange.startts = int(
@@ -574,87 +584,84 @@
             )
             data_load_timerange.stopts = int(time)
             retrain = True
 
         return retrain, trained_timerange, data_load_timerange
 
     def set_new_model_names(self, pair: str, timestamp_id: int):
-
         coin, _ = pair.split("/")
-        self.data_path = Path(
-            self.full_path
-            / f"sub-train-{pair.split('/')[0]}_{timestamp_id}"
-        )
+        self.data_path = Path(self.full_path / f"sub-train-{pair.split('/')[0]}_{timestamp_id}")
 
         self.model_filename = f"cb_{coin.lower()}_{timestamp_id}"
 
     def set_all_pairs(self) -> None:
-
         self.all_pairs = copy.deepcopy(
             self.freqai_config["feature_parameters"].get("include_corr_pairlist", [])
         )
         for pair in self.config.get("exchange", "").get("pair_whitelist"):
             if pair not in self.all_pairs:
                 self.all_pairs.append(pair)
 
     def extract_corr_pair_columns_from_populated_indicators(
-        self,
-        dataframe: DataFrame
+        self, dataframe: DataFrame
     ) -> Dict[str, DataFrame]:
         """
         Find the columns of the dataframe corresponding to the corr_pairlist, save them
         in a dictionary to be reused and attached to other pairs.
 
         :param dataframe: fully populated dataframe (current pair + corr_pairs)
         :return: corr_dataframes, dictionary of dataframes to be attached
                  to other pairs in same candle.
         """
         corr_dataframes: Dict[str, DataFrame] = {}
         pairs = self.freqai_config["feature_parameters"].get("include_corr_pairlist", [])
 
         for pair in pairs:
-            pair = pair.replace(':', '')  # lightgbm does not like colons
-            pair_cols = [col for col in dataframe.columns if col.startswith("%")
-                         and f"{pair}_" in col]
+            pair = pair.replace(":", "")  # lightgbm does not like colons
+            pair_cols = [
+                col for col in dataframe.columns if col.startswith("%") and f"{pair}_" in col
+            ]
 
             if pair_cols:
-                pair_cols.insert(0, 'date')
+                pair_cols.insert(0, "date")
                 corr_dataframes[pair] = dataframe.filter(pair_cols, axis=1)
 
         return corr_dataframes
 
-    def attach_corr_pair_columns(self, dataframe: DataFrame,
-                                 corr_dataframes: Dict[str, DataFrame],
-                                 current_pair: str) -> DataFrame:
+    def attach_corr_pair_columns(
+        self, dataframe: DataFrame, corr_dataframes: Dict[str, DataFrame], current_pair: str
+    ) -> DataFrame:
         """
         Attach the existing corr_pair dataframes to the current pair dataframe before training
 
         :param dataframe: current pair strategy dataframe, indicators populated already
         :param corr_dataframes: dictionary of saved dataframes from earlier in the same candle
         :param current_pair: current pair to which we will attach corr pair dataframe
         :return:
         :dataframe: current pair dataframe of populated indicators, concatenated with corr_pairs
                     ready for training
         """
         pairs = self.freqai_config["feature_parameters"].get("include_corr_pairlist", [])
-        current_pair = current_pair.replace(':', '')
+        current_pair = current_pair.replace(":", "")
         for pair in pairs:
-            pair = pair.replace(':', '')  # lightgbm does not work with colons
+            pair = pair.replace(":", "")  # lightgbm does not work with colons
             if current_pair != pair:
-                dataframe = dataframe.merge(corr_dataframes[pair], how='left', on='date')
+                dataframe = dataframe.merge(corr_dataframes[pair], how="left", on="date")
 
         return dataframe
 
-    def get_pair_data_for_features(self,
-                                   pair: str,
-                                   tf: str,
-                                   strategy: IStrategy,
-                                   corr_dataframes: dict = {},
-                                   base_dataframes: dict = {},
-                                   is_corr_pairs: bool = False) -> DataFrame:
+    def get_pair_data_for_features(
+        self,
+        pair: str,
+        tf: str,
+        strategy: IStrategy,
+        corr_dataframes: dict = {},
+        base_dataframes: dict = {},
+        is_corr_pairs: bool = False,
+    ) -> DataFrame:
         """
         Get the data for the pair. If it's not in the dictionary, get it from the data provider
         :param pair: str = pair to get data for
         :param tf: str = timeframe to get data for
         :param strategy: IStrategy = user defined strategy object
         :param corr_dataframes: dict = dict containing the df pair dataframes
                                 (for user defined timeframes)
@@ -674,36 +681,50 @@
             dataframe = base_dataframes[tf]
             if not dataframe.empty:
                 return dataframe
             else:
                 dataframe = strategy.dp.get_pair_dataframe(pair=pair, timeframe=tf)
                 return dataframe
 
-    def merge_features(self, df_main: DataFrame, df_to_merge: DataFrame,
-                       tf: str, timeframe_inf: str, suffix: str) -> DataFrame:
+    def merge_features(
+        self, df_main: DataFrame, df_to_merge: DataFrame, tf: str, timeframe_inf: str, suffix: str
+    ) -> DataFrame:
         """
         Merge the features of the dataframe and remove HLCV and date added columns
         :param df_main: DataFrame = main dataframe
         :param df_to_merge: DataFrame = dataframe to merge
         :param tf: str = timeframe of the main dataframe
         :param timeframe_inf: str = timeframe of the dataframe to merge
         :param suffix: str = suffix to add to the columns of the dataframe to merge
         :return: dataframe = merged dataframe
         """
-        dataframe = merge_informative_pair(df_main, df_to_merge, tf, timeframe_inf=timeframe_inf,
-                                           append_timeframe=False, suffix=suffix, ffill=True)
+        dataframe = merge_informative_pair(
+            df_main,
+            df_to_merge,
+            tf,
+            timeframe_inf=timeframe_inf,
+            append_timeframe=False,
+            suffix=suffix,
+            ffill=True,
+        )
         skip_columns = [
             (f"{s}_{suffix}") for s in ["date", "open", "high", "low", "close", "volume"]
         ]
         dataframe = dataframe.drop(columns=skip_columns)
         return dataframe
 
-    def populate_features(self, dataframe: DataFrame, pair: str, strategy: IStrategy,
-                          corr_dataframes: dict, base_dataframes: dict,
-                          is_corr_pairs: bool = False) -> DataFrame:
+    def populate_features(
+        self,
+        dataframe: DataFrame,
+        pair: str,
+        strategy: IStrategy,
+        corr_dataframes: dict,
+        base_dataframes: dict,
+        is_corr_pairs: bool = False,
+    ) -> DataFrame:
         """
         Use the user defined strategy functions for populating features
         :param dataframe: DataFrame = dataframe to populate
         :param pair: str = pair to populate
         :param strategy: IStrategy = user defined strategy object
         :param corr_dataframes: dict = dict containing the df pair dataframes
         :param base_dataframes: dict = dict containing the current pair dataframes
@@ -711,41 +732,45 @@
         :return: dataframe = populated dataframe
         """
         tfs: List[str] = self.freqai_config["feature_parameters"].get("include_timeframes")
 
         for tf in tfs:
             metadata = {"pair": pair, "tf": tf}
             informative_df = self.get_pair_data_for_features(
-                pair, tf, strategy, corr_dataframes, base_dataframes, is_corr_pairs)
+                pair, tf, strategy, corr_dataframes, base_dataframes, is_corr_pairs
+            )
             informative_copy = informative_df.copy()
 
             logger.debug(f"Populating features for {pair} {tf}")
 
             for t in self.freqai_config["feature_parameters"]["indicator_periods_candles"]:
                 df_features = strategy.feature_engineering_expand_all(
-                    informative_copy.copy(), t, metadata=metadata)
+                    informative_copy.copy(), t, metadata=metadata
+                )
                 suffix = f"{t}"
                 informative_df = self.merge_features(informative_df, df_features, tf, tf, suffix)
 
             generic_df = strategy.feature_engineering_expand_basic(
-                informative_copy.copy(), metadata=metadata)
+                informative_copy.copy(), metadata=metadata
+            )
             suffix = "gen"
 
             informative_df = self.merge_features(informative_df, generic_df, tf, tf, suffix)
 
             indicators = [col for col in informative_df if col.startswith("%")]
             for n in range(self.freqai_config["feature_parameters"]["include_shifted_candles"] + 1):
                 if n == 0:
                     continue
                 df_shift = informative_df[indicators].shift(n)
                 df_shift = df_shift.add_suffix("_shift-" + str(n))
                 informative_df = pd.concat((informative_df, df_shift), axis=1)
 
-            dataframe = self.merge_features(dataframe.copy(), informative_df,
-                                            self.config["timeframe"], tf, f'{pair}_{tf}')
+            dataframe = self.merge_features(
+                dataframe.copy(), informative_df, self.config["timeframe"], tf, f"{pair}_{tf}"
+            )
 
         return dataframe
 
     def use_strategy_to_populate_indicators(  # noqa: C901
         self,
         strategy: IStrategy,
         corr_dataframes: dict = {},
@@ -767,30 +792,30 @@
         :param do_corr_pairs: bool = whether to populate corr pairs or not
         :return:
         dataframe: DataFrame = dataframe containing populated indicators
         """
 
         # check if the user is using the deprecated populate_any_indicators function
         new_version = inspect.getsource(strategy.populate_any_indicators) == (
-            inspect.getsource(IStrategy.populate_any_indicators))
+            inspect.getsource(IStrategy.populate_any_indicators)
+        )
 
         if not new_version:
             raise OperationalException(
                 "You are using the `populate_any_indicators()` function"
                 " which was deprecated on March 1, 2023. Please refer "
                 "to the strategy migration guide to use the new "
                 "feature_engineering_* methods: \n"
                 f"{DOCS_LINK}/strategy_migration/#freqai-strategy \n"
                 "And the feature_engineering_* documentation: \n"
                 f"{DOCS_LINK}/freqai-feature-engineering/"
-                )
+            )
 
         tfs: List[str] = self.freqai_config["feature_parameters"].get("include_timeframes")
-        pairs: List[str] = self.freqai_config["feature_parameters"].get(
-            "include_corr_pairlist", [])
+        pairs: List[str] = self.freqai_config["feature_parameters"].get("include_corr_pairlist", [])
 
         for tf in tfs:
             if tf not in base_dataframes:
                 base_dataframes[tf] = pd.DataFrame()
             for p in pairs:
                 if p not in corr_dataframes:
                     corr_dataframes[p] = {}
@@ -800,34 +825,37 @@
         if not prediction_dataframe.empty:
             dataframe = prediction_dataframe.copy()
             base_dataframes[self.config["timeframe"]] = dataframe.copy()
         else:
             dataframe = base_dataframes[self.config["timeframe"]].copy()
 
         corr_pairs: List[str] = self.freqai_config["feature_parameters"].get(
-            "include_corr_pairlist", [])
-        dataframe = self.populate_features(dataframe.copy(), pair, strategy,
-                                           corr_dataframes, base_dataframes)
+            "include_corr_pairlist", []
+        )
+        dataframe = self.populate_features(
+            dataframe.copy(), pair, strategy, corr_dataframes, base_dataframes
+        )
         metadata = {"pair": pair}
         dataframe = strategy.feature_engineering_standard(dataframe.copy(), metadata=metadata)
         # ensure corr pairs are always last
         for corr_pair in corr_pairs:
             if pair == corr_pair:
                 continue  # dont repeat anything from whitelist
             if corr_pairs and do_corr_pairs:
-                dataframe = self.populate_features(dataframe.copy(), corr_pair, strategy,
-                                                   corr_dataframes, base_dataframes, True)
+                dataframe = self.populate_features(
+                    dataframe.copy(), corr_pair, strategy, corr_dataframes, base_dataframes, True
+                )
 
         if self.live:
             dataframe = strategy.set_freqai_targets(dataframe.copy(), metadata=metadata)
             dataframe = self.remove_special_chars_from_feature_names(dataframe)
 
         self.get_unique_classes_from_labels(dataframe)
 
-        if self.config.get('reduce_df_footprint', False):
+        if self.config.get("reduce_df_footprint", False):
             dataframe = reduce_dataframe_footprint(dataframe)
 
         return dataframe
 
     def fit_labels(self) -> None:
         """
         Fit the labels with a gaussian distribution
@@ -854,100 +882,92 @@
         """
         to_keep = [
             col for col in dataframe.columns if not col.startswith("%") or col.startswith("%%")
         ]
         return dataframe[to_keep]
 
     def get_unique_classes_from_labels(self, dataframe: DataFrame) -> None:
-
         # self.find_features(dataframe)
         self.find_labels(dataframe)
 
         for key in self.label_list:
             if dataframe[key].dtype == object:
                 self.unique_classes[key] = dataframe[key].dropna().unique()
 
         if self.unique_classes:
             for label in self.unique_classes:
                 self.unique_class_list += list(self.unique_classes[label])
 
-    def save_backtesting_prediction(
-        self, append_df: DataFrame
-    ) -> None:
+    def save_backtesting_prediction(self, append_df: DataFrame) -> None:
         """
         Save prediction dataframe from backtesting to feather file format
         :param append_df: dataframe for backtesting period
         """
         full_predictions_folder = Path(self.full_path / self.backtest_predictions_folder)
         if not full_predictions_folder.is_dir():
             full_predictions_folder.mkdir(parents=True, exist_ok=True)
 
         append_df.to_feather(self.backtesting_results_path)
 
-    def get_backtesting_prediction(
-        self
-    ) -> DataFrame:
+    def get_backtesting_prediction(self) -> DataFrame:
         """
         Get prediction dataframe from feather file format
         """
         append_df = pd.read_feather(self.backtesting_results_path)
         return append_df
 
-    def check_if_backtest_prediction_is_valid(
-        self,
-        len_backtest_df: int
-    ) -> bool:
+    def check_if_backtest_prediction_is_valid(self, len_backtest_df: int) -> bool:
         """
         Check if a backtesting prediction already exists and if the predictions
         to append have the same size as the backtesting dataframe slice
         :param length_backtesting_dataframe: Length of backtesting dataframe slice
         :return:
         :boolean: whether the prediction file is valid.
         """
-        path_to_predictionfile = Path(self.full_path /
-                                      self.backtest_predictions_folder /
-                                      f"{self.model_filename}_prediction.feather")
+        path_to_predictionfile = Path(
+            self.full_path
+            / self.backtest_predictions_folder
+            / f"{self.model_filename}_prediction.feather"
+        )
         self.backtesting_results_path = path_to_predictionfile
 
         file_exists = path_to_predictionfile.is_file()
 
         if file_exists:
             append_df = self.get_backtesting_prediction()
-            if len(append_df) == len_backtest_df and 'date' in append_df:
+            if len(append_df) == len_backtest_df and "date" in append_df:
                 logger.info(f"Found backtesting prediction file at {path_to_predictionfile}")
                 return True
             else:
-                logger.info("A new backtesting prediction file is required. "
-                            "(Number of predictions is different from dataframe length or "
-                            "old prediction file version).")
+                logger.info(
+                    "A new backtesting prediction file is required. "
+                    "(Number of predictions is different from dataframe length or "
+                    "old prediction file version)."
+                )
                 return False
         else:
-            logger.info(
-                f"Could not find backtesting prediction file at {path_to_predictionfile}"
-            )
+            logger.info(f"Could not find backtesting prediction file at {path_to_predictionfile}")
             return False
 
     def get_full_models_path(self, config: Config) -> Path:
         """
         Returns default FreqAI model path
         :param config: Configuration dictionary
         """
         freqai_config: Dict[str, Any] = config["freqai"]
-        return Path(
-            config["user_data_dir"] / "models" / str(freqai_config.get("identifier"))
-        )
+        return Path(config["user_data_dir"] / "models" / str(freqai_config.get("identifier")))
 
     def remove_special_chars_from_feature_names(self, dataframe: pd.DataFrame) -> pd.DataFrame:
         """
         Remove all special characters from feature strings (:)
         :param dataframe: the dataframe that just finished indicator population. (unfiltered)
-        :return: dataframe with cleaned featrue names
+        :return: dataframe with cleaned feature names
         """
 
-        spec_chars = [':']
+        spec_chars = [":"]
         for c in spec_chars:
             dataframe.columns = dataframe.columns.str.replace(c, "")
 
         return dataframe
 
     def buffer_timerange(self, timerange: TimeRange):
         """
@@ -972,30 +992,34 @@
         return timerange
 
     # deprecated functions
     def normalize_data(self, data_dictionary: Dict) -> Dict[Any, Any]:
         """
         Deprecation warning, migration assistance
         """
-        logger.warning(f"Your custom IFreqaiModel relies on the deprecated"
-                       " data pipeline. Please update your model to use the new data pipeline."
-                       " This can be achieved by following the migration guide at "
-                       f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline "
-                       "We added a basic pipeline for you, but this will be removed "
-                       "in a future version.")
+        logger.warning(
+            f"Your custom IFreqaiModel relies on the deprecated"
+            " data pipeline. Please update your model to use the new data pipeline."
+            " This can be achieved by following the migration guide at "
+            f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline "
+            "We added a basic pipeline for you, but this will be removed "
+            "in a future version."
+        )
 
         return data_dictionary
 
     def denormalize_labels_from_metadata(self, df: DataFrame) -> DataFrame:
         """
         Deprecation warning, migration assistance
         """
-        logger.warning(f"Your custom IFreqaiModel relies on the deprecated"
-                       " data pipeline. Please update your model to use the new data pipeline."
-                       " This can be achieved by following the migration guide at "
-                       f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline "
-                       "We added a basic pipeline for you, but this will be removed "
-                       "in a future version.")
+        logger.warning(
+            f"Your custom IFreqaiModel relies on the deprecated"
+            " data pipeline. Please update your model to use the new data pipeline."
+            " This can be achieved by following the migration guide at "
+            f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline "
+            "We added a basic pipeline for you, but this will be removed "
+            "in a future version."
+        )
 
         pred_df, _, _ = self.label_pipeline.inverse_transform(df)
 
         return pred_df
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/freqai_interface.py` & `freqtrade-2024.5/freqtrade/freqai/freqai_interface.py`

 * *Files 2% similar despite different names*

```diff
@@ -53,81 +53,81 @@
 
     Beta testing and bug reporting:
     @bloodhunter4rc, Salah Lamkadem @ikonx, @ken11o2, @longyu, @paranoidandy, @smidelis, @smarm
     Juha Nyknen @suikula, Wagner Costa @wagnercosta, Johan Vlugt @Jooopieeert
     """
 
     def __init__(self, config: Config) -> None:
-
         self.config = config
         self.assert_config(self.config)
         self.freqai_info: Dict[str, Any] = config["freqai"]
         self.data_split_parameters: Dict[str, Any] = config.get("freqai", {}).get(
-            "data_split_parameters", {})
+            "data_split_parameters", {}
+        )
         self.model_training_parameters: Dict[str, Any] = config.get("freqai", {}).get(
-            "model_training_parameters", {})
+            "model_training_parameters", {}
+        )
         self.identifier: str = self.freqai_info.get("identifier", "no_id_provided")
         self.retrain = False
         self.first = True
         self.set_full_path()
         self.save_backtest_models: bool = self.freqai_info.get("save_backtest_models", True)
         if self.save_backtest_models:
-            logger.info('Backtesting module configured to save all models.')
+            logger.info("Backtesting module configured to save all models.")
 
         self.dd = FreqaiDataDrawer(Path(self.full_path), self.config)
         # set current candle to arbitrary historical date
         self.current_candle: datetime = datetime.fromtimestamp(637887600, tz=timezone.utc)
         self.dd.current_candle = self.current_candle
         self.scanning = False
         self.ft_params = self.freqai_info["feature_parameters"]
         self.corr_pairlist: List[str] = self.ft_params.get("include_corr_pairlist", [])
         self.keras: bool = self.freqai_info.get("keras", False)
         if self.keras and self.ft_params.get("DI_threshold", 0):
             self.ft_params["DI_threshold"] = 0
             logger.warning("DI threshold is not configured for Keras models yet. Deactivating.")
 
-        self.CONV_WIDTH = self.freqai_info.get('conv_width', 1)
+        self.CONV_WIDTH = self.freqai_info.get("conv_width", 1)
         self.class_names: List[str] = []  # used in classification subclasses
         self.pair_it = 0
         self.pair_it_train = 0
         self.total_pairs = len(self.config.get("exchange", {}).get("pair_whitelist"))
         self.train_queue = self._set_train_queue()
         self.inference_time: float = 0
         self.train_time: float = 0
         self.begin_time: float = 0
         self.begin_time_train: float = 0
-        self.base_tf_seconds = timeframe_to_seconds(self.config['timeframe'])
-        self.continual_learning = self.freqai_info.get('continual_learning', False)
+        self.base_tf_seconds = timeframe_to_seconds(self.config["timeframe"])
+        self.continual_learning = self.freqai_info.get("continual_learning", False)
         self.plot_features = self.ft_params.get("plot_feature_importances", 0)
         self.corr_dataframes: Dict[str, DataFrame] = {}
         # get_corr_dataframes is controlling the caching of corr_dataframes
         # for improved performance. Careful with this boolean.
         self.get_corr_dataframes: bool = True
         self._threads: List[threading.Thread] = []
         self._stop_event = threading.Event()
         self.metadata: Dict[str, Any] = self.dd.load_global_metadata_from_disk()
         self.data_provider: Optional[DataProvider] = None
         self.max_system_threads = max(int(psutil.cpu_count() * 2 - 2), 1)
         self.can_short = True  # overridden in start() with strategy.can_short
         self.model: Any = None
-        if self.ft_params.get('principal_component_analysis', False) and self.continual_learning:
-            self.ft_params.update({'principal_component_analysis': False})
-            logger.warning('User tried to use PCA with continual learning. Deactivating PCA.')
-        self.activate_tensorboard: bool = self.freqai_info.get('activate_tensorboard', True)
+        if self.ft_params.get("principal_component_analysis", False) and self.continual_learning:
+            self.ft_params.update({"principal_component_analysis": False})
+            logger.warning("User tried to use PCA with continual learning. Deactivating PCA.")
+        self.activate_tensorboard: bool = self.freqai_info.get("activate_tensorboard", True)
 
         record_params(config, self.full_path)
 
     def __getstate__(self):
         """
         Return an empty state to be pickled in hyperopt
         """
-        return ({})
+        return {}
 
     def assert_config(self, config: Config) -> None:
-
         if not config.get("freqai", {}):
             raise OperationalException("No freqai parameters found in configuration file.")
 
     def start(self, dataframe: DataFrame, metadata: dict, strategy: IStrategy) -> DataFrame:
         """
         Entry point to the FreqaiModel from a specific pair, it will train a new model if
         necessary before making the prediction.
@@ -140,15 +140,15 @@
         """
         self.live = strategy.dp.runmode in (RunMode.DRY_RUN, RunMode.LIVE)
         self.dd.set_pair_dict_info(metadata)
         self.data_provider = strategy.dp
         self.can_short = strategy.can_short
 
         if self.live:
-            self.inference_timer('start')
+            self.inference_timer("start")
             self.dk = FreqaiDataKitchen(self.config, self.live, metadata["pair"])
             dk = self.start_live(dataframe, metadata, strategy, self.dk)
             dataframe = dk.remove_features_from_df(dk.return_dataframe)
 
         # For backtesting, each pair enters and then gets trained for each window along the
         # sliding window defined by "train_period_days" (training window) and "live_retrain_hours"
         # (backtest window, i.e. window immediately following the training window).
@@ -158,21 +158,20 @@
             self.dk = FreqaiDataKitchen(self.config, self.live, metadata["pair"])
             if not self.config.get("freqai_backtest_live_models", False):
                 logger.info(f"Training {len(self.dk.training_timeranges)} timeranges")
                 dk = self.start_backtesting(dataframe, metadata, self.dk, strategy)
                 dataframe = dk.remove_features_from_df(dk.return_dataframe)
             else:
                 logger.info("Backtesting using historic predictions (live models)")
-                dk = self.start_backtesting_from_historic_predictions(
-                    dataframe, metadata, self.dk)
+                dk = self.start_backtesting_from_historic_predictions(dataframe, metadata, self.dk)
                 dataframe = dk.return_dataframe
 
         self.clean_up()
         if self.live:
-            self.inference_timer('stop', metadata["pair"])
+            self.inference_timer("stop", metadata["pair"])
 
         return dataframe
 
     def clean_up(self):
         """
         Objects that should be handled by GC already between coins, but
         are explicitly shown here to help demonstrate the non-persistence of these
@@ -221,44 +220,46 @@
         while not self._stop_event.is_set():
             time.sleep(1)
             pair = self.train_queue[0]
 
             # ensure pair is available in dp
             if pair not in strategy.dp.current_whitelist():
                 self.train_queue.popleft()
-                logger.warning(f'{pair} not in current whitelist, removing from train queue.')
+                logger.warning(f"{pair} not in current whitelist, removing from train queue.")
                 continue
 
             (_, trained_timestamp) = self.dd.get_pair_dict_info(pair)
 
             dk = FreqaiDataKitchen(self.config, self.live, pair)
             (
                 retrain,
                 new_trained_timerange,
                 data_load_timerange,
             ) = dk.check_if_new_training_required(trained_timestamp)
 
             if retrain:
-                self.train_timer('start')
+                self.train_timer("start")
                 dk.set_paths(pair, new_trained_timerange.stopts)
                 try:
                     self.extract_data_and_train_model(
                         new_trained_timerange, pair, strategy, dk, data_load_timerange
                     )
                 except Exception as msg:
-                    logger.exception(f"Training {pair} raised exception {msg.__class__.__name__}. "
-                                     f"Message: {msg}, skipping.")
+                    logger.exception(
+                        f"Training {pair} raised exception {msg.__class__.__name__}. "
+                        f"Message: {msg}, skipping."
+                    )
 
-                self.train_timer('stop', pair)
+                self.train_timer("stop", pair)
 
                 # only rotate the queue after the first has been trained.
                 self.train_queue.rotate(-1)
 
                 self.dd.save_historic_predictions_to_disk()
-                if self.freqai_info.get('write_metrics_to_disk', False):
+                if self.freqai_info.get("write_metrics_to_disk", False):
                     self.dd.save_metric_tracker_to_disk()
 
     def start_backtesting(
         self, dataframe: DataFrame, metadata: dict, dk: FreqaiDataKitchen, strategy: IStrategy
     ) -> FreqaiDataKitchen:
         """
         The main broad execution for backtesting. For backtesting, each pair enters and then gets
@@ -286,16 +287,21 @@
         # following tr_train. Both of these windows slide through the
         # entire backtest
         for tr_train, tr_backtest in zip(dk.training_timeranges, dk.backtesting_timeranges):
             (_, _) = self.dd.get_pair_dict_info(pair)
             train_it += 1
             total_trains = len(dk.backtesting_timeranges)
             self.training_timerange = tr_train
-            len_backtest_df = len(dataframe.loc[(dataframe["date"] >= tr_backtest.startdt) & (
-                                  dataframe["date"] < tr_backtest.stopdt), :])
+            len_backtest_df = len(
+                dataframe.loc[
+                    (dataframe["date"] >= tr_backtest.startdt)
+                    & (dataframe["date"] < tr_backtest.stopdt),
+                    :,
+                ]
+            )
 
             if not self.ensure_data_exists(len_backtest_df, tr_backtest, pair):
                 continue
 
             self.log_backtesting_progress(tr_train, pair, train_it, total_trains)
 
             timestamp_model_id = int(tr_train.stopts)
@@ -323,18 +329,20 @@
                     dataframe = self.dk.use_strategy_to_populate_indicators(
                         strategy, prediction_dataframe=dataframe, pair=pair
                     )
                     populate_indicators = False
 
                 dataframe_base_train = dataframe.loc[dataframe["date"] < tr_train.stopdt, :]
                 dataframe_base_train = strategy.set_freqai_targets(
-                    dataframe_base_train, metadata=metadata)
+                    dataframe_base_train, metadata=metadata
+                )
                 dataframe_base_backtest = dataframe.loc[dataframe["date"] < tr_backtest.stopdt, :]
                 dataframe_base_backtest = strategy.set_freqai_targets(
-                    dataframe_base_backtest, metadata=metadata)
+                    dataframe_base_backtest, metadata=metadata
+                )
 
                 tr_train = dk.buffer_timerange(tr_train)
 
                 dataframe_train = dk.slice_dataframe(tr_train, dataframe_base_train)
                 dataframe_backtest = dk.slice_dataframe(tr_backtest, dataframe_base_backtest)
 
                 dataframe_train = dk.remove_special_chars_from_feature_names(dataframe_train)
@@ -342,33 +350,35 @@
                 dk.get_unique_classes_from_labels(dataframe_train)
 
                 if not self.model_exists(dk):
                     dk.find_features(dataframe_train)
                     dk.find_labels(dataframe_train)
 
                     try:
-                        self.tb_logger = get_tb_logger(self.dd.model_type, dk.data_path,
-                                                       self.activate_tensorboard)
+                        self.tb_logger = get_tb_logger(
+                            self.dd.model_type, dk.data_path, self.activate_tensorboard
+                        )
                         self.model = self.train(dataframe_train, pair, dk)
                         self.tb_logger.close()
                     except Exception as msg:
                         logger.warning(
                             f"Training {pair} raised exception {msg.__class__.__name__}. "
-                            f"Message: {msg}, skipping.", exc_info=True)
+                            f"Message: {msg}, skipping.",
+                            exc_info=True,
+                        )
                         self.model = None
 
-                    self.dd.pair_dict[pair]["trained_timestamp"] = int(
-                        tr_train.stopts)
+                    self.dd.pair_dict[pair]["trained_timestamp"] = int(tr_train.stopts)
                     if self.plot_features and self.model is not None:
                         plot_feature_importance(self.model, pair, dk, self.plot_features)
                     if self.save_backtest_models and self.model is not None:
-                        logger.info('Saving backtest model to disk.')
+                        logger.info("Saving backtest model to disk.")
                         self.dd.save_data(self.model, pair, dk)
                     else:
-                        logger.info('Saving metadata to disk.')
+                        logger.info("Saving metadata to disk.")
                         self.dd.save_metadata(dk)
                 else:
                     self.model = self.dd.load_data(pair, dk)
 
                 pred_df, do_preds = self.predict(dataframe_backtest, dk)
                 append_df = dk.get_predictions_to_append(pred_df, do_preds, dataframe_backtest)
                 dk.append_predictions(append_df)
@@ -390,17 +400,19 @@
         :param strategy: IStrategy = currently employed strategy
         dk: FreqaiDataKitchen = Data management/analysis tool associated to present pair only
         :returns:
         dk: FreqaiDataKitchen = Data management/analysis tool associated to present pair only
         """
 
         if not strategy.process_only_new_candles:
-            raise OperationalException("You are trying to use a FreqAI strategy with "
-                                       "process_only_new_candles = False. This is not supported "
-                                       "by FreqAI, and it is therefore aborting.")
+            raise OperationalException(
+                "You are trying to use a FreqAI strategy with "
+                "process_only_new_candles = False. This is not supported "
+                "by FreqAI, and it is therefore aborting."
+            )
 
         # get the model metadata associated with the current pair
         (_, trained_timestamp) = self.dd.get_pair_dict_info(metadata["pair"])
 
         # append the historic data once per round
         if self.dd.historic_data:
             self.dd.update_historic_data(strategy, dk)
@@ -420,16 +432,18 @@
             self.scanning = True
             self.start_scanning(strategy)
 
         # load the model and associated data into the data kitchen
         self.model = self.dd.load_data(metadata["pair"], dk)
 
         dataframe = dk.use_strategy_to_populate_indicators(
-            strategy, prediction_dataframe=dataframe, pair=metadata["pair"],
-            do_corr_pairs=self.get_corr_dataframes
+            strategy,
+            prediction_dataframe=dataframe,
+            pair=metadata["pair"],
+            do_corr_pairs=self.get_corr_dataframes,
         )
 
         if not self.model:
             logger.warning(
                 f"No model ready for {metadata['pair']}, returning null values to strategy."
             )
             self.dd.return_null_values_to_strategy(dataframe, dk)
@@ -443,15 +457,14 @@
         self.build_strategy_return_arrays(dataframe, dk, metadata["pair"], trained_timestamp)
 
         return dk
 
     def build_strategy_return_arrays(
         self, dataframe: DataFrame, dk: FreqaiDataKitchen, pair: str, trained_timestamp: int
     ) -> None:
-
         # hold the historical predictions in memory so we are sending back
         # correct array to strategy
 
         if pair not in self.dd.model_return_values:
             # first predictions are made on entire historical candle set coming from strategy. This
             # allows FreqUI to show full return values.
             pred_df, do_preds = self.predict(dataframe, dk)
@@ -469,38 +482,36 @@
                 f"Model expired for {pair}, returning null values to strategy. Strategy "
                 "construction should take care to consider this event with "
                 "prediction == 0 and do_predict == 2"
             )
         else:
             # remaining predictions are made only on the most recent candles for performance and
             # historical accuracy reasons.
-            pred_df, do_preds = self.predict(dataframe.iloc[-self.CONV_WIDTH:], dk, first=False)
+            pred_df, do_preds = self.predict(dataframe.iloc[-self.CONV_WIDTH :], dk, first=False)
 
-        if self.freqai_info.get('fit_live_predictions_candles', 0) and self.live:
+        if self.freqai_info.get("fit_live_predictions_candles", 0) and self.live:
             self.fit_live_predictions(dk, pair)
         self.dd.append_model_predictions(pair, pred_df, do_preds, dk, dataframe)
         dk.return_dataframe = self.dd.attach_return_values_to_return_dataframe(pair, dataframe)
 
         return
 
-    def check_if_feature_list_matches_strategy(
-        self, dk: FreqaiDataKitchen
-    ) -> None:
+    def check_if_feature_list_matches_strategy(self, dk: FreqaiDataKitchen) -> None:
         """
         Ensure user is passing the proper feature set if they are reusing an `identifier` pointing
         to a folder holding existing models.
         :param dataframe: DataFrame = strategy provided dataframe
         :param dk: FreqaiDataKitchen = non-persistent data container/analyzer for
                    current coin/bot loop
         """
 
         if "training_features_list_raw" in dk.data:
             feature_list = dk.data["training_features_list_raw"]
         else:
-            feature_list = dk.data['training_features_list']
+            feature_list = dk.data["training_features_list"]
 
         if dk.training_features_list != feature_list:
             raise OperationalException(
                 "Trying to access pretrained model with `identifier` "
                 "but found different features furnished by current strategy. "
                 "Change `identifier` to train from scratch, or ensure the "
                 "strategy is furnishing the same features as the pretrained "
@@ -508,58 +519,55 @@
                 "requires all strategies to maintain identical "
                 "feature_engineering_* functions"
             )
 
     def define_data_pipeline(self, threads=-1) -> Pipeline:
         ft_params = self.freqai_info["feature_parameters"]
         pipe_steps = [
-            ('const', ds.VarianceThreshold(threshold=0)),
-            ('scaler', SKLearnWrapper(MinMaxScaler(feature_range=(-1, 1))))
-            ]
+            ("const", ds.VarianceThreshold(threshold=0)),
+            ("scaler", SKLearnWrapper(MinMaxScaler(feature_range=(-1, 1)))),
+        ]
 
         if ft_params.get("principal_component_analysis", False):
-            pipe_steps.append(('pca', ds.PCA(n_components=0.999)))
-            pipe_steps.append(('post-pca-scaler',
-                               SKLearnWrapper(MinMaxScaler(feature_range=(-1, 1)))))
+            pipe_steps.append(("pca", ds.PCA(n_components=0.999)))
+            pipe_steps.append(
+                ("post-pca-scaler", SKLearnWrapper(MinMaxScaler(feature_range=(-1, 1))))
+            )
 
         if ft_params.get("use_SVM_to_remove_outliers", False):
-            svm_params = ft_params.get(
-                "svm_params", {"shuffle": False, "nu": 0.01})
-            pipe_steps.append(('svm', ds.SVMOutlierExtractor(**svm_params)))
+            svm_params = ft_params.get("svm_params", {"shuffle": False, "nu": 0.01})
+            pipe_steps.append(("svm", ds.SVMOutlierExtractor(**svm_params)))
 
         di = ft_params.get("DI_threshold", 0)
         if di:
-            pipe_steps.append(('di', ds.DissimilarityIndex(di_threshold=di, n_jobs=threads)))
+            pipe_steps.append(("di", ds.DissimilarityIndex(di_threshold=di, n_jobs=threads)))
 
         if ft_params.get("use_DBSCAN_to_remove_outliers", False):
-            pipe_steps.append(('dbscan', ds.DBSCAN(n_jobs=threads)))
+            pipe_steps.append(("dbscan", ds.DBSCAN(n_jobs=threads)))
 
-        sigma = self.freqai_info["feature_parameters"].get('noise_standard_deviation', 0)
+        sigma = self.freqai_info["feature_parameters"].get("noise_standard_deviation", 0)
         if sigma:
-            pipe_steps.append(('noise', ds.Noise(sigma=sigma)))
+            pipe_steps.append(("noise", ds.Noise(sigma=sigma)))
 
         return Pipeline(pipe_steps)
 
     def define_label_pipeline(self, threads=-1) -> Pipeline:
-
-        label_pipeline = Pipeline([
-            ('scaler', SKLearnWrapper(MinMaxScaler(feature_range=(-1, 1))))
-            ])
+        label_pipeline = Pipeline([("scaler", SKLearnWrapper(MinMaxScaler(feature_range=(-1, 1))))])
 
         return label_pipeline
 
     def model_exists(self, dk: FreqaiDataKitchen) -> bool:
         """
         Given a pair and path, check if a model already exists
         :param pair: pair e.g. BTC/USD
         :param path: path to model
         :return:
         :boolean: whether the model file exists or not.
         """
-        if self.dd.model_type == 'joblib':
+        if self.dd.model_type == "joblib":
             file_type = ".joblib"
         elif self.dd.model_type in ["stable_baselines3", "sb3_contrib", "pytorch"]:
             file_type = ".zip"
 
         path_to_modelfile = Path(dk.data_path / f"{dk.model_filename}_model{file_type}")
         file_exists = path_to_modelfile.is_file()
         if file_exists:
@@ -568,17 +576,15 @@
             logger.info("Could not find model at %s", dk.data_path / dk.model_filename)
         return file_exists
 
     def set_full_path(self) -> None:
         """
         Creates and sets the full path for the identifier
         """
-        self.full_path = Path(
-            self.config["user_data_dir"] / "models" / f"{self.identifier}"
-        )
+        self.full_path = Path(self.config["user_data_dir"] / "models" / f"{self.identifier}")
         self.full_path.mkdir(parents=True, exist_ok=True)
 
     def extract_data_and_train_model(
         self,
         new_trained_timerange: TimeRange,
         pair: str,
         strategy: IStrategy,
@@ -611,16 +617,15 @@
 
         unfiltered_dataframe = dk.slice_dataframe(buffered_timerange, unfiltered_dataframe)
 
         # find the features indicated by strategy and store in datakitchen
         dk.find_features(unfiltered_dataframe)
         dk.find_labels(unfiltered_dataframe)
 
-        self.tb_logger = get_tb_logger(self.dd.model_type, dk.data_path,
-                                       self.activate_tensorboard)
+        self.tb_logger = get_tb_logger(self.dd.model_type, dk.data_path, self.activate_tensorboard)
         model = self.train(unfiltered_dataframe, pair, dk)
         self.tb_logger.close()
 
         self.dd.pair_dict[pair]["trained_timestamp"] = trained_timestamp
         dk.set_new_model_names(pair, trained_timestamp)
         self.dd.save_data(model, pair, dk)
 
@@ -660,29 +665,29 @@
         hist_preds_df = self.dd.historic_predictions[pair]
 
         self.set_start_dry_live_date(strat_df)
 
         for label in hist_preds_df.columns:
             if hist_preds_df[label].dtype == object:
                 continue
-            hist_preds_df[f'{label}_mean'] = 0
-            hist_preds_df[f'{label}_std'] = 0
+            hist_preds_df[f"{label}_mean"] = 0
+            hist_preds_df[f"{label}_std"] = 0
 
-        hist_preds_df['do_predict'] = 0
+        hist_preds_df["do_predict"] = 0
 
-        if self.freqai_info['feature_parameters'].get('DI_threshold', 0) > 0:
-            hist_preds_df['DI_values'] = 0
+        if self.freqai_info["feature_parameters"].get("DI_threshold", 0) > 0:
+            hist_preds_df["DI_values"] = 0
 
-        for return_str in dk.data['extra_returns_per_train']:
-            hist_preds_df[return_str] = dk.data['extra_returns_per_train'][return_str]
+        for return_str in dk.data["extra_returns_per_train"]:
+            hist_preds_df[return_str] = dk.data["extra_returns_per_train"][return_str]
 
-        hist_preds_df['high_price'] = strat_df['high']
-        hist_preds_df['low_price'] = strat_df['low']
-        hist_preds_df['close_price'] = strat_df['close']
-        hist_preds_df['date_pred'] = strat_df['date']
+        hist_preds_df["high_price"] = strat_df["high"]
+        hist_preds_df["low_price"] = strat_df["low"]
+        hist_preds_df["close_price"] = strat_df["close"]
+        hist_preds_df["date_pred"] = strat_df["date"]
 
     def fit_live_predictions(self, dk: FreqaiDataKitchen, pair: str) -> None:
         """
         Fit the labels with a gaussian distribution
         """
         import scipy as spy
 
@@ -690,60 +695,59 @@
         full_labels = dk.label_list + dk.unique_class_list
 
         num_candles = self.freqai_info.get("fit_live_predictions_candles", 100)
         dk.data["labels_mean"], dk.data["labels_std"] = {}, {}
         for label in full_labels:
             if self.dd.historic_predictions[dk.pair][label].dtype == object:
                 continue
-            f = spy.stats.norm.fit(
-                self.dd.historic_predictions[dk.pair][label].tail(num_candles))
+            f = spy.stats.norm.fit(self.dd.historic_predictions[dk.pair][label].tail(num_candles))
             dk.data["labels_mean"][label], dk.data["labels_std"][label] = f[0], f[1]
 
         return
 
-    def inference_timer(self, do: Literal['start', 'stop'] = 'start', pair: str = ''):
+    def inference_timer(self, do: Literal["start", "stop"] = "start", pair: str = ""):
         """
         Timer designed to track the cumulative time spent in FreqAI for one pass through
         the whitelist. This will check if the time spent is more than 1/4 the time
         of a single candle, and if so, it will warn the user of degraded performance
         """
-        if do == 'start':
+        if do == "start":
             self.pair_it += 1
             self.begin_time = time.time()
-        elif do == 'stop':
+        elif do == "stop":
             end = time.time()
-            time_spent = (end - self.begin_time)
-            if self.freqai_info.get('write_metrics_to_disk', False):
-                self.dd.update_metric_tracker('inference_time', time_spent, pair)
+            time_spent = end - self.begin_time
+            if self.freqai_info.get("write_metrics_to_disk", False):
+                self.dd.update_metric_tracker("inference_time", time_spent, pair)
             self.inference_time += time_spent
             if self.pair_it == self.total_pairs:
                 logger.info(
-                    f'Total time spent inferencing pairlist {self.inference_time:.2f} seconds')
+                    f"Total time spent inferencing pairlist {self.inference_time:.2f} seconds"
+                )
                 self.pair_it = 0
                 self.inference_time = 0
         return
 
-    def train_timer(self, do: Literal['start', 'stop'] = 'start', pair: str = ''):
+    def train_timer(self, do: Literal["start", "stop"] = "start", pair: str = ""):
         """
         Timer designed to track the cumulative time spent training the full pairlist in
         FreqAI.
         """
-        if do == 'start':
+        if do == "start":
             self.pair_it_train += 1
             self.begin_time_train = time.time()
-        elif do == 'stop':
+        elif do == "stop":
             end = time.time()
-            time_spent = (end - self.begin_time_train)
-            if self.freqai_info.get('write_metrics_to_disk', False):
+            time_spent = end - self.begin_time_train
+            if self.freqai_info.get("write_metrics_to_disk", False):
                 self.dd.collect_metrics(time_spent, pair)
 
             self.train_time += time_spent
             if self.pair_it_train == self.total_pairs:
-                logger.info(
-                    f'Total time spent training pairlist {self.train_time:.2f} seconds')
+                logger.info(f"Total time spent training pairlist {self.train_time:.2f} seconds")
                 self.pair_it_train = 0
                 self.train_time = 0
         return
 
     def get_init_model(self, pair: str) -> Any:
         if pair not in self.dd.model_dictionary or not self.continual_learning:
             init_model = None
@@ -755,53 +759,55 @@
     def _set_train_queue(self):
         """
         Sets train queue from existing train timestamps if they exist
         otherwise it sets the train queue based on the provided whitelist.
         """
         current_pairlist = self.config.get("exchange", {}).get("pair_whitelist")
         if not self.dd.pair_dict:
-            logger.info('Set fresh train queue from whitelist. '
-                        f'Queue: {current_pairlist}')
+            logger.info("Set fresh train queue from whitelist. Queue: {current_pairlist}")
             return deque(current_pairlist)
 
         best_queue = deque()
 
-        pair_dict_sorted = sorted(self.dd.pair_dict.items(),
-                                  key=lambda k: k[1]['trained_timestamp'])
+        pair_dict_sorted = sorted(
+            self.dd.pair_dict.items(), key=lambda k: k[1]["trained_timestamp"]
+        )
         for pair in pair_dict_sorted:
             if pair[0] in current_pairlist:
                 best_queue.append(pair[0])
         for pair in current_pairlist:
             if pair not in best_queue:
                 best_queue.appendleft(pair)
 
-        logger.info('Set existing queue from trained timestamps. '
-                    f'Best approximation queue: {best_queue}')
+        logger.info(
+            "Set existing queue from trained timestamps. Best approximation queue: {best_queue}"
+        )
         return best_queue
 
     def cache_corr_pairlist_dfs(self, dataframe: DataFrame, dk: FreqaiDataKitchen) -> DataFrame:
         """
         Cache the corr_pairlist dfs to speed up performance for subsequent pairs during the
         current candle.
         :param dataframe: strategy fed dataframe
         :param dk: datakitchen object for current asset
         :return: dataframe to attach/extract cached corr_pair dfs to/from.
         """
 
         if self.get_corr_dataframes:
             self.corr_dataframes = dk.extract_corr_pair_columns_from_populated_indicators(dataframe)
             if not self.corr_dataframes:
-                logger.warning("Couldn't cache corr_pair dataframes for improved performance. "
-                               "Consider ensuring that the full coin/stake, e.g. XYZ/USD, "
-                               "is included in the column names when you are creating features "
-                               "in `feature_engineering_*` functions.")
+                logger.warning(
+                    "Couldn't cache corr_pair dataframes for improved performance. "
+                    "Consider ensuring that the full coin/stake, e.g. XYZ/USD, "
+                    "is included in the column names when you are creating features "
+                    "in `feature_engineering_*` functions."
+                )
             self.get_corr_dataframes = not bool(self.corr_dataframes)
         elif self.corr_dataframes:
-            dataframe = dk.attach_corr_pair_columns(
-                dataframe, self.corr_dataframes, dk.pair)
+            dataframe = dk.attach_corr_pair_columns(dataframe, self.corr_dataframes, dk.pair)
 
         return dataframe
 
     def track_current_candle(self):
         """
         Checks if the latest candle appended by the datadrawer is
         equivalent to the latest candle seen by FreqAI. If not, it
@@ -809,32 +815,36 @@
         counter.
         """
         if self.dd.current_candle > self.current_candle:
             self.get_corr_dataframes = True
             self.pair_it = 1
             self.current_candle = self.dd.current_candle
 
-    def ensure_data_exists(self, len_dataframe_backtest: int,
-                           tr_backtest: TimeRange, pair: str) -> bool:
+    def ensure_data_exists(
+        self, len_dataframe_backtest: int, tr_backtest: TimeRange, pair: str
+    ) -> bool:
         """
         Check if the dataframe is empty, if not, report useful information to user.
         :param len_dataframe_backtest: the len of backtesting dataframe
         :param tr_backtest: current backtesting timerange.
         :param pair: current pair
         :return: if the data exists or not
         """
         if self.config.get("freqai_backtest_live_models", False) and len_dataframe_backtest == 0:
-            logger.info(f"No data found for pair {pair} from "
-                        f"from {tr_backtest.start_fmt} to {tr_backtest.stop_fmt}. "
-                        "Probably more than one training within the same candle period.")
+            logger.info(
+                f"No data found for pair {pair} from "
+                f"from {tr_backtest.start_fmt} to {tr_backtest.stop_fmt}. "
+                "Probably more than one training within the same candle period."
+            )
             return False
         return True
 
-    def log_backtesting_progress(self, tr_train: TimeRange, pair: str,
-                                 train_it: int, total_trains: int):
+    def log_backtesting_progress(
+        self, tr_train: TimeRange, pair: str, train_it: int, total_trains: int
+    ):
         """
         Log the backtesting progress so user knows how many pairs have been trained and
         how many more pairs/trains remain.
         :param tr_train: the training timerange
         :param train_it: the train iteration for the current pair (the sliding window progress)
         :param pair: the current pair
         :param total_trains: total trains (total number of slides for the sliding window)
@@ -853,38 +863,45 @@
         The loop is required to simulate dry/live operation, as it is not possible to predict
         the type of logic implemented by the user.
         :param dk: datakitchen object
         """
         fit_live_predictions_candles = self.freqai_info.get("fit_live_predictions_candles", 0)
         if fit_live_predictions_candles:
             logger.info("Applying fit_live_predictions in backtesting")
-            label_columns = [col for col in dk.full_df.columns if (
-                col.startswith("&") and
-                not (col.startswith("&") and col.endswith("_mean")) and
-                not (col.startswith("&") and col.endswith("_std")) and
-                col not in self.dk.data["extra_returns_per_train"])
+            label_columns = [
+                col
+                for col in dk.full_df.columns
+                if (
+                    col.startswith("&")
+                    and not (col.startswith("&") and col.endswith("_mean"))
+                    and not (col.startswith("&") and col.endswith("_std"))
+                    and col not in self.dk.data["extra_returns_per_train"]
+                )
             ]
 
             for index in range(len(dk.full_df)):
                 if index >= fit_live_predictions_candles:
-                    self.dd.historic_predictions[self.dk.pair] = (
-                        dk.full_df.iloc[index - fit_live_predictions_candles:index])
+                    self.dd.historic_predictions[self.dk.pair] = dk.full_df.iloc[
+                        index - fit_live_predictions_candles : index
+                    ]
                     self.fit_live_predictions(self.dk, self.dk.pair)
                     for label in label_columns:
                         if dk.full_df[label].dtype == object:
                             continue
                         if "labels_mean" in self.dk.data:
-                            dk.full_df.at[index, f"{label}_mean"] = (
-                                self.dk.data["labels_mean"][label])
+                            dk.full_df.at[index, f"{label}_mean"] = self.dk.data["labels_mean"][
+                                label
+                            ]
                         if "labels_std" in self.dk.data:
                             dk.full_df.at[index, f"{label}_std"] = self.dk.data["labels_std"][label]
 
                     for extra_col in self.dk.data["extra_returns_per_train"]:
-                        dk.full_df.at[index, f"{extra_col}"] = (
-                            self.dk.data["extra_returns_per_train"][extra_col])
+                        dk.full_df.at[index, f"{extra_col}"] = self.dk.data[
+                            "extra_returns_per_train"
+                        ][extra_col]
 
         return
 
     def update_metadata(self, metadata: Dict[str, Any]):
         """
         Update global metadata and save the updated json file
         :param metadata: new global metadata dict
@@ -893,15 +910,16 @@
         self.metadata = metadata
 
     def set_start_dry_live_date(self, live_dataframe: DataFrame):
         key_name = "start_dry_live_date"
         if key_name not in self.metadata:
             metadata = self.metadata
             metadata[key_name] = int(
-                pd.to_datetime(live_dataframe.tail(1)["date"].values[0]).timestamp())
+                pd.to_datetime(live_dataframe.tail(1)["date"].values[0]).timestamp()
+            )
             self.update_metadata(metadata)
 
     def start_backtesting_from_historic_predictions(
         self, dataframe: DataFrame, metadata: dict, dk: FreqaiDataKitchen
     ) -> FreqaiDataKitchen:
         """
         :param dataframe: DataFrame = strategy passed dataframe
@@ -909,27 +927,28 @@
         :param dk: FreqaiDataKitchen = Data management/analysis tool associated to present pair only
         :return:
             FreqaiDataKitchen = Data management/analysis tool associated to present pair only
         """
         pair = metadata["pair"]
         dk.return_dataframe = dataframe
         saved_dataframe = self.dd.historic_predictions[pair]
-        columns_to_drop = list(set(saved_dataframe.columns).intersection(
-            dk.return_dataframe.columns))
+        columns_to_drop = list(
+            set(saved_dataframe.columns).intersection(dk.return_dataframe.columns)
+        )
         dk.return_dataframe = dk.return_dataframe.drop(columns=list(columns_to_drop))
         dk.return_dataframe = pd.merge(
-            dk.return_dataframe, saved_dataframe, how='left', left_on='date', right_on="date_pred")
+            dk.return_dataframe, saved_dataframe, how="left", left_on="date", right_on="date_pred"
+        )
         return dk
 
     # Following methods which are overridden by user made prediction models.
     # See freqai/prediction_models/CatboostPredictionModel.py for an example.
 
     @abstractmethod
-    def train(self, unfiltered_df: DataFrame, pair: str,
-              dk: FreqaiDataKitchen, **kwargs) -> Any:
+    def train(self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         Filter the training data and train a model to it. Train makes heavy use of the datahandler
         for storing, saving, loading, and analyzing the data.
         :param unfiltered_df: Full dataframe for the current training period
         :param metadata: pair metadata from strategy.
         :return: Trained model which can be used to inference (self.predict)
         """
@@ -962,48 +981,53 @@
         """
 
     # deprecated functions
     def data_cleaning_train(self, dk: FreqaiDataKitchen, pair: str):
         """
         throw deprecation warning if this function is called
         """
-        logger.warning(f"Your model {self.__class__.__name__} relies on the deprecated"
-                       " data pipeline. Please update your model to use the new data pipeline."
-                       " This can be achieved by following the migration guide at "
-                       f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline")
+        logger.warning(
+            f"Your model {self.__class__.__name__} relies on the deprecated"
+            " data pipeline. Please update your model to use the new data pipeline."
+            " This can be achieved by following the migration guide at "
+            f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline"
+        )
         dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)
         dd = dk.data_dictionary
-        (dd["train_features"],
-         dd["train_labels"],
-         dd["train_weights"]) = dk.feature_pipeline.fit_transform(dd["train_features"],
-                                                                  dd["train_labels"],
-                                                                  dd["train_weights"])
-
-        (dd["test_features"],
-         dd["test_labels"],
-         dd["test_weights"]) = dk.feature_pipeline.transform(dd["test_features"],
-                                                             dd["test_labels"],
-                                                             dd["test_weights"])
+        (dd["train_features"], dd["train_labels"], dd["train_weights"]) = (
+            dk.feature_pipeline.fit_transform(
+                dd["train_features"], dd["train_labels"], dd["train_weights"]
+            )
+        )
+
+        (dd["test_features"], dd["test_labels"], dd["test_weights"]) = (
+            dk.feature_pipeline.transform(
+                dd["test_features"], dd["test_labels"], dd["test_weights"]
+            )
+        )
 
         dk.label_pipeline = self.define_label_pipeline(threads=dk.thread_count)
 
         dd["train_labels"], _, _ = dk.label_pipeline.fit_transform(dd["train_labels"])
         dd["test_labels"], _, _ = dk.label_pipeline.transform(dd["test_labels"])
         return
 
     def data_cleaning_predict(self, dk: FreqaiDataKitchen, pair: str):
         """
         throw deprecation warning if this function is called
         """
-        logger.warning(f"Your model {self.__class__.__name__} relies on the deprecated"
-                       " data pipeline. Please update your model to use the new data pipeline."
-                       " This can be achieved by following the migration guide at "
-                       f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline")
+        logger.warning(
+            f"Your model {self.__class__.__name__} relies on the deprecated"
+            " data pipeline. Please update your model to use the new data pipeline."
+            " This can be achieved by following the migration guide at "
+            f"{DOCS_LINK}/strategy_migration/#freqai-new-data-pipeline"
+        )
         dd = dk.data_dictionary
         dd["predict_features"], outliers, _ = dk.feature_pipeline.transform(
-            dd["predict_features"], outlier_check=True)
+            dd["predict_features"], outlier_check=True
+        )
         if self.freqai_info.get("DI_threshold", 0) > 0:
             dk.DI_values = dk.feature_pipeline["di"].di_values
         else:
             dk.DI_values = np.zeros(outliers.shape[0])
         dk.do_predict = outliers
         return
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostRegressor.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,22 +1,21 @@
 import logging
-import sys
 from pathlib import Path
 from typing import Any, Dict
 
-from catboost import CatBoostClassifier, Pool
+from catboost import CatBoostRegressor, Pool
 
-from freqtrade.freqai.base_models.BaseClassifierModel import BaseClassifierModel
+from freqtrade.freqai.base_models.BaseRegressionModel import BaseRegressionModel
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
 
 
 logger = logging.getLogger(__name__)
 
 
-class CatboostClassifier(BaseClassifierModel):
+class CatboostRegressor(BaseRegressionModel):
     """
     User created prediction model. The class inherits IFreqaiModel, which
     means it has full access to all Frequency AI functionality. Typically,
     users would use this to override the common `fit()`, `train()`, or
     `predict()` methods to add their custom data handling tools or change
     various aspects of the training that cannot be configured via the
     top level config.json file.
@@ -40,20 +39,22 @@
         else:
             test_data = Pool(
                 data=data_dictionary["test_features"],
                 label=data_dictionary["test_labels"],
                 weight=data_dictionary["test_weights"],
             )
 
-        cbr = CatBoostClassifier(
+        init_model = self.get_init_model(dk.pair)
+
+        model = CatBoostRegressor(
             allow_writing_files=True,
-            loss_function='MultiClass',
             train_dir=Path(dk.data_path),
             **self.model_training_parameters,
         )
 
-        init_model = self.get_init_model(dk.pair)
-
-        cbr.fit(X=train_data, eval_set=test_data, init_model=init_model,
-                log_cout=sys.stdout, log_cerr=sys.stderr)
+        model.fit(
+            X=train_data,
+            eval_set=test_data,
+            init_model=init_model,
+        )
 
-        return cbr
+        return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostClassifierMultiTarget.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostClassifierMultiTarget.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 import logging
-import sys
 from pathlib import Path
 from typing import Any, Dict
 
 from catboost import CatBoostClassifier, Pool
 
 from freqtrade.freqai.base_models.BaseClassifierModel import BaseClassifierModel
 from freqtrade.freqai.base_models.FreqaiMultiOutputClassifier import FreqaiMultiOutputClassifier
@@ -29,30 +28,30 @@
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         """
 
         cbc = CatBoostClassifier(
             allow_writing_files=True,
-            loss_function='MultiClass',
+            loss_function="MultiClass",
             train_dir=Path(dk.data_path),
             **self.model_training_parameters,
         )
 
         X = data_dictionary["train_features"]
         y = data_dictionary["train_labels"]
 
         sample_weight = data_dictionary["train_weights"]
 
         eval_sets = [None] * y.shape[1]
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            eval_sets = [None] * data_dictionary['test_labels'].shape[1]
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            eval_sets = [None] * data_dictionary["test_labels"].shape[1]
 
-            for i in range(data_dictionary['test_labels'].shape[1]):
+            for i in range(data_dictionary["test_labels"].shape[1]):
                 eval_sets[i] = Pool(
                     data=data_dictionary["test_features"],
                     label=data_dictionary["test_labels"].iloc[:, i],
                     weight=data_dictionary["test_weights"],
                 )
 
         init_model = self.get_init_model(dk.pair)
@@ -60,19 +59,21 @@
         if init_model:
             init_models = init_model.estimators_
         else:
             init_models = [None] * y.shape[1]
 
         fit_params = []
         for i in range(len(eval_sets)):
-            fit_params.append({
-                'eval_set': eval_sets[i], 'init_model': init_models[i],
-                'log_cout': sys.stdout, 'log_cerr': sys.stderr,
-            })
+            fit_params.append(
+                {
+                    "eval_set": eval_sets[i],
+                    "init_model": init_models[i],
+                }
+            )
 
         model = FreqaiMultiOutputClassifier(estimator=cbc)
-        thread_training = self.freqai_info.get('multitarget_parallel_training', False)
+        thread_training = self.freqai_info.get("multitarget_parallel_training", False)
         if thread_training:
             model.n_jobs = y.shape[1]
         model.fit(X=X, y=y, sample_weight=sample_weight, fit_params=fit_params)
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostClassifier.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,22 +1,21 @@
 import logging
-import sys
 from pathlib import Path
 from typing import Any, Dict
 
-from catboost import CatBoostRegressor, Pool
+from catboost import CatBoostClassifier, Pool
 
-from freqtrade.freqai.base_models.BaseRegressionModel import BaseRegressionModel
+from freqtrade.freqai.base_models.BaseClassifierModel import BaseClassifierModel
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
 
 
 logger = logging.getLogger(__name__)
 
 
-class CatboostRegressor(BaseRegressionModel):
+class CatboostClassifier(BaseClassifierModel):
     """
     User created prediction model. The class inherits IFreqaiModel, which
     means it has full access to all Frequency AI functionality. Typically,
     users would use this to override the common `fit()`, `train()`, or
     `predict()` methods to add their custom data handling tools or change
     various aspects of the training that cannot be configured via the
     top level config.json file.
@@ -31,28 +30,32 @@
         """
 
         train_data = Pool(
             data=data_dictionary["train_features"],
             label=data_dictionary["train_labels"],
             weight=data_dictionary["train_weights"],
         )
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) == 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             test_data = None
         else:
             test_data = Pool(
                 data=data_dictionary["test_features"],
                 label=data_dictionary["test_labels"],
                 weight=data_dictionary["test_weights"],
             )
 
-        init_model = self.get_init_model(dk.pair)
-
-        model = CatBoostRegressor(
+        cbr = CatBoostClassifier(
             allow_writing_files=True,
+            loss_function="MultiClass",
             train_dir=Path(dk.data_path),
             **self.model_training_parameters,
         )
 
-        model.fit(X=train_data, eval_set=test_data, init_model=init_model,
-                  log_cout=sys.stdout, log_cerr=sys.stderr)
+        init_model = self.get_init_model(dk.pair)
+
+        cbr.fit(
+            X=train_data,
+            eval_set=test_data,
+            init_model=init_model,
+        )
 
-        return model
+        return cbr
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/CatboostRegressorMultiTarget.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRegressorMultiTarget.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,21 @@
 import logging
-import sys
-from pathlib import Path
 from typing import Any, Dict
 
-from catboost import CatBoostRegressor, Pool
+from xgboost import XGBRegressor
 
 from freqtrade.freqai.base_models.BaseRegressionModel import BaseRegressionModel
 from freqtrade.freqai.base_models.FreqaiMultiOutputRegressor import FreqaiMultiOutputRegressor
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
 
 
 logger = logging.getLogger(__name__)
 
 
-class CatboostRegressorMultiTarget(BaseRegressionModel):
+class XGBoostRegressorMultiTarget(BaseRegressionModel):
     """
     User created prediction model. The class inherits IFreqaiModel, which
     means it has full access to all Frequency AI functionality. Typically,
     users would use this to override the common `fit()`, `train()`, or
     `predict()` methods to add their custom data handling tools or change
     various aspects of the training that cannot be configured via the
     top level config.json file.
@@ -27,51 +25,49 @@
         """
         User sets up the training and test data to fit their desired model here
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         """
 
-        cbr = CatBoostRegressor(
-            allow_writing_files=True,
-            train_dir=Path(dk.data_path),
-            **self.model_training_parameters,
-        )
+        xgb = XGBRegressor(**self.model_training_parameters)
 
         X = data_dictionary["train_features"]
         y = data_dictionary["train_labels"]
-
         sample_weight = data_dictionary["train_weights"]
 
+        eval_weights = None
         eval_sets = [None] * y.shape[1]
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            eval_sets = [None] * data_dictionary['test_labels'].shape[1]
-
-            for i in range(data_dictionary['test_labels'].shape[1]):
-                eval_sets[i] = Pool(
-                    data=data_dictionary["test_features"],
-                    label=data_dictionary["test_labels"].iloc[:, i],
-                    weight=data_dictionary["test_weights"],
-                )
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            eval_weights = [data_dictionary["test_weights"]]
+            for i in range(data_dictionary["test_labels"].shape[1]):
+                eval_sets[i] = [  # type: ignore
+                    (
+                        data_dictionary["test_features"],
+                        data_dictionary["test_labels"].iloc[:, i],
+                    )
+                ]
 
         init_model = self.get_init_model(dk.pair)
-
         if init_model:
             init_models = init_model.estimators_
         else:
             init_models = [None] * y.shape[1]
 
         fit_params = []
         for i in range(len(eval_sets)):
-            fit_params.append({
-                    'eval_set': eval_sets[i],  'init_model': init_models[i],
-                    'log_cout': sys.stdout, 'log_cerr': sys.stderr,
-                 })
+            fit_params.append(
+                {
+                    "eval_set": eval_sets[i],
+                    "sample_weight_eval_set": eval_weights,
+                    "xgb_model": init_models[i],
+                }
+            )
 
-        model = FreqaiMultiOutputRegressor(estimator=cbr)
-        thread_training = self.freqai_info.get('multitarget_parallel_training', False)
+        model = FreqaiMultiOutputRegressor(estimator=xgb)
+        thread_training = self.freqai_info.get("multitarget_parallel_training", False)
         if thread_training:
             model.n_jobs = y.shape[1]
         model.fit(X=X, y=y, sample_weight=sample_weight, fit_params=fit_params)
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMClassifier.py`

 * *Files 6% similar despite different names*

```diff
@@ -24,25 +24,35 @@
         """
         User sets up the training and test data to fit their desired model here
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         """
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) == 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             eval_set = None
             test_weights = None
         else:
-            eval_set = [(data_dictionary["test_features"].to_numpy(),
-                        data_dictionary["test_labels"].to_numpy()[:, 0])]
+            eval_set = [
+                (
+                    data_dictionary["test_features"].to_numpy(),
+                    data_dictionary["test_labels"].to_numpy()[:, 0],
+                )
+            ]
             test_weights = data_dictionary["test_weights"]
         X = data_dictionary["train_features"].to_numpy()
         y = data_dictionary["train_labels"].to_numpy()[:, 0]
         train_weights = data_dictionary["train_weights"]
 
         init_model = self.get_init_model(dk.pair)
 
         model = LGBMClassifier(**self.model_training_parameters)
-        model.fit(X=X, y=y, eval_set=eval_set, sample_weight=train_weights,
-                  eval_sample_weight=[test_weights], init_model=init_model)
+        model.fit(
+            X=X,
+            y=y,
+            eval_set=eval_set,
+            sample_weight=train_weights,
+            eval_sample_weight=[test_weights],
+            init_model=init_model,
+        )
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMClassifierMultiTarget.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMClassifierMultiTarget.py`

 * *Files 5% similar despite different names*

```diff
@@ -34,35 +34,39 @@
         X = data_dictionary["train_features"]
         y = data_dictionary["train_labels"]
         sample_weight = data_dictionary["train_weights"]
 
         eval_weights = None
         eval_sets = [None] * y.shape[1]
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
             eval_weights = [data_dictionary["test_weights"]]
-            eval_sets = [(None, None)] * data_dictionary['test_labels'].shape[1]  # type: ignore
-            for i in range(data_dictionary['test_labels'].shape[1]):
+            eval_sets = [(None, None)] * data_dictionary["test_labels"].shape[1]  # type: ignore
+            for i in range(data_dictionary["test_labels"].shape[1]):
                 eval_sets[i] = (  # type: ignore
                     data_dictionary["test_features"],
-                    data_dictionary["test_labels"].iloc[:, i]
+                    data_dictionary["test_labels"].iloc[:, i],
                 )
 
         init_model = self.get_init_model(dk.pair)
         if init_model:
             init_models = init_model.estimators_
         else:
             init_models = [None] * y.shape[1]
 
         fit_params = []
         for i in range(len(eval_sets)):
             fit_params.append(
-                {'eval_set': eval_sets[i], 'eval_sample_weight': eval_weights,
-                 'init_model': init_models[i]})
+                {
+                    "eval_set": eval_sets[i],
+                    "eval_sample_weight": eval_weights,
+                    "init_model": init_models[i],
+                }
+            )
 
         model = FreqaiMultiOutputClassifier(estimator=lgb)
-        thread_training = self.freqai_info.get('multitarget_parallel_training', False)
+        thread_training = self.freqai_info.get("multitarget_parallel_training", False)
         if thread_training:
             model.n_jobs = y.shape[1]
         model.fit(X=X, y=y, sample_weight=sample_weight, fit_params=fit_params)
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMRegressor.py`

 * *Files 5% similar despite different names*

```diff
@@ -24,25 +24,31 @@
         """
         User sets up the training and test data to fit their desired model here
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         """
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) == 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             eval_set = None
             eval_weights = None
         else:
             eval_set = [(data_dictionary["test_features"], data_dictionary["test_labels"])]
             eval_weights = data_dictionary["test_weights"]
         X = data_dictionary["train_features"]
         y = data_dictionary["train_labels"]
         train_weights = data_dictionary["train_weights"]
 
         init_model = self.get_init_model(dk.pair)
 
         model = LGBMRegressor(**self.model_training_parameters)
 
-        model.fit(X=X, y=y, eval_set=eval_set, sample_weight=train_weights,
-                  eval_sample_weight=[eval_weights], init_model=init_model)
+        model.fit(
+            X=X,
+            y=y,
+            eval_set=eval_set,
+            sample_weight=train_weights,
+            eval_sample_weight=[eval_weights],
+            init_model=init_model,
+        )
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/LightGBMRegressorMultiTarget.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/LightGBMRegressorMultiTarget.py`

 * *Files 7% similar despite different names*

```diff
@@ -34,35 +34,41 @@
         X = data_dictionary["train_features"]
         y = data_dictionary["train_labels"]
         sample_weight = data_dictionary["train_weights"]
 
         eval_weights = None
         eval_sets = [None] * y.shape[1]
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
             eval_weights = [data_dictionary["test_weights"]]
-            eval_sets = [(None, None)] * data_dictionary['test_labels'].shape[1]  # type: ignore
-            for i in range(data_dictionary['test_labels'].shape[1]):
-                eval_sets[i] = [(  # type: ignore
-                    data_dictionary["test_features"],
-                    data_dictionary["test_labels"].iloc[:, i]
-                )]
+            eval_sets = [(None, None)] * data_dictionary["test_labels"].shape[1]  # type: ignore
+            for i in range(data_dictionary["test_labels"].shape[1]):
+                eval_sets[i] = [  # type: ignore
+                    (
+                        data_dictionary["test_features"],
+                        data_dictionary["test_labels"].iloc[:, i],
+                    )
+                ]
 
         init_model = self.get_init_model(dk.pair)
         if init_model:
             init_models = init_model.estimators_
         else:
             init_models = [None] * y.shape[1]
 
         fit_params = []
         for i in range(len(eval_sets)):
             fit_params.append(
-                {'eval_set': eval_sets[i], 'eval_sample_weight': eval_weights,
-                 'init_model': init_models[i]})
+                {
+                    "eval_set": eval_sets[i],
+                    "eval_sample_weight": eval_weights,
+                    "init_model": init_models[i],
+                }
+            )
 
         model = FreqaiMultiOutputRegressor(estimator=lgb)
-        thread_training = self.freqai_info.get('multitarget_parallel_training', False)
+        thread_training = self.freqai_info.get("multitarget_parallel_training", False)
         if thread_training:
             model.n_jobs = y.shape[1]
         model.fit(X=X, y=y, sample_weight=sample_weight, fit_params=fit_params)
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/PyTorchMLPClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/PyTorchMLPClassifier.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,17 @@
 from typing import Any, Dict
 
 import torch
 
 from freqtrade.freqai.base_models.BasePyTorchClassifier import BasePyTorchClassifier
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
-from freqtrade.freqai.torch.PyTorchDataConvertor import (DefaultPyTorchDataConvertor,
-                                                         PyTorchDataConvertor)
+from freqtrade.freqai.torch.PyTorchDataConvertor import (
+    DefaultPyTorchDataConvertor,
+    PyTorchDataConvertor,
+)
 from freqtrade.freqai.torch.PyTorchMLPModel import PyTorchMLPModel
 from freqtrade.freqai.torch.PyTorchModelTrainer import PyTorchModelTrainer
 
 
 class PyTorchMLPClassifier(BasePyTorchClassifier):
     """
     This class implements the fit method of IFreqaiModel.
@@ -39,41 +41,38 @@
         }
     }
     """
 
     @property
     def data_convertor(self) -> PyTorchDataConvertor:
         return DefaultPyTorchDataConvertor(
-            target_tensor_type=torch.long,
-            squeeze_target_tensor=True
+            target_tensor_type=torch.long, squeeze_target_tensor=True
         )
 
     def __init__(self, **kwargs) -> None:
         super().__init__(**kwargs)
         config = self.freqai_info.get("model_training_parameters", {})
-        self.learning_rate: float = config.get("learning_rate",  3e-4)
-        self.model_kwargs: Dict[str, Any] = config.get("model_kwargs",  {})
-        self.trainer_kwargs: Dict[str, Any] = config.get("trainer_kwargs",  {})
+        self.learning_rate: float = config.get("learning_rate", 3e-4)
+        self.model_kwargs: Dict[str, Any] = config.get("model_kwargs", {})
+        self.trainer_kwargs: Dict[str, Any] = config.get("trainer_kwargs", {})
 
     def fit(self, data_dictionary: Dict, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         User sets up the training and test data to fit their desired model here
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         :raises ValueError: If self.class_names is not defined in the parent class.
         """
 
         class_names = self.get_class_names()
         self.convert_label_column_to_int(data_dictionary, dk, class_names)
         n_features = data_dictionary["train_features"].shape[-1]
         model = PyTorchMLPModel(
-            input_dim=n_features,
-            output_dim=len(class_names),
-            **self.model_kwargs
+            input_dim=n_features, output_dim=len(class_names), **self.model_kwargs
         )
         model.to(self.device)
         optimizer = torch.optim.AdamW(model.parameters(), lr=self.learning_rate)
         criterion = torch.nn.CrossEntropyLoss()
         # check if continual_learning is activated, and retrieve the model to continue training
         trainer = self.get_init_model(dk.pair)
         if trainer is None:
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/PyTorchMLPRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/PyTorchMLPRegressor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,17 @@
 from typing import Any, Dict
 
 import torch
 
 from freqtrade.freqai.base_models.BasePyTorchRegressor import BasePyTorchRegressor
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
-from freqtrade.freqai.torch.PyTorchDataConvertor import (DefaultPyTorchDataConvertor,
-                                                         PyTorchDataConvertor)
+from freqtrade.freqai.torch.PyTorchDataConvertor import (
+    DefaultPyTorchDataConvertor,
+    PyTorchDataConvertor,
+)
 from freqtrade.freqai.torch.PyTorchMLPModel import PyTorchMLPModel
 from freqtrade.freqai.torch.PyTorchModelTrainer import PyTorchModelTrainer
 
 
 class PyTorchMLPRegressor(BasePyTorchRegressor):
     """
     This class implements the fit method of IFreqaiModel.
@@ -44,32 +46,28 @@
     @property
     def data_convertor(self) -> PyTorchDataConvertor:
         return DefaultPyTorchDataConvertor(target_tensor_type=torch.float)
 
     def __init__(self, **kwargs) -> None:
         super().__init__(**kwargs)
         config = self.freqai_info.get("model_training_parameters", {})
-        self.learning_rate: float = config.get("learning_rate",  3e-4)
-        self.model_kwargs: Dict[str, Any] = config.get("model_kwargs",  {})
-        self.trainer_kwargs: Dict[str, Any] = config.get("trainer_kwargs",  {})
+        self.learning_rate: float = config.get("learning_rate", 3e-4)
+        self.model_kwargs: Dict[str, Any] = config.get("model_kwargs", {})
+        self.trainer_kwargs: Dict[str, Any] = config.get("trainer_kwargs", {})
 
     def fit(self, data_dictionary: Dict, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         User sets up the training and test data to fit their desired model here
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         """
 
         n_features = data_dictionary["train_features"].shape[-1]
-        model = PyTorchMLPModel(
-            input_dim=n_features,
-            output_dim=1,
-            **self.model_kwargs
-        )
+        model = PyTorchMLPModel(input_dim=n_features, output_dim=1, **self.model_kwargs)
         model.to(self.device)
         optimizer = torch.optim.AdamW(model.parameters(), lr=self.learning_rate)
         criterion = torch.nn.MSELoss()
         # check if continual_learning is activated, and retrieve the model to continue training
         trainer = self.get_init_model(dk.pair)
         if trainer is None:
             trainer = PyTorchModelTrainer(
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/PyTorchTransformerRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/PyTorchTransformerRegressor.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,16 +3,18 @@
 import numpy as np
 import numpy.typing as npt
 import pandas as pd
 import torch
 
 from freqtrade.freqai.base_models.BasePyTorchRegressor import BasePyTorchRegressor
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
-from freqtrade.freqai.torch.PyTorchDataConvertor import (DefaultPyTorchDataConvertor,
-                                                         PyTorchDataConvertor)
+from freqtrade.freqai.torch.PyTorchDataConvertor import (
+    DefaultPyTorchDataConvertor,
+    PyTorchDataConvertor,
+)
 from freqtrade.freqai.torch.PyTorchModelTrainer import PyTorchTransformerTrainer
 from freqtrade.freqai.torch.PyTorchTransformerModel import PyTorchTransformerModel
 
 
 class PyTorchTransformerRegressor(BasePyTorchRegressor):
     """
     This class implements the fit method of IFreqaiModel.
@@ -53,17 +55,17 @@
     @property
     def data_convertor(self) -> PyTorchDataConvertor:
         return DefaultPyTorchDataConvertor(target_tensor_type=torch.float)
 
     def __init__(self, **kwargs) -> None:
         super().__init__(**kwargs)
         config = self.freqai_info.get("model_training_parameters", {})
-        self.learning_rate: float = config.get("learning_rate",  3e-4)
-        self.model_kwargs: Dict[str, Any] = config.get("model_kwargs",  {})
-        self.trainer_kwargs: Dict[str, Any] = config.get("trainer_kwargs",  {})
+        self.learning_rate: float = config.get("learning_rate", 3e-4)
+        self.model_kwargs: Dict[str, Any] = config.get("model_kwargs", {})
+        self.trainer_kwargs: Dict[str, Any] = config.get("trainer_kwargs", {})
 
     def fit(self, data_dictionary: Dict, dk: FreqaiDataKitchen, **kwargs) -> Any:
         """
         User sets up the training and test data to fit their desired model here
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
@@ -71,15 +73,15 @@
 
         n_features = data_dictionary["train_features"].shape[-1]
         n_labels = data_dictionary["train_labels"].shape[-1]
         model = PyTorchTransformerModel(
             input_dim=n_features,
             output_dim=n_labels,
             time_window=self.window_size,
-            **self.model_kwargs
+            **self.model_kwargs,
         )
         model.to(self.device)
         optimizer = torch.optim.AdamW(model.parameters(), lr=self.learning_rate)
         criterion = torch.nn.MSELoss()
         # check if continual_learning is activated, and retrieve the model to continue training
         trainer = self.get_init_model(dk.pair)
         if trainer is None:
@@ -110,30 +112,30 @@
 
         dk.find_features(unfiltered_df)
         dk.data_dictionary["prediction_features"], _ = dk.filter_features(
             unfiltered_df, dk.training_features_list, training_filter=False
         )
 
         dk.data_dictionary["prediction_features"], outliers, _ = dk.feature_pipeline.transform(
-            dk.data_dictionary["prediction_features"], outlier_check=True)
+            dk.data_dictionary["prediction_features"], outlier_check=True
+        )
 
         x = self.data_convertor.convert_x(
-            dk.data_dictionary["prediction_features"],
-            device=self.device
+            dk.data_dictionary["prediction_features"], device=self.device
         )
         # if user is asking for multiple predictions, slide the window
         # along the tensor
         x = x.unsqueeze(0)
         # create empty torch tensor
         self.model.model.eval()
         yb = torch.empty(0).to(self.device)
         if x.shape[1] > self.window_size:
             ws = self.window_size
             for i in range(0, x.shape[1] - ws):
-                xb = x[:, i:i + ws, :].to(self.device)
+                xb = x[:, i : i + ws, :].to(self.device)
                 y = self.model.model(xb)
                 yb = torch.cat((yb, y), dim=1)
         else:
             yb = self.model.model(x)
 
         yb = yb.cpu().squeeze(0)
         pred_df = pd.DataFrame(yb.detach().numpy(), columns=dk.label_list)
@@ -142,11 +144,12 @@
         if self.freqai_info.get("DI_threshold", 0) > 0:
             dk.DI_values = dk.feature_pipeline["di"].di_values
         else:
             dk.DI_values = np.zeros(outliers.shape[0])
         dk.do_predict = outliers
 
         if x.shape[1] > 1:
-            zeros_df = pd.DataFrame(np.zeros((x.shape[1] - len(pred_df), len(pred_df.columns))),
-                                    columns=pred_df.columns)
+            zeros_df = pd.DataFrame(
+                np.zeros((x.shape[1] - len(pred_df), len(pred_df.columns))), columns=pred_df.columns
+            )
             pred_df = pd.concat([zeros_df, pred_df], axis=0, ignore_index=True)
         return (pred_df, dk.do_predict)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/ReinforcementLearner.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/ReinforcementLearner.py`

 * *Files 4% similar despite different names*

```diff
@@ -52,49 +52,52 @@
         :param dk: FreqaiDatakitchen = data kitchen for current pair.
         :return:
         model Any = trained model to be used for inference in dry/live/backtesting
         """
         train_df = data_dictionary["train_features"]
         total_timesteps = self.freqai_info["rl_config"]["train_cycles"] * len(train_df)
 
-        policy_kwargs = dict(activation_fn=th.nn.ReLU,
-                             net_arch=self.net_arch)
+        policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=self.net_arch)
 
         if self.activate_tensorboard:
-            tb_path = Path(dk.full_path / "tensorboard" / dk.pair.split('/')[0])
+            tb_path = Path(dk.full_path / "tensorboard" / dk.pair.split("/")[0])
         else:
             tb_path = None
 
         if dk.pair not in self.dd.model_dictionary or not self.continual_learning:
-            model = self.MODELCLASS(self.policy_type, self.train_env, policy_kwargs=policy_kwargs,
-                                    tensorboard_log=tb_path,
-                                    **self.freqai_info.get('model_training_parameters', {})
-                                    )
+            model = self.MODELCLASS(
+                self.policy_type,
+                self.train_env,
+                policy_kwargs=policy_kwargs,
+                tensorboard_log=tb_path,
+                **self.freqai_info.get("model_training_parameters", {}),
+            )
         else:
-            logger.info('Continual training activated - starting training from previously '
-                        'trained agent.')
+            logger.info(
+                "Continual training activated - starting training from previously trained agent."
+            )
             model = self.dd.model_dictionary[dk.pair]
             model.set_env(self.train_env)
         callbacks: List[Any] = [self.eval_callback, self.tensorboard_callback]
         progressbar_callback: Optional[ProgressBarCallback] = None
-        if self.rl_config.get('progress_bar', False):
+        if self.rl_config.get("progress_bar", False):
             progressbar_callback = ProgressBarCallback()
             callbacks.insert(0, progressbar_callback)
 
         try:
             model.learn(
                 total_timesteps=int(total_timesteps),
                 callback=callbacks,
             )
         finally:
             if progressbar_callback:
                 progressbar_callback.on_training_end()
 
         if Path(dk.data_path / "best_model.zip").is_file():
-            logger.info('Callback found a best model.')
+            logger.info("Callback found a best model.")
             best_model = self.MODELCLASS.load(dk.data_path / "best_model")
             return best_model
 
         logger.info("Couldn't find best model, using final model instead.")
 
         return model
 
@@ -123,46 +126,46 @@
             """
             # first, penalize if the action is not valid
             if not self._is_valid(action):
                 self.tensorboard_log("invalid", category="actions")
                 return -2
 
             pnl = self.get_unrealized_profit()
-            factor = 100.
+            factor = 100.0
 
             # reward agent for entering trades
-            if (action == Actions.Long_enter.value
-                    and self._position == Positions.Neutral):
+            if action == Actions.Long_enter.value and self._position == Positions.Neutral:
                 return 25
-            if (action == Actions.Short_enter.value
-                    and self._position == Positions.Neutral):
+            if action == Actions.Short_enter.value and self._position == Positions.Neutral:
                 return 25
             # discourage agent from not entering trades
             if action == Actions.Neutral.value and self._position == Positions.Neutral:
                 return -1
 
-            max_trade_duration = self.rl_config.get('max_trade_duration_candles', 300)
+            max_trade_duration = self.rl_config.get("max_trade_duration_candles", 300)
             trade_duration = self._current_tick - self._last_trade_tick  # type: ignore
 
             if trade_duration <= max_trade_duration:
                 factor *= 1.5
             elif trade_duration > max_trade_duration:
                 factor *= 0.5
 
             # discourage sitting in position
-            if (self._position in (Positions.Short, Positions.Long) and
-                    action == Actions.Neutral.value):
+            if (
+                self._position in (Positions.Short, Positions.Long)
+                and action == Actions.Neutral.value
+            ):
                 return -1 * trade_duration / max_trade_duration
 
             # close long
             if action == Actions.Long_exit.value and self._position == Positions.Long:
                 if pnl > self.profit_aim * self.rr:
-                    factor *= self.rl_config['model_reward_parameters'].get('win_reward_factor', 2)
+                    factor *= self.rl_config["model_reward_parameters"].get("win_reward_factor", 2)
                 return float(pnl * factor)
 
             # close short
             if action == Actions.Short_exit.value and self._position == Positions.Short:
                 if pnl > self.profit_aim * self.rr:
-                    factor *= self.rl_config['model_reward_parameters'].get('win_reward_factor', 2)
+                    factor *= self.rl_config["model_reward_parameters"].get("win_reward_factor", 2)
                 return float(pnl * factor)
 
-            return 0.
+            return 0.0
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/ReinforcementLearner_multiproc.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/ReinforcementLearner_multiproc.py`

 * *Files 11% similar despite different names*

```diff
@@ -16,17 +16,21 @@
 
 
 class ReinforcementLearner_multiproc(ReinforcementLearner):
     """
     Demonstration of how to build vectorized environments
     """
 
-    def set_train_and_eval_environments(self, data_dictionary: Dict[str, Any],
-                                        prices_train: DataFrame, prices_test: DataFrame,
-                                        dk: FreqaiDataKitchen):
+    def set_train_and_eval_environments(
+        self,
+        data_dictionary: Dict[str, Any],
+        prices_train: DataFrame,
+        prices_test: DataFrame,
+        dk: FreqaiDataKitchen,
+    ):
         """
         User can override this if they are using a custom MyRLEnv
         :param data_dictionary: dict = common data dictionary containing train and test
             features/labels/weights.
         :param prices_train/test: DataFrame = dataframe comprised of the prices to be used in
             the environment during training
         or testing
@@ -41,28 +45,41 @@
             self.eval_env.close()
 
         env_info = self.pack_env_dict(dk.pair)
 
         eval_freq = len(train_df) // self.max_threads
 
         env_id = "train_env"
-        self.train_env = VecMonitor(SubprocVecEnv([make_env(self.MyRLEnv, env_id, i, 1,
-                                                            train_df, prices_train,
-                                                            env_info=env_info) for i
-                                                   in range(self.max_threads)]))
-
-        eval_env_id = 'eval_env'
-        self.eval_env = VecMonitor(SubprocVecEnv([make_env(self.MyRLEnv, eval_env_id, i, 1,
-                                                           test_df, prices_test,
-                                                           env_info=env_info) for i
-                                                  in range(self.max_threads)]))
-
-        self.eval_callback = MaskableEvalCallback(self.eval_env, deterministic=True,
-                                                  render=False, eval_freq=eval_freq,
-                                                  best_model_save_path=str(dk.data_path),
-                                                  use_masking=(self.model_type == 'MaskablePPO' and
-                                                               is_masking_supported(self.eval_env)))
+        self.train_env = VecMonitor(
+            SubprocVecEnv(
+                [
+                    make_env(self.MyRLEnv, env_id, i, 1, train_df, prices_train, env_info=env_info)
+                    for i in range(self.max_threads)
+                ]
+            )
+        )
+
+        eval_env_id = "eval_env"
+        self.eval_env = VecMonitor(
+            SubprocVecEnv(
+                [
+                    make_env(
+                        self.MyRLEnv, eval_env_id, i, 1, test_df, prices_test, env_info=env_info
+                    )
+                    for i in range(self.max_threads)
+                ]
+            )
+        )
+
+        self.eval_callback = MaskableEvalCallback(
+            self.eval_env,
+            deterministic=True,
+            render=False,
+            eval_freq=eval_freq,
+            best_model_save_path=str(dk.data_path),
+            use_masking=(self.model_type == "MaskablePPO" and is_masking_supported(self.eval_env)),
+        )
 
         # TENSORBOARD CALLBACK DOES NOT RECOMMENDED TO USE WITH MULTIPLE ENVS,
         # IT WILL RETURN FALSE INFORMATION, NEVERTHELESS NOT THREAD SAFE WITH SB3!!!
         actions = self.train_env.env_method("get_actions")[0]
         self.tensorboard_callback = TensorboardCallback(verbose=1, actions=actions)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/SKLearnRandomForestClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/SKLearnRandomForestClassifier.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,25 +31,27 @@
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         """
 
         X = data_dictionary["train_features"].to_numpy()
         y = data_dictionary["train_labels"].to_numpy()[:, 0]
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) == 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             eval_set = None
         else:
             test_features = data_dictionary["test_features"].to_numpy()
             test_labels = data_dictionary["test_labels"].to_numpy()[:, 0]
 
             eval_set = (test_features, test_labels)
 
         if self.freqai_info.get("continual_learning", False):
-            logger.warning("Continual learning is not supported for "
-                           "SKLearnRandomForestClassifier, ignoring.")
+            logger.warning(
+                "Continual learning is not supported for "
+                "SKLearnRandomForestClassifier, ignoring."
+            )
 
         train_weights = data_dictionary["train_weights"]
 
         model = RandomForestClassifier(**self.model_training_parameters)
 
         model.fit(X=X, y=y, sample_weight=train_weights)
         if eval_set:
@@ -69,14 +71,15 @@
         data (NaNs) or felt uncertain about data (PCA and DI index)
         """
 
         (pred_df, dk.do_predict) = super().predict(unfiltered_df, dk, **kwargs)
 
         le = LabelEncoder()
         label = dk.label_list[0]
-        labels_before = list(dk.data['labels_std'].keys())
+        labels_before = list(dk.data["labels_std"].keys())
         labels_after = le.fit_transform(labels_before).tolist()
         pred_df[label] = le.inverse_transform(pred_df[label])
         pred_df = pred_df.rename(
-            columns={labels_after[i]: labels_before[i] for i in range(len(labels_before))})
+            columns={labels_after[i]: labels_before[i] for i in range(len(labels_before))}
+        )
 
         return (pred_df, dk.do_predict)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostClassifier.py`

 * *Files 3% similar despite different names*

```diff
@@ -37,15 +37,15 @@
         X = data_dictionary["train_features"].to_numpy()
         y = data_dictionary["train_labels"].to_numpy()[:, 0]
 
         le = LabelEncoder()
         if not is_integer_dtype(y):
             y = pd.Series(le.fit_transform(y), dtype="int64")
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) == 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             eval_set = None
         else:
             test_features = data_dictionary["test_features"].to_numpy()
             test_labels = data_dictionary["test_labels"].to_numpy()[:, 0]
 
             if not is_integer_dtype(test_labels):
                 test_labels = pd.Series(le.transform(test_labels), dtype="int64")
@@ -54,16 +54,15 @@
 
         train_weights = data_dictionary["train_weights"]
 
         init_model = self.get_init_model(dk.pair)
 
         model = XGBClassifier(**self.model_training_parameters)
 
-        model.fit(X=X, y=y, eval_set=eval_set, sample_weight=train_weights,
-                  xgb_model=init_model)
+        model.fit(X=X, y=y, eval_set=eval_set, sample_weight=train_weights, xgb_model=init_model)
 
         return model
 
     def predict(
         self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs
     ) -> Tuple[DataFrame, npt.NDArray[np.int_]]:
         """
@@ -75,14 +74,15 @@
         data (NaNs) or felt uncertain about data (PCA and DI index)
         """
 
         (pred_df, dk.do_predict) = super().predict(unfiltered_df, dk, **kwargs)
 
         le = LabelEncoder()
         label = dk.label_list[0]
-        labels_before = list(dk.data['labels_std'].keys())
+        labels_before = list(dk.data["labels_std"].keys())
         labels_after = le.fit_transform(labels_before).tolist()
         pred_df[label] = le.inverse_transform(pred_df[label])
         pred_df = pred_df.rename(
-            columns={labels_after[i]: labels_before[i] for i in range(len(labels_before))})
+            columns={labels_after[i]: labels_before[i] for i in range(len(labels_before))}
+        )
 
         return (pred_df, dk.do_predict)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRFClassifier.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRFClassifier.py`

 * *Files 3% similar despite different names*

```diff
@@ -37,15 +37,15 @@
         X = data_dictionary["train_features"].to_numpy()
         y = data_dictionary["train_labels"].to_numpy()[:, 0]
 
         le = LabelEncoder()
         if not is_integer_dtype(y):
             y = pd.Series(le.fit_transform(y), dtype="int64")
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) == 0:
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             eval_set = None
         else:
             test_features = data_dictionary["test_features"].to_numpy()
             test_labels = data_dictionary["test_labels"].to_numpy()[:, 0]
 
             if not is_integer_dtype(test_labels):
                 test_labels = pd.Series(le.transform(test_labels), dtype="int64")
@@ -54,16 +54,15 @@
 
         train_weights = data_dictionary["train_weights"]
 
         init_model = self.get_init_model(dk.pair)
 
         model = XGBRFClassifier(**self.model_training_parameters)
 
-        model.fit(X=X, y=y, eval_set=eval_set, sample_weight=train_weights,
-                  xgb_model=init_model)
+        model.fit(X=X, y=y, eval_set=eval_set, sample_weight=train_weights, xgb_model=init_model)
 
         return model
 
     def predict(
         self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs
     ) -> Tuple[DataFrame, npt.NDArray[np.int_]]:
         """
@@ -75,14 +74,15 @@
         data (NaNs) or felt uncertain about data (PCA and DI index)
         """
 
         (pred_df, dk.do_predict) = super().predict(unfiltered_df, dk, **kwargs)
 
         le = LabelEncoder()
         label = dk.label_list[0]
-        labels_before = list(dk.data['labels_std'].keys())
+        labels_before = list(dk.data["labels_std"].keys())
         labels_after = le.fit_transform(labels_before).tolist()
         pred_df[label] = le.inverse_transform(pred_df[label])
         pred_df = pred_df.rename(
-            columns={labels_after[i]: labels_before[i] for i in range(len(labels_before))})
+            columns={labels_after[i]: labels_before[i] for i in range(len(labels_before))}
+        )
 
         return (pred_df, dk.do_predict)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRFRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRFRegressor.py`

 * *Files 12% similar despite different names*

```diff
@@ -33,22 +33,28 @@
         y = data_dictionary["train_labels"]
 
         if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             eval_set = None
             eval_weights = None
         else:
             eval_set = [(data_dictionary["test_features"], data_dictionary["test_labels"])]
-            eval_weights = [data_dictionary['test_weights']]
+            eval_weights = [data_dictionary["test_weights"]]
 
         sample_weight = data_dictionary["train_weights"]
 
         xgb_model = self.get_init_model(dk.pair)
 
         model = XGBRFRegressor(**self.model_training_parameters)
 
         model.set_params(callbacks=[TBCallback(dk.data_path)])
-        model.fit(X=X, y=y, sample_weight=sample_weight, eval_set=eval_set,
-                  sample_weight_eval_set=eval_weights, xgb_model=xgb_model)
+        model.fit(
+            X=X,
+            y=y,
+            sample_weight=sample_weight,
+            eval_set=eval_set,
+            sample_weight_eval_set=eval_weights,
+            xgb_model=xgb_model,
+        )
         # set the callbacks to empty so that we can serialize to disk later
         model.set_params(callbacks=[])
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRegressor.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/XGBoostRegressor.py`

 * *Files 5% similar despite different names*

```diff
@@ -32,30 +32,29 @@
         X = data_dictionary["train_features"]
         y = data_dictionary["train_labels"]
 
         if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) == 0:
             eval_set = None
             eval_weights = None
         else:
-            eval_set = [
-                (data_dictionary["test_features"],
-                 data_dictionary["test_labels"]),
-                (X, y)
-            ]
-            eval_weights = [
-                data_dictionary['test_weights'],
-                data_dictionary['train_weights']
-            ]
+            eval_set = [(data_dictionary["test_features"], data_dictionary["test_labels"]), (X, y)]
+            eval_weights = [data_dictionary["test_weights"], data_dictionary["train_weights"]]
 
         sample_weight = data_dictionary["train_weights"]
 
         xgb_model = self.get_init_model(dk.pair)
 
         model = XGBRegressor(**self.model_training_parameters)
 
         model.set_params(callbacks=[TBCallback(dk.data_path)])
-        model.fit(X=X, y=y, sample_weight=sample_weight, eval_set=eval_set,
-                  sample_weight_eval_set=eval_weights, xgb_model=xgb_model)
+        model.fit(
+            X=X,
+            y=y,
+            sample_weight=sample_weight,
+            eval_set=eval_set,
+            sample_weight_eval_set=eval_weights,
+            xgb_model=xgb_model,
+        )
         # set the callbacks to empty so that we can serialize to disk later
         model.set_params(callbacks=[])
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/prediction_models/XGBoostRegressorMultiTarget.py` & `freqtrade-2024.5/freqtrade/freqai/prediction_models/CatboostRegressorMultiTarget.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 import logging
+from pathlib import Path
 from typing import Any, Dict
 
-from xgboost import XGBRegressor
+from catboost import CatBoostRegressor, Pool
 
 from freqtrade.freqai.base_models.BaseRegressionModel import BaseRegressionModel
 from freqtrade.freqai.base_models.FreqaiMultiOutputRegressor import FreqaiMultiOutputRegressor
 from freqtrade.freqai.data_kitchen import FreqaiDataKitchen
 
 
 logger = logging.getLogger(__name__)
 
 
-class XGBoostRegressorMultiTarget(BaseRegressionModel):
+class CatboostRegressorMultiTarget(BaseRegressionModel):
     """
     User created prediction model. The class inherits IFreqaiModel, which
     means it has full access to all Frequency AI functionality. Typically,
     users would use this to override the common `fit()`, `train()`, or
     `predict()` methods to add their custom data handling tools or change
     various aspects of the training that cannot be configured via the
     top level config.json file.
@@ -25,43 +26,53 @@
         """
         User sets up the training and test data to fit their desired model here
         :param data_dictionary: the dictionary holding all data for train, test,
             labels, weights
         :param dk: The datakitchen object for the current coin/model
         """
 
-        xgb = XGBRegressor(**self.model_training_parameters)
+        cbr = CatBoostRegressor(
+            allow_writing_files=True,
+            train_dir=Path(dk.data_path),
+            **self.model_training_parameters,
+        )
 
         X = data_dictionary["train_features"]
         y = data_dictionary["train_labels"]
+
         sample_weight = data_dictionary["train_weights"]
 
-        eval_weights = None
         eval_sets = [None] * y.shape[1]
 
-        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:
-            eval_weights = [data_dictionary["test_weights"]]
-            for i in range(data_dictionary['test_labels'].shape[1]):
-                eval_sets[i] = [(  # type: ignore
-                    data_dictionary["test_features"],
-                    data_dictionary["test_labels"].iloc[:, i]
-                )]
+        if self.freqai_info.get("data_split_parameters", {}).get("test_size", 0.1) != 0:
+            eval_sets = [None] * data_dictionary["test_labels"].shape[1]
+
+            for i in range(data_dictionary["test_labels"].shape[1]):
+                eval_sets[i] = Pool(
+                    data=data_dictionary["test_features"],
+                    label=data_dictionary["test_labels"].iloc[:, i],
+                    weight=data_dictionary["test_weights"],
+                )
 
         init_model = self.get_init_model(dk.pair)
+
         if init_model:
             init_models = init_model.estimators_
         else:
             init_models = [None] * y.shape[1]
 
         fit_params = []
         for i in range(len(eval_sets)):
             fit_params.append(
-                {'eval_set': eval_sets[i], 'sample_weight_eval_set': eval_weights,
-                 'xgb_model': init_models[i]})
+                {
+                    "eval_set": eval_sets[i],
+                    "init_model": init_models[i],
+                }
+            )
 
-        model = FreqaiMultiOutputRegressor(estimator=xgb)
-        thread_training = self.freqai_info.get('multitarget_parallel_training', False)
+        model = FreqaiMultiOutputRegressor(estimator=cbr)
+        thread_training = self.freqai_info.get("multitarget_parallel_training", False)
         if thread_training:
             model.n_jobs = y.shape[1]
         model.fit(X=X, y=y, sample_weight=sample_weight, fit_params=fit_params)
 
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/tensorboard/TensorboardCallback.py` & `freqtrade-2024.5/freqtrade/freqai/tensorboard/TensorboardCallback.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 
 
 class TensorboardCallback(BaseCallback):
     """
     Custom callback for plotting additional values in tensorboard and
     episodic summary reports.
     """
+
     def __init__(self, verbose=1, actions: Type[Enum] = BaseActions):
         super().__init__(verbose)
         self.model: Any = None
         self.actions: Type[Enum] = actions
 
     def _on_training_start(self) -> None:
         hparam_dict = {
@@ -36,18 +37,17 @@
         self.logger.record(
             "hparams",
             HParam(hparam_dict, metric_dict),
             exclude=("stdout", "log", "json", "csv"),
         )
 
     def _on_step(self) -> bool:
-
         local_info = self.locals["infos"][0]
 
-        if hasattr(self.training_env, 'envs'):
+        if hasattr(self.training_env, "envs"):
             tensorboard_metrics = self.training_env.envs[0].unwrapped.tensorboard_metrics
 
         else:
             # For RL-multiproc - usage of [0] might need to be evaluated
             tensorboard_metrics = self.training_env.get_attr("tensorboard_metrics")[0]
 
         for metric in local_info:
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/tensorboard/__init__.py` & `freqtrade-2024.5/freqtrade/freqai/tensorboard/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 # ensure users can still use a non-torch freqai version
 try:
     from freqtrade.freqai.tensorboard.tensorboard import TensorBoardCallback, TensorboardLogger
+
     TBLogger = TensorboardLogger
     TBCallback = TensorBoardCallback
 except ModuleNotFoundError:
-    from freqtrade.freqai.tensorboard.base_tensorboard import (BaseTensorBoardCallback,
-                                                               BaseTensorboardLogger)
+    from freqtrade.freqai.tensorboard.base_tensorboard import (
+        BaseTensorBoardCallback,
+        BaseTensorboardLogger,
+    )
+
     TBLogger = BaseTensorboardLogger  # type: ignore
     TBCallback = BaseTensorBoardCallback  # type: ignore
 
-__all__ = (
-    "TBLogger",
-    "TBCallback"
-)
+__all__ = ("TBLogger", "TBCallback")
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/tensorboard/base_tensorboard.py` & `freqtrade-2024.5/freqtrade/freqai/tensorboard/base_tensorboard.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,18 +16,15 @@
         return
 
     def close(self):
         return
 
 
 class BaseTensorBoardCallback(TrainingCallback):
-
     def __init__(self, logdir: Path, activate: bool = True):
         pass
 
-    def after_iteration(
-        self, model, epoch: int, evals_log: TrainingCallback.EvalsLog
-    ) -> bool:
+    def after_iteration(self, model, epoch: int, evals_log: TrainingCallback.EvalsLog) -> bool:
         return False
 
     def after_training(self, model):
         return model
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/tensorboard/tensorboard.py` & `freqtrade-2024.5/freqtrade/freqai/tensorboard/tensorboard.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 import logging
 from pathlib import Path
 from typing import Any
 
 from torch.utils.tensorboard import SummaryWriter
 from xgboost import callback
 
-from freqtrade.freqai.tensorboard.base_tensorboard import (BaseTensorBoardCallback,
-                                                           BaseTensorboardLogger)
+from freqtrade.freqai.tensorboard.base_tensorboard import (
+    BaseTensorBoardCallback,
+    BaseTensorboardLogger,
+)
 
 
 logger = logging.getLogger(__name__)
 
 
 class TensorboardLogger(BaseTensorboardLogger):
     def __init__(self, logdir: Path, activate: bool = True):
@@ -25,15 +27,14 @@
     def close(self):
         if self.activate:
             self.writer.flush()
             self.writer.close()
 
 
 class TensorBoardCallback(BaseTensorBoardCallback):
-
     def __init__(self, logdir: Path, activate: bool = True):
         self.activate = activate
         if self.activate:
             self.writer: SummaryWriter = SummaryWriter(f"{str(logdir)}/tensorboard")
 
     def after_iteration(
         self, model, epoch: int, evals_log: callback.TrainingCallback.EvalsLog
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/torch/PyTorchDataConvertor.py` & `freqtrade-2024.5/freqtrade/freqai/torch/PyTorchDataConvertor.py`

 * *Files 0% similar despite different names*

```diff
@@ -27,17 +27,17 @@
 
 class DefaultPyTorchDataConvertor(PyTorchDataConvertor):
     """
     A default conversion that keeps features dataframe shapes.
     """
 
     def __init__(
-            self,
-            target_tensor_type: torch.dtype = torch.float32,
-            squeeze_target_tensor: bool = False,
+        self,
+        target_tensor_type: torch.dtype = torch.float32,
+        squeeze_target_tensor: bool = False,
     ):
         """
         :param target_tensor_type: type of target tensor, for classification use
             torch.long, for regressor use torch.float or torch.double.
         :param squeeze_target_tensor: controls the target shape, used for loss functions
             that requires 0D or 1D.
         """
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/torch/PyTorchMLPModel.py` & `freqtrade-2024.5/freqtrade/freqai/torch/PyTorchMLPModel.py`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/freqai/torch/PyTorchModelTrainer.py` & `freqtrade-2024.5/freqtrade/freqai/torch/PyTorchModelTrainer.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,24 +15,24 @@
 
 
 logger = logging.getLogger(__name__)
 
 
 class PyTorchModelTrainer(PyTorchTrainerInterface):
     def __init__(
-            self,
-            model: nn.Module,
-            optimizer: Optimizer,
-            criterion: nn.Module,
-            device: str,
-            data_convertor: PyTorchDataConvertor,
-            model_meta_data: Dict[str, Any] = {},
-            window_size: int = 1,
-            tb_logger: Any = None,
-            **kwargs
+        self,
+        model: nn.Module,
+        optimizer: Optimizer,
+        criterion: nn.Module,
+        device: str,
+        data_convertor: PyTorchDataConvertor,
+        model_meta_data: Dict[str, Any] = {},
+        window_size: int = 1,
+        tb_logger: Any = None,
+        **kwargs,
     ):
         """
         :param model: The PyTorch model to be trained.
         :param optimizer: The optimizer to use for training.
         :param criterion: The loss function to use for training.
         :param device: The device to use for training (e.g. 'cpu', 'cuda').
         :param init_model: A dictionary containing the initial model/optimizer
@@ -97,17 +97,17 @@
 
             # evaluation
             if "test" in splits:
                 self.estimate_loss(data_loaders_dictionary, "test")
 
     @torch.no_grad()
     def estimate_loss(
-            self,
-            data_loader_dictionary: Dict[str, DataLoader],
-            split: str,
+        self,
+        data_loader_dictionary: Dict[str, DataLoader],
+        split: str,
     ) -> None:
         self.model.eval()
         for _, batch_data in enumerate(data_loader_dictionary[split]):
             xb, yb = batch_data
             xb = xb.to(self.device)
             yb = yb.to(self.device)
 
@@ -115,17 +115,15 @@
             loss = self.criterion(yb_pred, yb)
             self.tb_logger.log_scalar(f"{split}_loss", loss.item(), self.test_batch_counter)
             self.test_batch_counter += 1
 
         self.model.train()
 
     def create_data_loaders_dictionary(
-            self,
-            data_dictionary: Dict[str, pd.DataFrame],
-            splits: List[str]
+        self, data_dictionary: Dict[str, pd.DataFrame], splits: List[str]
     ) -> Dict[str, DataLoader]:
         """
         Converts the input data to PyTorch tensors using a data loader.
         """
         data_loader_dictionary = {}
         for split in splits:
             x = self.data_convertor.convert_x(data_dictionary[f"{split}_features"], self.device)
@@ -164,20 +162,23 @@
     def save(self, path: Path):
         """
         - Saving any nn.Module state_dict
         - Saving model_meta_data, this dict should contain any additional data that the
           user needs to store. e.g. class_names for classification models.
         """
 
-        torch.save({
-            "model_state_dict": self.model.state_dict(),
-            "optimizer_state_dict": self.optimizer.state_dict(),
-            "model_meta_data": self.model_meta_data,
-            "pytrainer": self
-        }, path)
+        torch.save(
+            {
+                "model_state_dict": self.model.state_dict(),
+                "optimizer_state_dict": self.optimizer.state_dict(),
+                "model_meta_data": self.model_meta_data,
+                "pytrainer": self,
+            },
+            path,
+        )
 
     def load(self, path: Path):
         checkpoint = torch.load(path)
         return self.load_from_checkpoint(checkpoint)
 
     def load_from_checkpoint(self, checkpoint: Dict):
         """
@@ -194,17 +195,15 @@
 
 class PyTorchTransformerTrainer(PyTorchModelTrainer):
     """
     Creating a trainer for the Transformer model.
     """
 
     def create_data_loaders_dictionary(
-            self,
-            data_dictionary: Dict[str, pd.DataFrame],
-            splits: List[str]
+        self, data_dictionary: Dict[str, pd.DataFrame], splits: List[str]
     ) -> Dict[str, DataLoader]:
         """
         Converts the input data to PyTorch tensors using a data loader.
         """
         data_loader_dictionary = {}
         for split in splits:
             x = self.data_convertor.convert_x(data_dictionary[f"{split}_features"], self.device)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/torch/PyTorchTrainerInterface.py` & `freqtrade-2024.5/freqtrade/freqai/torch/PyTorchTrainerInterface.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 
 import pandas as pd
 import torch
 from torch import nn
 
 
 class PyTorchTrainerInterface(ABC):
-
     @abstractmethod
     def fit(self, data_dictionary: Dict[str, pd.DataFrame], splits: List[str]) -> None:
         """
         :param data_dictionary: the dictionary constructed by DataHandler to hold
         all the training and test data/labels.
         :param splits: splits to use in training, splits must contain "train",
         optional "test" could be added by setting freqai.data_split_parameters.test_size > 0
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/torch/PyTorchTransformerModel.py` & `freqtrade-2024.5/freqtrade/freqai/torch/PyTorchTransformerModel.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,44 +15,53 @@
     """
     A transformer approach to time series modeling using positional encoding.
     The architecture is based on the paper Attention Is All You Need.
     Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
     Lukasz Kaiser, and Illia Polosukhin. 2017.
     """
 
-    def __init__(self, input_dim: int = 7, output_dim: int = 7, hidden_dim=1024,
-                 n_layer=2, dropout_percent=0.1, time_window=10, nhead=8):
+    def __init__(
+        self,
+        input_dim: int = 7,
+        output_dim: int = 7,
+        hidden_dim=1024,
+        n_layer=2,
+        dropout_percent=0.1,
+        time_window=10,
+        nhead=8,
+    ):
         super().__init__()
         self.time_window = time_window
         # ensure the input dimension to the transformer is divisible by nhead
         self.dim_val = input_dim - (input_dim % nhead)
         self.input_net = nn.Sequential(
             nn.Dropout(dropout_percent), nn.Linear(input_dim, self.dim_val)
         )
 
         # Encode the timeseries with Positional encoding
         self.positional_encoding = PositionalEncoding(d_model=self.dim_val, max_len=self.dim_val)
 
         # Define the encoder block of the Transformer
         self.encoder_layer = nn.TransformerEncoderLayer(
-            d_model=self.dim_val, nhead=nhead, dropout=dropout_percent, batch_first=True)
+            d_model=self.dim_val, nhead=nhead, dropout=dropout_percent, batch_first=True
+        )
         self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layer)
 
         # the pseudo decoding FC
         self.output_net = nn.Sequential(
             nn.Linear(self.dim_val * time_window, int(hidden_dim)),
             nn.ReLU(),
             nn.Dropout(dropout_percent),
             nn.Linear(int(hidden_dim), int(hidden_dim / 2)),
             nn.ReLU(),
             nn.Dropout(dropout_percent),
             nn.Linear(int(hidden_dim / 2), int(hidden_dim / 4)),
             nn.ReLU(),
             nn.Dropout(dropout_percent),
-            nn.Linear(int(hidden_dim / 4), output_dim)
+            nn.Linear(int(hidden_dim / 4), output_dim),
         )
 
     def forward(self, x, mask=None, add_positional_encoding=True):
         """
         Args:
             x: Input features of shape [Batch, SeqLen, input_dim]
             mask: Mask to apply on the attention outputs (optional)
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/torch/datasets.py` & `freqtrade-2024.5/freqtrade/freqai/torch/datasets.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,12 +8,12 @@
         self.window_size = window_size
 
     def __len__(self):
         return len(self.xs) - self.window_size
 
     def __getitem__(self, index):
         idx_rev = len(self.xs) - self.window_size - index - 1
-        window_x = self.xs[idx_rev:idx_rev + self.window_size, :]
+        window_x = self.xs[idx_rev : idx_rev + self.window_size, :]
         # Beware of indexing, these two window_x and window_y are aimed at the same row!
         # this is what happens when you use :
         window_y = self.ys[idx_rev + self.window_size - 1, :].unsqueeze(0)
         return window_x, window_y
```

### Comparing `freqtrade-2024.4/freqtrade/freqai/utils.py` & `freqtrade-2024.5/freqtrade/freqai/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -27,19 +27,20 @@
     populating indicators and training the model.
     :param timerange: TimeRange = The full data timerange for populating the indicators
                                     and training the model.
     :param dp: DataProvider instance attached to the strategy
     """
 
     if dp._exchange is None:
-        raise OperationalException('No exchange object found.')
+        raise OperationalException("No exchange object found.")
     markets = [
-        p for p in dp._exchange.get_markets(
-            tradable_only=True, active_only=not config.get('include_inactive')
-            ).keys()
+        p
+        for p in dp._exchange.get_markets(
+            tradable_only=True, active_only=not config.get("include_inactive")
+        ).keys()
     ]
 
     all_pairs = dynamic_expand_pairlist(config, markets)
 
     timerange = get_required_data_timerange(config)
 
     new_pairs_days = int((timerange.stopts - timerange.startts) / 86400)
@@ -69,114 +70,117 @@
 
     max_tf_seconds = 0
     for tf in timeframes:
         secs = timeframe_to_seconds(tf)
         if secs > max_tf_seconds:
             max_tf_seconds = secs
 
-    startup_candles = config.get('startup_candle_count', 0)
+    startup_candles = config.get("startup_candle_count", 0)
     indicator_periods = config["freqai"]["feature_parameters"]["indicator_periods_candles"]
 
     # factor the max_period as a factor of safety.
     max_period = int(max(startup_candles, max(indicator_periods)) * 1.5)
-    config['startup_candle_count'] = max_period
-    logger.info(f'FreqAI auto-downloader using {max_period} startup candles.')
+    config["startup_candle_count"] = max_period
+    logger.info(f"FreqAI auto-downloader using {max_period} startup candles.")
 
     additional_seconds = max_period * max_tf_seconds
 
-    startts = int(
-        time
-        - config["freqai"].get("train_period_days", 0) * 86400
-        - additional_seconds
-    )
+    startts = int(time - config["freqai"].get("train_period_days", 0) * 86400 - additional_seconds)
     stopts = int(time)
-    data_load_timerange = TimeRange('date', 'date', startts, stopts)
+    data_load_timerange = TimeRange("date", "date", startts, stopts)
 
     return data_load_timerange
 
 
-def plot_feature_importance(model: Any, pair: str, dk: FreqaiDataKitchen,
-                            count_max: int = 25) -> None:
-    """
-        Plot Best and worst features by importance for a single sub-train.
-        :param model: Any = A model which was `fit` using a common library
-                            such as catboost or lightgbm
-        :param pair: str = pair e.g. BTC/USD
-        :param dk: FreqaiDataKitchen = non-persistent data container for current coin/loop
-        :param count_max: int = the amount of features to be loaded per column
+def plot_feature_importance(
+    model: Any, pair: str, dk: FreqaiDataKitchen, count_max: int = 25
+) -> None:
+    """
+    Plot Best and worst features by importance for a single sub-train.
+    :param model: Any = A model which was `fit` using a common library
+                        such as catboost or lightgbm
+    :param pair: str = pair e.g. BTC/USD
+    :param dk: FreqaiDataKitchen = non-persistent data container for current coin/loop
+    :param count_max: int = the amount of features to be loaded per column
     """
     from freqtrade.plot.plotting import go, make_subplots, store_plot_file
 
     # Extract feature importance from model
     models = {}
-    if 'FreqaiMultiOutputRegressor' in str(model.__class__):
+    if "FreqaiMultiOutputRegressor" in str(model.__class__):
         for estimator, label in zip(model.estimators_, dk.label_list):
             models[label] = estimator
     else:
         models[dk.label_list[0]] = model
 
     for label in models:
         mdl = models[label]
         if "catboost.core" in str(mdl.__class__):
             feature_importance = mdl.get_feature_importance()
         elif "lightgbm.sklearn" in str(mdl.__class__):
             feature_importance = mdl.feature_importances_
         elif "xgb" in str(mdl.__class__):
             feature_importance = mdl.feature_importances_
         else:
-            logger.info('Model type does not support generating feature importances.')
+            logger.info("Model type does not support generating feature importances.")
             return
 
         # Data preparation
-        fi_df = pd.DataFrame({
-            "feature_names": np.array(dk.data_dictionary['train_features'].columns),
-            "feature_importance": np.array(feature_importance)
-        })
+        fi_df = pd.DataFrame(
+            {
+                "feature_names": np.array(dk.data_dictionary["train_features"].columns),
+                "feature_importance": np.array(feature_importance),
+            }
+        )
         fi_df_top = fi_df.nlargest(count_max, "feature_importance")[::-1]
         fi_df_worst = fi_df.nsmallest(count_max, "feature_importance")[::-1]
 
         # Plotting
         def add_feature_trace(fig, fi_df, col):
             return fig.add_trace(
                 go.Bar(
                     x=fi_df["feature_importance"],
                     y=fi_df["feature_names"],
-                    orientation='h', showlegend=False
-                ), row=1, col=col
+                    orientation="h",
+                    showlegend=False,
+                ),
+                row=1,
+                col=col,
             )
+
         fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.5)
         fig = add_feature_trace(fig, fi_df_top, 1)
         fig = add_feature_trace(fig, fi_df_worst, 2)
         fig.update_layout(title_text=f"Best and worst features by importance {pair}")
-        label = label.replace('&', '').replace('%', '')  # escape two FreqAI specific characters
+        label = label.replace("&", "").replace("%", "")  # escape two FreqAI specific characters
         store_plot_file(fig, f"{dk.model_filename}-{label}.html", dk.data_path)
 
 
 def record_params(config: Dict[str, Any], full_path: Path) -> None:
     """
     Records run params in the full path for reproducibility
     """
     params_record_path = full_path / "run_params.json"
 
     run_params = {
-        "freqai": config.get('freqai', {}),
-        "timeframe": config.get('timeframe'),
-        "stake_amount": config.get('stake_amount'),
-        "stake_currency": config.get('stake_currency'),
-        "max_open_trades": config.get('max_open_trades'),
-        "pairs": config.get('exchange', {}).get('pair_whitelist')
+        "freqai": config.get("freqai", {}),
+        "timeframe": config.get("timeframe"),
+        "stake_amount": config.get("stake_amount"),
+        "stake_currency": config.get("stake_currency"),
+        "max_open_trades": config.get("max_open_trades"),
+        "pairs": config.get("exchange", {}).get("pair_whitelist"),
     }
 
     with params_record_path.open("w") as handle:
         rapidjson.dump(
             run_params,
             handle,
             indent=4,
             default=str,
-            number_mode=rapidjson.NM_NATIVE | rapidjson.NM_NAN
+            number_mode=rapidjson.NM_NATIVE | rapidjson.NM_NAN,
         )
 
 
 def get_timerange_backtest_live_models(config: Config) -> str:
     """
     Returns a formatted timerange for backtest live/ready models
     :param config: Configuration dictionary
@@ -187,14 +191,15 @@
     models_path = dk.get_full_models_path(config)
     dd = FreqaiDataDrawer(models_path, config)
     timerange = dd.get_timerange_from_live_historic_predictions()
     return timerange.timerange_str
 
 
 def get_tb_logger(model_type: str, path: Path, activate: bool) -> Any:
-
     if model_type == "pytorch" and activate:
         from freqtrade.freqai.tensorboard import TBLogger
+
         return TBLogger(path, activate)
     else:
         from freqtrade.freqai.tensorboard.base_tensorboard import BaseTensorboardLogger
+
         return BaseTensorboardLogger(path, activate)
```

### Comparing `freqtrade-2024.4/freqtrade/freqtradebot.py` & `freqtrade-2024.5/freqtrade/freqtradebot.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Freqtrade is the main module of this bot. It contains the class Freqtrade()
 """
+
 import logging
 import traceback
 from copy import deepcopy
 from datetime import datetime, time, timedelta, timezone
 from math import isclose
 from threading import Lock
 from time import sleep
@@ -14,35 +15,58 @@
 
 from freqtrade import constants
 from freqtrade.configuration import validate_config_consistency
 from freqtrade.constants import BuySell, Config, EntryExecuteMode, ExchangeConfig, LongShort
 from freqtrade.data.converter import order_book_to_dataframe
 from freqtrade.data.dataprovider import DataProvider
 from freqtrade.edge import Edge
-from freqtrade.enums import (ExitCheckTuple, ExitType, RPCMessageType, SignalDirection, State,
-                             TradingMode)
-from freqtrade.exceptions import (DependencyException, ExchangeError, InsufficientFundsError,
-                                  InvalidOrderException, PricingError)
-from freqtrade.exchange import (ROUND_DOWN, ROUND_UP, remove_exchange_credentials,
-                                timeframe_to_minutes, timeframe_to_next_date, timeframe_to_seconds)
+from freqtrade.enums import (
+    ExitCheckTuple,
+    ExitType,
+    RPCMessageType,
+    SignalDirection,
+    State,
+    TradingMode,
+)
+from freqtrade.exceptions import (
+    DependencyException,
+    ExchangeError,
+    InsufficientFundsError,
+    InvalidOrderException,
+    PricingError,
+)
+from freqtrade.exchange import (
+    ROUND_DOWN,
+    ROUND_UP,
+    remove_exchange_credentials,
+    timeframe_to_minutes,
+    timeframe_to_next_date,
+    timeframe_to_seconds,
+)
 from freqtrade.misc import safe_value_fallback, safe_value_fallback2
 from freqtrade.mixins import LoggingMixin
 from freqtrade.persistence import Order, PairLocks, Trade, init_db
 from freqtrade.persistence.key_value_store import set_startup_time
 from freqtrade.plugins.pairlistmanager import PairListManager
 from freqtrade.plugins.protectionmanager import ProtectionManager
 from freqtrade.resolvers import ExchangeResolver, StrategyResolver
 from freqtrade.rpc import RPCManager
 from freqtrade.rpc.external_message_consumer import ExternalMessageConsumer
-from freqtrade.rpc.rpc_types import (ProfitLossStr, RPCCancelMsg, RPCEntryMsg, RPCExitCancelMsg,
-                                     RPCExitMsg, RPCProtectionMsg)
+from freqtrade.rpc.rpc_types import (
+    ProfitLossStr,
+    RPCCancelMsg,
+    RPCEntryMsg,
+    RPCExitCancelMsg,
+    RPCExitMsg,
+    RPCProtectionMsg,
+)
 from freqtrade.strategy.interface import IStrategy
 from freqtrade.strategy.strategy_wrapper import strategy_safe_wrapper
 from freqtrade.util import MeasureTime
-from freqtrade.util.migrations import migrate_binance_futures_names
+from freqtrade.util.migrations.binance_mig import migrate_binance_futures_names
 from freqtrade.wallets import Wallets
 
 
 logger = logging.getLogger(__name__)
 
 
 class FreqtradeBot(LoggingMixin):
@@ -60,33 +84,34 @@
         self.active_pair_whitelist: List[str] = []
 
         # Init bot state
         self.state = State.STOPPED
 
         # Init objects
         self.config = config
-        exchange_config: ExchangeConfig = deepcopy(config['exchange'])
+        exchange_config: ExchangeConfig = deepcopy(config["exchange"])
         # Remove credentials from original exchange config to avoid accidental credential exposure
-        remove_exchange_credentials(config['exchange'], True)
+        remove_exchange_credentials(config["exchange"], True)
 
         self.strategy: IStrategy = StrategyResolver.load_strategy(self.config)
 
         # Check config consistency here since strategies can set certain options
         validate_config_consistency(config)
 
         self.exchange = ExchangeResolver.load_exchange(
-            self.config, exchange_config=exchange_config, load_leverage_tiers=True)
+            self.config, exchange_config=exchange_config, load_leverage_tiers=True
+        )
 
-        init_db(self.config['db_url'])
+        init_db(self.config["db_url"])
 
         self.wallets = Wallets(self.config, self.exchange)
 
-        PairLocks.timeframe = self.config['timeframe']
+        PairLocks.timeframe = self.config["timeframe"]
 
-        self.trading_mode: TradingMode = self.config.get('trading_mode', TradingMode.SPOT)
+        self.trading_mode: TradingMode = self.config.get("trading_mode", TradingMode.SPOT)
         self.last_process: Optional[datetime] = None
 
         # RPC runs in separate threads, can start handling external commands just after
         # initialization, even before Freqtradebot has a chance to start its throttling,
         # so anything in the Freqtradebot instance should be ready (initialized), including
         # the initial state of the bot.
         # Keep this at the end of this initialization method.
@@ -99,25 +124,31 @@
 
         # Attach Dataprovider to strategy instance
         self.strategy.dp = self.dataprovider
         # Attach Wallets to strategy instance
         self.strategy.wallets = self.wallets
 
         # Initializing Edge only if enabled
-        self.edge = Edge(self.config, self.exchange, self.strategy) if \
-            self.config.get('edge', {}).get('enabled', False) else None
+        self.edge = (
+            Edge(self.config, self.exchange, self.strategy)
+            if self.config.get("edge", {}).get("enabled", False)
+            else None
+        )
 
         # Init ExternalMessageConsumer if enabled
-        self.emc = ExternalMessageConsumer(self.config, self.dataprovider) if \
-            self.config.get('external_message_consumer', {}).get('enabled', False) else None
+        self.emc = (
+            ExternalMessageConsumer(self.config, self.dataprovider)
+            if self.config.get("external_message_consumer", {}).get("enabled", False)
+            else None
+        )
 
         self.active_pair_whitelist = self._refresh_active_whitelist()
 
         # Set initial bot state from config
-        initial_state = self.config.get('initial_state')
+        initial_state = self.config.get("initial_state")
         self.state = State[initial_state.upper()] if initial_state else State.STOPPED
 
         # Protect exit-logic from forcesell and vice versa
         self._exit_lock = Lock()
         timeframe_secs = timeframe_to_seconds(self.strategy.timeframe)
         LoggingMixin.__init__(self, logger, timeframe_secs)
 
@@ -139,47 +170,44 @@
 
         self.strategy.ft_bot_start()
         # Initialize protections AFTER bot start - otherwise parameters are not loaded.
         self.protections = ProtectionManager(self.config, self.strategy.protections)
 
         def log_took_too_long(duration: float, time_limit: float):
             logger.warning(
-                f"Strategy analysis took {duration:.2f}, which is 25% of the timeframe. "
-                "This can lead to delayed orders and missed signals."
+                f"Strategy analysis took {duration:.2f}s, more than 25% of the timeframe "
+                f"({time_limit:.2f}s). This can lead to delayed orders and missed signals."
                 "Consider either reducing the amount of work your strategy performs "
                 "or reduce the amount of pairs in the Pairlist."
             )
 
         self._measure_execution = MeasureTime(log_took_too_long, timeframe_secs * 0.25)
 
     def notify_status(self, msg: str, msg_type=RPCMessageType.STATUS) -> None:
         """
         Public method for users of this class (worker, etc.) to send notifications
         via RPC about changes in the bot status.
         """
-        self.rpc.send_msg({
-            'type': msg_type,
-            'status': msg
-        })
+        self.rpc.send_msg({"type": msg_type, "status": msg})
 
     def cleanup(self) -> None:
         """
         Cleanup pending resources on an already stopped bot
         :return: None
         """
-        logger.info('Cleaning up modules ...')
+        logger.info("Cleaning up modules ...")
         try:
             # Wrap db activities in shutdown to avoid problems if database is gone,
             # and raises further exceptions.
-            if self.config['cancel_open_orders_on_exit']:
+            if self.config["cancel_open_orders_on_exit"]:
                 self.cancel_all_open_orders()
 
             self.check_for_open_trades()
         except Exception as e:
-            logger.warning(f'Exception during cleanup: {e.__class__.__name__} {e}')
+            logger.warning(f"Exception during cleanup: {e.__class__.__name__} {e}")
 
         finally:
             self.strategy.ft_bot_cleanup()
 
         self.rpc.cleanup()
         if self.emc:
             self.emc.shutdown()
@@ -225,19 +253,22 @@
 
         # Query trades from persistence layer
         trades: List[Trade] = Trade.get_open_trades()
 
         self.active_pair_whitelist = self._refresh_active_whitelist(trades)
 
         # Refreshing candles
-        self.dataprovider.refresh(self.pairlists.create_pair_list(self.active_pair_whitelist),
-                                  self.strategy.gather_informative_pairs())
+        self.dataprovider.refresh(
+            self.pairlists.create_pair_list(self.active_pair_whitelist),
+            self.strategy.gather_informative_pairs(),
+        )
 
         strategy_safe_wrapper(self.strategy.bot_loop_start, supress_error=True)(
-            current_time=datetime.now(timezone.utc))
+            current_time=datetime.now(timezone.utc)
+        )
 
         with self._measure_execution:
             self.strategy.analyze(self.active_pair_whitelist)
 
         with self._exit_lock:
             # Check for exchange cancellations, timeouts and user requested replace
             self.manage_open_orders()
@@ -264,33 +295,32 @@
         self.rpc.process_msg_queue(self.dataprovider._msg_queue)
         self.last_process = datetime.now(timezone.utc)
 
     def process_stopped(self) -> None:
         """
         Close all orders that were left open
         """
-        if self.config['cancel_open_orders_on_exit']:
+        if self.config["cancel_open_orders_on_exit"]:
             self.cancel_all_open_orders()
 
     def check_for_open_trades(self):
         """
         Notify the user when the bot is stopped (not reloaded)
         and there are still open trades active.
         """
         open_trades = Trade.get_open_trades()
 
         if len(open_trades) != 0 and self.state != State.RELOAD_CONFIG:
             msg = {
-                'type': RPCMessageType.WARNING,
-                'status':
-                    f"{len(open_trades)} open trades active.\n\n"
-                    f"Handle these trades manually on {self.exchange.name}, "
-                    f"or '/start' the bot again and use '/stopentry' "
-                    f"to handle open trades gracefully. \n"
-                    f"{'Note: Trades are simulated (dry run).' if self.config['dry_run'] else ''}",
+                "type": RPCMessageType.WARNING,
+                "status": f"{len(open_trades)} open trades active.\n\n"
+                f"Handle these trades manually on {self.exchange.name}, "
+                f"or '/start' the bot again and use '/stopentry' "
+                f"to handle open trades gracefully. \n"
+                f"{'Note: Trades are simulated (dry run).' if self.config['dry_run'] else ''}",
             }
             self.rpc.send_msg(msg)
 
     def _refresh_active_whitelist(self, trades: Optional[List[Trade]] = None) -> List[str]:
         """
         Refresh active whitelist from pairlist or edge and extend it with
         pairs that have open trades.
@@ -308,40 +338,40 @@
         if trades:
             # Extend active-pair whitelist with pairs of open trades
             # It ensures that candle (OHLCV) data are downloaded for open trades as well
             _whitelist.extend([trade.pair for trade in trades if trade.pair not in _whitelist])
 
         # Called last to include the included pairs
         if _prev_whitelist != _whitelist:
-            self.rpc.send_msg({'type': RPCMessageType.WHITELIST, 'data': _whitelist})
+            self.rpc.send_msg({"type": RPCMessageType.WHITELIST, "data": _whitelist})
 
         return _whitelist
 
     def get_free_open_trades(self) -> int:
         """
         Return the number of free open trades slots or 0 if
         max number of open trades reached
         """
         open_trades = Trade.get_open_trade_count()
-        return max(0, self.config['max_open_trades'] - open_trades)
+        return max(0, self.config["max_open_trades"] - open_trades)
 
     def update_funding_fees(self) -> None:
         if self.trading_mode == TradingMode.FUTURES:
             trades: List[Trade] = Trade.get_open_trades()
             for trade in trades:
                 trade.set_funding_fees(
                     self.exchange.get_funding_fees(
                         pair=trade.pair,
                         amount=trade.amount,
                         is_short=trade.is_short,
-                        open_date=trade.date_last_filled_utc)
+                        open_date=trade.date_last_filled_utc,
+                    )
                 )
 
     def startup_backpopulate_precision(self) -> None:
-
         trades = Trade.get_trades([Trade.contract_size.is_(None)])
         for trade in trades:
             if trade.exchange != self.exchange.id:
                 continue
             trade.precision_mode = self.exchange.precisionMode
             trade.amount_precision = self.exchange.get_precision_amount(trade.pair)
             trade.price_precision = self.exchange.get_precision_price(trade.pair)
@@ -349,75 +379,83 @@
         Trade.commit()
 
     def startup_update_open_orders(self):
         """
         Updates open orders based on order list kept in the database.
         Mainly updates the state of orders - but may also close trades
         """
-        if self.config['dry_run'] or self.config['exchange'].get('skip_open_order_update', False):
+        if self.config["dry_run"] or self.config["exchange"].get("skip_open_order_update", False):
             # Updating open orders in dry-run does not make sense and will fail.
             return
 
         orders = Order.get_open_orders()
         logger.info(f"Updating {len(orders)} open orders.")
         for order in orders:
             try:
-                fo = self.exchange.fetch_order_or_stoploss_order(order.order_id, order.ft_pair,
-                                                                 order.ft_order_side == 'stoploss')
+                fo = self.exchange.fetch_order_or_stoploss_order(
+                    order.order_id, order.ft_pair, order.ft_order_side == "stoploss"
+                )
                 if not order.trade:
                     # This should not happen, but it does if trades were deleted manually.
                     # This can only incur on sqlite, which doesn't enforce foreign constraints.
                     logger.warning(
                         f"Order {order.order_id} has no trade attached. "
                         "This may suggest a database corruption. "
                         f"The expected trade ID is {order.ft_trade_id}. Ignoring this order."
                     )
                     continue
-                self.update_trade_state(order.trade, order.order_id, fo,
-                                        stoploss_order=(order.ft_order_side == 'stoploss'))
+                self.update_trade_state(
+                    order.trade,
+                    order.order_id,
+                    fo,
+                    stoploss_order=(order.ft_order_side == "stoploss"),
+                )
 
             except InvalidOrderException as e:
                 logger.warning(f"Error updating Order {order.order_id} due to {e}.")
                 if order.order_date_utc - timedelta(days=5) < datetime.now(timezone.utc):
                     logger.warning(
-                        "Order is older than 5 days. Assuming order was fully cancelled.")
+                        "Order is older than 5 days. Assuming order was fully cancelled."
+                    )
                     fo = order.to_ccxt_object()
-                    fo['status'] = 'canceled'
+                    fo["status"] = "canceled"
                     self.handle_cancel_order(
-                        fo, order, order.trade, constants.CANCEL_REASON['TIMEOUT']
+                        fo, order, order.trade, constants.CANCEL_REASON["TIMEOUT"]
                     )
 
             except ExchangeError as e:
-
                 logger.warning(f"Error updating Order {order.order_id} due to {e}")
 
     def update_trades_without_assigned_fees(self) -> None:
         """
         Update closed trades without close fees assigned.
         Only acts when Orders are in the database, otherwise the last order-id is unknown.
         """
-        if self.config['dry_run']:
+        if self.config["dry_run"]:
             # Updating open orders in dry-run does not make sense and will fail.
             return
 
         trades: List[Trade] = Trade.get_closed_trades_without_assigned_fees()
         for trade in trades:
             if not trade.is_open and not trade.fee_updated(trade.exit_side):
                 # Get sell fee
                 order = trade.select_order(trade.exit_side, False, only_filled=True)
                 if not order:
-                    order = trade.select_order('stoploss', False)
+                    order = trade.select_order("stoploss", False)
                 if order:
                     logger.info(
                         f"Updating {trade.exit_side}-fee on trade {trade}"
                         f"for order {order.order_id}."
                     )
-                    self.update_trade_state(trade, order.order_id,
-                                            stoploss_order=order.ft_order_side == 'stoploss',
-                                            send_msg=False)
+                    self.update_trade_state(
+                        trade,
+                        order.order_id,
+                        stoploss_order=order.ft_order_side == "stoploss",
+                        send_msg=False,
+                    )
 
         trades = Trade.get_open_trades_without_assigned_fees()
         for trade in trades:
             with self._exit_lock:
                 if trade.is_open and not trade.fee_updated(trade.entry_side):
                     order = trade.select_order(trade.entry_side, False, only_filled=True)
                     open_order = trade.select_order(trade.entry_side, True)
@@ -438,68 +476,89 @@
         for order in trade.orders:
             logger.info(f"Trying to refind {order}")
             fo = None
             if not order.ft_is_open:
                 logger.debug(f"Order {order} is no longer open.")
                 continue
             try:
-                fo = self.exchange.fetch_order_or_stoploss_order(order.order_id, order.ft_pair,
-                                                                 order.ft_order_side == 'stoploss')
+                fo = self.exchange.fetch_order_or_stoploss_order(
+                    order.order_id, order.ft_pair, order.ft_order_side == "stoploss"
+                )
                 if fo:
                     logger.info(f"Found {order} for trade {trade}.")
-                    self.update_trade_state(trade, order.order_id, fo,
-                                            stoploss_order=order.ft_order_side == 'stoploss')
+                    self.update_trade_state(
+                        trade, order.order_id, fo, stoploss_order=order.ft_order_side == "stoploss"
+                    )
 
             except ExchangeError:
                 logger.warning(f"Error updating {order.order_id}.")
 
-    def handle_onexchange_order(self, trade: Trade):
+    def handle_onexchange_order(self, trade: Trade) -> bool:
         """
         Try refinding a order that is not in the database.
         Only used balance disappeared, which would make exiting impossible.
+        :return: True if the trade was deleted, False otherwise
         """
         try:
             orders = self.exchange.fetch_orders(
-                trade.pair, trade.open_date_utc - timedelta(seconds=10))
+                trade.pair, trade.open_date_utc - timedelta(seconds=10)
+            )
             prev_exit_reason = trade.exit_reason
             prev_trade_state = trade.is_open
             prev_trade_amount = trade.amount
             for order in orders:
-                trade_order = [o for o in trade.orders if o.order_id == order['id']]
+                trade_order = [o for o in trade.orders if o.order_id == order["id"]]
 
                 if trade_order:
                     # We knew this order, but didn't have it updated properly
                     order_obj = trade_order[0]
                 else:
                     logger.info(f"Found previously unknown order {order['id']} for {trade.pair}.")
 
-                    order_obj = Order.parse_from_ccxt_object(order, trade.pair, order['side'])
+                    order_obj = Order.parse_from_ccxt_object(order, trade.pair, order["side"])
                     order_obj.order_filled_date = datetime.fromtimestamp(
-                        safe_value_fallback(order, 'lastTradeTimestamp', 'timestamp') // 1000,
-                        tz=timezone.utc)
+                        safe_value_fallback(order, "lastTradeTimestamp", "timestamp") // 1000,
+                        tz=timezone.utc,
+                    )
                     trade.orders.append(order_obj)
                     Trade.commit()
                     trade.exit_reason = ExitType.SOLD_ON_EXCHANGE.value
 
-                self.update_trade_state(trade, order['id'], order, send_msg=False)
+                self.update_trade_state(trade, order["id"], order, send_msg=False)
 
                 logger.info(f"handled order {order['id']}")
 
             # Refresh trade from database
             Trade.session.refresh(trade)
             if not trade.is_open:
                 # Trade was just closed
                 trade.close_date = trade.date_last_filled_utc
-                self.order_close_notify(trade, order_obj,
-                                        order_obj.ft_order_side == 'stoploss',
-                                        send_msg=prev_trade_state != trade.is_open)
+                self.order_close_notify(
+                    trade,
+                    order_obj,
+                    order_obj.ft_order_side == "stoploss",
+                    send_msg=prev_trade_state != trade.is_open,
+                )
             else:
                 trade.exit_reason = prev_exit_reason
                 total = self.wallets.get_total(trade.base_currency) if trade.base_currency else 0
                 if total < trade.amount:
+                    if trade.fully_canceled_entry_order_count == len(trade.orders):
+                        logger.warning(
+                            f"Trade only had fully canceled entry orders. "
+                            f"Removing {trade} from database."
+                        )
+
+                        self._notify_enter_cancel(
+                            trade,
+                            order_type=self.strategy.order_types["entry"],
+                            reason=constants.CANCEL_REASON["FULLY_CANCELLED"],
+                        )
+                        trade.delete()
+                        return True
                     if total > trade.amount * 0.98:
                         logger.warning(
                             f"{trade} has a total of {trade.amount} {trade.base_currency}, "
                             f"but the Wallet shows a total of {total} {trade.base_currency}. "
                             f"Adjusting trade amount to {total}."
                             "This may however lead to further issues."
                         )
@@ -517,17 +576,19 @@
             Trade.commit()
 
         except ExchangeError:
             logger.warning("Error finding onexchange order.")
         except Exception:
             # catching https://github.com/freqtrade/freqtrade/issues/9025
             logger.warning("Error finding onexchange order", exc_info=True)
-#
-# enter positions / open trades logic and methods
-#
+        return False
+
+    #
+    # enter positions / open trades logic and methods
+    #
 
     def enter_positions(self) -> int:
         """
         Tries to execute entry orders for new trades (positions)
         """
         trades_created = 0
 
@@ -535,39 +596,44 @@
         if not whitelist:
             self.log_once("Active pair whitelist is empty.", logger.info)
             return trades_created
         # Remove pairs for currently opened trades from the whitelist
         for trade in Trade.get_open_trades():
             if trade.pair in whitelist:
                 whitelist.remove(trade.pair)
-                logger.debug('Ignoring %s in pair whitelist', trade.pair)
+                logger.debug("Ignoring %s in pair whitelist", trade.pair)
 
         if not whitelist:
-            self.log_once("No currency pair in active pair whitelist, "
-                          "but checking to exit open trades.", logger.info)
+            self.log_once(
+                "No currency pair in active pair whitelist, but checking to exit open trades.",
+                logger.info,
+            )
             return trades_created
-        if PairLocks.is_global_lock(side='*'):
+        if PairLocks.is_global_lock(side="*"):
             # This only checks for total locks (both sides).
             # per-side locks will be evaluated by `is_pair_locked` within create_trade,
             # once the direction for the trade is clear.
-            lock = PairLocks.get_pair_longest_lock('*')
+            lock = PairLocks.get_pair_longest_lock("*")
             if lock:
-                self.log_once(f"Global pairlock active until "
-                              f"{lock.lock_end_time.strftime(constants.DATETIME_PRINT_FORMAT)}. "
-                              f"Not creating new trades, reason: {lock.reason}.", logger.info)
+                self.log_once(
+                    f"Global pairlock active until "
+                    f"{lock.lock_end_time.strftime(constants.DATETIME_PRINT_FORMAT)}. "
+                    f"Not creating new trades, reason: {lock.reason}.",
+                    logger.info,
+                )
             else:
                 self.log_once("Global pairlock active. Not creating new trades.", logger.info)
             return trades_created
         # Create entity and execute trade for each pair from whitelist
         for pair in whitelist:
             try:
                 with self._exit_lock:
                     trades_created += self.create_trade(pair)
             except DependencyException as exception:
-                logger.warning('Unable to create trade for %s: %s', pair, exception)
+                logger.warning("Unable to create trade for %s: %s", pair, exception)
 
         if not trades_created:
             logger.debug("Found no enter signals for whitelisted currencies. Trying again...")
 
         return trades_created
 
     def create_trade(self, pair: str) -> bool:
@@ -578,68 +644,67 @@
         and the entry-order opening the trade gets issued towards the exchange.
 
         :return: True if a trade has been created.
         """
         logger.debug(f"create_trade for pair {pair}")
 
         analyzed_df, _ = self.dataprovider.get_analyzed_dataframe(pair, self.strategy.timeframe)
-        nowtime = analyzed_df.iloc[-1]['date'] if len(analyzed_df) > 0 else None
+        nowtime = analyzed_df.iloc[-1]["date"] if len(analyzed_df) > 0 else None
 
         # get_free_open_trades is checked before create_trade is called
         # but it is still used here to prevent opening too many trades within one iteration
         if not self.get_free_open_trades():
             logger.debug(f"Can't open a new trade for {pair}: max number of trades is reached.")
             return False
 
         # running get_signal on historical data fetched
         (signal, enter_tag) = self.strategy.get_entry_signal(
-            pair,
-            self.strategy.timeframe,
-            analyzed_df
+            pair, self.strategy.timeframe, analyzed_df
         )
 
         if signal:
             if self.strategy.is_pair_locked(pair, candle_date=nowtime, side=signal):
                 lock = PairLocks.get_pair_longest_lock(pair, nowtime, signal)
                 if lock:
-                    self.log_once(f"Pair {pair} {lock.side} is locked until "
-                                  f"{lock.lock_end_time.strftime(constants.DATETIME_PRINT_FORMAT)} "
-                                  f"due to {lock.reason}.",
-                                  logger.info)
+                    self.log_once(
+                        f"Pair {pair} {lock.side} is locked until "
+                        f"{lock.lock_end_time.strftime(constants.DATETIME_PRINT_FORMAT)} "
+                        f"due to {lock.reason}.",
+                        logger.info,
+                    )
                 else:
                     self.log_once(f"Pair {pair} is currently locked.", logger.info)
                 return False
             stake_amount = self.wallets.get_trade_stake_amount(
-                pair, self.config['max_open_trades'], self.edge)
+                pair, self.config["max_open_trades"], self.edge
+            )
 
-            bid_check_dom = self.config.get('entry_pricing', {}).get('check_depth_of_market', {})
-            if ((bid_check_dom.get('enabled', False)) and
-                    (bid_check_dom.get('bids_to_ask_delta', 0) > 0)):
+            bid_check_dom = self.config.get("entry_pricing", {}).get("check_depth_of_market", {})
+            if (bid_check_dom.get("enabled", False)) and (
+                bid_check_dom.get("bids_to_ask_delta", 0) > 0
+            ):
                 if self._check_depth_of_market(pair, bid_check_dom, side=signal):
                     return self.execute_entry(
                         pair,
                         stake_amount,
                         enter_tag=enter_tag,
-                        is_short=(signal == SignalDirection.SHORT)
+                        is_short=(signal == SignalDirection.SHORT),
                     )
                 else:
                     return False
 
             return self.execute_entry(
-                pair,
-                stake_amount,
-                enter_tag=enter_tag,
-                is_short=(signal == SignalDirection.SHORT)
+                pair, stake_amount, enter_tag=enter_tag, is_short=(signal == SignalDirection.SHORT)
             )
         else:
             return False
 
-#
-# Modify positions / DCA logic and methods
-#
+    #
+    # Modify positions / DCA logic and methods
+    #
     def process_open_trade_positions(self):
         """
         Tries to execute additional buy or sell orders for open trades (positions)
         """
         # Walk through each pair and check if it needs changes
         for trade in Trade.get_open_trades():
             # If there is any open orders, wait for them to finish.
@@ -647,88 +712,107 @@
             if not trade.has_open_orders:
                 # Do a wallets update (will be ratelimited to once per hour)
                 self.wallets.update(False)
                 try:
                     self.check_and_call_adjust_trade_position(trade)
                 except DependencyException as exception:
                     logger.warning(
-                        f"Unable to adjust position of trade for {trade.pair}: {exception}")
+                        f"Unable to adjust position of trade for {trade.pair}: {exception}"
+                    )
 
     def check_and_call_adjust_trade_position(self, trade: Trade):
         """
         Check the implemented trading strategy for adjustment command.
         If the strategy triggers the adjustment, a new order gets issued.
         Once that completes, the existing trade is modified to match new data.
         """
         current_entry_rate, current_exit_rate = self.exchange.get_rates(
-            trade.pair, True, trade.is_short)
+            trade.pair, True, trade.is_short
+        )
 
         current_entry_profit = trade.calc_profit_ratio(current_entry_rate)
         current_exit_profit = trade.calc_profit_ratio(current_exit_rate)
 
-        min_entry_stake = self.exchange.get_min_pair_stake_amount(trade.pair,
-                                                                  current_entry_rate,
-                                                                  0.0)
-        min_exit_stake = self.exchange.get_min_pair_stake_amount(trade.pair,
-                                                                 current_exit_rate,
-                                                                 self.strategy.stoploss)
+        min_entry_stake = self.exchange.get_min_pair_stake_amount(
+            trade.pair, current_entry_rate, 0.0
+        )
+        min_exit_stake = self.exchange.get_min_pair_stake_amount(
+            trade.pair, current_exit_rate, self.strategy.stoploss
+        )
         max_entry_stake = self.exchange.get_max_pair_stake_amount(trade.pair, current_entry_rate)
         stake_available = self.wallets.get_available_stake_amount()
         logger.debug(f"Calling adjust_trade_position for pair {trade.pair}")
         stake_amount, order_tag = self.strategy._adjust_trade_position_internal(
             trade=trade,
-            current_time=datetime.now(timezone.utc), current_rate=current_entry_rate,
-            current_profit=current_entry_profit, min_stake=min_entry_stake,
+            current_time=datetime.now(timezone.utc),
+            current_rate=current_entry_rate,
+            current_profit=current_entry_profit,
+            min_stake=min_entry_stake,
             max_stake=min(max_entry_stake, stake_available),
-            current_entry_rate=current_entry_rate, current_exit_rate=current_exit_rate,
-            current_entry_profit=current_entry_profit, current_exit_profit=current_exit_profit
+            current_entry_rate=current_entry_rate,
+            current_exit_rate=current_exit_rate,
+            current_entry_profit=current_entry_profit,
+            current_exit_profit=current_exit_profit,
         )
 
         if stake_amount is not None and stake_amount > 0.0:
             # We should increase our position
             if self.strategy.max_entry_position_adjustment > -1:
                 count_of_entries = trade.nr_of_successful_entries
                 if count_of_entries > self.strategy.max_entry_position_adjustment:
                     logger.debug(f"Max adjustment entries for {trade.pair} has been reached.")
                     return
                 else:
                     logger.debug("Max adjustment entries is set to unlimited.")
-            self.execute_entry(trade.pair, stake_amount, price=current_entry_rate,
-                               trade=trade, is_short=trade.is_short, mode='pos_adjust',
-                               enter_tag=order_tag)
+            self.execute_entry(
+                trade.pair,
+                stake_amount,
+                price=current_entry_rate,
+                trade=trade,
+                is_short=trade.is_short,
+                mode="pos_adjust",
+                enter_tag=order_tag,
+            )
 
         if stake_amount is not None and stake_amount < 0.0:
             # We should decrease our position
             amount = self.exchange.amount_to_contract_precision(
-                trade.pair,
-                abs(float(stake_amount * trade.amount / trade.stake_amount)))
+                trade.pair, abs(float(stake_amount * trade.amount / trade.stake_amount))
+            )
 
             if amount == 0.0:
                 logger.info("Amount to exit is 0.0 due to exchange limits - not exiting.")
                 return
 
             remaining = (trade.amount - amount) * current_exit_rate
             if min_exit_stake and remaining != 0 and remaining < min_exit_stake:
-                logger.info(f"Remaining amount of {remaining} would be smaller "
-                            f"than the minimum of {min_exit_stake}.")
+                logger.info(
+                    f"Remaining amount of {remaining} would be smaller "
+                    f"than the minimum of {min_exit_stake}."
+                )
                 return
 
-            self.execute_trade_exit(trade, current_exit_rate, exit_check=ExitCheckTuple(
-                exit_type=ExitType.PARTIAL_EXIT), sub_trade_amt=amount, exit_tag=order_tag)
+            self.execute_trade_exit(
+                trade,
+                current_exit_rate,
+                exit_check=ExitCheckTuple(exit_type=ExitType.PARTIAL_EXIT),
+                sub_trade_amt=amount,
+                exit_tag=order_tag,
+            )
 
     def _check_depth_of_market(self, pair: str, conf: Dict, side: SignalDirection) -> bool:
         """
         Checks depth of market before executing an entry
         """
-        conf_bids_to_ask_delta = conf.get('bids_to_ask_delta', 0)
+        conf_bids_to_ask_delta = conf.get("bids_to_ask_delta", 0)
         logger.info(f"Checking depth of market for {pair} ...")
         order_book = self.exchange.fetch_l2_order_book(pair, 1000)
-        order_book_data_frame = order_book_to_dataframe(order_book['bids'], order_book['asks'])
-        order_book_bids = order_book_data_frame['b_size'].sum()
-        order_book_asks = order_book_data_frame['a_size'].sum()
+        order_book_data_frame = order_book_to_dataframe(order_book["bids"], order_book["asks"])
+        order_book_bids = order_book_data_frame["b_size"].sum()
+        order_book_asks = order_book_data_frame["a_size"].sum()
 
         entry_side = order_book_bids if side == SignalDirection.LONG else order_book_asks
         exit_side = order_book_asks if side == SignalDirection.LONG else order_book_bids
         bids_ask_delta = entry_side / exit_side
 
         bids = f"Bids: {order_book_bids}"
         asks = f"Asks: {order_book_asks}"
@@ -753,137 +837,157 @@
         stake_amount: float,
         price: Optional[float] = None,
         *,
         is_short: bool = False,
         ordertype: Optional[str] = None,
         enter_tag: Optional[str] = None,
         trade: Optional[Trade] = None,
-        mode: EntryExecuteMode = 'initial',
+        mode: EntryExecuteMode = "initial",
         leverage_: Optional[float] = None,
     ) -> bool:
         """
         Executes an entry for the given pair
         :param pair: pair for which we want to create a LIMIT order
         :param stake_amount: amount of stake-currency for the pair
         :return: True if an entry order is created, False if it fails.
         :raise: DependencyException or it's subclasses like ExchangeError.
         """
-        time_in_force = self.strategy.order_time_in_force['entry']
+        time_in_force = self.strategy.order_time_in_force["entry"]
 
-        side: BuySell = 'sell' if is_short else 'buy'
-        name = 'Short' if is_short else 'Long'
-        trade_side: LongShort = 'short' if is_short else 'long'
+        side: BuySell = "sell" if is_short else "buy"
+        name = "Short" if is_short else "Long"
+        trade_side: LongShort = "short" if is_short else "long"
         pos_adjust = trade is not None
 
         enter_limit_requested, stake_amount, leverage = self.get_valid_enter_price_and_stake(
-            pair, price, stake_amount, trade_side, enter_tag, trade, mode, leverage_)
+            pair, price, stake_amount, trade_side, enter_tag, trade, mode, leverage_
+        )
 
         if not stake_amount:
             return False
 
-        msg = (f"Position adjust: about to create a new order for {pair} with stake_amount: "
-               f"{stake_amount} for {trade}" if mode == 'pos_adjust'
-               else
-               (f"Replacing {side} order: about create a new order for {pair} with stake_amount: "
+        msg = (
+            f"Position adjust: about to create a new order for {pair} with stake_amount: "
+            f"{stake_amount} for {trade}"
+            if mode == "pos_adjust"
+            else (
+                f"Replacing {side} order: about create a new order for {pair} with stake_amount: "
                 f"{stake_amount} ..."
-                if mode == 'replace' else
-                f"{name} signal found: about create a new trade for {pair} with stake_amount: "
+                if mode == "replace"
+                else f"{name} signal found: about create a new trade for {pair} with stake_amount: "
                 f"{stake_amount} ..."
-                ))
+            )
+        )
         logger.info(msg)
         amount = (stake_amount / enter_limit_requested) * leverage
-        order_type = ordertype or self.strategy.order_types['entry']
+        order_type = ordertype or self.strategy.order_types["entry"]
 
-        if mode == 'initial' and not strategy_safe_wrapper(
-                self.strategy.confirm_trade_entry, default_retval=True)(
-                pair=pair, order_type=order_type, amount=amount, rate=enter_limit_requested,
-                time_in_force=time_in_force, current_time=datetime.now(timezone.utc),
-                entry_tag=enter_tag, side=trade_side):
+        if mode == "initial" and not strategy_safe_wrapper(
+            self.strategy.confirm_trade_entry, default_retval=True
+        )(
+            pair=pair,
+            order_type=order_type,
+            amount=amount,
+            rate=enter_limit_requested,
+            time_in_force=time_in_force,
+            current_time=datetime.now(timezone.utc),
+            entry_tag=enter_tag,
+            side=trade_side,
+        ):
             logger.info(f"User denied entry for {pair}.")
             return False
         order = self.exchange.create_order(
             pair=pair,
             ordertype=order_type,
             side=side,
             amount=amount,
             rate=enter_limit_requested,
             reduceOnly=False,
             time_in_force=time_in_force,
-            leverage=leverage
+            leverage=leverage,
         )
         order_obj = Order.parse_from_ccxt_object(order, pair, side, amount, enter_limit_requested)
         order_obj.ft_order_tag = enter_tag
-        order_id = order['id']
-        order_status = order.get('status')
+        order_id = order["id"]
+        order_status = order.get("status")
         logger.info(f"Order {order_id} was created for {pair} and status is {order_status}.")
 
         # we assume the order is executed at the price requested
         enter_limit_filled_price = enter_limit_requested
         amount_requested = amount
 
-        if order_status == 'expired' or order_status == 'rejected':
-
+        if order_status == "expired" or order_status == "rejected":
             # return false if the order is not filled
-            if float(order['filled']) == 0:
-                logger.warning(f'{name} {time_in_force} order with time in force {order_type} '
-                               f'for {pair} is {order_status} by {self.exchange.name}.'
-                               ' zero amount is fulfilled.')
+            if float(order["filled"]) == 0:
+                logger.warning(
+                    f"{name} {time_in_force} order with time in force {order_type} "
+                    f"for {pair} is {order_status} by {self.exchange.name}."
+                    " zero amount is fulfilled."
+                )
                 return False
             else:
                 # the order is partially fulfilled
                 # in case of IOC orders we can check immediately
                 # if the order is fulfilled fully or partially
-                logger.warning('%s %s order with time in force %s for %s is %s by %s.'
-                               ' %s amount fulfilled out of %s (%s remaining which is canceled).',
-                               name, time_in_force, order_type, pair, order_status,
-                               self.exchange.name, order['filled'], order['amount'],
-                               order['remaining']
-                               )
-                amount = safe_value_fallback(order, 'filled', 'amount', amount)
+                logger.warning(
+                    "%s %s order with time in force %s for %s is %s by %s."
+                    " %s amount fulfilled out of %s (%s remaining which is canceled).",
+                    name,
+                    time_in_force,
+                    order_type,
+                    pair,
+                    order_status,
+                    self.exchange.name,
+                    order["filled"],
+                    order["amount"],
+                    order["remaining"],
+                )
+                amount = safe_value_fallback(order, "filled", "amount", amount)
                 enter_limit_filled_price = safe_value_fallback(
-                    order, 'average', 'price', enter_limit_filled_price)
+                    order, "average", "price", enter_limit_filled_price
+                )
 
         # in case of FOK the order may be filled immediately and fully
-        elif order_status == 'closed':
-            amount = safe_value_fallback(order, 'filled', 'amount', amount)
+        elif order_status == "closed":
+            amount = safe_value_fallback(order, "filled", "amount", amount)
             enter_limit_filled_price = safe_value_fallback(
-                order, 'average', 'price', enter_limit_requested)
+                order, "average", "price", enter_limit_requested
+            )
 
         # Fee is applied twice because we make a LIMIT_BUY and LIMIT_SELL
-        fee = self.exchange.get_fee(symbol=pair, taker_or_maker='maker')
+        fee = self.exchange.get_fee(symbol=pair, taker_or_maker="maker")
         base_currency = self.exchange.get_pair_base_currency(pair)
         open_date = datetime.now(timezone.utc)
 
         funding_fees = self.exchange.get_funding_fees(
             pair=pair,
             amount=amount + trade.amount if trade else amount,
             is_short=is_short,
-            open_date=trade.date_last_filled_utc if trade else open_date
+            open_date=trade.date_last_filled_utc if trade else open_date,
         )
 
         # This is a new trade
         if trade is None:
-
             trade = Trade(
                 pair=pair,
                 base_currency=base_currency,
-                stake_currency=self.config['stake_currency'],
+                stake_currency=self.config["stake_currency"],
                 stake_amount=stake_amount,
                 amount=amount,
                 is_open=True,
                 amount_requested=amount_requested,
                 fee_open=fee,
                 fee_close=fee,
                 open_rate=enter_limit_filled_price,
                 open_rate_requested=enter_limit_requested,
                 open_date=open_date,
                 exchange=self.exchange.id,
                 strategy=self.strategy.get_strategy_name(),
                 enter_tag=enter_tag,
-                timeframe=timeframe_to_minutes(self.config['timeframe']),
+                timeframe=timeframe_to_minutes(self.config["timeframe"]),
                 leverage=leverage,
                 is_short=is_short,
                 trading_mode=self.trading_mode,
                 funding_fees=funding_fees,
                 amount_precision=self.exchange.get_precision_amount(pair),
                 price_precision=self.exchange.get_precision_price(pair),
                 precision_mode=self.exchange.precisionMode,
@@ -906,42 +1010,52 @@
 
         # Updating wallets
         self.wallets.update()
 
         self._notify_enter(trade, order_obj, order_type, sub_trade=pos_adjust)
 
         if pos_adjust:
-            if order_status == 'closed':
+            if order_status == "closed":
                 logger.info(f"DCA order closed, trade should be up to date: {trade}")
                 trade = self.cancel_stoploss_on_exchange(trade)
             else:
                 logger.info(f"DCA order {order_status}, will wait for resolution: {trade}")
 
         # Update fees if order is non-opened
         if order_status in constants.NON_OPEN_EXCHANGE_STATES:
-            self.update_trade_state(trade, order_id, order)
+            fully_canceled = self.update_trade_state(trade, order_id, order)
+            if fully_canceled and mode != "replace":
+                # Fully canceled orders, may happen with some time in force setups (IOC).
+                # Should be handled immediately.
+                self.handle_cancel_enter(
+                    trade, order, order_obj, constants.CANCEL_REASON["TIMEOUT"]
+                )
 
         return True
 
     def cancel_stoploss_on_exchange(self, trade: Trade) -> Trade:
         # First cancelling stoploss on exchange ...
         for oslo in trade.open_sl_orders:
             try:
-                logger.info(f"Cancelling stoploss on exchange for {trade} "
-                            f"order: {oslo.order_id}")
+                logger.info(f"Cancelling stoploss on exchange for {trade} order: {oslo.order_id}")
                 co = self.exchange.cancel_stoploss_order_with_result(
-                    oslo.order_id, trade.pair, trade.amount)
+                    oslo.order_id, trade.pair, trade.amount
+                )
                 self.update_trade_state(trade, oslo.order_id, co, stoploss_order=True)
             except InvalidOrderException:
-                logger.exception(f"Could not cancel stoploss order {oslo.order_id} "
-                                 f"for pair {trade.pair}")
+                logger.exception(
+                    f"Could not cancel stoploss order {oslo.order_id} for pair {trade.pair}"
+                )
         return trade
 
     def get_valid_enter_price_and_stake(
-        self, pair: str, price: Optional[float], stake_amount: float,
+        self,
+        pair: str,
+        price: Optional[float],
+        stake_amount: float,
         trade_side: LongShort,
         entry_tag: Optional[str],
         trade: Optional[Trade],
         mode: EntryExecuteMode,
         leverage_: Optional[float],
     ) -> Tuple[float, float, float]:
         """
@@ -950,252 +1064,282 @@
         """
 
         if price:
             enter_limit_requested = price
         else:
             # Calculate price
             enter_limit_requested = self.exchange.get_rate(
-                pair, side='entry', is_short=(trade_side == 'short'), refresh=True)
-        if mode != 'replace':
+                pair, side="entry", is_short=(trade_side == "short"), refresh=True
+            )
+        if mode != "replace":
             # Don't call custom_entry_price in order-adjust scenario
-            custom_entry_price = strategy_safe_wrapper(self.strategy.custom_entry_price,
-                                                       default_retval=enter_limit_requested)(
-                pair=pair, trade=trade,
+            custom_entry_price = strategy_safe_wrapper(
+                self.strategy.custom_entry_price, default_retval=enter_limit_requested
+            )(
+                pair=pair,
+                trade=trade,
                 current_time=datetime.now(timezone.utc),
-                proposed_rate=enter_limit_requested, entry_tag=entry_tag,
+                proposed_rate=enter_limit_requested,
+                entry_tag=entry_tag,
                 side=trade_side,
             )
 
             enter_limit_requested = self.get_valid_price(custom_entry_price, enter_limit_requested)
 
         if not enter_limit_requested:
-            raise PricingError('Could not determine entry price.')
+            raise PricingError("Could not determine entry price.")
 
         if self.trading_mode != TradingMode.SPOT and trade is None:
             max_leverage = self.exchange.get_max_leverage(pair, stake_amount)
             if leverage_:
                 leverage = leverage_
             else:
                 leverage = strategy_safe_wrapper(self.strategy.leverage, default_retval=1.0)(
                     pair=pair,
                     current_time=datetime.now(timezone.utc),
                     current_rate=enter_limit_requested,
                     proposed_leverage=1.0,
                     max_leverage=max_leverage,
-                    side=trade_side, entry_tag=entry_tag,
+                    side=trade_side,
+                    entry_tag=entry_tag,
                 )
             # Cap leverage between 1.0 and max_leverage.
             leverage = min(max(leverage, 1.0), max_leverage)
         else:
             # Changing leverage currently not possible
             leverage = trade.leverage if trade else 1.0
 
         # Min-stake-amount should actually include Leverage - this way our "minimal"
         # stake- amount might be higher than necessary.
         # We do however also need min-stake to determine leverage, therefore this is ignored as
         # edge-case for now.
         min_stake_amount = self.exchange.get_min_pair_stake_amount(
-            pair, enter_limit_requested,
-            self.strategy.stoploss if not mode == 'pos_adjust' else 0.0,
-            leverage)
+            pair,
+            enter_limit_requested,
+            self.strategy.stoploss if not mode == "pos_adjust" else 0.0,
+            leverage,
+        )
         max_stake_amount = self.exchange.get_max_pair_stake_amount(
-            pair, enter_limit_requested, leverage)
+            pair, enter_limit_requested, leverage
+        )
 
         if not self.edge and trade is None:
             stake_available = self.wallets.get_available_stake_amount()
-            stake_amount = strategy_safe_wrapper(self.strategy.custom_stake_amount,
-                                                 default_retval=stake_amount)(
-                pair=pair, current_time=datetime.now(timezone.utc),
-                current_rate=enter_limit_requested, proposed_stake=stake_amount,
-                min_stake=min_stake_amount, max_stake=min(max_stake_amount, stake_available),
-                leverage=leverage, entry_tag=entry_tag, side=trade_side
+            stake_amount = strategy_safe_wrapper(
+                self.strategy.custom_stake_amount, default_retval=stake_amount
+            )(
+                pair=pair,
+                current_time=datetime.now(timezone.utc),
+                current_rate=enter_limit_requested,
+                proposed_stake=stake_amount,
+                min_stake=min_stake_amount,
+                max_stake=min(max_stake_amount, stake_available),
+                leverage=leverage,
+                entry_tag=entry_tag,
+                side=trade_side,
             )
 
         stake_amount = self.wallets.validate_stake_amount(
             pair=pair,
             stake_amount=stake_amount,
             min_stake_amount=min_stake_amount,
             max_stake_amount=max_stake_amount,
             trade_amount=trade.stake_amount if trade else None,
         )
 
         return enter_limit_requested, stake_amount, leverage
 
-    def _notify_enter(self, trade: Trade, order: Order, order_type: Optional[str],
-                      fill: bool = False, sub_trade: bool = False) -> None:
+    def _notify_enter(
+        self,
+        trade: Trade,
+        order: Order,
+        order_type: Optional[str],
+        fill: bool = False,
+        sub_trade: bool = False,
+    ) -> None:
         """
         Sends rpc notification when a entry order occurred.
         """
         open_rate = order.safe_price
 
         if open_rate is None:
             open_rate = trade.open_rate
 
         current_rate = self.exchange.get_rate(
-            trade.pair, side='entry', is_short=trade.is_short, refresh=False)
+            trade.pair, side="entry", is_short=trade.is_short, refresh=False
+        )
 
         msg: RPCEntryMsg = {
-            'trade_id': trade.id,
-            'type': RPCMessageType.ENTRY_FILL if fill else RPCMessageType.ENTRY,
-            'buy_tag': trade.enter_tag,
-            'enter_tag': trade.enter_tag,
-            'exchange': trade.exchange.capitalize(),
-            'pair': trade.pair,
-            'leverage': trade.leverage if trade.leverage else None,
-            'direction': 'Short' if trade.is_short else 'Long',
-            'limit': open_rate,  # Deprecated (?)
-            'open_rate': open_rate,
-            'order_type': order_type or 'unknown',
-            'stake_amount': trade.stake_amount,
-            'stake_currency': self.config['stake_currency'],
-            'base_currency': self.exchange.get_pair_base_currency(trade.pair),
-            'quote_currency': self.exchange.get_pair_quote_currency(trade.pair),
-            'fiat_currency': self.config.get('fiat_display_currency', None),
-            'amount': order.safe_amount_after_fee if fill else (order.amount or trade.amount),
-            'open_date': trade.open_date_utc or datetime.now(timezone.utc),
-            'current_rate': current_rate,
-            'sub_trade': sub_trade,
+            "trade_id": trade.id,
+            "type": RPCMessageType.ENTRY_FILL if fill else RPCMessageType.ENTRY,
+            "buy_tag": trade.enter_tag,
+            "enter_tag": trade.enter_tag,
+            "exchange": trade.exchange.capitalize(),
+            "pair": trade.pair,
+            "leverage": trade.leverage if trade.leverage else None,
+            "direction": "Short" if trade.is_short else "Long",
+            "limit": open_rate,  # Deprecated (?)
+            "open_rate": open_rate,
+            "order_type": order_type or "unknown",
+            "stake_amount": trade.stake_amount,
+            "stake_currency": self.config["stake_currency"],
+            "base_currency": self.exchange.get_pair_base_currency(trade.pair),
+            "quote_currency": self.exchange.get_pair_quote_currency(trade.pair),
+            "fiat_currency": self.config.get("fiat_display_currency", None),
+            "amount": order.safe_amount_after_fee if fill else (order.amount or trade.amount),
+            "open_date": trade.open_date_utc or datetime.now(timezone.utc),
+            "current_rate": current_rate,
+            "sub_trade": sub_trade,
         }
 
         # Send the message
         self.rpc.send_msg(msg)
 
-    def _notify_enter_cancel(self, trade: Trade, order_type: str, reason: str,
-                             sub_trade: bool = False) -> None:
+    def _notify_enter_cancel(
+        self, trade: Trade, order_type: str, reason: str, sub_trade: bool = False
+    ) -> None:
         """
         Sends rpc notification when a entry order cancel occurred.
         """
         current_rate = self.exchange.get_rate(
-            trade.pair, side='entry', is_short=trade.is_short, refresh=False)
+            trade.pair, side="entry", is_short=trade.is_short, refresh=False
+        )
 
         msg: RPCCancelMsg = {
-            'trade_id': trade.id,
-            'type': RPCMessageType.ENTRY_CANCEL,
-            'buy_tag': trade.enter_tag,
-            'enter_tag': trade.enter_tag,
-            'exchange': trade.exchange.capitalize(),
-            'pair': trade.pair,
-            'leverage': trade.leverage,
-            'direction': 'Short' if trade.is_short else 'Long',
-            'limit': trade.open_rate,
-            'order_type': order_type,
-            'stake_amount': trade.stake_amount,
-            'open_rate': trade.open_rate,
-            'stake_currency': self.config['stake_currency'],
-            'base_currency': self.exchange.get_pair_base_currency(trade.pair),
-            'quote_currency': self.exchange.get_pair_quote_currency(trade.pair),
-            'fiat_currency': self.config.get('fiat_display_currency', None),
-            'amount': trade.amount,
-            'open_date': trade.open_date,
-            'current_rate': current_rate,
-            'reason': reason,
-            'sub_trade': sub_trade,
+            "trade_id": trade.id,
+            "type": RPCMessageType.ENTRY_CANCEL,
+            "buy_tag": trade.enter_tag,
+            "enter_tag": trade.enter_tag,
+            "exchange": trade.exchange.capitalize(),
+            "pair": trade.pair,
+            "leverage": trade.leverage,
+            "direction": "Short" if trade.is_short else "Long",
+            "limit": trade.open_rate,
+            "order_type": order_type,
+            "stake_amount": trade.stake_amount,
+            "open_rate": trade.open_rate,
+            "stake_currency": self.config["stake_currency"],
+            "base_currency": self.exchange.get_pair_base_currency(trade.pair),
+            "quote_currency": self.exchange.get_pair_quote_currency(trade.pair),
+            "fiat_currency": self.config.get("fiat_display_currency", None),
+            "amount": trade.amount,
+            "open_date": trade.open_date,
+            "current_rate": current_rate,
+            "reason": reason,
+            "sub_trade": sub_trade,
         }
 
         # Send the message
         self.rpc.send_msg(msg)
 
-#
-# SELL / exit positions / close trades logic and methods
-#
+    #
+    # SELL / exit positions / close trades logic and methods
+    #
 
     def exit_positions(self, trades: List[Trade]) -> int:
         """
         Tries to execute exit orders for open trades (positions)
         """
         trades_closed = 0
         for trade in trades:
-
             if (
                 not trade.has_open_orders
                 and not trade.has_open_sl_orders
                 and not self.wallets.check_exit_amount(trade)
             ):
                 logger.warning(
-                    f'Not enough {trade.safe_base_currency} in wallet to exit {trade}. '
-                    'Trying to recover.')
-                self.handle_onexchange_order(trade)
+                    f"Not enough {trade.safe_base_currency} in wallet to exit {trade}. "
+                    "Trying to recover."
+                )
+                if self.handle_onexchange_order(trade):
+                    # Trade was deleted. Don't continue.
+                    continue
 
             try:
                 try:
-                    if (self.strategy.order_types.get('stoploss_on_exchange') and
-                            self.handle_stoploss_on_exchange(trade)):
+                    if self.strategy.order_types.get(
+                        "stoploss_on_exchange"
+                    ) and self.handle_stoploss_on_exchange(trade):
                         trades_closed += 1
                         Trade.commit()
                         continue
 
                 except InvalidOrderException as exception:
                     logger.warning(
-                        f'Unable to handle stoploss on exchange for {trade.pair}: {exception}')
+                        f"Unable to handle stoploss on exchange for {trade.pair}: {exception}"
+                    )
                 # Check if we can sell our current pair
                 if not trade.has_open_orders and trade.is_open and self.handle_trade(trade):
                     trades_closed += 1
 
             except DependencyException as exception:
-                logger.warning(f'Unable to exit trade {trade.pair}: {exception}')
+                logger.warning(f"Unable to exit trade {trade.pair}: {exception}")
 
         # Updating wallets if any trade occurred
         if trades_closed:
             self.wallets.update()
 
         return trades_closed
 
     def handle_trade(self, trade: Trade) -> bool:
         """
         Exits the current pair if the threshold is reached and updates the trade record.
         :return: True if trade has been sold/exited_short, False otherwise
         """
         if not trade.is_open:
-            raise DependencyException(f'Attempt to handle closed trade: {trade}')
+            raise DependencyException(f"Attempt to handle closed trade: {trade}")
 
-        logger.debug('Handling %s ...', trade)
+        logger.debug("Handling %s ...", trade)
 
         (enter, exit_) = (False, False)
         exit_tag = None
         exit_signal_type = "exit_short" if trade.is_short else "exit_long"
 
-        if (self.config.get('use_exit_signal', True) or
-                self.config.get('ignore_roi_if_entry_signal', False)):
-            analyzed_df, _ = self.dataprovider.get_analyzed_dataframe(trade.pair,
-                                                                      self.strategy.timeframe)
+        if self.config.get("use_exit_signal", True) or self.config.get(
+            "ignore_roi_if_entry_signal", False
+        ):
+            analyzed_df, _ = self.dataprovider.get_analyzed_dataframe(
+                trade.pair, self.strategy.timeframe
+            )
 
             (enter, exit_, exit_tag) = self.strategy.get_exit_signal(
-                trade.pair,
-                self.strategy.timeframe,
-                analyzed_df,
-                is_short=trade.is_short
+                trade.pair, self.strategy.timeframe, analyzed_df, is_short=trade.is_short
             )
 
-        logger.debug('checking exit')
+        logger.debug("checking exit")
         exit_rate = self.exchange.get_rate(
-            trade.pair, side='exit', is_short=trade.is_short, refresh=True)
+            trade.pair, side="exit", is_short=trade.is_short, refresh=True
+        )
         if self._check_and_execute_exit(trade, exit_rate, enter, exit_, exit_tag):
             return True
 
-        logger.debug(f'Found no {exit_signal_type} signal for %s.', trade)
+        logger.debug(f"Found no {exit_signal_type} signal for %s.", trade)
         return False
 
-    def _check_and_execute_exit(self, trade: Trade, exit_rate: float,
-                                enter: bool, exit_: bool, exit_tag: Optional[str]) -> bool:
+    def _check_and_execute_exit(
+        self, trade: Trade, exit_rate: float, enter: bool, exit_: bool, exit_tag: Optional[str]
+    ) -> bool:
         """
         Check and execute trade exit
         """
         exits: List[ExitCheckTuple] = self.strategy.should_exit(
             trade,
             exit_rate,
             datetime.now(timezone.utc),
             enter=enter,
             exit_=exit_,
-            force_stoploss=self.edge.get_stoploss(trade.pair) if self.edge else 0
+            force_stoploss=self.edge.get_stoploss(trade.pair) if self.edge else 0,
         )
         for should_exit in exits:
             if should_exit.exit_flag:
                 exit_tag1 = exit_tag if should_exit.exit_type == ExitType.EXIT_SIGNAL else None
-                logger.info(f'Exit for {trade.pair} detected. Reason: {should_exit.exit_type}'
-                            f'{f" Tag: {exit_tag1}" if exit_tag1 is not None else ""}')
+                logger.info(
+                    f"Exit for {trade.pair} detected. Reason: {should_exit.exit_type}"
+                    f"{f' Tag: {exit_tag1}' if exit_tag1 is not None else ''}"
+                )
                 exited = self.execute_trade_exit(trade, exit_rate, should_exit, exit_tag=exit_tag1)
                 if exited:
                     return True
         return False
 
     def create_stoploss_order(self, trade: Trade, stop_price: float) -> bool:
         """
@@ -1207,63 +1351,66 @@
         try:
             stoploss_order = self.exchange.create_stoploss(
                 pair=trade.pair,
                 amount=trade.amount,
                 stop_price=stop_price,
                 order_types=self.strategy.order_types,
                 side=trade.exit_side,
-                leverage=trade.leverage
+                leverage=trade.leverage,
             )
 
-            order_obj = Order.parse_from_ccxt_object(stoploss_order, trade.pair, 'stoploss',
-                                                     trade.amount, stop_price)
+            order_obj = Order.parse_from_ccxt_object(
+                stoploss_order, trade.pair, "stoploss", trade.amount, stop_price
+            )
             trade.orders.append(order_obj)
             return True
         except InsufficientFundsError as e:
             logger.warning(f"Unable to place stoploss order {e}.")
             # Try to figure out what went wrong
             self.handle_insufficient_funds(trade)
 
         except InvalidOrderException as e:
-            logger.error(f'Unable to place a stoploss order on exchange. {e}')
-            logger.warning('Exiting the trade forcefully')
+            logger.error(f"Unable to place a stoploss order on exchange. {e}")
+            logger.warning("Exiting the trade forcefully")
             self.emergency_exit(trade, stop_price)
 
         except ExchangeError:
-            logger.exception('Unable to place a stoploss order on exchange.')
+            logger.exception("Unable to place a stoploss order on exchange.")
         return False
 
     def handle_stoploss_on_exchange(self, trade: Trade) -> bool:
         """
         Check if trade is fulfilled in which case the stoploss
         on exchange should be added immediately if stoploss on exchange
         is enabled.
         # TODO: liquidation price always on exchange, even without stoploss_on_exchange
         # Therefore fetching account liquidations for open pairs may make sense.
         """
 
-        logger.debug('Handling stoploss on exchange %s ...', trade)
+        logger.debug("Handling stoploss on exchange %s ...", trade)
 
         stoploss_orders = []
         for slo in trade.open_sl_orders:
             stoploss_order = None
             try:
                 # First we check if there is already a stoploss on exchange
-                stoploss_order = self.exchange.fetch_stoploss_order(
-                    slo.order_id, trade.pair) if slo.order_id else None
+                stoploss_order = (
+                    self.exchange.fetch_stoploss_order(slo.order_id, trade.pair)
+                    if slo.order_id
+                    else None
+                )
             except InvalidOrderException as exception:
-                logger.warning('Unable to fetch stoploss order: %s', exception)
+                logger.warning("Unable to fetch stoploss order: %s", exception)
 
             if stoploss_order:
                 stoploss_orders.append(stoploss_order)
-                self.update_trade_state(trade, slo.order_id, stoploss_order,
-                                        stoploss_order=True)
+                self.update_trade_state(trade, slo.order_id, stoploss_order, stoploss_order=True)
 
             # We check if stoploss order is fulfilled
-            if stoploss_order and stoploss_order['status'] in ('closed', 'triggered'):
+            if stoploss_order and stoploss_order["status"] in ("closed", "triggered"):
                 trade.exit_reason = ExitType.STOPLOSS_ON_EXCHANGE.value
                 self._notify_exit(trade, "stoploss", True)
                 self.handle_protections(trade.pair, trade.trade_direction)
                 return True
 
         if trade.has_open_orders or not trade.is_open:
             # Trade has an open order, Stoploss-handling can't happen in this case
@@ -1273,15 +1420,16 @@
 
         # If enter order is fulfilled but there is no stoploss, we add a stoploss on exchange
         if len(stoploss_orders) == 0:
             stop_price = trade.stoploss_or_liquidation
             if self.edge:
                 stoploss = self.edge.get_stoploss(pair=trade.pair)
                 stop_price = (
-                    trade.open_rate * (1 - stoploss) if trade.is_short
+                    trade.open_rate * (1 - stoploss)
+                    if trade.is_short
                     else trade.open_rate * (1 + stoploss)
                 )
 
             if self.create_stoploss_order(trade=trade, stop_price=stop_price):
                 # The above will return False if the placement failed and the trade was force-sold.
                 # in which case the trade will be closed - which we must check below.
                 return False
@@ -1295,66 +1443,77 @@
         Check to see if stoploss on exchange should be updated
         in case of trailing stoploss on exchange
         :param trade: Corresponding Trade
         :param order: Current on exchange stoploss order
         :return: None
         """
         stoploss_norm = self.exchange.price_to_precision(
-            trade.pair, trade.stoploss_or_liquidation,
-            rounding_mode=ROUND_DOWN if trade.is_short else ROUND_UP)
+            trade.pair,
+            trade.stoploss_or_liquidation,
+            rounding_mode=ROUND_DOWN if trade.is_short else ROUND_UP,
+        )
 
         if self.exchange.stoploss_adjust(stoploss_norm, order, side=trade.exit_side):
             # we check if the update is necessary
-            update_beat = self.strategy.order_types.get('stoploss_on_exchange_interval', 60)
+            update_beat = self.strategy.order_types.get("stoploss_on_exchange_interval", 60)
             upd_req = datetime.now(timezone.utc) - timedelta(seconds=update_beat)
             if trade.stoploss_last_update_utc and upd_req >= trade.stoploss_last_update_utc:
                 # cancelling the current stoploss on exchange first
-                logger.info(f"Cancelling current stoploss on exchange for pair {trade.pair} "
-                            f"(orderid:{order['id']}) in order to add another one ...")
+                logger.info(
+                    f"Cancelling current stoploss on exchange for pair {trade.pair} "
+                    f"(orderid:{order['id']}) in order to add another one ..."
+                )
 
                 self.cancel_stoploss_on_exchange(trade)
                 if not trade.is_open:
                     logger.warning(
-                        f"Trade {trade} is closed, not creating trailing stoploss order.")
+                        f"Trade {trade} is closed, not creating trailing stoploss order."
+                    )
                     return
 
                 # Create new stoploss order
                 if not self.create_stoploss_order(trade=trade, stop_price=stoploss_norm):
-                    logger.warning(f"Could not create trailing stoploss order "
-                                   f"for pair {trade.pair}.")
+                    logger.warning(
+                        f"Could not create trailing stoploss order for pair {trade.pair}."
+                    )
 
     def manage_trade_stoploss_orders(self, trade: Trade, stoploss_orders: List[Dict]):
         """
         Perform required actions according to existing stoploss orders of trade
         :param trade: Corresponding Trade
         :param stoploss_orders: Current on exchange stoploss orders
         :return: None
         """
         # If all stoploss ordered are canceled for some reason we add it again
-        canceled_sl_orders = [o for o in stoploss_orders
-                              if o['status'] in ('canceled', 'cancelled')]
+        canceled_sl_orders = [
+            o for o in stoploss_orders if o["status"] in ("canceled", "cancelled")
+        ]
         if (
-            trade.is_open and
-            len(stoploss_orders) > 0 and
-            len(stoploss_orders) == len(canceled_sl_orders)
+            trade.is_open
+            and len(stoploss_orders) > 0
+            and len(stoploss_orders) == len(canceled_sl_orders)
         ):
             if self.create_stoploss_order(trade=trade, stop_price=trade.stoploss_or_liquidation):
                 return False
             else:
-                logger.warning('All Stoploss orders are cancelled, but unable to recreate one.')
+                logger.warning("All Stoploss orders are cancelled, but unable to recreate one.")
 
         active_sl_orders = [o for o in stoploss_orders if o not in canceled_sl_orders]
         if len(active_sl_orders) > 0:
             last_active_sl_order = active_sl_orders[-1]
             # Finally we check if stoploss on exchange should be moved up because of trailing.
             # Triggered Orders are now real orders - so don't replace stoploss anymore
-            if (trade.is_open and
-                    last_active_sl_order.get('status_stop') != 'triggered' and
-                    (self.config.get('trailing_stop', False) or
-                     self.config.get('use_custom_stoploss', False))):
+            if (
+                trade.is_open
+                and last_active_sl_order.get("status_stop") != "triggered"
+                and (
+                    self.config.get("trailing_stop", False)
+                    or self.config.get("use_custom_stoploss", False)
+                )
+            ):
                 # if trailing stoploss is enabled we check if stoploss value has changed
                 # in which case we cancel stoploss order and put another one with new
                 # value immediately
                 self.handle_trailing_stoploss_on_exchange(trade, last_active_sl_order)
 
         return
 
@@ -1367,319 +1526,346 @@
         """
         for trade in Trade.get_open_trades():
             open_order: Order
             for open_order in trade.open_orders:
                 try:
                     order = self.exchange.fetch_order(open_order.order_id, trade.pair)
 
-                except (ExchangeError):
+                except ExchangeError:
                     logger.info(
-                        'Cannot query order for %s due to %s', trade, traceback.format_exc()
+                        "Cannot query order for %s due to %s", trade, traceback.format_exc()
                     )
                     continue
 
                 fully_cancelled = self.update_trade_state(trade, open_order.order_id, order)
-                not_closed = order['status'] == 'open' or fully_cancelled
+                not_closed = order["status"] == "open" or fully_cancelled
 
                 if not_closed:
-                    if (
-                        fully_cancelled or (
-                            open_order and self.strategy.ft_check_timed_out(
-                                trade, open_order, datetime.now(timezone.utc)
-                            )
+                    if fully_cancelled or (
+                        open_order
+                        and self.strategy.ft_check_timed_out(
+                            trade, open_order, datetime.now(timezone.utc)
                         )
                     ):
                         self.handle_cancel_order(
-                            order, open_order, trade, constants.CANCEL_REASON['TIMEOUT']
+                            order, open_order, trade, constants.CANCEL_REASON["TIMEOUT"]
                         )
                     else:
                         self.replace_order(order, open_order, trade)
 
     def handle_cancel_order(self, order: Dict, order_obj: Order, trade: Trade, reason: str) -> None:
         """
         Check if current analyzed order timed out and cancel if necessary.
         :param order: Order dict grabbed with exchange.fetch_order()
         :param order_obj: Order object from the database.
         :param trade: Trade object.
         :return: None
         """
-        if order['side'] == trade.entry_side:
+        if order["side"] == trade.entry_side:
             self.handle_cancel_enter(trade, order, order_obj, reason)
         else:
             canceled = self.handle_cancel_exit(trade, order, order_obj, reason)
             canceled_count = trade.get_canceled_exit_order_count()
-            max_timeouts = self.config.get('unfilledtimeout', {}).get('exit_timeout_count', 0)
-            if (canceled and max_timeouts > 0 and canceled_count >= max_timeouts):
-                logger.warning(f"Emergency exiting trade {trade}, as the exit order "
-                               f"timed out {max_timeouts} times. force selling {order['amount']}.")
-                self.emergency_exit(trade, order['price'], order['amount'])
+            max_timeouts = self.config.get("unfilledtimeout", {}).get("exit_timeout_count", 0)
+            if canceled and max_timeouts > 0 and canceled_count >= max_timeouts:
+                logger.warning(
+                    f"Emergency exiting trade {trade}, as the exit order "
+                    f"timed out {max_timeouts} times. force selling {order['amount']}."
+                )
+                self.emergency_exit(trade, order["price"], order["amount"])
 
     def emergency_exit(
-            self, trade: Trade, price: float, sub_trade_amt: Optional[float] = None) -> None:
+        self, trade: Trade, price: float, sub_trade_amt: Optional[float] = None
+    ) -> None:
         try:
             self.execute_trade_exit(
-                trade, price,
+                trade,
+                price,
                 exit_check=ExitCheckTuple(exit_type=ExitType.EMERGENCY_EXIT),
-                sub_trade_amt=sub_trade_amt
-                )
+                sub_trade_amt=sub_trade_amt,
+            )
         except DependencyException as exception:
-            logger.warning(
-                f'Unable to emergency exit trade {trade.pair}: {exception}')
+            logger.warning(f"Unable to emergency exit trade {trade.pair}: {exception}")
 
     def replace_order_failed(self, trade: Trade, msg: str) -> None:
         """
         Order replacement fail handling.
         Deletes the trade if necessary.
         :param trade: Trade object.
         :param msg: Error message.
         """
         logger.warning(msg)
         if trade.nr_of_successful_entries == 0:
             # this is the first entry and we didn't get filled yet, delete trade
             logger.warning(f"Removing {trade} from database.")
             self._notify_enter_cancel(
-                trade, order_type=self.strategy.order_types['entry'],
-                reason=constants.CANCEL_REASON['REPLACE_FAILED'])
+                trade,
+                order_type=self.strategy.order_types["entry"],
+                reason=constants.CANCEL_REASON["REPLACE_FAILED"],
+            )
             trade.delete()
 
     def replace_order(self, order: Dict, order_obj: Optional[Order], trade: Trade) -> None:
         """
         Check if current analyzed entry order should be replaced or simply cancelled.
         To simply cancel the existing order(no replacement) adjust_entry_price() should return None
         To maintain existing order adjust_entry_price() should return order_obj.price
         To replace existing order adjust_entry_price() should return desired price for limit order
         :param order: Order dict grabbed with exchange.fetch_order()
         :param order_obj: Order object.
         :param trade: Trade object.
         :return: None
         """
-        analyzed_df, _ = self.dataprovider.get_analyzed_dataframe(trade.pair,
-                                                                  self.strategy.timeframe)
-        latest_candle_open_date = analyzed_df.iloc[-1]['date'] if len(analyzed_df) > 0 else None
-        latest_candle_close_date = timeframe_to_next_date(self.strategy.timeframe,
-                                                          latest_candle_open_date)
+        analyzed_df, _ = self.dataprovider.get_analyzed_dataframe(
+            trade.pair, self.strategy.timeframe
+        )
+        latest_candle_open_date = analyzed_df.iloc[-1]["date"] if len(analyzed_df) > 0 else None
+        latest_candle_close_date = timeframe_to_next_date(
+            self.strategy.timeframe, latest_candle_open_date
+        )
         # Check if new candle
         if (
-            order_obj and order_obj.side == trade.entry_side
+            order_obj
+            and order_obj.side == trade.entry_side
             and latest_candle_close_date > order_obj.order_date_utc
         ):
             # New candle
             proposed_rate = self.exchange.get_rate(
-                trade.pair, side='entry', is_short=trade.is_short, refresh=True)
+                trade.pair, side="entry", is_short=trade.is_short, refresh=True
+            )
             adjusted_entry_price = strategy_safe_wrapper(
-                self.strategy.adjust_entry_price, default_retval=order_obj.safe_placement_price)(
-                trade=trade, order=order_obj, pair=trade.pair,
-                current_time=datetime.now(timezone.utc), proposed_rate=proposed_rate,
-                current_order_rate=order_obj.safe_placement_price, entry_tag=trade.enter_tag,
-                side=trade.trade_direction)
+                self.strategy.adjust_entry_price, default_retval=order_obj.safe_placement_price
+            )(
+                trade=trade,
+                order=order_obj,
+                pair=trade.pair,
+                current_time=datetime.now(timezone.utc),
+                proposed_rate=proposed_rate,
+                current_order_rate=order_obj.safe_placement_price,
+                entry_tag=trade.enter_tag,
+                side=trade.trade_direction,
+            )
 
             replacing = True
-            cancel_reason = constants.CANCEL_REASON['REPLACE']
+            cancel_reason = constants.CANCEL_REASON["REPLACE"]
             if not adjusted_entry_price:
                 replacing = False
-                cancel_reason = constants.CANCEL_REASON['USER_CANCEL']
+                cancel_reason = constants.CANCEL_REASON["USER_CANCEL"]
             if order_obj.safe_placement_price != adjusted_entry_price:
                 # cancel existing order if new price is supplied or None
-                res = self.handle_cancel_enter(trade, order, order_obj, cancel_reason,
-                                               replacing=replacing)
+                res = self.handle_cancel_enter(
+                    trade, order, order_obj, cancel_reason, replacing=replacing
+                )
                 if not res:
                     self.replace_order_failed(
-                        trade, f"Could not cancel order for {trade}, therefore not replacing.")
+                        trade, f"Could not cancel order for {trade}, therefore not replacing."
+                    )
                     return
                 if adjusted_entry_price:
                     # place new order only if new price is supplied
                     try:
                         if not self.execute_entry(
                             pair=trade.pair,
                             stake_amount=(
-                                order_obj.safe_remaining * order_obj.safe_price / trade.leverage),
+                                order_obj.safe_remaining * order_obj.safe_price / trade.leverage
+                            ),
                             price=adjusted_entry_price,
                             trade=trade,
                             is_short=trade.is_short,
-                            mode='replace',
+                            mode="replace",
                         ):
                             self.replace_order_failed(
-                                trade, f"Could not replace order for {trade}.")
+                                trade, f"Could not replace order for {trade}."
+                            )
                     except DependencyException as exception:
-                        logger.warning(
-                            f'Unable to replace order for {trade.pair}: {exception}')
+                        logger.warning(f"Unable to replace order for {trade.pair}: {exception}")
                         self.replace_order_failed(trade, f"Could not replace order for {trade}.")
 
     def cancel_all_open_orders(self) -> None:
         """
         Cancel all orders that are currently open
         :return: None
         """
 
         for trade in Trade.get_open_trades():
             for open_order in trade.open_orders:
                 try:
                     order = self.exchange.fetch_order(open_order.order_id, trade.pair)
-                except (ExchangeError):
+                except ExchangeError:
                     logger.info("Can't query order for %s due to %s", trade, traceback.format_exc())
                     continue
 
-                if order['side'] == trade.entry_side:
+                if order["side"] == trade.entry_side:
                     self.handle_cancel_enter(
-                        trade, order, open_order, constants.CANCEL_REASON['ALL_CANCELLED']
+                        trade, order, open_order, constants.CANCEL_REASON["ALL_CANCELLED"]
                     )
 
-                elif order['side'] == trade.exit_side:
+                elif order["side"] == trade.exit_side:
                     self.handle_cancel_exit(
-                        trade, order, open_order, constants.CANCEL_REASON['ALL_CANCELLED']
+                        trade, order, open_order, constants.CANCEL_REASON["ALL_CANCELLED"]
                     )
         Trade.commit()
 
     def handle_cancel_enter(
-            self, trade: Trade, order: Dict, order_obj: Order,
-            reason: str, replacing: Optional[bool] = False
+        self,
+        trade: Trade,
+        order: Dict,
+        order_obj: Order,
+        reason: str,
+        replacing: Optional[bool] = False,
     ) -> bool:
         """
         entry cancel - cancel order
         :param order_obj: Order object from the database.
         :param replacing: Replacing order - prevent trade deletion.
         :return: True if trade was fully cancelled
         """
         was_trade_fully_canceled = False
         order_id = order_obj.order_id
         side = trade.entry_side.capitalize()
 
-        if order['status'] not in constants.NON_OPEN_EXCHANGE_STATES:
-            filled_val: float = order.get('filled', 0.0) or 0.0
+        if order["status"] not in constants.NON_OPEN_EXCHANGE_STATES:
+            filled_val: float = order.get("filled", 0.0) or 0.0
             filled_stake = filled_val * trade.open_rate
             minstake = self.exchange.get_min_pair_stake_amount(
-                trade.pair, trade.open_rate, self.strategy.stoploss)
+                trade.pair, trade.open_rate, self.strategy.stoploss
+            )
 
             if filled_val > 0 and minstake and filled_stake < minstake:
                 logger.warning(
                     f"Order {order_id} for {trade.pair} not cancelled, "
-                    f"as the filled amount of {filled_val} would result in an unexitable trade.")
+                    f"as the filled amount of {filled_val} would result in an unexitable trade."
+                )
                 return False
             corder = self.exchange.cancel_order_with_result(order_id, trade.pair, trade.amount)
             order_obj.ft_cancel_reason = reason
             # if replacing, retry fetching the order 3 times if the status is not what we need
             if replacing:
                 retry_count = 0
                 while (
-                    corder.get('status') not in constants.NON_OPEN_EXCHANGE_STATES
+                    corder.get("status") not in constants.NON_OPEN_EXCHANGE_STATES
                     and retry_count < 3
                 ):
                     sleep(0.5)
                     corder = self.exchange.fetch_order(order_id, trade.pair)
                     retry_count += 1
 
             # Avoid race condition where the order could not be cancelled coz its already filled.
             # Simply bailing here is the only safe way - as this order will then be
             # handled in the next iteration.
-            if corder.get('status') not in constants.NON_OPEN_EXCHANGE_STATES:
+            if corder.get("status") not in constants.NON_OPEN_EXCHANGE_STATES:
                 logger.warning(f"Order {order_id} for {trade.pair} not cancelled.")
                 return False
         else:
             # Order was cancelled already, so we can reuse the existing dict
             corder = order
             if order_obj.ft_cancel_reason is None:
-                order_obj.ft_cancel_reason = constants.CANCEL_REASON['CANCELLED_ON_EXCHANGE']
+                order_obj.ft_cancel_reason = constants.CANCEL_REASON["CANCELLED_ON_EXCHANGE"]
 
-        logger.info(f'{side} order {order_obj.ft_cancel_reason} for {trade}.')
+        logger.info(f"{side} order {order_obj.ft_cancel_reason} for {trade}.")
 
         # Using filled to determine the filled amount
-        filled_amount = safe_value_fallback2(corder, order, 'filled', 'filled')
+        filled_amount = safe_value_fallback2(corder, order, "filled", "filled")
         if isclose(filled_amount, 0.0, abs_tol=constants.MATH_CLOSE_PREC):
             was_trade_fully_canceled = True
             # if trade is not partially completed and it's the only order, just delete the trade
-            open_order_count = len([
-                order for order in trade.orders if order.ft_is_open and order.order_id != order_id
-                ])
+            open_order_count = len(
+                [order for order in trade.orders if order.ft_is_open and order.order_id != order_id]
+            )
             if open_order_count < 1 and trade.nr_of_successful_entries == 0 and not replacing:
-                logger.info(f'{side} order fully cancelled. Removing {trade} from database.')
+                logger.info(f"{side} order fully cancelled. Removing {trade} from database.")
                 trade.delete()
                 order_obj.ft_cancel_reason += f", {constants.CANCEL_REASON['FULLY_CANCELLED']}"
             else:
                 self.update_trade_state(trade, order_id, corder)
-                logger.info(f'{side} Order timeout for {trade}.')
+                logger.info(f"{side} Order timeout for {trade}.")
         else:
             # update_trade_state (and subsequently recalc_trade_from_orders) will handle updates
             # to the trade object
             self.update_trade_state(trade, order_id, corder)
 
-            logger.info(f'Partial {trade.entry_side} order timeout for {trade}.')
+            logger.info(f"Partial {trade.entry_side} order timeout for {trade}.")
             order_obj.ft_cancel_reason += f", {constants.CANCEL_REASON['PARTIALLY_FILLED']}"
 
         self.wallets.update()
-        self._notify_enter_cancel(trade, order_type=self.strategy.order_types['entry'],
-                                  reason=order_obj.ft_cancel_reason)
+        self._notify_enter_cancel(
+            trade, order_type=self.strategy.order_types["entry"], reason=order_obj.ft_cancel_reason
+        )
         return was_trade_fully_canceled
 
-    def handle_cancel_exit(
-        self, trade: Trade, order: Dict, order_obj: Order, reason: str
-    ) -> bool:
+    def handle_cancel_exit(self, trade: Trade, order: Dict, order_obj: Order, reason: str) -> bool:
         """
         exit order cancel - cancel order and update trade
         :return: True if exit order was cancelled, false otherwise
         """
         order_id = order_obj.order_id
         cancelled = False
         # Cancelled orders may have the status of 'canceled' or 'closed'
-        if order['status'] not in constants.NON_OPEN_EXCHANGE_STATES:
-            filled_amt: float = order.get('filled', 0.0) or 0.0
+        if order["status"] not in constants.NON_OPEN_EXCHANGE_STATES:
+            filled_amt: float = order.get("filled", 0.0) or 0.0
             # Filled val is in quote currency (after leverage)
             filled_rem_stake = trade.stake_amount - (filled_amt * trade.open_rate / trade.leverage)
             minstake = self.exchange.get_min_pair_stake_amount(
-                trade.pair, trade.open_rate, self.strategy.stoploss)
+                trade.pair, trade.open_rate, self.strategy.stoploss
+            )
             # Double-check remaining amount
             if filled_amt > 0:
-                reason = constants.CANCEL_REASON['PARTIALLY_FILLED']
+                reason = constants.CANCEL_REASON["PARTIALLY_FILLED"]
                 if minstake and filled_rem_stake < minstake:
                     logger.warning(
                         f"Order {order_id} for {trade.pair} not cancelled, as "
-                        f"the filled amount of {filled_amt} would result in an unexitable trade.")
-                    reason = constants.CANCEL_REASON['PARTIALLY_FILLED_KEEP_OPEN']
+                        f"the filled amount of {filled_amt} would result in an unexitable trade."
+                    )
+                    reason = constants.CANCEL_REASON["PARTIALLY_FILLED_KEEP_OPEN"]
 
                     self._notify_exit_cancel(
                         trade,
-                        order_type=self.strategy.order_types['exit'],
-                        reason=reason, order_id=order['id'],
-                        sub_trade=trade.amount != order['amount']
+                        order_type=self.strategy.order_types["exit"],
+                        reason=reason,
+                        order_id=order["id"],
+                        sub_trade=trade.amount != order["amount"],
                     )
                     return False
             order_obj.ft_cancel_reason = reason
             try:
                 order = self.exchange.cancel_order_with_result(
-                    order['id'], trade.pair, trade.amount)
+                    order["id"], trade.pair, trade.amount
+                )
             except InvalidOrderException:
-                logger.exception(
-                    f"Could not cancel {trade.exit_side} order {order_id}")
+                logger.exception(f"Could not cancel {trade.exit_side} order {order_id}")
                 return False
 
             # Set exit_reason for fill message
             exit_reason_prev = trade.exit_reason
             trade.exit_reason = trade.exit_reason + f", {reason}" if trade.exit_reason else reason
             # Order might be filled above in odd timing issues.
-            if order.get('status') in ('canceled', 'cancelled'):
+            if order.get("status") in ("canceled", "cancelled"):
                 trade.exit_reason = None
             else:
                 trade.exit_reason = exit_reason_prev
             cancelled = True
         else:
             if order_obj.ft_cancel_reason is None:
-                order_obj.ft_cancel_reason = constants.CANCEL_REASON['CANCELLED_ON_EXCHANGE']
+                order_obj.ft_cancel_reason = constants.CANCEL_REASON["CANCELLED_ON_EXCHANGE"]
             trade.exit_reason = None
 
-        self.update_trade_state(trade, order['id'], order)
+        self.update_trade_state(trade, order["id"], order)
 
         logger.info(
-            f'{trade.exit_side.capitalize()} order {order_obj.ft_cancel_reason} for {trade}.')
+            f"{trade.exit_side.capitalize()} order {order_obj.ft_cancel_reason} for {trade}."
+        )
         trade.close_rate = None
         trade.close_rate_requested = None
 
         self._notify_exit_cancel(
             trade,
-            order_type=self.strategy.order_types['exit'],
-            reason=order_obj.ft_cancel_reason, order_id=order['id'],
-            sub_trade=trade.amount != order['amount']
+            order_type=self.strategy.order_types["exit"],
+            reason=order_obj.ft_cancel_reason,
+            order_id=order["id"],
+            sub_trade=trade.amount != order["amount"],
         )
         return cancelled
 
     def _safe_exit_amount(self, trade: Trade, pair: str, amount: float) -> float:
         """
         Get sellable amount.
         Should be trade.amount - but will fall back to the available amount if necessary.
@@ -1704,259 +1890,292 @@
             return amount
         elif wallet_amount > amount * 0.98:
             logger.info(f"{pair} - Falling back to wallet-amount {wallet_amount} -> {amount}.")
             trade.amount = wallet_amount
             return wallet_amount
         else:
             raise DependencyException(
-                f"Not enough amount to exit trade. Trade-amount: {amount}, Wallet: {wallet_amount}")
+                f"Not enough amount to exit trade. Trade-amount: {amount}, Wallet: {wallet_amount}"
+            )
 
     def execute_trade_exit(
-            self,
-            trade: Trade,
-            limit: float,
-            exit_check: ExitCheckTuple,
-            *,
-            exit_tag: Optional[str] = None,
-            ordertype: Optional[str] = None,
-            sub_trade_amt: Optional[float] = None,
+        self,
+        trade: Trade,
+        limit: float,
+        exit_check: ExitCheckTuple,
+        *,
+        exit_tag: Optional[str] = None,
+        ordertype: Optional[str] = None,
+        sub_trade_amt: Optional[float] = None,
     ) -> bool:
         """
         Executes a trade exit for the given trade and limit
         :param trade: Trade instance
         :param limit: limit rate for the sell order
         :param exit_check: CheckTuple with signal and reason
         :return: True if it succeeds False
         """
         trade.set_funding_fees(
             self.exchange.get_funding_fees(
                 pair=trade.pair,
                 amount=trade.amount,
                 is_short=trade.is_short,
-                open_date=trade.date_last_filled_utc)
+                open_date=trade.date_last_filled_utc,
+            )
         )
 
-        exit_type = 'exit'
+        exit_type = "exit"
         exit_reason = exit_tag or exit_check.exit_reason
         if exit_check.exit_type in (
-                ExitType.STOP_LOSS, ExitType.TRAILING_STOP_LOSS, ExitType.LIQUIDATION):
-            exit_type = 'stoploss'
+            ExitType.STOP_LOSS,
+            ExitType.TRAILING_STOP_LOSS,
+            ExitType.LIQUIDATION,
+        ):
+            exit_type = "stoploss"
 
         # set custom_exit_price if available
         proposed_limit_rate = limit
         current_profit = trade.calc_profit_ratio(limit)
-        custom_exit_price = strategy_safe_wrapper(self.strategy.custom_exit_price,
-                                                  default_retval=proposed_limit_rate)(
-            pair=trade.pair, trade=trade,
+        custom_exit_price = strategy_safe_wrapper(
+            self.strategy.custom_exit_price, default_retval=proposed_limit_rate
+        )(
+            pair=trade.pair,
+            trade=trade,
             current_time=datetime.now(timezone.utc),
-            proposed_rate=proposed_limit_rate, current_profit=current_profit,
-            exit_tag=exit_reason)
+            proposed_rate=proposed_limit_rate,
+            current_profit=current_profit,
+            exit_tag=exit_reason,
+        )
 
         limit = self.get_valid_price(custom_exit_price, proposed_limit_rate)
 
         # First cancelling stoploss on exchange ...
         trade = self.cancel_stoploss_on_exchange(trade)
 
         order_type = ordertype or self.strategy.order_types[exit_type]
         if exit_check.exit_type == ExitType.EMERGENCY_EXIT:
             # Emergency sells (default to market!)
             order_type = self.strategy.order_types.get("emergency_exit", "market")
 
         amount = self._safe_exit_amount(trade, trade.pair, sub_trade_amt or trade.amount)
-        time_in_force = self.strategy.order_time_in_force['exit']
+        time_in_force = self.strategy.order_time_in_force["exit"]
 
-        if (exit_check.exit_type != ExitType.LIQUIDATION
-                and not sub_trade_amt
-                and not strategy_safe_wrapper(
-                    self.strategy.confirm_trade_exit, default_retval=True)(
-                    pair=trade.pair, trade=trade, order_type=order_type, amount=amount, rate=limit,
-                    time_in_force=time_in_force, exit_reason=exit_reason,
-                    sell_reason=exit_reason,  # sellreason -> compatibility
-                    current_time=datetime.now(timezone.utc))):
+        if (
+            exit_check.exit_type != ExitType.LIQUIDATION
+            and not sub_trade_amt
+            and not strategy_safe_wrapper(self.strategy.confirm_trade_exit, default_retval=True)(
+                pair=trade.pair,
+                trade=trade,
+                order_type=order_type,
+                amount=amount,
+                rate=limit,
+                time_in_force=time_in_force,
+                exit_reason=exit_reason,
+                sell_reason=exit_reason,  # sellreason -> compatibility
+                current_time=datetime.now(timezone.utc),
+            )
+        ):
             logger.info(f"User denied exit for {trade.pair}.")
             return False
 
         try:
             # Execute sell and update trade record
             order = self.exchange.create_order(
                 pair=trade.pair,
                 ordertype=order_type,
                 side=trade.exit_side,
                 amount=amount,
                 rate=limit,
                 leverage=trade.leverage,
                 reduceOnly=self.trading_mode == TradingMode.FUTURES,
-                time_in_force=time_in_force
+                time_in_force=time_in_force,
             )
         except InsufficientFundsError as e:
             logger.warning(f"Unable to place order {e}.")
             # Try to figure out what went wrong
             self.handle_insufficient_funds(trade)
             return False
 
         order_obj = Order.parse_from_ccxt_object(order, trade.pair, trade.exit_side, amount, limit)
         order_obj.ft_order_tag = exit_reason
         trade.orders.append(order_obj)
 
-        trade.exit_order_status = ''
+        trade.exit_order_status = ""
         trade.close_rate_requested = limit
         trade.exit_reason = exit_reason
 
         self._notify_exit(trade, order_type, sub_trade=bool(sub_trade_amt), order=order_obj)
         # In case of market sell orders the order can be closed immediately
-        if order.get('status', 'unknown') in ('closed', 'expired'):
+        if order.get("status", "unknown") in ("closed", "expired"):
             self.update_trade_state(trade, order_obj.order_id, order)
         Trade.commit()
 
         return True
 
-    def _notify_exit(self, trade: Trade, order_type: Optional[str], fill: bool = False,
-                     sub_trade: bool = False, order: Optional[Order] = None) -> None:
+    def _notify_exit(
+        self,
+        trade: Trade,
+        order_type: Optional[str],
+        fill: bool = False,
+        sub_trade: bool = False,
+        order: Optional[Order] = None,
+    ) -> None:
         """
         Sends rpc notification when a sell occurred.
         """
         # Use cached rates here - it was updated seconds ago.
-        current_rate = self.exchange.get_rate(
-            trade.pair, side='exit', is_short=trade.is_short, refresh=False) if not fill else None
+        current_rate = (
+            self.exchange.get_rate(trade.pair, side="exit", is_short=trade.is_short, refresh=False)
+            if not fill
+            else None
+        )
 
         # second condition is for mypy only; order will always be passed during sub trade
         if sub_trade and order is not None:
             amount = order.safe_filled if fill else order.safe_amount
             order_rate: float = order.safe_price
 
             profit = trade.calculate_profit(order_rate, amount, trade.open_rate)
         else:
             order_rate = trade.safe_close_rate
             profit = trade.calculate_profit(rate=order_rate)
             amount = trade.amount
         gain: ProfitLossStr = "profit" if profit.profit_ratio > 0 else "loss"
 
         msg: RPCExitMsg = {
-            'type': (RPCMessageType.EXIT_FILL if fill
-                     else RPCMessageType.EXIT),
-            'trade_id': trade.id,
-            'exchange': trade.exchange.capitalize(),
-            'pair': trade.pair,
-            'leverage': trade.leverage,
-            'direction': 'Short' if trade.is_short else 'Long',
-            'gain': gain,
-            'limit': order_rate,  # Deprecated
-            'order_rate': order_rate,
-            'order_type': order_type or 'unknown',
-            'amount': amount,
-            'open_rate': trade.open_rate,
-            'close_rate': order_rate,
-            'current_rate': current_rate,
-            'profit_amount': profit.profit_abs,
-            'profit_ratio': profit.profit_ratio,
-            'buy_tag': trade.enter_tag,
-            'enter_tag': trade.enter_tag,
-            'exit_reason': trade.exit_reason,
-            'open_date': trade.open_date_utc,
-            'close_date': trade.close_date_utc or datetime.now(timezone.utc),
-            'stake_amount': trade.stake_amount,
-            'stake_currency': self.config['stake_currency'],
-            'base_currency': self.exchange.get_pair_base_currency(trade.pair),
-            'quote_currency': self.exchange.get_pair_quote_currency(trade.pair),
-            'fiat_currency': self.config.get('fiat_display_currency'),
-            'sub_trade': sub_trade,
-            'cumulative_profit': trade.realized_profit,
-            'final_profit_ratio': trade.close_profit if not trade.is_open else None,
-            'is_final_exit': trade.is_open is False,
+            "type": (RPCMessageType.EXIT_FILL if fill else RPCMessageType.EXIT),
+            "trade_id": trade.id,
+            "exchange": trade.exchange.capitalize(),
+            "pair": trade.pair,
+            "leverage": trade.leverage,
+            "direction": "Short" if trade.is_short else "Long",
+            "gain": gain,
+            "limit": order_rate,  # Deprecated
+            "order_rate": order_rate,
+            "order_type": order_type or "unknown",
+            "amount": amount,
+            "open_rate": trade.open_rate,
+            "close_rate": order_rate,
+            "current_rate": current_rate,
+            "profit_amount": profit.profit_abs,
+            "profit_ratio": profit.profit_ratio,
+            "buy_tag": trade.enter_tag,
+            "enter_tag": trade.enter_tag,
+            "exit_reason": trade.exit_reason,
+            "open_date": trade.open_date_utc,
+            "close_date": trade.close_date_utc or datetime.now(timezone.utc),
+            "stake_amount": trade.stake_amount,
+            "stake_currency": self.config["stake_currency"],
+            "base_currency": self.exchange.get_pair_base_currency(trade.pair),
+            "quote_currency": self.exchange.get_pair_quote_currency(trade.pair),
+            "fiat_currency": self.config.get("fiat_display_currency"),
+            "sub_trade": sub_trade,
+            "cumulative_profit": trade.realized_profit,
+            "final_profit_ratio": trade.close_profit if not trade.is_open else None,
+            "is_final_exit": trade.is_open is False,
         }
 
         # Send the message
         self.rpc.send_msg(msg)
 
-    def _notify_exit_cancel(self, trade: Trade, order_type: str, reason: str,
-                            order_id: str, sub_trade: bool = False) -> None:
+    def _notify_exit_cancel(
+        self, trade: Trade, order_type: str, reason: str, order_id: str, sub_trade: bool = False
+    ) -> None:
         """
         Sends rpc notification when a sell cancel occurred.
         """
         if trade.exit_order_status == reason:
             return
         else:
             trade.exit_order_status = reason
 
         order_or_none = trade.select_order_by_order_id(order_id)
         order = self.order_obj_or_raise(order_id, order_or_none)
 
         profit_rate: float = trade.safe_close_rate
         profit = trade.calculate_profit(rate=profit_rate)
         current_rate = self.exchange.get_rate(
-            trade.pair, side='exit', is_short=trade.is_short, refresh=False)
+            trade.pair, side="exit", is_short=trade.is_short, refresh=False
+        )
         gain: ProfitLossStr = "profit" if profit.profit_ratio > 0 else "loss"
 
         msg: RPCExitCancelMsg = {
-            'type': RPCMessageType.EXIT_CANCEL,
-            'trade_id': trade.id,
-            'exchange': trade.exchange.capitalize(),
-            'pair': trade.pair,
-            'leverage': trade.leverage,
-            'direction': 'Short' if trade.is_short else 'Long',
-            'gain': gain,
-            'limit': profit_rate or 0,
-            'order_type': order_type,
-            'amount': order.safe_amount_after_fee,
-            'open_rate': trade.open_rate,
-            'current_rate': current_rate,
-            'profit_amount': profit.profit_abs,
-            'profit_ratio': profit.profit_ratio,
-            'buy_tag': trade.enter_tag,
-            'enter_tag': trade.enter_tag,
-            'exit_reason': trade.exit_reason,
-            'open_date': trade.open_date,
-            'close_date': trade.close_date or datetime.now(timezone.utc),
-            'stake_currency': self.config['stake_currency'],
-            'base_currency': self.exchange.get_pair_base_currency(trade.pair),
-            'quote_currency': self.exchange.get_pair_quote_currency(trade.pair),
-            'fiat_currency': self.config.get('fiat_display_currency', None),
-            'reason': reason,
-            'sub_trade': sub_trade,
-            'stake_amount': trade.stake_amount,
+            "type": RPCMessageType.EXIT_CANCEL,
+            "trade_id": trade.id,
+            "exchange": trade.exchange.capitalize(),
+            "pair": trade.pair,
+            "leverage": trade.leverage,
+            "direction": "Short" if trade.is_short else "Long",
+            "gain": gain,
+            "limit": profit_rate or 0,
+            "order_type": order_type,
+            "amount": order.safe_amount_after_fee,
+            "open_rate": trade.open_rate,
+            "current_rate": current_rate,
+            "profit_amount": profit.profit_abs,
+            "profit_ratio": profit.profit_ratio,
+            "buy_tag": trade.enter_tag,
+            "enter_tag": trade.enter_tag,
+            "exit_reason": trade.exit_reason,
+            "open_date": trade.open_date,
+            "close_date": trade.close_date or datetime.now(timezone.utc),
+            "stake_currency": self.config["stake_currency"],
+            "base_currency": self.exchange.get_pair_base_currency(trade.pair),
+            "quote_currency": self.exchange.get_pair_quote_currency(trade.pair),
+            "fiat_currency": self.config.get("fiat_display_currency", None),
+            "reason": reason,
+            "sub_trade": sub_trade,
+            "stake_amount": trade.stake_amount,
         }
 
         # Send the message
         self.rpc.send_msg(msg)
 
     def order_obj_or_raise(self, order_id: str, order_obj: Optional[Order]) -> Order:
         if not order_obj:
             raise DependencyException(
-                f"Order_obj not found for {order_id}. This should not have happened.")
+                f"Order_obj not found for {order_id}. This should not have happened."
+            )
         return order_obj
 
-#
-# Common update trade state methods
-#
+    #
+    # Common update trade state methods
+    #
 
     def update_trade_state(
-            self, trade: Trade, order_id: Optional[str],
-            action_order: Optional[Dict[str, Any]] = None, *,
-            stoploss_order: bool = False, send_msg: bool = True) -> bool:
+        self,
+        trade: Trade,
+        order_id: Optional[str],
+        action_order: Optional[Dict[str, Any]] = None,
+        *,
+        stoploss_order: bool = False,
+        send_msg: bool = True,
+    ) -> bool:
         """
         Checks trades with open orders and updates the amount if necessary
         Handles closing both buy and sell orders.
         :param trade: Trade object of the trade we're analyzing
         :param order_id: Order-id of the order we're analyzing
         :param action_order: Already acquired order object
         :param send_msg: Send notification - should always be True except in "recovery" methods
         :return: True if order has been cancelled without being filled partially, False otherwise
         """
         if not order_id:
-            logger.warning(f'Orderid for trade {trade} is empty.')
+            logger.warning(f"Orderid for trade {trade} is empty.")
             return False
 
         # Update trade with order values
         if not stoploss_order:
-            logger.info(f'Found open order for {trade}')
+            logger.info(f"Found open order for {trade}")
         try:
             order = action_order or self.exchange.fetch_order_or_stoploss_order(
-                order_id, trade.pair, stoploss_order)
+                order_id, trade.pair, stoploss_order
+            )
         except InvalidOrderException as exception:
-            logger.warning('Unable to fetch order %s: %s', order_id, exception)
+            logger.warning("Unable to fetch order %s: %s", order_id, exception)
             return False
 
         trade.update_order(order)
 
         if self.exchange.check_order_canceled_empty(order):
             # Trade has been cancelled on exchange
             # Handling of this will happen in handle_cancel_order.
@@ -1974,114 +2193,125 @@
 
         self.order_close_notify(trade, order_obj, stoploss_order, send_msg)
 
         return False
 
     def _update_trade_after_fill(self, trade: Trade, order: Order, send_msg: bool) -> Trade:
         if order.status in constants.NON_OPEN_EXCHANGE_STATES:
-            strategy_safe_wrapper(
-                self.strategy.order_filled, default_retval=None)(
-                pair=trade.pair, trade=trade, order=order, current_time=datetime.now(timezone.utc))
+            strategy_safe_wrapper(self.strategy.order_filled, default_retval=None)(
+                pair=trade.pair, trade=trade, order=order, current_time=datetime.now(timezone.utc)
+            )
             # If a entry order was closed, force update on stoploss on exchange
             if order.ft_order_side == trade.entry_side:
                 if send_msg:
                     # Don't cancel stoploss in recovery modes immediately
                     trade = self.cancel_stoploss_on_exchange(trade)
                 if not self.edge:
                     # TODO: should shorting/leverage be supported by Edge,
                     # then this will need to be fixed.
                     trade.adjust_stop_loss(trade.open_rate, self.strategy.stoploss, initial=True)
             if order.ft_order_side == trade.entry_side or (trade.amount > 0 and trade.is_open):
                 # Must also run for partial exits
                 # TODO: Margin will need to use interest_rate as well.
                 # interest_rate = self.exchange.get_interest_rate()
                 try:
-                    trade.set_liquidation_price(self.exchange.get_liquidation_price(
-                        pair=trade.pair,
-                        open_rate=trade.open_rate,
-                        is_short=trade.is_short,
-                        amount=trade.amount,
-                        stake_amount=trade.stake_amount,
-                        leverage=trade.leverage,
-                        wallet_balance=trade.stake_amount,
-                    ))
+                    trade.set_liquidation_price(
+                        self.exchange.get_liquidation_price(
+                            pair=trade.pair,
+                            open_rate=trade.open_rate,
+                            is_short=trade.is_short,
+                            amount=trade.amount,
+                            stake_amount=trade.stake_amount,
+                            leverage=trade.leverage,
+                            wallet_balance=trade.stake_amount,
+                        )
+                    )
                 except DependencyException:
-                    logger.warning('Unable to calculate liquidation price')
+                    logger.warning("Unable to calculate liquidation price")
                 if self.strategy.use_custom_stoploss:
                     current_rate = self.exchange.get_rate(
-                        trade.pair, side='exit', is_short=trade.is_short, refresh=True)
+                        trade.pair, side="exit", is_short=trade.is_short, refresh=True
+                    )
                     profit = trade.calc_profit_ratio(current_rate)
-                    self.strategy.ft_stoploss_adjust(current_rate, trade,
-                                                     datetime.now(timezone.utc), profit, 0,
-                                                     after_fill=True)
+                    self.strategy.ft_stoploss_adjust(
+                        current_rate, trade, datetime.now(timezone.utc), profit, 0, after_fill=True
+                    )
             # Updating wallets when order is closed
             self.wallets.update()
         return trade
 
-    def order_close_notify(
-            self, trade: Trade, order: Order, stoploss_order: bool, send_msg: bool):
+    def order_close_notify(self, trade: Trade, order: Order, stoploss_order: bool, send_msg: bool):
         """send "fill" notifications"""
 
         if order.ft_order_side == trade.exit_side:
             # Exit notification
             if send_msg and not stoploss_order and order.order_id not in trade.open_orders_ids:
-                self._notify_exit(trade, order.order_type, fill=True,
-                                  sub_trade=trade.is_open, order=order)
+                self._notify_exit(
+                    trade, order.order_type, fill=True, sub_trade=trade.is_open, order=order
+                )
             if not trade.is_open:
                 self.handle_protections(trade.pair, trade.trade_direction)
         elif send_msg and order.order_id not in trade.open_orders_ids and not stoploss_order:
-            sub_trade = not isclose(order.safe_amount_after_fee,
-                                    trade.amount, abs_tol=constants.MATH_CLOSE_PREC)
+            sub_trade = not isclose(
+                order.safe_amount_after_fee, trade.amount, abs_tol=constants.MATH_CLOSE_PREC
+            )
             # Enter fill
             self._notify_enter(trade, order, order.order_type, fill=True, sub_trade=sub_trade)
 
     def handle_protections(self, pair: str, side: LongShort) -> None:
         # Lock pair for one candle to prevent immediate re-entries
-        self.strategy.lock_pair(pair, datetime.now(timezone.utc), reason='Auto lock')
+        self.strategy.lock_pair(pair, datetime.now(timezone.utc), reason="Auto lock")
         prot_trig = self.protections.stop_per_pair(pair, side=side)
         if prot_trig:
             msg: RPCProtectionMsg = {
-                'type': RPCMessageType.PROTECTION_TRIGGER,
-                'base_currency': self.exchange.get_pair_base_currency(prot_trig.pair),
-                **prot_trig.to_json()  # type: ignore
+                "type": RPCMessageType.PROTECTION_TRIGGER,
+                "base_currency": self.exchange.get_pair_base_currency(prot_trig.pair),
+                **prot_trig.to_json(),  # type: ignore
             }
             self.rpc.send_msg(msg)
 
         prot_trig_glb = self.protections.global_stop(side=side)
         if prot_trig_glb:
             msg = {
-                'type': RPCMessageType.PROTECTION_TRIGGER_GLOBAL,
-                'base_currency': self.exchange.get_pair_base_currency(prot_trig_glb.pair),
-                **prot_trig_glb.to_json()  # type: ignore
+                "type": RPCMessageType.PROTECTION_TRIGGER_GLOBAL,
+                "base_currency": self.exchange.get_pair_base_currency(prot_trig_glb.pair),
+                **prot_trig_glb.to_json(),  # type: ignore
             }
             self.rpc.send_msg(msg)
 
-    def apply_fee_conditional(self, trade: Trade, trade_base_currency: str,
-                              amount: float, fee_abs: float, order_obj: Order) -> Optional[float]:
+    def apply_fee_conditional(
+        self,
+        trade: Trade,
+        trade_base_currency: str,
+        amount: float,
+        fee_abs: float,
+        order_obj: Order,
+    ) -> Optional[float]:
         """
         Applies the fee to amount (either from Order or from Trades).
         Can eat into dust if more than the required asset is available.
         In case of trade adjustment orders, trade.amount will not have been adjusted yet.
         Can't happen in Futures mode - where Fees are always in settlement currency,
         never in base currency.
         """
         self.wallets.update()
         amount_ = trade.amount
-        if order_obj.ft_order_side == trade.exit_side or order_obj.ft_order_side == 'stoploss':
+        if order_obj.ft_order_side == trade.exit_side or order_obj.ft_order_side == "stoploss":
             # check against remaining amount!
             amount_ = trade.amount - amount
 
         if trade.nr_of_successful_entries >= 1 and order_obj.ft_order_side == trade.entry_side:
             # In case of re-entry's, trade.amount doesn't contain the amount of the last entry.
             amount_ = trade.amount + amount
 
         if fee_abs != 0 and self.wallets.get_free(trade_base_currency) >= amount_:
             # Eat into dust if we own more than base currency
-            logger.info(f"Fee amount for {trade} was in base currency - "
-                        f"Eating Fee {fee_abs} into dust.")
+            logger.info(
+                f"Fee amount for {trade} was in base currency - Eating Fee {fee_abs} into dust."
+            )
         elif fee_abs != 0:
             logger.info(f"Applying fee on amount for {trade}, fee={fee_abs}.")
             return fee_abs
         return None
 
     def handle_order_fee(self, trade: Trade, order_obj: Order, order: Dict[str, Any]) -> None:
         # Try update amount (binance-fix)
@@ -2097,100 +2327,111 @@
         Detect and update trade fee.
         Calls trade.update_fee() upon correct detection.
         Returns modified amount if the fee was taken from the destination currency.
         Necessary for exchanges which charge fees in base currency (e.g. binance)
         :return: Absolute fee to apply for this order or None
         """
         # Init variables
-        order_amount = safe_value_fallback(order, 'filled', 'amount')
+        order_amount = safe_value_fallback(order, "filled", "amount")
         # Only run for closed orders
         if (
-            trade.fee_updated(order.get('side', ''))
-            or order['status'] == 'open'
+            trade.fee_updated(order.get("side", ""))
+            or order["status"] == "open"
             or order_obj.ft_fee_base
         ):
             return None
 
         trade_base_currency = self.exchange.get_pair_base_currency(trade.pair)
         # use fee from order-dict if possible
         if self.exchange.order_has_fee(order):
             fee_cost, fee_currency, fee_rate = self.exchange.extract_cost_curr_rate(
-                order['fee'], order['symbol'], order['cost'], order_obj.safe_filled)
-            logger.info(f"Fee for Trade {trade} [{order_obj.ft_order_side}]: "
-                        f"{fee_cost:.8g} {fee_currency} - rate: {fee_rate}")
+                order["fee"], order["symbol"], order["cost"], order_obj.safe_filled
+            )
+            logger.info(
+                f"Fee for Trade {trade} [{order_obj.ft_order_side}]: "
+                f"{fee_cost:.8g} {fee_currency} - rate: {fee_rate}"
+            )
             if fee_rate is None or fee_rate < 0.02:
                 # Reject all fees that report as > 2%.
                 # These are most likely caused by a parsing bug in ccxt
                 # due to multiple trades (https://github.com/ccxt/ccxt/issues/8025)
-                trade.update_fee(fee_cost, fee_currency, fee_rate, order.get('side', ''))
+                trade.update_fee(fee_cost, fee_currency, fee_rate, order.get("side", ""))
                 if trade_base_currency == fee_currency:
                     # Apply fee to amount
-                    return self.apply_fee_conditional(trade, trade_base_currency,
-                                                      amount=order_amount, fee_abs=fee_cost,
-                                                      order_obj=order_obj)
+                    return self.apply_fee_conditional(
+                        trade,
+                        trade_base_currency,
+                        amount=order_amount,
+                        fee_abs=fee_cost,
+                        order_obj=order_obj,
+                    )
                 return None
         return self.fee_detection_from_trades(
-            trade, order, order_obj, order_amount, order.get('trades', []))
+            trade, order, order_obj, order_amount, order.get("trades", [])
+        )
 
-    def fee_detection_from_trades(self, trade: Trade, order: Dict, order_obj: Order,
-                                  order_amount: float, trades: List) -> Optional[float]:
+    def fee_detection_from_trades(
+        self, trade: Trade, order: Dict, order_obj: Order, order_amount: float, trades: List
+    ) -> Optional[float]:
         """
         fee-detection fallback to Trades.
         Either uses provided trades list or the result of fetch_my_trades to get correct fee.
         """
         if not trades:
             trades = self.exchange.get_trades_for_order(
-                self.exchange.get_order_id_conditional(order), trade.pair, order_obj.order_date)
+                self.exchange.get_order_id_conditional(order), trade.pair, order_obj.order_date
+            )
 
         if len(trades) == 0:
             logger.info("Applying fee on amount for %s failed: myTrade-Dict empty found", trade)
             return None
         fee_currency = None
         amount = 0
         fee_abs = 0.0
         fee_cost = 0.0
         trade_base_currency = self.exchange.get_pair_base_currency(trade.pair)
         fee_rate_array: List[float] = []
         for exectrade in trades:
-            amount += exectrade['amount']
+            amount += exectrade["amount"]
             if self.exchange.order_has_fee(exectrade):
                 # Prefer singular fee
-                fees = [exectrade['fee']]
+                fees = [exectrade["fee"]]
             else:
-                fees = exectrade.get('fees', [])
+                fees = exectrade.get("fees", [])
             for fee in fees:
-
                 fee_cost_, fee_currency, fee_rate_ = self.exchange.extract_cost_curr_rate(
-                    fee, exectrade['symbol'], exectrade['cost'], exectrade['amount']
+                    fee, exectrade["symbol"], exectrade["cost"], exectrade["amount"]
                 )
                 fee_cost += fee_cost_
                 if fee_rate_ is not None:
                     fee_rate_array.append(fee_rate_)
                 # only applies if fee is in quote currency!
                 if trade_base_currency == fee_currency:
                     fee_abs += fee_cost_
         # Ensure at least one trade was found:
         if fee_currency:
             # fee_rate should use mean
             fee_rate = sum(fee_rate_array) / float(len(fee_rate_array)) if fee_rate_array else None
             if fee_rate is not None and fee_rate < 0.02:
                 # Only update if fee-rate is < 2%
-                trade.update_fee(fee_cost, fee_currency, fee_rate, order.get('side', ''))
+                trade.update_fee(fee_cost, fee_currency, fee_rate, order.get("side", ""))
             else:
                 logger.warning(
-                    f"Not updating {order.get('side', '')}-fee - rate: {fee_rate}, {fee_currency}.")
+                    f"Not updating {order.get('side', '')}-fee - rate: {fee_rate}, {fee_currency}."
+                )
 
         if not isclose(amount, order_amount, abs_tol=constants.MATH_CLOSE_PREC):
             # * Leverage could be a cause for this warning
             logger.warning(f"Amount {amount} does not match amount {trade.amount}")
             raise DependencyException("Half bought? Amounts don't match")
 
         if fee_abs != 0:
             return self.apply_fee_conditional(
-                trade, trade_base_currency, amount=amount, fee_abs=fee_abs, order_obj=order_obj)
+                trade, trade_base_currency, amount=amount, fee_abs=fee_abs, order_obj=order_obj
+            )
         return None
 
     def get_valid_price(self, custom_price: float, proposed_price: float) -> float:
         """
         Return the valid price.
         Check if the custom price is of the good type if not return proposed_price
         :return: valid price for the order
@@ -2199,15 +2440,13 @@
             try:
                 valid_custom_price = float(custom_price)
             except ValueError:
                 valid_custom_price = proposed_price
         else:
             valid_custom_price = proposed_price
 
-        cust_p_max_dist_r = self.config.get('custom_price_max_distance_ratio', 0.02)
+        cust_p_max_dist_r = self.config.get("custom_price_max_distance_ratio", 0.02)
         min_custom_price_allowed = proposed_price - (proposed_price * cust_p_max_dist_r)
         max_custom_price_allowed = proposed_price + (proposed_price * cust_p_max_dist_r)
 
         # Bracket between min_custom_price_allowed and max_custom_price_allowed
-        return max(
-            min(valid_custom_price, max_custom_price_allowed),
-            min_custom_price_allowed)
+        return max(min(valid_custom_price, max_custom_price_allowed), min_custom_price_allowed)
```

### Comparing `freqtrade-2024.4/freqtrade/leverage/interest.py` & `freqtrade-2024.5/freqtrade/leverage/interest.py`

 * *Files 16% similar despite different names*

```diff
@@ -6,18 +6,15 @@
 
 one = FtPrecise(1.0)
 four = FtPrecise(4.0)
 twenty_four = FtPrecise(24.0)
 
 
 def interest(
-    exchange_name: str,
-    borrowed: FtPrecise,
-    rate: FtPrecise,
-    hours: FtPrecise
+    exchange_name: str, borrowed: FtPrecise, rate: FtPrecise, hours: FtPrecise
 ) -> FtPrecise:
     """
     Equation to calculate interest on margin trades
 
     :param exchange_name: The exchanged being trading on
     :param borrowed: The amount of currency being borrowed
     :param rate: The rate of interest (i.e daily interest rate)
```

### Comparing `freqtrade-2024.4/freqtrade/loggers/__init__.py` & `freqtrade-2024.5/freqtrade/loggers/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from freqtrade.exceptions import OperationalException
 from freqtrade.loggers.buffering_handler import FTBufferingHandler
 from freqtrade.loggers.set_log_levels import set_loggers
 from freqtrade.loggers.std_err_stream_handler import FTStdErrStreamHandler
 
 
 logger = logging.getLogger(__name__)
-LOGFORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+LOGFORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 
 # Initialize bufferhandler - will be used for /log endpoints
 bufferHandler = FTBufferingHandler(1000)
 bufferHandler.setFormatter(Formatter(LOGFORMAT))
 
 
 def get_existing_handlers(handlertype):
@@ -29,70 +29,72 @@
     Early setup for logging.
     Uses INFO loglevel and only the Streamhandler.
     Early messages (before proper logging setup) will therefore only be sent to additional
     logging handlers after the real initialization, because we don't know which
     ones the user desires beforehand.
     """
     logging.basicConfig(
-        level=logging.INFO,
-        format=LOGFORMAT,
-        handlers=[FTStdErrStreamHandler(), bufferHandler]
+        level=logging.INFO, format=LOGFORMAT, handlers=[FTStdErrStreamHandler(), bufferHandler]
     )
 
 
 def setup_logging(config: Config) -> None:
     """
     Process -v/--verbose, --logfile options
     """
     # Log level
-    verbosity = config['verbosity']
+    verbosity = config["verbosity"]
     logging.root.addHandler(bufferHandler)
 
-    logfile = config.get('logfile')
+    logfile = config.get("logfile")
 
     if logfile:
-        s = logfile.split(':')
-        if s[0] == 'syslog':
+        s = logfile.split(":")
+        if s[0] == "syslog":
             # Address can be either a string (socket filename) for Unix domain socket or
             # a tuple (hostname, port) for UDP socket.
             # Address can be omitted (i.e. simple 'syslog' used as the value of
             # config['logfilename']), which defaults to '/dev/log', applicable for most
             # of the systems.
-            address = (s[1], int(s[2])) if len(s) > 2 else s[1] if len(s) > 1 else '/dev/log'
+            address = (s[1], int(s[2])) if len(s) > 2 else s[1] if len(s) > 1 else "/dev/log"
             handler_sl = get_existing_handlers(SysLogHandler)
             if handler_sl:
                 logging.root.removeHandler(handler_sl)
             handler_sl = SysLogHandler(address=address)
             # No datetime field for logging into syslog, to allow syslog
             # to perform reduction of repeating messages if this is set in the
             # syslog config. The messages should be equal for this.
-            handler_sl.setFormatter(Formatter('%(name)s - %(levelname)s - %(message)s'))
+            handler_sl.setFormatter(Formatter("%(name)s - %(levelname)s - %(message)s"))
             logging.root.addHandler(handler_sl)
-        elif s[0] == 'journald':  # pragma: no cover
+        elif s[0] == "journald":  # pragma: no cover
             try:
                 from cysystemd.journal import JournaldLogHandler
             except ImportError:
-                raise OperationalException("You need the cysystemd python package be installed in "
-                                           "order to use logging to journald.")
+                raise OperationalException(
+                    "You need the cysystemd python package be installed in "
+                    "order to use logging to journald."
+                )
             handler_jd = get_existing_handlers(JournaldLogHandler)
             if handler_jd:
                 logging.root.removeHandler(handler_jd)
             handler_jd = JournaldLogHandler()
             # No datetime field for logging into journald, to allow syslog
             # to perform reduction of repeating messages if this is set in the
             # syslog config. The messages should be equal for this.
-            handler_jd.setFormatter(Formatter('%(name)s - %(levelname)s - %(message)s'))
+            handler_jd.setFormatter(Formatter("%(name)s - %(levelname)s - %(message)s"))
             logging.root.addHandler(handler_jd)
         else:
             handler_rf = get_existing_handlers(RotatingFileHandler)
             if handler_rf:
                 logging.root.removeHandler(handler_rf)
-            handler_rf = RotatingFileHandler(logfile,
-                                             maxBytes=1024 * 1024 * 10,  # 10Mb
-                                             backupCount=10)
+            handler_rf = RotatingFileHandler(
+                logfile,
+                maxBytes=1024 * 1024 * 10,  # 10Mb
+                backupCount=10,
+            )
             handler_rf.setFormatter(Formatter(LOGFORMAT))
             logging.root.addHandler(handler_rf)
 
     logging.root.setLevel(logging.INFO if verbosity < 1 else logging.DEBUG)
-    set_loggers(verbosity, config.get('api_server', {}).get('verbosity', 'info'))
+    set_loggers(verbosity, config.get("api_server", {}).get("verbosity", "info"))
 
-    logger.info('Verbosity set to %s', verbosity)
+    logger.info("Verbosity set to %s", verbosity)
```

### Comparing `freqtrade-2024.4/freqtrade/loggers/set_log_levels.py` & `freqtrade-2024.5/freqtrade/loggers/set_log_levels.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,39 +1,36 @@
-
 import logging
 
 
 logger = logging.getLogger(__name__)
 
 
-def set_loggers(verbosity: int = 0, api_verbosity: str = 'info') -> None:
+def set_loggers(verbosity: int = 0, api_verbosity: str = "info") -> None:
     """
     Set the logging level for third party libraries
     :param verbosity: Verbosity level. amount of `-v` passed to the command line
     :return: None
     """
-    for logger_name in ('requests', 'urllib3', 'httpcore'):
-        logging.getLogger(logger_name).setLevel(
-            logging.INFO if verbosity <= 1 else logging.DEBUG
-        )
-    logging.getLogger('ccxt.base.exchange').setLevel(
+    for logger_name in ("requests", "urllib3", "httpcore"):
+        logging.getLogger(logger_name).setLevel(logging.INFO if verbosity <= 1 else logging.DEBUG)
+    logging.getLogger("ccxt.base.exchange").setLevel(
         logging.INFO if verbosity <= 2 else logging.DEBUG
     )
-    logging.getLogger('telegram').setLevel(logging.INFO)
-    logging.getLogger('httpx').setLevel(logging.WARNING)
+    logging.getLogger("telegram").setLevel(logging.INFO)
+    logging.getLogger("httpx").setLevel(logging.WARNING)
 
-    logging.getLogger('werkzeug').setLevel(
-        logging.ERROR if api_verbosity == 'error' else logging.INFO
+    logging.getLogger("werkzeug").setLevel(
+        logging.ERROR if api_verbosity == "error" else logging.INFO
     )
 
 
 __BIAS_TESTER_LOGGERS = [
-    'freqtrade.resolvers',
-    'freqtrade.strategy.hyper',
-    'freqtrade.configuration.config_validation',
+    "freqtrade.resolvers",
+    "freqtrade.strategy.hyper",
+    "freqtrade.configuration.config_validation",
 ]
 
 
 def reduce_verbosity_for_bias_tester() -> None:
     """
     Reduce verbosity for bias tester.
     It loads the same strategy several times, which would spam the log.
```

### Comparing `freqtrade-2024.4/freqtrade/loggers/std_err_stream_handler.py` & `freqtrade-2024.5/freqtrade/loggers/std_err_stream_handler.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,13 +14,13 @@
         finally:
             self.release()
 
     def emit(self, record):
         try:
             msg = self.format(record)
             # Don't keep a reference to stderr - this can be problematic with progressbars.
-            sys.stderr.write(msg + '\n')
+            sys.stderr.write(msg + "\n")
             self.flush()
         except RecursionError:
             raise
         except Exception:
             self.handleError(record)
```

### Comparing `freqtrade-2024.4/freqtrade/main.py` & `freqtrade-2024.5/freqtrade/main.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 #!/usr/bin/env python3
 """
 Main Freqtrade bot script.
 Read the documentation to know what cli arguments you need.
 """
+
 import logging
 import sys
 from typing import Any, List, Optional
 
 
 # check min. python version
 if sys.version_info < (3, 9):  # pragma: no cover
@@ -16,15 +17,15 @@
 from freqtrade.commands import Arguments
 from freqtrade.constants import DOCS_LINK
 from freqtrade.exceptions import ConfigurationError, FreqtradeException, OperationalException
 from freqtrade.loggers import setup_logging_pre
 from freqtrade.util.gc_setup import gc_set_threshold
 
 
-logger = logging.getLogger('freqtrade')
+logger = logging.getLogger("freqtrade")
 
 
 def main(sysargv: Optional[List[str]] = None) -> None:
     """
     This function will initiate the bot and start the trading loop.
     :return: None
     """
@@ -32,41 +33,43 @@
     return_code: Any = 1
     try:
         setup_logging_pre()
         arguments = Arguments(sysargv)
         args = arguments.get_parsed_arg()
 
         # Call subcommand.
-        if 'func' in args:
-            logger.info(f'freqtrade {__version__}')
+        if "func" in args:
+            logger.info(f"freqtrade {__version__}")
             gc_set_threshold()
-            return_code = args['func'](args)
+            return_code = args["func"](args)
         else:
             # No subcommand was issued.
             raise OperationalException(
                 "Usage of Freqtrade requires a subcommand to be specified.\n"
                 "To have the bot executing trades in live/dry-run modes, "
                 "depending on the value of the `dry_run` setting in the config, run Freqtrade "
                 "as `freqtrade trade [options...]`.\n"
                 "To see the full list of options available, please use "
                 "`freqtrade --help` or `freqtrade <command> --help`."
             )
 
     except SystemExit as e:  # pragma: no cover
         return_code = e
     except KeyboardInterrupt:
-        logger.info('SIGINT received, aborting ...')
+        logger.info("SIGINT received, aborting ...")
         return_code = 0
     except ConfigurationError as e:
-        logger.error(f"Configuration error: {e}\n"
-                     f"Please make sure to review the documentation at {DOCS_LINK}.")
+        logger.error(
+            f"Configuration error: {e}\n"
+            f"Please make sure to review the documentation at {DOCS_LINK}."
+        )
     except FreqtradeException as e:
         logger.error(str(e))
         return_code = 2
     except Exception:
-        logger.exception('Fatal exception!')
+        logger.exception("Fatal exception!")
     finally:
         sys.exit(return_code)
 
 
-if __name__ == '__main__':  # pragma: no cover
+if __name__ == "__main__":  # pragma: no cover
     main()
```

### Comparing `freqtrade-2024.4/freqtrade/misc.py` & `freqtrade-2024.5/freqtrade/misc.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Various tool function for Freqtrade and scripts
 """
+
 import gzip
 import logging
 from io import StringIO
 from pathlib import Path
 from typing import Any, Dict, Iterator, List, Mapping, Optional, TextIO, Union
 from urllib.parse import urlparse
 
@@ -23,25 +24,25 @@
     :param filename: file to create
     :param is_zip: if file should be zip
     :param data: JSON Data to save
     :return:
     """
 
     if is_zip:
-        if filename.suffix != '.gz':
-            filename = filename.with_suffix('.gz')
+        if filename.suffix != ".gz":
+            filename = filename.with_suffix(".gz")
         if log:
             logger.info(f'dumping json to "{filename}"')
 
-        with gzip.open(filename, 'w') as fpz:
+        with gzip.open(filename, "w") as fpz:
             rapidjson.dump(data, fpz, default=str, number_mode=rapidjson.NM_NATIVE)
     else:
         if log:
             logger.info(f'dumping json to "{filename}"')
-        with filename.open('w') as fp:
+        with filename.open("w") as fp:
             rapidjson.dump(data, fp, default=str, number_mode=rapidjson.NM_NATIVE)
 
     logger.debug(f'done json to "{filename}"')
 
 
 def file_dump_joblib(filename: Path, data: Any, log: bool = True) -> None:
     """
@@ -50,32 +51,31 @@
     :param data: Object data to save
     :return:
     """
     import joblib
 
     if log:
         logger.info(f'dumping joblib to "{filename}"')
-    with filename.open('wb') as fp:
+    with filename.open("wb") as fp:
         joblib.dump(data, fp)
     logger.debug(f'done joblib dump to "{filename}"')
 
 
 def json_load(datafile: Union[gzip.GzipFile, TextIO]) -> Any:
     """
     load data with rapidjson
     Use this to have a consistent experience,
     set number_mode to "NM_NATIVE" for greatest speed
     """
     return rapidjson.load(datafile, number_mode=rapidjson.NM_NATIVE)
 
 
 def file_load_json(file: Path):
-
     if file.suffix != ".gz":
-        gzipfile = file.with_suffix(file.suffix + '.gz')
+        gzipfile = file.with_suffix(file.suffix + ".gz")
     else:
         gzipfile = file
     # Try gzip file first, otherwise regular json file.
     if gzipfile.is_file():
         logger.debug(f"Loading historical data from file {gzipfile}")
         with gzip.open(gzipfile) as datafile:
             pairdata = json_load(datafile)
@@ -92,16 +92,16 @@
     """
     Helper function to check if file is in directory.
     """
     return file.is_file() and file.parent.samefile(directory)
 
 
 def pair_to_filename(pair: str) -> str:
-    for ch in ['/', ' ', '.', '@', '$', '+', ':']:
-        pair = pair.replace(ch, '_')
+    for ch in ["/", " ", ".", "@", "$", "+", ":"]:
+        pair = pair.replace(ch, "_")
     return pair
 
 
 def deep_merge_dicts(source, destination, allow_null_overrides: bool = True):
     """
     Values from Source override destination, destination is returned (and modified!!)
     Sample:
@@ -157,59 +157,59 @@
     else:
         if key2 in dict2 and dict2[key2] is not None:
             return dict2[key2]
     return default_value
 
 
 def plural(num: float, singular: str, plural: Optional[str] = None) -> str:
-    return singular if (num == 1 or num == -1) else plural or singular + 's'
+    return singular if (num == 1 or num == -1) else plural or singular + "s"
 
 
 def chunks(lst: List[Any], n: int) -> Iterator[List[Any]]:
     """
     Split lst into chunks of the size n.
     :param lst: list to split into chunks
     :param n: number of max elements per chunk
     :return: None
     """
     for chunk in range(0, len(lst), n):
-        yield (lst[chunk:chunk + n])
+        yield (lst[chunk : chunk + n])
 
 
 def parse_db_uri_for_logging(uri: str):
     """
     Helper method to parse the DB URI and return the same DB URI with the password censored
     if it contains it. Otherwise, return the DB URI unchanged
     :param uri: DB URI to parse for logging
     """
     parsed_db_uri = urlparse(uri)
     if not parsed_db_uri.netloc:  # No need for censoring as no password was provided
         return uri
-    pwd = parsed_db_uri.netloc.split(':')[1].split('@')[0]
-    return parsed_db_uri.geturl().replace(f':{pwd}@', ':*****@')
+    pwd = parsed_db_uri.netloc.split(":")[1].split("@")[0]
+    return parsed_db_uri.geturl().replace(f":{pwd}@", ":*****@")
 
 
 def dataframe_to_json(dataframe: pd.DataFrame) -> str:
     """
     Serialize a DataFrame for transmission over the wire using JSON
     :param dataframe: A pandas DataFrame
     :returns: A JSON string of the pandas DataFrame
     """
-    return dataframe.to_json(orient='split')
+    return dataframe.to_json(orient="split")
 
 
 def json_to_dataframe(data: str) -> pd.DataFrame:
     """
     Deserialize JSON into a DataFrame
     :param data: A JSON string
     :returns: A pandas DataFrame from the JSON string
     """
-    dataframe = pd.read_json(StringIO(data), orient='split')
-    if 'date' in dataframe.columns:
-        dataframe['date'] = pd.to_datetime(dataframe['date'], unit='ms', utc=True)
+    dataframe = pd.read_json(StringIO(data), orient="split")
+    if "date" in dataframe.columns:
+        dataframe["date"] = pd.to_datetime(dataframe["date"], unit="ms", utc=True)
 
     return dataframe
 
 
 def remove_entry_exit_signals(dataframe: pd.DataFrame):
     """
     Remove Entry and Exit signals from a DataFrame
@@ -230,15 +230,15 @@
     """
     Append the `right` dataframe to the `left` dataframe
 
     :param left: The full dataframe you want appended to
     :param right: The new dataframe containing the data you want appended
     :returns: The dataframe with the right data in it
     """
-    if left.iloc[-1]['date'] != right.iloc[-1]['date']:
+    if left.iloc[-1]["date"] != right.iloc[-1]["date"]:
         left = pd.concat([left, right])
 
     # Only keep the last 1500 candles in memory
     left = left[-1500:] if len(left) > 1500 else left
     left.reset_index(drop=True, inplace=True)
 
     return left
```

### Comparing `freqtrade-2024.4/freqtrade/mixins/logging_mixin.py` & `freqtrade-2024.5/freqtrade/mixins/logging_mixin.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,14 +4,15 @@
 
 
 class LoggingMixin:
     """
     Logging Mixin
     Shows similar messages only once every `refresh_period`.
     """
+
     # Disable output completely
     show_output = True
 
     def __init__(self, logger, refresh_period: int = 3600):
         """
         :param refresh_period: in seconds - Show identical messages in this intervals
         """
@@ -23,14 +24,15 @@
         """
         Logs message - not more often than "refresh_period" to avoid log spamming
         Logs the log-message as debug as well to simplify debugging.
         :param message: String containing the message to be sent to the function.
         :param logmethod: Function that'll be called. Most likely `logger.info`.
         :return: None.
         """
+
         @cached(cache=self._log_cache)
         def _log_once(message: str):
             logmethod(message)
 
         # Log as debug first
         self.logger.debug(message)
         # Call hidden function.
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/analysis/lookahead.py` & `freqtrade-2024.5/freqtrade/optimize/analysis/lookahead.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,16 +5,18 @@
 from pathlib import Path
 from typing import Any, Dict, List
 
 from pandas import DataFrame
 
 from freqtrade.data.history import get_timerange
 from freqtrade.exchange import timeframe_to_minutes
-from freqtrade.loggers.set_log_levels import (reduce_verbosity_for_bias_tester,
-                                              restore_verbosity_for_bias_tester)
+from freqtrade.loggers.set_log_levels import (
+    reduce_verbosity_for_bias_tester,
+    restore_verbosity_for_bias_tester,
+)
 from freqtrade.optimize.backtesting import Backtesting
 from freqtrade.optimize.base_analysis import BaseAnalysis, VarHolder
 
 
 logger = logging.getLogger(__name__)
 
 
@@ -24,112 +26,106 @@
         self.false_entry_signals = 0
         self.false_exit_signals = 0
         self.false_indicators: List[str] = []
         self.has_bias = False
 
 
 class LookaheadAnalysis(BaseAnalysis):
-
     def __init__(self, config: Dict[str, Any], strategy_obj: Dict):
-
         super().__init__(config, strategy_obj)
 
         self.entry_varHolders: List[VarHolder] = []
         self.exit_varHolders: List[VarHolder] = []
 
         self.current_analysis = Analysis()
-        self.minimum_trade_amount = config['minimum_trade_amount']
-        self.targeted_trade_amount = config['targeted_trade_amount']
+        self.minimum_trade_amount = config["minimum_trade_amount"]
+        self.targeted_trade_amount = config["targeted_trade_amount"]
 
     @staticmethod
     def get_result(backtesting: Backtesting, processed: DataFrame):
         min_date, max_date = get_timerange(processed)
 
         result = backtesting.backtest(
-            processed=deepcopy(processed),
-            start_date=min_date,
-            end_date=max_date
+            processed=deepcopy(processed), start_date=min_date, end_date=max_date
         )
         return result
 
     @staticmethod
     def report_signal(result: dict, column_name: str, checked_timestamp: datetime):
-        df = result['results']
+        df = result["results"]
         row_count = df[column_name].shape[0]
 
         if row_count == 0:
             return False
         else:
-
             df_cut = df[(df[column_name] == checked_timestamp)]
             if df_cut[column_name].shape[0] == 0:
                 return False
             else:
                 return True
         return False
 
     # analyzes two data frames with processed indicators and shows differences between them.
     def analyze_indicators(self, full_vars: VarHolder, cut_vars: VarHolder, current_pair: str):
         # extract dataframes
         cut_df: DataFrame = cut_vars.indicators[current_pair]
         full_df: DataFrame = full_vars.indicators[current_pair]
 
         # cut longer dataframe to length of the shorter
-        full_df_cut = full_df[
-            (full_df.date == cut_vars.compared_dt)
-        ].reset_index(drop=True)
-        cut_df_cut = cut_df[
-            (cut_df.date == cut_vars.compared_dt)
-        ].reset_index(drop=True)
+        full_df_cut = full_df[(full_df.date == cut_vars.compared_dt)].reset_index(drop=True)
+        cut_df_cut = cut_df[(cut_df.date == cut_vars.compared_dt)].reset_index(drop=True)
 
         # check if dataframes are not empty
         if full_df_cut.shape[0] != 0 and cut_df_cut.shape[0] != 0:
-
             # compare dataframes
             compare_df = full_df_cut.compare(cut_df_cut)
 
             if compare_df.shape[0] > 0:
                 for col_name, values in compare_df.items():
                     col_idx = compare_df.columns.get_loc(col_name)
                     compare_df_row = compare_df.iloc[0]
                     # compare_df now comprises tuples with [1] having either 'self' or 'other'
-                    if 'other' in col_name[1]:
+                    if "other" in col_name[1]:
                         continue
                     self_value = compare_df_row.iloc[col_idx]
                     other_value = compare_df_row.iloc[col_idx + 1]
 
                     # output differences
                     if self_value != other_value:
-
                         if not self.current_analysis.false_indicators.__contains__(col_name[0]):
                             self.current_analysis.false_indicators.append(col_name[0])
-                            logger.info(f"=> found look ahead bias in indicator "
-                                        f"{col_name[0]}. "
-                                        f"{str(self_value)} != {str(other_value)}")
+                            logger.info(
+                                f"=> found look ahead bias in indicator "
+                                f"{col_name[0]}. "
+                                f"{str(self_value)} != {str(other_value)}"
+                            )
 
     def prepare_data(self, varholder: VarHolder, pairs_to_load: List[DataFrame]):
-
-        if 'freqai' in self.local_config and 'identifier' in self.local_config['freqai']:
+        if "freqai" in self.local_config and "identifier" in self.local_config["freqai"]:
             # purge previous data if the freqai model is defined
             # (to be sure nothing is carried over from older backtests)
-            path_to_current_identifier = (
-                Path(f"{self.local_config['user_data_dir']}/models/"
-                     f"{self.local_config['freqai']['identifier']}").resolve())
+            path_to_current_identifier = Path(
+                f"{self.local_config['user_data_dir']}/models/"
+                f"{self.local_config['freqai']['identifier']}"
+            ).resolve()
             # remove folder and its contents
             if Path.exists(path_to_current_identifier):
                 shutil.rmtree(path_to_current_identifier)
 
         prepare_data_config = deepcopy(self.local_config)
-        prepare_data_config['timerange'] = (str(self.dt_to_timestamp(varholder.from_dt)) + "-" +
-                                            str(self.dt_to_timestamp(varholder.to_dt)))
-        prepare_data_config['exchange']['pair_whitelist'] = pairs_to_load
+        prepare_data_config["timerange"] = (
+            str(self.dt_to_timestamp(varholder.from_dt))
+            + "-"
+            + str(self.dt_to_timestamp(varholder.to_dt))
+        )
+        prepare_data_config["exchange"]["pair_whitelist"] = pairs_to_load
 
         if self._fee is not None:
             # Don't re-calculate fee per pair, as fee might differ per pair.
-            prepare_data_config['fee'] = self._fee
+            prepare_data_config["fee"] = self._fee
 
         backtesting = Backtesting(prepare_data_config, self.exchange)
         self.exchange = backtesting.exchange
         self._fee = backtesting.fee
         backtesting._set_strategy(backtesting.strategylist[0])
 
         varholder.data, varholder.timerange = backtesting.load_bt_data()
@@ -140,31 +136,31 @@
         varholder.result = self.get_result(backtesting, varholder.indicators)
 
     def fill_entry_and_exit_varHolders(self, result_row):
         # entry_varHolder
         entry_varHolder = VarHolder()
         self.entry_varHolders.append(entry_varHolder)
         entry_varHolder.from_dt = self.full_varHolder.from_dt
-        entry_varHolder.compared_dt = result_row['open_date']
+        entry_varHolder.compared_dt = result_row["open_date"]
         # to_dt needs +1 candle since it won't buy on the last candle
-        entry_varHolder.to_dt = (
-                result_row['open_date'] +
-                timedelta(minutes=timeframe_to_minutes(self.full_varHolder.timeframe)))
-        self.prepare_data(entry_varHolder, [result_row['pair']])
+        entry_varHolder.to_dt = result_row["open_date"] + timedelta(
+            minutes=timeframe_to_minutes(self.full_varHolder.timeframe)
+        )
+        self.prepare_data(entry_varHolder, [result_row["pair"]])
 
         # exit_varHolder
         exit_varHolder = VarHolder()
         self.exit_varHolders.append(exit_varHolder)
         # to_dt needs +1 candle since it will always exit/force-exit trades on the last candle
         exit_varHolder.from_dt = self.full_varHolder.from_dt
-        exit_varHolder.to_dt = (
-                result_row['close_date'] +
-                timedelta(minutes=timeframe_to_minutes(self.full_varHolder.timeframe)))
-        exit_varHolder.compared_dt = result_row['close_date']
-        self.prepare_data(exit_varHolder, [result_row['pair']])
+        exit_varHolder.to_dt = result_row["close_date"] + timedelta(
+            minutes=timeframe_to_minutes(self.full_varHolder.timeframe)
+        )
+        exit_varHolder.compared_dt = result_row["close_date"]
+        self.prepare_data(exit_varHolder, [result_row["pair"]])
 
     # now we analyze a full trade of full_varholder and look for analyze its bias
     def analyze_row(self, idx: int, result_row):
         # if force-sold, ignore this signal since here it will unconditionally exit.
         if result_row.close_date == self.dt_to_timestamp(self.full_varHolder.to_dt):
             return
 
@@ -175,100 +171,113 @@
         self.fill_entry_and_exit_varHolders(result_row)
 
         # this will trigger a logger-message
         buy_or_sell_biased: bool = False
 
         # register if buy signal is broken
         if not self.report_signal(
-                self.entry_varHolders[idx].result,
-                "open_date",
-                self.entry_varHolders[idx].compared_dt):
+            self.entry_varHolders[idx].result, "open_date", self.entry_varHolders[idx].compared_dt
+        ):
             self.current_analysis.false_entry_signals += 1
             buy_or_sell_biased = True
 
         # register if buy or sell signal is broken
         if not self.report_signal(
-                self.exit_varHolders[idx].result,
-                "close_date",
-                self.exit_varHolders[idx].compared_dt):
+            self.exit_varHolders[idx].result, "close_date", self.exit_varHolders[idx].compared_dt
+        ):
             self.current_analysis.false_exit_signals += 1
             buy_or_sell_biased = True
 
         if buy_or_sell_biased:
-            logger.info(f"found lookahead-bias in trade "
-                        f"pair: {result_row['pair']}, "
-                        f"timerange:{result_row['open_date']} - {result_row['close_date']}, "
-                        f"idx: {idx}")
+            logger.info(
+                f"found lookahead-bias in trade "
+                f"pair: {result_row['pair']}, "
+                f"timerange:{result_row['open_date']} - {result_row['close_date']}, "
+                f"idx: {idx}"
+            )
 
         # check if the indicators themselves contain biased data
-        self.analyze_indicators(self.full_varHolder, self.entry_varHolders[idx], result_row['pair'])
-        self.analyze_indicators(self.full_varHolder, self.exit_varHolders[idx], result_row['pair'])
+        self.analyze_indicators(self.full_varHolder, self.entry_varHolders[idx], result_row["pair"])
+        self.analyze_indicators(self.full_varHolder, self.exit_varHolders[idx], result_row["pair"])
 
     def start(self) -> None:
-
         super().start()
 
         reduce_verbosity_for_bias_tester()
 
         # check if requirements have been met of full_varholder
-        found_signals: int = self.full_varHolder.result['results'].shape[0] + 1
+        found_signals: int = self.full_varHolder.result["results"].shape[0] + 1
         if found_signals >= self.targeted_trade_amount:
-            logger.info(f"Found {found_signals} trades, "
-                        f"calculating {self.targeted_trade_amount} trades.")
+            logger.info(
+                f"Found {found_signals} trades, "
+                f"calculating {self.targeted_trade_amount} trades."
+            )
         elif self.targeted_trade_amount >= found_signals >= self.minimum_trade_amount:
             logger.info(f"Only found {found_signals} trades. Calculating all available trades.")
         else:
-            logger.info(f"found {found_signals} trades "
-                        f"which is less than minimum_trade_amount {self.minimum_trade_amount}. "
-                        f"Cancelling this backtest lookahead bias test.")
+            logger.info(
+                f"found {found_signals} trades "
+                f"which is less than minimum_trade_amount {self.minimum_trade_amount}. "
+                f"Cancelling this backtest lookahead bias test."
+            )
             return
 
         # now we loop through all signals
         # starting from the same datetime to avoid miss-reports of bias
-        for idx, result_row in self.full_varHolder.result['results'].iterrows():
+        for idx, result_row in self.full_varHolder.result["results"].iterrows():
             if self.current_analysis.total_signals == self.targeted_trade_amount:
                 logger.info(f"Found targeted trade amount = {self.targeted_trade_amount} signals.")
                 break
             if found_signals < self.minimum_trade_amount:
-                logger.info(f"only found {found_signals} "
-                            f"which is smaller than "
-                            f"minimum trade amount = {self.minimum_trade_amount}. "
-                            f"Exiting this lookahead-analysis")
+                logger.info(
+                    f"only found {found_signals} "
+                    f"which is smaller than "
+                    f"minimum trade amount = {self.minimum_trade_amount}. "
+                    f"Exiting this lookahead-analysis"
+                )
                 return None
-            if "force_exit" in result_row['exit_reason']:
-                logger.info("found force-exit in pair: {result_row['pair']}, "
-                            f"timerange:{result_row['open_date']}-{result_row['close_date']}, "
-                            f"idx: {idx}, skipping this one to avoid a false-positive.")
+            if "force_exit" in result_row["exit_reason"]:
+                logger.info(
+                    "found force-exit in pair: {result_row['pair']}, "
+                    f"timerange:{result_row['open_date']}-{result_row['close_date']}, "
+                    f"idx: {idx}, skipping this one to avoid a false-positive."
+                )
 
                 # just to keep the IDs of both full, entry and exit varholders the same
                 # to achieve a better debugging experience
                 self.entry_varHolders.append(VarHolder())
                 self.exit_varHolders.append(VarHolder())
                 continue
 
             self.analyze_row(idx, result_row)
 
         if len(self.entry_varHolders) < self.minimum_trade_amount:
-            logger.info(f"only found {found_signals} after skipping forced exits "
-                        f"which is smaller than "
-                        f"minimum trade amount = {self.minimum_trade_amount}. "
-                        f"Exiting this lookahead-analysis")
+            logger.info(
+                f"only found {found_signals} after skipping forced exits "
+                f"which is smaller than "
+                f"minimum trade amount = {self.minimum_trade_amount}. "
+                f"Exiting this lookahead-analysis"
+            )
 
         # Restore verbosity, so it's not too quiet for the next strategy
         restore_verbosity_for_bias_tester()
         # check and report signals
-        if self.current_analysis.total_signals < self.local_config['minimum_trade_amount']:
-            logger.info(f" -> {self.local_config['strategy']} : too few trades. "
-                        f"We only found {self.current_analysis.total_signals} trades. "
-                        f"Hint: Extend the timerange "
-                        f"to get at least {self.local_config['minimum_trade_amount']} "
-                        f"or lower the value of minimum_trade_amount.")
+        if self.current_analysis.total_signals < self.local_config["minimum_trade_amount"]:
+            logger.info(
+                f" -> {self.local_config['strategy']} : too few trades. "
+                f"We only found {self.current_analysis.total_signals} trades. "
+                f"Hint: Extend the timerange "
+                f"to get at least {self.local_config['minimum_trade_amount']} "
+                f"or lower the value of minimum_trade_amount."
+            )
             self.failed_bias_check = True
-        elif (self.current_analysis.false_entry_signals > 0 or
-              self.current_analysis.false_exit_signals > 0 or
-              len(self.current_analysis.false_indicators) > 0):
+        elif (
+            self.current_analysis.false_entry_signals > 0
+            or self.current_analysis.false_exit_signals > 0
+            or len(self.current_analysis.false_indicators) > 0
+        ):
             logger.info(f" => {self.local_config['strategy']} : bias detected!")
             self.current_analysis.has_bias = True
             self.failed_bias_check = False
         else:
-            logger.info(self.local_config['strategy'] + ": no bias detected")
+            logger.info(self.local_config["strategy"] + ": no bias detected")
             self.failed_bias_check = False
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/analysis/lookahead_helpers.py` & `freqtrade-2024.5/freqtrade/optimize/analysis/lookahead_helpers.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,213 +11,241 @@
 from freqtrade.resolvers import StrategyResolver
 
 
 logger = logging.getLogger(__name__)
 
 
 class LookaheadAnalysisSubFunctions:
-
     @staticmethod
     def text_table_lookahead_analysis_instances(
-            config: Dict[str, Any],
-            lookahead_instances: List[LookaheadAnalysis]):
-        headers = ['filename', 'strategy', 'has_bias', 'total_signals',
-                   'biased_entry_signals', 'biased_exit_signals', 'biased_indicators']
+        config: Dict[str, Any], lookahead_instances: List[LookaheadAnalysis]
+    ):
+        headers = [
+            "filename",
+            "strategy",
+            "has_bias",
+            "total_signals",
+            "biased_entry_signals",
+            "biased_exit_signals",
+            "biased_indicators",
+        ]
         data = []
         for inst in lookahead_instances:
-            if config['minimum_trade_amount'] > inst.current_analysis.total_signals:
+            if config["minimum_trade_amount"] > inst.current_analysis.total_signals:
                 data.append(
                     [
-                        inst.strategy_obj['location'].parts[-1],
-                        inst.strategy_obj['name'],
+                        inst.strategy_obj["location"].parts[-1],
+                        inst.strategy_obj["name"],
                         "too few trades caught "
                         f"({inst.current_analysis.total_signals}/{config['minimum_trade_amount']})."
-                        f"Test failed."
+                        f"Test failed.",
                     ]
                 )
             elif inst.failed_bias_check:
                 data.append(
                     [
-                        inst.strategy_obj['location'].parts[-1],
-                        inst.strategy_obj['name'],
-                        'error while checking'
+                        inst.strategy_obj["location"].parts[-1],
+                        inst.strategy_obj["name"],
+                        "error while checking",
                     ]
                 )
             else:
                 data.append(
                     [
-                        inst.strategy_obj['location'].parts[-1],
-                        inst.strategy_obj['name'],
+                        inst.strategy_obj["location"].parts[-1],
+                        inst.strategy_obj["name"],
                         inst.current_analysis.has_bias,
                         inst.current_analysis.total_signals,
                         inst.current_analysis.false_entry_signals,
                         inst.current_analysis.false_exit_signals,
-                        ", ".join(inst.current_analysis.false_indicators)
+                        ", ".join(inst.current_analysis.false_indicators),
                     ]
                 )
         from tabulate import tabulate
+
         table = tabulate(data, headers=headers, tablefmt="orgtbl")
         print(table)
         return table, headers, data
 
     @staticmethod
     def export_to_csv(config: Dict[str, Any], lookahead_analysis: List[LookaheadAnalysis]):
         def add_or_update_row(df, row_data):
             if (
-                    (df['filename'] == row_data['filename']) &
-                    (df['strategy'] == row_data['strategy'])
+                (df["filename"] == row_data["filename"]) & (df["strategy"] == row_data["strategy"])
             ).any():
                 # Update existing row
                 pd_series = pd.DataFrame([row_data])
                 df.loc[
-                    (df['filename'] == row_data['filename']) &
-                    (df['strategy'] == row_data['strategy'])
-                    ] = pd_series
+                    (df["filename"] == row_data["filename"])
+                    & (df["strategy"] == row_data["strategy"])
+                ] = pd_series
             else:
                 # Add new row
                 df = pd.concat([df, pd.DataFrame([row_data], columns=df.columns)])
 
             return df
 
-        if Path(config['lookahead_analysis_exportfilename']).exists():
+        if Path(config["lookahead_analysis_exportfilename"]).exists():
             # Read CSV file into a pandas dataframe
-            csv_df = pd.read_csv(config['lookahead_analysis_exportfilename'])
+            csv_df = pd.read_csv(config["lookahead_analysis_exportfilename"])
         else:
             # Create a new empty DataFrame with the desired column names and set the index
-            csv_df = pd.DataFrame(columns=[
-                'filename', 'strategy', 'has_bias', 'total_signals',
-                'biased_entry_signals', 'biased_exit_signals', 'biased_indicators'
-            ],
-                index=None)
+            csv_df = pd.DataFrame(
+                columns=[
+                    "filename",
+                    "strategy",
+                    "has_bias",
+                    "total_signals",
+                    "biased_entry_signals",
+                    "biased_exit_signals",
+                    "biased_indicators",
+                ],
+                index=None,
+            )
 
         for inst in lookahead_analysis:
             # only update if
-            if (inst.current_analysis.total_signals > config['minimum_trade_amount']
-                    and inst.failed_bias_check is not True):
-                new_row_data = {'filename': inst.strategy_obj['location'].parts[-1],
-                                'strategy': inst.strategy_obj['name'],
-                                'has_bias': inst.current_analysis.has_bias,
-                                'total_signals':
-                                    int(inst.current_analysis.total_signals),
-                                'biased_entry_signals':
-                                    int(inst.current_analysis.false_entry_signals),
-                                'biased_exit_signals':
-                                    int(inst.current_analysis.false_exit_signals),
-                                'biased_indicators':
-                                    ",".join(inst.current_analysis.false_indicators)}
+            if (
+                inst.current_analysis.total_signals > config["minimum_trade_amount"]
+                and inst.failed_bias_check is not True
+            ):
+                new_row_data = {
+                    "filename": inst.strategy_obj["location"].parts[-1],
+                    "strategy": inst.strategy_obj["name"],
+                    "has_bias": inst.current_analysis.has_bias,
+                    "total_signals": int(inst.current_analysis.total_signals),
+                    "biased_entry_signals": int(inst.current_analysis.false_entry_signals),
+                    "biased_exit_signals": int(inst.current_analysis.false_exit_signals),
+                    "biased_indicators": ",".join(inst.current_analysis.false_indicators),
+                }
                 csv_df = add_or_update_row(csv_df, new_row_data)
 
         # Fill NaN values with a default value (e.g., 0)
-        csv_df['total_signals'] = csv_df['total_signals'].astype(int).fillna(0)
-        csv_df['biased_entry_signals'] = csv_df['biased_entry_signals'].astype(int).fillna(0)
-        csv_df['biased_exit_signals'] = csv_df['biased_exit_signals'].astype(int).fillna(0)
+        csv_df["total_signals"] = csv_df["total_signals"].astype(int).fillna(0)
+        csv_df["biased_entry_signals"] = csv_df["biased_entry_signals"].astype(int).fillna(0)
+        csv_df["biased_exit_signals"] = csv_df["biased_exit_signals"].astype(int).fillna(0)
 
         # Convert columns to integers
-        csv_df['total_signals'] = csv_df['total_signals'].astype(int)
-        csv_df['biased_entry_signals'] = csv_df['biased_entry_signals'].astype(int)
-        csv_df['biased_exit_signals'] = csv_df['biased_exit_signals'].astype(int)
+        csv_df["total_signals"] = csv_df["total_signals"].astype(int)
+        csv_df["biased_entry_signals"] = csv_df["biased_entry_signals"].astype(int)
+        csv_df["biased_exit_signals"] = csv_df["biased_exit_signals"].astype(int)
 
         logger.info(f"saving {config['lookahead_analysis_exportfilename']}")
-        csv_df.to_csv(config['lookahead_analysis_exportfilename'], index=False)
+        csv_df.to_csv(config["lookahead_analysis_exportfilename"], index=False)
 
     @staticmethod
     def calculate_config_overrides(config: Config):
-        if config.get('enable_protections', False):
+        if config.get("enable_protections", False):
             # if protections are used globally, they can produce false positives.
-            config['enable_protections'] = False
-            logger.info('Protections were enabled. '
-                        'Disabling protections now '
-                        'since they could otherwise produce false positives.')
-        if config['targeted_trade_amount'] < config['minimum_trade_amount']:
+            config["enable_protections"] = False
+            logger.info(
+                "Protections were enabled. "
+                "Disabling protections now "
+                "since they could otherwise produce false positives."
+            )
+        if config["targeted_trade_amount"] < config["minimum_trade_amount"]:
             # this combo doesn't make any sense.
             raise OperationalException(
                 "Targeted trade amount can't be smaller than minimum trade amount."
             )
-        if len(config['pairs']) > config.get('max_open_trades', 0):
-            logger.info('Max_open_trades were less than amount of pairs '
-                        'or defined in the strategy. '
-                        'Set max_open_trades to amount of pairs '
-                        'just to avoid false positives.')
-            config['max_open_trades'] = len(config['pairs'])
+        if len(config["pairs"]) > config.get("max_open_trades", 0):
+            logger.info(
+                "Max_open_trades were less than amount of pairs "
+                "or defined in the strategy. "
+                "Set max_open_trades to amount of pairs "
+                "just to avoid false positives."
+            )
+            config["max_open_trades"] = len(config["pairs"])
 
         min_dry_run_wallet = 1000000000
-        if config['dry_run_wallet'] < min_dry_run_wallet:
-            logger.info('Dry run wallet was not set to 1 billion, pushing it up there '
-                        'just to avoid false positives')
-            config['dry_run_wallet'] = min_dry_run_wallet
+        if config["dry_run_wallet"] < min_dry_run_wallet:
+            logger.info(
+                "Dry run wallet was not set to 1 billion, pushing it up there "
+                "just to avoid false positives"
+            )
+            config["dry_run_wallet"] = min_dry_run_wallet
 
-        if 'timerange' not in config:
+        if "timerange" not in config:
             # setting a timerange is enforced here
             raise OperationalException(
                 "Please set a timerange. "
                 "Usually a few months are enough depending on your needs and strategy."
             )
         # fix stake_amount to 10k.
         # in a combination with a wallet size of 1 billion it should always be able to trade
         # no matter if they use custom_stake_amount as a small percentage of wallet size
         # or fixate custom_stake_amount to a certain value.
-        logger.info('fixing stake_amount to 10k')
-        config['stake_amount'] = 10000
+        logger.info("fixing stake_amount to 10k")
+        config["stake_amount"] = 10000
 
         # enforce cache to be 'none', shift it to 'none' if not already
         # (since the default value is 'day')
-        if config.get('backtest_cache') is None:
-            config['backtest_cache'] = 'none'
-        elif config['backtest_cache'] != 'none':
-            logger.info(f"backtest_cache = "
-                        f"{config['backtest_cache']} detected. "
-                        f"Inside lookahead-analysis it is enforced to be 'none'. "
-                        f"Changed it to 'none'")
-            config['backtest_cache'] = 'none'
+        if config.get("backtest_cache") is None:
+            config["backtest_cache"] = "none"
+        elif config["backtest_cache"] != "none":
+            logger.info(
+                f"backtest_cache = "
+                f"{config['backtest_cache']} detected. "
+                f"Inside lookahead-analysis it is enforced to be 'none'. "
+                f"Changed it to 'none'"
+            )
+            config["backtest_cache"] = "none"
         return config
 
     @staticmethod
     def initialize_single_lookahead_analysis(config: Config, strategy_obj: Dict[str, Any]):
-
         logger.info(f"Bias test of {Path(strategy_obj['location']).name} started.")
         start = time.perf_counter()
         current_instance = LookaheadAnalysis(config, strategy_obj)
         current_instance.start()
         elapsed = time.perf_counter() - start
-        logger.info(f"Checking look ahead bias via backtests "
-                    f"of {Path(strategy_obj['location']).name} "
-                    f"took {elapsed:.0f} seconds.")
+        logger.info(
+            f"Checking look ahead bias via backtests "
+            f"of {Path(strategy_obj['location']).name} "
+            f"took {elapsed:.0f} seconds."
+        )
         return current_instance
 
     @staticmethod
     def start(config: Config):
         config = LookaheadAnalysisSubFunctions.calculate_config_overrides(config)
 
         strategy_objs = StrategyResolver.search_all_objects(
-            config, enum_failed=False, recursive=config.get('recursive_strategy_search', False))
+            config, enum_failed=False, recursive=config.get("recursive_strategy_search", False)
+        )
 
         lookaheadAnalysis_instances = []
 
         # unify --strategy and --strategy-list to one list
-        if not (strategy_list := config.get('strategy_list', [])):
-            if config.get('strategy') is None:
+        if not (strategy_list := config.get("strategy_list", [])):
+            if config.get("strategy") is None:
                 raise OperationalException(
                     "No Strategy specified. Please specify a strategy via --strategy or "
                     "--strategy-list"
                 )
-            strategy_list = [config['strategy']]
+            strategy_list = [config["strategy"]]
 
         # check if strategies can be properly loaded, only check them if they can be.
         for strat in strategy_list:
             for strategy_obj in strategy_objs:
-                if strategy_obj['name'] == strat and strategy_obj not in strategy_list:
+                if strategy_obj["name"] == strat and strategy_obj not in strategy_list:
                     lookaheadAnalysis_instances.append(
                         LookaheadAnalysisSubFunctions.initialize_single_lookahead_analysis(
-                            config, strategy_obj))
+                            config, strategy_obj
+                        )
+                    )
                     break
 
         # report the results
         if lookaheadAnalysis_instances:
             LookaheadAnalysisSubFunctions.text_table_lookahead_analysis_instances(
-                config, lookaheadAnalysis_instances)
-            if config.get('lookahead_analysis_exportfilename') is not None:
+                config, lookaheadAnalysis_instances
+            )
+            if config.get("lookahead_analysis_exportfilename") is not None:
                 LookaheadAnalysisSubFunctions.export_to_csv(config, lookaheadAnalysis_instances)
         else:
-            logger.error("There were no strategies specified neither through "
-                         "--strategy nor through "
-                         "--strategy-list "
-                         "or timeframe was not specified.")
+            logger.error(
+                "There were no strategies specified neither through "
+                "--strategy nor through "
+                "--strategy-list "
+                "or timeframe was not specified."
+            )
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/analysis/recursive.py` & `freqtrade-2024.5/freqtrade/optimize/analysis/recursive.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,124 +4,125 @@
 from datetime import timedelta
 from pathlib import Path
 from typing import Any, Dict, List
 
 from pandas import DataFrame
 
 from freqtrade.exchange import timeframe_to_minutes
-from freqtrade.loggers.set_log_levels import (reduce_verbosity_for_bias_tester,
-                                              restore_verbosity_for_bias_tester)
+from freqtrade.loggers.set_log_levels import (
+    reduce_verbosity_for_bias_tester,
+    restore_verbosity_for_bias_tester,
+)
 from freqtrade.optimize.backtesting import Backtesting
 from freqtrade.optimize.base_analysis import BaseAnalysis, VarHolder
 
 
 logger = logging.getLogger(__name__)
 
 
 class RecursiveAnalysis(BaseAnalysis):
-
     def __init__(self, config: Dict[str, Any], strategy_obj: Dict):
-
-        self._startup_candle = config.get('startup_candle', [199, 399, 499, 999, 1999])
+        self._startup_candle = config.get("startup_candle", [199, 399, 499, 999, 1999])
 
         super().__init__(config, strategy_obj)
 
         self.partial_varHolder_array: List[VarHolder] = []
         self.partial_varHolder_lookahead_array: List[VarHolder] = []
 
         self.dict_recursive: Dict[str, Any] = dict()
 
     # For recursive bias check
     # analyzes two data frames with processed indicators and shows differences between them.
     def analyze_indicators(self):
-
-        pair_to_check = self.local_config['pairs'][0]
+        pair_to_check = self.local_config["pairs"][0]
         logger.info("Start checking for recursive bias")
 
         # check and report signals
         base_last_row = self.full_varHolder.indicators[pair_to_check].iloc[-1]
 
         for part in self.partial_varHolder_array:
             part_last_row = part.indicators[pair_to_check].iloc[-1]
 
             compare_df = base_last_row.compare(part_last_row)
             if compare_df.shape[0] > 0:
                 # print(compare_df)
                 for col_name, values in compare_df.items():
                     # print(col_name)
-                    if 'other' == col_name:
+                    if "other" == col_name:
                         continue
                     indicators = values.index
 
                     for indicator in indicators:
-                        if (indicator not in self.dict_recursive):
+                        if indicator not in self.dict_recursive:
                             self.dict_recursive[indicator] = {}
 
                         values_diff = compare_df.loc[indicator]
-                        values_diff_self = values_diff.loc['self']
-                        values_diff_other = values_diff.loc['other']
+                        values_diff_self = values_diff.loc["self"]
+                        values_diff_other = values_diff.loc["other"]
                         diff = (values_diff_other - values_diff_self) / values_diff_self * 100
 
                         self.dict_recursive[indicator][part.startup_candle] = f"{diff:.3f}%"
 
             else:
                 logger.info("No variance on indicator(s) found due to recursive formula.")
                 break
 
     # For lookahead bias check
     # analyzes two data frames with processed indicators and shows differences between them.
     def analyze_indicators_lookahead(self):
-
-        pair_to_check = self.local_config['pairs'][0]
+        pair_to_check = self.local_config["pairs"][0]
         logger.info("Start checking for lookahead bias on indicators only")
 
         part = self.partial_varHolder_lookahead_array[0]
         part_last_row = part.indicators[pair_to_check].iloc[-1]
-        date_to_check = part_last_row['date']
-        index_to_get = (self.full_varHolder.indicators[pair_to_check]['date'] == date_to_check)
+        date_to_check = part_last_row["date"]
+        index_to_get = self.full_varHolder.indicators[pair_to_check]["date"] == date_to_check
         base_row_check = self.full_varHolder.indicators[pair_to_check].loc[index_to_get].iloc[-1]
 
-        check_time = part.to_dt.strftime('%Y-%m-%dT%H:%M:%S')
+        check_time = part.to_dt.strftime("%Y-%m-%dT%H:%M:%S")
 
         logger.info(f"Check indicators at {check_time}")
         # logger.info(f"vs {part_timerange} with {part.startup_candle} startup candle")
 
         compare_df = base_row_check.compare(part_last_row)
         if compare_df.shape[0] > 0:
             # print(compare_df)
             for col_name, values in compare_df.items():
                 # print(col_name)
-                if 'other' == col_name:
+                if "other" == col_name:
                     continue
                 indicators = values.index
 
                 for indicator in indicators:
                     logger.info(f"=> found lookahead in indicator {indicator}")
                     # logger.info("base value {:.5f}".format(values_diff_self))
                     # logger.info("part value {:.5f}".format(values_diff_other))
 
         else:
             logger.info("No lookahead bias on indicators found.")
 
     def prepare_data(self, varholder: VarHolder, pairs_to_load: List[DataFrame]):
-
-        if 'freqai' in self.local_config and 'identifier' in self.local_config['freqai']:
+        if "freqai" in self.local_config and "identifier" in self.local_config["freqai"]:
             # purge previous data if the freqai model is defined
             # (to be sure nothing is carried over from older backtests)
-            path_to_current_identifier = (
-                Path(f"{self.local_config['user_data_dir']}/models/"
-                     f"{self.local_config['freqai']['identifier']}").resolve())
+            path_to_current_identifier = Path(
+                f"{self.local_config['user_data_dir']}/models/"
+                f"{self.local_config['freqai']['identifier']}"
+            ).resolve()
             # remove folder and its contents
             if Path.exists(path_to_current_identifier):
                 shutil.rmtree(path_to_current_identifier)
 
         prepare_data_config = deepcopy(self.local_config)
-        prepare_data_config['timerange'] = (str(self.dt_to_timestamp(varholder.from_dt)) + "-" +
-                                            str(self.dt_to_timestamp(varholder.to_dt)))
-        prepare_data_config['exchange']['pair_whitelist'] = pairs_to_load
+        prepare_data_config["timerange"] = (
+            str(self.dt_to_timestamp(varholder.from_dt))
+            + "-"
+            + str(self.dt_to_timestamp(varholder.to_dt))
+        )
+        prepare_data_config["exchange"]["pair_whitelist"] = pairs_to_load
 
         backtesting = Backtesting(prepare_data_config, self.exchange)
         self.exchange = backtesting.exchange
         backtesting._set_strategy(backtesting.strategylist[0])
 
         varholder.data, varholder.timerange = backtesting.load_bt_data()
         backtesting.load_bt_data_detail()
@@ -133,34 +134,33 @@
         logger.info(f"Calculating indicators using startup candle of {startup_candle}.")
         partial_varHolder = VarHolder()
 
         partial_varHolder.from_dt = start_date
         partial_varHolder.to_dt = self.full_varHolder.to_dt
         partial_varHolder.startup_candle = startup_candle
 
-        self.local_config['startup_candle_count'] = startup_candle
+        self.local_config["startup_candle_count"] = startup_candle
 
-        self.prepare_data(partial_varHolder, self.local_config['pairs'])
+        self.prepare_data(partial_varHolder, self.local_config["pairs"])
 
         self.partial_varHolder_array.append(partial_varHolder)
 
     def fill_partial_varholder_lookahead(self, end_date):
         logger.info("Calculating indicators to test lookahead on indicators.")
 
         partial_varHolder = VarHolder()
 
         partial_varHolder.from_dt = self.full_varHolder.from_dt
         partial_varHolder.to_dt = end_date
 
-        self.prepare_data(partial_varHolder, self.local_config['pairs'])
+        self.prepare_data(partial_varHolder, self.local_config["pairs"])
 
         self.partial_varHolder_lookahead_array.append(partial_varHolder)
 
     def start(self) -> None:
-
         super().start()
 
         reduce_verbosity_for_bias_tester()
         start_date_full = self.full_varHolder.from_dt
         end_date_full = self.full_varHolder.to_dt
 
         timeframe_minutes = timeframe_to_minutes(self.full_varHolder.timeframe)
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/analysis/recursive_helpers.py` & `freqtrade-2024.5/freqtrade/optimize/analysis/recursive_helpers.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,98 +9,106 @@
 from freqtrade.resolvers import StrategyResolver
 
 
 logger = logging.getLogger(__name__)
 
 
 class RecursiveAnalysisSubFunctions:
-
     @staticmethod
-    def text_table_recursive_analysis_instances(
-            recursive_instances: List[RecursiveAnalysis]):
+    def text_table_recursive_analysis_instances(recursive_instances: List[RecursiveAnalysis]):
         startups = recursive_instances[0]._startup_candle
-        headers = ['indicators']
+        headers = ["indicators"]
         for candle in startups:
             headers.append(candle)
 
         data = []
         for inst in recursive_instances:
             if len(inst.dict_recursive) > 0:
                 for indicator, values in inst.dict_recursive.items():
                     temp_data = [indicator]
                     for candle in startups:
-                        temp_data.append(values.get(int(candle), '-'))
+                        temp_data.append(values.get(int(candle), "-"))
                     data.append(temp_data)
 
         if len(data) > 0:
             from tabulate import tabulate
+
             table = tabulate(data, headers=headers, tablefmt="orgtbl")
             print(table)
             return table, headers, data
 
         return None, None, data
 
     @staticmethod
     def calculate_config_overrides(config: Config):
-        if 'timerange' not in config:
+        if "timerange" not in config:
             # setting a timerange is enforced here
             raise OperationalException(
                 "Please set a timerange. "
                 "A timerange of 5000 candles are enough for recursive analysis."
             )
 
-        if config.get('backtest_cache') is None:
-            config['backtest_cache'] = 'none'
-        elif config['backtest_cache'] != 'none':
-            logger.info(f"backtest_cache = "
-                        f"{config['backtest_cache']} detected. "
-                        f"Inside recursive-analysis it is enforced to be 'none'. "
-                        f"Changed it to 'none'")
-            config['backtest_cache'] = 'none'
+        if config.get("backtest_cache") is None:
+            config["backtest_cache"] = "none"
+        elif config["backtest_cache"] != "none":
+            logger.info(
+                f"backtest_cache = "
+                f"{config['backtest_cache']} detected. "
+                f"Inside recursive-analysis it is enforced to be 'none'. "
+                f"Changed it to 'none'"
+            )
+            config["backtest_cache"] = "none"
         return config
 
     @staticmethod
     def initialize_single_recursive_analysis(config: Config, strategy_obj: Dict[str, Any]):
-
         logger.info(f"Recursive test of {Path(strategy_obj['location']).name} started.")
         start = time.perf_counter()
         current_instance = RecursiveAnalysis(config, strategy_obj)
         current_instance.start()
         elapsed = time.perf_counter() - start
-        logger.info(f"Checking recursive and indicator-only lookahead bias of indicators "
-                    f"of {Path(strategy_obj['location']).name} "
-                    f"took {elapsed:.0f} seconds.")
+        logger.info(
+            f"Checking recursive and indicator-only lookahead bias of indicators "
+            f"of {Path(strategy_obj['location']).name} "
+            f"took {elapsed:.0f} seconds."
+        )
         return current_instance
 
     @staticmethod
     def start(config: Config):
         config = RecursiveAnalysisSubFunctions.calculate_config_overrides(config)
 
         strategy_objs = StrategyResolver.search_all_objects(
-            config, enum_failed=False, recursive=config.get('recursive_strategy_search', False))
+            config, enum_failed=False, recursive=config.get("recursive_strategy_search", False)
+        )
 
         RecursiveAnalysis_instances = []
 
         # unify --strategy and --strategy-list to one list
-        if not (strategy_list := config.get('strategy_list', [])):
-            if config.get('strategy') is None:
+        if not (strategy_list := config.get("strategy_list", [])):
+            if config.get("strategy") is None:
                 raise OperationalException(
                     "No Strategy specified. Please specify a strategy via --strategy"
                 )
-            strategy_list = [config['strategy']]
+            strategy_list = [config["strategy"]]
 
         # check if strategies can be properly loaded, only check them if they can be.
         for strat in strategy_list:
             for strategy_obj in strategy_objs:
-                if strategy_obj['name'] == strat and strategy_obj not in strategy_list:
+                if strategy_obj["name"] == strat and strategy_obj not in strategy_list:
                     RecursiveAnalysis_instances.append(
                         RecursiveAnalysisSubFunctions.initialize_single_recursive_analysis(
-                            config, strategy_obj))
+                            config, strategy_obj
+                        )
+                    )
                     break
 
         # report the results
         if RecursiveAnalysis_instances:
             RecursiveAnalysisSubFunctions.text_table_recursive_analysis_instances(
-                RecursiveAnalysis_instances)
+                RecursiveAnalysis_instances
+            )
         else:
-            logger.error("There was no strategy specified through --strategy "
-                         "or timeframe was not specified.")
+            logger.error(
+                "There was no strategy specified through --strategy "
+                "or timeframe was not specified."
+            )
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/backtest_caching.py` & `freqtrade-2024.5/freqtrade/optimize/backtest_caching.py`

 * *Files 14% similar despite different names*

```diff
@@ -13,28 +13,32 @@
     :param strategy: strategy object.
     :return: hex string id.
     """
     digest = hashlib.sha1()
     config = deepcopy(strategy.config)
 
     # Options that have no impact on results of individual backtest.
-    not_important_keys = ('strategy_list', 'original_config', 'telegram', 'api_server')
+    not_important_keys = ("strategy_list", "original_config", "telegram", "api_server")
     for k in not_important_keys:
         if k in config:
             del config[k]
 
     # Explicitly allow NaN values (e.g. max_open_trades).
     # as it does not matter for getting the hash.
-    digest.update(rapidjson.dumps(config, default=str,
-                                  number_mode=rapidjson.NM_NAN).encode('utf-8'))
+    digest.update(
+        rapidjson.dumps(config, default=str, number_mode=rapidjson.NM_NAN).encode("utf-8")
+    )
     # Include _ft_params_from_file - so changing parameter files cause cache eviction
-    digest.update(rapidjson.dumps(
-        strategy._ft_params_from_file, default=str, number_mode=rapidjson.NM_NAN).encode('utf-8'))
-    with Path(strategy.__file__).open('rb') as fp:
+    digest.update(
+        rapidjson.dumps(
+            strategy._ft_params_from_file, default=str, number_mode=rapidjson.NM_NAN
+        ).encode("utf-8")
+    )
+    with Path(strategy.__file__).open("rb") as fp:
         digest.update(fp.read())
     return digest.hexdigest().lower()
 
 
 def get_backtest_metadata_filename(filename: Union[Path, str]) -> Path:
     """Return metadata filename for specified backtest results file."""
     filename = Path(filename)
-    return filename.parent / Path(f'{filename.stem}.meta{filename.suffix}')
+    return filename.parent / Path(f"{filename.stem}.meta{filename.suffix}")
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/backtesting.py` & `freqtrade-2024.5/freqtrade/optimize/backtesting.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=missing-docstring, W0212, too-many-arguments
 
 """
 This module contains the backtesting logic
 """
+
 import logging
 from collections import defaultdict
 from copy import deepcopy
 from datetime import datetime, timedelta, timezone
 from typing import Any, Dict, List, Optional, Tuple
 
 from numpy import nan
@@ -16,36 +17,56 @@
 from freqtrade.configuration import TimeRange, validate_config_consistency
 from freqtrade.constants import DATETIME_PRINT_FORMAT, Config, IntOrInf, LongShort
 from freqtrade.data import history
 from freqtrade.data.btanalysis import find_existing_backtest_stats, trade_list_to_dataframe
 from freqtrade.data.converter import trim_dataframe, trim_dataframes
 from freqtrade.data.dataprovider import DataProvider
 from freqtrade.data.metrics import combined_dataframes_with_rel_mean
-from freqtrade.enums import (BacktestState, CandleType, ExitCheckTuple, ExitType, RunMode,
-                             TradingMode)
+from freqtrade.enums import (
+    BacktestState,
+    CandleType,
+    ExitCheckTuple,
+    ExitType,
+    RunMode,
+    TradingMode,
+)
 from freqtrade.exceptions import DependencyException, OperationalException
-from freqtrade.exchange import (amount_to_contract_precision, price_to_precision,
-                                timeframe_to_seconds)
+from freqtrade.exchange import (
+    amount_to_contract_precision,
+    price_to_precision,
+    timeframe_to_seconds,
+)
 from freqtrade.exchange.exchange import Exchange
 from freqtrade.mixins import LoggingMixin
 from freqtrade.optimize.backtest_caching import get_strategy_run_id
 from freqtrade.optimize.bt_progress import BTProgress
-from freqtrade.optimize.optimize_reports import (generate_backtest_stats, generate_rejected_signals,
-                                                 generate_trade_signal_candles,
-                                                 show_backtest_results,
-                                                 store_backtest_analysis_results,
-                                                 store_backtest_stats)
-from freqtrade.persistence import (CustomDataWrapper, LocalTrade, Order, PairLocks, Trade,
-                                   disable_database_use, enable_database_use)
+from freqtrade.optimize.optimize_reports import (
+    generate_backtest_stats,
+    generate_rejected_signals,
+    generate_trade_signal_candles,
+    show_backtest_results,
+    store_backtest_analysis_results,
+    store_backtest_stats,
+)
+from freqtrade.persistence import (
+    CustomDataWrapper,
+    LocalTrade,
+    Order,
+    PairLocks,
+    Trade,
+    disable_database_use,
+    enable_database_use,
+)
 from freqtrade.plugins.pairlistmanager import PairListManager
 from freqtrade.plugins.protectionmanager import ProtectionManager
 from freqtrade.resolvers import ExchangeResolver, StrategyResolver
 from freqtrade.strategy.interface import IStrategy
 from freqtrade.strategy.strategy_wrapper import strategy_safe_wrapper
 from freqtrade.types import BacktestResultType, get_BacktestResultType_default
+from freqtrade.util import FtPrecise
 from freqtrade.util.migrations import migrate_data
 from freqtrade.wallets import Wallets
 
 
 logger = logging.getLogger(__name__)
 
 # Indexes for backtest tuples
@@ -59,151 +80,177 @@
 SHORT_IDX = 7
 ESHORT_IDX = 8  # Exit short
 ENTER_TAG_IDX = 9
 EXIT_TAG_IDX = 10
 
 # Every change to this headers list must evaluate further usages of the resulting tuple
 # and eventually change the constants for indexes at the top
-HEADERS = ['date', 'open', 'high', 'low', 'close', 'enter_long', 'exit_long',
-           'enter_short', 'exit_short', 'enter_tag', 'exit_tag']
+HEADERS = [
+    "date",
+    "open",
+    "high",
+    "low",
+    "close",
+    "enter_long",
+    "exit_long",
+    "enter_short",
+    "exit_short",
+    "enter_tag",
+    "exit_tag",
+]
 
 
 class Backtesting:
     """
     Backtesting class, this class contains all the logic to run a backtest
 
     To run a backtest:
     backtesting = Backtesting(config)
     backtesting.start()
     """
 
     def __init__(self, config: Config, exchange: Optional[Exchange] = None) -> None:
-
         LoggingMixin.show_output = False
         self.config = config
         self.results: BacktestResultType = get_BacktestResultType_default()
         self.trade_id_counter: int = 0
         self.order_id_counter: int = 0
 
-        config['dry_run'] = True
+        config["dry_run"] = True
         self.run_ids: Dict[str, str] = {}
         self.strategylist: List[IStrategy] = []
         self.all_results: Dict[str, Dict] = {}
         self.processed_dfs: Dict[str, Dict] = {}
         self.rejected_dict: Dict[str, List] = {}
         self.rejected_df: Dict[str, Dict] = {}
 
-        self._exchange_name = self.config['exchange']['name']
+        self._exchange_name = self.config["exchange"]["name"]
         if not exchange:
             exchange = ExchangeResolver.load_exchange(self.config, load_leverage_tiers=True)
         self.exchange = exchange
 
         self.dataprovider = DataProvider(self.config, self.exchange)
 
-        if self.config.get('strategy_list'):
-            if self.config.get('freqai', {}).get('enabled', False):
-                logger.warning("Using --strategy-list with FreqAI REQUIRES all strategies "
-                               "to have identical feature_engineering_* functions.")
-            for strat in list(self.config['strategy_list']):
+        if self.config.get("strategy_list"):
+            if self.config.get("freqai", {}).get("enabled", False):
+                logger.warning(
+                    "Using --strategy-list with FreqAI REQUIRES all strategies "
+                    "to have identical feature_engineering_* functions."
+                )
+            for strat in list(self.config["strategy_list"]):
                 stratconf = deepcopy(self.config)
-                stratconf['strategy'] = strat
+                stratconf["strategy"] = strat
                 self.strategylist.append(StrategyResolver.load_strategy(stratconf))
                 validate_config_consistency(stratconf)
 
         else:
             # No strategy list specified, only one strategy
             self.strategylist.append(StrategyResolver.load_strategy(self.config))
             validate_config_consistency(self.config)
 
         if "timeframe" not in self.config:
-            raise OperationalException("Timeframe needs to be set in either "
-                                       "configuration or as cli argument `--timeframe 5m`")
-        self.timeframe = str(self.config.get('timeframe'))
+            raise OperationalException(
+                "Timeframe needs to be set in either "
+                "configuration or as cli argument `--timeframe 5m`"
+            )
+        self.timeframe = str(self.config.get("timeframe"))
         self.timeframe_secs = timeframe_to_seconds(self.timeframe)
         self.timeframe_min = self.timeframe_secs // 60
         self.timeframe_td = timedelta(seconds=self.timeframe_secs)
         self.disable_database_use()
         self.init_backtest_detail()
         self.pairlists = PairListManager(self.exchange, self.config, self.dataprovider)
         self._validate_pairlists_for_backtesting()
 
         self.dataprovider.add_pairlisthandler(self.pairlists)
         self.pairlists.refresh_pairlist()
 
         if len(self.pairlists.whitelist) == 0:
             raise OperationalException("No pair in whitelist.")
 
-        if config.get('fee', None) is not None:
-            self.fee = config['fee']
+        if config.get("fee", None) is not None:
+            self.fee = config["fee"]
+            logger.info(f"Using fee {self.fee:.4%} from config.")
         else:
-            self.fee = self.exchange.get_fee(symbol=self.pairlists.whitelist[0])
+            fees = [
+                self.exchange.get_fee(
+                    symbol=self.pairlists.whitelist[0],
+                    taker_or_maker=mt,  # type: ignore
+                )
+                for mt in ("taker", "maker")
+            ]
+            self.fee = max(fee for fee in fees if fee is not None)
+            logger.info(f"Using fee {self.fee:.4%} - worst case fee from exchange (lowest tier).")
         self.precision_mode = self.exchange.precisionMode
 
-        if self.config.get('freqai_backtest_live_models', False):
+        if self.config.get("freqai_backtest_live_models", False):
             from freqtrade.freqai.utils import get_timerange_backtest_live_models
-            self.config['timerange'] = get_timerange_backtest_live_models(self.config)
+
+            self.config["timerange"] = get_timerange_backtest_live_models(self.config)
 
         self.timerange = TimeRange.parse_timerange(
-            None if self.config.get('timerange') is None else str(self.config.get('timerange')))
+            None if self.config.get("timerange") is None else str(self.config.get("timerange"))
+        )
 
         # Get maximum required startup period
         self.required_startup = max([strat.startup_candle_count for strat in self.strategylist])
         self.exchange.validate_required_startup_candles(self.required_startup, self.timeframe)
 
         # Add maximum startup candle count to configuration for informative pairs support
-        self.config['startup_candle_count'] = self.required_startup
+        self.config["startup_candle_count"] = self.required_startup
 
-        if self.config.get('freqai', {}).get('enabled', False):
+        if self.config.get("freqai", {}).get("enabled", False):
             # For FreqAI, increase the required_startup to includes the training data
             # This value should NOT be written to startup_candle_count
             self.required_startup = self.dataprovider.get_required_startup(self.timeframe)
 
-        self.trading_mode: TradingMode = config.get('trading_mode', TradingMode.SPOT)
+        self.trading_mode: TradingMode = config.get("trading_mode", TradingMode.SPOT)
         # strategies which define "can_short=True" will fail to load in Spot mode.
         self._can_short = self.trading_mode != TradingMode.SPOT
-        self._position_stacking: bool = self.config.get('position_stacking', False)
-        self.enable_protections: bool = self.config.get('enable_protections', False)
+        self._position_stacking: bool = self.config.get("position_stacking", False)
+        self.enable_protections: bool = self.config.get("enable_protections", False)
         migrate_data(config, self.exchange)
 
         self.init_backtest()
 
     def _validate_pairlists_for_backtesting(self):
-        if 'VolumePairList' in self.pairlists.name_list:
-            raise OperationalException("VolumePairList not allowed for backtesting. "
-                                       "Please use StaticPairList instead.")
-        if 'PerformanceFilter' in self.pairlists.name_list:
+        if "VolumePairList" in self.pairlists.name_list:
+            raise OperationalException(
+                "VolumePairList not allowed for backtesting. Please use StaticPairList instead."
+            )
+        if "PerformanceFilter" in self.pairlists.name_list:
             raise OperationalException("PerformanceFilter not allowed for backtesting.")
 
-        if len(self.strategylist) > 1 and 'PrecisionFilter' in self.pairlists.name_list:
+        if len(self.strategylist) > 1 and "PrecisionFilter" in self.pairlists.name_list:
             raise OperationalException(
                 "PrecisionFilter not allowed for backtesting multiple strategies."
             )
 
     @staticmethod
     def cleanup():
         LoggingMixin.show_output = True
         enable_database_use()
 
     def init_backtest_detail(self) -> None:
         # Load detail timeframe if specified
-        self.timeframe_detail = str(self.config.get('timeframe_detail', ''))
+        self.timeframe_detail = str(self.config.get("timeframe_detail", ""))
         if self.timeframe_detail:
             timeframe_detail_secs = timeframe_to_seconds(self.timeframe_detail)
             self.timeframe_detail_td = timedelta(seconds=timeframe_detail_secs)
             if self.timeframe_secs <= timeframe_detail_secs:
                 raise OperationalException(
-                    "Detail timeframe must be smaller than strategy timeframe.")
+                    "Detail timeframe must be smaller than strategy timeframe."
+                )
 
         else:
             self.timeframe_detail_td = timedelta(seconds=0)
         self.detail_data: Dict[str, DataFrame] = {}
         self.futures_data: Dict[str, DataFrame] = {}
 
     def init_backtest(self):
-
         self.prepare_backtest(False)
 
         self.wallets = Wallets(self.config, self.exchange, is_backtest=True)
 
         self.progress = BTProgress()
         self.abort = False
 
@@ -214,121 +261,125 @@
         self.strategy: IStrategy = strategy
         strategy.dp = self.dataprovider
         # Attach Wallets to Strategy baseclass
         strategy.wallets = self.wallets
         # Set stoploss_on_exchange to false for backtesting,
         # since a "perfect" stoploss-exit is assumed anyway
         # And the regular "stoploss" function would not apply to that case
-        self.strategy.order_types['stoploss_on_exchange'] = False
+        self.strategy.order_types["stoploss_on_exchange"] = False
         # Update can_short flag
         self._can_short = self.trading_mode != TradingMode.SPOT and strategy.can_short
 
         self.strategy.ft_bot_start()
 
     def _load_protections(self, strategy: IStrategy):
-        if self.config.get('enable_protections', False):
+        if self.config.get("enable_protections", False):
             conf = self.config
-            if hasattr(strategy, 'protections'):
+            if hasattr(strategy, "protections"):
                 conf = deepcopy(conf)
-                conf['protections'] = strategy.protections
+                conf["protections"] = strategy.protections
             self.protections = ProtectionManager(self.config, strategy.protections)
 
     def load_bt_data(self) -> Tuple[Dict[str, DataFrame], TimeRange]:
         """
         Loads backtest data and returns the data combined with the timerange
         as tuple.
         """
         self.progress.init_step(BacktestState.DATALOAD, 1)
 
         data = history.load_data(
-            datadir=self.config['datadir'],
+            datadir=self.config["datadir"],
             pairs=self.pairlists.whitelist,
             timeframe=self.timeframe,
             timerange=self.timerange,
             startup_candles=self.required_startup,
             fail_without_data=True,
-            data_format=self.config['dataformat_ohlcv'],
-            candle_type=self.config.get('candle_type_def', CandleType.SPOT)
+            data_format=self.config["dataformat_ohlcv"],
+            candle_type=self.config.get("candle_type_def", CandleType.SPOT),
         )
 
         min_date, max_date = history.get_timerange(data)
 
-        logger.info(f'Loading data from {min_date.strftime(DATETIME_PRINT_FORMAT)} '
-                    f'up to {max_date.strftime(DATETIME_PRINT_FORMAT)} '
-                    f'({(max_date - min_date).days} days).')
+        logger.info(
+            f"Loading data from {min_date.strftime(DATETIME_PRINT_FORMAT)} "
+            f"up to {max_date.strftime(DATETIME_PRINT_FORMAT)} "
+            f"({(max_date - min_date).days} days)."
+        )
 
         # Adjust startts forward if not enough data is available
-        self.timerange.adjust_start_if_necessary(timeframe_to_seconds(self.timeframe),
-                                                 self.required_startup, min_date)
+        self.timerange.adjust_start_if_necessary(
+            timeframe_to_seconds(self.timeframe), self.required_startup, min_date
+        )
 
         self.progress.set_new_value(1)
         return data, self.timerange
 
     def load_bt_data_detail(self) -> None:
         """
         Loads backtest detail data (smaller timeframe) if necessary.
         """
         if self.timeframe_detail:
             self.detail_data = history.load_data(
-                datadir=self.config['datadir'],
+                datadir=self.config["datadir"],
                 pairs=self.pairlists.whitelist,
                 timeframe=self.timeframe_detail,
                 timerange=self.timerange,
                 startup_candles=0,
                 fail_without_data=True,
-                data_format=self.config['dataformat_ohlcv'],
-                candle_type=self.config.get('candle_type_def', CandleType.SPOT)
+                data_format=self.config["dataformat_ohlcv"],
+                candle_type=self.config.get("candle_type_def", CandleType.SPOT),
             )
         else:
             self.detail_data = {}
         if self.trading_mode == TradingMode.FUTURES:
-            self.funding_fee_timeframe: str = self.exchange.get_option('funding_fee_timeframe')
+            self.funding_fee_timeframe: str = self.exchange.get_option("funding_fee_timeframe")
             self.funding_fee_timeframe_secs: int = timeframe_to_seconds(self.funding_fee_timeframe)
-            mark_timeframe: str = self.exchange.get_option('mark_ohlcv_timeframe')
+            mark_timeframe: str = self.exchange.get_option("mark_ohlcv_timeframe")
 
             # Load additional futures data.
             funding_rates_dict = history.load_data(
-                datadir=self.config['datadir'],
+                datadir=self.config["datadir"],
                 pairs=self.pairlists.whitelist,
                 timeframe=self.funding_fee_timeframe,
                 timerange=self.timerange,
                 startup_candles=0,
                 fail_without_data=True,
-                data_format=self.config['dataformat_ohlcv'],
-                candle_type=CandleType.FUNDING_RATE
+                data_format=self.config["dataformat_ohlcv"],
+                candle_type=CandleType.FUNDING_RATE,
             )
 
             # For simplicity, assign to CandleType.Mark (might contain index candles!)
             mark_rates_dict = history.load_data(
-                datadir=self.config['datadir'],
+                datadir=self.config["datadir"],
                 pairs=self.pairlists.whitelist,
                 timeframe=mark_timeframe,
                 timerange=self.timerange,
                 startup_candles=0,
                 fail_without_data=True,
-                data_format=self.config['dataformat_ohlcv'],
-                candle_type=CandleType.from_string(self.exchange.get_option("mark_ohlcv_price"))
+                data_format=self.config["dataformat_ohlcv"],
+                candle_type=CandleType.from_string(self.exchange.get_option("mark_ohlcv_price")),
             )
             # Combine data to avoid combining the data per trade.
             unavailable_pairs = []
             for pair in self.pairlists.whitelist:
                 if pair not in self.exchange._leverage_tiers:
                     unavailable_pairs.append(pair)
                     continue
 
                 self.futures_data[pair] = self.exchange.combine_funding_and_mark(
                     funding_rates=funding_rates_dict[pair],
                     mark_rates=mark_rates_dict[pair],
-                    futures_funding_rate=self.config.get('futures_funding_rate', None),
+                    futures_funding_rate=self.config.get("futures_funding_rate", None),
                 )
 
             if unavailable_pairs:
                 raise OperationalException(
                     f"Pairs {', '.join(unavailable_pairs)} got no leverage tiers available. "
-                    "It is therefore impossible to backtest with this pair at the moment.")
+                    "It is therefore impossible to backtest with this pair at the moment."
+                )
         else:
             self.futures_data = {}
 
     def disable_database_use(self):
         disable_database_use(self.timeframe)
 
     def prepare_backtest(self, enable_protections):
@@ -375,61 +426,71 @@
         for pair in processed.keys():
             pair_data = processed[pair]
             self.check_abort()
             self.progress.increment()
 
             if not pair_data.empty:
                 # Cleanup from prior runs
-                pair_data.drop(HEADERS[5:] + ['buy', 'sell'], axis=1, errors='ignore')
-            df_analyzed = self.strategy.ft_advise_signals(pair_data, {'pair': pair})
+                pair_data.drop(HEADERS[5:] + ["buy", "sell"], axis=1, errors="ignore")
+            df_analyzed = self.strategy.ft_advise_signals(pair_data, {"pair": pair})
             # Update dataprovider cache
             self.dataprovider._set_cached_df(
-                pair, self.timeframe, df_analyzed, self.config['candle_type_def'])
+                pair, self.timeframe, df_analyzed, self.config["candle_type_def"]
+            )
 
             # Trim startup period from analyzed dataframe
             df_analyzed = processed[pair] = pair_data = trim_dataframe(
-                df_analyzed, self.timerange, startup_candles=self.required_startup)
+                df_analyzed, self.timerange, startup_candles=self.required_startup
+            )
 
             # Create a copy of the dataframe before shifting, that way the entry signal/tag
             # remains on the correct candle for callbacks.
             df_analyzed = df_analyzed.copy()
 
             # To avoid using data from future, we use entry/exit signals shifted
             # from the previous candle
             for col in HEADERS[5:]:
-                tag_col = col in ('enter_tag', 'exit_tag')
+                tag_col = col in ("enter_tag", "exit_tag")
                 if col in df_analyzed.columns:
-                    df_analyzed[col] = df_analyzed.loc[:, col].replace(
-                        [nan], [0 if not tag_col else None]).shift(1)
+                    df_analyzed[col] = (
+                        df_analyzed.loc[:, col]
+                        .replace([nan], [0 if not tag_col else None])
+                        .shift(1)
+                    )
                 elif not df_analyzed.empty:
                     df_analyzed[col] = 0 if not tag_col else None
 
             df_analyzed = df_analyzed.drop(df_analyzed.head(1).index)
 
             # Convert from Pandas to list for performance reasons
             # (Looping Pandas is slow.)
             data[pair] = df_analyzed[HEADERS].values.tolist() if not df_analyzed.empty else []
         return data
 
-    def _get_close_rate(self, row: Tuple, trade: LocalTrade, exit: ExitCheckTuple,
-                        trade_dur: int) -> float:
+    def _get_close_rate(
+        self, row: Tuple, trade: LocalTrade, exit: ExitCheckTuple, trade_dur: int
+    ) -> float:
         """
         Get close rate for backtesting result
         """
         # Special handling if high or low hit STOP_LOSS or ROI
         if exit.exit_type in (
-                ExitType.STOP_LOSS, ExitType.TRAILING_STOP_LOSS, ExitType.LIQUIDATION):
+            ExitType.STOP_LOSS,
+            ExitType.TRAILING_STOP_LOSS,
+            ExitType.LIQUIDATION,
+        ):
             return self._get_close_rate_for_stoploss(row, trade, exit, trade_dur)
         elif exit.exit_type == (ExitType.ROI):
             return self._get_close_rate_for_roi(row, trade, exit, trade_dur)
         else:
             return row[OPEN_IDX]
 
-    def _get_close_rate_for_stoploss(self, row: Tuple, trade: LocalTrade, exit: ExitCheckTuple,
-                                     trade_dur: int) -> float:
+    def _get_close_rate_for_stoploss(
+        self, row: Tuple, trade: LocalTrade, exit: ExitCheckTuple, trade_dur: int
+    ) -> float:
         # our stoploss was already lower than candle high,
         # possibly due to a cancelled trade exit.
         # exit at open price.
         is_short = trade.is_short or False
         leverage = trade.leverage or 1.0
         side_1 = -1 if is_short else 1
         if exit.exit_type == ExitType.LIQUIDATION and trade.liquidation_price:
@@ -445,40 +506,45 @@
                 return row[OPEN_IDX]
 
         # Special case: trailing triggers within same candle as trade opened. Assume most
         # pessimistic price movement, which is moving just enough to arm stoploss and
         # immediately going down to stop price.
         if exit.exit_type == ExitType.TRAILING_STOP_LOSS and trade_dur == 0:
             if (
-                not self.strategy.use_custom_stoploss and self.strategy.trailing_stop
+                not self.strategy.use_custom_stoploss
+                and self.strategy.trailing_stop
                 and self.strategy.trailing_only_offset_is_reached
                 and self.strategy.trailing_stop_positive_offset is not None
                 and self.strategy.trailing_stop_positive
             ):
                 # Worst case: price reaches stop_positive_offset and dives down.
-                stop_rate = (row[OPEN_IDX] *
-                             (1 + side_1 * abs(self.strategy.trailing_stop_positive_offset) -
-                              side_1 * abs(self.strategy.trailing_stop_positive / leverage)))
+                stop_rate = row[OPEN_IDX] * (
+                    1
+                    + side_1 * abs(self.strategy.trailing_stop_positive_offset)
+                    - side_1 * abs(self.strategy.trailing_stop_positive / leverage)
+                )
             else:
                 # Worst case: price ticks tiny bit above open and dives down.
-                stop_rate = row[OPEN_IDX] * (1 - side_1 * abs(
-                    (trade.stop_loss_pct or 0.0) / leverage))
+                stop_rate = row[OPEN_IDX] * (
+                    1 - side_1 * abs((trade.stop_loss_pct or 0.0) / leverage)
+                )
 
             # Limit lower-end to candle low to avoid exits below the low.
             # This still remains "worst case" - but "worst realistic case".
             if is_short:
                 return min(row[HIGH_IDX], stop_rate)
             else:
                 return max(row[LOW_IDX], stop_rate)
 
         # Set close_rate to stoploss
         return stoploss_value
 
-    def _get_close_rate_for_roi(self, row: Tuple, trade: LocalTrade, exit: ExitCheckTuple,
-                                trade_dur: int) -> float:
+    def _get_close_rate_for_roi(
+        self, row: Tuple, trade: LocalTrade, exit: ExitCheckTuple, trade_dur: int
+    ) -> float:
         is_short = trade.is_short or False
         leverage = trade.leverage or 1.0
         side_1 = -1 if is_short else 1
         roi_entry, roi = self.strategy.min_roi_reached_entry(trade_dur)
         if roi is not None and roi_entry is not None:
             if roi == -1 and roi_entry % self.timeframe_min == 0:
                 # When force_exiting with ROI=-1, the roi time will always be equal to trade_dur.
@@ -490,38 +556,40 @@
             roi_rate = trade.open_rate * roi / leverage
             open_fee_rate = side_1 * trade.open_rate * (1 + side_1 * trade.fee_open)
             close_rate = -(roi_rate + open_fee_rate) / ((trade.fee_close or 0.0) - side_1 * 1)
             if is_short:
                 is_new_roi = row[OPEN_IDX] < close_rate
             else:
                 is_new_roi = row[OPEN_IDX] > close_rate
-            if (trade_dur > 0 and trade_dur == roi_entry
-                    and roi_entry % self.timeframe_min == 0
-                    and is_new_roi):
+            if (
+                trade_dur > 0
+                and trade_dur == roi_entry
+                and roi_entry % self.timeframe_min == 0
+                and is_new_roi
+            ):
                 # new ROI entry came into effect.
                 # use Open rate if open_rate > calculated exit rate
                 return row[OPEN_IDX]
 
-            if (trade_dur == 0 and (
+            if trade_dur == 0 and (
                 (
                     is_short
                     # Red candle (for longs)
                     and row[OPEN_IDX] < row[CLOSE_IDX]  # Red candle
                     and trade.open_rate > row[OPEN_IDX]  # trade-open above open_rate
                     and close_rate < row[CLOSE_IDX]  # closes below close
                 )
-                or
-                (
+                or (
                     not is_short
                     # green candle (for shorts)
                     and row[OPEN_IDX] > row[CLOSE_IDX]  # green candle
                     and trade.open_rate < row[OPEN_IDX]  # trade-open below open_rate
                     and close_rate > row[CLOSE_IDX]  # closes above close
                 )
-            )):
+            ):
                 # ROI on opening candles with custom pricing can only
                 # trigger if the entry was at Open or lower wick.
                 # details: https: // github.com/freqtrade/freqtrade/issues/6261
                 # If open_rate is < open, only allow exits below the close on red candles.
                 raise ValueError("Opening candle ROI on red candles.")
 
             # Use the maximum between close_rate and low as we
@@ -530,183 +598,246 @@
             return min(max(close_rate, row[LOW_IDX]), row[HIGH_IDX])
 
         else:
             # This should not be reached...
             return row[OPEN_IDX]
 
     def _get_adjust_trade_entry_for_candle(
-            self, trade: LocalTrade, row: Tuple, current_time: datetime
+        self, trade: LocalTrade, row: Tuple, current_time: datetime
     ) -> LocalTrade:
         current_rate: float = row[OPEN_IDX]
         current_profit = trade.calc_profit_ratio(current_rate)
         min_stake = self.exchange.get_min_pair_stake_amount(trade.pair, current_rate, -0.1)
         max_stake = self.exchange.get_max_pair_stake_amount(trade.pair, current_rate)
         stake_available = self.wallets.get_available_stake_amount()
         stake_amount, order_tag = self.strategy._adjust_trade_position_internal(
             trade=trade,  # type: ignore[arg-type]
-            current_time=current_time, current_rate=current_rate,
-            current_profit=current_profit, min_stake=min_stake,
+            current_time=current_time,
+            current_rate=current_rate,
+            current_profit=current_profit,
+            min_stake=min_stake,
             max_stake=min(max_stake, stake_available),
-            current_entry_rate=current_rate, current_exit_rate=current_rate,
-            current_entry_profit=current_profit, current_exit_profit=current_profit
+            current_entry_rate=current_rate,
+            current_exit_rate=current_rate,
+            current_entry_profit=current_profit,
+            current_exit_profit=current_profit,
         )
 
         # Check if we should increase our position
         if stake_amount is not None and stake_amount > 0.0:
             check_adjust_entry = True
             if self.strategy.max_entry_position_adjustment > -1:
                 entry_count = trade.nr_of_successful_entries
-                check_adjust_entry = (entry_count <= self.strategy.max_entry_position_adjustment)
+                check_adjust_entry = entry_count <= self.strategy.max_entry_position_adjustment
             if check_adjust_entry:
                 pos_trade = self._enter_trade(
-                    trade.pair, row, 'short' if trade.is_short else 'long', stake_amount, trade,
-                    entry_tag1=order_tag)
+                    trade.pair,
+                    row,
+                    "short" if trade.is_short else "long",
+                    stake_amount,
+                    trade,
+                    entry_tag1=order_tag,
+                )
                 if pos_trade is not None:
                     self.wallets.update()
                     return pos_trade
 
         if stake_amount is not None and stake_amount < 0.0:
             amount = amount_to_contract_precision(
-                abs(stake_amount * trade.amount / trade.stake_amount),
+                abs(
+                    float(
+                        FtPrecise(stake_amount)
+                        * FtPrecise(trade.amount)
+                        / FtPrecise(trade.stake_amount)
+                    )
+                ),
                 trade.amount_precision,
-                self.precision_mode, trade.contract_size)
+                self.precision_mode,
+                trade.contract_size,
+            )
             if amount == 0.0:
                 return trade
             remaining = (trade.amount - amount) * current_rate
             if min_stake and remaining != 0 and remaining < min_stake:
                 # Remaining stake is too low to be sold.
                 return trade
             exit_ = ExitCheckTuple(ExitType.PARTIAL_EXIT, order_tag)
             pos_trade = self._get_exit_for_signal(trade, row, exit_, current_time, amount)
             if pos_trade is not None:
                 order = pos_trade.orders[-1]
-                if self._try_close_open_order(order, trade, current_time, row):
-                    trade.recalc_trade_from_orders()
-                self.wallets.update()
+                # If the order was filled and for the full trade amount, we need to close the trade.
+                self._process_exit_order(order, pos_trade, current_time, row, trade.pair)
                 return pos_trade
 
         return trade
 
     def _get_order_filled(self, rate: float, row: Tuple) -> bool:
-        """ Rate is within candle, therefore filled"""
+        """Rate is within candle, therefore filled"""
         return row[LOW_IDX] <= rate <= row[HIGH_IDX]
 
     def _call_adjust_stop(self, current_date: datetime, trade: LocalTrade, current_rate: float):
         profit = trade.calc_profit_ratio(current_rate)
-        self.strategy.ft_stoploss_adjust(current_rate, trade,  # type: ignore
-                                         current_date, profit, 0, after_fill=True)
+        self.strategy.ft_stoploss_adjust(
+            current_rate,
+            trade,  # type: ignore
+            current_date,
+            profit,
+            0,
+            after_fill=True,
+        )
 
     def _try_close_open_order(
-            self, order: Optional[Order], trade: LocalTrade, current_date: datetime,
-            row: Tuple) -> bool:
+        self, order: Optional[Order], trade: LocalTrade, current_date: datetime, row: Tuple
+    ) -> bool:
         """
         Check if an order is open and if it should've filled.
         :return:  True if the order filled.
         """
         if order and self._get_order_filled(order.ft_price, row):
             order.close_bt_order(current_date, trade)
             self._run_funding_fees(trade, current_date, force=True)
-            strategy_safe_wrapper(
-                self.strategy.order_filled,
-                default_retval=None)(
-                pair=trade.pair, trade=trade,  # type: ignore[arg-type]
-                order=order, current_time=current_date)
+            strategy_safe_wrapper(self.strategy.order_filled, default_retval=None)(
+                pair=trade.pair,
+                trade=trade,  # type: ignore[arg-type]
+                order=order,
+                current_time=current_date,
+            )
 
             if not (order.ft_order_side == trade.exit_side and order.safe_amount == trade.amount):
                 # trade is still open
-                trade.set_liquidation_price(self.exchange.get_liquidation_price(
-                    pair=trade.pair,
-                    open_rate=trade.open_rate,
-                    is_short=trade.is_short,
-                    amount=trade.amount,
-                    stake_amount=trade.stake_amount,
-                    leverage=trade.leverage,
-                    wallet_balance=trade.stake_amount,
-                ))
+                trade.set_liquidation_price(
+                    self.exchange.get_liquidation_price(
+                        pair=trade.pair,
+                        open_rate=trade.open_rate,
+                        is_short=trade.is_short,
+                        amount=trade.amount,
+                        stake_amount=trade.stake_amount,
+                        leverage=trade.leverage,
+                        wallet_balance=trade.stake_amount,
+                    )
+                )
                 self._call_adjust_stop(current_date, trade, order.ft_price)
                 # pass
             return True
         return False
 
-    def _get_exit_for_signal(
-            self, trade: LocalTrade, row: Tuple, exit_: ExitCheckTuple,
-            current_time: datetime,
-            amount: Optional[float] = None) -> Optional[LocalTrade]:
+    def _process_exit_order(
+        self, order: Order, trade: LocalTrade, current_time: datetime, row: Tuple, pair: str
+    ):
+        """
+        Takes an exit order and processes it, potentially closing the trade.
+        """
+        if self._try_close_open_order(order, trade, current_time, row):
+            sub_trade = order.safe_amount_after_fee != trade.amount
+            if sub_trade:
+                trade.recalc_trade_from_orders()
+            else:
+                trade.close_date = current_time
+                trade.close(order.ft_price, show_msg=False)
+
+                # logger.debug(f"{pair} - Backtesting exit {trade}")
+                LocalTrade.close_bt_trade(trade)
+            self.wallets.update()
+            self.run_protections(pair, current_time, trade.trade_direction)
 
+    def _get_exit_for_signal(
+        self,
+        trade: LocalTrade,
+        row: Tuple,
+        exit_: ExitCheckTuple,
+        current_time: datetime,
+        amount: Optional[float] = None,
+    ) -> Optional[LocalTrade]:
         if exit_.exit_flag:
             trade.close_date = current_time
             exit_reason = exit_.exit_reason
             amount_ = amount if amount is not None else trade.amount
             trade_dur = int((trade.close_date_utc - trade.open_date_utc).total_seconds() // 60)
             try:
                 close_rate = self._get_close_rate(row, trade, exit_, trade_dur)
             except ValueError:
                 return None
             # call the custom exit price,with default value as previous close_rate
             current_profit = trade.calc_profit_ratio(close_rate)
-            order_type = self.strategy.order_types['exit']
-            if exit_.exit_type in (ExitType.EXIT_SIGNAL, ExitType.CUSTOM_EXIT,
-                                   ExitType.PARTIAL_EXIT):
+            order_type = self.strategy.order_types["exit"]
+            if exit_.exit_type in (
+                ExitType.EXIT_SIGNAL,
+                ExitType.CUSTOM_EXIT,
+                ExitType.PARTIAL_EXIT,
+            ):
                 # Checks and adds an exit tag, after checking that the length of the
                 # row has the length for an exit tag column
                 if (
                     len(row) > EXIT_TAG_IDX
                     and row[EXIT_TAG_IDX] is not None
                     and len(row[EXIT_TAG_IDX]) > 0
                     and exit_.exit_type in (ExitType.EXIT_SIGNAL,)
                 ):
                     exit_reason = row[EXIT_TAG_IDX]
                 # Custom exit pricing only for exit-signals
-                if order_type == 'limit':
-                    rate = strategy_safe_wrapper(self.strategy.custom_exit_price,
-                                                 default_retval=close_rate)(
+                if order_type == "limit":
+                    rate = strategy_safe_wrapper(
+                        self.strategy.custom_exit_price, default_retval=close_rate
+                    )(
                         pair=trade.pair,
                         trade=trade,  # type: ignore[arg-type]
                         current_time=current_time,
-                        proposed_rate=close_rate, current_profit=current_profit,
-                        exit_tag=exit_reason)
+                        proposed_rate=close_rate,
+                        current_profit=current_profit,
+                        exit_tag=exit_reason,
+                    )
                     if rate is not None and rate != close_rate:
-                        close_rate = price_to_precision(rate, trade.price_precision,
-                                                        self.precision_mode)
+                        close_rate = price_to_precision(
+                            rate, trade.price_precision, self.precision_mode
+                        )
                     # We can't place orders lower than current low.
                     # freqtrade does not support this in live, and the order would fill immediately
                     if trade.is_short:
                         close_rate = min(close_rate, row[HIGH_IDX])
                     else:
                         close_rate = max(close_rate, row[LOW_IDX])
             # Confirm trade exit:
-            time_in_force = self.strategy.order_time_in_force['exit']
+            time_in_force = self.strategy.order_time_in_force["exit"]
 
-            if (exit_.exit_type not in (ExitType.LIQUIDATION, ExitType.PARTIAL_EXIT)
-                    and not strategy_safe_wrapper(
-                    self.strategy.confirm_trade_exit, default_retval=True)(
-                        pair=trade.pair,
-                        trade=trade,  # type: ignore[arg-type]
-                        order_type=order_type,
-                        amount=amount_,
-                        rate=close_rate,
-                        time_in_force=time_in_force,
-                        sell_reason=exit_reason,  # deprecated
-                        exit_reason=exit_reason,
-                        current_time=current_time)):
+            if exit_.exit_type not in (
+                ExitType.LIQUIDATION,
+                ExitType.PARTIAL_EXIT,
+            ) and not strategy_safe_wrapper(self.strategy.confirm_trade_exit, default_retval=True)(
+                pair=trade.pair,
+                trade=trade,  # type: ignore[arg-type]
+                order_type=order_type,
+                amount=amount_,
+                rate=close_rate,
+                time_in_force=time_in_force,
+                sell_reason=exit_reason,  # deprecated
+                exit_reason=exit_reason,
+                current_time=current_time,
+            ):
                 return None
 
             trade.exit_reason = exit_reason
 
             return self._exit_trade(trade, row, close_rate, amount_, exit_reason)
         return None
 
-    def _exit_trade(self, trade: LocalTrade, sell_row: Tuple, close_rate: float,
-                    amount: float, exit_reason: Optional[str]) -> Optional[LocalTrade]:
+    def _exit_trade(
+        self,
+        trade: LocalTrade,
+        sell_row: Tuple,
+        close_rate: float,
+        amount: float,
+        exit_reason: Optional[str],
+    ) -> Optional[LocalTrade]:
         self.order_id_counter += 1
         exit_candle_time = sell_row[DATE_IDX].to_pydatetime()
-        order_type = self.strategy.order_types['exit']
+        order_type = self.strategy.order_types["exit"]
         # amount = amount or trade.amount
-        amount = amount_to_contract_precision(amount or trade.amount, trade.amount_precision,
-                                              self.precision_mode, trade.contract_size)
+        amount = amount_to_contract_precision(
+            amount or trade.amount, trade.amount_precision, self.precision_mode, trade.contract_size
+        )
         order = Order(
             id=self.order_id_counter,
             ft_trade_id=trade.id,
             order_date=exit_candle_time,
             order_update_date=exit_candle_time,
             ft_is_open=True,
             ft_pair=trade.pair,
@@ -726,200 +857,246 @@
             ft_order_tag=exit_reason,
         )
         order._trade_bt = trade
         trade.orders.append(order)
         return trade
 
     def _check_trade_exit(
-            self, trade: LocalTrade, row: Tuple, current_time: datetime
+        self, trade: LocalTrade, row: Tuple, current_time: datetime
     ) -> Optional[LocalTrade]:
-
         self._run_funding_fees(trade, current_time)
 
         # Check if we need to adjust our current positions
         if self.strategy.position_adjustment_enable:
             trade = self._get_adjust_trade_entry_for_candle(trade, row, current_time)
 
-        enter = row[SHORT_IDX] if trade.is_short else row[LONG_IDX]
-        exit_sig = row[ESHORT_IDX] if trade.is_short else row[ELONG_IDX]
-        exits = self.strategy.should_exit(
-            trade, row[OPEN_IDX], row[DATE_IDX].to_pydatetime(),  # type: ignore
-            enter=enter, exit_=exit_sig,
-            low=row[LOW_IDX], high=row[HIGH_IDX]
-        )
-        for exit_ in exits:
-            t = self._get_exit_for_signal(trade, row, exit_, current_time)
-            if t:
-                return t
+        if trade.is_open:
+            enter = row[SHORT_IDX] if trade.is_short else row[LONG_IDX]
+            exit_sig = row[ESHORT_IDX] if trade.is_short else row[ELONG_IDX]
+            exits = self.strategy.should_exit(
+                trade,  # type: ignore
+                row[OPEN_IDX],
+                row[DATE_IDX].to_pydatetime(),
+                enter=enter,
+                exit_=exit_sig,
+                low=row[LOW_IDX],
+                high=row[HIGH_IDX],
+            )
+            for exit_ in exits:
+                t = self._get_exit_for_signal(trade, row, exit_, current_time)
+                if t:
+                    return t
         return None
 
     def _run_funding_fees(self, trade: LocalTrade, current_time: datetime, force: bool = False):
         """
         Calculate funding fees if necessary and add them to the trade.
         """
         if self.trading_mode == TradingMode.FUTURES:
-
-            if (
-                force
-                or (current_time.timestamp() % self.funding_fee_timeframe_secs) == 0
-            ):
+            if force or (current_time.timestamp() % self.funding_fee_timeframe_secs) == 0:
                 # Funding fee interval.
                 trade.set_funding_fees(
                     self.exchange.calculate_funding_fees(
                         self.futures_data[trade.pair],
                         amount=trade.amount,
                         is_short=trade.is_short,
                         open_date=trade.date_last_filled_utc,
-                        close_date=current_time
+                        close_date=current_time,
                     )
                 )
 
     def get_valid_price_and_stake(
-        self, pair: str, row: Tuple, propose_rate: float, stake_amount: float,
-        direction: LongShort, current_time: datetime, entry_tag: Optional[str],
-        trade: Optional[LocalTrade], order_type: str, price_precision: Optional[float]
+        self,
+        pair: str,
+        row: Tuple,
+        propose_rate: float,
+        stake_amount: float,
+        direction: LongShort,
+        current_time: datetime,
+        entry_tag: Optional[str],
+        trade: Optional[LocalTrade],
+        order_type: str,
+        price_precision: Optional[float],
     ) -> Tuple[float, float, float, float]:
-
-        if order_type == 'limit':
-            new_rate = strategy_safe_wrapper(self.strategy.custom_entry_price,
-                                             default_retval=propose_rate)(
+        if order_type == "limit":
+            new_rate = strategy_safe_wrapper(
+                self.strategy.custom_entry_price, default_retval=propose_rate
+            )(
                 pair=pair,
                 trade=trade,  # type: ignore[arg-type]
                 current_time=current_time,
-                proposed_rate=propose_rate, entry_tag=entry_tag,
+                proposed_rate=propose_rate,
+                entry_tag=entry_tag,
                 side=direction,
             )  # default value is the open rate
             # We can't place orders higher than current high (otherwise it'd be a stop limit entry)
             # which freqtrade does not support in live.
             if new_rate is not None and new_rate != propose_rate:
-                propose_rate = price_to_precision(new_rate, price_precision,
-                                                  self.precision_mode)
+                propose_rate = price_to_precision(new_rate, price_precision, self.precision_mode)
             if direction == "short":
                 propose_rate = max(propose_rate, row[LOW_IDX])
             else:
                 propose_rate = min(propose_rate, row[HIGH_IDX])
 
         pos_adjust = trade is not None
         leverage = trade.leverage if trade else 1.0
         if not pos_adjust:
             try:
                 stake_amount = self.wallets.get_trade_stake_amount(
-                    pair, self.strategy.max_open_trades, update=False)
+                    pair, self.strategy.max_open_trades, update=False
+                )
             except DependencyException:
                 return 0, 0, 0, 0
 
             max_leverage = self.exchange.get_max_leverage(pair, stake_amount)
-            leverage = strategy_safe_wrapper(self.strategy.leverage, default_retval=1.0)(
-                pair=pair,
-                current_time=current_time,
-                current_rate=row[OPEN_IDX],
-                proposed_leverage=1.0,
-                max_leverage=max_leverage,
-                side=direction, entry_tag=entry_tag,
-            ) if self.trading_mode != TradingMode.SPOT else 1.0
+            leverage = (
+                strategy_safe_wrapper(self.strategy.leverage, default_retval=1.0)(
+                    pair=pair,
+                    current_time=current_time,
+                    current_rate=row[OPEN_IDX],
+                    proposed_leverage=1.0,
+                    max_leverage=max_leverage,
+                    side=direction,
+                    entry_tag=entry_tag,
+                )
+                if self.trading_mode != TradingMode.SPOT
+                else 1.0
+            )
             # Cap leverage between 1.0 and max_leverage.
             leverage = min(max(leverage, 1.0), max_leverage)
 
-        min_stake_amount = self.exchange.get_min_pair_stake_amount(
-            pair, propose_rate, -0.05 if not pos_adjust else 0.0, leverage=leverage) or 0
+        min_stake_amount = (
+            self.exchange.get_min_pair_stake_amount(
+                pair, propose_rate, -0.05 if not pos_adjust else 0.0, leverage=leverage
+            )
+            or 0
+        )
         max_stake_amount = self.exchange.get_max_pair_stake_amount(
-            pair, propose_rate, leverage=leverage)
+            pair, propose_rate, leverage=leverage
+        )
         stake_available = self.wallets.get_available_stake_amount()
 
         if not pos_adjust:
-            stake_amount = strategy_safe_wrapper(self.strategy.custom_stake_amount,
-                                                 default_retval=stake_amount)(
-                pair=pair, current_time=current_time, current_rate=propose_rate,
-                proposed_stake=stake_amount, min_stake=min_stake_amount,
+            stake_amount = strategy_safe_wrapper(
+                self.strategy.custom_stake_amount, default_retval=stake_amount
+            )(
+                pair=pair,
+                current_time=current_time,
+                current_rate=propose_rate,
+                proposed_stake=stake_amount,
+                min_stake=min_stake_amount,
                 max_stake=min(stake_available, max_stake_amount),
-                leverage=leverage, entry_tag=entry_tag, side=direction)
+                leverage=leverage,
+                entry_tag=entry_tag,
+                side=direction,
+            )
 
         stake_amount_val = self.wallets.validate_stake_amount(
             pair=pair,
             stake_amount=stake_amount,
             min_stake_amount=min_stake_amount,
             max_stake_amount=max_stake_amount,
-            trade_amount=trade.stake_amount if trade else None
+            trade_amount=trade.stake_amount if trade else None,
         )
 
         return propose_rate, stake_amount_val, leverage, min_stake_amount
 
-    def _enter_trade(self, pair: str, row: Tuple, direction: LongShort,
-                     stake_amount: Optional[float] = None,
-                     trade: Optional[LocalTrade] = None,
-                     requested_rate: Optional[float] = None,
-                     requested_stake: Optional[float] = None,
-                     entry_tag1: Optional[str] = None
-                     ) -> Optional[LocalTrade]:
+    def _enter_trade(
+        self,
+        pair: str,
+        row: Tuple,
+        direction: LongShort,
+        stake_amount: Optional[float] = None,
+        trade: Optional[LocalTrade] = None,
+        requested_rate: Optional[float] = None,
+        requested_stake: Optional[float] = None,
+        entry_tag1: Optional[str] = None,
+    ) -> Optional[LocalTrade]:
         """
         :param trade: Trade to adjust - initial entry if None
         :param requested_rate: Adjusted entry rate
         :param requested_stake: Stake amount for adjusted orders (`adjust_entry_price`).
         """
 
         current_time = row[DATE_IDX].to_pydatetime()
         entry_tag = entry_tag1 or (row[ENTER_TAG_IDX] if len(row) >= ENTER_TAG_IDX + 1 else None)
         # let's call the custom entry price, using the open price as default price
-        order_type = self.strategy.order_types['entry']
+        order_type = self.strategy.order_types["entry"]
         pos_adjust = trade is not None and requested_rate is None
 
         stake_amount_ = stake_amount or (trade.stake_amount if trade else 0.0)
         precision_price = self.exchange.get_precision_price(pair)
 
         propose_rate, stake_amount, leverage, min_stake_amount = self.get_valid_price_and_stake(
-            pair, row, row[OPEN_IDX], stake_amount_, direction, current_time, entry_tag, trade,
-            order_type, precision_price,
+            pair,
+            row,
+            row[OPEN_IDX],
+            stake_amount_,
+            direction,
+            current_time,
+            entry_tag,
+            trade,
+            order_type,
+            precision_price,
         )
 
         # replace proposed rate if another rate was requested
         propose_rate = requested_rate if requested_rate else propose_rate
         stake_amount = requested_stake if requested_stake else stake_amount
 
         if not stake_amount:
             # In case of pos adjust, still return the original trade
             # If not pos adjust, trade is None
             return trade
-        time_in_force = self.strategy.order_time_in_force['entry']
+        time_in_force = self.strategy.order_time_in_force["entry"]
 
         if stake_amount and (not min_stake_amount or stake_amount >= min_stake_amount):
             self.order_id_counter += 1
             base_currency = self.exchange.get_pair_base_currency(pair)
             amount_p = (stake_amount / propose_rate) * leverage
 
             contract_size = self.exchange.get_contract_size(pair)
             precision_amount = self.exchange.get_precision_amount(pair)
-            amount = amount_to_contract_precision(amount_p, precision_amount, self.precision_mode,
-                                                  contract_size)
+            amount = amount_to_contract_precision(
+                amount_p, precision_amount, self.precision_mode, contract_size
+            )
             if not amount:
                 # No amount left after truncating to precision.
                 return trade
             # Backcalculate actual stake amount.
             stake_amount = amount * propose_rate / leverage
 
             if not pos_adjust:
                 # Confirm trade entry:
                 if not strategy_safe_wrapper(
-                        self.strategy.confirm_trade_entry, default_retval=True)(
-                            pair=pair, order_type=order_type, amount=amount, rate=propose_rate,
-                            time_in_force=time_in_force, current_time=current_time,
-                            entry_tag=entry_tag, side=direction):
+                    self.strategy.confirm_trade_entry, default_retval=True
+                )(
+                    pair=pair,
+                    order_type=order_type,
+                    amount=amount,
+                    rate=propose_rate,
+                    time_in_force=time_in_force,
+                    current_time=current_time,
+                    entry_tag=entry_tag,
+                    side=direction,
+                ):
                     return trade
 
-            is_short = (direction == 'short')
+            is_short = direction == "short"
             # Necessary for Margin trading. Disabled until support is enabled.
             # interest_rate = self.exchange.get_interest_rate()
 
             if trade is None:
                 # Enter trade
                 self.trade_id_counter += 1
                 trade = LocalTrade(
                     id=self.trade_id_counter,
                     pair=pair,
                     base_currency=base_currency,
-                    stake_currency=self.config['stake_currency'],
+                    stake_currency=self.config["stake_currency"],
                     open_rate=propose_rate,
                     open_rate_requested=propose_rate,
                     open_date=current_time,
                     stake_amount=stake_amount,
                     amount=amount,
                     amount_requested=amount,
                     fee_open=self.fee,
@@ -933,14 +1110,15 @@
                     # interest_rate=interest_rate,
                     amount_precision=precision_amount,
                     price_precision=precision_price,
                     precision_mode=self.precision_mode,
                     contract_size=contract_size,
                     orders=[],
                 )
+                LocalTrade.add_bt_trade(trade)
 
             trade.adjust_stop_loss(trade.open_rate, self.strategy.stoploss, initial=True)
 
             order = Order(
                 id=self.order_id_counter,
                 ft_trade_id=trade.id,
                 ft_is_open=True,
@@ -966,27 +1144,29 @@
             order._trade_bt = trade
             trade.orders.append(order)
             self._try_close_open_order(order, trade, current_time, row)
             trade.recalc_trade_from_orders()
 
         return trade
 
-    def handle_left_open(self, open_trades: Dict[str, List[LocalTrade]],
-                         data: Dict[str, List[Tuple]]) -> None:
+    def handle_left_open(
+        self, open_trades: Dict[str, List[LocalTrade]], data: Dict[str, List[Tuple]]
+    ) -> None:
         """
         Handling of left open trades at the end of backtesting
         """
         for pair in open_trades.keys():
             for trade in list(open_trades[pair]):
                 if trade.has_open_orders and trade.nr_of_successful_entries == 0:
                     # Ignore trade if entry-order did not fill yet
                     continue
                 exit_row = data[pair][-1]
-                self._exit_trade(trade, exit_row, exit_row[OPEN_IDX], trade.amount,
-                                 ExitType.FORCE_EXIT.value)
+                self._exit_trade(
+                    trade, exit_row, exit_row[OPEN_IDX], trade.amount, ExitType.FORCE_EXIT.value
+                )
                 trade.orders[-1].close_bt_order(exit_row[DATE_IDX].to_pydatetime(), trade)
 
                 trade.close_date = exit_row[DATE_IDX].to_pydatetime()
                 trade.exit_reason = ExitType.FORCE_EXIT.value
                 trade.close(exit_row[OPEN_IDX], show_msg=False)
                 LocalTrade.close_bt_trade(trade)
 
@@ -1003,18 +1183,18 @@
         enter_long = row[LONG_IDX] == 1
         exit_long = row[ELONG_IDX] == 1
         enter_short = self._can_short and row[SHORT_IDX] == 1
         exit_short = self._can_short and row[ESHORT_IDX] == 1
 
         if enter_long == 1 and not any([exit_long, enter_short]):
             # Long
-            return 'long'
+            return "long"
         if enter_short == 1 and not any([exit_short, enter_long]):
             # Short
-            return 'short'
+            return "short"
         return None
 
     def run_protections(self, pair: str, current_time: datetime, side: LongShort):
         if self.enable_protections:
             self.protections.stop_per_pair(pair, current_time, side)
             self.protections.global_stop(current_time, side)
 
@@ -1032,24 +1212,27 @@
                 # delete trade due to user request
                 self.canceled_trade_entries += 1
                 return True
         # default maintain trade
         return False
 
     def check_order_cancel(
-            self, trade: LocalTrade, order: Order, current_time: datetime) -> Optional[bool]:
+        self, trade: LocalTrade, order: Order, current_time: datetime
+    ) -> Optional[bool]:
         """
         Check if current analyzed order has to be canceled.
         Returns True if the trade should be Deleted (initial order was canceled),
                 False if it's Canceled
                 None if the order is still active.
         """
         timedout = self.strategy.ft_check_timed_out(
             trade,  # type: ignore[arg-type]
-            order, current_time)
+            order,
+            current_time,
+        )
         if timedout:
             if order.side == trade.entry_side:
                 self.timedout_entry_orders += 1
                 if trade.nr_of_successful_entries == 0:
                     # Remove trade due to entry timeout expiration.
                     return True
                 else:
@@ -1059,58 +1242,68 @@
             if order.side == trade.exit_side:
                 self.timedout_exit_orders += 1
                 # Close exit order and retry exiting on next signal.
                 del trade.orders[trade.orders.index(order)]
                 return False
         return None
 
-    def check_order_replace(self, trade: LocalTrade, order: Order, current_time,
-                            row: Tuple) -> bool:
+    def check_order_replace(
+        self, trade: LocalTrade, order: Order, current_time, row: Tuple
+    ) -> bool:
         """
         Check if current analyzed entry order has to be replaced and do so.
         If user requested cancellation and there are no filled orders in the trade will
         instruct caller to delete the trade.
         Returns True if the trade should be deleted.
         """
         # only check on new candles for open entry orders
         if order.side == trade.entry_side and current_time > order.order_date_utc:
-            requested_rate = strategy_safe_wrapper(self.strategy.adjust_entry_price,
-                                                   default_retval=order.ft_price)(
+            requested_rate = strategy_safe_wrapper(
+                self.strategy.adjust_entry_price, default_retval=order.ft_price
+            )(
                 trade=trade,  # type: ignore[arg-type]
-                order=order, pair=trade.pair, current_time=current_time,
-                proposed_rate=row[OPEN_IDX], current_order_rate=order.ft_price,
-                entry_tag=trade.enter_tag, side=trade.trade_direction
+                order=order,
+                pair=trade.pair,
+                current_time=current_time,
+                proposed_rate=row[OPEN_IDX],
+                current_order_rate=order.ft_price,
+                entry_tag=trade.enter_tag,
+                side=trade.trade_direction,
             )  # default value is current order price
 
             # cancel existing order whenever a new rate is requested (or None)
             if requested_rate == order.ft_price:
                 # assumption: there can't be multiple open entry orders at any given time
                 return False
             else:
                 del trade.orders[trade.orders.index(order)]
                 self.canceled_entry_orders += 1
 
             # place new order if result was not None
             if requested_rate:
-                self._enter_trade(pair=trade.pair, row=row, trade=trade,
-                                  requested_rate=requested_rate,
-                                  requested_stake=(
-                                    order.safe_remaining * order.ft_price / trade.leverage),
-                                  direction='short' if trade.is_short else 'long')
+                self._enter_trade(
+                    pair=trade.pair,
+                    row=row,
+                    trade=trade,
+                    requested_rate=requested_rate,
+                    requested_stake=(order.safe_remaining * order.ft_price / trade.leverage),
+                    direction="short" if trade.is_short else "long",
+                )
                 # Delete trade if no successful entries happened (if placing the new order failed)
                 if not trade.has_open_orders and trade.nr_of_successful_entries == 0:
                     return True
                 self.replaced_entry_orders += 1
             else:
                 # assumption: there can't be multiple open entry orders at any given time
-                return (trade.nr_of_successful_entries == 0)
+                return trade.nr_of_successful_entries == 0
         return False
 
     def validate_row(
-            self, data: Dict, pair: str, row_index: int, current_time: datetime) -> Optional[Tuple]:
+        self, data: Dict, pair: str, row_index: int, current_time: datetime
+    ) -> Optional[Tuple]:
         try:
             # Row is treated as "current incomplete candle".
             # entry / exit signals are shifted by 1 to compensate for this.
             row = data[pair][row_index]
         except IndexError:
             # missing Data for one pair at the end.
             # Warnings for this are shown during data loading
@@ -1123,24 +1316,32 @@
 
     def _collate_rejected(self, pair, row):
         """
         Temporarily store rejected signal information for downstream use in backtesting_analysis
         """
         # It could be fun to enable hyperopt mode to write
         # a loss function to reduce rejected signals
-        if (self.config.get('export', 'none') == 'signals' and
-                self.dataprovider.runmode == RunMode.BACKTEST):
+        if (
+            self.config.get("export", "none") == "signals"
+            and self.dataprovider.runmode == RunMode.BACKTEST
+        ):
             if pair not in self.rejected_dict:
                 self.rejected_dict[pair] = []
             self.rejected_dict[pair].append([row[DATE_IDX], row[ENTER_TAG_IDX]])
 
     def backtest_loop(
-            self, row: Tuple, pair: str, current_time: datetime, end_date: datetime,
-            open_trade_count_start: int, trade_dir: Optional[LongShort],
-            is_first: bool = True) -> int:
+        self,
+        row: Tuple,
+        pair: str,
+        current_time: datetime,
+        end_date: datetime,
+        open_trade_count_start: int,
+        trade_dir: Optional[LongShort],
+        is_first: bool = True,
+    ) -> int:
         """
         NOTE: This method is used by Hyperopt at each iteration. Please keep it optimized.
 
         Backtesting processing for one candle/pair.
         """
         for t in list(LocalTrade.bt_trades_open_pp[pair]):
             # 1. Manage currently open orders of active trades
@@ -1158,23 +1359,21 @@
         if (
             (self._position_stacking or len(LocalTrade.bt_trades_open_pp[pair]) == 0)
             and is_first
             and current_time != end_date
             and trade_dir is not None
             and not PairLocks.is_pair_locked(pair, row[DATE_IDX], trade_dir)
         ):
-            if (self.trade_slot_available(open_trade_count_start)):
+            if self.trade_slot_available(open_trade_count_start):
                 trade = self._enter_trade(pair, row, trade_dir)
                 if trade:
                     # TODO: hacky workaround to avoid opening > max_open_trades
                     # This emulates previous behavior - not sure if this is correct
                     # Prevents entering if the trade-slot was freed in this candle
                     open_trade_count_start += 1
-                    # logger.debug(f"{pair} - Emulate creation of new trade: {trade}.")
-                    LocalTrade.add_bt_trade(trade)
                     self.wallets.update()
             else:
                 self._collate_rejected(pair, row)
 
         for trade in list(LocalTrade.bt_trades_open_pp[pair]):
             # 3. Process entry orders.
             order = trade.select_order(trade.entry_side, is_open=True)
@@ -1183,30 +1382,19 @@
 
             # 4. Create exit orders (if any)
             if not trade.has_open_orders:
                 self._check_trade_exit(trade, row, current_time)  # Place exit order if necessary
 
             # 5. Process exit orders.
             order = trade.select_order(trade.exit_side, is_open=True)
-            if order and self._try_close_open_order(order, trade, current_time, row):
-                sub_trade = order.safe_amount_after_fee != trade.amount
-                if sub_trade:
-                    trade.recalc_trade_from_orders()
-                else:
-                    trade.close_date = current_time
-                    trade.close(order.ft_price, show_msg=False)
-
-                    # logger.debug(f"{pair} - Backtesting exit {trade}")
-                    LocalTrade.close_bt_trade(trade)
-                self.wallets.update()
-                self.run_protections(pair, current_time, trade.trade_direction)
+            if order:
+                self._process_exit_order(order, trade, current_time, row, pair)
         return open_trade_count_start
 
-    def backtest(self, processed: Dict,
-                 start_date: datetime, end_date: datetime) -> Dict[str, Any]:
+    def backtest(self, processed: Dict, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
         """
         Implement backtesting functionality
 
         NOTE: This method is used by Hyperopt at each iteration. Please keep it optimized.
         Of course try to not have ugly code. By some accessor are sometime slower than functions.
         Avoid extensive logging in this method and functions it calls.
 
@@ -1223,22 +1411,24 @@
         # (looping lists is a lot faster than pandas DataFrames)
         data: Dict = self._get_ohlcv_as_lists(processed)
 
         # Indexes per pair, so some pairs are allowed to have a missing start.
         indexes: Dict = defaultdict(int)
         current_time = start_date + self.timeframe_td
 
-        self.progress.init_step(BacktestState.BACKTEST, int(
-            (end_date - start_date) / self.timeframe_td))
+        self.progress.init_step(
+            BacktestState.BACKTEST, int((end_date - start_date) / self.timeframe_td)
+        )
         # Loop timerange and get candle for each pair at that point in time
         while current_time <= end_date:
             open_trade_count_start = LocalTrade.bt_open_open_trade_count
             self.check_abort()
             strategy_safe_wrapper(self.strategy.bot_loop_start, supress_error=True)(
-                current_time=current_time)
+                current_time=current_time
+            )
             for i, pair in enumerate(data):
                 row_index = indexes[pair]
                 row = self.validate_row(data, pair, row_index, current_time)
                 if not row:
                     continue
 
                 row_index += 1
@@ -1246,201 +1436,227 @@
                 self.dataprovider._set_dataframe_max_index(self.required_startup + row_index)
                 self.dataprovider._set_dataframe_max_date(current_time)
                 current_detail_time: datetime = row[DATE_IDX].to_pydatetime()
                 trade_dir: Optional[LongShort] = self.check_for_trade_entry(row)
 
                 if (
                     (trade_dir is not None or len(LocalTrade.bt_trades_open_pp[pair]) > 0)
-                    and self.timeframe_detail and pair in self.detail_data
+                    and self.timeframe_detail
+                    and pair in self.detail_data
                 ):
                     # Spread out into detail timeframe.
                     # Should only happen when we are either in a trade for this pair
                     # or when we got the signal for a new trade.
                     exit_candle_end = current_detail_time + self.timeframe_td
 
                     detail_data = self.detail_data[pair]
                     detail_data = detail_data.loc[
-                        (detail_data['date'] >= current_detail_time) &
-                        (detail_data['date'] < exit_candle_end)
+                        (detail_data["date"] >= current_detail_time)
+                        & (detail_data["date"] < exit_candle_end)
                     ].copy()
                     if len(detail_data) == 0:
                         # Fall back to "regular" data if no detail data was found for this candle
                         open_trade_count_start = self.backtest_loop(
-                            row, pair, current_time, end_date,
-                            open_trade_count_start, trade_dir)
+                            row, pair, current_time, end_date, open_trade_count_start, trade_dir
+                        )
                         continue
-                    detail_data.loc[:, 'enter_long'] = row[LONG_IDX]
-                    detail_data.loc[:, 'exit_long'] = row[ELONG_IDX]
-                    detail_data.loc[:, 'enter_short'] = row[SHORT_IDX]
-                    detail_data.loc[:, 'exit_short'] = row[ESHORT_IDX]
-                    detail_data.loc[:, 'enter_tag'] = row[ENTER_TAG_IDX]
-                    detail_data.loc[:, 'exit_tag'] = row[EXIT_TAG_IDX]
+                    detail_data.loc[:, "enter_long"] = row[LONG_IDX]
+                    detail_data.loc[:, "exit_long"] = row[ELONG_IDX]
+                    detail_data.loc[:, "enter_short"] = row[SHORT_IDX]
+                    detail_data.loc[:, "exit_short"] = row[ESHORT_IDX]
+                    detail_data.loc[:, "enter_tag"] = row[ENTER_TAG_IDX]
+                    detail_data.loc[:, "exit_tag"] = row[EXIT_TAG_IDX]
                     is_first = True
                     current_time_det = current_time
                     for det_row in detail_data[HEADERS].values.tolist():
                         self.dataprovider._set_dataframe_max_date(current_time_det)
                         open_trade_count_start = self.backtest_loop(
-                            det_row, pair, current_time_det, end_date,
-                            open_trade_count_start, trade_dir, is_first)
+                            det_row,
+                            pair,
+                            current_time_det,
+                            end_date,
+                            open_trade_count_start,
+                            trade_dir,
+                            is_first,
+                        )
                         current_time_det += self.timeframe_detail_td
                         is_first = False
                 else:
                     self.dataprovider._set_dataframe_max_date(current_time)
                     open_trade_count_start = self.backtest_loop(
-                        row, pair, current_time, end_date,
-                        open_trade_count_start, trade_dir)
+                        row, pair, current_time, end_date, open_trade_count_start, trade_dir
+                    )
 
             # Move time one configured time_interval ahead.
             self.progress.increment()
             current_time += self.timeframe_td
 
         self.handle_left_open(LocalTrade.bt_trades_open_pp, data=data)
         self.wallets.update()
 
         results = trade_list_to_dataframe(LocalTrade.trades)
         return {
-            'results': results,
-            'config': self.strategy.config,
-            'locks': PairLocks.get_all_locks(),
-            'rejected_signals': self.rejected_trades,
-            'timedout_entry_orders': self.timedout_entry_orders,
-            'timedout_exit_orders': self.timedout_exit_orders,
-            'canceled_trade_entries': self.canceled_trade_entries,
-            'canceled_entry_orders': self.canceled_entry_orders,
-            'replaced_entry_orders': self.replaced_entry_orders,
-            'final_balance': self.wallets.get_total(self.strategy.config['stake_currency']),
+            "results": results,
+            "config": self.strategy.config,
+            "locks": PairLocks.get_all_locks(),
+            "rejected_signals": self.rejected_trades,
+            "timedout_entry_orders": self.timedout_entry_orders,
+            "timedout_exit_orders": self.timedout_exit_orders,
+            "canceled_trade_entries": self.canceled_trade_entries,
+            "canceled_entry_orders": self.canceled_entry_orders,
+            "replaced_entry_orders": self.replaced_entry_orders,
+            "final_balance": self.wallets.get_total(self.strategy.config["stake_currency"]),
         }
 
-    def backtest_one_strategy(self, strat: IStrategy, data: Dict[str, DataFrame],
-                              timerange: TimeRange):
+    def backtest_one_strategy(
+        self, strat: IStrategy, data: Dict[str, DataFrame], timerange: TimeRange
+    ):
         self.progress.init_step(BacktestState.ANALYZE, 0)
         strategy_name = strat.get_strategy_name()
         logger.info(f"Running backtesting for Strategy {strategy_name}")
         backtest_start_time = datetime.now(timezone.utc)
         self._set_strategy(strat)
 
         # Use max_open_trades in backtesting, except --disable-max-market-positions is set
-        if not self.config.get('use_max_market_positions', True):
-            logger.info(
-                'Ignoring max_open_trades (--disable-max-market-positions was used) ...')
-            self.strategy.max_open_trades = float('inf')
-            self.config.update({'max_open_trades': self.strategy.max_open_trades})
+        if not self.config.get("use_max_market_positions", True):
+            logger.info("Ignoring max_open_trades (--disable-max-market-positions was used) ...")
+            self.strategy.max_open_trades = float("inf")
+            self.config.update({"max_open_trades": self.strategy.max_open_trades})
 
         # need to reprocess data every time to populate signals
         preprocessed = self.strategy.advise_all_indicators(data)
 
         # Trim startup period from analyzed dataframe
         # This only used to determine if trimming would result in an empty dataframe
         preprocessed_tmp = trim_dataframes(preprocessed, timerange, self.required_startup)
 
         if not preprocessed_tmp:
-            raise OperationalException(
-                "No data left after adjusting for startup candles.")
+            raise OperationalException("No data left after adjusting for startup candles.")
 
         # Use preprocessed_tmp for date generation (the trimmed dataframe).
         # Backtesting will re-trim the dataframes after entry/exit signal generation.
         min_date, max_date = history.get_timerange(preprocessed_tmp)
-        logger.info(f'Backtesting with data from {min_date.strftime(DATETIME_PRINT_FORMAT)} '
-                    f'up to {max_date.strftime(DATETIME_PRINT_FORMAT)} '
-                    f'({(max_date - min_date).days} days).')
+        logger.info(
+            f"Backtesting with data from {min_date.strftime(DATETIME_PRINT_FORMAT)} "
+            f"up to {max_date.strftime(DATETIME_PRINT_FORMAT)} "
+            f"({(max_date - min_date).days} days)."
+        )
         # Execute backtest and store results
         results = self.backtest(
             processed=preprocessed,
             start_date=min_date,
             end_date=max_date,
         )
         backtest_end_time = datetime.now(timezone.utc)
-        results.update({
-            'run_id': self.run_ids.get(strategy_name, ''),
-            'backtest_start_time': int(backtest_start_time.timestamp()),
-            'backtest_end_time': int(backtest_end_time.timestamp()),
-        })
+        results.update(
+            {
+                "run_id": self.run_ids.get(strategy_name, ""),
+                "backtest_start_time": int(backtest_start_time.timestamp()),
+                "backtest_end_time": int(backtest_end_time.timestamp()),
+            }
+        )
         self.all_results[strategy_name] = results
 
-        if (self.config.get('export', 'none') == 'signals' and
-                self.dataprovider.runmode == RunMode.BACKTEST):
+        if (
+            self.config.get("export", "none") == "signals"
+            and self.dataprovider.runmode == RunMode.BACKTEST
+        ):
             self.processed_dfs[strategy_name] = generate_trade_signal_candles(
-                preprocessed_tmp, results)
+                preprocessed_tmp, results
+            )
             self.rejected_df[strategy_name] = generate_rejected_signals(
-                preprocessed_tmp, self.rejected_dict)
+                preprocessed_tmp, self.rejected_dict
+            )
 
         return min_date, max_date
 
     def _get_min_cached_backtest_date(self):
         min_backtest_date = None
-        backtest_cache_age = self.config.get('backtest_cache', constants.BACKTEST_CACHE_DEFAULT)
+        backtest_cache_age = self.config.get("backtest_cache", constants.BACKTEST_CACHE_DEFAULT)
         if self.timerange.stopts == 0 or self.timerange.stopdt > datetime.now(tz=timezone.utc):
-            logger.warning('Backtest result caching disabled due to use of open-ended timerange.')
-        elif backtest_cache_age == 'day':
+            logger.warning("Backtest result caching disabled due to use of open-ended timerange.")
+        elif backtest_cache_age == "day":
             min_backtest_date = datetime.now(tz=timezone.utc) - timedelta(days=1)
-        elif backtest_cache_age == 'week':
+        elif backtest_cache_age == "week":
             min_backtest_date = datetime.now(tz=timezone.utc) - timedelta(weeks=1)
-        elif backtest_cache_age == 'month':
+        elif backtest_cache_age == "month":
             min_backtest_date = datetime.now(tz=timezone.utc) - timedelta(weeks=4)
         return min_backtest_date
 
     def load_prior_backtest(self):
         self.run_ids = {
             strategy.get_strategy_name(): get_strategy_run_id(strategy)
             for strategy in self.strategylist
         }
 
         # Load previous result that will be updated incrementally.
         # This can be circumvented in certain instances in combination with downloading more data
         min_backtest_date = self._get_min_cached_backtest_date()
         if min_backtest_date is not None:
             self.results = find_existing_backtest_stats(
-                self.config['user_data_dir'] / 'backtest_results', self.run_ids, min_backtest_date)
+                self.config["user_data_dir"] / "backtest_results", self.run_ids, min_backtest_date
+            )
 
     def start(self) -> None:
         """
         Run backtesting end-to-end
         """
         data: Dict[str, DataFrame] = {}
 
         data, timerange = self.load_bt_data()
         self.load_bt_data_detail()
         logger.info("Dataload complete. Calculating indicators")
 
         self.load_prior_backtest()
 
         for strat in self.strategylist:
-            if self.results and strat.get_strategy_name() in self.results['strategy']:
+            if self.results and strat.get_strategy_name() in self.results["strategy"]:
                 # When previous result hash matches - reuse that result and skip backtesting.
-                logger.info(f'Reusing result of previous backtest for {strat.get_strategy_name()}')
+                logger.info(f"Reusing result of previous backtest for {strat.get_strategy_name()}")
                 continue
             min_date, max_date = self.backtest_one_strategy(strat, data, timerange)
 
         # Update old results with new ones.
         if len(self.all_results) > 0:
             results = generate_backtest_stats(
-                data, self.all_results, min_date=min_date, max_date=max_date)
+                data, self.all_results, min_date=min_date, max_date=max_date
+            )
             if self.results:
-                self.results['metadata'].update(results['metadata'])
-                self.results['strategy'].update(results['strategy'])
-                self.results['strategy_comparison'].extend(results['strategy_comparison'])
+                self.results["metadata"].update(results["metadata"])
+                self.results["strategy"].update(results["strategy"])
+                self.results["strategy_comparison"].extend(results["strategy_comparison"])
             else:
                 self.results = results
             dt_appendix = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
-            if self.config.get('export', 'none') in ('trades', 'signals'):
+            if self.config.get("export", "none") in ("trades", "signals"):
                 combined_res = combined_dataframes_with_rel_mean(data, min_date, max_date)
-                store_backtest_stats(self.config['exportfilename'], self.results, dt_appendix,
-                                     market_change_data=combined_res)
+                store_backtest_stats(
+                    self.config["exportfilename"],
+                    self.results,
+                    dt_appendix,
+                    market_change_data=combined_res,
+                )
 
-            if (self.config.get('export', 'none') == 'signals' and
-                    self.dataprovider.runmode == RunMode.BACKTEST):
+            if (
+                self.config.get("export", "none") == "signals"
+                and self.dataprovider.runmode == RunMode.BACKTEST
+            ):
                 store_backtest_analysis_results(
-                    self.config['exportfilename'], self.processed_dfs, self.rejected_df,
-                    dt_appendix)
+                    self.config["exportfilename"], self.processed_dfs, self.rejected_df, dt_appendix
+                )
 
         # Results may be mixed up now. Sort them so they follow --strategy-list order.
-        if 'strategy_list' in self.config and len(self.results) > 0:
-            self.results['strategy_comparison'] = sorted(
-                self.results['strategy_comparison'],
-                key=lambda c: self.config['strategy_list'].index(c['key']))
-            self.results['strategy'] = dict(
-                sorted(self.results['strategy'].items(),
-                       key=lambda kv: self.config['strategy_list'].index(kv[0])))
+        if "strategy_list" in self.config and len(self.results) > 0:
+            self.results["strategy_comparison"] = sorted(
+                self.results["strategy_comparison"],
+                key=lambda c: self.config["strategy_list"].index(c["key"]),
+            )
+            self.results["strategy"] = dict(
+                sorted(
+                    self.results["strategy"].items(),
+                    key=lambda kv: self.config["strategy_list"].index(kv[0]),
+                )
+            )
 
         if len(self.strategylist) > 0:
             # Show backtest results
             show_backtest_results(self.config, self.results)
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/base_analysis.py` & `freqtrade-2024.5/freqtrade/optimize/base_analysis.py`

 * *Files 15% similar despite different names*

```diff
@@ -21,46 +21,44 @@
     to_dt: datetime
     compared_dt: datetime
     timeframe: str
     startup_candle: int
 
 
 class BaseAnalysis:
-
     def __init__(self, config: Dict[str, Any], strategy_obj: Dict):
         self.failed_bias_check = True
         self.full_varHolder = VarHolder()
         self.exchange: Optional[Any] = None
         self._fee = None
 
         # pull variables the scope of the lookahead_analysis-instance
         self.local_config = deepcopy(config)
-        self.local_config['strategy'] = strategy_obj['name']
+        self.local_config["strategy"] = strategy_obj["name"]
         self.strategy_obj = strategy_obj
 
     @staticmethod
     def dt_to_timestamp(dt: datetime):
         timestamp = int(dt.replace(tzinfo=timezone.utc).timestamp())
         return timestamp
 
     def fill_full_varholder(self):
         self.full_varHolder = VarHolder()
 
         # define datetime in human-readable format
-        parsed_timerange = TimeRange.parse_timerange(self.local_config['timerange'])
+        parsed_timerange = TimeRange.parse_timerange(self.local_config["timerange"])
 
         if parsed_timerange.startdt is None:
             self.full_varHolder.from_dt = datetime.fromtimestamp(0, tz=timezone.utc)
         else:
             self.full_varHolder.from_dt = parsed_timerange.startdt
 
         if parsed_timerange.stopdt is None:
             self.full_varHolder.to_dt = datetime.now(timezone.utc)
         else:
             self.full_varHolder.to_dt = parsed_timerange.stopdt
 
-        self.prepare_data(self.full_varHolder, self.local_config['pairs'])
+        self.prepare_data(self.full_varHolder, self.local_config["pairs"])
 
     def start(self) -> None:
-
         # first make a single backtest
         self.fill_full_varholder()
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/bt_progress.py` & `freqtrade-2024.5/freqtrade/optimize/bt_progress.py`

 * *Files 14% similar despite different names*

```diff
@@ -21,13 +21,14 @@
         self._progress += 1
 
     @property
     def progress(self):
         """
         Get progress as ratio, capped to be between 0 and 1 (to avoid small calculation errors).
         """
-        return max(min(round(self._progress / self._max_steps, 5)
-                       if self._max_steps > 0 else 0, 1), 0)
+        return max(
+            min(round(self._progress / self._max_steps, 5) if self._max_steps > 0 else 0, 1), 0
+        )
 
     @property
     def action(self):
         return str(self._action)
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/edge_cli.py` & `freqtrade-2024.5/freqtrade/optimize/edge_cli.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=missing-docstring, W0212, too-many-arguments
 
 """
 This module contains the edge backtesting interface
 """
+
 import logging
 
 from freqtrade import constants
 from freqtrade.configuration import TimeRange, validate_config_consistency
 from freqtrade.constants import Config
 from freqtrade.data.dataprovider import DataProvider
 from freqtrade.edge import Edge
@@ -26,28 +27,29 @@
     edge.start()
     """
 
     def __init__(self, config: Config) -> None:
         self.config = config
 
         # Ensure using dry-run
-        self.config['dry_run'] = True
-        self.config['stake_amount'] = constants.UNLIMITED_STAKE_AMOUNT
+        self.config["dry_run"] = True
+        self.config["stake_amount"] = constants.UNLIMITED_STAKE_AMOUNT
         self.exchange = ExchangeResolver.load_exchange(self.config)
         self.strategy = StrategyResolver.load_strategy(self.config)
         self.strategy.dp = DataProvider(config, self.exchange)
 
         validate_config_consistency(self.config)
 
         self.edge = Edge(config, self.exchange, self.strategy)
         # Set refresh_pairs to false for edge-cli (it must be true for edge)
         self.edge._refresh_pairs = False
 
-        self.edge._timerange = TimeRange.parse_timerange(None if self.config.get(
-            'timerange') is None else str(self.config.get('timerange')))
+        self.edge._timerange = TimeRange.parse_timerange(
+            None if self.config.get("timerange") is None else str(self.config.get("timerange"))
+        )
         self.strategy.ft_bot_start()
 
     def start(self) -> None:
-        result = self.edge.calculate(self.config['exchange']['pair_whitelist'])
+        result = self.edge.calculate(self.config["exchange"]["pair_whitelist"])
         if result:
-            print('')  # blank line for readability
+            print("")  # blank line for readability
             print(generate_edge_table(self.edge._cached_pairs))
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt.py`

 * *Files 8% similar despite different names*

```diff
@@ -14,30 +14,41 @@
 from typing import Any, Dict, List, Optional, Tuple
 
 import rapidjson
 from colorama import init as colorama_init
 from joblib import Parallel, cpu_count, delayed, dump, load, wrap_non_picklable_objects
 from joblib.externals import cloudpickle
 from pandas import DataFrame
-from rich.progress import (BarColumn, MofNCompleteColumn, Progress, TaskProgressColumn, TextColumn,
-                           TimeElapsedColumn, TimeRemainingColumn)
+from rich.progress import (
+    BarColumn,
+    MofNCompleteColumn,
+    Progress,
+    TaskProgressColumn,
+    TextColumn,
+    TimeElapsedColumn,
+    TimeRemainingColumn,
+)
 
 from freqtrade.constants import DATETIME_PRINT_FORMAT, FTHYPT_FILEVERSION, LAST_BT_RESULT_FN, Config
 from freqtrade.data.converter import trim_dataframes
 from freqtrade.data.history import get_timerange
 from freqtrade.data.metrics import calculate_market_change
 from freqtrade.enums import HyperoptState
 from freqtrade.exceptions import OperationalException
 from freqtrade.misc import deep_merge_dicts, file_dump_json, plural
 from freqtrade.optimize.backtesting import Backtesting
+
 # Import IHyperOpt and IHyperOptLoss to allow unpickling classes from these modules
 from freqtrade.optimize.hyperopt_auto import HyperOptAuto
 from freqtrade.optimize.hyperopt_loss_interface import IHyperOptLoss
-from freqtrade.optimize.hyperopt_tools import (HyperoptStateContainer, HyperoptTools,
-                                               hyperopt_serializer)
+from freqtrade.optimize.hyperopt_tools import (
+    HyperoptStateContainer,
+    HyperoptTools,
+    hyperopt_serializer,
+)
 from freqtrade.optimize.optimize_reports import generate_strategy_stats
 from freqtrade.resolvers.hyperopt_resolver import HyperOptLossResolver
 
 
 # Suppress scikit-learn FutureWarnings from skopt
 with warnings.catch_warnings():
     warnings.filterwarnings("ignore", category=FutureWarning)
@@ -78,66 +89,71 @@
         self.config = config
         self.min_date: datetime
         self.max_date: datetime
 
         self.backtesting = Backtesting(self.config)
         self.pairlist = self.backtesting.pairlists.whitelist
         self.custom_hyperopt: HyperOptAuto
-        self.analyze_per_epoch = self.config.get('analyze_per_epoch', False)
+        self.analyze_per_epoch = self.config.get("analyze_per_epoch", False)
         HyperoptStateContainer.set_state(HyperoptState.STARTUP)
 
-        if not self.config.get('hyperopt'):
+        if not self.config.get("hyperopt"):
             self.custom_hyperopt = HyperOptAuto(self.config)
         else:
             raise OperationalException(
                 "Using separate Hyperopt files has been removed in 2021.9. Please convert "
-                "your existing Hyperopt file to the new Hyperoptable strategy interface")
+                "your existing Hyperopt file to the new Hyperoptable strategy interface"
+            )
 
         self.backtesting._set_strategy(self.backtesting.strategylist[0])
         self.custom_hyperopt.strategy = self.backtesting.strategy
 
         self.hyperopt_pickle_magic(self.backtesting.strategy.__class__.__bases__)
         self.custom_hyperoptloss: IHyperOptLoss = HyperOptLossResolver.load_hyperoptloss(
-            self.config)
+            self.config
+        )
         self.calculate_loss = self.custom_hyperoptloss.hyperopt_loss_function
         time_now = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
-        strategy = str(self.config['strategy'])
-        self.results_file: Path = (self.config['user_data_dir'] / 'hyperopt_results' /
-                                   f'strategy_{strategy}_{time_now}.fthypt')
-        self.data_pickle_file = (self.config['user_data_dir'] /
-                                 'hyperopt_results' / 'hyperopt_tickerdata.pkl')
-        self.total_epochs = config.get('epochs', 0)
+        strategy = str(self.config["strategy"])
+        self.results_file: Path = (
+            self.config["user_data_dir"]
+            / "hyperopt_results"
+            / f"strategy_{strategy}_{time_now}.fthypt"
+        )
+        self.data_pickle_file = (
+            self.config["user_data_dir"] / "hyperopt_results" / "hyperopt_tickerdata.pkl"
+        )
+        self.total_epochs = config.get("epochs", 0)
 
         self.current_best_loss = 100
 
         self.clean_hyperopt()
 
         self.market_change = 0.0
         self.num_epochs_saved = 0
         self.current_best_epoch: Optional[Dict[str, Any]] = None
 
         # Use max_open_trades for hyperopt as well, except --disable-max-market-positions is set
-        if not self.config.get('use_max_market_positions', True):
-            logger.debug('Ignoring max_open_trades (--disable-max-market-positions was used) ...')
-            self.backtesting.strategy.max_open_trades = float('inf')
-            config.update({'max_open_trades': self.backtesting.strategy.max_open_trades})
+        if not self.config.get("use_max_market_positions", True):
+            logger.debug("Ignoring max_open_trades (--disable-max-market-positions was used) ...")
+            self.backtesting.strategy.max_open_trades = float("inf")
+            config.update({"max_open_trades": self.backtesting.strategy.max_open_trades})
 
-        if HyperoptTools.has_space(self.config, 'sell'):
+        if HyperoptTools.has_space(self.config, "sell"):
             # Make sure use_exit_signal is enabled
-            self.config['use_exit_signal'] = True
+            self.config["use_exit_signal"] = True
 
-        self.print_all = self.config.get('print_all', False)
+        self.print_all = self.config.get("print_all", False)
         self.hyperopt_table_header = 0
-        self.print_colorized = self.config.get('print_colorized', False)
-        self.print_json = self.config.get('print_json', False)
+        self.print_colorized = self.config.get("print_colorized", False)
+        self.print_json = self.config.get("print_json", False)
 
     @staticmethod
     def get_lock_filename(config: Config) -> str:
-
-        return str(config['user_data_dir'] / 'hyperopt.lock')
+        return str(config["user_data_dir"] / "hyperopt.lock")
 
     def clean_hyperopt(self) -> None:
         """
         Remove hyperopt pickle files to restart hyperopt.
         """
         for f in [self.data_pickle_file, self.results_file]:
             p = Path(f)
@@ -148,153 +164,171 @@
     def hyperopt_pickle_magic(self, bases) -> None:
         """
         Hyperopt magic to allow strategy inheritance across files.
         For this to properly work, we need to register the module of the imported class
         to pickle as value.
         """
         for modules in bases:
-            if modules.__name__ != 'IStrategy':
+            if modules.__name__ != "IStrategy":
                 cloudpickle.register_pickle_by_value(sys.modules[modules.__module__])
                 self.hyperopt_pickle_magic(modules.__bases__)
 
     def _get_params_dict(self, dimensions: List[Dimension], raw_params: List[Any]) -> Dict:
-
         # Ensure the number of dimensions match
         # the number of parameters in the list.
         if len(raw_params) != len(dimensions):
-            raise ValueError('Mismatch in number of search-space dimensions.')
+            raise ValueError("Mismatch in number of search-space dimensions.")
 
         # Return a dict where the keys are the names of the dimensions
         # and the values are taken from the list of parameters.
         return {d.name: v for d, v in zip(dimensions, raw_params)}
 
     def _save_result(self, epoch: Dict) -> None:
         """
         Save hyperopt results to file
         Store one line per epoch.
         While not a valid json object - this allows appending easily.
         :param epoch: result dictionary for this epoch.
         """
         epoch[FTHYPT_FILEVERSION] = 2
-        with self.results_file.open('a') as f:
-            rapidjson.dump(epoch, f, default=hyperopt_serializer,
-                           number_mode=rapidjson.NM_NATIVE | rapidjson.NM_NAN)
+        with self.results_file.open("a") as f:
+            rapidjson.dump(
+                epoch,
+                f,
+                default=hyperopt_serializer,
+                number_mode=rapidjson.NM_NATIVE | rapidjson.NM_NAN,
+            )
             f.write("\n")
 
         self.num_epochs_saved += 1
-        logger.debug(f"{self.num_epochs_saved} {plural(self.num_epochs_saved, 'epoch')} "
-                     f"saved to '{self.results_file}'.")
+        logger.debug(
+            f"{self.num_epochs_saved} {plural(self.num_epochs_saved, 'epoch')} "
+            f"saved to '{self.results_file}'."
+        )
         # Store hyperopt filename
         latest_filename = Path.joinpath(self.results_file.parent, LAST_BT_RESULT_FN)
-        file_dump_json(latest_filename, {'latest_hyperopt': str(self.results_file.name)},
-                       log=False)
+        file_dump_json(latest_filename, {"latest_hyperopt": str(self.results_file.name)}, log=False)
 
     def _get_params_details(self, params: Dict) -> Dict:
         """
         Return the params for each space
         """
         result: Dict = {}
 
-        if HyperoptTools.has_space(self.config, 'buy'):
-            result['buy'] = {p.name: params.get(p.name) for p in self.buy_space}
-        if HyperoptTools.has_space(self.config, 'sell'):
-            result['sell'] = {p.name: params.get(p.name) for p in self.sell_space}
-        if HyperoptTools.has_space(self.config, 'protection'):
-            result['protection'] = {p.name: params.get(p.name) for p in self.protection_space}
-        if HyperoptTools.has_space(self.config, 'roi'):
-            result['roi'] = {str(k): v for k, v in
-                             self.custom_hyperopt.generate_roi_table(params).items()}
-        if HyperoptTools.has_space(self.config, 'stoploss'):
-            result['stoploss'] = {p.name: params.get(p.name) for p in self.stoploss_space}
-        if HyperoptTools.has_space(self.config, 'trailing'):
-            result['trailing'] = self.custom_hyperopt.generate_trailing_params(params)
-        if HyperoptTools.has_space(self.config, 'trades'):
-            result['max_open_trades'] = {
-                'max_open_trades': self.backtesting.strategy.max_open_trades
-                if self.backtesting.strategy.max_open_trades != float('inf') else -1}
+        if HyperoptTools.has_space(self.config, "buy"):
+            result["buy"] = {p.name: params.get(p.name) for p in self.buy_space}
+        if HyperoptTools.has_space(self.config, "sell"):
+            result["sell"] = {p.name: params.get(p.name) for p in self.sell_space}
+        if HyperoptTools.has_space(self.config, "protection"):
+            result["protection"] = {p.name: params.get(p.name) for p in self.protection_space}
+        if HyperoptTools.has_space(self.config, "roi"):
+            result["roi"] = {
+                str(k): v for k, v in self.custom_hyperopt.generate_roi_table(params).items()
+            }
+        if HyperoptTools.has_space(self.config, "stoploss"):
+            result["stoploss"] = {p.name: params.get(p.name) for p in self.stoploss_space}
+        if HyperoptTools.has_space(self.config, "trailing"):
+            result["trailing"] = self.custom_hyperopt.generate_trailing_params(params)
+        if HyperoptTools.has_space(self.config, "trades"):
+            result["max_open_trades"] = {
+                "max_open_trades": (
+                    self.backtesting.strategy.max_open_trades
+                    if self.backtesting.strategy.max_open_trades != float("inf")
+                    else -1
+                )
+            }
 
         return result
 
     def _get_no_optimize_details(self) -> Dict[str, Any]:
         """
         Get non-optimized parameters
         """
         result: Dict[str, Any] = {}
         strategy = self.backtesting.strategy
-        if not HyperoptTools.has_space(self.config, 'roi'):
-            result['roi'] = {str(k): v for k, v in strategy.minimal_roi.items()}
-        if not HyperoptTools.has_space(self.config, 'stoploss'):
-            result['stoploss'] = {'stoploss': strategy.stoploss}
-        if not HyperoptTools.has_space(self.config, 'trailing'):
-            result['trailing'] = {
-                'trailing_stop': strategy.trailing_stop,
-                'trailing_stop_positive': strategy.trailing_stop_positive,
-                'trailing_stop_positive_offset': strategy.trailing_stop_positive_offset,
-                'trailing_only_offset_is_reached': strategy.trailing_only_offset_is_reached,
+        if not HyperoptTools.has_space(self.config, "roi"):
+            result["roi"] = {str(k): v for k, v in strategy.minimal_roi.items()}
+        if not HyperoptTools.has_space(self.config, "stoploss"):
+            result["stoploss"] = {"stoploss": strategy.stoploss}
+        if not HyperoptTools.has_space(self.config, "trailing"):
+            result["trailing"] = {
+                "trailing_stop": strategy.trailing_stop,
+                "trailing_stop_positive": strategy.trailing_stop_positive,
+                "trailing_stop_positive_offset": strategy.trailing_stop_positive_offset,
+                "trailing_only_offset_is_reached": strategy.trailing_only_offset_is_reached,
             }
-        if not HyperoptTools.has_space(self.config, 'trades'):
-            result['max_open_trades'] = {'max_open_trades': strategy.max_open_trades}
+        if not HyperoptTools.has_space(self.config, "trades"):
+            result["max_open_trades"] = {"max_open_trades": strategy.max_open_trades}
         return result
 
     def print_results(self, results) -> None:
         """
         Log results if it is better than any previous evaluation
         TODO: this should be moved to HyperoptTools too
         """
-        is_best = results['is_best']
+        is_best = results["is_best"]
 
         if self.print_all or is_best:
             print(
                 HyperoptTools.get_result_table(
-                    self.config, results, self.total_epochs,
-                    self.print_all, self.print_colorized,
-                    self.hyperopt_table_header
+                    self.config,
+                    results,
+                    self.total_epochs,
+                    self.print_all,
+                    self.print_colorized,
+                    self.hyperopt_table_header,
                 )
             )
             self.hyperopt_table_header = 2
 
     def init_spaces(self):
         """
         Assign the dimensions in the hyperoptimization space.
         """
-        if HyperoptTools.has_space(self.config, 'protection'):
+        if HyperoptTools.has_space(self.config, "protection"):
             # Protections can only be optimized when using the Parameter interface
             logger.debug("Hyperopt has 'protection' space")
             # Enable Protections if protection space is selected.
-            self.config['enable_protections'] = True
+            self.config["enable_protections"] = True
             self.backtesting.enable_protections = True
             self.protection_space = self.custom_hyperopt.protection_space()
 
-        if HyperoptTools.has_space(self.config, 'buy'):
+        if HyperoptTools.has_space(self.config, "buy"):
             logger.debug("Hyperopt has 'buy' space")
             self.buy_space = self.custom_hyperopt.buy_indicator_space()
 
-        if HyperoptTools.has_space(self.config, 'sell'):
+        if HyperoptTools.has_space(self.config, "sell"):
             logger.debug("Hyperopt has 'sell' space")
             self.sell_space = self.custom_hyperopt.sell_indicator_space()
 
-        if HyperoptTools.has_space(self.config, 'roi'):
+        if HyperoptTools.has_space(self.config, "roi"):
             logger.debug("Hyperopt has 'roi' space")
             self.roi_space = self.custom_hyperopt.roi_space()
 
-        if HyperoptTools.has_space(self.config, 'stoploss'):
+        if HyperoptTools.has_space(self.config, "stoploss"):
             logger.debug("Hyperopt has 'stoploss' space")
             self.stoploss_space = self.custom_hyperopt.stoploss_space()
 
-        if HyperoptTools.has_space(self.config, 'trailing'):
+        if HyperoptTools.has_space(self.config, "trailing"):
             logger.debug("Hyperopt has 'trailing' space")
             self.trailing_space = self.custom_hyperopt.trailing_space()
 
-        if HyperoptTools.has_space(self.config, 'trades'):
+        if HyperoptTools.has_space(self.config, "trades"):
             logger.debug("Hyperopt has 'trades' space")
             self.max_open_trades_space = self.custom_hyperopt.max_open_trades_space()
 
-        self.dimensions = (self.buy_space + self.sell_space + self.protection_space
-                           + self.roi_space + self.stoploss_space + self.trailing_space
-                           + self.max_open_trades_space)
+        self.dimensions = (
+            self.buy_space
+            + self.sell_space
+            + self.protection_space
+            + self.roi_space
+            + self.stoploss_space
+            + self.trailing_space
+            + self.max_open_trades_space
+        )
 
     def assign_params(self, params_dict: Dict, category: str) -> None:
         """
         Assign hyperoptable parameters
         """
         for attr_name, attr in self.backtesting.strategy.enumerate_parameters(category):
             if attr.optimize:
@@ -308,112 +342,127 @@
         Keep this function as optimized as possible!
         """
         HyperoptStateContainer.set_state(HyperoptState.OPTIMIZE)
         backtest_start_time = datetime.now(timezone.utc)
         params_dict = self._get_params_dict(self.dimensions, raw_params)
 
         # Apply parameters
-        if HyperoptTools.has_space(self.config, 'buy'):
-            self.assign_params(params_dict, 'buy')
+        if HyperoptTools.has_space(self.config, "buy"):
+            self.assign_params(params_dict, "buy")
 
-        if HyperoptTools.has_space(self.config, 'sell'):
-            self.assign_params(params_dict, 'sell')
+        if HyperoptTools.has_space(self.config, "sell"):
+            self.assign_params(params_dict, "sell")
 
-        if HyperoptTools.has_space(self.config, 'protection'):
-            self.assign_params(params_dict, 'protection')
+        if HyperoptTools.has_space(self.config, "protection"):
+            self.assign_params(params_dict, "protection")
 
-        if HyperoptTools.has_space(self.config, 'roi'):
-            self.backtesting.strategy.minimal_roi = (
-                self.custom_hyperopt.generate_roi_table(params_dict))
+        if HyperoptTools.has_space(self.config, "roi"):
+            self.backtesting.strategy.minimal_roi = self.custom_hyperopt.generate_roi_table(
+                params_dict
+            )
 
-        if HyperoptTools.has_space(self.config, 'stoploss'):
-            self.backtesting.strategy.stoploss = params_dict['stoploss']
+        if HyperoptTools.has_space(self.config, "stoploss"):
+            self.backtesting.strategy.stoploss = params_dict["stoploss"]
 
-        if HyperoptTools.has_space(self.config, 'trailing'):
+        if HyperoptTools.has_space(self.config, "trailing"):
             d = self.custom_hyperopt.generate_trailing_params(params_dict)
-            self.backtesting.strategy.trailing_stop = d['trailing_stop']
-            self.backtesting.strategy.trailing_stop_positive = d['trailing_stop_positive']
-            self.backtesting.strategy.trailing_stop_positive_offset = \
-                d['trailing_stop_positive_offset']
-            self.backtesting.strategy.trailing_only_offset_is_reached = \
-                d['trailing_only_offset_is_reached']
-
-        if HyperoptTools.has_space(self.config, 'trades'):
-            if self.config["stake_amount"] == "unlimited" and \
-                    (params_dict['max_open_trades'] == -1 or params_dict['max_open_trades'] == 0):
+            self.backtesting.strategy.trailing_stop = d["trailing_stop"]
+            self.backtesting.strategy.trailing_stop_positive = d["trailing_stop_positive"]
+            self.backtesting.strategy.trailing_stop_positive_offset = d[
+                "trailing_stop_positive_offset"
+            ]
+            self.backtesting.strategy.trailing_only_offset_is_reached = d[
+                "trailing_only_offset_is_reached"
+            ]
+
+        if HyperoptTools.has_space(self.config, "trades"):
+            if self.config["stake_amount"] == "unlimited" and (
+                params_dict["max_open_trades"] == -1 or params_dict["max_open_trades"] == 0
+            ):
                 # Ignore unlimited max open trades if stake amount is unlimited
-                params_dict.update({'max_open_trades': self.config['max_open_trades']})
+                params_dict.update({"max_open_trades": self.config["max_open_trades"]})
 
-            updated_max_open_trades = int(params_dict['max_open_trades']) \
-                if (params_dict['max_open_trades'] != -1
-                    and params_dict['max_open_trades'] != 0) else float('inf')
+            updated_max_open_trades = (
+                int(params_dict["max_open_trades"])
+                if (params_dict["max_open_trades"] != -1 and params_dict["max_open_trades"] != 0)
+                else float("inf")
+            )
 
-            self.config.update({'max_open_trades': updated_max_open_trades})
+            self.config.update({"max_open_trades": updated_max_open_trades})
 
             self.backtesting.strategy.max_open_trades = updated_max_open_trades
 
-        with self.data_pickle_file.open('rb') as f:
-            processed = load(f, mmap_mode='r')
+        with self.data_pickle_file.open("rb") as f:
+            processed = load(f, mmap_mode="r")
             if self.analyze_per_epoch:
                 # Data is not yet analyzed, rerun populate_indicators.
                 processed = self.advise_and_trim(processed)
 
         bt_results = self.backtesting.backtest(
-            processed=processed,
-            start_date=self.min_date,
-            end_date=self.max_date
+            processed=processed, start_date=self.min_date, end_date=self.max_date
         )
         backtest_end_time = datetime.now(timezone.utc)
-        bt_results.update({
-            'backtest_start_time': int(backtest_start_time.timestamp()),
-            'backtest_end_time': int(backtest_end_time.timestamp()),
-        })
-
-        return self._get_results_dict(bt_results, self.min_date, self.max_date,
-                                      params_dict,
-                                      processed=processed)
-
-    def _get_results_dict(self, backtesting_results, min_date, max_date,
-                          params_dict, processed: Dict[str, DataFrame]
-                          ) -> Dict[str, Any]:
+        bt_results.update(
+            {
+                "backtest_start_time": int(backtest_start_time.timestamp()),
+                "backtest_end_time": int(backtest_end_time.timestamp()),
+            }
+        )
+
+        return self._get_results_dict(
+            bt_results, self.min_date, self.max_date, params_dict, processed=processed
+        )
+
+    def _get_results_dict(
+        self, backtesting_results, min_date, max_date, params_dict, processed: Dict[str, DataFrame]
+    ) -> Dict[str, Any]:
         params_details = self._get_params_details(params_dict)
 
         strat_stats = generate_strategy_stats(
-            self.pairlist, self.backtesting.strategy.get_strategy_name(),
-            backtesting_results, min_date, max_date, market_change=self.market_change,
+            self.pairlist,
+            self.backtesting.strategy.get_strategy_name(),
+            backtesting_results,
+            min_date,
+            max_date,
+            market_change=self.market_change,
             is_hyperopt=True,
         )
         results_explanation = HyperoptTools.format_results_explanation_string(
-            strat_stats, self.config['stake_currency'])
+            strat_stats, self.config["stake_currency"]
+        )
 
         not_optimized = self.backtesting.strategy.get_no_optimize_params()
         not_optimized = deep_merge_dicts(not_optimized, self._get_no_optimize_details())
 
-        trade_count = strat_stats['total_trades']
-        total_profit = strat_stats['profit_total']
+        trade_count = strat_stats["total_trades"]
+        total_profit = strat_stats["profit_total"]
 
         # If this evaluation contains too short amount of trades to be
         # interesting -- consider it as 'bad' (assigned max. loss value)
         # in order to cast this hyperspace point away from optimization
         # path. We do not want to optimize 'hodl' strategies.
         loss: float = MAX_LOSS
-        if trade_count >= self.config['hyperopt_min_trades']:
-            loss = self.calculate_loss(results=backtesting_results['results'],
-                                       trade_count=trade_count,
-                                       min_date=min_date, max_date=max_date,
-                                       config=self.config, processed=processed,
-                                       backtest_stats=strat_stats)
+        if trade_count >= self.config["hyperopt_min_trades"]:
+            loss = self.calculate_loss(
+                results=backtesting_results["results"],
+                trade_count=trade_count,
+                min_date=min_date,
+                max_date=max_date,
+                config=self.config,
+                processed=processed,
+                backtest_stats=strat_stats,
+            )
         return {
-            'loss': loss,
-            'params_dict': params_dict,
-            'params_details': params_details,
-            'params_not_optimized': not_optimized,
-            'results_metrics': strat_stats,
-            'results_explanation': results_explanation,
-            'total_profit': total_profit,
+            "loss": loss,
+            "params_dict": params_dict,
+            "params_details": params_details,
+            "params_not_optimized": not_optimized,
+            "results_metrics": strat_stats,
+            "results_explanation": results_explanation,
+            "total_profit": total_profit,
         }
 
     def get_optimizer(self, dimensions: List[Dimension], cpu_count) -> Optimizer:
         estimator = self.custom_hyperopt.generate_estimator(dimensions=dimensions)
 
         acq_optimizer = "sampling"
         if isinstance(estimator, str):
@@ -424,38 +473,38 @@
 
         logger.info(f"Using estimator {estimator}.")
         return Optimizer(
             dimensions,
             base_estimator=estimator,
             acq_optimizer=acq_optimizer,
             n_initial_points=INITIAL_POINTS,
-            acq_optimizer_kwargs={'n_jobs': cpu_count},
+            acq_optimizer_kwargs={"n_jobs": cpu_count},
             random_state=self.random_state,
             model_queue_size=SKOPT_MODEL_QUEUE_SIZE,
         )
 
-    def run_optimizer_parallel(
-            self, parallel: Parallel, asked: List[List]) -> List[Dict[str, Any]]:
-        """ Start optimizer in a parallel way """
-        return parallel(delayed(
-                        wrap_non_picklable_objects(self.generate_optimizer))(v) for v in asked)
+    def run_optimizer_parallel(self, parallel: Parallel, asked: List[List]) -> List[Dict[str, Any]]:
+        """Start optimizer in a parallel way"""
+        return parallel(
+            delayed(wrap_non_picklable_objects(self.generate_optimizer))(v) for v in asked
+        )
 
     def _set_random_state(self, random_state: Optional[int]) -> int:
         return random_state or random.randint(1, 2**16 - 1)
 
     def advise_and_trim(self, data: Dict[str, DataFrame]) -> Dict[str, DataFrame]:
         preprocessed = self.backtesting.strategy.advise_all_indicators(data)
 
         # Trim startup period from analyzed dataframe to get correct dates for output.
         # This is only used to keep track of min/max date after trimming.
         # The result is NOT returned from this method, actual trimming happens in backtesting.
         trimmed = trim_dataframes(preprocessed, self.timerange, self.backtesting.required_startup)
         self.min_date, self.max_date = get_timerange(trimmed)
         if not self.market_change:
-            self.market_change = calculate_market_change(trimmed, 'close')
+            self.market_change = calculate_market_change(trimmed, "close")
 
         # Real trimming will happen as part of backtesting.
         return preprocessed
 
     def prepare_hyperopt_data(self) -> None:
         HyperoptStateContainer.set_state(HyperoptState.DATALOAD)
         data, self.timerange = self.backtesting.load_bt_data()
@@ -463,18 +512,20 @@
         logger.info("Dataload complete. Calculating indicators")
 
         if not self.analyze_per_epoch:
             HyperoptStateContainer.set_state(HyperoptState.INDICATORS)
 
             preprocessed = self.advise_and_trim(data)
 
-            logger.info(f'Hyperopting with data from '
-                        f'{self.min_date.strftime(DATETIME_PRINT_FORMAT)} '
-                        f'up to {self.max_date.strftime(DATETIME_PRINT_FORMAT)} '
-                        f'({(self.max_date - self.min_date).days} days)..')
+            logger.info(
+                f"Hyperopting with data from "
+                f"{self.min_date.strftime(DATETIME_PRINT_FORMAT)} "
+                f"up to {self.max_date.strftime(DATETIME_PRINT_FORMAT)} "
+                f"({(self.max_date - self.min_date).days} days).."
+            )
             # Store non-trimmed data - will be trimmed after signal generation.
             dump(preprocessed, self.data_pickle_file)
         else:
             dump(data, self.data_pickle_file)
 
     def get_asked_points(self, n_points: int) -> Tuple[List[List[Any]], List[bool]]:
         """
@@ -484,73 +535,77 @@
         1. Try to get points using `self.opt.ask` first
         2. Discard the points that have already been evaluated
         3. Retry using `self.opt.ask` up to 3 times
         4. If still some points are missing in respect to `n_points`, random sample some points
         5. Repeat until at least `n_points` points in the `asked_non_tried` list
         6. Return a list with length truncated at `n_points`
         """
+
         def unique_list(a_list):
             new_list = []
             for item in a_list:
                 if item not in new_list:
                     new_list.append(item)
             return new_list
+
         i = 0
         asked_non_tried: List[List[Any]] = []
         is_random_non_tried: List[bool] = []
         while i < 5 and len(asked_non_tried) < n_points:
             if i < 3:
                 self.opt.cache_ = {}
                 asked = unique_list(self.opt.ask(n_points=n_points * 5 if i > 0 else n_points))
                 is_random = [False for _ in range(len(asked))]
             else:
                 asked = unique_list(self.opt.space.rvs(n_samples=n_points * 5))
                 is_random = [True for _ in range(len(asked))]
-            is_random_non_tried += [rand for x, rand in zip(asked, is_random)
-                                    if x not in self.opt.Xi
-                                    and x not in asked_non_tried]
-            asked_non_tried += [x for x in asked
-                                if x not in self.opt.Xi
-                                and x not in asked_non_tried]
+            is_random_non_tried += [
+                rand
+                for x, rand in zip(asked, is_random)
+                if x not in self.opt.Xi and x not in asked_non_tried
+            ]
+            asked_non_tried += [
+                x for x in asked if x not in self.opt.Xi and x not in asked_non_tried
+            ]
             i += 1
 
         if asked_non_tried:
             return (
-                asked_non_tried[:min(len(asked_non_tried), n_points)],
-                is_random_non_tried[:min(len(asked_non_tried), n_points)]
+                asked_non_tried[: min(len(asked_non_tried), n_points)],
+                is_random_non_tried[: min(len(asked_non_tried), n_points)],
             )
         else:
             return self.opt.ask(n_points=n_points), [False for _ in range(n_points)]
 
     def evaluate_result(self, val: Dict[str, Any], current: int, is_random: bool):
         """
         Evaluate results returned from generate_optimizer
         """
-        val['current_epoch'] = current
-        val['is_initial_point'] = current <= INITIAL_POINTS
+        val["current_epoch"] = current
+        val["is_initial_point"] = current <= INITIAL_POINTS
 
         logger.debug("Optimizer epoch evaluated: %s", val)
 
         is_best = HyperoptTools.is_best_loss(val, self.current_best_loss)
         # This value is assigned here and not in the optimization method
         # to keep proper order in the list of results. That's because
         # evaluations can take different time. Here they are aligned in the
         # order they will be shown to the user.
-        val['is_best'] = is_best
-        val['is_random'] = is_random
+        val["is_best"] = is_best
+        val["is_random"] = is_random
         self.print_results(val)
 
         if is_best:
-            self.current_best_loss = val['loss']
+            self.current_best_loss = val["loss"]
             self.current_best_epoch = val
 
         self._save_result(val)
 
     def start(self) -> None:
-        self.random_state = self._set_random_state(self.config.get('hyperopt_random_state'))
+        self.random_state = self._set_random_state(self.config.get("hyperopt_random_state"))
         logger.info(f"Using optimizer random state: {self.random_state}")
         self.hyperopt_table_header = -1
         # Initialize spaces ...
         self.init_spaces()
 
         self.prepare_hyperopt_data()
 
@@ -562,26 +617,26 @@
         self.backtesting.exchange._loop_lock = None  # type: ignore
         self.backtesting.exchange._cache_lock = None  # type: ignore
         # self.backtesting.exchange = None  # type: ignore
         self.backtesting.pairlists = None  # type: ignore
 
         cpus = cpu_count()
         logger.info(f"Found {cpus} CPU cores. Let's make them scream!")
-        config_jobs = self.config.get('hyperopt_jobs', -1)
-        logger.info(f'Number of parallel jobs set as: {config_jobs}')
+        config_jobs = self.config.get("hyperopt_jobs", -1)
+        logger.info(f"Number of parallel jobs set as: {config_jobs}")
 
         self.opt = self.get_optimizer(self.dimensions, config_jobs)
 
         if self.print_colorized:
             colorama_init(autoreset=True)
 
         try:
             with Parallel(n_jobs=config_jobs) as parallel:
                 jobs = parallel._effective_n_jobs()
-                logger.info(f'Effective number of parallel workers used: {jobs}')
+                logger.info(f"Effective number of parallel workers used: {jobs}")
 
                 # Define progressbar
                 with Progress(
                     TextColumn("[progress.description]{task.description}"),
                     BarColumn(bar_width=None),
                     MofNCompleteColumn(),
                     TaskProgressColumn(),
@@ -596,52 +651,55 @@
                     start = 0
 
                     if self.analyze_per_epoch:
                         # First analysis not in parallel mode when using --analyze-per-epoch.
                         # This allows dataprovider to load it's informative cache.
                         asked, is_random = self.get_asked_points(n_points=1)
                         f_val0 = self.generate_optimizer(asked[0])
-                        self.opt.tell(asked, [f_val0['loss']])
+                        self.opt.tell(asked, [f_val0["loss"]])
                         self.evaluate_result(f_val0, 1, is_random[0])
                         pbar.update(task, advance=1)
                         start += 1
 
                     evals = ceil((self.total_epochs - start) / jobs)
                     for i in range(evals):
                         # Correct the number of epochs to be processed for the last
                         # iteration (should not exceed self.total_epochs in total)
                         n_rest = (i + 1) * jobs - (self.total_epochs - start)
                         current_jobs = jobs - n_rest if n_rest > 0 else jobs
 
                         asked, is_random = self.get_asked_points(n_points=current_jobs)
                         f_val = self.run_optimizer_parallel(parallel, asked)
-                        self.opt.tell(asked, [v['loss'] for v in f_val])
+                        self.opt.tell(asked, [v["loss"] for v in f_val])
 
                         for j, val in enumerate(f_val):
                             # Use human-friendly indexes here (starting from 1)
                             current = i * jobs + j + 1 + start
 
                             self.evaluate_result(val, current, is_random[j])
                             pbar.update(task, advance=1)
 
         except KeyboardInterrupt:
-            print('User interrupted..')
+            print("User interrupted..")
 
-        logger.info(f"{self.num_epochs_saved} {plural(self.num_epochs_saved, 'epoch')} "
-                    f"saved to '{self.results_file}'.")
+        logger.info(
+            f"{self.num_epochs_saved} {plural(self.num_epochs_saved, 'epoch')} "
+            f"saved to '{self.results_file}'."
+        )
 
         if self.current_best_epoch:
             HyperoptTools.try_export_params(
-                self.config,
-                self.backtesting.strategy.get_strategy_name(),
-                self.current_best_epoch)
+                self.config, self.backtesting.strategy.get_strategy_name(), self.current_best_epoch
+            )
 
-            HyperoptTools.show_epoch_details(self.current_best_epoch, self.total_epochs,
-                                             self.print_json)
+            HyperoptTools.show_epoch_details(
+                self.current_best_epoch, self.total_epochs, self.print_json
+            )
         elif self.num_epochs_saved > 0:
             print(
                 f"No good result found for given optimization function in {self.num_epochs_saved} "
-                f"{plural(self.num_epochs_saved, 'epoch')}.")
+                f"{plural(self.num_epochs_saved, 'epoch')}."
+            )
         else:
             # This is printed when Ctrl+C is pressed quickly, before first epochs have
             # a chance to be evaluated.
             print("No epochs evaluated yet, no best result.")
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_auto.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_auto.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """
 HyperOptAuto class.
 This module implements a convenience auto-hyperopt class, which can be used together with strategies
  that implement IHyperStrategy interface.
 """
+
 import logging
 from contextlib import suppress
 from typing import Callable, Dict, List
 
 from freqtrade.exceptions import OperationalException
 
 
@@ -16,23 +17,25 @@
 from freqtrade.optimize.hyperopt_interface import EstimatorType, IHyperOpt
 
 
 logger = logging.getLogger(__name__)
 
 
 def _format_exception_message(space: str, ignore_missing_space: bool) -> None:
-    msg = (f"The '{space}' space is included into the hyperoptimization "
-           f"but no parameter for this space was found in your Strategy. "
-           )
+    msg = (
+        f"The '{space}' space is included into the hyperoptimization "
+        f"but no parameter for this space was found in your Strategy. "
+    )
     if ignore_missing_space:
         logger.warning(msg + "This space will be ignored.")
     else:
         raise OperationalException(
             msg + f"Please make sure to have parameters for this space enabled for optimization "
-            f"or remove the '{space}' space from hyperoptimization.")
+            f"or remove the '{space}' space from hyperoptimization."
+        )
 
 
 class HyperOptAuto(IHyperOpt):
     """
     This class delegates functionality to Strategy(IHyperStrategy) and Strategy.HyperOpt classes.
      Most of the time Strategy.HyperOpt class would only implement indicator_space and
      sell_indicator_space methods, but other hyperopt methods can be overridden as well.
@@ -40,15 +43,15 @@
 
     def _get_func(self, name) -> Callable:
         """
         Return a function defined in Strategy.HyperOpt class, or one defined in super() class.
         :param name: function name.
         :return: a requested function.
         """
-        hyperopt_cls = getattr(self.strategy, 'HyperOpt', None)
+        hyperopt_cls = getattr(self.strategy, "HyperOpt", None)
         default_func = getattr(super(), name)
         if hyperopt_cls:
             return getattr(hyperopt_cls, name, default_func)
         else:
             return default_func
 
     def _generate_indicator_space(self, category):
@@ -59,40 +62,40 @@
     def _get_indicator_space(self, category) -> List:
         # TODO: is this necessary, or can we call "generate_space" directly?
         indicator_space = list(self._generate_indicator_space(category))
         if len(indicator_space) > 0:
             return indicator_space
         else:
             _format_exception_message(
-                category,
-                self.config.get("hyperopt_ignore_missing_space", False))
+                category, self.config.get("hyperopt_ignore_missing_space", False)
+            )
             return []
 
-    def buy_indicator_space(self) -> List['Dimension']:
-        return self._get_indicator_space('buy')
+    def buy_indicator_space(self) -> List["Dimension"]:
+        return self._get_indicator_space("buy")
 
-    def sell_indicator_space(self) -> List['Dimension']:
-        return self._get_indicator_space('sell')
+    def sell_indicator_space(self) -> List["Dimension"]:
+        return self._get_indicator_space("sell")
 
-    def protection_space(self) -> List['Dimension']:
-        return self._get_indicator_space('protection')
+    def protection_space(self) -> List["Dimension"]:
+        return self._get_indicator_space("protection")
 
     def generate_roi_table(self, params: Dict) -> Dict[int, float]:
-        return self._get_func('generate_roi_table')(params)
+        return self._get_func("generate_roi_table")(params)
 
-    def roi_space(self) -> List['Dimension']:
-        return self._get_func('roi_space')()
+    def roi_space(self) -> List["Dimension"]:
+        return self._get_func("roi_space")()
 
-    def stoploss_space(self) -> List['Dimension']:
-        return self._get_func('stoploss_space')()
+    def stoploss_space(self) -> List["Dimension"]:
+        return self._get_func("stoploss_space")()
 
     def generate_trailing_params(self, params: Dict) -> Dict:
-        return self._get_func('generate_trailing_params')(params)
+        return self._get_func("generate_trailing_params")(params)
 
-    def trailing_space(self) -> List['Dimension']:
-        return self._get_func('trailing_space')()
+    def trailing_space(self) -> List["Dimension"]:
+        return self._get_func("trailing_space")()
 
-    def max_open_trades_space(self) -> List['Dimension']:
-        return self._get_func('max_open_trades_space')()
+    def max_open_trades_space(self) -> List["Dimension"]:
+        return self._get_func("max_open_trades_space")()
 
-    def generate_estimator(self, dimensions: List['Dimension'], **kwargs) -> EstimatorType:
-        return self._get_func('generate_estimator')(dimensions=dimensions, **kwargs)
+    def generate_estimator(self, dimensions: List["Dimension"], **kwargs) -> EstimatorType:
+        return self._get_func("generate_estimator")(dimensions=dimensions, **kwargs)
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_epoch_filters.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_epoch_filters.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,122 +7,117 @@
 logger = logging.getLogger(__name__)
 
 
 def hyperopt_filter_epochs(epochs: List, filteroptions: dict, log: bool = True) -> List:
     """
     Filter our items from the list of hyperopt results
     """
-    if filteroptions['only_best']:
-        epochs = [x for x in epochs if x['is_best']]
-    if filteroptions['only_profitable']:
-        epochs = [x for x in epochs
-                  if x['results_metrics'].get('profit_total', 0) > 0]
+    if filteroptions["only_best"]:
+        epochs = [x for x in epochs if x["is_best"]]
+    if filteroptions["only_profitable"]:
+        epochs = [x for x in epochs if x["results_metrics"].get("profit_total", 0) > 0]
 
     epochs = _hyperopt_filter_epochs_trade_count(epochs, filteroptions)
 
     epochs = _hyperopt_filter_epochs_duration(epochs, filteroptions)
 
     epochs = _hyperopt_filter_epochs_profit(epochs, filteroptions)
 
     epochs = _hyperopt_filter_epochs_objective(epochs, filteroptions)
     if log:
-        logger.info(f"{len(epochs)} " +
-                    ("best " if filteroptions['only_best'] else "") +
-                    ("profitable " if filteroptions['only_profitable'] else "") +
-                    "epochs found.")
+        logger.info(
+            f"{len(epochs)} "
+            + ("best " if filteroptions["only_best"] else "")
+            + ("profitable " if filteroptions["only_profitable"] else "")
+            + "epochs found."
+        )
     return epochs
 
 
 def _hyperopt_filter_epochs_trade(epochs: List, trade_count: int):
     """
     Filter epochs with trade-counts > trades
     """
-    return [
-        x for x in epochs if x['results_metrics'].get('total_trades', 0) > trade_count
-    ]
+    return [x for x in epochs if x["results_metrics"].get("total_trades", 0) > trade_count]
 
 
 def _hyperopt_filter_epochs_trade_count(epochs: List, filteroptions: dict) -> List:
+    if filteroptions["filter_min_trades"] > 0:
+        epochs = _hyperopt_filter_epochs_trade(epochs, filteroptions["filter_min_trades"])
 
-    if filteroptions['filter_min_trades'] > 0:
-        epochs = _hyperopt_filter_epochs_trade(epochs, filteroptions['filter_min_trades'])
-
-    if filteroptions['filter_max_trades'] > 0:
+    if filteroptions["filter_max_trades"] > 0:
         epochs = [
-            x for x in epochs
-            if x['results_metrics'].get('total_trades') < filteroptions['filter_max_trades']
+            x
+            for x in epochs
+            if x["results_metrics"].get("total_trades") < filteroptions["filter_max_trades"]
         ]
     return epochs
 
 
 def _hyperopt_filter_epochs_duration(epochs: List, filteroptions: dict) -> List:
-
     def get_duration_value(x):
         # Duration in minutes ...
-        if 'holding_avg_s' in x['results_metrics']:
-            avg = x['results_metrics']['holding_avg_s']
+        if "holding_avg_s" in x["results_metrics"]:
+            avg = x["results_metrics"]["holding_avg_s"]
             return avg // 60
         raise OperationalException(
             "Holding-average not available. Please omit the filter on average time, "
-            "or rerun hyperopt with this version")
+            "or rerun hyperopt with this version"
+        )
 
-    if filteroptions['filter_min_avg_time'] is not None:
+    if filteroptions["filter_min_avg_time"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
-        epochs = [
-            x for x in epochs
-            if get_duration_value(x) > filteroptions['filter_min_avg_time']
-        ]
-    if filteroptions['filter_max_avg_time'] is not None:
+        epochs = [x for x in epochs if get_duration_value(x) > filteroptions["filter_min_avg_time"]]
+    if filteroptions["filter_max_avg_time"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
-        epochs = [
-            x for x in epochs
-            if get_duration_value(x) < filteroptions['filter_max_avg_time']
-        ]
+        epochs = [x for x in epochs if get_duration_value(x) < filteroptions["filter_max_avg_time"]]
 
     return epochs
 
 
 def _hyperopt_filter_epochs_profit(epochs: List, filteroptions: dict) -> List:
-
-    if filteroptions['filter_min_avg_profit'] is not None:
+    if filteroptions["filter_min_avg_profit"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
         epochs = [
-            x for x in epochs
-            if x['results_metrics'].get('profit_mean', 0) * 100
-            > filteroptions['filter_min_avg_profit']
+            x
+            for x in epochs
+            if x["results_metrics"].get("profit_mean", 0) * 100
+            > filteroptions["filter_min_avg_profit"]
         ]
-    if filteroptions['filter_max_avg_profit'] is not None:
+    if filteroptions["filter_max_avg_profit"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
         epochs = [
-            x for x in epochs
-            if x['results_metrics'].get('profit_mean', 0) * 100
-            < filteroptions['filter_max_avg_profit']
+            x
+            for x in epochs
+            if x["results_metrics"].get("profit_mean", 0) * 100
+            < filteroptions["filter_max_avg_profit"]
         ]
-    if filteroptions['filter_min_total_profit'] is not None:
+    if filteroptions["filter_min_total_profit"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
         epochs = [
-            x for x in epochs
-            if x['results_metrics'].get('profit_total_abs', 0)
-            > filteroptions['filter_min_total_profit']
+            x
+            for x in epochs
+            if x["results_metrics"].get("profit_total_abs", 0)
+            > filteroptions["filter_min_total_profit"]
         ]
-    if filteroptions['filter_max_total_profit'] is not None:
+    if filteroptions["filter_max_total_profit"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
         epochs = [
-            x for x in epochs
-            if x['results_metrics'].get('profit_total_abs', 0)
-            < filteroptions['filter_max_total_profit']
+            x
+            for x in epochs
+            if x["results_metrics"].get("profit_total_abs", 0)
+            < filteroptions["filter_max_total_profit"]
         ]
     return epochs
 
 
 def _hyperopt_filter_epochs_objective(epochs: List, filteroptions: dict) -> List:
-
-    if filteroptions['filter_min_objective'] is not None:
+    if filteroptions["filter_min_objective"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
 
-        epochs = [x for x in epochs if x['loss'] < filteroptions['filter_min_objective']]
-    if filteroptions['filter_max_objective'] is not None:
+        epochs = [x for x in epochs if x["loss"] < filteroptions["filter_min_objective"]]
+    if filteroptions["filter_max_objective"] is not None:
         epochs = _hyperopt_filter_epochs_trade(epochs, 0)
 
-        epochs = [x for x in epochs if x['loss'] > filteroptions['filter_max_objective']]
+        epochs = [x for x in epochs if x["loss"] > filteroptions["filter_max_objective"]]
 
     return epochs
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_interface.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_interface.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 """
 IHyperOpt interface
 This module defines the interface to apply for hyperopt
 """
+
 import logging
 import math
 from abc import ABC
 from typing import Dict, List, Union
 
 from sklearn.base import RegressorMixin
 from skopt.space import Categorical, Dimension, Integer
@@ -26,43 +27,44 @@
     """
     Interface for freqtrade hyperopt
     Defines the mandatory structure must follow any custom hyperopt
 
     Class attributes you can use:
         timeframe -> int: value of the timeframe to use for the strategy
     """
+
     timeframe: str
     strategy: IStrategy
 
     def __init__(self, config: Config) -> None:
         self.config = config
 
         # Assign timeframe to be used in hyperopt
-        IHyperOpt.timeframe = str(config['timeframe'])
+        IHyperOpt.timeframe = str(config["timeframe"])
 
     def generate_estimator(self, dimensions: List[Dimension], **kwargs) -> EstimatorType:
         """
         Return base_estimator.
         Can be any of "GP", "RF", "ET", "GBRT" or an instance of a class
         inheriting from RegressorMixin (from sklearn).
         """
-        return 'ET'
+        return "ET"
 
     def generate_roi_table(self, params: Dict) -> Dict[int, float]:
         """
         Create a ROI table.
 
         Generates the ROI table that will be used by Hyperopt.
         You may override it in your custom Hyperopt class.
         """
         roi_table = {}
-        roi_table[0] = params['roi_p1'] + params['roi_p2'] + params['roi_p3']
-        roi_table[params['roi_t3']] = params['roi_p1'] + params['roi_p2']
-        roi_table[params['roi_t3'] + params['roi_t2']] = params['roi_p1']
-        roi_table[params['roi_t3'] + params['roi_t2'] + params['roi_t1']] = 0
+        roi_table[0] = params["roi_p1"] + params["roi_p2"] + params["roi_p3"]
+        roi_table[params["roi_t3"]] = params["roi_p1"] + params["roi_p2"]
+        roi_table[params["roi_t3"] + params["roi_t2"]] = params["roi_p1"]
+        roi_table[params["roi_t3"] + params["roi_t2"] + params["roi_t1"]] = 0
 
         return roi_table
 
     def roi_space(self) -> List[Dimension]:
         """
         Create a ROI space.
 
@@ -92,80 +94,84 @@
         # * 'roi_p' (limits for the ROI value steps) components are scaled logarithmically.
         #
         # The scaling is designed so that it maps exactly to the legacy Freqtrade roi_space()
         # method for the 5m timeframe.
         roi_t_scale = timeframe_min / 5
         roi_p_scale = math.log1p(timeframe_min) / math.log1p(5)
         roi_limits = {
-            'roi_t1_min': int(10 * roi_t_scale * roi_t_alpha),
-            'roi_t1_max': int(120 * roi_t_scale * roi_t_alpha),
-            'roi_t2_min': int(10 * roi_t_scale * roi_t_alpha),
-            'roi_t2_max': int(60 * roi_t_scale * roi_t_alpha),
-            'roi_t3_min': int(10 * roi_t_scale * roi_t_alpha),
-            'roi_t3_max': int(40 * roi_t_scale * roi_t_alpha),
-            'roi_p1_min': 0.01 * roi_p_scale * roi_p_alpha,
-            'roi_p1_max': 0.04 * roi_p_scale * roi_p_alpha,
-            'roi_p2_min': 0.01 * roi_p_scale * roi_p_alpha,
-            'roi_p2_max': 0.07 * roi_p_scale * roi_p_alpha,
-            'roi_p3_min': 0.01 * roi_p_scale * roi_p_alpha,
-            'roi_p3_max': 0.20 * roi_p_scale * roi_p_alpha,
+            "roi_t1_min": int(10 * roi_t_scale * roi_t_alpha),
+            "roi_t1_max": int(120 * roi_t_scale * roi_t_alpha),
+            "roi_t2_min": int(10 * roi_t_scale * roi_t_alpha),
+            "roi_t2_max": int(60 * roi_t_scale * roi_t_alpha),
+            "roi_t3_min": int(10 * roi_t_scale * roi_t_alpha),
+            "roi_t3_max": int(40 * roi_t_scale * roi_t_alpha),
+            "roi_p1_min": 0.01 * roi_p_scale * roi_p_alpha,
+            "roi_p1_max": 0.04 * roi_p_scale * roi_p_alpha,
+            "roi_p2_min": 0.01 * roi_p_scale * roi_p_alpha,
+            "roi_p2_max": 0.07 * roi_p_scale * roi_p_alpha,
+            "roi_p3_min": 0.01 * roi_p_scale * roi_p_alpha,
+            "roi_p3_max": 0.20 * roi_p_scale * roi_p_alpha,
         }
         logger.debug(f"Using roi space limits: {roi_limits}")
         p = {
-            'roi_t1': roi_limits['roi_t1_min'],
-            'roi_t2': roi_limits['roi_t2_min'],
-            'roi_t3': roi_limits['roi_t3_min'],
-            'roi_p1': roi_limits['roi_p1_min'],
-            'roi_p2': roi_limits['roi_p2_min'],
-            'roi_p3': roi_limits['roi_p3_min'],
+            "roi_t1": roi_limits["roi_t1_min"],
+            "roi_t2": roi_limits["roi_t2_min"],
+            "roi_t3": roi_limits["roi_t3_min"],
+            "roi_p1": roi_limits["roi_p1_min"],
+            "roi_p2": roi_limits["roi_p2_min"],
+            "roi_p3": roi_limits["roi_p3_min"],
         }
         logger.info(f"Min roi table: {round_dict(self.generate_roi_table(p), 3)}")
         p = {
-            'roi_t1': roi_limits['roi_t1_max'],
-            'roi_t2': roi_limits['roi_t2_max'],
-            'roi_t3': roi_limits['roi_t3_max'],
-            'roi_p1': roi_limits['roi_p1_max'],
-            'roi_p2': roi_limits['roi_p2_max'],
-            'roi_p3': roi_limits['roi_p3_max'],
+            "roi_t1": roi_limits["roi_t1_max"],
+            "roi_t2": roi_limits["roi_t2_max"],
+            "roi_t3": roi_limits["roi_t3_max"],
+            "roi_p1": roi_limits["roi_p1_max"],
+            "roi_p2": roi_limits["roi_p2_max"],
+            "roi_p3": roi_limits["roi_p3_max"],
         }
         logger.info(f"Max roi table: {round_dict(self.generate_roi_table(p), 3)}")
 
         return [
-            Integer(roi_limits['roi_t1_min'], roi_limits['roi_t1_max'], name='roi_t1'),
-            Integer(roi_limits['roi_t2_min'], roi_limits['roi_t2_max'], name='roi_t2'),
-            Integer(roi_limits['roi_t3_min'], roi_limits['roi_t3_max'], name='roi_t3'),
-            SKDecimal(roi_limits['roi_p1_min'], roi_limits['roi_p1_max'], decimals=3,
-                      name='roi_p1'),
-            SKDecimal(roi_limits['roi_p2_min'], roi_limits['roi_p2_max'], decimals=3,
-                      name='roi_p2'),
-            SKDecimal(roi_limits['roi_p3_min'], roi_limits['roi_p3_max'], decimals=3,
-                      name='roi_p3'),
+            Integer(roi_limits["roi_t1_min"], roi_limits["roi_t1_max"], name="roi_t1"),
+            Integer(roi_limits["roi_t2_min"], roi_limits["roi_t2_max"], name="roi_t2"),
+            Integer(roi_limits["roi_t3_min"], roi_limits["roi_t3_max"], name="roi_t3"),
+            SKDecimal(
+                roi_limits["roi_p1_min"], roi_limits["roi_p1_max"], decimals=3, name="roi_p1"
+            ),
+            SKDecimal(
+                roi_limits["roi_p2_min"], roi_limits["roi_p2_max"], decimals=3, name="roi_p2"
+            ),
+            SKDecimal(
+                roi_limits["roi_p3_min"], roi_limits["roi_p3_max"], decimals=3, name="roi_p3"
+            ),
         ]
 
     def stoploss_space(self) -> List[Dimension]:
         """
         Create a stoploss space.
 
         Defines range of stoploss values to search.
         You may override it in your custom Hyperopt class.
         """
         return [
-            SKDecimal(-0.35, -0.02, decimals=3, name='stoploss'),
+            SKDecimal(-0.35, -0.02, decimals=3, name="stoploss"),
         ]
 
     def generate_trailing_params(self, params: Dict) -> Dict:
         """
         Create dict with trailing stop parameters.
         """
         return {
-            'trailing_stop': params['trailing_stop'],
-            'trailing_stop_positive': params['trailing_stop_positive'],
-            'trailing_stop_positive_offset': (params['trailing_stop_positive'] +
-                                              params['trailing_stop_positive_offset_p1']),
-            'trailing_only_offset_is_reached': params['trailing_only_offset_is_reached'],
+            "trailing_stop": params["trailing_stop"],
+            "trailing_stop_positive": params["trailing_stop_positive"],
+            "trailing_stop_positive_offset": (
+                params["trailing_stop_positive"] + params["trailing_stop_positive_offset_p1"]
+            ),
+            "trailing_only_offset_is_reached": params["trailing_only_offset_is_reached"],
         }
 
     def trailing_space(self) -> List[Dimension]:
         """
         Create a trailing stoploss space.
 
         You may override it in your custom Hyperopt class.
@@ -173,42 +179,39 @@
         return [
             # It was decided to always set trailing_stop is to True if the 'trailing' hyperspace
             # is used. Otherwise hyperopt will vary other parameters that won't have effect if
             # trailing_stop is set False.
             # This parameter is included into the hyperspace dimensions rather than assigning
             # it explicitly in the code in order to have it printed in the results along with
             # other 'trailing' hyperspace parameters.
-            Categorical([True], name='trailing_stop'),
-
-            SKDecimal(0.01, 0.35, decimals=3, name='trailing_stop_positive'),
-
+            Categorical([True], name="trailing_stop"),
+            SKDecimal(0.01, 0.35, decimals=3, name="trailing_stop_positive"),
             # 'trailing_stop_positive_offset' should be greater than 'trailing_stop_positive',
             # so this intermediate parameter is used as the value of the difference between
             # them. The value of the 'trailing_stop_positive_offset' is constructed in the
             # generate_trailing_params() method.
             # This is similar to the hyperspace dimensions used for constructing the ROI tables.
-            SKDecimal(0.001, 0.1, decimals=3, name='trailing_stop_positive_offset_p1'),
-
-            Categorical([True, False], name='trailing_only_offset_is_reached'),
+            SKDecimal(0.001, 0.1, decimals=3, name="trailing_stop_positive_offset_p1"),
+            Categorical([True, False], name="trailing_only_offset_is_reached"),
         ]
 
     def max_open_trades_space(self) -> List[Dimension]:
         """
         Create a max open trades space.
 
         You may override it in your custom Hyperopt class.
         """
         return [
-            Integer(-1, 10, name='max_open_trades'),
+            Integer(-1, 10, name="max_open_trades"),
         ]
 
     # This is needed for proper unpickling the class attribute timeframe
     # which is set to the actual value by the resolver.
     # Why do I still need such shamanic mantras in modern python?
     def __getstate__(self):
         state = self.__dict__.copy()
-        state['timeframe'] = self.timeframe
+        state["timeframe"] = self.timeframe
         return state
 
     def __setstate__(self, state):
         self.__dict__.update(state)
-        IHyperOpt.timeframe = state['timeframe']
+        IHyperOpt.timeframe = state["timeframe"]
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_calmar.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_calmar.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """
 CalmarHyperOptLoss
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
+
 from datetime import datetime
 
 from pandas import DataFrame
 
 from freqtrade.constants import Config
 from freqtrade.data.metrics import calculate_calmar
 from freqtrade.optimize.hyperopt import IHyperOptLoss
@@ -17,19 +18,25 @@
     """
     Defines the loss function for hyperopt.
 
     This implementation uses the Calmar Ratio calculation.
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               min_date: datetime, max_date: datetime,
-                               config: Config, *args, **kwargs) -> float:
+    def hyperopt_loss_function(
+        results: DataFrame,
+        trade_count: int,
+        min_date: datetime,
+        max_date: datetime,
+        config: Config,
+        *args,
+        **kwargs,
+    ) -> float:
         """
         Objective function, returns smaller number for more optimal results.
 
         Uses Calmar Ratio calculation.
         """
-        starting_balance = config['dry_run_wallet']
+        starting_balance = config["dry_run_wallet"]
         calmar_ratio = calculate_calmar(results, min_date, max_date, starting_balance)
         # print(expected_returns_mean, max_drawdown, calmar_ratio)
         return -calmar_ratio
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown_relative.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,41 +1,42 @@
 """
-MaxDrawDownHyperOptLoss
+MaxDrawDownRelativeHyperOptLoss
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
-from datetime import datetime
 
 from pandas import DataFrame
 
-from freqtrade.data.metrics import calculate_max_drawdown
+from freqtrade.constants import Config
+from freqtrade.data.metrics import calculate_underwater
 from freqtrade.optimize.hyperopt import IHyperOptLoss
 
 
-class MaxDrawDownHyperOptLoss(IHyperOptLoss):
-
+class MaxDrawDownRelativeHyperOptLoss(IHyperOptLoss):
     """
     Defines the loss function for hyperopt.
 
     This implementation optimizes for max draw down and profit
     Less max drawdown more profit -> Lower return value
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               min_date: datetime, max_date: datetime,
-                               *args, **kwargs) -> float:
-
+    def hyperopt_loss_function(results: DataFrame, config: Config, *args, **kwargs) -> float:
         """
         Objective function.
 
         Uses profit ratio weighted max_drawdown when drawdown is available.
         Otherwise directly optimizes profit ratio.
         """
-        total_profit = results['profit_abs'].sum()
+        total_profit = results["profit_abs"].sum()
         try:
-            max_drawdown = calculate_max_drawdown(results, value_col='profit_abs')
-        except ValueError:
-            # No losing trade, therefore no drawdown.
+            drawdown_df = calculate_underwater(
+                results, value_col="profit_abs", starting_balance=config["dry_run_wallet"]
+            )
+            max_drawdown = abs(min(drawdown_df["drawdown"]))
+            relative_drawdown = max(drawdown_df["drawdown_relative"])
+            if max_drawdown == 0:
+                return -total_profit
+            return -total_profit / max_drawdown / relative_drawdown
+        except (Exception, ValueError):
             return -total_profit
-        return -total_profit / max_drawdown[0]
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown_relative.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_max_drawdown.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,46 +1,45 @@
 """
-MaxDrawDownRelativeHyperOptLoss
+MaxDrawDownHyperOptLoss
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
+
+from datetime import datetime
+
 from pandas import DataFrame
 
-from freqtrade.constants import Config
-from freqtrade.data.metrics import calculate_underwater
+from freqtrade.data.metrics import calculate_max_drawdown
 from freqtrade.optimize.hyperopt import IHyperOptLoss
 
 
-class MaxDrawDownRelativeHyperOptLoss(IHyperOptLoss):
-
+class MaxDrawDownHyperOptLoss(IHyperOptLoss):
     """
     Defines the loss function for hyperopt.
 
     This implementation optimizes for max draw down and profit
     Less max drawdown more profit -> Lower return value
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, config: Config,
-                               *args, **kwargs) -> float:
-
+    def hyperopt_loss_function(
+        results: DataFrame,
+        trade_count: int,
+        min_date: datetime,
+        max_date: datetime,
+        *args,
+        **kwargs,
+    ) -> float:
         """
         Objective function.
 
         Uses profit ratio weighted max_drawdown when drawdown is available.
         Otherwise directly optimizes profit ratio.
         """
-        total_profit = results['profit_abs'].sum()
+        total_profit = results["profit_abs"].sum()
         try:
-            drawdown_df = calculate_underwater(
-                results,
-                value_col='profit_abs',
-                starting_balance=config['dry_run_wallet']
-            )
-            max_drawdown = abs(min(drawdown_df['drawdown']))
-            relative_drawdown = max(drawdown_df['drawdown_relative'])
-            if max_drawdown == 0:
-                return -total_profit
-            return -total_profit / max_drawdown / relative_drawdown
-        except (Exception, ValueError):
+            max_drawdown = calculate_max_drawdown(results, value_col="profit_abs")
+        except ValueError:
+            # No losing trade, therefore no drawdown.
             return -total_profit
+        return -total_profit / max_drawdown.drawdown_abs
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_onlyprofit.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_onlyprofit.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 """
 OnlyProfitHyperOptLoss
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
+
 from pandas import DataFrame
 
 from freqtrade.optimize.hyperopt import IHyperOptLoss
 
 
 class OnlyProfitHyperOptLoss(IHyperOptLoss):
     """
     Defines the loss function for hyperopt.
 
     This implementation takes only absolute profit into account, not looking at any other indicator.
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               *args, **kwargs) -> float:
+    def hyperopt_loss_function(results: DataFrame, trade_count: int, *args, **kwargs) -> float:
         """
         Objective function, returns smaller number for better results.
         """
-        total_profit = results['profit_abs'].sum()
+        total_profit = results["profit_abs"].sum()
         return -1 * total_profit
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """
 SharpeHyperOptLoss
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
+
 from datetime import datetime
 
 from pandas import DataFrame
 
 from freqtrade.constants import Config
 from freqtrade.data.metrics import calculate_sharpe
 from freqtrade.optimize.hyperopt import IHyperOptLoss
@@ -17,19 +18,25 @@
     """
     Defines the loss function for hyperopt.
 
     This implementation uses the Sharpe Ratio calculation.
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               min_date: datetime, max_date: datetime,
-                               config: Config, *args, **kwargs) -> float:
+    def hyperopt_loss_function(
+        results: DataFrame,
+        trade_count: int,
+        min_date: datetime,
+        max_date: datetime,
+        config: Config,
+        *args,
+        **kwargs,
+    ) -> float:
         """
         Objective function, returns smaller number for more optimal results.
 
         Uses Sharpe Ratio calculation.
         """
-        starting_balance = config['dry_run_wallet']
+        starting_balance = config["dry_run_wallet"]
         sharp_ratio = calculate_sharpe(results, min_date, max_date, starting_balance)
         # print(expected_returns_mean, up_stdev, sharp_ratio)
         return -sharp_ratio
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe_daily.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sharpe_daily.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """
 SharpeHyperOptLossDaily
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
+
 import math
 from datetime import datetime
 
 from pandas import DataFrame, date_range
 
 from freqtrade.optimize.hyperopt import IHyperOptLoss
 
@@ -16,47 +17,54 @@
     """
     Defines the loss function for hyperopt.
 
     This implementation uses the Sharpe Ratio calculation.
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               min_date: datetime, max_date: datetime,
-                               *args, **kwargs) -> float:
+    def hyperopt_loss_function(
+        results: DataFrame,
+        trade_count: int,
+        min_date: datetime,
+        max_date: datetime,
+        *args,
+        **kwargs,
+    ) -> float:
         """
         Objective function, returns smaller number for more optimal results.
 
         Uses Sharpe Ratio calculation.
         """
-        resample_freq = '1D'
+        resample_freq = "1D"
         slippage_per_trade_ratio = 0.0005
         days_in_year = 365
         annual_risk_free_rate = 0.0
         risk_free_rate = annual_risk_free_rate / days_in_year
 
         # apply slippage per trade to profit_ratio
-        results.loc[:, 'profit_ratio_after_slippage'] = \
-            results['profit_ratio'] - slippage_per_trade_ratio
+        results.loc[:, "profit_ratio_after_slippage"] = (
+            results["profit_ratio"] - slippage_per_trade_ratio
+        )
 
         # create the index within the min_date and end max_date
-        t_index = date_range(start=min_date, end=max_date, freq=resample_freq,
-                             normalize=True)
+        t_index = date_range(start=min_date, end=max_date, freq=resample_freq, normalize=True)
 
         sum_daily = (
-            results.resample(resample_freq, on='close_date').agg(
-                {"profit_ratio_after_slippage": 'sum'}).reindex(t_index).fillna(0)
+            results.resample(resample_freq, on="close_date")
+            .agg({"profit_ratio_after_slippage": "sum"})
+            .reindex(t_index)
+            .fillna(0)
         )
 
         total_profit = sum_daily["profit_ratio_after_slippage"] - risk_free_rate
         expected_returns_mean = total_profit.mean()
         up_stdev = total_profit.std()
 
         if up_stdev != 0:
             sharp_ratio = expected_returns_mean / up_stdev * math.sqrt(days_in_year)
         else:
             # Define high (negative) sharpe ratio to be clear that this is NOT optimal.
-            sharp_ratio = -20.
+            sharp_ratio = -20.0
 
         # print(t_index, sum_daily, total_profit)
         # print(risk_free_rate, expected_returns_mean, up_stdev, sharp_ratio)
         return -sharp_ratio
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_short_trade_dur.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_short_trade_dur.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """
 ShortTradeDurHyperOptLoss
 This module defines the default HyperoptLoss class which is being used for
 Hyperoptimization.
 """
+
 from math import exp
 
 from pandas import DataFrame
 
 from freqtrade.optimize.hyperopt import IHyperOptLoss
 
 
@@ -28,28 +29,27 @@
 
 class ShortTradeDurHyperOptLoss(IHyperOptLoss):
     """
     Defines the default loss function for hyperopt
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               *args, **kwargs) -> float:
+    def hyperopt_loss_function(results: DataFrame, trade_count: int, *args, **kwargs) -> float:
         """
         Objective function, returns smaller number for better results
         This is the Default algorithm
         Weights are distributed as follows:
         * 0.4 to trade duration
         * 0.25: Avoiding trade loss
         * 1.0 to total profit, compared to the expected value (`EXPECTED_MAX_PROFIT`) defined above
         """
-        total_profit = results['profit_ratio'].sum()
-        trade_duration = results['trade_duration'].mean()
+        total_profit = results["profit_ratio"].sum()
+        trade_duration = results["trade_duration"].mean()
 
-        trade_loss = 1 - 0.25 * exp(-(trade_count - TARGET_TRADES) ** 2 / 10 ** 5.8)
+        trade_loss = 1 - 0.25 * exp(-((trade_count - TARGET_TRADES) ** 2) / 10**5.8)
         profit_loss = max(0, 1 - total_profit / EXPECTED_MAX_PROFIT)
         duration_loss = 0.4 * min(trade_duration / MAX_ACCEPTED_TRADE_DURATION, 1)
         result = trade_loss + profit_loss + duration_loss
         return result
 
 
 # Create an alias for This to allow the legacy Method to work as well.
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """
 SortinoHyperOptLoss
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
+
 from datetime import datetime
 
 from pandas import DataFrame
 
 from freqtrade.constants import Config
 from freqtrade.data.metrics import calculate_sortino
 from freqtrade.optimize.hyperopt import IHyperOptLoss
@@ -17,19 +18,25 @@
     """
     Defines the loss function for hyperopt.
 
     This implementation uses the Sortino Ratio calculation.
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               min_date: datetime, max_date: datetime,
-                               config: Config, *args, **kwargs) -> float:
+    def hyperopt_loss_function(
+        results: DataFrame,
+        trade_count: int,
+        min_date: datetime,
+        max_date: datetime,
+        config: Config,
+        *args,
+        **kwargs,
+    ) -> float:
         """
         Objective function, returns smaller number for more optimal results.
 
         Uses Sortino Ratio calculation.
         """
-        starting_balance = config['dry_run_wallet']
+        starting_balance = config["dry_run_wallet"]
         sortino_ratio = calculate_sortino(results, min_date, max_date, starting_balance)
         # print(expected_returns_mean, down_stdev, sortino_ratio)
         return -sortino_ratio
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino_daily.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_loss/hyperopt_loss_sortino_daily.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """
 SortinoHyperOptLossDaily
 
 This module defines the alternative HyperOptLoss class which can be used for
 Hyperoptimization.
 """
+
 import math
 from datetime import datetime
 
 from pandas import DataFrame, date_range
 
 from freqtrade.optimize.hyperopt import IHyperOptLoss
 
@@ -16,55 +17,62 @@
     """
     Defines the loss function for hyperopt.
 
     This implementation uses the Sortino Ratio calculation.
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               min_date: datetime, max_date: datetime,
-                               *args, **kwargs) -> float:
+    def hyperopt_loss_function(
+        results: DataFrame,
+        trade_count: int,
+        min_date: datetime,
+        max_date: datetime,
+        *args,
+        **kwargs,
+    ) -> float:
         """
         Objective function, returns smaller number for more optimal results.
 
         Uses Sortino Ratio calculation.
 
         Sortino Ratio calculated as described in
         http://www.redrockcapital.com/Sortino__A__Sharper__Ratio_Red_Rock_Capital.pdf
         """
-        resample_freq = '1D'
+        resample_freq = "1D"
         slippage_per_trade_ratio = 0.0005
         days_in_year = 365
         minimum_acceptable_return = 0.0
 
         # apply slippage per trade to profit_ratio
-        results.loc[:, 'profit_ratio_after_slippage'] = \
-            results['profit_ratio'] - slippage_per_trade_ratio
+        results.loc[:, "profit_ratio_after_slippage"] = (
+            results["profit_ratio"] - slippage_per_trade_ratio
+        )
 
         # create the index within the min_date and end max_date
-        t_index = date_range(start=min_date, end=max_date, freq=resample_freq,
-                             normalize=True)
+        t_index = date_range(start=min_date, end=max_date, freq=resample_freq, normalize=True)
 
         sum_daily = (
-            results.resample(resample_freq, on='close_date').agg(
-                {"profit_ratio_after_slippage": 'sum'}).reindex(t_index).fillna(0)
+            results.resample(resample_freq, on="close_date")
+            .agg({"profit_ratio_after_slippage": "sum"})
+            .reindex(t_index)
+            .fillna(0)
         )
 
         total_profit = sum_daily["profit_ratio_after_slippage"] - minimum_acceptable_return
         expected_returns_mean = total_profit.mean()
 
-        sum_daily['downside_returns'] = 0.0
-        sum_daily.loc[total_profit < 0, 'downside_returns'] = total_profit
-        total_downside = sum_daily['downside_returns']
+        sum_daily["downside_returns"] = 0.0
+        sum_daily.loc[total_profit < 0, "downside_returns"] = total_profit
+        total_downside = sum_daily["downside_returns"]
         # Here total_downside contains min(0, P - MAR) values,
         # where P = sum_daily["profit_ratio_after_slippage"]
         down_stdev = math.sqrt((total_downside**2).sum() / len(total_downside))
 
         if down_stdev != 0:
             sortino_ratio = expected_returns_mean / down_stdev * math.sqrt(days_in_year)
         else:
             # Define high (negative) sortino ratio to be clear that this is NOT optimal.
-            sortino_ratio = -20.
+            sortino_ratio = -20.0
 
         # print(t_index, sum_daily, total_profit)
         # print(minimum_acceptable_return, expected_returns_mean, down_stdev, sortino_ratio)
         return -sortino_ratio
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/hyperopt_tools.py` & `freqtrade-2024.5/freqtrade/optimize/hyperopt_tools.py`

 * *Files 12% similar despite different names*

```diff
@@ -33,240 +33,266 @@
     if isinstance(x, np.bool_):
         return bool(x)
 
     return str(x)
 
 
 class HyperoptStateContainer:
-    """ Singleton class to track state of hyperopt"""
+    """Singleton class to track state of hyperopt"""
+
     state: HyperoptState = HyperoptState.OPTIMIZE
 
     @classmethod
     def set_state(cls, value: HyperoptState):
         cls.state = value
 
 
 class HyperoptTools:
-
     @staticmethod
     def get_strategy_filename(config: Config, strategy_name: str) -> Optional[Path]:
         """
         Get Strategy-location (filename) from strategy_name
         """
         from freqtrade.resolvers.strategy_resolver import StrategyResolver
+
         strategy_objs = StrategyResolver.search_all_objects(
-            config, False, config.get('recursive_strategy_search', False))
-        strategies = [s for s in strategy_objs if s['name'] == strategy_name]
+            config, False, config.get("recursive_strategy_search", False)
+        )
+        strategies = [s for s in strategy_objs if s["name"] == strategy_name]
         if strategies:
             strategy = strategies[0]
 
-            return Path(strategy['location'])
+            return Path(strategy["location"])
         return None
 
     @staticmethod
     def export_params(params, strategy_name: str, filename: Path):
         """
         Generate files
         """
-        final_params = deepcopy(params['params_not_optimized'])
-        final_params = deep_merge_dicts(params['params_details'], final_params)
+        final_params = deepcopy(params["params_not_optimized"])
+        final_params = deep_merge_dicts(params["params_details"], final_params)
         final_params = {
-            'strategy_name': strategy_name,
-            'params': final_params,
-            'ft_stratparam_v': 1,
-            'export_time': datetime.now(timezone.utc),
+            "strategy_name": strategy_name,
+            "params": final_params,
+            "ft_stratparam_v": 1,
+            "export_time": datetime.now(timezone.utc),
         }
         logger.info(f"Dumping parameters to {filename}")
-        with filename.open('w') as f:
-            rapidjson.dump(final_params, f, indent=2,
-                           default=hyperopt_serializer,
-                           number_mode=HYPER_PARAMS_FILE_FORMAT
-                           )
+        with filename.open("w") as f:
+            rapidjson.dump(
+                final_params,
+                f,
+                indent=2,
+                default=hyperopt_serializer,
+                number_mode=HYPER_PARAMS_FILE_FORMAT,
+            )
 
     @staticmethod
     def load_params(filename: Path) -> Dict:
         """
         Load parameters from file
         """
-        with filename.open('r') as f:
+        with filename.open("r") as f:
             params = rapidjson.load(f, number_mode=HYPER_PARAMS_FILE_FORMAT)
         return params
 
     @staticmethod
     def try_export_params(config: Config, strategy_name: str, params: Dict):
-        if params.get(FTHYPT_FILEVERSION, 1) >= 2 and not config.get('disableparamexport', False):
+        if params.get(FTHYPT_FILEVERSION, 1) >= 2 and not config.get("disableparamexport", False):
             # Export parameters ...
             fn = HyperoptTools.get_strategy_filename(config, strategy_name)
             if fn:
-                HyperoptTools.export_params(params, strategy_name, fn.with_suffix('.json'))
+                HyperoptTools.export_params(params, strategy_name, fn.with_suffix(".json"))
             else:
                 logger.warning("Strategy not found, not exporting parameter file.")
 
     @staticmethod
     def has_space(config: Config, space: str) -> bool:
         """
         Tell if the space value is contained in the configuration
         """
         # 'trailing' and 'protection spaces are not included in the 'default' set of spaces
-        if space in ('trailing', 'protection', 'trades'):
-            return any(s in config['spaces'] for s in [space, 'all'])
+        if space in ("trailing", "protection", "trades"):
+            return any(s in config["spaces"] for s in [space, "all"])
         else:
-            return any(s in config['spaces'] for s in [space, 'all', 'default'])
+            return any(s in config["spaces"] for s in [space, "all", "default"])
 
     @staticmethod
     def _read_results(results_file: Path, batch_size: int = 10) -> Iterator[List[Any]]:
         """
         Stream hyperopt results from file
         """
         import rapidjson
+
         logger.info(f"Reading epochs from '{results_file}'")
-        with results_file.open('r') as f:
+        with results_file.open("r") as f:
             data = []
             for line in f:
                 data += [rapidjson.loads(line)]
                 if len(data) >= batch_size:
                     yield data
                     data = []
         yield data
 
     @staticmethod
     def _test_hyperopt_results_exist(results_file) -> bool:
         if results_file.is_file() and results_file.stat().st_size > 0:
-            if results_file.suffix == '.pickle':
+            if results_file.suffix == ".pickle":
                 raise OperationalException(
                     "Legacy hyperopt results are no longer supported."
                     "Please rerun hyperopt or use an older version to load this file."
                 )
             return True
         else:
             # No file found.
             return False
 
     @staticmethod
     def load_filtered_results(results_file: Path, config: Config) -> Tuple[List, int]:
         filteroptions = {
-            'only_best': config.get('hyperopt_list_best', False),
-            'only_profitable': config.get('hyperopt_list_profitable', False),
-            'filter_min_trades': config.get('hyperopt_list_min_trades', 0),
-            'filter_max_trades': config.get('hyperopt_list_max_trades', 0),
-            'filter_min_avg_time': config.get('hyperopt_list_min_avg_time'),
-            'filter_max_avg_time': config.get('hyperopt_list_max_avg_time'),
-            'filter_min_avg_profit': config.get('hyperopt_list_min_avg_profit'),
-            'filter_max_avg_profit': config.get('hyperopt_list_max_avg_profit'),
-            'filter_min_total_profit': config.get('hyperopt_list_min_total_profit'),
-            'filter_max_total_profit': config.get('hyperopt_list_max_total_profit'),
-            'filter_min_objective': config.get('hyperopt_list_min_objective'),
-            'filter_max_objective': config.get('hyperopt_list_max_objective'),
+            "only_best": config.get("hyperopt_list_best", False),
+            "only_profitable": config.get("hyperopt_list_profitable", False),
+            "filter_min_trades": config.get("hyperopt_list_min_trades", 0),
+            "filter_max_trades": config.get("hyperopt_list_max_trades", 0),
+            "filter_min_avg_time": config.get("hyperopt_list_min_avg_time"),
+            "filter_max_avg_time": config.get("hyperopt_list_max_avg_time"),
+            "filter_min_avg_profit": config.get("hyperopt_list_min_avg_profit"),
+            "filter_max_avg_profit": config.get("hyperopt_list_max_avg_profit"),
+            "filter_min_total_profit": config.get("hyperopt_list_min_total_profit"),
+            "filter_max_total_profit": config.get("hyperopt_list_max_total_profit"),
+            "filter_min_objective": config.get("hyperopt_list_min_objective"),
+            "filter_max_objective": config.get("hyperopt_list_max_objective"),
         }
         if not HyperoptTools._test_hyperopt_results_exist(results_file):
             # No file found.
             logger.warning(f"Hyperopt file {results_file} not found.")
             return [], 0
 
         epochs = []
         total_epochs = 0
         for epochs_tmp in HyperoptTools._read_results(results_file):
-            if total_epochs == 0 and epochs_tmp[0].get('is_best') is None:
+            if total_epochs == 0 and epochs_tmp[0].get("is_best") is None:
                 raise OperationalException(
                     "The file with HyperoptTools results is incompatible with this version "
-                    "of Freqtrade and cannot be loaded.")
+                    "of Freqtrade and cannot be loaded."
+                )
             total_epochs += len(epochs_tmp)
             epochs += hyperopt_filter_epochs(epochs_tmp, filteroptions, log=False)
 
         logger.info(f"Loaded {total_epochs} previous evaluations from disk.")
 
         # Final filter run ...
         epochs = hyperopt_filter_epochs(epochs, filteroptions, log=True)
 
         return epochs, total_epochs
 
     @staticmethod
-    def show_epoch_details(results, total_epochs: int, print_json: bool,
-                           no_header: bool = False, header_str: Optional[str] = None) -> None:
+    def show_epoch_details(
+        results,
+        total_epochs: int,
+        print_json: bool,
+        no_header: bool = False,
+        header_str: Optional[str] = None,
+    ) -> None:
         """
         Display details of the hyperopt result
         """
-        params = results.get('params_details', {})
-        non_optimized = results.get('params_not_optimized', {})
+        params = results.get("params_details", {})
+        non_optimized = results.get("params_not_optimized", {})
 
         # Default header string
         if header_str is None:
             header_str = "Best result"
 
         if not no_header:
             explanation_str = HyperoptTools._format_explanation_string(results, total_epochs)
             print(f"\n{header_str}:\n\n{explanation_str}\n")
 
         if print_json:
             result_dict: Dict = {}
-            for s in ['buy', 'sell', 'protection',
-                      'roi', 'stoploss', 'trailing', 'max_open_trades']:
+            for s in [
+                "buy",
+                "sell",
+                "protection",
+                "roi",
+                "stoploss",
+                "trailing",
+                "max_open_trades",
+            ]:
                 HyperoptTools._params_update_for_json(result_dict, params, non_optimized, s)
             print(rapidjson.dumps(result_dict, default=str, number_mode=HYPER_PARAMS_FILE_FORMAT))
 
         else:
-            HyperoptTools._params_pretty_print(params, 'buy', "Buy hyperspace params:",
-                                               non_optimized)
-            HyperoptTools._params_pretty_print(params, 'sell', "Sell hyperspace params:",
-                                               non_optimized)
-            HyperoptTools._params_pretty_print(params, 'protection',
-                                               "Protection hyperspace params:", non_optimized)
-            HyperoptTools._params_pretty_print(params, 'roi', "ROI table:", non_optimized)
-            HyperoptTools._params_pretty_print(params, 'stoploss', "Stoploss:", non_optimized)
-            HyperoptTools._params_pretty_print(params, 'trailing', "Trailing stop:", non_optimized)
             HyperoptTools._params_pretty_print(
-                params, 'max_open_trades', "Max Open Trades:", non_optimized)
+                params, "buy", "Buy hyperspace params:", non_optimized
+            )
+            HyperoptTools._params_pretty_print(
+                params, "sell", "Sell hyperspace params:", non_optimized
+            )
+            HyperoptTools._params_pretty_print(
+                params, "protection", "Protection hyperspace params:", non_optimized
+            )
+            HyperoptTools._params_pretty_print(params, "roi", "ROI table:", non_optimized)
+            HyperoptTools._params_pretty_print(params, "stoploss", "Stoploss:", non_optimized)
+            HyperoptTools._params_pretty_print(params, "trailing", "Trailing stop:", non_optimized)
+            HyperoptTools._params_pretty_print(
+                params, "max_open_trades", "Max Open Trades:", non_optimized
+            )
 
     @staticmethod
     def _params_update_for_json(result_dict, params, non_optimized, space: str) -> None:
         if (space in params) or (space in non_optimized):
             space_params = HyperoptTools._space_params(params, space)
             space_non_optimized = HyperoptTools._space_params(non_optimized, space)
             all_space_params = space_params
 
             # Merge non optimized params if there are any
             if len(space_non_optimized) > 0:
                 all_space_params = {**space_params, **space_non_optimized}
 
-            if space in ['buy', 'sell']:
-                result_dict.setdefault('params', {}).update(all_space_params)
-            elif space == 'roi':
+            if space in ["buy", "sell"]:
+                result_dict.setdefault("params", {}).update(all_space_params)
+            elif space == "roi":
                 # Convert keys in min_roi dict to strings because
                 # rapidjson cannot dump dicts with integer keys...
-                result_dict['minimal_roi'] = {str(k): v for k, v in all_space_params.items()}
+                result_dict["minimal_roi"] = {str(k): v for k, v in all_space_params.items()}
             else:  # 'stoploss', 'trailing'
                 result_dict.update(all_space_params)
 
     @staticmethod
     def _params_pretty_print(
-            params, space: str, header: str, non_optimized: Optional[Dict] = None) -> None:
-
+        params, space: str, header: str, non_optimized: Optional[Dict] = None
+    ) -> None:
         if space in params or (non_optimized and space in non_optimized):
             space_params = HyperoptTools._space_params(params, space, 5)
             no_params = HyperoptTools._space_params(non_optimized, space, 5)
-            appendix = ''
+            appendix = ""
             if not space_params and not no_params:
                 # No parameters - don't print
                 return
             if not space_params:
                 # Not optimized parameters - append string
                 appendix = NON_OPT_PARAM_APPENDIX
 
             result = f"\n# {header}\n"
             if space == "stoploss":
                 stoploss = safe_value_fallback2(space_params, no_params, space, space)
-                result += (f"stoploss = {stoploss}{appendix}")
+                result += f"stoploss = {stoploss}{appendix}"
             elif space == "max_open_trades":
                 max_open_trades = safe_value_fallback2(space_params, no_params, space, space)
-                result += (f"max_open_trades = {max_open_trades}{appendix}")
+                result += f"max_open_trades = {max_open_trades}{appendix}"
             elif space == "roi":
-                result = result[:-1] + f'{appendix}\n'
-                minimal_roi_result = rapidjson.dumps({
-                    str(k): v for k, v in (space_params or no_params).items()
-                }, default=str, indent=4, number_mode=rapidjson.NM_NATIVE)
+                result = result[:-1] + f"{appendix}\n"
+                minimal_roi_result = rapidjson.dumps(
+                    {str(k): v for k, v in (space_params or no_params).items()},
+                    default=str,
+                    indent=4,
+                    number_mode=rapidjson.NM_NATIVE,
+                )
                 result += f"minimal_roi = {minimal_roi_result}"
             elif space == "trailing":
                 for k, v in (space_params or no_params).items():
                     result += f"{k} = {v}{appendix}\n"
 
             else:
                 # Buy / sell parameters
@@ -287,185 +313,220 @@
     @staticmethod
     def _pprint_dict(params, non_optimized, indent: int = 4):
         """
         Pretty-print hyperopt results (based on 2 dicts - with add. comment)
         """
         p = params.copy()
         p.update(non_optimized)
-        result = '{\n'
+        result = "{\n"
 
         for k, param in p.items():
             result += " " * indent + f'"{k}": '
-            result += f'"{param}",' if isinstance(param, str) else f'{param},'
+            result += f'"{param}",' if isinstance(param, str) else f"{param},"
             if k in non_optimized:
                 result += NON_OPT_PARAM_APPENDIX
             result += "\n"
-        result += '}'
+        result += "}"
         return result
 
     @staticmethod
     def is_best_loss(results, current_best_loss: float) -> bool:
-        return bool(results['loss'] < current_best_loss)
+        return bool(results["loss"] < current_best_loss)
 
     @staticmethod
     def format_results_explanation_string(results_metrics: Dict, stake_currency: str) -> str:
         """
         Return the formatted results explanation in a string
         """
-        return (f"{results_metrics['total_trades']:6d} trades. "
-                f"{results_metrics['wins']}/{results_metrics['draws']}"
-                f"/{results_metrics['losses']} Wins/Draws/Losses. "
-                f"Avg profit {results_metrics['profit_mean']:7.2%}. "
-                f"Median profit {results_metrics['profit_median']:7.2%}. "
-                f"Total profit {results_metrics['profit_total_abs']:11.8f} {stake_currency} "
-                f"({results_metrics['profit_total']:8.2%}). "
-                f"Avg duration {results_metrics['holding_avg']} min."
-                )
+        return (
+            f"{results_metrics['total_trades']:6d} trades. "
+            f"{results_metrics['wins']}/{results_metrics['draws']}"
+            f"/{results_metrics['losses']} Wins/Draws/Losses. "
+            f"Avg profit {results_metrics['profit_mean']:7.2%}. "
+            f"Median profit {results_metrics['profit_median']:7.2%}. "
+            f"Total profit {results_metrics['profit_total_abs']:11.8f} {stake_currency} "
+            f"({results_metrics['profit_total']:8.2%}). "
+            f"Avg duration {results_metrics['holding_avg']} min."
+        )
 
     @staticmethod
     def _format_explanation_string(results, total_epochs) -> str:
-        return (("*" if results['is_initial_point'] else " ") +
-                f"{results['current_epoch']:5d}/{total_epochs}: " +
-                f"{results['results_explanation']} " +
-                f"Objective: {results['loss']:.5f}")
+        return (
+            ("*" if results["is_initial_point"] else " ")
+            + f"{results['current_epoch']:5d}/{total_epochs}: "
+            + f"{results['results_explanation']} "
+            + f"Objective: {results['loss']:.5f}"
+        )
 
     @staticmethod
-    def prepare_trials_columns(trials: pd.DataFrame, has_drawdown: bool) -> pd.DataFrame:
-        trials['Best'] = ''
+    def prepare_trials_columns(trials: pd.DataFrame) -> pd.DataFrame:
+        trials["Best"] = ""
 
-        if 'results_metrics.winsdrawslosses' not in trials.columns:
+        if "results_metrics.winsdrawslosses" not in trials.columns:
             # Ensure compatibility with older versions of hyperopt results
-            trials['results_metrics.winsdrawslosses'] = 'N/A'
+            trials["results_metrics.winsdrawslosses"] = "N/A"
 
-        if not has_drawdown:
+        has_account_drawdown = "results_metrics.max_drawdown_account" in trials.columns
+        if not has_account_drawdown:
             # Ensure compatibility with older versions of hyperopt results
-            trials['results_metrics.max_drawdown_account'] = None
-        if 'is_random' not in trials.columns:
-            trials['is_random'] = False
+            trials["results_metrics.max_drawdown_account"] = None
+        if "is_random" not in trials.columns:
+            trials["is_random"] = False
 
         # New mode, using backtest result for metrics
-        trials['results_metrics.winsdrawslosses'] = trials.apply(
+        trials["results_metrics.winsdrawslosses"] = trials.apply(
             lambda x: generate_wins_draws_losses(
-                            x['results_metrics.wins'], x['results_metrics.draws'],
-                            x['results_metrics.losses']
-                      ), axis=1)
-
-        trials = trials[['Best', 'current_epoch', 'results_metrics.total_trades',
-                         'results_metrics.winsdrawslosses',
-                         'results_metrics.profit_mean', 'results_metrics.profit_total_abs',
-                         'results_metrics.profit_total', 'results_metrics.holding_avg',
-                         'results_metrics.max_drawdown',
-                         'results_metrics.max_drawdown_account', 'results_metrics.max_drawdown_abs',
-                         'loss', 'is_initial_point', 'is_random', 'is_best']]
+                x["results_metrics.wins"], x["results_metrics.draws"], x["results_metrics.losses"]
+            ),
+            axis=1,
+        )
 
-        trials.columns = [
-            'Best', 'Epoch', 'Trades', ' Win  Draw  Loss  Win%', 'Avg profit',
-            'Total profit', 'Profit', 'Avg duration', 'max_drawdown', 'max_drawdown_account',
-            'max_drawdown_abs', 'Objective', 'is_initial_point', 'is_random', 'is_best'
+        trials = trials[
+            [
+                "Best",
+                "current_epoch",
+                "results_metrics.total_trades",
+                "results_metrics.winsdrawslosses",
+                "results_metrics.profit_mean",
+                "results_metrics.profit_total_abs",
+                "results_metrics.profit_total",
+                "results_metrics.holding_avg",
+                "results_metrics.max_drawdown_account",
+                "results_metrics.max_drawdown_abs",
+                "loss",
+                "is_initial_point",
+                "is_random",
+                "is_best",
             ]
+        ]
+
+        trials.columns = [
+            "Best",
+            "Epoch",
+            "Trades",
+            " Win  Draw  Loss  Win%",
+            "Avg profit",
+            "Total profit",
+            "Profit",
+            "Avg duration",
+            "max_drawdown_account",
+            "max_drawdown_abs",
+            "Objective",
+            "is_initial_point",
+            "is_random",
+            "is_best",
+        ]
 
         return trials
 
     @staticmethod
-    def get_result_table(config: Config, results: list, total_epochs: int, highlight_best: bool,
-                         print_colorized: bool, remove_header: int) -> str:
+    def get_result_table(
+        config: Config,
+        results: list,
+        total_epochs: int,
+        highlight_best: bool,
+        print_colorized: bool,
+        remove_header: int,
+    ) -> str:
         """
         Log result table
         """
         if not results:
-            return ''
+            return ""
 
         tabulate.PRESERVE_WHITESPACE = True
         trials = json_normalize(results, max_level=1)
 
-        has_account_drawdown = 'results_metrics.max_drawdown_account' in trials.columns
-
-        trials = HyperoptTools.prepare_trials_columns(trials, has_account_drawdown)
+        trials = HyperoptTools.prepare_trials_columns(trials)
 
-        trials['is_profit'] = False
-        trials.loc[trials['is_initial_point'] | trials['is_random'], 'Best'] = '*     '
-        trials.loc[trials['is_best'], 'Best'] = 'Best'
+        trials["is_profit"] = False
+        trials.loc[trials["is_initial_point"] | trials["is_random"], "Best"] = "*     "
+        trials.loc[trials["is_best"], "Best"] = "Best"
         trials.loc[
-            (trials['is_initial_point'] | trials['is_random']) & trials['is_best'],
-            'Best'] = '* Best'
-        trials.loc[trials['Total profit'] > 0, 'is_profit'] = True
-        trials['Trades'] = trials['Trades'].astype(str)
+            (trials["is_initial_point"] | trials["is_random"]) & trials["is_best"], "Best"
+        ] = "* Best"
+        trials.loc[trials["Total profit"] > 0, "is_profit"] = True
+        trials["Trades"] = trials["Trades"].astype(str)
         # perc_multi = 1 if legacy_mode else 100
-        trials['Epoch'] = trials['Epoch'].apply(
-            lambda x: '{}/{}'.format(str(x).rjust(len(str(total_epochs)), ' '), total_epochs)
+        trials["Epoch"] = trials["Epoch"].apply(
+            lambda x: "{}/{}".format(str(x).rjust(len(str(total_epochs)), " "), total_epochs)
         )
-        trials['Avg profit'] = trials['Avg profit'].apply(
-            lambda x: f'{x:,.2%}'.rjust(7, ' ') if not isna(x) else "--".rjust(7, ' ')
+        trials["Avg profit"] = trials["Avg profit"].apply(
+            lambda x: f"{x:,.2%}".rjust(7, " ") if not isna(x) else "--".rjust(7, " ")
+        )
+        trials["Avg duration"] = trials["Avg duration"].apply(
+            lambda x: (
+                f"{x:,.1f} m".rjust(7, " ")
+                if isinstance(x, float)
+                else f"{x}"
+                if not isna(x)
+                else "--".rjust(7, " ")
+            )
         )
-        trials['Avg duration'] = trials['Avg duration'].apply(
-            lambda x: f'{x:,.1f} m'.rjust(7, ' ') if isinstance(x, float) else f"{x}"
-                      if not isna(x) else "--".rjust(7, ' ')
-        )
-        trials['Objective'] = trials['Objective'].apply(
-            lambda x: f'{x:,.5f}'.rjust(8, ' ') if x != 100000 else "N/A".rjust(8, ' ')
-        )
-
-        stake_currency = config['stake_currency']
-
-        trials[f"Max Drawdown{' (Acct)' if has_account_drawdown else ''}"] = trials.apply(
-            lambda x: "{} {}".format(
-                fmt_coin(x['max_drawdown_abs'], stake_currency, keep_trailing_zeros=True),
-                (f"({x['max_drawdown_account']:,.2%})"
-                    if has_account_drawdown
-                    else f"({x['max_drawdown']:,.2%})"
-                 ).rjust(10, ' ')
-            ).rjust(25 + len(stake_currency))
-            if x['max_drawdown'] != 0.0 or x['max_drawdown_account'] != 0.0
-            else '--'.rjust(25 + len(stake_currency)),
-            axis=1
-        )
-
-        trials = trials.drop(columns=['max_drawdown_abs', 'max_drawdown', 'max_drawdown_account'])
-
-        trials['Profit'] = trials.apply(
-            lambda x: '{} {}'.format(
-                fmt_coin(x['Total profit'], stake_currency, keep_trailing_zeros=True),
-                f"({x['Profit']:,.2%})".rjust(10, ' ')
-            ).rjust(25 + len(stake_currency))
-            if x['Total profit'] != 0.0 else '--'.rjust(25 + len(stake_currency)),
-            axis=1
+        trials["Objective"] = trials["Objective"].apply(
+            lambda x: f"{x:,.5f}".rjust(8, " ") if x != 100000 else "N/A".rjust(8, " ")
         )
-        trials = trials.drop(columns=['Total profit'])
+
+        stake_currency = config["stake_currency"]
+
+        trials["Max Drawdown (Acct)"] = trials.apply(
+            lambda x: (
+                "{} {}".format(
+                    fmt_coin(x["max_drawdown_abs"], stake_currency, keep_trailing_zeros=True),
+                    (f"({x['max_drawdown_account']:,.2%})").rjust(10, " "),
+                ).rjust(25 + len(stake_currency))
+                if x["max_drawdown_account"] != 0.0
+                else "--".rjust(25 + len(stake_currency))
+            ),
+            axis=1,
+        )
+
+        trials = trials.drop(columns=["max_drawdown_abs", "max_drawdown_account"])
+
+        trials["Profit"] = trials.apply(
+            lambda x: (
+                "{} {}".format(
+                    fmt_coin(x["Total profit"], stake_currency, keep_trailing_zeros=True),
+                    f"({x['Profit']:,.2%})".rjust(10, " "),
+                ).rjust(25 + len(stake_currency))
+                if x["Total profit"] != 0.0
+                else "--".rjust(25 + len(stake_currency))
+            ),
+            axis=1,
+        )
+        trials = trials.drop(columns=["Total profit"])
 
         if print_colorized:
             trials2 = trials.astype(str)
             for i in range(len(trials)):
-                if trials.loc[i]['is_profit']:
+                if trials.loc[i]["is_profit"]:
                     for j in range(len(trials.loc[i]) - 3):
                         trials2.iat[i, j] = f"{Fore.GREEN}{str(trials.iloc[i, j])}{Fore.RESET}"
-                if trials.loc[i]['is_best'] and highlight_best:
+                if trials.loc[i]["is_best"] and highlight_best:
                     for j in range(len(trials.loc[i]) - 3):
                         trials2.iat[i, j] = (
                             f"{Style.BRIGHT}{str(trials.iloc[i, j])}{Style.RESET_ALL}"
                         )
             trials = trials2
             del trials2
-        trials = trials.drop(columns=['is_initial_point', 'is_best', 'is_profit', 'is_random'])
+        trials = trials.drop(columns=["is_initial_point", "is_best", "is_profit", "is_random"])
         if remove_header > 0:
             table = tabulate.tabulate(
-                trials.to_dict(orient='list'), tablefmt='orgtbl',
-                headers='keys', stralign="right"
+                trials.to_dict(orient="list"), tablefmt="orgtbl", headers="keys", stralign="right"
             )
 
             table = table.split("\n", remove_header)[remove_header]
         elif remove_header < 0:
             table = tabulate.tabulate(
-                trials.to_dict(orient='list'), tablefmt='psql',
-                headers='keys', stralign="right"
+                trials.to_dict(orient="list"), tablefmt="psql", headers="keys", stralign="right"
             )
             table = "\n".join(table.split("\n")[0:remove_header])
         else:
             table = tabulate.tabulate(
-                trials.to_dict(orient='list'), tablefmt='psql',
-                headers='keys', stralign="right"
+                trials.to_dict(orient="list"), tablefmt="psql", headers="keys", stralign="right"
             )
         return table
 
     @staticmethod
     def export_csv_file(config: Config, results: list, csv_file: str) -> None:
         """
         Log result to csv-file
@@ -475,60 +536,79 @@
 
         # Verification for overwrite
         if Path(csv_file).is_file():
             logger.error(f"CSV file already exists: {csv_file}")
             return
 
         try:
-            Path(csv_file).open('w+').close()
+            Path(csv_file).open("w+").close()
         except OSError:
             logger.error(f"Failed to create CSV file: {csv_file}")
             return
 
         trials = json_normalize(results, max_level=1)
-        trials['Best'] = ''
-        trials['Stake currency'] = config['stake_currency']
+        trials["Best"] = ""
+        trials["Stake currency"] = config["stake_currency"]
 
-        base_metrics = ['Best', 'current_epoch', 'results_metrics.total_trades',
-                        'results_metrics.profit_mean', 'results_metrics.profit_median',
-                        'results_metrics.profit_total', 'Stake currency',
-                        'results_metrics.profit_total_abs', 'results_metrics.holding_avg',
-                        'results_metrics.trade_count_long', 'results_metrics.trade_count_short',
-                        'loss', 'is_initial_point', 'is_best']
+        base_metrics = [
+            "Best",
+            "current_epoch",
+            "results_metrics.total_trades",
+            "results_metrics.profit_mean",
+            "results_metrics.profit_median",
+            "results_metrics.profit_total",
+            "Stake currency",
+            "results_metrics.profit_total_abs",
+            "results_metrics.holding_avg",
+            "results_metrics.trade_count_long",
+            "results_metrics.trade_count_short",
+            "loss",
+            "is_initial_point",
+            "is_best",
+        ]
         perc_multi = 100
 
-        param_metrics = [("params_dict." + param) for param in results[0]['params_dict'].keys()]
+        param_metrics = [("params_dict." + param) for param in results[0]["params_dict"].keys()]
         trials = trials[base_metrics + param_metrics]
 
-        base_columns = ['Best', 'Epoch', 'Trades', 'Avg profit', 'Median profit', 'Total profit',
-                        'Stake currency', 'Profit', 'Avg duration',
-                        'Trade count long', 'Trade count short',
-                        'Objective',
-                        'is_initial_point', 'is_best']
-        param_columns = list(results[0]['params_dict'].keys())
+        base_columns = [
+            "Best",
+            "Epoch",
+            "Trades",
+            "Avg profit",
+            "Median profit",
+            "Total profit",
+            "Stake currency",
+            "Profit",
+            "Avg duration",
+            "Trade count long",
+            "Trade count short",
+            "Objective",
+            "is_initial_point",
+            "is_best",
+        ]
+        param_columns = list(results[0]["params_dict"].keys())
         trials.columns = base_columns + param_columns
 
-        trials['is_profit'] = False
-        trials.loc[trials['is_initial_point'], 'Best'] = '*'
-        trials.loc[trials['is_best'], 'Best'] = 'Best'
-        trials.loc[trials['is_initial_point'] & trials['is_best'], 'Best'] = '* Best'
-        trials.loc[trials['Total profit'] > 0, 'is_profit'] = True
-        trials['Epoch'] = trials['Epoch'].astype(str)
-        trials['Trades'] = trials['Trades'].astype(str)
-        trials['Median profit'] = trials['Median profit'] * perc_multi
-
-        trials['Total profit'] = trials['Total profit'].apply(
-            lambda x: f'{x:,.8f}' if x != 0.0 else ""
-        )
-        trials['Profit'] = trials['Profit'].apply(
-            lambda x: f'{x:,.2f}' if not isna(x) else ""
-        )
-        trials['Avg profit'] = trials['Avg profit'].apply(
-            lambda x: f'{x * perc_multi:,.2f}%' if not isna(x) else ""
+        trials["is_profit"] = False
+        trials.loc[trials["is_initial_point"], "Best"] = "*"
+        trials.loc[trials["is_best"], "Best"] = "Best"
+        trials.loc[trials["is_initial_point"] & trials["is_best"], "Best"] = "* Best"
+        trials.loc[trials["Total profit"] > 0, "is_profit"] = True
+        trials["Epoch"] = trials["Epoch"].astype(str)
+        trials["Trades"] = trials["Trades"].astype(str)
+        trials["Median profit"] = trials["Median profit"] * perc_multi
+
+        trials["Total profit"] = trials["Total profit"].apply(
+            lambda x: f"{x:,.8f}" if x != 0.0 else ""
+        )
+        trials["Profit"] = trials["Profit"].apply(lambda x: f"{x:,.2f}" if not isna(x) else "")
+        trials["Avg profit"] = trials["Avg profit"].apply(
+            lambda x: f"{x * perc_multi:,.2f}%" if not isna(x) else ""
         )
-        trials['Objective'] = trials['Objective'].apply(
-            lambda x: f'{x:,.5f}' if x != 100000 else ""
+        trials["Objective"] = trials["Objective"].apply(
+            lambda x: f"{x:,.5f}" if x != 100000 else ""
         )
 
-        trials = trials.drop(columns=['is_initial_point', 'is_best', 'is_profit'])
-        trials.to_csv(csv_file, index=False, header=True, mode='w', encoding='UTF-8')
+        trials = trials.drop(columns=["is_initial_point", "is_best", "is_profit"])
+        trials.to_csv(csv_file, index=False, header=True, mode="w", encoding="UTF-8")
         logger.info(f"CSV file created: {csv_file}")
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/optimize_reports/bt_output.py` & `freqtrade-2024.5/freqtrade/optimize/optimize_reports/bt_output.py`

 * *Files 16% similar despite different names*

```diff
@@ -12,375 +12,493 @@
 logger = logging.getLogger(__name__)
 
 
 def _get_line_floatfmt(stake_currency: str) -> List[str]:
     """
     Generate floatformat (goes in line with _generate_result_line())
     """
-    return ['s', 'd', '.2f', f'.{decimals_per_coin(stake_currency)}f',
-            '.2f', 'd', 's', 's']
+    return ["s", "d", ".2f", f".{decimals_per_coin(stake_currency)}f", ".2f", "d", "s", "s"]
 
 
-def _get_line_header(first_column: str, stake_currency: str,
-                     direction: str = 'Entries') -> List[str]:
+def _get_line_header(
+    first_column: str, stake_currency: str, direction: str = "Entries"
+) -> List[str]:
     """
     Generate header lines (goes in line with _generate_result_line())
     """
-    return [first_column, direction, 'Avg Profit %',
-            f'Tot Profit {stake_currency}', 'Tot Profit %', 'Avg Duration',
-            'Win  Draw  Loss  Win%']
+    return [
+        first_column,
+        direction,
+        "Avg Profit %",
+        f"Tot Profit {stake_currency}",
+        "Tot Profit %",
+        "Avg Duration",
+        "Win  Draw  Loss  Win%",
+    ]
 
 
 def generate_wins_draws_losses(wins, draws, losses):
     if wins > 0 and losses == 0:
-        wl_ratio = '100'
+        wl_ratio = "100"
     elif wins == 0:
-        wl_ratio = '0'
+        wl_ratio = "0"
     else:
-        wl_ratio = f'{100.0 / (wins + draws + losses) * wins:.1f}' if losses > 0 else '100'
-    return f'{wins:>4}  {draws:>4}  {losses:>4}  {wl_ratio:>4}'
+        wl_ratio = f"{100.0 / (wins + draws + losses) * wins:.1f}" if losses > 0 else "100"
+    return f"{wins:>4}  {draws:>4}  {losses:>4}  {wl_ratio:>4}"
 
 
 def text_table_bt_results(pair_results: List[Dict[str, Any]], stake_currency: str) -> str:
     """
     Generates and returns a text table for the given backtest data and the results dataframe
     :param pair_results: List of Dictionaries - one entry per pair + final TOTAL row
     :param stake_currency: stake-currency - used to correctly name headers
     :return: pretty printed table with tabulate as string
     """
 
-    headers = _get_line_header('Pair', stake_currency)
+    headers = _get_line_header("Pair", stake_currency)
     floatfmt = _get_line_floatfmt(stake_currency)
-    output = [[
-        t['key'], t['trades'], t['profit_mean_pct'], t['profit_total_abs'],
-        t['profit_total_pct'], t['duration_avg'],
-        generate_wins_draws_losses(t['wins'], t['draws'], t['losses'])
-    ] for t in pair_results]
+    output = [
+        [
+            t["key"],
+            t["trades"],
+            t["profit_mean_pct"],
+            t["profit_total_abs"],
+            t["profit_total_pct"],
+            t["duration_avg"],
+            generate_wins_draws_losses(t["wins"], t["draws"], t["losses"]),
+        ]
+        for t in pair_results
+    ]
     # Ignore type as floatfmt does allow tuples but mypy does not know that
-    return tabulate(output, headers=headers,
-                    floatfmt=floatfmt, tablefmt="orgtbl", stralign="right")
+    return tabulate(output, headers=headers, floatfmt=floatfmt, tablefmt="orgtbl", stralign="right")
 
 
 def text_table_tags(tag_type: str, tag_results: List[Dict[str, Any]], stake_currency: str) -> str:
     """
     Generates and returns a text table for the given backtest data and the results dataframe
     :param pair_results: List of Dictionaries - one entry per pair + final TOTAL row
     :param stake_currency: stake-currency - used to correctly name headers
     :return: pretty printed table with tabulate as string
     """
-    fallback: str = ''
-    if (tag_type == "enter_tag"):
+    fallback: str = ""
+    if tag_type == "enter_tag":
         headers = _get_line_header("TAG", stake_currency)
     else:
-        headers = _get_line_header("Exit Reason", stake_currency, 'Exits')
-        fallback = 'exit_reason'
+        headers = _get_line_header("Exit Reason", stake_currency, "Exits")
+        fallback = "exit_reason"
 
     floatfmt = _get_line_floatfmt(stake_currency)
     output = [
         [
-            t['key'] if t.get('key') is not None and len(
-                str(t['key'])) > 0 else t.get(fallback, "OTHER"),
-            t['trades'],
-            t['profit_mean_pct'],
-            t['profit_total_abs'],
-            t['profit_total_pct'],
-            t.get('duration_avg'),
-            generate_wins_draws_losses(
-                t['wins'],
-                t['draws'],
-                t['losses'])] for t in tag_results]
+            (
+                t["key"]
+                if t.get("key") is not None and len(str(t["key"])) > 0
+                else t.get(fallback, "OTHER")
+            ),
+            t["trades"],
+            t["profit_mean_pct"],
+            t["profit_total_abs"],
+            t["profit_total_pct"],
+            t.get("duration_avg"),
+            generate_wins_draws_losses(t["wins"], t["draws"], t["losses"]),
+        ]
+        for t in tag_results
+    ]
     # Ignore type as floatfmt does allow tuples but mypy does not know that
-    return tabulate(output, headers=headers,
-                    floatfmt=floatfmt, tablefmt="orgtbl", stralign="right")
+    return tabulate(output, headers=headers, floatfmt=floatfmt, tablefmt="orgtbl", stralign="right")
 
 
-def text_table_periodic_breakdown(days_breakdown_stats: List[Dict[str, Any]],
-                                  stake_currency: str, period: str) -> str:
+def text_table_periodic_breakdown(
+    days_breakdown_stats: List[Dict[str, Any]], stake_currency: str, period: str
+) -> str:
     """
     Generate small table with Backtest results by days
     :param days_breakdown_stats: Days breakdown metrics
     :param stake_currency: Stakecurrency used
     :return: pretty printed table with tabulate as string
     """
     headers = [
         period.capitalize(),
-        f'Tot Profit {stake_currency}',
-        'Wins',
-        'Draws',
-        'Losses',
+        f"Tot Profit {stake_currency}",
+        "Wins",
+        "Draws",
+        "Losses",
+    ]
+    output = [
+        [
+            d["date"],
+            fmt_coin(d["profit_abs"], stake_currency, False),
+            d["wins"],
+            d["draws"],
+            d["loses"],
+        ]
+        for d in days_breakdown_stats
     ]
-    output = [[
-        d['date'], fmt_coin(d['profit_abs'], stake_currency, False),
-        d['wins'], d['draws'], d['loses'],
-    ] for d in days_breakdown_stats]
     return tabulate(output, headers=headers, tablefmt="orgtbl", stralign="right")
 
 
 def text_table_strategy(strategy_results, stake_currency: str) -> str:
     """
     Generate summary table per strategy
     :param strategy_results: Dict of <Strategyname: DataFrame> containing results for all strategies
     :param stake_currency: stake-currency - used to correctly name headers
     :return: pretty printed table with tabulate as string
     """
     floatfmt = _get_line_floatfmt(stake_currency)
-    headers = _get_line_header('Strategy', stake_currency)
+    headers = _get_line_header("Strategy", stake_currency)
     # _get_line_header() is also used for per-pair summary. Per-pair drawdown is mostly useless
     # therefore we slip this column in only for strategy summary here.
-    headers.append('Drawdown')
+    headers.append("Drawdown")
 
     # Align drawdown string on the center two space separator.
-    if 'max_drawdown_account' in strategy_results[0]:
+    if "max_drawdown_account" in strategy_results[0]:
         drawdown = [f'{t["max_drawdown_account"] * 100:.2f}' for t in strategy_results]
     else:
         # Support for prior backtest results
         drawdown = [f'{t["max_drawdown_per"]:.2f}' for t in strategy_results]
 
-    dd_pad_abs = max([len(t['max_drawdown_abs']) for t in strategy_results])
+    dd_pad_abs = max([len(t["max_drawdown_abs"]) for t in strategy_results])
     dd_pad_per = max([len(dd) for dd in drawdown])
-    drawdown = [f'{t["max_drawdown_abs"]:>{dd_pad_abs}} {stake_currency}  {dd:>{dd_pad_per}}%'
-                for t, dd in zip(strategy_results, drawdown)]
+    drawdown = [
+        f'{t["max_drawdown_abs"]:>{dd_pad_abs}} {stake_currency}  {dd:>{dd_pad_per}}%'
+        for t, dd in zip(strategy_results, drawdown)
+    ]
 
-    output = [[
-        t['key'], t['trades'], t['profit_mean_pct'], t['profit_total_abs'],
-        t['profit_total_pct'], t['duration_avg'],
-        generate_wins_draws_losses(t['wins'], t['draws'], t['losses']), drawdown]
-        for t, drawdown in zip(strategy_results, drawdown)]
+    output = [
+        [
+            t["key"],
+            t["trades"],
+            t["profit_mean_pct"],
+            t["profit_total_abs"],
+            t["profit_total_pct"],
+            t["duration_avg"],
+            generate_wins_draws_losses(t["wins"], t["draws"], t["losses"]),
+            drawdown,
+        ]
+        for t, drawdown in zip(strategy_results, drawdown)
+    ]
     # Ignore type as floatfmt does allow tuples but mypy does not know that
-    return tabulate(output, headers=headers,
-                    floatfmt=floatfmt, tablefmt="orgtbl", stralign="right")
+    return tabulate(output, headers=headers, floatfmt=floatfmt, tablefmt="orgtbl", stralign="right")
 
 
 def text_table_add_metrics(strat_results: Dict) -> str:
-    if len(strat_results['trades']) > 0:
-        best_trade = max(strat_results['trades'], key=lambda x: x['profit_ratio'])
-        worst_trade = min(strat_results['trades'], key=lambda x: x['profit_ratio'])
-
-        short_metrics = [
-            ('', ''),  # Empty line to improve readability
-            ('Long / Short',
-             f"{strat_results.get('trade_count_long', 'total_trades')} / "
-             f"{strat_results.get('trade_count_short', 0)}"),
-            ('Total profit Long %', f"{strat_results['profit_total_long']:.2%}"),
-            ('Total profit Short %', f"{strat_results['profit_total_short']:.2%}"),
-            ('Absolute profit Long', fmt_coin(strat_results['profit_total_long_abs'],
-                                              strat_results['stake_currency'])),
-            ('Absolute profit Short', fmt_coin(strat_results['profit_total_short_abs'],
-                                               strat_results['stake_currency'])),
-        ] if strat_results.get('trade_count_short', 0) > 0 else []
+    if len(strat_results["trades"]) > 0:
+        best_trade = max(strat_results["trades"], key=lambda x: x["profit_ratio"])
+        worst_trade = min(strat_results["trades"], key=lambda x: x["profit_ratio"])
+
+        short_metrics = (
+            [
+                ("", ""),  # Empty line to improve readability
+                (
+                    "Long / Short",
+                    f"{strat_results.get('trade_count_long', 'total_trades')} / "
+                    f"{strat_results.get('trade_count_short', 0)}",
+                ),
+                ("Total profit Long %", f"{strat_results['profit_total_long']:.2%}"),
+                ("Total profit Short %", f"{strat_results['profit_total_short']:.2%}"),
+                (
+                    "Absolute profit Long",
+                    fmt_coin(
+                        strat_results["profit_total_long_abs"], strat_results["stake_currency"]
+                    ),
+                ),
+                (
+                    "Absolute profit Short",
+                    fmt_coin(
+                        strat_results["profit_total_short_abs"], strat_results["stake_currency"]
+                    ),
+                ),
+            ]
+            if strat_results.get("trade_count_short", 0) > 0
+            else []
+        )
 
         drawdown_metrics = []
-        if 'max_relative_drawdown' in strat_results:
+        if "max_relative_drawdown" in strat_results:
             # Compatibility to show old hyperopt results
             drawdown_metrics.append(
-                ('Max % of account underwater', f"{strat_results['max_relative_drawdown']:.2%}")
+                ("Max % of account underwater", f"{strat_results['max_relative_drawdown']:.2%}")
             )
-        drawdown_metrics.extend([
-            ('Absolute Drawdown (Account)', f"{strat_results['max_drawdown_account']:.2%}")
-            if 'max_drawdown_account' in strat_results else (
-                'Drawdown', f"{strat_results['max_drawdown']:.2%}"),
-            ('Absolute Drawdown', fmt_coin(strat_results['max_drawdown_abs'],
-                                           strat_results['stake_currency'])),
-            ('Drawdown high', fmt_coin(strat_results['max_drawdown_high'],
-                                       strat_results['stake_currency'])),
-            ('Drawdown low', fmt_coin(strat_results['max_drawdown_low'],
-                                      strat_results['stake_currency'])),
-            ('Drawdown Start', strat_results['drawdown_start']),
-            ('Drawdown End', strat_results['drawdown_end']),
-        ])
-
-        entry_adjustment_metrics = [
-            ('Canceled Trade Entries', strat_results.get('canceled_trade_entries', 'N/A')),
-            ('Canceled Entry Orders', strat_results.get('canceled_entry_orders', 'N/A')),
-            ('Replaced Entry Orders', strat_results.get('replaced_entry_orders', 'N/A')),
-        ] if strat_results.get('canceled_entry_orders', 0) > 0 else []
+        drawdown_metrics.extend(
+            [
+                (
+                    ("Absolute Drawdown (Account)", f"{strat_results['max_drawdown_account']:.2%}")
+                    if "max_drawdown_account" in strat_results
+                    else ("Drawdown", f"{strat_results['max_drawdown']:.2%}")
+                ),
+                (
+                    "Absolute Drawdown",
+                    fmt_coin(strat_results["max_drawdown_abs"], strat_results["stake_currency"]),
+                ),
+                (
+                    "Drawdown high",
+                    fmt_coin(strat_results["max_drawdown_high"], strat_results["stake_currency"]),
+                ),
+                (
+                    "Drawdown low",
+                    fmt_coin(strat_results["max_drawdown_low"], strat_results["stake_currency"]),
+                ),
+                ("Drawdown Start", strat_results["drawdown_start"]),
+                ("Drawdown End", strat_results["drawdown_end"]),
+            ]
+        )
+
+        entry_adjustment_metrics = (
+            [
+                ("Canceled Trade Entries", strat_results.get("canceled_trade_entries", "N/A")),
+                ("Canceled Entry Orders", strat_results.get("canceled_entry_orders", "N/A")),
+                ("Replaced Entry Orders", strat_results.get("replaced_entry_orders", "N/A")),
+            ]
+            if strat_results.get("canceled_entry_orders", 0) > 0
+            else []
+        )
 
         # Newly added fields should be ignored if they are missing in strat_results. hyperopt-show
         # command stores these results and newer version of freqtrade must be able to handle old
         # results with missing new fields.
         metrics = [
-            ('Backtesting from', strat_results['backtest_start']),
-            ('Backtesting to', strat_results['backtest_end']),
-            ('Max open trades', strat_results['max_open_trades']),
-            ('', ''),  # Empty line to improve readability
-            ('Total/Daily Avg Trades',
-                f"{strat_results['total_trades']} / {strat_results['trades_per_day']}"),
-
-            ('Starting balance', fmt_coin(strat_results['starting_balance'],
-                                          strat_results['stake_currency'])),
-            ('Final balance', fmt_coin(strat_results['final_balance'],
-                                       strat_results['stake_currency'])),
-            ('Absolute profit ', fmt_coin(strat_results['profit_total_abs'],
-                                          strat_results['stake_currency'])),
-            ('Total profit %', f"{strat_results['profit_total']:.2%}"),
-            ('CAGR %', f"{strat_results['cagr']:.2%}" if 'cagr' in strat_results else 'N/A'),
-            ('Sortino', f"{strat_results['sortino']:.2f}" if 'sortino' in strat_results else 'N/A'),
-            ('Sharpe', f"{strat_results['sharpe']:.2f}" if 'sharpe' in strat_results else 'N/A'),
-            ('Calmar', f"{strat_results['calmar']:.2f}" if 'calmar' in strat_results else 'N/A'),
-            ('Profit factor', f'{strat_results["profit_factor"]:.2f}' if 'profit_factor'
-                              in strat_results else 'N/A'),
-            ('Expectancy (Ratio)', (
-                f"{strat_results['expectancy']:.2f} ({strat_results['expectancy_ratio']:.2f})" if
-                'expectancy_ratio' in strat_results else 'N/A')),
-            ('Trades per day', strat_results['trades_per_day']),
-            ('Avg. daily profit %',
-             f"{(strat_results['profit_total'] / strat_results['backtest_days']):.2%}"),
-            ('Avg. stake amount', fmt_coin(strat_results['avg_stake_amount'],
-                                           strat_results['stake_currency'])),
-            ('Total trade volume', fmt_coin(strat_results['total_volume'],
-                                            strat_results['stake_currency'])),
+            ("Backtesting from", strat_results["backtest_start"]),
+            ("Backtesting to", strat_results["backtest_end"]),
+            ("Max open trades", strat_results["max_open_trades"]),
+            ("", ""),  # Empty line to improve readability
+            (
+                "Total/Daily Avg Trades",
+                f"{strat_results['total_trades']} / {strat_results['trades_per_day']}",
+            ),
+            (
+                "Starting balance",
+                fmt_coin(strat_results["starting_balance"], strat_results["stake_currency"]),
+            ),
+            (
+                "Final balance",
+                fmt_coin(strat_results["final_balance"], strat_results["stake_currency"]),
+            ),
+            (
+                "Absolute profit ",
+                fmt_coin(strat_results["profit_total_abs"], strat_results["stake_currency"]),
+            ),
+            ("Total profit %", f"{strat_results['profit_total']:.2%}"),
+            ("CAGR %", f"{strat_results['cagr']:.2%}" if "cagr" in strat_results else "N/A"),
+            ("Sortino", f"{strat_results['sortino']:.2f}" if "sortino" in strat_results else "N/A"),
+            ("Sharpe", f"{strat_results['sharpe']:.2f}" if "sharpe" in strat_results else "N/A"),
+            ("Calmar", f"{strat_results['calmar']:.2f}" if "calmar" in strat_results else "N/A"),
+            (
+                "Profit factor",
+                (
+                    f'{strat_results["profit_factor"]:.2f}'
+                    if "profit_factor" in strat_results
+                    else "N/A"
+                ),
+            ),
+            (
+                "Expectancy (Ratio)",
+                (
+                    f"{strat_results['expectancy']:.2f} ({strat_results['expectancy_ratio']:.2f})"
+                    if "expectancy_ratio" in strat_results
+                    else "N/A"
+                ),
+            ),
+            (
+                "Avg. daily profit %",
+                f"{(strat_results['profit_total'] / strat_results['backtest_days']):.2%}",
+            ),
+            (
+                "Avg. stake amount",
+                fmt_coin(strat_results["avg_stake_amount"], strat_results["stake_currency"]),
+            ),
+            (
+                "Total trade volume",
+                fmt_coin(strat_results["total_volume"], strat_results["stake_currency"]),
+            ),
             *short_metrics,
-            ('', ''),  # Empty line to improve readability
-            ('Best Pair', f"{strat_results['best_pair']['key']} "
-                          f"{strat_results['best_pair']['profit_total']:.2%}"),
-            ('Worst Pair', f"{strat_results['worst_pair']['key']} "
-                           f"{strat_results['worst_pair']['profit_total']:.2%}"),
-            ('Best trade', f"{best_trade['pair']} {best_trade['profit_ratio']:.2%}"),
-            ('Worst trade', f"{worst_trade['pair']} "
-                            f"{worst_trade['profit_ratio']:.2%}"),
-
-            ('Best day', fmt_coin(strat_results['backtest_best_day_abs'],
-                                  strat_results['stake_currency'])),
-            ('Worst day', fmt_coin(strat_results['backtest_worst_day_abs'],
-                                   strat_results['stake_currency'])),
-            ('Days win/draw/lose', f"{strat_results['winning_days']} / "
-                f"{strat_results['draw_days']} / {strat_results['losing_days']}"),
-            ('Avg. Duration Winners', f"{strat_results['winner_holding_avg']}"),
-            ('Avg. Duration Loser', f"{strat_results['loser_holding_avg']}"),
-            ('Max Consecutive Wins / Loss',
-             f"{strat_results['max_consecutive_wins']} / {strat_results['max_consecutive_losses']}"
-             if 'max_consecutive_losses' in strat_results else 'N/A'),
-            ('Rejected Entry signals', strat_results.get('rejected_signals', 'N/A')),
-            ('Entry/Exit Timeouts',
-             f"{strat_results.get('timedout_entry_orders', 'N/A')} / "
-             f"{strat_results.get('timedout_exit_orders', 'N/A')}"),
+            ("", ""),  # Empty line to improve readability
+            (
+                "Best Pair",
+                f"{strat_results['best_pair']['key']} "
+                f"{strat_results['best_pair']['profit_total']:.2%}",
+            ),
+            (
+                "Worst Pair",
+                f"{strat_results['worst_pair']['key']} "
+                f"{strat_results['worst_pair']['profit_total']:.2%}",
+            ),
+            ("Best trade", f"{best_trade['pair']} {best_trade['profit_ratio']:.2%}"),
+            ("Worst trade", f"{worst_trade['pair']} {worst_trade['profit_ratio']:.2%}"),
+            (
+                "Best day",
+                fmt_coin(strat_results["backtest_best_day_abs"], strat_results["stake_currency"]),
+            ),
+            (
+                "Worst day",
+                fmt_coin(strat_results["backtest_worst_day_abs"], strat_results["stake_currency"]),
+            ),
+            (
+                "Days win/draw/lose",
+                f"{strat_results['winning_days']} / "
+                f"{strat_results['draw_days']} / {strat_results['losing_days']}",
+            ),
+            ("Avg. Duration Winners", f"{strat_results['winner_holding_avg']}"),
+            ("Avg. Duration Loser", f"{strat_results['loser_holding_avg']}"),
+            (
+                "Max Consecutive Wins / Loss",
+                (
+                    (
+                        f"{strat_results['max_consecutive_wins']} / "
+                        f"{strat_results['max_consecutive_losses']}"
+                    )
+                    if "max_consecutive_losses" in strat_results
+                    else "N/A"
+                ),
+            ),
+            ("Rejected Entry signals", strat_results.get("rejected_signals", "N/A")),
+            (
+                "Entry/Exit Timeouts",
+                f"{strat_results.get('timedout_entry_orders', 'N/A')} / "
+                f"{strat_results.get('timedout_exit_orders', 'N/A')}",
+            ),
             *entry_adjustment_metrics,
-            ('', ''),  # Empty line to improve readability
-
-            ('Min balance', fmt_coin(strat_results['csum_min'], strat_results['stake_currency'])),
-            ('Max balance', fmt_coin(strat_results['csum_max'], strat_results['stake_currency'])),
-
+            ("", ""),  # Empty line to improve readability
+            ("Min balance", fmt_coin(strat_results["csum_min"], strat_results["stake_currency"])),
+            ("Max balance", fmt_coin(strat_results["csum_max"], strat_results["stake_currency"])),
             *drawdown_metrics,
-            ('Market change', f"{strat_results['market_change']:.2%}"),
+            ("Market change", f"{strat_results['market_change']:.2%}"),
         ]
 
         return tabulate(metrics, headers=["Metric", "Value"], tablefmt="orgtbl")
     else:
-        start_balance = fmt_coin(strat_results['starting_balance'], strat_results['stake_currency'])
-        stake_amount = fmt_coin(
-            strat_results['stake_amount'], strat_results['stake_currency']
-        ) if strat_results['stake_amount'] != UNLIMITED_STAKE_AMOUNT else 'unlimited'
-
-        message = ("No trades made. "
-                   f"Your starting balance was {start_balance}, "
-                   f"and your stake was {stake_amount}."
-                   )
+        start_balance = fmt_coin(strat_results["starting_balance"], strat_results["stake_currency"])
+        stake_amount = (
+            fmt_coin(strat_results["stake_amount"], strat_results["stake_currency"])
+            if strat_results["stake_amount"] != UNLIMITED_STAKE_AMOUNT
+            else "unlimited"
+        )
+
+        message = (
+            "No trades made. "
+            f"Your starting balance was {start_balance}, "
+            f"and your stake was {stake_amount}."
+        )
         return message
 
 
-def show_backtest_result(strategy: str, results: Dict[str, Any], stake_currency: str,
-                         backtest_breakdown: List[str]):
+def show_backtest_result(
+    strategy: str, results: Dict[str, Any], stake_currency: str, backtest_breakdown: List[str]
+):
     """
     Print results for one strategy
     """
     # Print results
     print(f"Result for strategy {strategy}")
-    table = text_table_bt_results(results['results_per_pair'], stake_currency=stake_currency)
+    table = text_table_bt_results(results["results_per_pair"], stake_currency=stake_currency)
     if isinstance(table, str):
-        print(' BACKTESTING REPORT '.center(len(table.splitlines()[0]), '='))
+        print(" BACKTESTING REPORT ".center(len(table.splitlines()[0]), "="))
     print(table)
 
-    table = text_table_bt_results(results['left_open_trades'], stake_currency=stake_currency)
+    table = text_table_bt_results(results["left_open_trades"], stake_currency=stake_currency)
     if isinstance(table, str) and len(table) > 0:
-        print(' LEFT OPEN TRADES REPORT '.center(len(table.splitlines()[0]), '='))
+        print(" LEFT OPEN TRADES REPORT ".center(len(table.splitlines()[0]), "="))
     print(table)
 
-    if (enter_tags := results.get('results_per_enter_tag')) is not None:
+    if (enter_tags := results.get("results_per_enter_tag")) is not None:
         table = text_table_tags("enter_tag", enter_tags, stake_currency)
 
         if isinstance(table, str) and len(table) > 0:
-            print(' ENTER TAG STATS '.center(len(table.splitlines()[0]), '='))
+            print(" ENTER TAG STATS ".center(len(table.splitlines()[0]), "="))
         print(table)
 
-    if (exit_reasons := results.get('exit_reason_summary')) is not None:
+    if (exit_reasons := results.get("exit_reason_summary")) is not None:
         table = text_table_tags("exit_tag", exit_reasons, stake_currency)
 
         if isinstance(table, str) and len(table) > 0:
-            print(' EXIT REASON STATS '.center(len(table.splitlines()[0]), '='))
+            print(" EXIT REASON STATS ".center(len(table.splitlines()[0]), "="))
         print(table)
 
     for period in backtest_breakdown:
-        if period in results.get('periodic_breakdown', {}):
-            days_breakdown_stats = results['periodic_breakdown'][period]
+        if period in results.get("periodic_breakdown", {}):
+            days_breakdown_stats = results["periodic_breakdown"][period]
         else:
             days_breakdown_stats = generate_periodic_breakdown_stats(
-                trade_list=results['trades'], period=period)
-        table = text_table_periodic_breakdown(days_breakdown_stats=days_breakdown_stats,
-                                              stake_currency=stake_currency, period=period)
+                trade_list=results["trades"], period=period
+            )
+        table = text_table_periodic_breakdown(
+            days_breakdown_stats=days_breakdown_stats, stake_currency=stake_currency, period=period
+        )
         if isinstance(table, str) and len(table) > 0:
-            print(f' {period.upper()} BREAKDOWN '.center(len(table.splitlines()[0]), '='))
+            print(f" {period.upper()} BREAKDOWN ".center(len(table.splitlines()[0]), "="))
         print(table)
 
     table = text_table_add_metrics(results)
     if isinstance(table, str) and len(table) > 0:
-        print(' SUMMARY METRICS '.center(len(table.splitlines()[0]), '='))
+        print(" SUMMARY METRICS ".center(len(table.splitlines()[0]), "="))
     print(table)
 
     if isinstance(table, str) and len(table) > 0:
-        print('=' * len(table.splitlines()[0]))
+        print("=" * len(table.splitlines()[0]))
 
     print()
 
 
 def show_backtest_results(config: Config, backtest_stats: BacktestResultType):
-    stake_currency = config['stake_currency']
+    stake_currency = config["stake_currency"]
 
-    for strategy, results in backtest_stats['strategy'].items():
+    for strategy, results in backtest_stats["strategy"].items():
         show_backtest_result(
-            strategy, results, stake_currency,
-            config.get('backtest_breakdown', []))
+            strategy, results, stake_currency, config.get("backtest_breakdown", [])
+        )
 
-    if len(backtest_stats['strategy']) > 0:
+    if len(backtest_stats["strategy"]) > 0:
         # Print Strategy summary table
 
-        table = text_table_strategy(backtest_stats['strategy_comparison'], stake_currency)
-        print(f"Backtested {results['backtest_start']} -> {results['backtest_end']} |"
-              f" Max open trades : {results['max_open_trades']}")
-        print(' STRATEGY SUMMARY '.center(len(table.splitlines()[0]), '='))
+        table = text_table_strategy(backtest_stats["strategy_comparison"], stake_currency)
+        print(
+            f"Backtested {results['backtest_start']} -> {results['backtest_end']} |"
+            f" Max open trades : {results['max_open_trades']}"
+        )
+        print(" STRATEGY SUMMARY ".center(len(table.splitlines()[0]), "="))
         print(table)
-        print('=' * len(table.splitlines()[0]))
-        print('\nFor more details, please look at the detail tables above')
+        print("=" * len(table.splitlines()[0]))
+        print("\nFor more details, please look at the detail tables above")
 
 
 def show_sorted_pairlist(config: Config, backtest_stats: BacktestResultType):
-    if config.get('backtest_show_pair_list', False):
-        for strategy, results in backtest_stats['strategy'].items():
+    if config.get("backtest_show_pair_list", False):
+        for strategy, results in backtest_stats["strategy"].items():
             print(f"Pairs for Strategy {strategy}: \n[")
-            for result in results['results_per_pair']:
-                if result["key"] != 'TOTAL':
+            for result in results["results_per_pair"]:
+                if result["key"] != "TOTAL":
                     print(f'"{result["key"]}",  // {result["profit_mean"]:.2%}')
             print("]")
 
 
 def generate_edge_table(results: dict) -> str:
-    floatfmt = ('s', '.10g', '.2f', '.2f', '.2f', '.2f', 'd', 'd', 'd')
+    floatfmt = ("s", ".10g", ".2f", ".2f", ".2f", ".2f", "d", "d", "d")
     tabular_data = []
-    headers = ['Pair', 'Stoploss', 'Win Rate', 'Risk Reward Ratio',
-               'Required Risk Reward', 'Expectancy', 'Total Number of Trades',
-               'Average Duration (min)']
+    headers = [
+        "Pair",
+        "Stoploss",
+        "Win Rate",
+        "Risk Reward Ratio",
+        "Required Risk Reward",
+        "Expectancy",
+        "Total Number of Trades",
+        "Average Duration (min)",
+    ]
 
     for result in results.items():
         if result[1].nb_trades > 0:
-            tabular_data.append([
-                result[0],
-                result[1].stoploss,
-                result[1].winrate,
-                result[1].risk_reward_ratio,
-                result[1].required_risk_reward,
-                result[1].expectancy,
-                result[1].nb_trades,
-                round(result[1].avg_trade_duration)
-            ])
+            tabular_data.append(
+                [
+                    result[0],
+                    result[1].stoploss,
+                    result[1].winrate,
+                    result[1].risk_reward_ratio,
+                    result[1].required_risk_reward,
+                    result[1].expectancy,
+                    result[1].nb_trades,
+                    round(result[1].avg_trade_duration),
+                ]
+            )
 
     # Ignore type as floatfmt does allow tuples but mypy does not know that
-    return tabulate(tabular_data, headers=headers,
-                    floatfmt=floatfmt, tablefmt="orgtbl", stralign="right")
+    return tabulate(
+        tabular_data, headers=headers, floatfmt=floatfmt, tablefmt="orgtbl", stralign="right"
+    )
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/optimize_reports/bt_storage.py` & `freqtrade-2024.5/freqtrade/optimize/optimize_reports/bt_storage.py`

 * *Files 3% similar despite different names*

```diff
@@ -18,74 +18,79 @@
     Generates a filename based on the provided parameters.
     :param recordfilename: Path object, which can either be a filename or a directory.
     :param appendix: use for the filename. e.g. backtest-result-<datetime>
     :param suffix: Suffix to use for the file, e.g. .json, .pkl
     :return: Generated filename as a Path object
     """
     if recordfilename.is_dir():
-        filename = (recordfilename / f'backtest-result-{appendix}').with_suffix(suffix)
+        filename = (recordfilename / f"backtest-result-{appendix}").with_suffix(suffix)
     else:
         filename = Path.joinpath(
-            recordfilename.parent, f'{recordfilename.stem}-{appendix}'
+            recordfilename.parent, f"{recordfilename.stem}-{appendix}"
         ).with_suffix(suffix)
     return filename
 
 
 def store_backtest_stats(
-        recordfilename: Path, stats: BacktestResultType, dtappendix: str, *,
-        market_change_data: Optional[DataFrame] = None) -> Path:
+    recordfilename: Path,
+    stats: BacktestResultType,
+    dtappendix: str,
+    *,
+    market_change_data: Optional[DataFrame] = None,
+) -> Path:
     """
     Stores backtest results
     :param recordfilename: Path object, which can either be a filename or a directory.
         Filenames will be appended with a timestamp right before the suffix
         while for directories, <directory>/backtest-result-<datetime>.json will be used as filename
     :param stats: Dataframe containing the backtesting statistics
     :param dtappendix: Datetime to use for the filename
     """
-    filename = _generate_filename(recordfilename, dtappendix, '.json')
+    filename = _generate_filename(recordfilename, dtappendix, ".json")
 
     # Store metadata separately.
-    file_dump_json(get_backtest_metadata_filename(filename), stats['metadata'])
+    file_dump_json(get_backtest_metadata_filename(filename), stats["metadata"])
     # Don't mutate the original stats dict.
     stats_copy = {
-        'strategy': stats['strategy'],
-        'strategy_comparison': stats['strategy_comparison'],
+        "strategy": stats["strategy"],
+        "strategy_comparison": stats["strategy_comparison"],
     }
 
     file_dump_json(filename, stats_copy)
 
     latest_filename = Path.joinpath(filename.parent, LAST_BT_RESULT_FN)
-    file_dump_json(latest_filename, {'latest_backtest': str(filename.name)})
+    file_dump_json(latest_filename, {"latest_backtest": str(filename.name)})
 
     if market_change_data is not None:
-        filename_mc = _generate_filename(recordfilename, f"{dtappendix}_market_change", '.feather')
+        filename_mc = _generate_filename(recordfilename, f"{dtappendix}_market_change", ".feather")
         market_change_data.reset_index().to_feather(
-            filename_mc, compression_level=9, compression='lz4')
+            filename_mc, compression_level=9, compression="lz4"
+        )
 
     return filename
 
 
 def _store_backtest_analysis_data(
-        recordfilename: Path, data: Dict[str, Dict],
-        dtappendix: str, name: str) -> Path:
+    recordfilename: Path, data: Dict[str, Dict], dtappendix: str, name: str
+) -> Path:
     """
     Stores backtest trade candles for analysis
     :param recordfilename: Path object, which can either be a filename or a directory.
         Filenames will be appended with a timestamp right before the suffix
         while for directories, <directory>/backtest-result-<datetime>_<name>.pkl will be used
         as filename
     :param candles: Dict containing the backtesting data for analysis
     :param dtappendix: Datetime to use for the filename
     :param name: Name to use for the file, e.g. signals, rejected
     """
-    filename = _generate_filename(recordfilename, f"{dtappendix}_{name}", '.pkl')
+    filename = _generate_filename(recordfilename, f"{dtappendix}_{name}", ".pkl")
 
     file_dump_joblib(filename, data)
 
     return filename
 
 
 def store_backtest_analysis_results(
-        recordfilename: Path, candles: Dict[str, Dict], trades: Dict[str, Dict],
-        dtappendix: str) -> None:
+    recordfilename: Path, candles: Dict[str, Dict], trades: Dict[str, Dict], dtappendix: str
+) -> None:
     _store_backtest_analysis_data(recordfilename, candles, dtappendix, "signals")
     _store_backtest_analysis_data(recordfilename, trades, dtappendix, "rejected")
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/optimize_reports/optimize_reports.py` & `freqtrade-2024.5/freqtrade/optimize/optimize_reports/optimize_reports.py`

 * *Files 22% similar despite different names*

```diff
@@ -3,216 +3,233 @@
 from datetime import datetime, timedelta, timezone
 from typing import Any, Dict, List, Tuple, Union
 
 import numpy as np
 from pandas import DataFrame, Series, concat, to_datetime
 
 from freqtrade.constants import BACKTEST_BREAKDOWNS, DATETIME_PRINT_FORMAT
-from freqtrade.data.metrics import (calculate_cagr, calculate_calmar, calculate_csum,
-                                    calculate_expectancy, calculate_market_change,
-                                    calculate_max_drawdown, calculate_sharpe, calculate_sortino)
+from freqtrade.data.metrics import (
+    calculate_cagr,
+    calculate_calmar,
+    calculate_csum,
+    calculate_expectancy,
+    calculate_market_change,
+    calculate_max_drawdown,
+    calculate_sharpe,
+    calculate_sortino,
+)
 from freqtrade.types import BacktestResultType
 from freqtrade.util import decimals_per_coin, fmt_coin
 
 
 logger = logging.getLogger(__name__)
 
 
-def generate_trade_signal_candles(preprocessed_df: Dict[str, DataFrame],
-                                  bt_results: Dict[str, Any]) -> DataFrame:
+def generate_trade_signal_candles(
+    preprocessed_df: Dict[str, DataFrame], bt_results: Dict[str, Any]
+) -> DataFrame:
     signal_candles_only = {}
     for pair in preprocessed_df.keys():
         signal_candles_only_df = DataFrame()
 
         pairdf = preprocessed_df[pair]
-        resdf = bt_results['results']
+        resdf = bt_results["results"]
         pairresults = resdf.loc[(resdf["pair"] == pair)]
 
         if pairdf.shape[0] > 0:
             for t, v in pairresults.open_date.items():
-                allinds = pairdf.loc[(pairdf['date'] < v)]
+                allinds = pairdf.loc[(pairdf["date"] < v)]
                 signal_inds = allinds.iloc[[-1]]
-                signal_candles_only_df = concat([
-                    signal_candles_only_df.infer_objects(),
-                    signal_inds.infer_objects()])
+                signal_candles_only_df = concat(
+                    [signal_candles_only_df.infer_objects(), signal_inds.infer_objects()]
+                )
 
             signal_candles_only[pair] = signal_candles_only_df
     return signal_candles_only
 
 
-def generate_rejected_signals(preprocessed_df: Dict[str, DataFrame],
-                              rejected_dict: Dict[str, DataFrame]) -> Dict[str, DataFrame]:
+def generate_rejected_signals(
+    preprocessed_df: Dict[str, DataFrame], rejected_dict: Dict[str, DataFrame]
+) -> Dict[str, DataFrame]:
     rejected_candles_only = {}
     for pair, signals in rejected_dict.items():
         rejected_signals_only_df = DataFrame()
         pairdf = preprocessed_df[pair]
 
         for t in signals:
-            data_df_row = pairdf.loc[(pairdf['date'] == t[0])].copy()
-            data_df_row['pair'] = pair
-            data_df_row['enter_tag'] = t[1]
-
-            rejected_signals_only_df = concat([
-                rejected_signals_only_df.infer_objects(),
-                data_df_row.infer_objects()])
+            data_df_row = pairdf.loc[(pairdf["date"] == t[0])].copy()
+            data_df_row["pair"] = pair
+            data_df_row["enter_tag"] = t[1]
+
+            rejected_signals_only_df = concat(
+                [rejected_signals_only_df.infer_objects(), data_df_row.infer_objects()]
+            )
 
         rejected_candles_only[pair] = rejected_signals_only_df
     return rejected_candles_only
 
 
 def _generate_result_line(result: DataFrame, starting_balance: int, first_column: str) -> Dict:
     """
     Generate one result dict, with "first_column" as key.
     """
-    profit_sum = result['profit_ratio'].sum()
+    profit_sum = result["profit_ratio"].sum()
     # (end-capital - starting capital) / starting capital
-    profit_total = result['profit_abs'].sum() / starting_balance
+    profit_total = result["profit_abs"].sum() / starting_balance
 
     return {
-        'key': first_column,
-        'trades': len(result),
-        'profit_mean': result['profit_ratio'].mean() if len(result) > 0 else 0.0,
-        'profit_mean_pct': round(result['profit_ratio'].mean() * 100.0, 2
-                                 ) if len(result) > 0 else 0.0,
-        'profit_sum': profit_sum,
-        'profit_sum_pct': round(profit_sum * 100.0, 2),
-        'profit_total_abs': result['profit_abs'].sum(),
-        'profit_total': profit_total,
-        'profit_total_pct': round(profit_total * 100.0, 2),
-        'duration_avg': str(timedelta(
-                            minutes=round(result['trade_duration'].mean()))
-                            ) if not result.empty else '0:00',
+        "key": first_column,
+        "trades": len(result),
+        "profit_mean": result["profit_ratio"].mean() if len(result) > 0 else 0.0,
+        "profit_mean_pct": (
+            round(result["profit_ratio"].mean() * 100.0, 2) if len(result) > 0 else 0.0
+        ),
+        "profit_sum": profit_sum,
+        "profit_sum_pct": round(profit_sum * 100.0, 2),
+        "profit_total_abs": result["profit_abs"].sum(),
+        "profit_total": profit_total,
+        "profit_total_pct": round(profit_total * 100.0, 2),
+        "duration_avg": (
+            str(timedelta(minutes=round(result["trade_duration"].mean())))
+            if not result.empty
+            else "0:00"
+        ),
         # 'duration_max': str(timedelta(
         #                     minutes=round(result['trade_duration'].max()))
         #                     ) if not result.empty else '0:00',
         # 'duration_min': str(timedelta(
         #                     minutes=round(result['trade_duration'].min()))
         #                     ) if not result.empty else '0:00',
-        'wins': len(result[result['profit_abs'] > 0]),
-        'draws': len(result[result['profit_abs'] == 0]),
-        'losses': len(result[result['profit_abs'] < 0]),
-        'winrate': len(result[result['profit_abs'] > 0]) / len(result) if len(result) else 0.0,
+        "wins": len(result[result["profit_abs"] > 0]),
+        "draws": len(result[result["profit_abs"] == 0]),
+        "losses": len(result[result["profit_abs"] < 0]),
+        "winrate": len(result[result["profit_abs"] > 0]) / len(result) if len(result) else 0.0,
     }
 
 
-def generate_pair_metrics(pairlist: List[str], stake_currency: str, starting_balance: int,
-                          results: DataFrame, skip_nan: bool = False) -> List[Dict]:
+def generate_pair_metrics(
+    pairlist: List[str],
+    stake_currency: str,
+    starting_balance: int,
+    results: DataFrame,
+    skip_nan: bool = False,
+) -> List[Dict]:
     """
     Generates and returns a list  for the given backtest data and the results dataframe
     :param pairlist: Pairlist used
     :param stake_currency: stake-currency - used to correctly name headers
     :param starting_balance: Starting balance
     :param results: Dataframe containing the backtest results
     :param skip_nan: Print "left open" open trades
     :return: List of Dicts containing the metrics per pair
     """
 
     tabular_data = []
 
     for pair in pairlist:
-        result = results[results['pair'] == pair]
-        if skip_nan and result['profit_abs'].isnull().all():
+        result = results[results["pair"] == pair]
+        if skip_nan and result["profit_abs"].isnull().all():
             continue
 
         tabular_data.append(_generate_result_line(result, starting_balance, pair))
 
     # Sort by total profit %:
-    tabular_data = sorted(tabular_data, key=lambda k: k['profit_total_abs'], reverse=True)
+    tabular_data = sorted(tabular_data, key=lambda k: k["profit_total_abs"], reverse=True)
 
     # Append Total
-    tabular_data.append(_generate_result_line(results, starting_balance, 'TOTAL'))
+    tabular_data.append(_generate_result_line(results, starting_balance, "TOTAL"))
     return tabular_data
 
 
-def generate_tag_metrics(tag_type: str,
-                         starting_balance: int,
-                         results: DataFrame,
-                         skip_nan: bool = False) -> List[Dict]:
+def generate_tag_metrics(
+    tag_type: str, starting_balance: int, results: DataFrame, skip_nan: bool = False
+) -> List[Dict]:
     """
     Generates and returns a list of metrics for the given tag trades and the results dataframe
     :param starting_balance: Starting balance
     :param results: Dataframe containing the backtest results
     :param skip_nan: Print "left open" open trades
     :return: List of Dicts containing the metrics per pair
     """
 
     tabular_data = []
 
     if tag_type in results.columns:
         for tag, count in results[tag_type].value_counts().items():
             result = results[results[tag_type] == tag]
-            if skip_nan and result['profit_abs'].isnull().all():
+            if skip_nan and result["profit_abs"].isnull().all():
                 continue
 
             tabular_data.append(_generate_result_line(result, starting_balance, tag))
 
         # Sort by total profit %:
-        tabular_data = sorted(tabular_data, key=lambda k: k['profit_total_abs'], reverse=True)
+        tabular_data = sorted(tabular_data, key=lambda k: k["profit_total_abs"], reverse=True)
 
         # Append Total
-        tabular_data.append(_generate_result_line(results, starting_balance, 'TOTAL'))
+        tabular_data.append(_generate_result_line(results, starting_balance, "TOTAL"))
         return tabular_data
     else:
         return []
 
 
 def generate_strategy_comparison(bt_stats: Dict) -> List[Dict]:
     """
     Generate summary per strategy
     :param bt_stats: Dict of <Strategyname: DataFrame> containing results for all strategies
     :return: List of Dicts containing the metrics per Strategy
     """
 
     tabular_data = []
     for strategy, result in bt_stats.items():
-        tabular_data.append(deepcopy(result['results_per_pair'][-1]))
+        tabular_data.append(deepcopy(result["results_per_pair"][-1]))
         # Update "key" to strategy (results_per_pair has it as "Total").
-        tabular_data[-1]['key'] = strategy
-        tabular_data[-1]['max_drawdown_account'] = result['max_drawdown_account']
-        tabular_data[-1]['max_drawdown_abs'] = fmt_coin(
-            result['max_drawdown_abs'], result['stake_currency'], False)
+        tabular_data[-1]["key"] = strategy
+        tabular_data[-1]["max_drawdown_account"] = result["max_drawdown_account"]
+        tabular_data[-1]["max_drawdown_abs"] = fmt_coin(
+            result["max_drawdown_abs"], result["stake_currency"], False
+        )
     return tabular_data
 
 
 def _get_resample_from_period(period: str) -> str:
-    if period == 'day':
-        return '1d'
-    if period == 'week':
+    if period == "day":
+        return "1d"
+    if period == "week":
         # Weekly defaulting to Monday.
-        return '1W-MON'
-    if period == 'month':
-        return '1ME'
+        return "1W-MON"
+    if period == "month":
+        return "1ME"
     raise ValueError(f"Period {period} is not supported.")
 
 
 def generate_periodic_breakdown_stats(
-        trade_list: Union[List,  DataFrame], period: str) -> List[Dict[str, Any]]:
-
+    trade_list: Union[List, DataFrame], period: str
+) -> List[Dict[str, Any]]:
     results = trade_list if not isinstance(trade_list, list) else DataFrame.from_records(trade_list)
     if len(results) == 0:
         return []
-    results['close_date'] = to_datetime(results['close_date'], utc=True)
+    results["close_date"] = to_datetime(results["close_date"], utc=True)
     resample_period = _get_resample_from_period(period)
-    resampled = results.resample(resample_period, on='close_date')
+    resampled = results.resample(resample_period, on="close_date")
     stats = []
     for name, day in resampled:
-        profit_abs = day['profit_abs'].sum().round(10)
-        wins = sum(day['profit_abs'] > 0)
-        draws = sum(day['profit_abs'] == 0)
-        loses = sum(day['profit_abs'] < 0)
-        trades = (wins + draws + loses)
+        profit_abs = day["profit_abs"].sum().round(10)
+        wins = sum(day["profit_abs"] > 0)
+        draws = sum(day["profit_abs"] == 0)
+        loses = sum(day["profit_abs"] < 0)
+        trades = wins + draws + loses
         stats.append(
             {
-                'date': name.strftime('%d/%m/%Y'),
-                'date_ts': int(name.to_pydatetime().timestamp() * 1000),
-                'profit_abs': profit_abs,
-                'wins': wins,
-                'draws': draws,
-                'loses': loses,
-                'winrate': wins / trades if trades else 0.0,
+                "date": name.strftime("%d/%m/%Y"),
+                "date_ts": int(name.to_pydatetime().timestamp() * 1000),
+                "profit_abs": profit_abs,
+                "wins": wins,
+                "draws": draws,
+                "loses": loses,
+                "winrate": wins / trades if trades else 0.0,
             }
         )
     return stats
 
 
 def generate_all_periodic_breakdown_stats(trade_list: List) -> Dict[str, List]:
     result = {}
@@ -224,317 +241,346 @@
 def calc_streak(dataframe: DataFrame) -> Tuple[int, int]:
     """
     Calculate consecutive win and loss streaks
     :param dataframe: Dataframe containing the trades dataframe, with profit_ratio column
     :return: Tuple containing consecutive wins and losses
     """
 
-    df = Series(np.where(dataframe['profit_ratio'] > 0, 'win', 'loss')).to_frame('result')
-    df['streaks'] = df['result'].ne(df['result'].shift()).cumsum().rename('streaks')
-    df['counter'] = df['streaks'].groupby(df['streaks']).cumcount() + 1
-    res = df.groupby(df['result']).max()
+    df = Series(np.where(dataframe["profit_ratio"] > 0, "win", "loss")).to_frame("result")
+    df["streaks"] = df["result"].ne(df["result"].shift()).cumsum().rename("streaks")
+    df["counter"] = df["streaks"].groupby(df["streaks"]).cumcount() + 1
+    res = df.groupby(df["result"]).max()
     #
-    cons_wins = int(res.loc['win', 'counter']) if 'win' in res.index else 0
-    cons_losses = int(res.loc['loss', 'counter']) if 'loss' in res.index else 0
+    cons_wins = int(res.loc["win", "counter"]) if "win" in res.index else 0
+    cons_losses = int(res.loc["loss", "counter"]) if "loss" in res.index else 0
     return cons_wins, cons_losses
 
 
 def generate_trading_stats(results: DataFrame) -> Dict[str, Any]:
-    """ Generate overall trade statistics """
+    """Generate overall trade statistics"""
     if len(results) == 0:
         return {
-            'wins': 0,
-            'losses': 0,
-            'draws': 0,
-            'winrate': 0,
-            'holding_avg': timedelta(),
-            'winner_holding_avg': timedelta(),
-            'loser_holding_avg': timedelta(),
-            'max_consecutive_wins': 0,
-            'max_consecutive_losses': 0,
+            "wins": 0,
+            "losses": 0,
+            "draws": 0,
+            "winrate": 0,
+            "holding_avg": timedelta(),
+            "winner_holding_avg": timedelta(),
+            "loser_holding_avg": timedelta(),
+            "max_consecutive_wins": 0,
+            "max_consecutive_losses": 0,
         }
 
-    winning_trades = results.loc[results['profit_ratio'] > 0]
-    draw_trades = results.loc[results['profit_ratio'] == 0]
-    losing_trades = results.loc[results['profit_ratio'] < 0]
-
-    holding_avg = (timedelta(minutes=round(results['trade_duration'].mean()))
-                   if not results.empty else timedelta())
-    winner_holding_avg = (timedelta(minutes=round(winning_trades['trade_duration'].mean()))
-                          if not winning_trades.empty else timedelta())
-    loser_holding_avg = (timedelta(minutes=round(losing_trades['trade_duration'].mean()))
-                         if not losing_trades.empty else timedelta())
+    winning_trades = results.loc[results["profit_ratio"] > 0]
+    draw_trades = results.loc[results["profit_ratio"] == 0]
+    losing_trades = results.loc[results["profit_ratio"] < 0]
+
+    holding_avg = (
+        timedelta(minutes=round(results["trade_duration"].mean()))
+        if not results.empty
+        else timedelta()
+    )
+    winner_holding_avg = (
+        timedelta(minutes=round(winning_trades["trade_duration"].mean()))
+        if not winning_trades.empty
+        else timedelta()
+    )
+    loser_holding_avg = (
+        timedelta(minutes=round(losing_trades["trade_duration"].mean()))
+        if not losing_trades.empty
+        else timedelta()
+    )
     winstreak, loss_streak = calc_streak(results)
 
     return {
-        'wins': len(winning_trades),
-        'losses': len(losing_trades),
-        'draws': len(draw_trades),
-        'winrate': len(winning_trades) / len(results) if len(results) else 0.0,
-        'holding_avg': holding_avg,
-        'holding_avg_s': holding_avg.total_seconds(),
-        'winner_holding_avg': winner_holding_avg,
-        'winner_holding_avg_s': winner_holding_avg.total_seconds(),
-        'loser_holding_avg': loser_holding_avg,
-        'loser_holding_avg_s': loser_holding_avg.total_seconds(),
-        'max_consecutive_wins': winstreak,
-        'max_consecutive_losses': loss_streak,
+        "wins": len(winning_trades),
+        "losses": len(losing_trades),
+        "draws": len(draw_trades),
+        "winrate": len(winning_trades) / len(results) if len(results) else 0.0,
+        "holding_avg": holding_avg,
+        "holding_avg_s": holding_avg.total_seconds(),
+        "winner_holding_avg": winner_holding_avg,
+        "winner_holding_avg_s": winner_holding_avg.total_seconds(),
+        "loser_holding_avg": loser_holding_avg,
+        "loser_holding_avg_s": loser_holding_avg.total_seconds(),
+        "max_consecutive_wins": winstreak,
+        "max_consecutive_losses": loss_streak,
     }
 
 
 def generate_daily_stats(results: DataFrame) -> Dict[str, Any]:
-    """ Generate daily statistics """
+    """Generate daily statistics"""
     if len(results) == 0:
         return {
-            'backtest_best_day': 0,
-            'backtest_worst_day': 0,
-            'backtest_best_day_abs': 0,
-            'backtest_worst_day_abs': 0,
-            'winning_days': 0,
-            'draw_days': 0,
-            'losing_days': 0,
-            'daily_profit_list': [],
+            "backtest_best_day": 0,
+            "backtest_worst_day": 0,
+            "backtest_best_day_abs": 0,
+            "backtest_worst_day_abs": 0,
+            "winning_days": 0,
+            "draw_days": 0,
+            "losing_days": 0,
+            "daily_profit_list": [],
         }
-    daily_profit_rel = results.resample('1d', on='close_date')['profit_ratio'].sum()
-    daily_profit = results.resample('1d', on='close_date')['profit_abs'].sum().round(10)
+    daily_profit_rel = results.resample("1d", on="close_date")["profit_ratio"].sum()
+    daily_profit = results.resample("1d", on="close_date")["profit_abs"].sum().round(10)
     worst_rel = min(daily_profit_rel)
     best_rel = max(daily_profit_rel)
     worst = min(daily_profit)
     best = max(daily_profit)
     winning_days = sum(daily_profit > 0)
     draw_days = sum(daily_profit == 0)
     losing_days = sum(daily_profit < 0)
     daily_profit_list = [(str(idx.date()), val) for idx, val in daily_profit.items()]
 
     return {
-        'backtest_best_day': best_rel,
-        'backtest_worst_day': worst_rel,
-        'backtest_best_day_abs': best,
-        'backtest_worst_day_abs': worst,
-        'winning_days': winning_days,
-        'draw_days': draw_days,
-        'losing_days': losing_days,
-        'daily_profit': daily_profit_list,
+        "backtest_best_day": best_rel,
+        "backtest_worst_day": worst_rel,
+        "backtest_best_day_abs": best,
+        "backtest_worst_day_abs": worst,
+        "winning_days": winning_days,
+        "draw_days": draw_days,
+        "losing_days": losing_days,
+        "daily_profit": daily_profit_list,
     }
 
 
-def generate_strategy_stats(pairlist: List[str],
-                            strategy: str,
-                            content: Dict[str, Any],
-                            min_date: datetime, max_date: datetime,
-                            market_change: float,
-                            is_hyperopt: bool = False,
-                            ) -> Dict[str, Any]:
+def generate_strategy_stats(
+    pairlist: List[str],
+    strategy: str,
+    content: Dict[str, Any],
+    min_date: datetime,
+    max_date: datetime,
+    market_change: float,
+    is_hyperopt: bool = False,
+) -> Dict[str, Any]:
     """
     :param pairlist: List of pairs to backtest
     :param strategy: Strategy name
     :param content: Backtest result data in the format:
                     {'results: results, 'config: config}}.
     :param min_date: Backtest start date
     :param max_date: Backtest end date
     :param market_change: float indicating the market change
     :return: Dictionary containing results per strategy and a strategy summary.
     """
-    results: Dict[str, DataFrame] = content['results']
+    results: Dict[str, DataFrame] = content["results"]
     if not isinstance(results, DataFrame):
         return {}
-    config = content['config']
-    max_open_trades = min(config['max_open_trades'], len(pairlist))
-    start_balance = config['dry_run_wallet']
-    stake_currency = config['stake_currency']
-
-    pair_results = generate_pair_metrics(pairlist, stake_currency=stake_currency,
-                                         starting_balance=start_balance,
-                                         results=results, skip_nan=False)
-
-    enter_tag_results = generate_tag_metrics("enter_tag", starting_balance=start_balance,
-                                             results=results, skip_nan=False)
-    exit_reason_stats = generate_tag_metrics('exit_reason', starting_balance=start_balance,
-                                             results=results, skip_nan=False)
+    config = content["config"]
+    max_open_trades = min(config["max_open_trades"], len(pairlist))
+    start_balance = config["dry_run_wallet"]
+    stake_currency = config["stake_currency"]
+
+    pair_results = generate_pair_metrics(
+        pairlist,
+        stake_currency=stake_currency,
+        starting_balance=start_balance,
+        results=results,
+        skip_nan=False,
+    )
+
+    enter_tag_results = generate_tag_metrics(
+        "enter_tag", starting_balance=start_balance, results=results, skip_nan=False
+    )
+    exit_reason_stats = generate_tag_metrics(
+        "exit_reason", starting_balance=start_balance, results=results, skip_nan=False
+    )
     left_open_results = generate_pair_metrics(
-        pairlist, stake_currency=stake_currency, starting_balance=start_balance,
-        results=results.loc[results['exit_reason'] == 'force_exit'], skip_nan=True)
+        pairlist,
+        stake_currency=stake_currency,
+        starting_balance=start_balance,
+        results=results.loc[results["exit_reason"] == "force_exit"],
+        skip_nan=True,
+    )
 
     daily_stats = generate_daily_stats(results)
     trade_stats = generate_trading_stats(results)
 
     periodic_breakdown = {}
     if not is_hyperopt:
-        periodic_breakdown = {'periodic_breakdown': generate_all_periodic_breakdown_stats(results)}
+        periodic_breakdown = {"periodic_breakdown": generate_all_periodic_breakdown_stats(results)}
 
-    best_pair = max([pair for pair in pair_results if pair['key'] != 'TOTAL'],
-                    key=lambda x: x['profit_sum']) if len(pair_results) > 1 else None
-    worst_pair = min([pair for pair in pair_results if pair['key'] != 'TOTAL'],
-                     key=lambda x: x['profit_sum']) if len(pair_results) > 1 else None
-    winning_profit = results.loc[results['profit_abs'] > 0, 'profit_abs'].sum()
-    losing_profit = results.loc[results['profit_abs'] < 0, 'profit_abs'].sum()
+    best_pair = (
+        max(
+            [pair for pair in pair_results if pair["key"] != "TOTAL"], key=lambda x: x["profit_sum"]
+        )
+        if len(pair_results) > 1
+        else None
+    )
+    worst_pair = (
+        min(
+            [pair for pair in pair_results if pair["key"] != "TOTAL"], key=lambda x: x["profit_sum"]
+        )
+        if len(pair_results) > 1
+        else None
+    )
+    winning_profit = results.loc[results["profit_abs"] > 0, "profit_abs"].sum()
+    losing_profit = results.loc[results["profit_abs"] < 0, "profit_abs"].sum()
     profit_factor = winning_profit / abs(losing_profit) if losing_profit else 0.0
 
     expectancy, expectancy_ratio = calculate_expectancy(results)
     backtest_days = (max_date - min_date).days or 1
     strat_stats = {
-        'trades': results.to_dict(orient='records'),
-        'locks': [lock.to_json() for lock in content['locks']],
-        'best_pair': best_pair,
-        'worst_pair': worst_pair,
-        'results_per_pair': pair_results,
-        'results_per_enter_tag': enter_tag_results,
-        'exit_reason_summary': exit_reason_stats,
-        'left_open_trades': left_open_results,
-
-        'total_trades': len(results),
-        'trade_count_long': len(results.loc[~results['is_short']]),
-        'trade_count_short': len(results.loc[results['is_short']]),
-        'total_volume': float(results['stake_amount'].sum()),
-        'avg_stake_amount': results['stake_amount'].mean() if len(results) > 0 else 0,
-        'profit_mean': results['profit_ratio'].mean() if len(results) > 0 else 0,
-        'profit_median': results['profit_ratio'].median() if len(results) > 0 else 0,
-        'profit_total': results['profit_abs'].sum() / start_balance,
-        'profit_total_long': results.loc[~results['is_short'], 'profit_abs'].sum() / start_balance,
-        'profit_total_short': results.loc[results['is_short'], 'profit_abs'].sum() / start_balance,
-        'profit_total_abs': results['profit_abs'].sum(),
-        'profit_total_long_abs': results.loc[~results['is_short'], 'profit_abs'].sum(),
-        'profit_total_short_abs': results.loc[results['is_short'], 'profit_abs'].sum(),
-        'cagr': calculate_cagr(backtest_days, start_balance, content['final_balance']),
-        'expectancy': expectancy,
-        'expectancy_ratio': expectancy_ratio,
-        'sortino': calculate_sortino(results, min_date, max_date, start_balance),
-        'sharpe': calculate_sharpe(results, min_date, max_date, start_balance),
-        'calmar': calculate_calmar(results, min_date, max_date, start_balance),
-        'profit_factor': profit_factor,
-        'backtest_start': min_date.strftime(DATETIME_PRINT_FORMAT),
-        'backtest_start_ts': int(min_date.timestamp() * 1000),
-        'backtest_end': max_date.strftime(DATETIME_PRINT_FORMAT),
-        'backtest_end_ts': int(max_date.timestamp() * 1000),
-        'backtest_days': backtest_days,
-
-        'backtest_run_start_ts': content['backtest_start_time'],
-        'backtest_run_end_ts': content['backtest_end_time'],
-
-        'trades_per_day': round(len(results) / backtest_days, 2),
-        'market_change': market_change,
-        'pairlist': pairlist,
-        'stake_amount': config['stake_amount'],
-        'stake_currency': config['stake_currency'],
-        'stake_currency_decimals': decimals_per_coin(config['stake_currency']),
-        'starting_balance': start_balance,
-        'dry_run_wallet': start_balance,
-        'final_balance': content['final_balance'],
-        'rejected_signals': content['rejected_signals'],
-        'timedout_entry_orders': content['timedout_entry_orders'],
-        'timedout_exit_orders': content['timedout_exit_orders'],
-        'canceled_trade_entries': content['canceled_trade_entries'],
-        'canceled_entry_orders': content['canceled_entry_orders'],
-        'replaced_entry_orders': content['replaced_entry_orders'],
-        'max_open_trades': max_open_trades,
-        'max_open_trades_setting': (config['max_open_trades']
-                                    if config['max_open_trades'] != float('inf') else -1),
-        'timeframe': config['timeframe'],
-        'timeframe_detail': config.get('timeframe_detail', ''),
-        'timerange': config.get('timerange', ''),
-        'enable_protections': config.get('enable_protections', False),
-        'strategy_name': strategy,
+        "trades": results.to_dict(orient="records"),
+        "locks": [lock.to_json() for lock in content["locks"]],
+        "best_pair": best_pair,
+        "worst_pair": worst_pair,
+        "results_per_pair": pair_results,
+        "results_per_enter_tag": enter_tag_results,
+        "exit_reason_summary": exit_reason_stats,
+        "left_open_trades": left_open_results,
+        "total_trades": len(results),
+        "trade_count_long": len(results.loc[~results["is_short"]]),
+        "trade_count_short": len(results.loc[results["is_short"]]),
+        "total_volume": float(results["stake_amount"].sum()),
+        "avg_stake_amount": results["stake_amount"].mean() if len(results) > 0 else 0,
+        "profit_mean": results["profit_ratio"].mean() if len(results) > 0 else 0,
+        "profit_median": results["profit_ratio"].median() if len(results) > 0 else 0,
+        "profit_total": results["profit_abs"].sum() / start_balance,
+        "profit_total_long": results.loc[~results["is_short"], "profit_abs"].sum() / start_balance,
+        "profit_total_short": results.loc[results["is_short"], "profit_abs"].sum() / start_balance,
+        "profit_total_abs": results["profit_abs"].sum(),
+        "profit_total_long_abs": results.loc[~results["is_short"], "profit_abs"].sum(),
+        "profit_total_short_abs": results.loc[results["is_short"], "profit_abs"].sum(),
+        "cagr": calculate_cagr(backtest_days, start_balance, content["final_balance"]),
+        "expectancy": expectancy,
+        "expectancy_ratio": expectancy_ratio,
+        "sortino": calculate_sortino(results, min_date, max_date, start_balance),
+        "sharpe": calculate_sharpe(results, min_date, max_date, start_balance),
+        "calmar": calculate_calmar(results, min_date, max_date, start_balance),
+        "profit_factor": profit_factor,
+        "backtest_start": min_date.strftime(DATETIME_PRINT_FORMAT),
+        "backtest_start_ts": int(min_date.timestamp() * 1000),
+        "backtest_end": max_date.strftime(DATETIME_PRINT_FORMAT),
+        "backtest_end_ts": int(max_date.timestamp() * 1000),
+        "backtest_days": backtest_days,
+        "backtest_run_start_ts": content["backtest_start_time"],
+        "backtest_run_end_ts": content["backtest_end_time"],
+        "trades_per_day": round(len(results) / backtest_days, 2),
+        "market_change": market_change,
+        "pairlist": pairlist,
+        "stake_amount": config["stake_amount"],
+        "stake_currency": config["stake_currency"],
+        "stake_currency_decimals": decimals_per_coin(config["stake_currency"]),
+        "starting_balance": start_balance,
+        "dry_run_wallet": start_balance,
+        "final_balance": content["final_balance"],
+        "rejected_signals": content["rejected_signals"],
+        "timedout_entry_orders": content["timedout_entry_orders"],
+        "timedout_exit_orders": content["timedout_exit_orders"],
+        "canceled_trade_entries": content["canceled_trade_entries"],
+        "canceled_entry_orders": content["canceled_entry_orders"],
+        "replaced_entry_orders": content["replaced_entry_orders"],
+        "max_open_trades": max_open_trades,
+        "max_open_trades_setting": (
+            config["max_open_trades"] if config["max_open_trades"] != float("inf") else -1
+        ),
+        "timeframe": config["timeframe"],
+        "timeframe_detail": config.get("timeframe_detail", ""),
+        "timerange": config.get("timerange", ""),
+        "enable_protections": config.get("enable_protections", False),
+        "strategy_name": strategy,
         # Parameters relevant for backtesting
-        'stoploss': config['stoploss'],
-        'trailing_stop': config.get('trailing_stop', False),
-        'trailing_stop_positive': config.get('trailing_stop_positive'),
-        'trailing_stop_positive_offset': config.get('trailing_stop_positive_offset', 0.0),
-        'trailing_only_offset_is_reached': config.get('trailing_only_offset_is_reached', False),
-        'use_custom_stoploss': config.get('use_custom_stoploss', False),
-        'minimal_roi': config['minimal_roi'],
-        'use_exit_signal': config['use_exit_signal'],
-        'exit_profit_only': config['exit_profit_only'],
-        'exit_profit_offset': config['exit_profit_offset'],
-        'ignore_roi_if_entry_signal': config['ignore_roi_if_entry_signal'],
+        "stoploss": config["stoploss"],
+        "trailing_stop": config.get("trailing_stop", False),
+        "trailing_stop_positive": config.get("trailing_stop_positive"),
+        "trailing_stop_positive_offset": config.get("trailing_stop_positive_offset", 0.0),
+        "trailing_only_offset_is_reached": config.get("trailing_only_offset_is_reached", False),
+        "use_custom_stoploss": config.get("use_custom_stoploss", False),
+        "minimal_roi": config["minimal_roi"],
+        "use_exit_signal": config["use_exit_signal"],
+        "exit_profit_only": config["exit_profit_only"],
+        "exit_profit_offset": config["exit_profit_offset"],
+        "ignore_roi_if_entry_signal": config["ignore_roi_if_entry_signal"],
         **periodic_breakdown,
         **daily_stats,
-        **trade_stats
+        **trade_stats,
     }
 
     try:
-        max_drawdown_legacy, _, _, _, _, _ = calculate_max_drawdown(
-            results, value_col='profit_ratio')
-        (drawdown_abs, drawdown_start, drawdown_end, high_val, low_val,
-         max_drawdown) = calculate_max_drawdown(
-             results, value_col='profit_abs', starting_balance=start_balance)
+        drawdown = calculate_max_drawdown(
+            results, value_col="profit_abs", starting_balance=start_balance
+        )
         # max_relative_drawdown = Underwater
-        (_, _, _, _, _, max_relative_drawdown) = calculate_max_drawdown(
-             results, value_col='profit_abs', starting_balance=start_balance, relative=True)
+        underwater = calculate_max_drawdown(
+            results, value_col="profit_abs", starting_balance=start_balance, relative=True
+        )
 
-        strat_stats.update({
-            'max_drawdown': max_drawdown_legacy,  # Deprecated - do not use
-            'max_drawdown_account': max_drawdown,
-            'max_relative_drawdown': max_relative_drawdown,
-            'max_drawdown_abs': drawdown_abs,
-            'drawdown_start': drawdown_start.strftime(DATETIME_PRINT_FORMAT),
-            'drawdown_start_ts': drawdown_start.timestamp() * 1000,
-            'drawdown_end': drawdown_end.strftime(DATETIME_PRINT_FORMAT),
-            'drawdown_end_ts': drawdown_end.timestamp() * 1000,
-
-            'max_drawdown_low': low_val,
-            'max_drawdown_high': high_val,
-        })
+        strat_stats.update(
+            {
+                "max_drawdown_account": drawdown.relative_account_drawdown,
+                "max_relative_drawdown": underwater.relative_account_drawdown,
+                "max_drawdown_abs": drawdown.drawdown_abs,
+                "drawdown_start": drawdown.high_date.strftime(DATETIME_PRINT_FORMAT),
+                "drawdown_start_ts": drawdown.high_date.timestamp() * 1000,
+                "drawdown_end": drawdown.low_date.strftime(DATETIME_PRINT_FORMAT),
+                "drawdown_end_ts": drawdown.low_date.timestamp() * 1000,
+                "max_drawdown_low": drawdown.low_value,
+                "max_drawdown_high": drawdown.high_value,
+            }
+        )
 
         csum_min, csum_max = calculate_csum(results, start_balance)
-        strat_stats.update({
-            'csum_min': csum_min,
-            'csum_max': csum_max
-        })
+        strat_stats.update({"csum_min": csum_min, "csum_max": csum_max})
 
     except ValueError:
-        strat_stats.update({
-            'max_drawdown': 0.0,
-            'max_drawdown_account': 0.0,
-            'max_relative_drawdown': 0.0,
-            'max_drawdown_abs': 0.0,
-            'max_drawdown_low': 0.0,
-            'max_drawdown_high': 0.0,
-            'drawdown_start': datetime(1970, 1, 1, tzinfo=timezone.utc),
-            'drawdown_start_ts': 0,
-            'drawdown_end': datetime(1970, 1, 1, tzinfo=timezone.utc),
-            'drawdown_end_ts': 0,
-            'csum_min': 0,
-            'csum_max': 0
-        })
+        strat_stats.update(
+            {
+                "max_drawdown_account": 0.0,
+                "max_relative_drawdown": 0.0,
+                "max_drawdown_abs": 0.0,
+                "max_drawdown_low": 0.0,
+                "max_drawdown_high": 0.0,
+                "drawdown_start": datetime(1970, 1, 1, tzinfo=timezone.utc),
+                "drawdown_start_ts": 0,
+                "drawdown_end": datetime(1970, 1, 1, tzinfo=timezone.utc),
+                "drawdown_end_ts": 0,
+                "csum_min": 0,
+                "csum_max": 0,
+            }
+        )
 
     return strat_stats
 
 
-def generate_backtest_stats(btdata: Dict[str, DataFrame],
-                            all_results: Dict[str, Dict[str, Union[DataFrame, Dict]]],
-                            min_date: datetime, max_date: datetime
-                            ) -> BacktestResultType:
+def generate_backtest_stats(
+    btdata: Dict[str, DataFrame],
+    all_results: Dict[str, Dict[str, Union[DataFrame, Dict]]],
+    min_date: datetime,
+    max_date: datetime,
+) -> BacktestResultType:
     """
     :param btdata: Backtest data
     :param all_results: backtest result - dictionary in the form:
                      { Strategy: {'results: results, 'config: config}}.
     :param min_date: Backtest start date
     :param max_date: Backtest end date
     :return: Dictionary containing results per strategy and a strategy summary.
     """
     result: BacktestResultType = {
-        'metadata': {},
-        'strategy': {},
-        'strategy_comparison': [],
+        "metadata": {},
+        "strategy": {},
+        "strategy_comparison": [],
     }
-    market_change = calculate_market_change(btdata, 'close')
+    market_change = calculate_market_change(btdata, "close")
     metadata = {}
     pairlist = list(btdata.keys())
     for strategy, content in all_results.items():
-        strat_stats = generate_strategy_stats(pairlist, strategy, content,
-                                              min_date, max_date, market_change=market_change)
+        strat_stats = generate_strategy_stats(
+            pairlist, strategy, content, min_date, max_date, market_change=market_change
+        )
         metadata[strategy] = {
-            'run_id': content['run_id'],
-            'backtest_start_time': content['backtest_start_time'],
-            'timeframe': content['config']['timeframe'],
-            'timeframe_detail': content['config'].get('timeframe_detail', None),
-            'backtest_start_ts': int(min_date.timestamp()),
-            'backtest_end_ts': int(max_date.timestamp()),
+            "run_id": content["run_id"],
+            "backtest_start_time": content["backtest_start_time"],
+            "timeframe": content["config"]["timeframe"],
+            "timeframe_detail": content["config"].get("timeframe_detail", None),
+            "backtest_start_ts": int(min_date.timestamp()),
+            "backtest_end_ts": int(max_date.timestamp()),
         }
-        result['strategy'][strategy] = strat_stats
+        result["strategy"][strategy] = strat_stats
 
-    strategy_results = generate_strategy_comparison(bt_stats=result['strategy'])
+    strategy_results = generate_strategy_comparison(bt_stats=result["strategy"])
 
-    result['metadata'] = metadata
-    result['strategy_comparison'] = strategy_results
+    result["metadata"] = metadata
+    result["strategy_comparison"] = strategy_results
 
     return result
```

### Comparing `freqtrade-2024.4/freqtrade/optimize/space/decimalspace.py` & `freqtrade-2024.5/freqtrade/optimize/space/decimalspace.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,15 +1,23 @@
 import numpy as np
 from skopt.space import Integer
 
 
 class SKDecimal(Integer):
-
-    def __init__(self, low, high, decimals=3, prior="uniform", base=10, transform=None,
-                 name=None, dtype=np.int64):
+    def __init__(
+        self,
+        low,
+        high,
+        decimals=3,
+        prior="uniform",
+        base=10,
+        transform=None,
+        name=None,
+        dtype=np.int64,
+    ):
         self.decimals = decimals
 
         self.pow_dot_one = pow(0.1, self.decimals)
         self.pow_ten = pow(10, self.decimals)
 
         _low = int(low * self.pow_ten)
         _high = int(high * self.pow_ten)
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/custom_data.py` & `freqtrade-2024.5/freqtrade/persistence/custom_data.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,48 +19,54 @@
     CustomData database model
     Keeps records of metadata as key/value store
     for trades or global persistent values
     One to many relationship with Trades:
       - One trade can have many metadata entries
       - One metadata entry can only be associated with one Trade
     """
-    __tablename__ = 'trade_custom_data'
+
+    __tablename__ = "trade_custom_data"
     __allow_unmapped__ = True
     session: ClassVar[SessionType]
 
     # Uniqueness should be ensured over pair, order_id
     # its likely that order_id is unique per Pair on some exchanges.
-    __table_args__ = (UniqueConstraint('ft_trade_id', 'cd_key', name="_trade_id_cd_key"),)
+    __table_args__ = (UniqueConstraint("ft_trade_id", "cd_key", name="_trade_id_cd_key"),)
 
     id = mapped_column(Integer, primary_key=True)
-    ft_trade_id = mapped_column(Integer, ForeignKey('trades.id'), index=True)
+    ft_trade_id = mapped_column(Integer, ForeignKey("trades.id"), index=True)
 
     trade = relationship("Trade", back_populates="custom_data")
 
     cd_key: Mapped[str] = mapped_column(String(255), nullable=False)
     cd_type: Mapped[str] = mapped_column(String(25), nullable=False)
     cd_value: Mapped[str] = mapped_column(Text, nullable=False)
     created_at: Mapped[datetime] = mapped_column(DateTime, nullable=False, default=dt_now)
     updated_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
 
     # Empty container value - not persisted, but filled with cd_value on query
     value: Any = None
 
     def __repr__(self):
-        create_time = (self.created_at.strftime(DATETIME_PRINT_FORMAT)
-                       if self.created_at is not None else None)
-        update_time = (self.updated_at.strftime(DATETIME_PRINT_FORMAT)
-                       if self.updated_at is not None else None)
-        return (f'CustomData(id={self.id}, key={self.cd_key}, type={self.cd_type}, ' +
-                f'value={self.cd_value}, trade_id={self.ft_trade_id}, created={create_time}, ' +
-                f'updated={update_time})')
+        create_time = (
+            self.created_at.strftime(DATETIME_PRINT_FORMAT) if self.created_at is not None else None
+        )
+        update_time = (
+            self.updated_at.strftime(DATETIME_PRINT_FORMAT) if self.updated_at is not None else None
+        )
+        return (
+            f"CustomData(id={self.id}, key={self.cd_key}, type={self.cd_type}, "
+            + f"value={self.cd_value}, trade_id={self.ft_trade_id}, created={create_time}, "
+            + f"updated={update_time})"
+        )
 
     @classmethod
-    def query_cd(cls, key: Optional[str] = None,
-                 trade_id: Optional[int] = None) -> Sequence['_CustomData']:
+    def query_cd(
+        cls, key: Optional[str] = None, trade_id: Optional[int] = None
+    ) -> Sequence["_CustomData"]:
         """
         Get all CustomData, if trade_id is not specified
         return will be for generic values not tied to a trade
         :param trade_id: id of the Trade
         """
         filters = []
         if trade_id is not None:
@@ -76,25 +82,25 @@
     CustomData middleware class
     Abstracts the database layer away so it becomes optional - which will be necessary to support
     backtesting and hyperopt in the future.
     """
 
     use_db = True
     custom_data: List[_CustomData] = []
-    unserialized_types = ['bool', 'float', 'int', 'str']
+    unserialized_types = ["bool", "float", "int", "str"]
 
     @staticmethod
     def _convert_custom_data(data: _CustomData) -> _CustomData:
         if data.cd_type in CustomDataWrapper.unserialized_types:
             data.value = data.cd_value
-            if data.cd_type == 'bool':
-                data.value = data.cd_value.lower() == 'true'
-            elif data.cd_type == 'int':
+            if data.cd_type == "bool":
+                data.value = data.cd_value.lower() == "true"
+            elif data.cd_type == "int":
                 data.value = int(data.cd_value)
-            elif data.cd_type == 'float':
+            elif data.cd_type == "float":
                 data.value = float(data.cd_value)
         else:
             data.value = json.loads(data.cd_value)
         return data
 
     @staticmethod
     def reset_custom_data() -> None:
@@ -107,39 +113,40 @@
     @staticmethod
     def delete_custom_data(trade_id: int) -> None:
         _CustomData.session.query(_CustomData).filter(_CustomData.ft_trade_id == trade_id).delete()
         _CustomData.session.commit()
 
     @staticmethod
     def get_custom_data(*, trade_id: int, key: Optional[str] = None) -> List[_CustomData]:
-
         if CustomDataWrapper.use_db:
             filters = [
                 _CustomData.ft_trade_id == trade_id,
             ]
             if key is not None:
                 filters.append(_CustomData.cd_key.ilike(key))
-            filtered_custom_data = _CustomData.session.scalars(select(_CustomData).filter(
-                *filters)).all()
+            filtered_custom_data = _CustomData.session.scalars(
+                select(_CustomData).filter(*filters)
+            ).all()
 
         else:
             filtered_custom_data = [
-                data_entry for data_entry in CustomDataWrapper.custom_data
+                data_entry
+                for data_entry in CustomDataWrapper.custom_data
                 if (data_entry.ft_trade_id == trade_id)
             ]
             if key is not None:
                 filtered_custom_data = [
-                    data_entry for data_entry in filtered_custom_data
+                    data_entry
+                    for data_entry in filtered_custom_data
                     if (data_entry.cd_key.casefold() == key.casefold())
                 ]
         return [CustomDataWrapper._convert_custom_data(d) for d in filtered_custom_data]
 
     @staticmethod
     def set_custom_data(trade_id: int, key: str, value: Any) -> None:
-
         value_type = type(value).__name__
 
         if value_type not in CustomDataWrapper.unserialized_types:
             try:
                 value_db = json.dumps(value)
             except TypeError as e:
                 logger.warning(f"could not serialize {key} value due to {e}")
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/key_value_store.py` & `freqtrade-2024.5/freqtrade/persistence/key_value_store.py`

 * *Files 9% similar despite different names*

```diff
@@ -8,30 +8,31 @@
 from freqtrade.persistence.base import ModelBase, SessionType
 
 
 ValueTypes = Union[str, datetime, float, int]
 
 
 class ValueTypesEnum(str, Enum):
-    STRING = 'str'
-    DATETIME = 'datetime'
-    FLOAT = 'float'
-    INT = 'int'
+    STRING = "str"
+    DATETIME = "datetime"
+    FLOAT = "float"
+    INT = "int"
 
 
 class KeyStoreKeys(str, Enum):
-    BOT_START_TIME = 'bot_start_time'
-    STARTUP_TIME = 'startup_time'
+    BOT_START_TIME = "bot_start_time"
+    STARTUP_TIME = "startup_time"
 
 
 class _KeyValueStoreModel(ModelBase):
     """
     Pair Locks database model.
     """
-    __tablename__ = 'KeyValueStore'
+
+    __tablename__ = "KeyValueStore"
     session: ClassVar[SessionType]
 
     id: Mapped[int] = mapped_column(primary_key=True)
 
     key: Mapped[KeyStoreKeys] = mapped_column(String(25), nullable=False, index=True)
 
     value_type: Mapped[ValueTypesEnum] = mapped_column(String(20), nullable=False)
@@ -52,16 +53,19 @@
     @staticmethod
     def store_value(key: KeyStoreKeys, value: ValueTypes) -> None:
         """
         Store the given value for the given key.
         :param key: Key to store the value for - can be used in get-value to retrieve the key
         :param value: Value to store - can be str, datetime, float or int
         """
-        kv = _KeyValueStoreModel.session.query(_KeyValueStoreModel).filter(
-            _KeyValueStoreModel.key == key).first()
+        kv = (
+            _KeyValueStoreModel.session.query(_KeyValueStoreModel)
+            .filter(_KeyValueStoreModel.key == key)
+            .first()
+        )
         if kv is None:
             kv = _KeyValueStoreModel(key=key)
         if isinstance(value, str):
             kv.value_type = ValueTypesEnum.STRING
             kv.string_value = value
         elif isinstance(value, datetime):
             kv.value_type = ValueTypesEnum.DATETIME
@@ -69,111 +73,137 @@
         elif isinstance(value, float):
             kv.value_type = ValueTypesEnum.FLOAT
             kv.float_value = value
         elif isinstance(value, int):
             kv.value_type = ValueTypesEnum.INT
             kv.int_value = value
         else:
-            raise ValueError(f'Unknown value type {kv.value_type}')
+            raise ValueError(f"Unknown value type {kv.value_type}")
         _KeyValueStoreModel.session.add(kv)
         _KeyValueStoreModel.session.commit()
 
     @staticmethod
     def delete_value(key: KeyStoreKeys) -> None:
         """
         Delete the value for the given key.
         :param key: Key to delete the value for
         """
-        kv = _KeyValueStoreModel.session.query(_KeyValueStoreModel).filter(
-            _KeyValueStoreModel.key == key).first()
+        kv = (
+            _KeyValueStoreModel.session.query(_KeyValueStoreModel)
+            .filter(_KeyValueStoreModel.key == key)
+            .first()
+        )
         if kv is not None:
             _KeyValueStoreModel.session.delete(kv)
             _KeyValueStoreModel.session.commit()
 
     @staticmethod
     def get_value(key: KeyStoreKeys) -> Optional[ValueTypes]:
         """
         Get the value for the given key.
         :param key: Key to get the value for
         """
-        kv = _KeyValueStoreModel.session.query(_KeyValueStoreModel).filter(
-            _KeyValueStoreModel.key == key).first()
+        kv = (
+            _KeyValueStoreModel.session.query(_KeyValueStoreModel)
+            .filter(_KeyValueStoreModel.key == key)
+            .first()
+        )
         if kv is None:
             return None
         if kv.value_type == ValueTypesEnum.STRING:
             return kv.string_value
         if kv.value_type == ValueTypesEnum.DATETIME and kv.datetime_value is not None:
             return kv.datetime_value.replace(tzinfo=timezone.utc)
         if kv.value_type == ValueTypesEnum.FLOAT:
             return kv.float_value
         if kv.value_type == ValueTypesEnum.INT:
             return kv.int_value
         # This should never happen unless someone messed with the database manually
-        raise ValueError(f'Unknown value type {kv.value_type}')  # pragma: no cover
+        raise ValueError(f"Unknown value type {kv.value_type}")  # pragma: no cover
 
     @staticmethod
     def get_string_value(key: KeyStoreKeys) -> Optional[str]:
         """
         Get the value for the given key.
         :param key: Key to get the value for
         """
-        kv = _KeyValueStoreModel.session.query(_KeyValueStoreModel).filter(
-            _KeyValueStoreModel.key == key,
-            _KeyValueStoreModel.value_type == ValueTypesEnum.STRING).first()
+        kv = (
+            _KeyValueStoreModel.session.query(_KeyValueStoreModel)
+            .filter(
+                _KeyValueStoreModel.key == key,
+                _KeyValueStoreModel.value_type == ValueTypesEnum.STRING,
+            )
+            .first()
+        )
         if kv is None:
             return None
         return kv.string_value
 
     @staticmethod
     def get_datetime_value(key: KeyStoreKeys) -> Optional[datetime]:
         """
         Get the value for the given key.
         :param key: Key to get the value for
         """
-        kv = _KeyValueStoreModel.session.query(_KeyValueStoreModel).filter(
-            _KeyValueStoreModel.key == key,
-            _KeyValueStoreModel.value_type == ValueTypesEnum.DATETIME).first()
+        kv = (
+            _KeyValueStoreModel.session.query(_KeyValueStoreModel)
+            .filter(
+                _KeyValueStoreModel.key == key,
+                _KeyValueStoreModel.value_type == ValueTypesEnum.DATETIME,
+            )
+            .first()
+        )
         if kv is None or kv.datetime_value is None:
             return None
         return kv.datetime_value.replace(tzinfo=timezone.utc)
 
     @staticmethod
     def get_float_value(key: KeyStoreKeys) -> Optional[float]:
         """
         Get the value for the given key.
         :param key: Key to get the value for
         """
-        kv = _KeyValueStoreModel.session.query(_KeyValueStoreModel).filter(
-            _KeyValueStoreModel.key == key,
-            _KeyValueStoreModel.value_type == ValueTypesEnum.FLOAT).first()
+        kv = (
+            _KeyValueStoreModel.session.query(_KeyValueStoreModel)
+            .filter(
+                _KeyValueStoreModel.key == key,
+                _KeyValueStoreModel.value_type == ValueTypesEnum.FLOAT,
+            )
+            .first()
+        )
         if kv is None:
             return None
         return kv.float_value
 
     @staticmethod
     def get_int_value(key: KeyStoreKeys) -> Optional[int]:
         """
         Get the value for the given key.
         :param key: Key to get the value for
         """
-        kv = _KeyValueStoreModel.session.query(_KeyValueStoreModel).filter(
-            _KeyValueStoreModel.key == key,
-            _KeyValueStoreModel.value_type == ValueTypesEnum.INT).first()
+        kv = (
+            _KeyValueStoreModel.session.query(_KeyValueStoreModel)
+            .filter(
+                _KeyValueStoreModel.key == key, _KeyValueStoreModel.value_type == ValueTypesEnum.INT
+            )
+            .first()
+        )
         if kv is None:
             return None
         return kv.int_value
 
 
 def set_startup_time():
     """
     sets bot_start_time to the first trade open date - or "now" on new databases.
     sets startup_time to "now"
     """
-    st = KeyValueStore.get_value('bot_start_time')
+    st = KeyValueStore.get_value("bot_start_time")
     if st is None:
         from freqtrade.persistence import Trade
+
         t = Trade.session.query(Trade).order_by(Trade.open_date.asc()).first()
         if t is not None:
-            KeyValueStore.store_value('bot_start_time', t.open_date_utc)
+            KeyValueStore.store_value("bot_start_time", t.open_date_utc)
         else:
-            KeyValueStore.store_value('bot_start_time', datetime.now(timezone.utc))
-    KeyValueStore.store_value('startup_time', datetime.now(timezone.utc))
+            KeyValueStore.store_value("bot_start_time", datetime.now(timezone.utc))
+    KeyValueStore.store_value("startup_time", datetime.now(timezone.utc))
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/migrations.py` & `freqtrade-2024.5/freqtrade/persistence/migrations.py`

 * *Files 7% similar despite different names*

```diff
@@ -21,124 +21,136 @@
 def get_column_def(columns: List, column: str, default: str) -> str:
     return default if not has_column(columns, column) else column
 
 
 def get_backup_name(tabs: List[str], backup_prefix: str):
     table_back_name = backup_prefix
     for i, table_back_name in enumerate(tabs):
-        table_back_name = f'{backup_prefix}{i}'
-        logger.debug(f'trying {table_back_name}')
+        table_back_name = f"{backup_prefix}{i}"
+        logger.debug(f"trying {table_back_name}")
 
     return table_back_name
 
 
 def get_last_sequence_ids(engine, trade_back_name: str, order_back_name: str):
     order_id: Optional[int] = None
     trade_id: Optional[int] = None
 
-    if engine.name == 'postgresql':
+    if engine.name == "postgresql":
         with engine.begin() as connection:
             trade_id = connection.execute(text("select nextval('trades_id_seq')")).fetchone()[0]
             order_id = connection.execute(text("select nextval('orders_id_seq')")).fetchone()[0]
         with engine.begin() as connection:
-            connection.execute(text(
-                f"ALTER SEQUENCE orders_id_seq rename to {order_back_name}_id_seq_bak"))
-            connection.execute(text(
-                f"ALTER SEQUENCE trades_id_seq rename to {trade_back_name}_id_seq_bak"))
+            connection.execute(
+                text(f"ALTER SEQUENCE orders_id_seq rename to {order_back_name}_id_seq_bak")
+            )
+            connection.execute(
+                text(f"ALTER SEQUENCE trades_id_seq rename to {trade_back_name}_id_seq_bak")
+            )
     return order_id, trade_id
 
 
 def set_sequence_ids(engine, order_id, trade_id, pairlock_id=None):
-
-    if engine.name == 'postgresql':
+    if engine.name == "postgresql":
         with engine.begin() as connection:
             if order_id:
                 connection.execute(text(f"ALTER SEQUENCE orders_id_seq RESTART WITH {order_id}"))
             if trade_id:
                 connection.execute(text(f"ALTER SEQUENCE trades_id_seq RESTART WITH {trade_id}"))
             if pairlock_id:
                 connection.execute(
-                    text(f"ALTER SEQUENCE pairlocks_id_seq RESTART WITH {pairlock_id}"))
+                    text(f"ALTER SEQUENCE pairlocks_id_seq RESTART WITH {pairlock_id}")
+                )
 
 
 def drop_index_on_table(engine, inspector, table_bak_name):
     with engine.begin() as connection:
         # drop indexes on backup table in new session
         for index in inspector.get_indexes(table_bak_name):
-            if engine.name == 'mysql':
+            if engine.name == "mysql":
                 connection.execute(text(f"drop index {index['name']} on {table_bak_name}"))
             else:
                 connection.execute(text(f"drop index {index['name']}"))
 
 
 def migrate_trades_and_orders_table(
-        decl_base, inspector, engine,
-        trade_back_name: str, cols: List,
-        order_back_name: str, cols_order: List):
-    base_currency = get_column_def(cols, 'base_currency', 'null')
-    stake_currency = get_column_def(cols, 'stake_currency', 'null')
-    fee_open = get_column_def(cols, 'fee_open', 'fee')
-    fee_open_cost = get_column_def(cols, 'fee_open_cost', 'null')
-    fee_open_currency = get_column_def(cols, 'fee_open_currency', 'null')
-    fee_close = get_column_def(cols, 'fee_close', 'fee')
-    fee_close_cost = get_column_def(cols, 'fee_close_cost', 'null')
-    fee_close_currency = get_column_def(cols, 'fee_close_currency', 'null')
-    open_rate_requested = get_column_def(cols, 'open_rate_requested', 'null')
-    close_rate_requested = get_column_def(cols, 'close_rate_requested', 'null')
-    stop_loss = get_column_def(cols, 'stop_loss', '0.0')
-    stop_loss_pct = get_column_def(cols, 'stop_loss_pct', 'null')
-    initial_stop_loss = get_column_def(cols, 'initial_stop_loss', '0.0')
-    initial_stop_loss_pct = get_column_def(cols, 'initial_stop_loss_pct', 'null')
+    decl_base,
+    inspector,
+    engine,
+    trade_back_name: str,
+    cols: List,
+    order_back_name: str,
+    cols_order: List,
+):
+    base_currency = get_column_def(cols, "base_currency", "null")
+    stake_currency = get_column_def(cols, "stake_currency", "null")
+    fee_open = get_column_def(cols, "fee_open", "fee")
+    fee_open_cost = get_column_def(cols, "fee_open_cost", "null")
+    fee_open_currency = get_column_def(cols, "fee_open_currency", "null")
+    fee_close = get_column_def(cols, "fee_close", "fee")
+    fee_close_cost = get_column_def(cols, "fee_close_cost", "null")
+    fee_close_currency = get_column_def(cols, "fee_close_currency", "null")
+    open_rate_requested = get_column_def(cols, "open_rate_requested", "null")
+    close_rate_requested = get_column_def(cols, "close_rate_requested", "null")
+    stop_loss = get_column_def(cols, "stop_loss", "0.0")
+    stop_loss_pct = get_column_def(cols, "stop_loss_pct", "null")
+    initial_stop_loss = get_column_def(cols, "initial_stop_loss", "0.0")
+    initial_stop_loss_pct = get_column_def(cols, "initial_stop_loss_pct", "null")
     is_stop_loss_trailing = get_column_def(
-        cols, 'is_stop_loss_trailing',
-        f'coalesce({stop_loss_pct}, 0.0) <> coalesce({initial_stop_loss_pct}, 0.0)')
-    max_rate = get_column_def(cols, 'max_rate', '0.0')
-    min_rate = get_column_def(cols, 'min_rate', 'null')
-    exit_reason = get_column_def(cols, 'sell_reason', get_column_def(cols, 'exit_reason', 'null'))
-    strategy = get_column_def(cols, 'strategy', 'null')
-    enter_tag = get_column_def(cols, 'buy_tag', get_column_def(cols, 'enter_tag', 'null'))
-    realized_profit = get_column_def(cols, 'realized_profit', '0.0')
+        cols,
+        "is_stop_loss_trailing",
+        f"coalesce({stop_loss_pct}, 0.0) <> coalesce({initial_stop_loss_pct}, 0.0)",
+    )
+    max_rate = get_column_def(cols, "max_rate", "0.0")
+    min_rate = get_column_def(cols, "min_rate", "null")
+    exit_reason = get_column_def(cols, "sell_reason", get_column_def(cols, "exit_reason", "null"))
+    strategy = get_column_def(cols, "strategy", "null")
+    enter_tag = get_column_def(cols, "buy_tag", get_column_def(cols, "enter_tag", "null"))
+    realized_profit = get_column_def(cols, "realized_profit", "0.0")
 
-    trading_mode = get_column_def(cols, 'trading_mode', 'null')
+    trading_mode = get_column_def(cols, "trading_mode", "null")
 
     # Leverage Properties
-    leverage = get_column_def(cols, 'leverage', '1.0')
-    liquidation_price = get_column_def(cols, 'liquidation_price',
-                                       get_column_def(cols, 'isolated_liq', 'null'))
+    leverage = get_column_def(cols, "leverage", "1.0")
+    liquidation_price = get_column_def(
+        cols, "liquidation_price", get_column_def(cols, "isolated_liq", "null")
+    )
     # sqlite does not support literals for booleans
-    if engine.name == 'postgresql':
-        is_short = get_column_def(cols, 'is_short', 'false')
+    if engine.name == "postgresql":
+        is_short = get_column_def(cols, "is_short", "false")
     else:
-        is_short = get_column_def(cols, 'is_short', '0')
+        is_short = get_column_def(cols, "is_short", "0")
 
     # Futures Properties
-    interest_rate = get_column_def(cols, 'interest_rate', '0.0')
-    funding_fees = get_column_def(cols, 'funding_fees', '0.0')
-    funding_fee_running = get_column_def(cols, 'funding_fee_running', 'null')
-    max_stake_amount = get_column_def(cols, 'max_stake_amount', 'stake_amount')
+    interest_rate = get_column_def(cols, "interest_rate", "0.0")
+    funding_fees = get_column_def(cols, "funding_fees", "0.0")
+    funding_fee_running = get_column_def(cols, "funding_fee_running", "null")
+    max_stake_amount = get_column_def(cols, "max_stake_amount", "stake_amount")
 
     # If ticker-interval existed use that, else null.
-    if has_column(cols, 'ticker_interval'):
-        timeframe = get_column_def(cols, 'timeframe', 'ticker_interval')
+    if has_column(cols, "ticker_interval"):
+        timeframe = get_column_def(cols, "timeframe", "ticker_interval")
     else:
-        timeframe = get_column_def(cols, 'timeframe', 'null')
+        timeframe = get_column_def(cols, "timeframe", "null")
 
-    open_trade_value = get_column_def(cols, 'open_trade_value',
-                                      f'amount * open_rate * (1 + {fee_open})')
+    open_trade_value = get_column_def(
+        cols, "open_trade_value", f"amount * open_rate * (1 + {fee_open})"
+    )
     close_profit_abs = get_column_def(
-        cols, 'close_profit_abs',
-        f"(amount * close_rate * (1 - {fee_close})) - {open_trade_value}")
-    exit_order_status = get_column_def(cols, 'exit_order_status',
-                                       get_column_def(cols, 'sell_order_status', 'null'))
-    amount_requested = get_column_def(cols, 'amount_requested', 'amount')
-
-    amount_precision = get_column_def(cols, 'amount_precision', 'null')
-    price_precision = get_column_def(cols, 'price_precision', 'null')
-    precision_mode = get_column_def(cols, 'precision_mode', 'null')
-    contract_size = get_column_def(cols, 'contract_size', 'null')
+        cols, "close_profit_abs", f"(amount * close_rate * (1 - {fee_close})) - {open_trade_value}"
+    )
+    exit_order_status = get_column_def(
+        cols, "exit_order_status", get_column_def(cols, "sell_order_status", "null")
+    )
+    amount_requested = get_column_def(cols, "amount_requested", "amount")
+
+    amount_precision = get_column_def(cols, "amount_precision", "null")
+    price_precision = get_column_def(cols, "price_precision", "null")
+    precision_mode = get_column_def(cols, "precision_mode", "null")
+    contract_size = get_column_def(cols, "contract_size", "null")
 
     # Schema migration necessary
     with engine.begin() as connection:
         connection.execute(text(f"alter table trades rename to {trade_back_name}"))
 
     drop_index_on_table(engine, inspector, trade_back_name)
 
@@ -147,15 +159,17 @@
     drop_orders_table(engine, order_back_name)
 
     # let SQLAlchemy create the schema as required
     decl_base.metadata.create_all(engine)
 
     # Copy data back - following the correct schema
     with engine.begin() as connection:
-        connection.execute(text(f"""insert into trades
+        connection.execute(
+            text(
+                f"""insert into trades
             (id, exchange, pair, base_currency, stake_currency, is_open,
             fee_open, fee_open_cost, fee_open_currency,
             fee_close, fee_close_cost, fee_close_currency, open_rate,
             open_rate_requested, close_rate, close_rate_requested, close_profit,
             stake_amount, amount, amount_requested, open_date, close_date,
             stop_loss, stop_loss_pct, initial_stop_loss, initial_stop_loss_pct,
             is_stop_loss_trailing,
@@ -192,15 +206,17 @@
             {is_short} is_short, {interest_rate} interest_rate,
             {funding_fees} funding_fees, {funding_fee_running} funding_fee_running,
             {realized_profit} realized_profit,
             {amount_precision} amount_precision, {price_precision} price_precision,
             {precision_mode} precision_mode, {contract_size} contract_size,
             {max_stake_amount} max_stake_amount
             from {trade_back_name}
-            """))
+            """
+            )
+        )
 
     migrate_orders_table(engine, order_back_name, cols_order)
     set_sequence_ids(engine, order_id, trade_id)
 
 
 def drop_orders_table(engine, table_back_name: str):
     # Drop and recreate orders table as backup
@@ -208,150 +224,163 @@
 
     with engine.begin() as connection:
         connection.execute(text(f"create table {table_back_name} as select * from orders"))
         connection.execute(text("drop table orders"))
 
 
 def migrate_orders_table(engine, table_back_name: str, cols_order: List):
-
-    ft_fee_base = get_column_def(cols_order, 'ft_fee_base', 'null')
-    average = get_column_def(cols_order, 'average', 'null')
-    stop_price = get_column_def(cols_order, 'stop_price', 'null')
-    funding_fee = get_column_def(cols_order, 'funding_fee', '0.0')
-    ft_amount = get_column_def(cols_order, 'ft_amount', 'coalesce(amount, 0.0)')
-    ft_price = get_column_def(cols_order, 'ft_price', 'coalesce(price, 0.0)')
-    ft_cancel_reason = get_column_def(cols_order, 'ft_cancel_reason', 'null')
-    ft_order_tag = get_column_def(cols_order, 'ft_order_tag', 'null')
+    ft_fee_base = get_column_def(cols_order, "ft_fee_base", "null")
+    average = get_column_def(cols_order, "average", "null")
+    stop_price = get_column_def(cols_order, "stop_price", "null")
+    funding_fee = get_column_def(cols_order, "funding_fee", "0.0")
+    ft_amount = get_column_def(cols_order, "ft_amount", "coalesce(amount, 0.0)")
+    ft_price = get_column_def(cols_order, "ft_price", "coalesce(price, 0.0)")
+    ft_cancel_reason = get_column_def(cols_order, "ft_cancel_reason", "null")
+    ft_order_tag = get_column_def(cols_order, "ft_order_tag", "null")
 
     # sqlite does not support literals for booleans
     with engine.begin() as connection:
-        connection.execute(text(f"""
+        connection.execute(
+            text(
+                f"""
             insert into orders (id, ft_trade_id, ft_order_side, ft_pair, ft_is_open, order_id,
             status, symbol, order_type, side, price, amount, filled, average, remaining, cost,
             stop_price, order_date, order_filled_date, order_update_date, ft_fee_base, funding_fee,
             ft_amount, ft_price, ft_cancel_reason, ft_order_tag
             )
             select id, ft_trade_id, ft_order_side, ft_pair, ft_is_open, order_id,
             status, symbol, order_type, side, price, amount, filled, {average} average, remaining,
             cost, {stop_price} stop_price, order_date, order_filled_date,
             order_update_date, {ft_fee_base} ft_fee_base, {funding_fee} funding_fee,
             {ft_amount} ft_amount, {ft_price} ft_price, {ft_cancel_reason} ft_cancel_reason,
             {ft_order_tag} ft_order_tag
             from {table_back_name}
-            """))
-
+            """
+            )
+        )
 
-def migrate_pairlocks_table(
-        decl_base, inspector, engine,
-        pairlock_back_name: str, cols: List):
 
+def migrate_pairlocks_table(decl_base, inspector, engine, pairlock_back_name: str, cols: List):
     # Schema migration necessary
     with engine.begin() as connection:
         connection.execute(text(f"alter table pairlocks rename to {pairlock_back_name}"))
 
     drop_index_on_table(engine, inspector, pairlock_back_name)
 
-    side = get_column_def(cols, 'side', "'*'")
+    side = get_column_def(cols, "side", "'*'")
 
     # let SQLAlchemy create the schema as required
     decl_base.metadata.create_all(engine)
     # Copy data back - following the correct schema
     with engine.begin() as connection:
-        connection.execute(text(f"""insert into pairlocks
+        connection.execute(
+            text(
+                f"""insert into pairlocks
         (id, pair, side, reason, lock_time,
          lock_end_time, active)
         select id, pair, {side} side, reason, lock_time,
          lock_end_time, active
         from {pairlock_back_name}
-        """))
+        """
+            )
+        )
 
 
 def set_sqlite_to_wal(engine):
-    if engine.name == 'sqlite' and str(engine.url) != 'sqlite://':
+    if engine.name == "sqlite" and str(engine.url) != "sqlite://":
         # Set Mode to
         with engine.begin() as connection:
             connection.execute(text("PRAGMA journal_mode=wal"))
 
 
 def fix_old_dry_orders(engine):
     with engine.begin() as connection:
-
         # Update current dry-run Orders where
         # - stoploss order is Open (will be replaced eventually)
         # 2nd query:
         # - current Order is open
         # - current Trade is closed
         # - current Order trade_id not equal to current Trade.id
         # - current Order not stoploss
 
-        stmt = update(Order).where(
-            Order.ft_is_open.is_(True),
-            Order.ft_order_side == 'stoploss',
-            Order.order_id.like('dry%'),
-
-        ).values(ft_is_open=False)
+        stmt = (
+            update(Order)
+            .where(
+                Order.ft_is_open.is_(True),
+                Order.ft_order_side == "stoploss",
+                Order.order_id.like("dry%"),
+            )
+            .values(ft_is_open=False)
+        )
         connection.execute(stmt)
 
         # Close dry-run orders for closed trades.
-        stmt = update(Order).where(
-            Order.ft_is_open.is_(True),
-            Order.ft_trade_id.not_in(
-                select(
-                    Trade.id
-                ).where(Trade.is_open.is_(True))
-                  ),
-            Order.ft_order_side != 'stoploss',
-            Order.order_id.like('dry%')
-
-        ).values(ft_is_open=False)
+        stmt = (
+            update(Order)
+            .where(
+                Order.ft_is_open.is_(True),
+                Order.ft_trade_id.not_in(select(Trade.id).where(Trade.is_open.is_(True))),
+                Order.ft_order_side != "stoploss",
+                Order.order_id.like("dry%"),
+            )
+            .values(ft_is_open=False)
+        )
         connection.execute(stmt)
 
 
 def check_migrate(engine, decl_base, previous_tables) -> None:
     """
     Checks if migration is necessary and migrates if necessary
     """
     inspector = inspect(engine)
 
-    cols_trades = inspector.get_columns('trades')
-    cols_orders = inspector.get_columns('orders')
-    cols_pairlocks = inspector.get_columns('pairlocks')
-    tabs = get_table_names_for_table(inspector, 'trades')
-    table_back_name = get_backup_name(tabs, 'trades_bak')
-    order_tabs = get_table_names_for_table(inspector, 'orders')
-    order_table_bak_name = get_backup_name(order_tabs, 'orders_bak')
-    pairlock_tabs = get_table_names_for_table(inspector, 'pairlocks')
-    pairlock_table_bak_name = get_backup_name(pairlock_tabs, 'pairlocks_bak')
+    cols_trades = inspector.get_columns("trades")
+    cols_orders = inspector.get_columns("orders")
+    cols_pairlocks = inspector.get_columns("pairlocks")
+    tabs = get_table_names_for_table(inspector, "trades")
+    table_back_name = get_backup_name(tabs, "trades_bak")
+    order_tabs = get_table_names_for_table(inspector, "orders")
+    order_table_bak_name = get_backup_name(order_tabs, "orders_bak")
+    pairlock_tabs = get_table_names_for_table(inspector, "pairlocks")
+    pairlock_table_bak_name = get_backup_name(pairlock_tabs, "pairlocks_bak")
 
     # Check if migration necessary
     # Migrates both trades and orders table!
     # if ('orders' not in previous_tables
     # or not has_column(cols_orders, 'funding_fee')):
     migrating = False
     # if not has_column(cols_trades, 'funding_fee_running'):
-    if not has_column(cols_orders, 'ft_order_tag'):
+    if not has_column(cols_orders, "ft_order_tag"):
         migrating = True
-        logger.info(f"Running database migration for trades - "
-                    f"backup: {table_back_name}, {order_table_bak_name}")
+        logger.info(
+            f"Running database migration for trades - "
+            f"backup: {table_back_name}, {order_table_bak_name}"
+        )
         migrate_trades_and_orders_table(
-            decl_base, inspector, engine, table_back_name, cols_trades,
-            order_table_bak_name, cols_orders)
+            decl_base,
+            inspector,
+            engine,
+            table_back_name,
+            cols_trades,
+            order_table_bak_name,
+            cols_orders,
+        )
 
-    if not has_column(cols_pairlocks, 'side'):
+    if not has_column(cols_pairlocks, "side"):
         migrating = True
-        logger.info(f"Running database migration for pairlocks - "
-                    f"backup: {pairlock_table_bak_name}")
+        logger.info(f"Running database migration for pairlocks - backup: {pairlock_table_bak_name}")
 
         migrate_pairlocks_table(
             decl_base, inspector, engine, pairlock_table_bak_name, cols_pairlocks
         )
-    if 'orders' not in previous_tables and 'trades' in previous_tables:
+    if "orders" not in previous_tables and "trades" in previous_tables:
         raise OperationalException(
             "Your database seems to be very old. "
             "Please update to freqtrade 2022.3 to migrate this database or "
-            "start with a fresh database.")
+            "start with a fresh database."
+        )
 
     set_sqlite_to_wal(engine)
     fix_old_dry_orders(engine)
 
     if migrating:
         logger.info("Database migration finished.")
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/models.py` & `freqtrade-2024.5/freqtrade/persistence/models.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 This module contains the class to persist trades into SQLite
 """
+
 import logging
 import threading
 from contextvars import ContextVar
 from typing import Any, Dict, Final, Optional
 
 from sqlalchemy import create_engine, inspect
 from sqlalchemy.exc import NoSuchModuleError
@@ -19,15 +20,15 @@
 from freqtrade.persistence.pairlock import PairLock
 from freqtrade.persistence.trade_model import Order, Trade
 
 
 logger = logging.getLogger(__name__)
 
 
-REQUEST_ID_CTX_KEY: Final[str] = 'request_id'
+REQUEST_ID_CTX_KEY: Final[str] = "request_id"
 _request_id_ctx_var: ContextVar[Optional[str]] = ContextVar(REQUEST_ID_CTX_KEY, default=None)
 
 
 def get_request_or_thread_id() -> Optional[str]:
     """
     Helper method to get either async context (for fastapi requests), or thread id
     """
@@ -35,53 +36,62 @@
     if id is None:
         # when not in request context - use thread id
         id = str(threading.current_thread().ident)
 
     return id
 
 
-_SQL_DOCS_URL = 'http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls'
+_SQL_DOCS_URL = "http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls"
 
 
 def init_db(db_url: str) -> None:
     """
     Initializes this module with the given config,
     registers all known command handlers
     and starts polling for message updates
     :param db_url: Database to use
     :return: None
     """
     kwargs: Dict[str, Any] = {}
 
-    if db_url == 'sqlite:///':
+    if db_url == "sqlite:///":
         raise OperationalException(
-            f'Bad db-url {db_url}. For in-memory database, please use `sqlite://`.')
-    if db_url == 'sqlite://':
-        kwargs.update({
-            'poolclass': StaticPool,
-        })
+            f"Bad db-url {db_url}. For in-memory database, please use `sqlite://`."
+        )
+    if db_url == "sqlite://":
+        kwargs.update(
+            {
+                "poolclass": StaticPool,
+            }
+        )
     # Take care of thread ownership
-    if db_url.startswith('sqlite://'):
-        kwargs.update({
-            'connect_args': {'check_same_thread': False},
-        })
+    if db_url.startswith("sqlite://"):
+        kwargs.update(
+            {
+                "connect_args": {"check_same_thread": False},
+            }
+        )
 
     try:
         engine = create_engine(db_url, future=True, **kwargs)
     except NoSuchModuleError:
-        raise OperationalException(f"Given value for db_url: '{db_url}' "
-                                   f"is no valid database URL! (See {_SQL_DOCS_URL})")
+        raise OperationalException(
+            f"Given value for db_url: '{db_url}' "
+            f"is no valid database URL! (See {_SQL_DOCS_URL})"
+        )
 
     # https://docs.sqlalchemy.org/en/13/orm/contextual.html#thread-local-scope
     # Scoped sessions proxy requests to the appropriate thread-local session.
     # Since we also use fastAPI, we need to make it aware of the request id, too
-    Trade.session = scoped_session(sessionmaker(
-        bind=engine, autoflush=False), scopefunc=get_request_or_thread_id)
+    Trade.session = scoped_session(
+        sessionmaker(bind=engine, autoflush=False), scopefunc=get_request_or_thread_id
+    )
     Order.session = Trade.session
     PairLock.session = Trade.session
     _KeyValueStoreModel.session = Trade.session
-    _CustomData.session = scoped_session(sessionmaker(bind=engine, autoflush=True),
-                                         scopefunc=get_request_or_thread_id)
+    _CustomData.session = scoped_session(
+        sessionmaker(bind=engine, autoflush=True), scopefunc=get_request_or_thread_id
+    )
 
     previous_tables = inspect(engine).get_table_names()
     ModelBase.metadata.create_all(engine)
     check_migrate(engine, decl_base=ModelBase, previous_tables=previous_tables)
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/pairlock.py` & `freqtrade-2024.5/freqtrade/persistence/pairlock.py`

 * *Files 10% similar despite different names*

```diff
@@ -8,15 +8,16 @@
 from freqtrade.persistence.base import ModelBase, SessionType
 
 
 class PairLock(ModelBase):
     """
     Pair Locks database model.
     """
-    __tablename__ = 'pairlocks'
+
+    __tablename__ = "pairlocks"
     session: ClassVar[SessionType]
 
     id: Mapped[int] = mapped_column(primary_key=True)
 
     pair: Mapped[str] = mapped_column(String(25), nullable=False, index=True)
     # lock direction - long, short or * (for both)
     side: Mapped[str] = mapped_column(String(25), nullable=False, default="*")
@@ -28,47 +29,52 @@
 
     active: Mapped[bool] = mapped_column(nullable=False, default=True, index=True)
 
     def __repr__(self) -> str:
         lock_time = self.lock_time.strftime(DATETIME_PRINT_FORMAT)
         lock_end_time = self.lock_end_time.strftime(DATETIME_PRINT_FORMAT)
         return (
-            f'PairLock(id={self.id}, pair={self.pair}, side={self.side}, lock_time={lock_time}, '
-            f'lock_end_time={lock_end_time}, reason={self.reason}, active={self.active})')
+            f"PairLock(id={self.id}, pair={self.pair}, side={self.side}, lock_time={lock_time}, "
+            f"lock_end_time={lock_end_time}, reason={self.reason}, active={self.active})"
+        )
 
     @staticmethod
     def query_pair_locks(
-            pair: Optional[str], now: datetime, side: str = '*') -> ScalarResult['PairLock']:
+        pair: Optional[str], now: datetime, side: str = "*"
+    ) -> ScalarResult["PairLock"]:
         """
         Get all currently active locks for this pair
         :param pair: Pair to check for. Returns all current locks if pair is empty
         :param now: Datetime object (generated via datetime.now(timezone.utc)).
         """
-        filters = [PairLock.lock_end_time > now,
-                   # Only active locks
-                   PairLock.active.is_(True), ]
+        filters = [
+            PairLock.lock_end_time > now,
+            # Only active locks
+            PairLock.active.is_(True),
+        ]
         if pair:
             filters.append(PairLock.pair == pair)
-        if side != '*':
-            filters.append(or_(PairLock.side == side, PairLock.side == '*'))
+        if side != "*":
+            filters.append(or_(PairLock.side == side, PairLock.side == "*"))
         else:
-            filters.append(PairLock.side == '*')
+            filters.append(PairLock.side == "*")
 
         return PairLock.session.scalars(select(PairLock).filter(*filters))
 
     @staticmethod
-    def get_all_locks() -> ScalarResult['PairLock']:
+    def get_all_locks() -> ScalarResult["PairLock"]:
         return PairLock.session.scalars(select(PairLock))
 
     def to_json(self) -> Dict[str, Any]:
         return {
-            'id': self.id,
-            'pair': self.pair,
-            'lock_time': self.lock_time.strftime(DATETIME_PRINT_FORMAT),
-            'lock_timestamp': int(self.lock_time.replace(tzinfo=timezone.utc).timestamp() * 1000),
-            'lock_end_time': self.lock_end_time.strftime(DATETIME_PRINT_FORMAT),
-            'lock_end_timestamp': int(self.lock_end_time.replace(tzinfo=timezone.utc
-                                                                 ).timestamp() * 1000),
-            'reason': self.reason,
-            'side': self.side,
-            'active': self.active,
+            "id": self.id,
+            "pair": self.pair,
+            "lock_time": self.lock_time.strftime(DATETIME_PRINT_FORMAT),
+            "lock_timestamp": int(self.lock_time.replace(tzinfo=timezone.utc).timestamp() * 1000),
+            "lock_end_time": self.lock_end_time.strftime(DATETIME_PRINT_FORMAT),
+            "lock_end_timestamp": int(
+                self.lock_end_time.replace(tzinfo=timezone.utc).timestamp() * 1000
+            ),
+            "reason": self.reason,
+            "side": self.side,
+            "active": self.active,
         }
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/pairlock_middleware.py` & `freqtrade-2024.5/freqtrade/persistence/pairlock_middleware.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,27 +17,33 @@
     Abstracts the database layer away so it becomes optional - which will be necessary to support
     backtesting and hyperopt in the future.
     """
 
     use_db = True
     locks: List[PairLock] = []
 
-    timeframe: str = ''
+    timeframe: str = ""
 
     @staticmethod
     def reset_locks() -> None:
         """
         Resets all locks. Only active for backtesting mode.
         """
         if not PairLocks.use_db:
             PairLocks.locks = []
 
     @staticmethod
-    def lock_pair(pair: str, until: datetime, reason: Optional[str] = None, *,
-                  now: Optional[datetime] = None, side: str = '*') -> PairLock:
+    def lock_pair(
+        pair: str,
+        until: datetime,
+        reason: Optional[str] = None,
+        *,
+        now: Optional[datetime] = None,
+        side: str = "*",
+    ) -> PairLock:
         """
         Create PairLock from now to "until".
         Uses database by default, unless PairLocks.use_db is set to False,
         in which case a list is maintained.
         :param pair: pair to lock. use '*' to lock all pairs
         :param until: End time of the lock. Will be rounded up to the next candle.
         :param reason: Reason string that will be shown as reason for the lock
@@ -46,58 +52,64 @@
         """
         lock = PairLock(
             pair=pair,
             lock_time=now or datetime.now(timezone.utc),
             lock_end_time=timeframe_to_next_date(PairLocks.timeframe, until),
             reason=reason,
             side=side,
-            active=True
+            active=True,
         )
         if PairLocks.use_db:
             PairLock.session.add(lock)
             PairLock.session.commit()
         else:
             PairLocks.locks.append(lock)
         return lock
 
     @staticmethod
-    def get_pair_locks(pair: Optional[str], now: Optional[datetime] = None,
-                       side: str = '*') -> Sequence[PairLock]:
+    def get_pair_locks(
+        pair: Optional[str], now: Optional[datetime] = None, side: str = "*"
+    ) -> Sequence[PairLock]:
         """
         Get all currently active locks for this pair
         :param pair: Pair to check for. Returns all current locks if pair is empty
         :param now: Datetime object (generated via datetime.now(timezone.utc)).
                     defaults to datetime.now(timezone.utc)
         """
         if not now:
             now = datetime.now(timezone.utc)
 
         if PairLocks.use_db:
             return PairLock.query_pair_locks(pair, now, side).all()
         else:
-            locks = [lock for lock in PairLocks.locks if (
-                lock.lock_end_time >= now
-                and lock.active is True
-                and (pair is None or lock.pair == pair)
-                and (lock.side == '*' or lock.side == side)
-            )]
+            locks = [
+                lock
+                for lock in PairLocks.locks
+                if (
+                    lock.lock_end_time >= now
+                    and lock.active is True
+                    and (pair is None or lock.pair == pair)
+                    and (lock.side == "*" or lock.side == side)
+                )
+            ]
             return locks
 
     @staticmethod
     def get_pair_longest_lock(
-            pair: str, now: Optional[datetime] = None, side: str = '*') -> Optional[PairLock]:
+        pair: str, now: Optional[datetime] = None, side: str = "*"
+    ) -> Optional[PairLock]:
         """
         Get the lock that expires the latest for the pair given.
         """
         locks = PairLocks.get_pair_locks(pair, now, side=side)
         locks = sorted(locks, key=lambda lock: lock.lock_end_time, reverse=True)
         return locks[0] if locks else None
 
     @staticmethod
-    def unlock_pair(pair: str, now: Optional[datetime] = None, side: str = '*') -> None:
+    def unlock_pair(pair: str, now: Optional[datetime] = None, side: str = "*") -> None:
         """
         Release all locks for this pair.
         :param pair: Pair to unlock
         :param now: Datetime object (generated via datetime.now(timezone.utc)).
             defaults to datetime.now(timezone.utc)
         """
         if not now:
@@ -120,54 +132,54 @@
         """
         if not now:
             now = datetime.now(timezone.utc)
 
         if PairLocks.use_db:
             # used in live modes
             logger.info(f"Releasing all locks with reason '{reason}':")
-            filters = [PairLock.lock_end_time > now,
-                       PairLock.active.is_(True),
-                       PairLock.reason == reason
-                       ]
+            filters = [
+                PairLock.lock_end_time > now,
+                PairLock.active.is_(True),
+                PairLock.reason == reason,
+            ]
             locks = PairLock.session.scalars(select(PairLock).filter(*filters)).all()
             for lock in locks:
                 logger.info(f"Releasing lock for {lock.pair} with reason '{reason}'.")
                 lock.active = False
             PairLock.session.commit()
         else:
             # used in backtesting mode; don't show log messages for speed
             locksb = PairLocks.get_pair_locks(None)
             for lock in locksb:
                 if lock.reason == reason:
                     lock.active = False
 
     @staticmethod
-    def is_global_lock(now: Optional[datetime] = None, side: str = '*') -> bool:
+    def is_global_lock(now: Optional[datetime] = None, side: str = "*") -> bool:
         """
         :param now: Datetime object (generated via datetime.now(timezone.utc)).
             defaults to datetime.now(timezone.utc)
         """
         if not now:
             now = datetime.now(timezone.utc)
 
-        return len(PairLocks.get_pair_locks('*', now, side)) > 0
+        return len(PairLocks.get_pair_locks("*", now, side)) > 0
 
     @staticmethod
-    def is_pair_locked(pair: str, now: Optional[datetime] = None, side: str = '*') -> bool:
+    def is_pair_locked(pair: str, now: Optional[datetime] = None, side: str = "*") -> bool:
         """
         :param pair: Pair to check for
         :param now: Datetime object (generated via datetime.now(timezone.utc)).
             defaults to datetime.now(timezone.utc)
         """
         if not now:
             now = datetime.now(timezone.utc)
 
-        return (
-            len(PairLocks.get_pair_locks(pair, now, side)) > 0
-            or PairLocks.is_global_lock(now, side)
+        return len(PairLocks.get_pair_locks(pair, now, side)) > 0 or PairLocks.is_global_lock(
+            now, side
         )
 
     @staticmethod
     def get_all_locks() -> Sequence[PairLock]:
         """
         Return all locks, also locks with expired end date
         """
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/trade_model.py` & `freqtrade-2024.5/freqtrade/persistence/trade_model.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,29 +1,51 @@
 """
 This module contains the class to persist trades into SQLite
 """
+
 import logging
 from collections import defaultdict
 from dataclasses import dataclass
 from datetime import datetime, timedelta, timezone
 from math import isclose
 from typing import Any, ClassVar, Dict, List, Optional, Sequence, cast
 
-from sqlalchemy import (Enum, Float, ForeignKey, Integer, ScalarResult, Select, String,
-                        UniqueConstraint, desc, func, select)
+from sqlalchemy import (
+    Enum,
+    Float,
+    ForeignKey,
+    Integer,
+    ScalarResult,
+    Select,
+    String,
+    UniqueConstraint,
+    desc,
+    func,
+    select,
+)
 from sqlalchemy.orm import Mapped, lazyload, mapped_column, relationship, validates
 from typing_extensions import Self
 
-from freqtrade.constants import (CANCELED_EXCHANGE_STATES, CUSTOM_TAG_MAX_LENGTH,
-                                 DATETIME_PRINT_FORMAT, MATH_CLOSE_PREC, NON_OPEN_EXCHANGE_STATES,
-                                 BuySell, LongShort)
+from freqtrade.constants import (
+    CANCELED_EXCHANGE_STATES,
+    CUSTOM_TAG_MAX_LENGTH,
+    DATETIME_PRINT_FORMAT,
+    MATH_CLOSE_PREC,
+    NON_OPEN_EXCHANGE_STATES,
+    BuySell,
+    LongShort,
+)
 from freqtrade.enums import ExitType, TradingMode
 from freqtrade.exceptions import DependencyException, OperationalException
-from freqtrade.exchange import (ROUND_DOWN, ROUND_UP, amount_to_contract_precision,
-                                price_to_precision)
+from freqtrade.exchange import (
+    ROUND_DOWN,
+    ROUND_UP,
+    amount_to_contract_precision,
+    price_to_precision,
+)
 from freqtrade.leverage import interest
 from freqtrade.misc import safe_value_fallback
 from freqtrade.persistence.base import ModelBase, SessionType
 from freqtrade.persistence.custom_data import CustomDataWrapper, _CustomData
 from freqtrade.util import FtPrecise, dt_from_ts, dt_now, dt_ts, dt_ts_none
 
 
@@ -45,24 +67,25 @@
 
     One to many relationship with Trades:
       - One trade can have many orders
       - One Order can only be associated with one Trade
 
     Mirrors CCXT Order structure
     """
-    __tablename__ = 'orders'
+
+    __tablename__ = "orders"
     __allow_unmapped__ = True
     session: ClassVar[SessionType]
 
     # Uniqueness should be ensured over pair, order_id
     # its likely that order_id is unique per Pair on some exchanges.
-    __table_args__ = (UniqueConstraint('ft_pair', 'order_id', name="_order_pair_order_id"),)
+    __table_args__ = (UniqueConstraint("ft_pair", "order_id", name="_order_pair_order_id"),)
 
     id: Mapped[int] = mapped_column(Integer, primary_key=True)
-    ft_trade_id: Mapped[int] = mapped_column(Integer, ForeignKey('trades.id'), index=True)
+    ft_trade_id: Mapped[int] = mapped_column(Integer, ForeignKey("trades.id"), index=True)
 
     _trade_live: Mapped["Trade"] = relationship("Trade", back_populates="orders", lazy="immediate")
     _trade_bt: "LocalTrade" = None  # type: ignore
 
     # order_side can only be 'buy', 'sell' or 'stoploss'
     ft_order_side: Mapped[str] = mapped_column(String(25), nullable=False)
     ft_pair: Mapped[str] = mapped_column(String(25), nullable=False)
@@ -85,25 +108,26 @@
     stop_price: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)
     order_date: Mapped[datetime] = mapped_column(nullable=True, default=dt_now)
     order_filled_date: Mapped[Optional[datetime]] = mapped_column(nullable=True)
     order_update_date: Mapped[Optional[datetime]] = mapped_column(nullable=True)
     funding_fee: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)
 
     ft_fee_base: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)
-    ft_order_tag: Mapped[Optional[str]] = mapped_column(String(CUSTOM_TAG_MAX_LENGTH),
-                                                        nullable=True)
+    ft_order_tag: Mapped[Optional[str]] = mapped_column(
+        String(CUSTOM_TAG_MAX_LENGTH), nullable=True
+    )
 
     @property
     def order_date_utc(self) -> datetime:
-        """ Order-date with UTC timezoneinfo"""
+        """Order-date with UTC timezoneinfo"""
         return self.order_date.replace(tzinfo=timezone.utc)
 
     @property
     def order_filled_utc(self) -> Optional[datetime]:
-        """ last order-date with UTC timezoneinfo"""
+        """last order-date with UTC timezoneinfo"""
         return (
             self.order_filled_date.replace(tzinfo=timezone.utc) if self.order_filled_date else None
         )
 
     @property
     def safe_amount(self) -> float:
         return self.amount or self.ft_amount
@@ -124,16 +148,17 @@
     @property
     def safe_cost(self) -> float:
         return self.cost or 0.0
 
     @property
     def safe_remaining(self) -> float:
         return (
-            self.remaining if self.remaining is not None else
-            self.safe_amount - (self.filled or 0.0)
+            self.remaining
+            if self.remaining is not None
+            else self.safe_amount - (self.filled or 0.0)
         )
 
     @property
     def safe_fee_base(self) -> float:
         return self.ft_fee_base or 0.0
 
     @property
@@ -142,222 +167,239 @@
 
     @property
     def trade(self) -> "LocalTrade":
         return self._trade_bt or self._trade_live
 
     @property
     def stake_amount(self) -> float:
-        """ Amount in stake currency used for this order"""
+        """Amount in stake currency used for this order"""
         return self.safe_amount * self.safe_price / self.trade.leverage
 
     def __repr__(self):
-
-        return (f"Order(id={self.id}, trade={self.ft_trade_id}, order_id={self.order_id}, "
-                f"side={self.side}, filled={self.safe_filled}, price={self.safe_price}, "
-                f"status={self.status}, date={self.order_date_utc:{DATETIME_PRINT_FORMAT}})")
+        return (
+            f"Order(id={self.id}, trade={self.ft_trade_id}, order_id={self.order_id}, "
+            f"side={self.side}, filled={self.safe_filled}, price={self.safe_price}, "
+            f"status={self.status}, date={self.order_date_utc:{DATETIME_PRINT_FORMAT}})"
+        )
 
     def update_from_ccxt_object(self, order):
         """
         Update Order from ccxt response
         Only updates if fields are available from ccxt -
         """
-        if self.order_id != str(order['id']):
+        if self.order_id != str(order["id"]):
             raise DependencyException("Order-id's don't match")
 
-        self.status = safe_value_fallback(order, 'status', default_value=self.status)
-        self.symbol = safe_value_fallback(order, 'symbol', default_value=self.symbol)
-        self.order_type = safe_value_fallback(order, 'type', default_value=self.order_type)
-        self.side = safe_value_fallback(order, 'side', default_value=self.side)
-        self.price = safe_value_fallback(order, 'price', default_value=self.price)
-        self.amount = safe_value_fallback(order, 'amount', default_value=self.amount)
-        self.filled = safe_value_fallback(order, 'filled', default_value=self.filled)
-        self.average = safe_value_fallback(order, 'average', default_value=self.average)
-        self.remaining = safe_value_fallback(order, 'remaining', default_value=self.remaining)
-        self.cost = safe_value_fallback(order, 'cost', default_value=self.cost)
-        self.stop_price = safe_value_fallback(order, 'stopPrice', default_value=self.stop_price)
-        order_date = safe_value_fallback(order, 'timestamp')
+        self.status = safe_value_fallback(order, "status", default_value=self.status)
+        self.symbol = safe_value_fallback(order, "symbol", default_value=self.symbol)
+        self.order_type = safe_value_fallback(order, "type", default_value=self.order_type)
+        self.side = safe_value_fallback(order, "side", default_value=self.side)
+        self.price = safe_value_fallback(order, "price", default_value=self.price)
+        self.amount = safe_value_fallback(order, "amount", default_value=self.amount)
+        self.filled = safe_value_fallback(order, "filled", default_value=self.filled)
+        self.average = safe_value_fallback(order, "average", default_value=self.average)
+        self.remaining = safe_value_fallback(order, "remaining", default_value=self.remaining)
+        self.cost = safe_value_fallback(order, "cost", default_value=self.cost)
+        self.stop_price = safe_value_fallback(order, "stopPrice", default_value=self.stop_price)
+        order_date = safe_value_fallback(order, "timestamp")
         if order_date:
             self.order_date = datetime.fromtimestamp(order_date / 1000, tz=timezone.utc)
         elif not self.order_date:
             self.order_date = dt_now()
 
         self.ft_is_open = True
         if self.status in NON_OPEN_EXCHANGE_STATES:
             self.ft_is_open = False
-            if (order.get('filled', 0.0) or 0.0) > 0 and not self.order_filled_date:
+            if (order.get("filled", 0.0) or 0.0) > 0 and not self.order_filled_date:
                 self.order_filled_date = dt_from_ts(
-                    safe_value_fallback(order, 'lastTradeTimestamp', default_value=dt_ts())
+                    safe_value_fallback(order, "lastTradeTimestamp", default_value=dt_ts())
                 )
         self.order_update_date = datetime.now(timezone.utc)
 
-    def to_ccxt_object(self, stopPriceName: str = 'stopPrice') -> Dict[str, Any]:
+    def to_ccxt_object(self, stopPriceName: str = "stopPrice") -> Dict[str, Any]:
         order: Dict[str, Any] = {
-            'id': self.order_id,
-            'symbol': self.ft_pair,
-            'price': self.price,
-            'average': self.average,
-            'amount': self.amount,
-            'cost': self.cost,
-            'type': self.order_type,
-            'side': self.ft_order_side,
-            'filled': self.filled,
-            'remaining': self.remaining,
-            'datetime': self.order_date_utc.strftime('%Y-%m-%dT%H:%M:%S.%f'),
-            'timestamp': int(self.order_date_utc.timestamp() * 1000),
-            'status': self.status,
-            'fee': None,
-            'info': {},
+            "id": self.order_id,
+            "symbol": self.ft_pair,
+            "price": self.price,
+            "average": self.average,
+            "amount": self.amount,
+            "cost": self.cost,
+            "type": self.order_type,
+            "side": self.ft_order_side,
+            "filled": self.filled,
+            "remaining": self.remaining,
+            "datetime": self.order_date_utc.strftime("%Y-%m-%dT%H:%M:%S.%f"),
+            "timestamp": int(self.order_date_utc.timestamp() * 1000),
+            "status": self.status,
+            "fee": None,
+            "info": {},
         }
-        if self.ft_order_side == 'stoploss':
-            order.update({
-                stopPriceName: self.stop_price,
-                'ft_order_type': 'stoploss',
-            })
+        if self.ft_order_side == "stoploss":
+            order.update(
+                {
+                    stopPriceName: self.stop_price,
+                    "ft_order_type": "stoploss",
+                }
+            )
 
         return order
 
     def to_json(self, entry_side: str, minified: bool = False) -> Dict[str, Any]:
         """
         :param minified: If True, only return a subset of the data is returned.
                          Only used for backtesting.
         """
         resp = {
-            'amount': self.safe_amount,
-            'safe_price': self.safe_price,
-            'ft_order_side': self.ft_order_side,
-            'order_filled_timestamp': dt_ts_none(self.order_filled_utc),
-            'ft_is_entry': self.ft_order_side == entry_side,
-            'ft_order_tag': self.ft_order_tag,
+            "amount": self.safe_amount,
+            "safe_price": self.safe_price,
+            "ft_order_side": self.ft_order_side,
+            "order_filled_timestamp": dt_ts_none(self.order_filled_utc),
+            "ft_is_entry": self.ft_order_side == entry_side,
+            "ft_order_tag": self.ft_order_tag,
         }
         if not minified:
-            resp.update({
-                'pair': self.ft_pair,
-                'order_id': self.order_id,
-                'status': self.status,
-                'average': round(self.average, 8) if self.average else 0,
-                'cost': self.cost if self.cost else 0,
-                'filled': self.filled,
-                'is_open': self.ft_is_open,
-                'order_date': self.order_date.strftime(DATETIME_PRINT_FORMAT)
-                if self.order_date else None,
-                'order_timestamp': int(self.order_date.replace(
-                    tzinfo=timezone.utc).timestamp() * 1000) if self.order_date else None,
-                'order_filled_date': self.order_filled_date.strftime(DATETIME_PRINT_FORMAT)
-                if self.order_filled_date else None,
-                'order_type': self.order_type,
-                'price': self.price,
-                'remaining': self.remaining,
-                'ft_fee_base': self.ft_fee_base,
-                'funding_fee': self.funding_fee,
-            })
+            resp.update(
+                {
+                    "pair": self.ft_pair,
+                    "order_id": self.order_id,
+                    "status": self.status,
+                    "average": round(self.average, 8) if self.average else 0,
+                    "cost": self.cost if self.cost else 0,
+                    "filled": self.filled,
+                    "is_open": self.ft_is_open,
+                    "order_date": (
+                        self.order_date.strftime(DATETIME_PRINT_FORMAT) if self.order_date else None
+                    ),
+                    "order_timestamp": (
+                        int(self.order_date.replace(tzinfo=timezone.utc).timestamp() * 1000)
+                        if self.order_date
+                        else None
+                    ),
+                    "order_filled_date": (
+                        self.order_filled_date.strftime(DATETIME_PRINT_FORMAT)
+                        if self.order_filled_date
+                        else None
+                    ),
+                    "order_type": self.order_type,
+                    "price": self.price,
+                    "remaining": self.remaining,
+                    "ft_fee_base": self.ft_fee_base,
+                    "funding_fee": self.funding_fee,
+                }
+            )
         return resp
 
-    def close_bt_order(self, close_date: datetime, trade: 'LocalTrade'):
+    def close_bt_order(self, close_date: datetime, trade: "LocalTrade"):
         self.order_filled_date = close_date
         self.filled = self.amount
         self.remaining = 0
-        self.status = 'closed'
+        self.status = "closed"
         self.ft_is_open = False
         # Assign funding fees to Order.
         # Assumes backtesting will use date_last_filled_utc to calculate future funding fees.
         self.funding_fee = trade.funding_fee_running
         trade.funding_fee_running = 0.0
 
-        if (self.ft_order_side == trade.entry_side and self.price):
+        if self.ft_order_side == trade.entry_side and self.price:
             trade.open_rate = self.price
             trade.recalc_trade_from_orders()
             if trade.nr_of_successful_entries == 1:
                 trade.initial_stop_loss_pct = None
                 trade.is_stop_loss_trailing = False
             trade.adjust_stop_loss(trade.open_rate, trade.stop_loss_pct)
 
     @staticmethod
-    def update_orders(orders: List['Order'], order: Dict[str, Any]):
+    def update_orders(orders: List["Order"], order: Dict[str, Any]):
         """
         Get all non-closed orders - useful when trying to batch-update orders
         """
         if not isinstance(order, dict):
             logger.warning(f"{order} is not a valid response object.")
             return
 
-        filtered_orders = [o for o in orders if o.order_id == order.get('id')]
+        filtered_orders = [o for o in orders if o.order_id == order.get("id")]
         if filtered_orders:
             oobj = filtered_orders[0]
             oobj.update_from_ccxt_object(order)
             Trade.commit()
         else:
             logger.warning(f"Did not find order for {order}.")
 
     @classmethod
     def parse_from_ccxt_object(
-            cls, order: Dict[str, Any], pair: str, side: str,
-            amount: Optional[float] = None, price: Optional[float] = None) -> Self:
+        cls,
+        order: Dict[str, Any],
+        pair: str,
+        side: str,
+        amount: Optional[float] = None,
+        price: Optional[float] = None,
+    ) -> Self:
         """
         Parse an order from a ccxt object and return a new order Object.
         Optional support for overriding amount and price is only used for test simplification.
         """
         o = cls(
-            order_id=str(order['id']),
+            order_id=str(order["id"]),
             ft_order_side=side,
             ft_pair=pair,
-            ft_amount=amount if amount else order['amount'],
-            ft_price=price if price else order['price'],
-            )
+            ft_amount=amount if amount else order["amount"],
+            ft_price=price if price else order["price"],
+        )
 
         o.update_from_ccxt_object(order)
         return o
 
     @staticmethod
-    def get_open_orders() -> Sequence['Order']:
+    def get_open_orders() -> Sequence["Order"]:
         """
         Retrieve open orders from the database
         :return: List of open orders
         """
         return Order.session.scalars(select(Order).filter(Order.ft_is_open.is_(True))).all()
 
     @staticmethod
-    def order_by_id(order_id: str) -> Optional['Order']:
+    def order_by_id(order_id: str) -> Optional["Order"]:
         """
         Retrieve order based on order_id
         :return: Order or None
         """
         return Order.session.scalars(select(Order).filter(Order.order_id == order_id)).first()
 
 
 class LocalTrade:
     """
     Trade database model.
     Used in backtesting - must be aligned to Trade model!
-
     """
+
     use_db: bool = False
     # Trades container for backtesting
-    trades: List['LocalTrade'] = []
-    trades_open: List['LocalTrade'] = []
+    trades: List["LocalTrade"] = []
+    trades_open: List["LocalTrade"] = []
     # Copy of trades_open - but indexed by pair
-    bt_trades_open_pp: Dict[str, List['LocalTrade']] = defaultdict(list)
+    bt_trades_open_pp: Dict[str, List["LocalTrade"]] = defaultdict(list)
     bt_open_open_trade_count: int = 0
     total_profit: float = 0
     realized_profit: float = 0
 
     id: int = 0
 
     orders: List[Order] = []
 
-    exchange: str = ''
-    pair: str = ''
-    base_currency: Optional[str] = ''
-    stake_currency: Optional[str] = ''
+    exchange: str = ""
+    pair: str = ""
+    base_currency: Optional[str] = ""
+    stake_currency: Optional[str] = ""
     is_open: bool = True
     fee_open: float = 0.0
     fee_open_cost: Optional[float] = None
-    fee_open_currency: Optional[str] = ''
+    fee_open_currency: Optional[str] = ""
     fee_close: Optional[float] = 0.0
     fee_close_cost: Optional[float] = None
-    fee_close_currency: Optional[str] = ''
+    fee_close_currency: Optional[str] = ""
     open_rate: float = 0.0
     open_rate_requested: Optional[float] = None
     # open_trade_value - calculated via _calc_open_trade_value
     open_trade_value: float = 0.0
     close_rate: Optional[float] = None
     close_rate_requested: Optional[float] = None
     close_profit: Optional[float] = None
@@ -377,17 +419,17 @@
     # percentage value of the initial stop loss
     initial_stop_loss_pct: Optional[float] = None
     is_stop_loss_trailing: bool = False
     # absolute value of the highest reached price
     max_rate: Optional[float] = None
     # Lowest price reached
     min_rate: Optional[float] = None
-    exit_reason: Optional[str] = ''
-    exit_order_status: Optional[str] = ''
-    strategy: Optional[str] = ''
+    exit_reason: Optional[str] = ""
+    exit_order_status: Optional[str] = ""
+    strategy: Optional[str] = ""
     enter_tag: Optional[str] = None
     timeframe: Optional[int] = None
 
     trading_mode: TradingMode = TradingMode.SPOT
     amount_precision: Optional[float] = None
     price_precision: Optional[float] = None
     precision_mode: Optional[int] = None
@@ -424,53 +466,52 @@
         Consider buy_tag deprecated
         """
         return self.enter_tag
 
     @property
     def has_no_leverage(self) -> bool:
         """Returns true if this is a non-leverage, non-short trade"""
-        return ((self.leverage == 1.0 or self.leverage is None) and not self.is_short)
+        return (self.leverage == 1.0 or self.leverage is None) and not self.is_short
 
     @property
     def borrowed(self) -> float:
         """
-            The amount of currency borrowed from the exchange for leverage trades
-            If a long trade, the amount is in base currency
-            If a short trade, the amount is in the other currency being traded
+        The amount of currency borrowed from the exchange for leverage trades
+        If a long trade, the amount is in base currency
+        If a short trade, the amount is in the other currency being traded
         """
         if self.has_no_leverage:
             return 0.0
         elif not self.is_short:
             return (self.amount * self.open_rate) * ((self.leverage - 1) / self.leverage)
         else:
             return self.amount
 
     @property
     def _date_last_filled_utc(self) -> Optional[datetime]:
-        """ Date of the last filled order"""
+        """Date of the last filled order"""
         orders = self.select_filled_orders()
         if orders:
             return max(o.order_filled_utc for o in orders if o.order_filled_utc)
         return None
 
     @property
     def date_last_filled_utc(self) -> datetime:
-        """ Date of the last filled order - or open_date if no orders are filled"""
+        """Date of the last filled order - or open_date if no orders are filled"""
         dt_last_filled = self._date_last_filled_utc
         if not dt_last_filled:
             return self.open_date_utc
         return max([self.open_date_utc, dt_last_filled])
 
     @property
     def date_entry_fill_utc(self) -> Optional[datetime]:
-        """ Date of the first filled order"""
+        """Date of the first filled order"""
         orders = self.select_filled_orders(self.entry_side)
-        if (
-            orders
-            and len(filled_date := [o.order_filled_utc for o in orders if o.order_filled_utc])
+        if orders and len(
+            filled_date := [o.order_filled_utc for o in orders if o.order_filled_utc]
         ):
             return min(filled_date)
         return None
 
     @property
     def open_date_utc(self):
         return self.open_date.replace(tzinfo=timezone.utc)
@@ -508,194 +549,194 @@
 
     @property
     def safe_base_currency(self) -> str:
         """
         Compatibility layer for asset - which can be empty for old trades.
         """
         try:
-            return self.base_currency or self.pair.split('/')[0]
+            return self.base_currency or self.pair.split("/")[0]
         except IndexError:
-            return ''
+            return ""
 
     @property
     def safe_quote_currency(self) -> str:
         """
         Compatibility layer for asset - which can be empty for old trades.
         """
         try:
-            return self.stake_currency or self.pair.split('/')[1].split(':')[0]
+            return self.stake_currency or self.pair.split("/")[1].split(":")[0]
         except IndexError:
-            return ''
+            return ""
 
     @property
     def open_orders(self) -> List[Order]:
         """
         All open orders for this trade excluding stoploss orders
         """
-        return [o for o in self.orders if o.ft_is_open and o.ft_order_side != 'stoploss']
+        return [o for o in self.orders if o.ft_is_open and o.ft_order_side != "stoploss"]
 
     @property
     def has_open_orders(self) -> bool:
         """
         True if there are open orders for this trade excluding stoploss orders
         """
         open_orders_wo_sl = [
-            o for o in self.orders
-            if o.ft_order_side not in ['stoploss'] and o.ft_is_open
+            o for o in self.orders if o.ft_order_side not in ["stoploss"] and o.ft_is_open
         ]
         return len(open_orders_wo_sl) > 0
 
     @property
     def open_sl_orders(self) -> List[Order]:
         """
         All open stoploss orders for this trade
         """
-        return [
-            o for o in self.orders
-            if o.ft_order_side in ['stoploss'] and o.ft_is_open
-        ]
+        return [o for o in self.orders if o.ft_order_side in ["stoploss"] and o.ft_is_open]
 
     @property
     def has_open_sl_orders(self) -> bool:
         """
         True if there are open stoploss orders for this trade
         """
         open_sl_orders = [
-            o for o in self.orders
-            if o.ft_order_side in ['stoploss'] and o.ft_is_open
+            o for o in self.orders if o.ft_order_side in ["stoploss"] and o.ft_is_open
         ]
         return len(open_sl_orders) > 0
 
     @property
     def sl_orders(self) -> List[Order]:
         """
         All stoploss orders for this trade
         """
-        return [
-            o for o in self.orders
-            if o.ft_order_side in ['stoploss']
-        ]
+        return [o for o in self.orders if o.ft_order_side in ["stoploss"]]
 
     @property
     def open_orders_ids(self) -> List[str]:
         open_orders_ids_wo_sl = [
-            oo.order_id for oo in self.open_orders
-            if oo.ft_order_side not in ['stoploss']
+            oo.order_id for oo in self.open_orders if oo.ft_order_side not in ["stoploss"]
         ]
         return open_orders_ids_wo_sl
 
     def __init__(self, **kwargs):
         for key in kwargs:
             setattr(self, key, kwargs[key])
         self.recalc_open_trade_value()
         self.orders = []
         if self.trading_mode == TradingMode.MARGIN and self.interest_rate is None:
             raise OperationalException(
-                f"{self.trading_mode.value} trading requires param interest_rate on trades")
+                f"{self.trading_mode.value} trading requires param interest_rate on trades"
+            )
 
     def __repr__(self):
         open_since = (
-            self.open_date_utc.strftime(DATETIME_PRINT_FORMAT) if self.is_open else 'closed'
+            self.open_date_utc.strftime(DATETIME_PRINT_FORMAT) if self.is_open else "closed"
         )
 
         return (
-            f'Trade(id={self.id}, pair={self.pair}, amount={self.amount:.8f}, '
-            f'is_short={self.is_short or False}, leverage={self.leverage or 1.0}, '
-            f'open_rate={self.open_rate:.8f}, open_since={open_since})'
+            f"Trade(id={self.id}, pair={self.pair}, amount={self.amount:.8f}, "
+            f"is_short={self.is_short or False}, leverage={self.leverage or 1.0}, "
+            f"open_rate={self.open_rate:.8f}, open_since={open_since})"
         )
 
     def to_json(self, minified: bool = False) -> Dict[str, Any]:
         """
         :param minified: If True, only return a subset of the data is returned.
                          Only used for backtesting.
         :return: Dictionary with trade data
         """
         filled_or_open_orders = self.select_filled_or_open_orders()
         orders_json = [order.to_json(self.entry_side, minified) for order in filled_or_open_orders]
 
         return {
-            'trade_id': self.id,
-            'pair': self.pair,
-            'base_currency': self.safe_base_currency,
-            'quote_currency': self.safe_quote_currency,
-            'is_open': self.is_open,
-            'exchange': self.exchange,
-            'amount': round(self.amount, 8),
-            'amount_requested': round(self.amount_requested, 8) if self.amount_requested else None,
-            'stake_amount': round(self.stake_amount, 8),
-            'max_stake_amount': round(self.max_stake_amount, 8) if self.max_stake_amount else None,
-            'strategy': self.strategy,
-            'enter_tag': self.enter_tag,
-            'timeframe': self.timeframe,
-
-            'fee_open': self.fee_open,
-            'fee_open_cost': self.fee_open_cost,
-            'fee_open_currency': self.fee_open_currency,
-            'fee_close': self.fee_close,
-            'fee_close_cost': self.fee_close_cost,
-            'fee_close_currency': self.fee_close_currency,
-
-            'open_date': self.open_date.strftime(DATETIME_PRINT_FORMAT),
-            'open_timestamp': dt_ts_none(self.open_date_utc),
-            'open_fill_date': (self.date_entry_fill_utc.strftime(DATETIME_PRINT_FORMAT)
-                               if self.date_entry_fill_utc else None),
-            'open_fill_timestamp': dt_ts_none(self.date_entry_fill_utc),
-            'open_rate': self.open_rate,
-            'open_rate_requested': self.open_rate_requested,
-            'open_trade_value': round(self.open_trade_value, 8),
-
-            'close_date': (self.close_date.strftime(DATETIME_PRINT_FORMAT)
-                           if self.close_date else None),
-            'close_timestamp': dt_ts_none(self.close_date_utc),
-            'realized_profit': self.realized_profit or 0.0,
+            "trade_id": self.id,
+            "pair": self.pair,
+            "base_currency": self.safe_base_currency,
+            "quote_currency": self.safe_quote_currency,
+            "is_open": self.is_open,
+            "exchange": self.exchange,
+            "amount": round(self.amount, 8),
+            "amount_requested": round(self.amount_requested, 8) if self.amount_requested else None,
+            "stake_amount": round(self.stake_amount, 8),
+            "max_stake_amount": round(self.max_stake_amount, 8) if self.max_stake_amount else None,
+            "strategy": self.strategy,
+            "enter_tag": self.enter_tag,
+            "timeframe": self.timeframe,
+            "fee_open": self.fee_open,
+            "fee_open_cost": self.fee_open_cost,
+            "fee_open_currency": self.fee_open_currency,
+            "fee_close": self.fee_close,
+            "fee_close_cost": self.fee_close_cost,
+            "fee_close_currency": self.fee_close_currency,
+            "open_date": self.open_date.strftime(DATETIME_PRINT_FORMAT),
+            "open_timestamp": dt_ts_none(self.open_date_utc),
+            "open_fill_date": (
+                self.date_entry_fill_utc.strftime(DATETIME_PRINT_FORMAT)
+                if self.date_entry_fill_utc
+                else None
+            ),
+            "open_fill_timestamp": dt_ts_none(self.date_entry_fill_utc),
+            "open_rate": self.open_rate,
+            "open_rate_requested": self.open_rate_requested,
+            "open_trade_value": round(self.open_trade_value, 8),
+            "close_date": (
+                self.close_date.strftime(DATETIME_PRINT_FORMAT) if self.close_date else None
+            ),
+            "close_timestamp": dt_ts_none(self.close_date_utc),
+            "realized_profit": self.realized_profit or 0.0,
             # Close-profit corresponds to relative realized_profit ratio
-            'realized_profit_ratio': self.close_profit or None,
-            'close_rate': self.close_rate,
-            'close_rate_requested': self.close_rate_requested,
-            'close_profit': self.close_profit,  # Deprecated
-            'close_profit_pct': round(self.close_profit * 100, 2) if self.close_profit else None,
-            'close_profit_abs': self.close_profit_abs,  # Deprecated
-
-            'trade_duration_s': (int((self.close_date_utc - self.open_date_utc).total_seconds())
-                                 if self.close_date else None),
-            'trade_duration': (int((self.close_date_utc - self.open_date_utc).total_seconds() // 60)
-                               if self.close_date else None),
-
-            'profit_ratio': self.close_profit,
-            'profit_pct': round(self.close_profit * 100, 2) if self.close_profit else None,
-            'profit_abs': self.close_profit_abs,
-
-            'exit_reason': self.exit_reason,
-            'exit_order_status': self.exit_order_status,
-            'stop_loss_abs': self.stop_loss,
-            'stop_loss_ratio': self.stop_loss_pct if self.stop_loss_pct else None,
-            'stop_loss_pct': (self.stop_loss_pct * 100) if self.stop_loss_pct else None,
-            'stoploss_last_update': (self.stoploss_last_update_utc.strftime(DATETIME_PRINT_FORMAT)
-                                     if self.stoploss_last_update_utc else None),
-            'stoploss_last_update_timestamp': dt_ts_none(self.stoploss_last_update_utc),
-            'initial_stop_loss_abs': self.initial_stop_loss,
-            'initial_stop_loss_ratio': (self.initial_stop_loss_pct
-                                        if self.initial_stop_loss_pct else None),
-            'initial_stop_loss_pct': (self.initial_stop_loss_pct * 100
-                                      if self.initial_stop_loss_pct else None),
-            'min_rate': self.min_rate,
-            'max_rate': self.max_rate,
-
-            'leverage': self.leverage,
-            'interest_rate': self.interest_rate,
-            'liquidation_price': self.liquidation_price,
-            'is_short': self.is_short,
-            'trading_mode': self.trading_mode,
-            'funding_fees': self.funding_fees,
-            'amount_precision': self.amount_precision,
-            'price_precision': self.price_precision,
-            'precision_mode': self.precision_mode,
-            'contract_size': self.contract_size,
-            'has_open_orders': self.has_open_orders,
-            'orders': orders_json,
+            "realized_profit_ratio": self.close_profit or None,
+            "close_rate": self.close_rate,
+            "close_rate_requested": self.close_rate_requested,
+            "close_profit": self.close_profit,  # Deprecated
+            "close_profit_pct": round(self.close_profit * 100, 2) if self.close_profit else None,
+            "close_profit_abs": self.close_profit_abs,  # Deprecated
+            "trade_duration_s": (
+                int((self.close_date_utc - self.open_date_utc).total_seconds())
+                if self.close_date
+                else None
+            ),
+            "trade_duration": (
+                int((self.close_date_utc - self.open_date_utc).total_seconds() // 60)
+                if self.close_date
+                else None
+            ),
+            "profit_ratio": self.close_profit,
+            "profit_pct": round(self.close_profit * 100, 2) if self.close_profit else None,
+            "profit_abs": self.close_profit_abs,
+            "exit_reason": self.exit_reason,
+            "exit_order_status": self.exit_order_status,
+            "stop_loss_abs": self.stop_loss,
+            "stop_loss_ratio": self.stop_loss_pct if self.stop_loss_pct else None,
+            "stop_loss_pct": (self.stop_loss_pct * 100) if self.stop_loss_pct else None,
+            "stoploss_last_update": (
+                self.stoploss_last_update_utc.strftime(DATETIME_PRINT_FORMAT)
+                if self.stoploss_last_update_utc
+                else None
+            ),
+            "stoploss_last_update_timestamp": dt_ts_none(self.stoploss_last_update_utc),
+            "initial_stop_loss_abs": self.initial_stop_loss,
+            "initial_stop_loss_ratio": (
+                self.initial_stop_loss_pct if self.initial_stop_loss_pct else None
+            ),
+            "initial_stop_loss_pct": (
+                self.initial_stop_loss_pct * 100 if self.initial_stop_loss_pct else None
+            ),
+            "min_rate": self.min_rate,
+            "max_rate": self.max_rate,
+            "leverage": self.leverage,
+            "interest_rate": self.interest_rate,
+            "liquidation_price": self.liquidation_price,
+            "is_short": self.is_short,
+            "trading_mode": self.trading_mode,
+            "funding_fees": self.funding_fees,
+            "amount_precision": self.amount_precision,
+            "price_precision": self.price_precision,
+            "precision_mode": self.precision_mode,
+            "contract_size": self.contract_size,
+            "has_open_orders": self.has_open_orders,
+            "orders": orders_json,
         }
 
     @staticmethod
     def reset_trades() -> None:
         """
         Resets all trades. Only active for backtesting mode.
         """
@@ -737,16 +778,21 @@
         """
         if not self.stop_loss:
             self.initial_stop_loss = stop_loss
         self.stop_loss = stop_loss
 
         self.stop_loss_pct = -1 * abs(percent)
 
-    def adjust_stop_loss(self, current_price: float, stoploss: Optional[float],
-                         initial: bool = False, allow_refresh: bool = False) -> None:
+    def adjust_stop_loss(
+        self,
+        current_price: float,
+        stoploss: Optional[float],
+        initial: bool = False,
+        allow_refresh: bool = False,
+    ) -> None:
         """
         This adjusts the stop loss to it's most recently observed setting
         :param current_price: Current rate the asset is traded
         :param stoploss: Stoploss as factor (sample -0.05 -> -5% below current price).
         :param initial: Called to initiate stop_loss.
             Skips everything if self.stop_loss is already set.
         :param refresh: Called to refresh stop_loss, allows adjustment in both directions
@@ -757,22 +803,29 @@
 
         leverage = self.leverage or 1.0
         if self.is_short:
             new_loss = float(current_price * (1 + abs(stoploss / leverage)))
         else:
             new_loss = float(current_price * (1 - abs(stoploss / leverage)))
 
-        stop_loss_norm = price_to_precision(new_loss, self.price_precision, self.precision_mode,
-                                            rounding_mode=ROUND_DOWN if self.is_short else ROUND_UP)
+        stop_loss_norm = price_to_precision(
+            new_loss,
+            self.price_precision,
+            self.precision_mode,
+            rounding_mode=ROUND_DOWN if self.is_short else ROUND_UP,
+        )
         # no stop loss assigned yet
         if self.initial_stop_loss_pct is None:
             self.__set_stop_loss(stop_loss_norm, stoploss)
             self.initial_stop_loss = price_to_precision(
-                stop_loss_norm, self.price_precision, self.precision_mode,
-                rounding_mode=ROUND_DOWN if self.is_short else ROUND_UP)
+                stop_loss_norm,
+                self.price_precision,
+                self.precision_mode,
+                rounding_mode=ROUND_DOWN if self.is_short else ROUND_UP,
+            )
             self.initial_stop_loss_pct = -1 * abs(stoploss)
 
         # evaluate if the stop loss needs to be updated
         else:
             higher_stop = stop_loss_norm > self.stop_loss
             lower_stop = stop_loss_norm < self.stop_loss
 
@@ -793,63 +846,64 @@
 
         logger.debug(
             f"{self.pair} - Stoploss adjusted. current_price={current_price:.8f}, "
             f"open_rate={self.open_rate:.8f}, max_rate={self.max_rate or self.open_rate:.8f}, "
             f"initial_stop_loss={self.initial_stop_loss:.8f}, "
             f"stop_loss={self.stop_loss:.8f}. "
             f"Trailing stoploss saved us: "
-            f"{float(self.stop_loss) - float(self.initial_stop_loss or 0.0):.8f}.")
+            f"{float(self.stop_loss) - float(self.initial_stop_loss or 0.0):.8f}."
+        )
 
     def update_trade(self, order: Order, recalculating: bool = False) -> None:
         """
         Updates this entity with amount and actual open/close rates.
         :param order: order retrieved by exchange.fetch_order()
         :return: None
         """
 
         # Ignore open and cancelled orders
-        if order.status == 'open' or order.safe_price is None:
+        if order.status == "open" or order.safe_price is None:
             return
 
-        logger.info(f'Updating trade (id={self.id}) ...')
-        if order.ft_order_side != 'stoploss':
+        logger.info(f"Updating trade (id={self.id}) ...")
+        if order.ft_order_side != "stoploss":
             order.funding_fee = self.funding_fee_running
             # Reset running funding fees
             self.funding_fee_running = 0.0
         order_type = order.order_type.upper() if order.order_type else None
 
         if order.ft_order_side == self.entry_side:
             # Update open rate and actual amount
             self.open_rate = order.safe_price
             self.amount = order.safe_amount_after_fee
             if self.is_open:
                 payment = "SELL" if self.is_short else "BUY"
-                logger.info(f'{order_type}_{payment} has been fulfilled for {self}.')
+                logger.info(f"{order_type}_{payment} has been fulfilled for {self}.")
 
             self.recalc_trade_from_orders()
         elif order.ft_order_side == self.exit_side:
             if self.is_open:
                 payment = "BUY" if self.is_short else "SELL"
                 # * On margin shorts, you buy a little bit more than the amount (amount + interest)
-                logger.info(f'{order_type}_{payment} has been fulfilled for {self}.')
+                logger.info(f"{order_type}_{payment} has been fulfilled for {self}.")
 
-        elif order.ft_order_side == 'stoploss' and order.status not in ('open', ):
+        elif order.ft_order_side == "stoploss" and order.status not in ("open",):
             self.close_rate_requested = self.stop_loss
             self.exit_reason = ExitType.STOPLOSS_ON_EXCHANGE.value
             if self.is_open and order.safe_filled > 0:
-                logger.info(f'{order_type} is hit for {self}.')
+                logger.info(f"{order_type} is hit for {self}.")
         else:
-            raise ValueError(f'Unknown order type: {order.order_type}')
+            raise ValueError(f"Unknown order type: {order.order_type}")
 
         if order.ft_order_side != self.entry_side:
-            amount_tr = amount_to_contract_precision(self.amount, self.amount_precision,
-                                                     self.precision_mode, self.contract_size)
-            if (
-                isclose(order.safe_amount_after_fee, amount_tr, abs_tol=MATH_CLOSE_PREC)
-                or (not recalculating and order.safe_amount_after_fee > amount_tr)
+            amount_tr = amount_to_contract_precision(
+                self.amount, self.amount_precision, self.precision_mode, self.contract_size
+            )
+            if isclose(order.safe_amount_after_fee, amount_tr, abs_tol=MATH_CLOSE_PREC) or (
+                not recalculating and order.safe_amount_after_fee > amount_tr
             ):
                 # When recalculating a trade, only coming out to 0 can force a close
                 self.close(order.safe_price)
             else:
                 self.recalc_trade_from_orders()
 
         Trade.commit()
@@ -858,22 +912,25 @@
         """
         Sets close_rate to the given rate, calculates total profit
         and marks trade as closed
         """
         self.close_rate = rate
         self.close_date = self.close_date or self._date_last_filled_utc or dt_now()
         self.is_open = False
-        self.exit_order_status = 'closed'
+        self.exit_order_status = "closed"
         self.recalc_trade_from_orders(is_closing=True)
         if show_msg:
-            logger.info(f"Marking {self} as closed as the trade is fulfilled "
-                        "and found no open orders for it.")
+            logger.info(
+                f"Marking {self} as closed as the trade is fulfilled "
+                "and found no open orders for it."
+            )
 
-    def update_fee(self, fee_cost: float, fee_currency: Optional[str], fee_rate: Optional[float],
-                   side: str) -> None:
+    def update_fee(
+        self, fee_cost: float, fee_currency: Optional[str], fee_rate: Optional[float], side: str
+    ) -> None:
         """
         Update Fee parameters. Only acts once per side
         """
         if self.entry_side == side and self.fee_open_currency is None:
             self.fee_open_cost = fee_cost
             self.fee_open_currency = fee_currency
             if fee_rate is not None:
@@ -896,21 +953,50 @@
             return self.fee_close_currency is not None
         else:
             return False
 
     def update_order(self, order: Dict) -> None:
         Order.update_orders(self.orders, order)
 
+    @property
+    def fully_canceled_entry_order_count(self) -> int:
+        """
+        Get amount of failed exiting orders
+        assumes full exits.
+        """
+        return len(
+            [
+                o
+                for o in self.orders
+                if o.ft_order_side == self.entry_side
+                and o.status in CANCELED_EXCHANGE_STATES
+                and o.filled == 0
+            ]
+        )
+
+    @property
+    def canceled_exit_order_count(self) -> int:
+        """
+        Get amount of failed exiting orders
+        assumes full exits.
+        """
+        return len(
+            [
+                o
+                for o in self.orders
+                if o.ft_order_side == self.exit_side and o.status in CANCELED_EXCHANGE_STATES
+            ]
+        )
+
     def get_canceled_exit_order_count(self) -> int:
         """
         Get amount of failed exiting orders
         assumes full exits.
         """
-        return len([o for o in self.orders if o.ft_order_side == self.exit_side
-                    and o.status in CANCELED_EXCHANGE_STATES])
+        return self.canceled_exit_order_count
 
     def _calc_open_trade_value(self, amount: float, open_rate: float) -> float:
         """
         Calculate the open_rate including open_fee.
         :return: Price in of the open trade incl. Fees
         """
         open_trade = FtPrecise(amount) * FtPrecise(open_rate)
@@ -944,15 +1030,14 @@
 
         rate = FtPrecise(self.interest_rate)
         borrowed = FtPrecise(self.borrowed)
 
         return interest(exchange_name=self.exchange, borrowed=borrowed, rate=rate, hours=hours)
 
     def _calc_base_close(self, amount: FtPrecise, rate: float, fee: Optional[float]) -> FtPrecise:
-
         close_trade = amount * FtPrecise(rate)
         fees = close_trade * FtPrecise(fee or 0.0)
 
         if self.is_short:
             return close_trade + fees
         else:
             return close_trade - fees
@@ -968,52 +1053,54 @@
 
         amount1 = FtPrecise(amount or self.amount)
         trading_mode = self.trading_mode or TradingMode.SPOT
 
         if trading_mode == TradingMode.SPOT:
             return float(self._calc_base_close(amount1, rate, self.fee_close))
 
-        elif (trading_mode == TradingMode.MARGIN):
-
+        elif trading_mode == TradingMode.MARGIN:
             total_interest = self.calculate_interest()
 
             if self.is_short:
                 amount1 = amount1 + total_interest
                 return float(self._calc_base_close(amount1, rate, self.fee_close))
             else:
                 # Currency already owned for longs, no need to purchase
                 return float(self._calc_base_close(amount1, rate, self.fee_close) - total_interest)
 
-        elif (trading_mode == TradingMode.FUTURES):
+        elif trading_mode == TradingMode.FUTURES:
             funding_fees = self.funding_fees or 0.0
             # Positive funding_fees -> Trade has gained from fees.
             # Negative funding_fees -> Trade had to pay the fees.
             if self.is_short:
                 return float(self._calc_base_close(amount1, rate, self.fee_close)) - funding_fees
             else:
                 return float(self._calc_base_close(amount1, rate, self.fee_close)) + funding_fees
         else:
             raise OperationalException(
-                f"{self.trading_mode.value} trading is not yet available using freqtrade")
+                f"{self.trading_mode.value} trading is not yet available using freqtrade"
+            )
 
-    def calc_profit(self, rate: float, amount: Optional[float] = None,
-                    open_rate: Optional[float] = None) -> float:
+    def calc_profit(
+        self, rate: float, amount: Optional[float] = None, open_rate: Optional[float] = None
+    ) -> float:
         """
         Calculate the absolute profit in stake currency between Close and Open trade
         Deprecated - only available for backwards compatibility
         :param rate: close rate to compare with.
         :param amount: Amount to use for the calculation. Falls back to trade.amount if not set.
         :param open_rate: open_rate to use. Defaults to self.open_rate if not provided.
         :return: profit in stake currency as float
         """
         prof = self.calculate_profit(rate, amount, open_rate)
         return prof.profit_abs
 
-    def calculate_profit(self, rate: float, amount: Optional[float] = None,
-                         open_rate: Optional[float] = None) -> ProfitStruct:
+    def calculate_profit(
+        self, rate: float, amount: Optional[float] = None, open_rate: Optional[float] = None
+    ) -> ProfitStruct:
         """
         Calculate profit metrics (absolute, ratio, total, total ratio).
         All calculations include fees.
         :param rate: close rate to compare with.
         :param amount: Amount to use for the calculation. Falls back to trade.amount if not set.
         :param open_rate: open_rate to use. Defaults to self.open_rate if not provided.
         :return: Profit structure, containing absolute and relative profits.
@@ -1038,47 +1125,48 @@
             profit_ratio = float(f"{profit_ratio:.8f}")
         except ZeroDivisionError:
             profit_ratio = 0.0
 
         total_profit_abs = profit_abs + self.realized_profit
         total_profit_ratio = (
             (total_profit_abs / self.max_stake_amount) * self.leverage
-            if self.max_stake_amount else 0.0
+            if self.max_stake_amount
+            else 0.0
         )
         total_profit_ratio = float(f"{total_profit_ratio:.8f}")
         profit_abs = float(f"{profit_abs:.8f}")
 
         return ProfitStruct(
             profit_abs=profit_abs,
             profit_ratio=profit_ratio,
             total_profit=profit_abs + self.realized_profit,
             total_profit_ratio=total_profit_ratio,
         )
 
     def calc_profit_ratio(
-            self, rate: float, amount: Optional[float] = None,
-            open_rate: Optional[float] = None) -> float:
+        self, rate: float, amount: Optional[float] = None, open_rate: Optional[float] = None
+    ) -> float:
         """
         Calculates the profit as ratio (including fee).
         :param rate: rate to compare with.
         :param amount: Amount to use for the calculation. Falls back to trade.amount if not set.
         :param open_rate: open_rate to use. Defaults to self.open_rate if not provided.
         :return: profit ratio as float
         """
         close_trade_value = self.calc_close_trade_value(rate, amount)
 
         if amount is None or open_rate is None:
             open_trade_value = self.open_trade_value
         else:
             open_trade_value = self._calc_open_trade_value(amount, open_rate)
 
-        short_close_zero = (self.is_short and close_trade_value == 0.0)
-        long_close_zero = (not self.is_short and open_trade_value == 0.0)
+        short_close_zero = self.is_short and close_trade_value == 0.0
+        long_close_zero = not self.is_short and open_trade_value == 0.0
 
-        if (short_close_zero or long_close_zero):
+        if short_close_zero or long_close_zero:
             return 0.0
         else:
             if self.is_short:
                 profit_ratio = (1 - (close_trade_value / open_trade_value)) * self.leverage
             else:
                 profit_ratio = ((close_trade_value / open_trade_value) - 1) * self.leverage
 
@@ -1096,15 +1184,15 @@
         # Reset funding fees
         self.funding_fees = 0.0
         funding_fees = 0.0
         ordercount = len(self.orders) - 1
         for i, o in enumerate(self.orders):
             if o.ft_is_open or not o.filled:
                 continue
-            funding_fees += (o.funding_fee or 0.0)
+            funding_fees += o.funding_fee or 0.0
             tmp_amount = FtPrecise(o.safe_amount_after_fee)
             tmp_price = FtPrecise(o.safe_price)
 
             is_exit = o.ft_order_side != self.entry_side
             side = FtPrecise(-1 if is_exit else 1)
             if tmp_amount > ZERO and tmp_price is not None:
                 current_amount += tmp_amount * side
@@ -1126,25 +1214,26 @@
                 close_profit_abs += prof.profit_abs
                 if total_stake > 0:
                     # This needs to be calculated based on the last occurring exit to be aligned
                     # with realized_profit.
                     close_profit = (close_profit_abs / total_stake) * self.leverage
             else:
                 total_stake = total_stake + self._calc_open_trade_value(tmp_amount, price)
-                max_stake_amount += (tmp_amount * price)
+                max_stake_amount += tmp_amount * price
         self.funding_fees = funding_fees
         self.max_stake_amount = float(max_stake_amount)
 
         if close_profit:
             self.close_profit = close_profit
             self.realized_profit = close_profit_abs
             self.close_profit_abs = prof.profit_abs
 
         current_amount_tr = amount_to_contract_precision(
-            float(current_amount), self.amount_precision, self.precision_mode, self.contract_size)
+            float(current_amount), self.amount_precision, self.precision_mode, self.contract_size
+        )
         if current_amount_tr > 0.0:
             # Trade is still open
             # Leverage not updated, as we don't allow changing leverage through DCA at the moment.
             self.open_rate = float(current_stake / current_amount)
             self.amount = current_amount_tr
             self.stake_amount = float(current_stake) / (self.leverage or 1.0)
             self.fee_open_cost = self.fee_open * float(current_stake)
@@ -1163,16 +1252,20 @@
         :param order_id: Exchange order id
         """
         for o in self.orders:
             if o.order_id == order_id:
                 return o
         return None
 
-    def select_order(self, order_side: Optional[str] = None,
-                     is_open: Optional[bool] = None, only_filled: bool = False) -> Optional[Order]:
+    def select_order(
+        self,
+        order_side: Optional[str] = None,
+        is_open: Optional[bool] = None,
+        only_filled: bool = False,
+    ) -> Optional[Order]:
         """
         Finds latest order for this orderside and status
         :param order_side: ft_order_side of the order (either 'buy', 'sell' or 'stoploss')
         :param is_open: Only search for open orders?
         :param only_filled: Only search for Filled orders (only valid with is_open=False).
         :return: latest Order object if it exists, else None
         """
@@ -1184,40 +1277,46 @@
         if is_open is False and only_filled:
             orders = [o for o in orders if o.filled and o.status in NON_OPEN_EXCHANGE_STATES]
         if len(orders) > 0:
             return orders[-1]
         else:
             return None
 
-    def select_filled_orders(self, order_side: Optional[str] = None) -> List['Order']:
+    def select_filled_orders(self, order_side: Optional[str] = None) -> List["Order"]:
         """
         Finds filled orders for this order side.
         Will not return open orders which already partially filled.
         :param order_side: Side of the order (either 'buy', 'sell', or None)
         :return: array of Order objects
         """
-        return [o for o in self.orders if ((o.ft_order_side == order_side) or (order_side is None))
-                and o.ft_is_open is False
-                and o.filled
-                and o.status in NON_OPEN_EXCHANGE_STATES]
+        return [
+            o
+            for o in self.orders
+            if ((o.ft_order_side == order_side) or (order_side is None))
+            and o.ft_is_open is False
+            and o.filled
+            and o.status in NON_OPEN_EXCHANGE_STATES
+        ]
 
-    def select_filled_or_open_orders(self) -> List['Order']:
+    def select_filled_or_open_orders(self) -> List["Order"]:
         """
         Finds filled or open orders
         :param order_side: Side of the order (either 'buy', 'sell', or None)
         :return: array of Order objects
         """
-        return [o for o in self.orders if
-                (
-                    o.ft_is_open is False
-                    and (o.filled or 0) > 0
-                    and o.status in NON_OPEN_EXCHANGE_STATES
-                    )
-                or (o.ft_is_open is True and o.status is not None)
-                ]
+        return [
+            o
+            for o in self.orders
+            if (
+                o.ft_is_open is False
+                and (o.filled or 0) > 0
+                and o.status in NON_OPEN_EXCHANGE_STATES
+            )
+            or (o.ft_is_open is True and o.status is not None)
+        ]
 
     def set_custom_data(self, key: str, value: Any) -> None:
         """
         Set custom data for this trade
         :param key: key of the custom data
         :param value: value of the custom data (must be JSON serializable)
         """
@@ -1270,39 +1369,42 @@
     def nr_of_successful_buys(self) -> int:
         """
         Helper function to count the number of buy orders that have been filled.
         WARNING: Please use nr_of_successful_entries for short support.
         :return: int count of buy orders that have been filled for this trade.
         """
 
-        return len(self.select_filled_orders('buy'))
+        return len(self.select_filled_orders("buy"))
 
     @property
     def nr_of_successful_sells(self) -> int:
         """
         Helper function to count the number of sell orders that have been filled.
         WARNING: Please use nr_of_successful_exits for short support.
         :return: int count of sell orders that have been filled for this trade.
         """
-        return len(self.select_filled_orders('sell'))
+        return len(self.select_filled_orders("sell"))
 
     @property
     def sell_reason(self) -> Optional[str]:
-        """ DEPRECATED! Please use exit_reason instead."""
+        """DEPRECATED! Please use exit_reason instead."""
         return self.exit_reason
 
     @property
     def safe_close_rate(self) -> float:
         return self.close_rate or self.close_rate_requested or 0.0
 
     @staticmethod
-    def get_trades_proxy(*, pair: Optional[str] = None, is_open: Optional[bool] = None,
-                         open_date: Optional[datetime] = None,
-                         close_date: Optional[datetime] = None,
-                         ) -> List['LocalTrade']:
+    def get_trades_proxy(
+        *,
+        pair: Optional[str] = None,
+        is_open: Optional[bool] = None,
+        open_date: Optional[datetime] = None,
+        close_date: Optional[datetime] = None,
+    ) -> List["LocalTrade"]:
         """
         Helper function to query Trades.
         Returns a List of trades, filtered on the parameters given.
         In live mode, converts the filter to a database query and returns all rows
         In Backtest mode, uses filters on Trade.trades to get the result.
 
         :param pair: Filter by pair
@@ -1325,16 +1427,17 @@
             sel_trades = list(LocalTrade.trades + LocalTrade.trades_open)
 
         if pair:
             sel_trades = [trade for trade in sel_trades if trade.pair == pair]
         if open_date:
             sel_trades = [trade for trade in sel_trades if trade.open_date > open_date]
         if close_date:
-            sel_trades = [trade for trade in sel_trades if trade.close_date
-                          and trade.close_date > close_date]
+            sel_trades = [
+                trade for trade in sel_trades if trade.close_date and trade.close_date > close_date
+            ]
 
         return sel_trades
 
     @staticmethod
     def close_bt_trade(trade):
         LocalTrade.trades_open.remove(trade)
         LocalTrade.bt_trades_open_pp[trade.pair].remove(trade)
@@ -1382,16 +1485,15 @@
         Adjust initial Stoploss to desired stoploss for all open trades.
         """
         trade: Trade
         for trade in Trade.get_open_trades():
             logger.info(f"Found open trade: {trade}")
 
             # skip case if trailing-stop changed the stoploss already.
-            if (not trade.is_stop_loss_trailing
-                    and trade.initial_stop_loss_pct != desired_stoploss):
+            if not trade.is_stop_loss_trailing and trade.initial_stop_loss_pct != desired_stoploss:
                 # Stoploss value got changed
 
                 logger.info(f"Stoploss for {trade} needs adjustment...")
                 # Force reset of stoploss
                 trade.stop_loss = 0.0
                 trade.initial_stop_loss_pct = None
                 trade.adjust_stop_loss(trade.open_rate, desired_stoploss)
@@ -1403,14 +1505,15 @@
         Create a Trade instance from a json string.
 
         Used for debugging purposes - please keep.
         :param json_str: json string to parse
         :return: Trade instance
         """
         import rapidjson
+
         data = rapidjson.loads(json_str)
         trade = cls(
             __FROM_JSON=True,
             id=data["trade_id"],
             pair=data["pair"],
             base_currency=data["base_currency"],
             stake_currency=data["quote_currency"],
@@ -1428,16 +1531,19 @@
             fee_close=data["fee_close"],
             fee_close_cost=data["fee_close_cost"],
             fee_close_currency=data["fee_close_currency"],
             open_date=datetime.fromtimestamp(data["open_timestamp"] // 1000, tz=timezone.utc),
             open_rate=data["open_rate"],
             open_rate_requested=data["open_rate_requested"],
             open_trade_value=data["open_trade_value"],
-            close_date=(datetime.fromtimestamp(data["close_timestamp"] // 1000, tz=timezone.utc)
-                        if data["close_timestamp"] else None),
+            close_date=(
+                datetime.fromtimestamp(data["close_timestamp"] // 1000, tz=timezone.utc)
+                if data["close_timestamp"]
+                else None
+            ),
             realized_profit=data["realized_profit"],
             close_rate=data["close_rate"],
             close_rate_requested=data["close_rate_requested"],
             close_profit=data["close_profit"],
             close_profit_abs=data["close_profit_abs"],
             exit_reason=data["exit_reason"],
             exit_order_status=data["exit_order_status"],
@@ -1449,36 +1555,37 @@
             max_rate=data["max_rate"],
             leverage=data["leverage"],
             interest_rate=data["interest_rate"],
             liquidation_price=data["liquidation_price"],
             is_short=data["is_short"],
             trading_mode=data["trading_mode"],
             funding_fees=data["funding_fees"],
-            amount_precision=data.get('amount_precision', None),
-            price_precision=data.get('price_precision', None),
-            precision_mode=data.get('precision_mode', None),
-            contract_size=data.get('contract_size', None),
+            amount_precision=data.get("amount_precision", None),
+            price_precision=data.get("price_precision", None),
+            precision_mode=data.get("precision_mode", None),
+            contract_size=data.get("contract_size", None),
         )
         for order in data["orders"]:
-
             order_obj = Order(
                 amount=order["amount"],
                 ft_amount=order["amount"],
                 ft_order_side=order["ft_order_side"],
                 ft_pair=order["pair"],
                 ft_is_open=order["is_open"],
                 order_id=order["order_id"],
                 status=order["status"],
                 average=order["average"],
                 cost=order["cost"],
                 filled=order["filled"],
                 order_date=datetime.strptime(order["order_date"], DATETIME_PRINT_FORMAT),
-                order_filled_date=(datetime.fromtimestamp(
-                    order["order_filled_timestamp"] // 1000, tz=timezone.utc)
-                    if order["order_filled_timestamp"] else None),
+                order_filled_date=(
+                    datetime.fromtimestamp(order["order_filled_timestamp"] // 1000, tz=timezone.utc)
+                    if order["order_filled_timestamp"]
+                    else None
+                ),
                 order_type=order["order_type"],
                 price=order["price"],
                 ft_price=order["price"],
                 remaining=order["remaining"],
                 funding_fee=order.get("funding_fee", None),
                 ft_order_tag=order.get("ft_order_tag", None),
             )
@@ -1490,127 +1597,146 @@
 class Trade(ModelBase, LocalTrade):
     """
     Trade database model.
     Also handles updating and querying trades
 
     Note: Fields must be aligned with LocalTrade class
     """
-    __tablename__ = 'trades'
+
+    __tablename__ = "trades"
     session: ClassVar[SessionType]
 
     use_db: bool = True
 
     id: Mapped[int] = mapped_column(Integer, primary_key=True)  # type: ignore
 
     orders: Mapped[List[Order]] = relationship(
-        "Order", order_by="Order.id", cascade="all, delete-orphan", lazy="selectin",
-        innerjoin=True)  # type: ignore
+        "Order", order_by="Order.id", cascade="all, delete-orphan", lazy="selectin", innerjoin=True
+    )  # type: ignore
     custom_data: Mapped[List[_CustomData]] = relationship(
-        "_CustomData", cascade="all, delete-orphan",
-        lazy="raise")
+        "_CustomData", cascade="all, delete-orphan", lazy="raise"
+    )
 
     exchange: Mapped[str] = mapped_column(String(25), nullable=False)  # type: ignore
     pair: Mapped[str] = mapped_column(String(25), nullable=False, index=True)  # type: ignore
     base_currency: Mapped[Optional[str]] = mapped_column(String(25), nullable=True)  # type: ignore
     stake_currency: Mapped[Optional[str]] = mapped_column(String(25), nullable=True)  # type: ignore
     is_open: Mapped[bool] = mapped_column(nullable=False, default=True, index=True)  # type: ignore
     fee_open: Mapped[float] = mapped_column(Float(), nullable=False, default=0.0)  # type: ignore
     fee_open_cost: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)  # type: ignore
-    fee_open_currency: Mapped[Optional[str]] = mapped_column(
-        String(25), nullable=True)  # type: ignore
-    fee_close: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=False, default=0.0)  # type: ignore
+    fee_open_currency: Mapped[Optional[str]] = mapped_column(  # type: ignore
+        String(25), nullable=True
+    )
+    fee_close: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=False, default=0.0
+    )
     fee_close_cost: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)  # type: ignore
-    fee_close_currency: Mapped[Optional[str]] = mapped_column(
-        String(25), nullable=True)  # type: ignore
+    fee_close_currency: Mapped[Optional[str]] = mapped_column(  # type: ignore
+        String(25), nullable=True
+    )
     open_rate: Mapped[float] = mapped_column(Float())  # type: ignore
-    open_rate_requested: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True)  # type: ignore
+    open_rate_requested: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True
+    )
     # open_trade_value - calculated via _calc_open_trade_value
     open_trade_value: Mapped[float] = mapped_column(Float(), nullable=True)  # type: ignore
     close_rate: Mapped[Optional[float]] = mapped_column(Float())  # type: ignore
     close_rate_requested: Mapped[Optional[float]] = mapped_column(Float())  # type: ignore
-    realized_profit: Mapped[float] = mapped_column(
-        Float(), default=0.0, nullable=True)  # type: ignore
+    realized_profit: Mapped[float] = mapped_column(  # type: ignore
+        Float(), default=0.0, nullable=True
+    )
     close_profit: Mapped[Optional[float]] = mapped_column(Float())  # type: ignore
     close_profit_abs: Mapped[Optional[float]] = mapped_column(Float())  # type: ignore
     stake_amount: Mapped[float] = mapped_column(Float(), nullable=False)  # type: ignore
     max_stake_amount: Mapped[Optional[float]] = mapped_column(Float())  # type: ignore
     amount: Mapped[float] = mapped_column(Float())  # type: ignore
     amount_requested: Mapped[Optional[float]] = mapped_column(Float())  # type: ignore
-    open_date: Mapped[datetime] = mapped_column(
-        nullable=False, default=datetime.now)  # type: ignore
+    open_date: Mapped[datetime] = mapped_column(  # type: ignore
+        nullable=False, default=datetime.now
+    )
     close_date: Mapped[Optional[datetime]] = mapped_column()  # type: ignore
     # absolute value of the stop loss
     stop_loss: Mapped[float] = mapped_column(Float(), nullable=True, default=0.0)  # type: ignore
     # percentage value of the stop loss
     stop_loss_pct: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)  # type: ignore
     # absolute value of the initial stop loss
-    initial_stop_loss: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True, default=0.0)  # type: ignore
+    initial_stop_loss: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True, default=0.0
+    )
     # percentage value of the initial stop loss
-    initial_stop_loss_pct: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True)  # type: ignore
-    is_stop_loss_trailing: Mapped[bool] = mapped_column(
-        nullable=False, default=False)  # type: ignore
+    initial_stop_loss_pct: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True
+    )
+    is_stop_loss_trailing: Mapped[bool] = mapped_column(  # type: ignore
+        nullable=False, default=False
+    )
     # absolute value of the highest reached price
-    max_rate: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True, default=0.0)  # type: ignore
+    max_rate: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True, default=0.0
+    )
     # Lowest price reached
     min_rate: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)  # type: ignore
-    exit_reason: Mapped[Optional[str]] = mapped_column(
-        String(CUSTOM_TAG_MAX_LENGTH), nullable=True)  # type: ignore
-    exit_order_status: Mapped[Optional[str]] = mapped_column(
-        String(100), nullable=True)  # type: ignore
+    exit_reason: Mapped[Optional[str]] = mapped_column(  # type: ignore
+        String(CUSTOM_TAG_MAX_LENGTH), nullable=True
+    )
+    exit_order_status: Mapped[Optional[str]] = mapped_column(  # type: ignore
+        String(100), nullable=True
+    )
     strategy: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)  # type: ignore
-    enter_tag: Mapped[Optional[str]] = mapped_column(
-        String(CUSTOM_TAG_MAX_LENGTH), nullable=True)  # type: ignore
+    enter_tag: Mapped[Optional[str]] = mapped_column(  # type: ignore
+        String(CUSTOM_TAG_MAX_LENGTH), nullable=True
+    )
     timeframe: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)  # type: ignore
 
-    trading_mode: Mapped[TradingMode] = mapped_column(
-        Enum(TradingMode), nullable=True)  # type: ignore
-    amount_precision: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True)  # type: ignore
+    trading_mode: Mapped[TradingMode] = mapped_column(  # type: ignore
+        Enum(TradingMode), nullable=True
+    )
+    amount_precision: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True
+    )
     price_precision: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)  # type: ignore
     precision_mode: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)  # type: ignore
     contract_size: Mapped[Optional[float]] = mapped_column(Float(), nullable=True)  # type: ignore
 
     # Leverage trading properties
     leverage: Mapped[float] = mapped_column(Float(), nullable=True, default=1.0)  # type: ignore
     is_short: Mapped[bool] = mapped_column(nullable=False, default=False)  # type: ignore
-    liquidation_price: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True)  # type: ignore
+    liquidation_price: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True
+    )
 
     # Margin Trading Properties
-    interest_rate: Mapped[float] = mapped_column(
-        Float(), nullable=False, default=0.0)  # type: ignore
+    interest_rate: Mapped[float] = mapped_column(  # type: ignore
+        Float(), nullable=False, default=0.0
+    )
 
     # Futures properties
-    funding_fees: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True, default=None)  # type: ignore
-    funding_fee_running: Mapped[Optional[float]] = mapped_column(
-        Float(), nullable=True, default=None)  # type: ignore
+    funding_fees: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True, default=None
+    )
+    funding_fee_running: Mapped[Optional[float]] = mapped_column(  # type: ignore
+        Float(), nullable=True, default=None
+    )
 
     def __init__(self, **kwargs):
-        from_json = kwargs.pop('__FROM_JSON', None)
+        from_json = kwargs.pop("__FROM_JSON", None)
         super().__init__(**kwargs)
         if not from_json:
             # Skip recalculation when loading from json
             self.realized_profit = 0
             self.recalc_open_trade_value()
 
-    @validates('enter_tag', 'exit_reason')
+    @validates("enter_tag", "exit_reason")
     def validate_string_len(self, key, value):
         max_len = getattr(self.__class__, key).prop.columns[0].type.length
         if value and len(value) > max_len:
             return value[:max_len]
         return value
 
     def delete(self) -> None:
-
         for order in self.orders:
             Order.session.delete(order)
 
         CustomDataWrapper.delete_custom_data(trade_id=self.id)
 
         Trade.session.delete(self)
         Trade.commit()
@@ -1620,18 +1746,21 @@
         Trade.session.commit()
 
     @staticmethod
     def rollback():
         Trade.session.rollback()
 
     @staticmethod
-    def get_trades_proxy(*, pair: Optional[str] = None, is_open: Optional[bool] = None,
-                         open_date: Optional[datetime] = None,
-                         close_date: Optional[datetime] = None,
-                         ) -> List['LocalTrade']:
+    def get_trades_proxy(
+        *,
+        pair: Optional[str] = None,
+        is_open: Optional[bool] = None,
+        open_date: Optional[datetime] = None,
+        close_date: Optional[datetime] = None,
+    ) -> List["LocalTrade"]:
         """
         Helper function to query Trades.j
         Returns a List of trades, filtered on the parameters given.
         In live mode, converts the filter to a database query and returns all rows
         In Backtest mode, uses filters on Trade.trades to get the result.
 
         :return: unsorted List[Trade]
@@ -1645,46 +1774,44 @@
             if close_date:
                 trade_filter.append(Trade.close_date > close_date)
             if is_open is not None:
                 trade_filter.append(Trade.is_open.is_(is_open))
             return cast(List[LocalTrade], Trade.get_trades(trade_filter).all())
         else:
             return LocalTrade.get_trades_proxy(
-                pair=pair, is_open=is_open,
-                open_date=open_date,
-                close_date=close_date
+                pair=pair, is_open=is_open, open_date=open_date, close_date=close_date
             )
 
     @staticmethod
     def get_trades_query(trade_filter=None, include_orders: bool = True) -> Select:
         """
         Helper function to query Trades using filters.
         NOTE: Not supported in Backtesting.
         :param trade_filter: Optional filter to apply to trades
                              Can be either a Filter object, or a List of filters
                              e.g. `(trade_filter=[Trade.id == trade_id, Trade.is_open.is_(True),])`
                              e.g. `(trade_filter=Trade.id == trade_id)`
         :return: unsorted query object
         """
         if not Trade.use_db:
-            raise NotImplementedError('`Trade.get_trades()` not supported in backtesting mode.')
+            raise NotImplementedError("`Trade.get_trades()` not supported in backtesting mode.")
         if trade_filter is not None:
             if not isinstance(trade_filter, list):
                 trade_filter = [trade_filter]
             this_query = select(Trade).filter(*trade_filter)
         else:
             this_query = select(Trade)
         if not include_orders:
             # Don't load order relations
             # Consider using noload or raiseload instead of lazyload
             this_query = this_query.options(lazyload(Trade.orders))
         return this_query
 
     @staticmethod
-    def get_trades(trade_filter=None, include_orders: bool = True) -> ScalarResult['Trade']:
+    def get_trades(trade_filter=None, include_orders: bool = True) -> ScalarResult["Trade"]:
         """
         Helper function to query Trades using filters.
         NOTE: Not supported in Backtesting.
         :param trade_filter: Optional filter to apply to trades
                              Can be either a Filter object, or a List of filters
                              e.g. `(trade_filter=[Trade.id == trade_id, Trade.is_open.is_(True),])`
                              e.g. `(trade_filter=Trade.id == trade_id)`
@@ -1697,57 +1824,66 @@
 
     @staticmethod
     def get_open_trades_without_assigned_fees():
         """
         Returns all open trades which don't have open fees set correctly
         NOTE: Not supported in Backtesting.
         """
-        return Trade.get_trades([Trade.fee_open_currency.is_(None),
-                                 Trade.orders.any(),
-                                 Trade.is_open.is_(True),
-                                 ]).all()
+        return Trade.get_trades(
+            [
+                Trade.fee_open_currency.is_(None),
+                Trade.orders.any(),
+                Trade.is_open.is_(True),
+            ]
+        ).all()
 
     @staticmethod
     def get_closed_trades_without_assigned_fees():
         """
         Returns all closed trades which don't have fees set correctly
         NOTE: Not supported in Backtesting.
         """
-        return Trade.get_trades([Trade.fee_close_currency.is_(None),
-                                 Trade.orders.any(),
-                                 Trade.is_open.is_(False),
-                                 ]).all()
+        return Trade.get_trades(
+            [
+                Trade.fee_close_currency.is_(None),
+                Trade.orders.any(),
+                Trade.is_open.is_(False),
+            ]
+        ).all()
 
     @staticmethod
     def get_total_closed_profit() -> float:
         """
         Retrieves total realized profit
         """
         if Trade.use_db:
             total_profit = Trade.session.execute(
                 select(func.sum(Trade.close_profit_abs)).filter(Trade.is_open.is_(False))
             ).scalar_one()
         else:
-            total_profit = sum(t.close_profit_abs  # type: ignore
-                               for t in LocalTrade.get_trades_proxy(is_open=False))
+            total_profit = sum(
+                t.close_profit_abs  # type: ignore
+                for t in LocalTrade.get_trades_proxy(is_open=False)
+            )
         return total_profit or 0
 
     @staticmethod
     def total_open_trades_stakes() -> float:
         """
         Calculates total invested amount in open trades
         in stake currency
         """
         if Trade.use_db:
             total_open_stake_amount = Trade.session.scalar(
                 select(func.sum(Trade.stake_amount)).filter(Trade.is_open.is_(True))
             )
         else:
             total_open_stake_amount = sum(
-                t.stake_amount for t in LocalTrade.get_trades_proxy(is_open=True))
+                t.stake_amount for t in LocalTrade.get_trades_proxy(is_open=True)
+            )
         return total_open_stake_amount or 0
 
     @staticmethod
     def get_overall_performance(minutes=None) -> List[Dict[str, Any]]:
         """
         Returns List of dicts containing all Trades, including profit and trade count
         NOTE: Not supported in Backtesting.
@@ -1756,179 +1892,188 @@
         if minutes:
             start_date = datetime.now(timezone.utc) - timedelta(minutes=minutes)
             filters.append(Trade.close_date >= start_date)
 
         pair_rates = Trade.session.execute(
             select(
                 Trade.pair,
-                func.sum(Trade.close_profit).label('profit_sum'),
-                func.sum(Trade.close_profit_abs).label('profit_sum_abs'),
-                func.count(Trade.pair).label('count')
-            ).filter(*filters)
+                func.sum(Trade.close_profit).label("profit_sum"),
+                func.sum(Trade.close_profit_abs).label("profit_sum_abs"),
+                func.count(Trade.pair).label("count"),
+            )
+            .filter(*filters)
             .group_by(Trade.pair)
-            .order_by(desc('profit_sum_abs'))
-            ).all()
+            .order_by(desc("profit_sum_abs"))
+        ).all()
 
         return [
             {
-                'pair': pair,
-                'profit_ratio': profit,
-                'profit': round(profit * 100, 2),  # Compatibility mode
-                'profit_pct': round(profit * 100, 2),
-                'profit_abs': profit_abs,
-                'count': count
+                "pair": pair,
+                "profit_ratio": profit,
+                "profit": round(profit * 100, 2),  # Compatibility mode
+                "profit_pct": round(profit * 100, 2),
+                "profit_abs": profit_abs,
+                "count": count,
             }
             for pair, profit, profit_abs, count in pair_rates
         ]
 
     @staticmethod
     def get_enter_tag_performance(pair: Optional[str]) -> List[Dict[str, Any]]:
         """
         Returns List of dicts containing all Trades, based on buy tag performance
         Can either be average for all pairs or a specific pair provided
         NOTE: Not supported in Backtesting.
         """
 
         filters: List = [Trade.is_open.is_(False)]
-        if (pair is not None):
+        if pair is not None:
             filters.append(Trade.pair == pair)
 
         enter_tag_perf = Trade.session.execute(
             select(
                 Trade.enter_tag,
-                func.sum(Trade.close_profit).label('profit_sum'),
-                func.sum(Trade.close_profit_abs).label('profit_sum_abs'),
-                func.count(Trade.pair).label('count')
-            ).filter(*filters)
+                func.sum(Trade.close_profit).label("profit_sum"),
+                func.sum(Trade.close_profit_abs).label("profit_sum_abs"),
+                func.count(Trade.pair).label("count"),
+            )
+            .filter(*filters)
             .group_by(Trade.enter_tag)
-            .order_by(desc('profit_sum_abs'))
+            .order_by(desc("profit_sum_abs"))
         ).all()
 
         return [
             {
-                'enter_tag': enter_tag if enter_tag is not None else "Other",
-                'profit_ratio': profit,
-                'profit_pct': round(profit * 100, 2),
-                'profit_abs': profit_abs,
-                'count': count
+                "enter_tag": enter_tag if enter_tag is not None else "Other",
+                "profit_ratio": profit,
+                "profit_pct": round(profit * 100, 2),
+                "profit_abs": profit_abs,
+                "count": count,
             }
             for enter_tag, profit, profit_abs, count in enter_tag_perf
         ]
 
     @staticmethod
     def get_exit_reason_performance(pair: Optional[str]) -> List[Dict[str, Any]]:
         """
         Returns List of dicts containing all Trades, based on exit reason performance
         Can either be average for all pairs or a specific pair provided
         NOTE: Not supported in Backtesting.
         """
 
         filters: List = [Trade.is_open.is_(False)]
-        if (pair is not None):
+        if pair is not None:
             filters.append(Trade.pair == pair)
         sell_tag_perf = Trade.session.execute(
             select(
                 Trade.exit_reason,
-                func.sum(Trade.close_profit).label('profit_sum'),
-                func.sum(Trade.close_profit_abs).label('profit_sum_abs'),
-                func.count(Trade.pair).label('count')
-            ).filter(*filters)
+                func.sum(Trade.close_profit).label("profit_sum"),
+                func.sum(Trade.close_profit_abs).label("profit_sum_abs"),
+                func.count(Trade.pair).label("count"),
+            )
+            .filter(*filters)
             .group_by(Trade.exit_reason)
-            .order_by(desc('profit_sum_abs'))
+            .order_by(desc("profit_sum_abs"))
         ).all()
 
         return [
             {
-                'exit_reason': exit_reason if exit_reason is not None else "Other",
-                'profit_ratio': profit,
-                'profit_pct': round(profit * 100, 2),
-                'profit_abs': profit_abs,
-                'count': count
+                "exit_reason": exit_reason if exit_reason is not None else "Other",
+                "profit_ratio": profit,
+                "profit_pct": round(profit * 100, 2),
+                "profit_abs": profit_abs,
+                "count": count,
             }
             for exit_reason, profit, profit_abs, count in sell_tag_perf
         ]
 
     @staticmethod
     def get_mix_tag_performance(pair: Optional[str]) -> List[Dict[str, Any]]:
         """
         Returns List of dicts containing all Trades, based on entry_tag + exit_reason performance
         Can either be average for all pairs or a specific pair provided
         NOTE: Not supported in Backtesting.
         """
 
         filters: List = [Trade.is_open.is_(False)]
-        if (pair is not None):
+        if pair is not None:
             filters.append(Trade.pair == pair)
         mix_tag_perf = Trade.session.execute(
             select(
                 Trade.id,
                 Trade.enter_tag,
                 Trade.exit_reason,
-                func.sum(Trade.close_profit).label('profit_sum'),
-                func.sum(Trade.close_profit_abs).label('profit_sum_abs'),
-                func.count(Trade.pair).label('count')
-            ).filter(*filters)
+                func.sum(Trade.close_profit).label("profit_sum"),
+                func.sum(Trade.close_profit_abs).label("profit_sum_abs"),
+                func.count(Trade.pair).label("count"),
+            )
+            .filter(*filters)
             .group_by(Trade.id)
-            .order_by(desc('profit_sum_abs'))
+            .order_by(desc("profit_sum_abs"))
         ).all()
 
         resp: List[Dict] = []
         for id, enter_tag, exit_reason, profit, profit_abs, count in mix_tag_perf:
             enter_tag = enter_tag if enter_tag is not None else "Other"
             exit_reason = exit_reason if exit_reason is not None else "Other"
 
-            if (exit_reason is not None and enter_tag is not None):
+            if exit_reason is not None and enter_tag is not None:
                 mix_tag = enter_tag + " " + exit_reason
                 i = 0
                 if not any(item["mix_tag"] == mix_tag for item in resp):
-                    resp.append({'mix_tag': mix_tag,
-                                 'profit_ratio': profit,
-                                 'profit_pct': round(profit * 100, 2),
-                                 'profit_abs': profit_abs,
-                                 'count': count})
+                    resp.append(
+                        {
+                            "mix_tag": mix_tag,
+                            "profit_ratio": profit,
+                            "profit_pct": round(profit * 100, 2),
+                            "profit_abs": profit_abs,
+                            "count": count,
+                        }
+                    )
                 else:
                     while i < len(resp):
                         if resp[i]["mix_tag"] == mix_tag:
                             resp[i] = {
-                                'mix_tag': mix_tag,
-                                'profit_ratio': profit + resp[i]["profit_ratio"],
-                                'profit_pct': round(profit + resp[i]["profit_ratio"] * 100, 2),
-                                'profit_abs': profit_abs + resp[i]["profit_abs"],
-                                'count': 1 + resp[i]["count"]
+                                "mix_tag": mix_tag,
+                                "profit_ratio": profit + resp[i]["profit_ratio"],
+                                "profit_pct": round(profit + resp[i]["profit_ratio"] * 100, 2),
+                                "profit_abs": profit_abs + resp[i]["profit_abs"],
+                                "count": 1 + resp[i]["count"],
                             }
                         i += 1
 
         return resp
 
     @staticmethod
-    def get_best_pair(start_date: datetime = datetime.fromtimestamp(0)):
+    def get_best_pair(start_date: Optional[datetime] = None):
         """
         Get best pair with closed trade.
         NOTE: Not supported in Backtesting.
         :returns: Tuple containing (pair, profit_sum)
         """
+        filters: List = [Trade.is_open.is_(False)]
+        if start_date:
+            filters.append(Trade.close_date >= start_date)
+
         best_pair = Trade.session.execute(
-            select(
-                Trade.pair,
-                func.sum(Trade.close_profit).label('profit_sum')
-            ).filter(Trade.is_open.is_(False) & (Trade.close_date >= start_date))
+            select(Trade.pair, func.sum(Trade.close_profit).label("profit_sum"))
+            .filter(*filters)
             .group_by(Trade.pair)
-            .order_by(desc('profit_sum'))
+            .order_by(desc("profit_sum"))
         ).first()
 
         return best_pair
 
     @staticmethod
-    def get_trading_volume(start_date: datetime = datetime.fromtimestamp(0)) -> float:
+    def get_trading_volume(start_date: Optional[datetime] = None) -> float:
         """
         Get Trade volume based on Orders
         NOTE: Not supported in Backtesting.
         :returns: Tuple containing (pair, profit_sum)
         """
+        filters = [Order.status == "closed"]
+        if start_date:
+            filters.append(Order.order_filled_date >= start_date)
         trading_volume = Trade.session.execute(
-            select(
-                func.sum(Order.cost).label('volume')
-            ).filter(
-                Order.order_filled_date >= start_date,
-                Order.status == 'closed'
-            )).scalar_one()
+            select(func.sum(Order.cost).label("volume")).filter(*filters)
+        ).scalar_one()
         return trading_volume or 0.0
```

### Comparing `freqtrade-2024.4/freqtrade/persistence/usedb_context.py` & `freqtrade-2024.5/freqtrade/persistence/usedb_context.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 from freqtrade.persistence.custom_data import CustomDataWrapper
 from freqtrade.persistence.pairlock_middleware import PairLocks
 from freqtrade.persistence.trade_model import Trade
 
 
 def disable_database_use(timeframe: str) -> None:
     """
@@ -16,21 +15,21 @@
 
 
 def enable_database_use() -> None:
     """
     Cleanup function to restore database usage.
     """
     PairLocks.use_db = True
-    PairLocks.timeframe = ''
+    PairLocks.timeframe = ""
     Trade.use_db = True
     CustomDataWrapper.use_db = True
 
 
 class FtNoDBContext:
-    def __init__(self, timeframe: str = ''):
+    def __init__(self, timeframe: str = ""):
         self.timeframe = timeframe
 
     def __enter__(self):
         disable_database_use(self.timeframe)
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         enable_database_use()
```

### Comparing `freqtrade-2024.4/freqtrade/plot/plotting.py` & `freqtrade-2024.5/freqtrade/plot/plotting.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,21 +3,28 @@
 from pathlib import Path
 from typing import Dict, List, Optional
 
 import pandas as pd
 
 from freqtrade.configuration import TimeRange
 from freqtrade.constants import Config
-from freqtrade.data.btanalysis import (analyze_trade_parallelism, extract_trades_of_period,
-                                       load_trades)
+from freqtrade.data.btanalysis import (
+    analyze_trade_parallelism,
+    extract_trades_of_period,
+    load_trades,
+)
 from freqtrade.data.converter import trim_dataframe
 from freqtrade.data.dataprovider import DataProvider
 from freqtrade.data.history import get_timerange, load_data
-from freqtrade.data.metrics import (calculate_max_drawdown, calculate_underwater,
-                                    combine_dataframes_with_mean, create_cum_profit)
+from freqtrade.data.metrics import (
+    calculate_max_drawdown,
+    calculate_underwater,
+    combine_dataframes_with_mean,
+    create_cum_profit,
+)
 from freqtrade.enums import CandleType
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange import timeframe_to_prev_date, timeframe_to_seconds
 from freqtrade.misc import pair_to_filename
 from freqtrade.plugins.pairlist.pairlist_helpers import expand_pairlist
 from freqtrade.resolvers import ExchangeResolver, StrategyResolver
 from freqtrade.strategy import IStrategy
@@ -39,107 +46,111 @@
 def init_plotscript(config, markets: List, startup_candles: int = 0):
     """
     Initialize objects needed for plotting
     :return: Dict with candle (OHLCV) data, trades and pairs
     """
 
     if "pairs" in config:
-        pairs = expand_pairlist(config['pairs'], markets)
+        pairs = expand_pairlist(config["pairs"], markets)
     else:
-        pairs = expand_pairlist(config['exchange']['pair_whitelist'], markets)
+        pairs = expand_pairlist(config["exchange"]["pair_whitelist"], markets)
 
     # Set timerange to use
-    timerange = TimeRange.parse_timerange(config.get('timerange'))
+    timerange = TimeRange.parse_timerange(config.get("timerange"))
 
     data = load_data(
-        datadir=config.get('datadir'),
+        datadir=config.get("datadir"),
         pairs=pairs,
-        timeframe=config['timeframe'],
+        timeframe=config["timeframe"],
         timerange=timerange,
         startup_candles=startup_candles,
-        data_format=config['dataformat_ohlcv'],
-        candle_type=config.get('candle_type_def', CandleType.SPOT)
+        data_format=config["dataformat_ohlcv"],
+        candle_type=config.get("candle_type_def", CandleType.SPOT),
     )
 
     if startup_candles and data:
         min_date, max_date = get_timerange(data)
         logger.info(f"Loading data from {min_date} to {max_date}")
-        timerange.adjust_start_if_necessary(timeframe_to_seconds(config['timeframe']),
-                                            startup_candles, min_date)
+        timerange.adjust_start_if_necessary(
+            timeframe_to_seconds(config["timeframe"]), startup_candles, min_date
+        )
 
     no_trades = False
     filename = config.get("exportfilename")
     if config.get("no_trades", False):
         no_trades = True
-    elif config['trade_source'] == 'file':
+    elif config["trade_source"] == "file":
         if not filename.is_dir() and not filename.is_file():
             logger.warning("Backtest file is missing skipping trades.")
             no_trades = True
     try:
         trades = load_trades(
-            config['trade_source'],
-            db_url=config.get('db_url'),
+            config["trade_source"],
+            db_url=config.get("db_url"),
             exportfilename=filename,
             no_trades=no_trades,
-            strategy=config.get('strategy'),
+            strategy=config.get("strategy"),
         )
     except ValueError as e:
         raise OperationalException(e) from e
     if not trades.empty:
-        trades = trim_dataframe(trades, timerange, df_date_col='open_date')
+        trades = trim_dataframe(trades, timerange, df_date_col="open_date")
 
-    return {"ohlcv": data,
-            "trades": trades,
-            "pairs": pairs,
-            "timerange": timerange,
-            }
+    return {
+        "ohlcv": data,
+        "trades": trades,
+        "pairs": pairs,
+        "timerange": timerange,
+    }
 
 
 def add_indicators(fig, row, indicators: Dict[str, Dict], data: pd.DataFrame) -> make_subplots:
     """
     Generate all the indicators selected by the user for a specific row, based on the configuration
     :param fig: Plot figure to append to
     :param row: row number for this plot
     :param indicators: Dict of Indicators with configuration options.
                        Dict key must correspond to dataframe column.
     :param data: candlestick DataFrame
     """
     plot_kinds = {
-        'scatter': go.Scatter,
-        'bar': go.Bar,
+        "scatter": go.Scatter,
+        "bar": go.Bar,
     }
     for indicator, conf in indicators.items():
         logger.debug(f"indicator {indicator} with config {conf}")
         if indicator in data:
-            kwargs = {'x': data['date'],
-                      'y': data[indicator].values,
-                      'name': indicator
-                      }
-
-            plot_type = conf.get('type', 'scatter')
-            color = conf.get('color')
-            if plot_type == 'bar':
-                kwargs.update({'marker_color': color or 'DarkSlateGrey',
-                               'marker_line_color': color or 'DarkSlateGrey'})
+            kwargs = {"x": data["date"], "y": data[indicator].values, "name": indicator}
+
+            plot_type = conf.get("type", "scatter")
+            color = conf.get("color")
+            if plot_type == "bar":
+                kwargs.update(
+                    {
+                        "marker_color": color or "DarkSlateGrey",
+                        "marker_line_color": color or "DarkSlateGrey",
+                    }
+                )
             else:
                 if color:
-                    kwargs.update({'line': {'color': color}})
-                kwargs['mode'] = 'lines'
-                if plot_type != 'scatter':
-                    logger.warning(f'Indicator {indicator} has unknown plot trace kind {plot_type}'
-                                   f', assuming "scatter".')
+                    kwargs.update({"line": {"color": color}})
+                kwargs["mode"] = "lines"
+                if plot_type != "scatter":
+                    logger.warning(
+                        f"Indicator {indicator} has unknown plot trace kind {plot_type}"
+                        f', assuming "scatter".'
+                    )
 
-            kwargs.update(conf.get('plotly', {}))
+            kwargs.update(conf.get("plotly", {}))
             trace = plot_kinds[plot_type](**kwargs)
             fig.add_trace(trace, row, 1)
         else:
             logger.info(
-                'Indicator "%s" ignored. Reason: This indicator is not found '
-                'in your strategy.',
-                indicator
+                'Indicator "%s" ignored. Reason: This indicator is not found ' "in your strategy.",
+                indicator,
             )
 
     return fig
 
 
 def add_profit(fig, row, data: pd.DataFrame, column: str, name: str) -> make_subplots:
     """
@@ -157,75 +168,65 @@
         name=name,
     )
     fig.add_trace(profit, row, 1)
 
     return fig
 
 
-def add_max_drawdown(fig, row, trades: pd.DataFrame, df_comb: pd.DataFrame,
-                     timeframe: str, starting_balance: float) -> make_subplots:
+def add_max_drawdown(
+    fig, row, trades: pd.DataFrame, df_comb: pd.DataFrame, timeframe: str, starting_balance: float
+) -> make_subplots:
     """
     Add scatter points indicating max drawdown
     """
     try:
-        _, highdate, lowdate, _, _, max_drawdown = calculate_max_drawdown(
-            trades,
-            starting_balance=starting_balance
-        )
+        drawdown = calculate_max_drawdown(trades, starting_balance=starting_balance)
 
         drawdown = go.Scatter(
-            x=[highdate, lowdate],
+            x=[drawdown.high_date, drawdown.low_date],
             y=[
-                df_comb.loc[timeframe_to_prev_date(timeframe, highdate), 'cum_profit'],
-                df_comb.loc[timeframe_to_prev_date(timeframe, lowdate), 'cum_profit'],
+                df_comb.loc[timeframe_to_prev_date(timeframe, drawdown.high_date), "cum_profit"],
+                df_comb.loc[timeframe_to_prev_date(timeframe, drawdown.low_date), "cum_profit"],
             ],
-            mode='markers',
-            name=f"Max drawdown {max_drawdown:.2%}",
-            text=f"Max drawdown {max_drawdown:.2%}",
-            marker=dict(
-                symbol='square-open',
-                size=9,
-                line=dict(width=2),
-                color='green'
-
-            )
+            mode="markers",
+            name=f"Max drawdown {drawdown.relative_account_drawdown:.2%}",
+            text=f"Max drawdown {drawdown.relative_account_drawdown:.2%}",
+            marker=dict(symbol="square-open", size=9, line=dict(width=2), color="green"),
         )
         fig.add_trace(drawdown, row, 1)
     except ValueError:
         logger.warning("No trades found - not plotting max drawdown.")
     return fig
 
 
 def add_underwater(fig, row, trades: pd.DataFrame, starting_balance: float) -> make_subplots:
     """
     Add underwater plots
     """
     try:
         underwater = calculate_underwater(
-            trades,
-            value_col="profit_abs",
-            starting_balance=starting_balance
+            trades, value_col="profit_abs", starting_balance=starting_balance
         )
 
         underwater_plot = go.Scatter(
-            x=underwater['date'],
-            y=underwater['drawdown'],
+            x=underwater["date"],
+            y=underwater["drawdown"],
             name="Underwater Plot",
-            fill='tozeroy',
-            fillcolor='#cc362b',
-            line={'color': '#cc362b'}
+            fill="tozeroy",
+            fillcolor="#cc362b",
+            line={"color": "#cc362b"},
         )
 
         underwater_plot_relative = go.Scatter(
-            x=underwater['date'],
-            y=(-underwater['drawdown_relative']),
+            x=underwater["date"],
+            y=(-underwater["drawdown_relative"]),
             name="Underwater Plot (%)",
-            fill='tozeroy',
-            fillcolor='green',
-            line={'color': 'green'}
+            fill="tozeroy",
+            fillcolor="green",
+            line={"color": "green"},
         )
 
         fig.add_trace(underwater_plot, row, 1)
         fig.add_trace(underwater_plot_relative, row + 1, 1)
     except ValueError:
         logger.warning("No trades found - not plotting underwater plot")
     return fig
@@ -236,217 +237,211 @@
     Add Chart showing trade parallelism
     """
     try:
         result = analyze_trade_parallelism(trades, timeframe)
 
         drawdown = go.Scatter(
             x=result.index,
-            y=result['open_trades'],
+            y=result["open_trades"],
             name="Parallel trades",
-            fill='tozeroy',
-            fillcolor='#242222',
-            line={'color': '#242222'},
+            fill="tozeroy",
+            fillcolor="#242222",
+            line={"color": "#242222"},
         )
         fig.add_trace(drawdown, row, 1)
     except ValueError:
         logger.warning("No trades found - not plotting Parallelism.")
     return fig
 
 
 def plot_trades(fig, trades: pd.DataFrame) -> make_subplots:
     """
     Add trades to "fig"
     """
     # Trades can be empty
     if trades is not None and len(trades) > 0:
         # Create description for exit summarizing the trade
-        trades['desc'] = trades.apply(
-            lambda row: f"{row['profit_ratio']:.2%}, " +
-            (f"{row['enter_tag']}, " if row['enter_tag'] is not None else "") +
-            f"{row['exit_reason']}, " +
-            f"{row['trade_duration']} min",
-            axis=1)
+        trades["desc"] = trades.apply(
+            lambda row: f"{row['profit_ratio']:.2%}, "
+            + (f"{row['enter_tag']}, " if row["enter_tag"] is not None else "")
+            + f"{row['exit_reason']}, "
+            + f"{row['trade_duration']} min",
+            axis=1,
+        )
         trade_entries = go.Scatter(
             x=trades["open_date"],
             y=trades["open_rate"],
-            mode='markers',
-            name='Trade entry',
+            mode="markers",
+            name="Trade entry",
             text=trades["desc"],
-            marker=dict(
-                symbol='circle-open',
-                size=11,
-                line=dict(width=2),
-                color='cyan'
-
-            )
+            marker=dict(symbol="circle-open", size=11, line=dict(width=2), color="cyan"),
         )
 
         trade_exits = go.Scatter(
-            x=trades.loc[trades['profit_ratio'] > 0, "close_date"],
-            y=trades.loc[trades['profit_ratio'] > 0, "close_rate"],
-            text=trades.loc[trades['profit_ratio'] > 0, "desc"],
-            mode='markers',
-            name='Exit - Profit',
-            marker=dict(
-                symbol='square-open',
-                size=11,
-                line=dict(width=2),
-                color='green'
-            )
+            x=trades.loc[trades["profit_ratio"] > 0, "close_date"],
+            y=trades.loc[trades["profit_ratio"] > 0, "close_rate"],
+            text=trades.loc[trades["profit_ratio"] > 0, "desc"],
+            mode="markers",
+            name="Exit - Profit",
+            marker=dict(symbol="square-open", size=11, line=dict(width=2), color="green"),
         )
         trade_exits_loss = go.Scatter(
-            x=trades.loc[trades['profit_ratio'] <= 0, "close_date"],
-            y=trades.loc[trades['profit_ratio'] <= 0, "close_rate"],
-            text=trades.loc[trades['profit_ratio'] <= 0, "desc"],
-            mode='markers',
-            name='Exit - Loss',
-            marker=dict(
-                symbol='square-open',
-                size=11,
-                line=dict(width=2),
-                color='red'
-            )
+            x=trades.loc[trades["profit_ratio"] <= 0, "close_date"],
+            y=trades.loc[trades["profit_ratio"] <= 0, "close_rate"],
+            text=trades.loc[trades["profit_ratio"] <= 0, "desc"],
+            mode="markers",
+            name="Exit - Loss",
+            marker=dict(symbol="square-open", size=11, line=dict(width=2), color="red"),
         )
         fig.add_trace(trade_entries, 1, 1)
         fig.add_trace(trade_exits, 1, 1)
         fig.add_trace(trade_exits_loss, 1, 1)
     else:
         logger.warning("No trades found.")
     return fig
 
 
-def create_plotconfig(indicators1: List[str], indicators2: List[str],
-                      plot_config: Dict[str, Dict]) -> Dict[str, Dict]:
+def create_plotconfig(
+    indicators1: List[str], indicators2: List[str], plot_config: Dict[str, Dict]
+) -> Dict[str, Dict]:
     """
     Combines indicators 1 and indicators 2 into plot_config if necessary
     :param indicators1: List containing Main plot indicators
     :param indicators2: List containing Sub plot indicators
     :param plot_config: Dict of Dicts containing advanced plot configuration
     :return: plot_config - eventually with indicators 1 and 2
     """
 
     if plot_config:
         if indicators1:
-            plot_config['main_plot'] = {ind: {} for ind in indicators1}
+            plot_config["main_plot"] = {ind: {} for ind in indicators1}
         if indicators2:
-            plot_config['subplots'] = {'Other': {ind: {} for ind in indicators2}}
+            plot_config["subplots"] = {"Other": {ind: {} for ind in indicators2}}
 
     if not plot_config:
         # If no indicators and no plot-config given, use defaults.
         if not indicators1:
-            indicators1 = ['sma', 'ema3', 'ema5']
+            indicators1 = ["sma", "ema3", "ema5"]
         if not indicators2:
-            indicators2 = ['macd', 'macdsignal']
+            indicators2 = ["macd", "macdsignal"]
 
         # Create subplot configuration if plot_config is not available.
         plot_config = {
-            'main_plot': {ind: {} for ind in indicators1},
-            'subplots': {'Other': {ind: {} for ind in indicators2}},
+            "main_plot": {ind: {} for ind in indicators1},
+            "subplots": {"Other": {ind: {} for ind in indicators2}},
         }
-    if 'main_plot' not in plot_config:
-        plot_config['main_plot'] = {}
+    if "main_plot" not in plot_config:
+        plot_config["main_plot"] = {}
 
-    if 'subplots' not in plot_config:
-        plot_config['subplots'] = {}
+    if "subplots" not in plot_config:
+        plot_config["subplots"] = {}
     return plot_config
 
 
-def plot_area(fig, row: int, data: pd.DataFrame, indicator_a: str,
-              indicator_b: str, label: str = "",
-              fill_color: str = "rgba(0,176,246,0.2)") -> make_subplots:
-    """ Creates a plot for the area between two traces and adds it to fig.
+def plot_area(
+    fig,
+    row: int,
+    data: pd.DataFrame,
+    indicator_a: str,
+    indicator_b: str,
+    label: str = "",
+    fill_color: str = "rgba(0,176,246,0.2)",
+) -> make_subplots:
+    """Creates a plot for the area between two traces and adds it to fig.
     :param fig: Plot figure to append to
     :param row: row number for this plot
     :param data: candlestick DataFrame
     :param indicator_a: indicator name as populated in strategy
     :param indicator_b: indicator name as populated in strategy
     :param label: label for the filled area
     :param fill_color: color to be used for the filled area
     :return: fig with added  filled_traces plot
     """
     if indicator_a in data and indicator_b in data:
         # make lines invisible to get the area plotted, only.
-        line = {'color': 'rgba(255,255,255,0)'}
+        line = {"color": "rgba(255,255,255,0)"}
         # TODO: Figure out why scattergl causes problems plotly/plotly.js#2284
-        trace_a = go.Scatter(x=data.date, y=data[indicator_a],
-                             showlegend=False,
-                             line=line)
-        trace_b = go.Scatter(x=data.date, y=data[indicator_b], name=label,
-                             fill="tonexty", fillcolor=fill_color,
-                             line=line)
+        trace_a = go.Scatter(x=data.date, y=data[indicator_a], showlegend=False, line=line)
+        trace_b = go.Scatter(
+            x=data.date,
+            y=data[indicator_b],
+            name=label,
+            fill="tonexty",
+            fillcolor=fill_color,
+            line=line,
+        )
         fig.add_trace(trace_a, row, 1)
         fig.add_trace(trace_b, row, 1)
     return fig
 
 
 def add_areas(fig, row: int, data: pd.DataFrame, indicators) -> make_subplots:
-    """ Adds all area plots (specified in plot_config) to fig.
+    """Adds all area plots (specified in plot_config) to fig.
     :param fig: Plot figure to append to
     :param row: row number for this plot
     :param data: candlestick DataFrame
     :param indicators: dict with indicators. ie.: plot_config['main_plot'] or
                             plot_config['subplots'][subplot_label]
     :return: fig with added  filled_traces plot
     """
     for indicator, ind_conf in indicators.items():
-        if 'fill_to' in ind_conf:
-            indicator_b = ind_conf['fill_to']
+        if "fill_to" in ind_conf:
+            indicator_b = ind_conf["fill_to"]
             if indicator in data and indicator_b in data:
-                label = ind_conf.get('fill_label',
-                                     f'{indicator}<>{indicator_b}')
-                fill_color = ind_conf.get('fill_color', 'rgba(0,176,246,0.2)')
-                fig = plot_area(fig, row, data, indicator, indicator_b,
-                                label=label, fill_color=fill_color)
+                label = ind_conf.get("fill_label", f"{indicator}<>{indicator_b}")
+                fill_color = ind_conf.get("fill_color", "rgba(0,176,246,0.2)")
+                fig = plot_area(
+                    fig, row, data, indicator, indicator_b, label=label, fill_color=fill_color
+                )
             elif indicator not in data:
                 logger.info(
                     'Indicator "%s" ignored. Reason: This indicator is not '
-                    'found in your strategy.', indicator
+                    "found in your strategy.",
+                    indicator,
                 )
             elif indicator_b not in data:
                 logger.info(
-                    'fill_to: "%s" ignored. Reason: This indicator is not '
-                    'in your strategy.', indicator_b
+                    'fill_to: "%s" ignored. Reason: This indicator is not ' "in your strategy.",
+                    indicator_b,
                 )
     return fig
 
 
-def create_scatter(
-    data,
-    column_name,
-    color,
-    direction
-) -> Optional[go.Scatter]:
-
+def create_scatter(data, column_name, color, direction) -> Optional[go.Scatter]:
     if column_name in data.columns:
         df_short = data[data[column_name] == 1]
         if len(df_short) > 0:
             shorts = go.Scatter(
                 x=df_short.date,
                 y=df_short.close,
-                mode='markers',
+                mode="markers",
                 name=column_name,
                 marker=dict(
                     symbol=f"triangle-{direction}-dot",
                     size=9,
                     line=dict(width=1),
                     color=color,
-                )
+                ),
             )
             return shorts
         else:
             logger.warning(f"No {column_name}-signals found.")
 
     return None
 
 
 def generate_candlestick_graph(
-        pair: str, data: pd.DataFrame, trades: Optional[pd.DataFrame] = None, *,
-        indicators1: Optional[List[str]] = None, indicators2: Optional[List[str]] = None,
-        plot_config: Optional[Dict[str, Dict]] = None,
-        ) -> go.Figure:
+    pair: str,
+    data: pd.DataFrame,
+    trades: Optional[pd.DataFrame] = None,
+    *,
+    indicators1: Optional[List[str]] = None,
+    indicators2: Optional[List[str]] = None,
+    plot_config: Optional[Dict[str, Dict]] = None,
+) -> go.Figure:
     """
     Generate the graph from the data generated by Backtesting or from DB
     Volume will always be plotted in row2, so Row 1 and 3 are to our disposal for custom indicators
     :param pair: Pair to Display on the graph
     :param data: OHLCV DataFrame containing indicators and entry/exit signals
     :param trades: All trades created
     :param indicators1: List containing Main plot indicators
@@ -455,159 +450,163 @@
     :return: Plotly figure
     """
     plot_config = create_plotconfig(
         indicators1 or [],
         indicators2 or [],
         plot_config or {},
     )
-    rows = 2 + len(plot_config['subplots'])
-    row_widths = [1 for _ in plot_config['subplots']]
+    rows = 2 + len(plot_config["subplots"])
+    row_widths = [1 for _ in plot_config["subplots"]]
     # Define the graph
     fig = make_subplots(
         rows=rows,
         cols=1,
         shared_xaxes=True,
         row_width=row_widths + [1, 4],
         vertical_spacing=0.0001,
     )
-    fig['layout'].update(title=pair)
-    fig['layout']['yaxis1'].update(title='Price')
-    fig['layout']['yaxis2'].update(title='Volume')
-    for i, name in enumerate(plot_config['subplots']):
-        fig['layout'][f'yaxis{3 + i}'].update(title=name)
-    fig['layout']['xaxis']['rangeslider'].update(visible=False)
+    fig["layout"].update(title=pair)
+    fig["layout"]["yaxis1"].update(title="Price")
+    fig["layout"]["yaxis2"].update(title="Volume")
+    for i, name in enumerate(plot_config["subplots"]):
+        fig["layout"][f"yaxis{3 + i}"].update(title=name)
+    fig["layout"]["xaxis"]["rangeslider"].update(visible=False)
     fig.update_layout(modebar_add=["v1hovermode", "toggleSpikeLines"])
 
     # Common information
     candles = go.Candlestick(
-        x=data.date,
-        open=data.open,
-        high=data.high,
-        low=data.low,
-        close=data.close,
-        name='Price'
+        x=data.date, open=data.open, high=data.high, low=data.low, close=data.close, name="Price"
     )
     fig.add_trace(candles, 1, 1)
 
-    longs = create_scatter(data, 'enter_long', 'green', 'up')
-    exit_longs = create_scatter(data, 'exit_long', 'red', 'down')
-    shorts = create_scatter(data, 'enter_short', 'blue', 'down')
-    exit_shorts = create_scatter(data, 'exit_short', 'violet', 'up')
+    longs = create_scatter(data, "enter_long", "green", "up")
+    exit_longs = create_scatter(data, "exit_long", "red", "down")
+    shorts = create_scatter(data, "enter_short", "blue", "down")
+    exit_shorts = create_scatter(data, "exit_short", "violet", "up")
 
     for scatter in [longs, exit_longs, shorts, exit_shorts]:
         if scatter:
             fig.add_trace(scatter, 1, 1)
 
     # Add Bollinger Bands
-    fig = plot_area(fig, 1, data, 'bb_lowerband', 'bb_upperband',
-                    label="Bollinger Band")
+    fig = plot_area(fig, 1, data, "bb_lowerband", "bb_upperband", label="Bollinger Band")
     # prevent bb_lower and bb_upper from plotting
     try:
-        del plot_config['main_plot']['bb_lowerband']
-        del plot_config['main_plot']['bb_upperband']
+        del plot_config["main_plot"]["bb_lowerband"]
+        del plot_config["main_plot"]["bb_upperband"]
     except KeyError:
         pass
     # main plot goes to row 1
-    fig = add_indicators(fig=fig, row=1, indicators=plot_config['main_plot'], data=data)
-    fig = add_areas(fig, 1, data, plot_config['main_plot'])
+    fig = add_indicators(fig=fig, row=1, indicators=plot_config["main_plot"], data=data)
+    fig = add_areas(fig, 1, data, plot_config["main_plot"])
     fig = plot_trades(fig, trades)
     # sub plot: Volume goes to row 2
     volume = go.Bar(
-        x=data['date'],
-        y=data['volume'],
-        name='Volume',
-        marker_color='DarkSlateGrey',
-        marker_line_color='DarkSlateGrey'
+        x=data["date"],
+        y=data["volume"],
+        name="Volume",
+        marker_color="DarkSlateGrey",
+        marker_line_color="DarkSlateGrey",
     )
     fig.add_trace(volume, 2, 1)
     # add each sub plot to a separate row
-    for i, label in enumerate(plot_config['subplots']):
-        sub_config = plot_config['subplots'][label]
+    for i, label in enumerate(plot_config["subplots"]):
+        sub_config = plot_config["subplots"][label]
         row = 3 + i
-        fig = add_indicators(fig=fig, row=row, indicators=sub_config,
-                             data=data)
+        fig = add_indicators(fig=fig, row=row, indicators=sub_config, data=data)
         # fill area between indicators ( 'fill_to': 'other_indicator')
         fig = add_areas(fig, row, data, sub_config)
 
     return fig
 
 
-def generate_profit_graph(pairs: str, data: Dict[str, pd.DataFrame],
-                          trades: pd.DataFrame, timeframe: str, stake_currency: str,
-                          starting_balance: float) -> go.Figure:
+def generate_profit_graph(
+    pairs: str,
+    data: Dict[str, pd.DataFrame],
+    trades: pd.DataFrame,
+    timeframe: str,
+    stake_currency: str,
+    starting_balance: float,
+) -> go.Figure:
     # Combine close-values for all pairs, rename columns to "pair"
     try:
         df_comb = combine_dataframes_with_mean(data, "close")
     except ValueError:
         raise OperationalException(
             "No data found. Please make sure that data is available for "
-            "the timerange and pairs selected.")
+            "the timerange and pairs selected."
+        )
 
     # Trim trades to available OHLCV data
     trades = extract_trades_of_period(df_comb, trades, date_index=True)
     if len(trades) == 0:
-        raise OperationalException('No trades found in selected timerange.')
+        raise OperationalException("No trades found in selected timerange.")
 
     # Add combined cumulative profit
-    df_comb = create_cum_profit(df_comb, trades, 'cum_profit', timeframe)
+    df_comb = create_cum_profit(df_comb, trades, "cum_profit", timeframe)
 
     # Plot the pairs average close prices, and total profit growth
     avgclose = go.Scatter(
         x=df_comb.index,
-        y=df_comb['mean'],
-        name='Avg close price',
+        y=df_comb["mean"],
+        name="Avg close price",
     )
 
-    fig = make_subplots(rows=6, cols=1, shared_xaxes=True,
-                        row_heights=[1, 1, 1, 0.5, 0.75, 0.75],
-                        vertical_spacing=0.05,
-                        subplot_titles=[
-                            "AVG Close Price",
-                            "Combined Profit",
-                            "Profit per pair",
-                            "Parallelism",
-                            "Underwater",
-                            "Relative Drawdown",
-                        ])
-    fig['layout'].update(title="Freqtrade Profit plot")
-    fig['layout']['yaxis1'].update(title='Price')
-    fig['layout']['yaxis2'].update(title=f'Profit {stake_currency}')
-    fig['layout']['yaxis3'].update(title=f'Profit {stake_currency}')
-    fig['layout']['yaxis4'].update(title='Trade count')
-    fig['layout']['yaxis5'].update(title='Underwater Plot')
-    fig['layout']['yaxis6'].update(title='Underwater Plot Relative (%)', tickformat=',.2%')
-    fig['layout']['xaxis']['rangeslider'].update(visible=False)
+    fig = make_subplots(
+        rows=6,
+        cols=1,
+        shared_xaxes=True,
+        row_heights=[1, 1, 1, 0.5, 0.75, 0.75],
+        vertical_spacing=0.05,
+        subplot_titles=[
+            "AVG Close Price",
+            "Combined Profit",
+            "Profit per pair",
+            "Parallelism",
+            "Underwater",
+            "Relative Drawdown",
+        ],
+    )
+    fig["layout"].update(title="Freqtrade Profit plot")
+    fig["layout"]["yaxis1"].update(title="Price")
+    fig["layout"]["yaxis2"].update(title=f"Profit {stake_currency}")
+    fig["layout"]["yaxis3"].update(title=f"Profit {stake_currency}")
+    fig["layout"]["yaxis4"].update(title="Trade count")
+    fig["layout"]["yaxis5"].update(title="Underwater Plot")
+    fig["layout"]["yaxis6"].update(title="Underwater Plot Relative (%)", tickformat=",.2%")
+    fig["layout"]["xaxis"]["rangeslider"].update(visible=False)
     fig.update_layout(modebar_add=["v1hovermode", "toggleSpikeLines"])
 
     fig.add_trace(avgclose, 1, 1)
-    fig = add_profit(fig, 2, df_comb, 'cum_profit', 'Profit')
+    fig = add_profit(fig, 2, df_comb, "cum_profit", "Profit")
     fig = add_max_drawdown(fig, 2, trades, df_comb, timeframe, starting_balance)
     fig = add_parallelism(fig, 4, trades, timeframe)
     # Two rows consumed
     fig = add_underwater(fig, 5, trades, starting_balance)
 
     for pair in pairs:
-        profit_col = f'cum_profit_{pair}'
+        profit_col = f"cum_profit_{pair}"
         try:
-            df_comb = create_cum_profit(df_comb, trades[trades['pair'] == pair], profit_col,
-                                        timeframe)
+            df_comb = create_cum_profit(
+                df_comb, trades[trades["pair"] == pair], profit_col, timeframe
+            )
             fig = add_profit(fig, 3, df_comb, profit_col, f"Profit {pair}")
         except ValueError:
             pass
     return fig
 
 
 def generate_plot_filename(pair: str, timeframe: str) -> str:
     """
     Generate filenames per pair/timeframe to be used for storing plots
     """
     pair_s = pair_to_filename(pair)
-    file_name = 'freqtrade-plot-' + pair_s + '-' + timeframe + '.html'
+    file_name = "freqtrade-plot-" + pair_s + "-" + timeframe + ".html"
 
-    logger.info('Generate plot file for %s', pair)
+    logger.info("Generate plot file for %s", pair)
 
     return file_name
 
 
 def store_plot_file(fig, filename: str, directory: Path, auto_open: bool = False) -> None:
     """
     Generate a plot html file from pre populated fig plotly object
@@ -616,16 +615,15 @@
     :param directory: Directory to store the file in
     :param auto_open: Automatically open files saved
     :return: None
     """
     directory.mkdir(parents=True, exist_ok=True)
 
     _filename = directory.joinpath(filename)
-    plot(fig, filename=str(_filename),
-         auto_open=auto_open)
+    plot(fig, filename=str(_filename), auto_open=auto_open)
     logger.info(f"Stored plot as {_filename}")
 
 
 def load_and_plot_trades(config: Config):
     """
     From configuration provided
     - Initializes plot-script
@@ -639,69 +637,81 @@
     strategy = StrategyResolver.load_strategy(config)
 
     exchange = ExchangeResolver.load_exchange(config)
     IStrategy.dp = DataProvider(config, exchange)
     strategy.ft_bot_start()
     strategy_safe_wrapper(strategy.bot_loop_start)(current_time=datetime.now(timezone.utc))
     plot_elements = init_plotscript(config, list(exchange.markets), strategy.startup_candle_count)
-    timerange = plot_elements['timerange']
-    trades = plot_elements['trades']
+    timerange = plot_elements["timerange"]
+    trades = plot_elements["trades"]
     pair_counter = 0
     for pair, data in plot_elements["ohlcv"].items():
         pair_counter += 1
         logger.info("analyse pair %s", pair)
 
-        df_analyzed = strategy.analyze_ticker(data, {'pair': pair})
+        df_analyzed = strategy.analyze_ticker(data, {"pair": pair})
         df_analyzed = trim_dataframe(df_analyzed, timerange)
         if not trades.empty:
-            trades_pair = trades.loc[trades['pair'] == pair]
+            trades_pair = trades.loc[trades["pair"] == pair]
             trades_pair = extract_trades_of_period(df_analyzed, trades_pair)
         else:
             trades_pair = trades
 
         fig = generate_candlestick_graph(
             pair=pair,
             data=df_analyzed,
             trades=trades_pair,
-            indicators1=config.get('indicators1', []),
-            indicators2=config.get('indicators2', []),
-            plot_config=strategy.plot_config if hasattr(strategy, 'plot_config') else {}
+            indicators1=config.get("indicators1", []),
+            indicators2=config.get("indicators2", []),
+            plot_config=strategy.plot_config if hasattr(strategy, "plot_config") else {},
         )
 
-        store_plot_file(fig, filename=generate_plot_filename(pair, config['timeframe']),
-                        directory=config['user_data_dir'] / 'plot')
+        store_plot_file(
+            fig,
+            filename=generate_plot_filename(pair, config["timeframe"]),
+            directory=config["user_data_dir"] / "plot",
+        )
 
-    logger.info('End of plotting process. %s plots generated', pair_counter)
+    logger.info("End of plotting process. %s plots generated", pair_counter)
 
 
 def plot_profit(config: Config) -> None:
     """
     Plots the total profit for all pairs.
     Note, the profit calculation isn't realistic.
     But should be somewhat proportional, and therefore useful
     in helping out to find a good algorithm.
     """
-    if 'timeframe' not in config:
-        raise OperationalException('Timeframe must be set in either config or via --timeframe.')
+    if "timeframe" not in config:
+        raise OperationalException("Timeframe must be set in either config or via --timeframe.")
 
     exchange = ExchangeResolver.load_exchange(config)
     plot_elements = init_plotscript(config, list(exchange.markets))
-    trades = plot_elements['trades']
+    trades = plot_elements["trades"]
     # Filter trades to relevant pairs
     # Remove open pairs - we don't know the profit yet so can't calculate profit for these.
     # Also, If only one open pair is left, then the profit-generation would fail.
-    trades = trades[(trades['pair'].isin(plot_elements['pairs']))
-                    & (~trades['close_date'].isnull())
-                    ]
+    trades = trades[
+        (trades["pair"].isin(plot_elements["pairs"])) & (~trades["close_date"].isnull())
+    ]
     if len(trades) == 0:
-        raise OperationalException("No trades found, cannot generate Profit-plot without "
-                                   "trades from either Backtest result or database.")
+        raise OperationalException(
+            "No trades found, cannot generate Profit-plot without "
+            "trades from either Backtest result or database."
+        )
 
     # Create an average close price of all the pairs that were involved.
     # this could be useful to gauge the overall market trend
-    fig = generate_profit_graph(plot_elements['pairs'], plot_elements['ohlcv'],
-                                trades, config['timeframe'],
-                                config.get('stake_currency', ''),
-                                config.get('available_capital', config['dry_run_wallet']))
-    store_plot_file(fig, filename='freqtrade-profit-plot.html',
-                    directory=config['user_data_dir'] / 'plot',
-                    auto_open=config.get('plot_auto_open', False))
+    fig = generate_profit_graph(
+        plot_elements["pairs"],
+        plot_elements["ohlcv"],
+        trades,
+        config["timeframe"],
+        config.get("stake_currency", ""),
+        config.get("available_capital", config["dry_run_wallet"]),
+    )
+    store_plot_file(
+        fig,
+        filename="freqtrade-profit-plot.html",
+        directory=config["user_data_dir"] / "plot",
+        auto_open=config.get("plot_auto_open", False),
+    )
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/AgeFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/AgeFilter.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Minimum age (days listed) pair list filter
 """
+
 import logging
 from copy import deepcopy
 from datetime import timedelta
 from typing import Any, Dict, List, Optional
 
 from pandas import DataFrame
 
@@ -16,40 +17,48 @@
 from freqtrade.util import PeriodicCache, dt_floor_day, dt_now, dt_ts
 
 
 logger = logging.getLogger(__name__)
 
 
 class AgeFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
         # Checked symbols cache (dictionary of ticker symbol => timestamp)
         self._symbolsChecked: Dict[str, int] = {}
         self._symbolsCheckFailed = PeriodicCache(maxsize=1000, ttl=86_400)
 
-        self._min_days_listed = pairlistconfig.get('min_days_listed', 10)
-        self._max_days_listed = pairlistconfig.get('max_days_listed')
+        self._min_days_listed = pairlistconfig.get("min_days_listed", 10)
+        self._max_days_listed = pairlistconfig.get("max_days_listed")
 
-        candle_limit = exchange.ohlcv_candle_limit('1d', self._config['candle_type_def'])
+        candle_limit = exchange.ohlcv_candle_limit("1d", self._config["candle_type_def"])
         if self._min_days_listed < 1:
             raise OperationalException("AgeFilter requires min_days_listed to be >= 1")
         if self._min_days_listed > candle_limit:
-            raise OperationalException("AgeFilter requires min_days_listed to not exceed "
-                                       "exchange max request size "
-                                       f"({candle_limit})")
+            raise OperationalException(
+                "AgeFilter requires min_days_listed to not exceed "
+                "exchange max request size "
+                f"({candle_limit})"
+            )
         if self._max_days_listed and self._max_days_listed <= self._min_days_listed:
             raise OperationalException("AgeFilter max_days_listed <= min_days_listed not permitted")
         if self._max_days_listed and self._max_days_listed > candle_limit:
-            raise OperationalException("AgeFilter requires max_days_listed to not exceed "
-                                       "exchange max request size "
-                                       f"({candle_limit})")
+            raise OperationalException(
+                "AgeFilter requires max_days_listed to not exceed "
+                "exchange max request size "
+                f"({candle_limit})"
+            )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
@@ -59,18 +68,19 @@
     def short_desc(self) -> str:
         """
         Short whitelist method description - used for startup-messages
         """
         return (
             f"{self.name} - Filtering pairs with age less than "
             f"{self._min_days_listed} {plural(self._min_days_listed, 'day')}"
-        ) + ((
-            " or more than "
-            f"{self._max_days_listed} {plural(self._max_days_listed, 'day')}"
-        ) if self._max_days_listed else '')
+        ) + (
+            (" or more than {self._max_days_listed} {plural(self._max_days_listed, 'day')}")
+            if self._max_days_listed
+            else ""
+        )
 
     @staticmethod
     def description() -> str:
         return "Filter pairs by age (days listed)."
 
     @staticmethod
     def available_parameters() -> Dict[str, PairlistParameter]:
@@ -92,29 +102,34 @@
     def filter_pairlist(self, pairlist: List[str], tickers: Tickers) -> List[str]:
         """
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new allowlist
         """
         needed_pairs: ListPairsWithTimeframes = [
-            (p, '1d', self._config['candle_type_def']) for p in pairlist
-            if p not in self._symbolsChecked and p not in self._symbolsCheckFailed]
+            (p, "1d", self._config["candle_type_def"])
+            for p in pairlist
+            if p not in self._symbolsChecked and p not in self._symbolsCheckFailed
+        ]
         if not needed_pairs:
             # Remove pairs that have been removed before
             return [p for p in pairlist if p not in self._symbolsCheckFailed]
 
-        since_days = -(
-            self._max_days_listed if self._max_days_listed else self._min_days_listed
-        ) - 1
+        since_days = (
+            -(self._max_days_listed if self._max_days_listed else self._min_days_listed) - 1
+        )
         since_ms = dt_ts(dt_floor_day(dt_now()) + timedelta(days=since_days))
         candles = self._exchange.refresh_latest_ohlcv(needed_pairs, since_ms=since_ms, cache=False)
         if self._enabled:
             for p in deepcopy(pairlist):
-                daily_candles = candles[(p, '1d', self._config['candle_type_def'])] if (
-                    p, '1d', self._config['candle_type_def']) in candles else None
+                daily_candles = (
+                    candles[(p, "1d", self._config["candle_type_def"])]
+                    if (p, "1d", self._config["candle_type_def"]) in candles
+                    else None
+                )
                 if not self._validate_pair_loc(p, daily_candles):
                     pairlist.remove(p)
         self.log_once(f"Validated {len(pairlist)} pairs.", logger.info)
         return pairlist
 
     def _validate_pair_loc(self, pair: str, daily_candles: Optional[DataFrame]) -> bool:
         """
@@ -124,27 +139,34 @@
         :return: True if the pair can stay, false if it should be removed
         """
         # Check symbol in cache
         if pair in self._symbolsChecked:
             return True
 
         if daily_candles is not None:
-            if (
-                len(daily_candles) >= self._min_days_listed
-                and (not self._max_days_listed or len(daily_candles) <= self._max_days_listed)
+            if len(daily_candles) >= self._min_days_listed and (
+                not self._max_days_listed or len(daily_candles) <= self._max_days_listed
             ):
                 # We have fetched at least the minimum required number of daily candles
                 # Add to cache, store the time we last checked this symbol
                 self._symbolsChecked[pair] = dt_ts()
                 return True
             else:
-                self.log_once((
-                    f"Removed {pair} from whitelist, because age "
-                    f"{len(daily_candles)} is less than {self._min_days_listed} "
-                    f"{plural(self._min_days_listed, 'day')}"
-                ) + ((
-                    " or more than "
-                    f"{self._max_days_listed} {plural(self._max_days_listed, 'day')}"
-                ) if self._max_days_listed else ''), logger.info)
+                self.log_once(
+                    (
+                        f"Removed {pair} from whitelist, because age "
+                        f"{len(daily_candles)} is less than {self._min_days_listed} "
+                        f"{plural(self._min_days_listed, 'day')}"
+                    )
+                    + (
+                        (
+                            " or more than "
+                            f"{self._max_days_listed} {plural(self._max_days_listed, 'day')}"
+                        )
+                        if self._max_days_listed
+                        else ""
+                    ),
+                    logger.info,
+                )
                 self._symbolsCheckFailed[pair] = dt_ts()
                 return False
         return False
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/FullTradesFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/FullTradesFilter.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,32 @@
 """
 Full trade slots pair list filter
 """
+
 import logging
 from typing import Any, Dict, List
 
 from freqtrade.constants import Config
 from freqtrade.exchange.types import Tickers
 from freqtrade.persistence import Trade
 from freqtrade.plugins.pairlist.IPairList import IPairList
 
 
 logger = logging.getLogger(__name__)
 
 
 class FullTradesFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty List is passed
@@ -45,13 +50,13 @@
         Called on each bot iteration - please use internal caching if necessary
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new allowlist
         """
         # Get the number of open trades and max open trades config
         num_open = Trade.get_open_trade_count()
-        max_trades = self._config['max_open_trades']
+        max_trades = self._config["max_open_trades"]
 
         if (num_open >= max_trades) and (max_trades > 0):
             return []
 
         return pairlist
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/IPairList.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/IPairList.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 PairList Handler base class
 """
+
 import logging
 from abc import ABC, abstractmethod, abstractproperty
 from copy import deepcopy
 from typing import Any, Dict, List, Literal, Optional, TypedDict, Union
 
 from freqtrade.constants import Config
 from freqtrade.exceptions import OperationalException
@@ -42,40 +43,44 @@
     default: Union[bool, None]
 
 
 PairlistParameter = Union[
     __NumberPairlistParameter,
     __StringPairlistParameter,
     __OptionPairlistParameter,
-    __BoolPairlistParameter
-    ]
+    __BoolPairlistParameter,
+]
 
 
 class IPairList(LoggingMixin, ABC):
-
     is_pairlist_generator = False
 
-    def __init__(self, exchange: Exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange: Exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         """
         :param exchange: Exchange instance
         :param pairlistmanager: Instantiated Pairlist manager
         :param config: Global bot configuration
         :param pairlistconfig: Configuration for this Pairlist Handler - can be empty.
         :param pairlist_pos: Position of the Pairlist Handler in the chain
         """
         self._enabled = True
 
         self._exchange: Exchange = exchange
         self._pairlistmanager = pairlistmanager
         self._config = config
         self._pairlistconfig = pairlistconfig
         self._pairlist_pos = pairlist_pos
-        self.refresh_period = self._pairlistconfig.get('refresh_period', 1800)
+        self.refresh_period = self._pairlistconfig.get("refresh_period", 1800)
         LoggingMixin.__init__(self, logger, self.refresh_period)
 
     @property
     def name(self) -> str:
         """
         Gets name of the class
         -> no need to overwrite in subclasses
@@ -151,16 +156,18 @@
         position in the chain) shall not override this base implementation --
         it will raise the exception if a Pairlist Handler is used at the first
         position in the chain.
 
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: List of pairs
         """
-        raise OperationalException("This Pairlist Handler should not be used "
-                                   "at the first position in the list of Pairlist Handlers.")
+        raise OperationalException(
+            "This Pairlist Handler should not be used "
+            "at the first position in the list of Pairlist Handlers."
+        )
 
     def filter_pairlist(self, pairlist: List[str], tickers: Tickers) -> List[str]:
         """
         Filters and sorts pairlist and returns the whitelist again.
 
         Called on each bot iteration - please use internal caching if necessary
         This generic implementation calls self._validate_pair() for each pair
@@ -187,16 +194,17 @@
         Proxy method to verify_blacklist for easy access for child classes.
         :param pairlist: Pairlist to validate
         :param logmethod: Function that'll be called, `logger.info` or `logger.warning`.
         :return: pairlist - blacklisted pairs
         """
         return self._pairlistmanager.verify_blacklist(pairlist, logmethod)
 
-    def verify_whitelist(self, pairlist: List[str], logmethod,
-                         keep_invalid: bool = False) -> List[str]:
+    def verify_whitelist(
+        self, pairlist: List[str], logmethod, keep_invalid: bool = False
+    ) -> List[str]:
         """
         Proxy method to verify_whitelist for easy access for child classes.
         :param pairlist: Pairlist to validate
         :param logmethod: Function that'll be called, `logger.info` or `logger.warning`
         :param keep_invalid: If sets to True, drops invalid pairs silently while expanding regexes.
         :return: pairlist - whitelisted pairs
         """
@@ -208,34 +216,41 @@
         :param pairlist: the sorted list of pairs the user might want to trade
         :return: the list of pairs the user wants to trade without those unavailable or
         black_listed
         """
         markets = self._exchange.markets
         if not markets:
             raise OperationalException(
-                'Markets not loaded. Make sure that exchange is initialized correctly.')
+                "Markets not loaded. Make sure that exchange is initialized correctly."
+            )
 
         sanitized_whitelist: List[str] = []
         for pair in pairlist:
             # pair is not in the generated dynamic market or has the wrong stake currency
             if pair not in markets:
-                self.log_once(f"Pair {pair} is not compatible with exchange "
-                              f"{self._exchange.name}. Removing it from whitelist..",
-                              logger.warning)
+                self.log_once(
+                    f"Pair {pair} is not compatible with exchange "
+                    f"{self._exchange.name}. Removing it from whitelist..",
+                    logger.warning,
+                )
                 continue
 
             if not self._exchange.market_is_tradable(markets[pair]):
-                self.log_once(f"Pair {pair} is not tradable with Freqtrade."
-                              "Removing it from whitelist..", logger.warning)
+                self.log_once(
+                    f"Pair {pair} is not tradable with Freqtrade. Removing it from whitelist..",
+                    logger.warning,
+                )
                 continue
 
-            if self._exchange.get_pair_quote_currency(pair) != self._config['stake_currency']:
-                self.log_once(f"Pair {pair} is not compatible with your stake currency "
-                              f"{self._config['stake_currency']}. Removing it from whitelist..",
-                              logger.warning)
+            if self._exchange.get_pair_quote_currency(pair) != self._config["stake_currency"]:
+                self.log_once(
+                    f"Pair {pair} is not compatible with your stake currency "
+                    f"{self._config['stake_currency']}. Removing it from whitelist..",
+                    logger.warning,
+                )
                 continue
 
             # Check if market is active
             market = markets[pair]
             if not market_is_active(market):
                 self.log_once(f"Ignoring {pair} from whitelist. Market is not active.", logger.info)
                 continue
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/MarketCapPairList.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/MarketCapPairList.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,53 +1,63 @@
 """
 Market Cap PairList provider
 
 Provides dynamic pair list based on Market Cap
 """
+
 import logging
 from typing import Any, Dict, List
 
 from cachetools import TTLCache
-from pycoingecko import CoinGeckoAPI
 
 from freqtrade.constants import Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange.types import Tickers
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
+from freqtrade.util.coin_gecko import FtCoinGeckoApi
 
 
 logger = logging.getLogger(__name__)
 
 
 class MarketCapPairList(IPairList):
-
     is_pairlist_generator = True
 
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        if 'number_assets' not in self._pairlistconfig:
+        if "number_assets" not in self._pairlistconfig:
             raise OperationalException(
-                '`number_assets` not specified. Please check your configuration '
-                'for "pairlist.config.number_assets"')
+                "`number_assets` not specified. Please check your configuration "
+                'for "pairlist.config.number_assets"'
+            )
 
-        self._stake_currency = config['stake_currency']
-        self._number_assets = self._pairlistconfig['number_assets']
-        self._max_rank = self._pairlistconfig.get('max_rank', 30)
-        self._refresh_period = self._pairlistconfig.get('refresh_period', 86400)
+        self._stake_currency = config["stake_currency"]
+        self._number_assets = self._pairlistconfig["number_assets"]
+        self._max_rank = self._pairlistconfig.get("max_rank", 30)
+        self._refresh_period = self._pairlistconfig.get("refresh_period", 86400)
         self._marketcap_cache: TTLCache = TTLCache(maxsize=1, ttl=self._refresh_period)
-        self._def_candletype = self._config['candle_type_def']
-        self._coingecko: CoinGeckoAPI = CoinGeckoAPI()
+        self._def_candletype = self._config["candle_type_def"]
+
+        _coingecko_config = config.get("coingecko", {})
+
+        self._coingecko: FtCoinGeckoApi = FtCoinGeckoApi(
+            api_key=_coingecko_config.get("api_key", ""),
+            is_demo=_coingecko_config.get("is_demo", True),
+        )
 
         if self._max_rank > 250:
-            raise OperationalException(
-                "This filter only support marketcap rank up to 250."
-            )
+            raise OperationalException("This filter only support marketcap rank up to 250.")
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
@@ -83,70 +93,78 @@
                 "help": "Maximum rank of assets to use from the pairlist",
             },
             "refresh_period": {
                 "type": "number",
                 "default": 86400,
                 "description": "Refresh period",
                 "help": "Refresh period in seconds",
-            }
+            },
         }
 
     def gen_pairlist(self, tickers: Tickers) -> List[str]:
         """
         Generate the pairlist
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: List of pairs
         """
         # Generate dynamic whitelist
         # Must always run if this pairlist is the first in the list.
-        pairlist = self._marketcap_cache.get('pairlist_mc')
+        pairlist = self._marketcap_cache.get("pairlist_mc")
         if pairlist:
             # Item found - no refresh necessary
             return pairlist.copy()
         else:
             # Use fresh pairlist
             # Check if pair quote currency equals to the stake currency.
-            _pairlist = [k for k in self._exchange.get_markets(
-                quote_currencies=[self._stake_currency],
-                tradable_only=True, active_only=True).keys()]
+            _pairlist = [
+                k
+                for k in self._exchange.get_markets(
+                    quote_currencies=[self._stake_currency], tradable_only=True, active_only=True
+                ).keys()
+            ]
             # No point in testing for blacklisted pairs...
             _pairlist = self.verify_blacklist(_pairlist, logger.info)
 
             pairlist = self.filter_pairlist(_pairlist, tickers)
-            self._marketcap_cache['pairlist_mc'] = pairlist.copy()
+            self._marketcap_cache["pairlist_mc"] = pairlist.copy()
 
         return pairlist
 
     def filter_pairlist(self, pairlist: List[str], tickers: Dict) -> List[str]:
         """
         Filters and sorts pairlist and returns the whitelist again.
         Called on each bot iteration - please use internal caching if necessary
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new whitelist
         """
-        marketcap_list = self._marketcap_cache.get('marketcap')
+        marketcap_list = self._marketcap_cache.get("marketcap")
 
         if marketcap_list is None:
-            data = self._coingecko.get_coins_markets(vs_currency='usd', order='market_cap_desc',
-                                                     per_page='250', page='1', sparkline='false',
-                                                     locale='en')
+            data = self._coingecko.get_coins_markets(
+                vs_currency="usd",
+                order="market_cap_desc",
+                per_page="250",
+                page="1",
+                sparkline="false",
+                locale="en",
+            )
             if data:
-                marketcap_list = [row['symbol'] for row in data]
-                self._marketcap_cache['marketcap'] = marketcap_list
+                marketcap_list = [row["symbol"] for row in data]
+                self._marketcap_cache["marketcap"] = marketcap_list
 
         if marketcap_list:
             filtered_pairlist = []
 
-            market = self._config['trading_mode']
+            market = self._config["trading_mode"]
             pair_format = f"{self._stake_currency.upper()}"
-            if (market == 'futures'):
+            if market == "futures":
                 pair_format += f":{self._stake_currency.upper()}"
 
-            top_marketcap = marketcap_list[:self._max_rank:]
+            top_marketcap = marketcap_list[: self._max_rank :]
 
             for mc_pair in top_marketcap:
                 test_pair = f"{mc_pair.upper()}/{pair_format}"
                 if test_pair in pairlist:
                     filtered_pairlist.append(test_pair)
                     if len(filtered_pairlist) == self._number_assets:
                         break
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/OffsetFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/OffsetFilter.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,31 +1,36 @@
 """
 Offset pair list filter
 """
+
 import logging
 from typing import Any, Dict, List
 
 from freqtrade.constants import Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange.types import Tickers
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 
 
 logger = logging.getLogger(__name__)
 
 
 class OffsetFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._offset = pairlistconfig.get('offset', 0)
-        self._number_pairs = pairlistconfig.get('number_assets', 0)
+        self._offset = pairlistconfig.get("offset", 0)
+        self._number_pairs = pairlistconfig.get("number_assets", 0)
 
         if self._offset < 0:
             raise OperationalException("OffsetFilter requires offset to be >= 0")
 
     @property
     def needstickers(self) -> bool:
         """
@@ -69,16 +74,18 @@
         Filters and sorts pairlist and returns the whitelist again.
         Called on each bot iteration - please use internal caching if necessary
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new whitelist
         """
         if self._offset > len(pairlist):
-            self.log_once(f"Offset of {self._offset} is larger than " +
-                          f"pair count of {len(pairlist)}", logger.warning)
-        pairs = pairlist[self._offset:]
+            self.log_once(
+                f"Offset of {self._offset} is larger than " + f"pair count of {len(pairlist)}",
+                logger.warning,
+            )
+        pairs = pairlist[self._offset :]
         if self._number_pairs:
-            pairs = pairs[:self._number_pairs]
+            pairs = pairs[: self._number_pairs]
 
         self.log_once(f"Searching {len(pairs)} pairs: {pairs}", logger.info)
 
         return pairs
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/PerformanceFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/PerformanceFilter.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Performance pair list filter
 """
+
 import logging
 from typing import Any, Dict, List
 
 import pandas as pd
 
 from freqtrade.constants import Config
 from freqtrade.exchange.types import Tickers
@@ -12,22 +13,26 @@
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 
 
 logger = logging.getLogger(__name__)
 
 
 class PerformanceFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._minutes = pairlistconfig.get('minutes', 0)
-        self._min_profit = pairlistconfig.get('min_profit')
+        self._minutes = pairlistconfig.get("minutes", 0)
+        self._min_profit = pairlistconfig.get("min_profit")
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty List is passed
         as tickers argument to filter_pairlist
@@ -78,29 +83,33 @@
             return pairlist
 
         # Skip performance-based sorting if no performance data is available
         if len(performance) == 0:
             return pairlist
 
         # Get pairlist from performance dataframe values
-        list_df = pd.DataFrame({'pair': pairlist})
-        list_df['prior_idx'] = list_df.index
+        list_df = pd.DataFrame({"pair": pairlist})
+        list_df["prior_idx"] = list_df.index
 
         # Set initial value for pairs with no trades to 0
         # Sort the list using:
         #  - primarily performance (high to low)
         #  - then count (low to high, so as to favor same performance with fewer trades)
         #  - then by prior index, keeping original sorting order
-        sorted_df = list_df.merge(performance, on='pair', how='left')\
-            .fillna(0).sort_values(by=['profit_ratio', 'count', 'prior_idx'],
-                                   ascending=[False, True, True])
+        sorted_df = (
+            list_df.merge(performance, on="pair", how="left")
+            .fillna(0)
+            .sort_values(by=["profit_ratio", "count", "prior_idx"], ascending=[False, True, True])
+        )
         if self._min_profit is not None:
-            removed = sorted_df[sorted_df['profit_ratio'] < self._min_profit]
+            removed = sorted_df[sorted_df["profit_ratio"] < self._min_profit]
             for _, row in removed.iterrows():
                 self.log_once(
                     f"Removing pair {row['pair']} since {row['profit_ratio']} is "
-                    f"below {self._min_profit}", logger.info)
-            sorted_df = sorted_df[sorted_df['profit_ratio'] >= self._min_profit]
+                    f"below {self._min_profit}",
+                    logger.info,
+                )
+            sorted_df = sorted_df[sorted_df["profit_ratio"] >= self._min_profit]
 
-        pairlist = sorted_df['pair'].tolist()
+        pairlist = sorted_df["pair"].tolist()
 
         return pairlist
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/PrecisionFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/PrecisionFilter.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,35 +1,41 @@
 """
 Precision pair list filter
 """
+
 import logging
 from typing import Any, Dict, Optional
 
 from freqtrade.constants import Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange import ROUND_UP
 from freqtrade.exchange.types import Ticker
 from freqtrade.plugins.pairlist.IPairList import IPairList
 
 
 logger = logging.getLogger(__name__)
 
 
 class PrecisionFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        if 'stoploss' not in self._config:
+        if "stoploss" not in self._config:
             raise OperationalException(
-                'PrecisionFilter can only work with stoploss defined. Please add the '
-                'stoploss key to your configuration (overwrites eventual strategy settings).')
-        self._stoploss = self._config['stoploss']
+                "PrecisionFilter can only work with stoploss defined. Please add the "
+                "stoploss key to your configuration (overwrites eventual strategy settings)."
+            )
+        self._stoploss = self._config["stoploss"]
         self._enabled = self._stoploss != 0
 
         # Precalculate sanitized stoploss value to avoid recalculation for every pair
         self._stoploss = 1 - abs(self._stoploss)
 
     @property
     def needstickers(self) -> bool:
@@ -54,27 +60,33 @@
         """
         Check if pair has enough room to add a stoploss to avoid "unsellable" buys of very
         low value pairs.
         :param pair: Pair that's currently validated
         :param ticker: ticker dict as returned from ccxt.fetch_ticker
         :return: True if the pair can stay, false if it should be removed
         """
-        if not ticker or ticker.get('last', None) is None:
-            self.log_once(f"Removed {pair} from whitelist, because "
-                          "ticker['last'] is empty (Usually no trade in the last 24h).",
-                          logger.info)
+        if not ticker or ticker.get("last", None) is None:
+            self.log_once(
+                f"Removed {pair} from whitelist, because "
+                "ticker['last'] is empty (Usually no trade in the last 24h).",
+                logger.info,
+            )
             return False
-        stop_price = ticker['last'] * self._stoploss
+        stop_price = ticker["last"] * self._stoploss
 
         # Adjust stop-prices to precision
         sp = self._exchange.price_to_precision(pair, stop_price, rounding_mode=ROUND_UP)
 
-        stop_gap_price = self._exchange.price_to_precision(pair, stop_price * 0.99,
-                                                           rounding_mode=ROUND_UP)
+        stop_gap_price = self._exchange.price_to_precision(
+            pair, stop_price * 0.99, rounding_mode=ROUND_UP
+        )
         logger.debug(f"{pair} - {sp} : {stop_gap_price}")
 
         if sp <= stop_gap_price:
-            self.log_once(f"Removed {pair} from whitelist, because "
-                          f"stop price {sp} would be <= stop limit {stop_gap_price}", logger.info)
+            self.log_once(
+                f"Removed {pair} from whitelist, because "
+                f"stop price {sp} would be <= stop limit {stop_gap_price}",
+                logger.info,
+            )
             return False
 
         return True
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/PriceFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/PriceFilter.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,45 +1,52 @@
 """
 Price pair list filter
 """
+
 import logging
 from typing import Any, Dict, Optional
 
 from freqtrade.constants import Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange.types import Ticker
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 
 
 logger = logging.getLogger(__name__)
 
 
 class PriceFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._low_price_ratio = pairlistconfig.get('low_price_ratio', 0)
+        self._low_price_ratio = pairlistconfig.get("low_price_ratio", 0)
         if self._low_price_ratio < 0:
             raise OperationalException("PriceFilter requires low_price_ratio to be >= 0")
-        self._min_price = pairlistconfig.get('min_price', 0)
+        self._min_price = pairlistconfig.get("min_price", 0)
         if self._min_price < 0:
             raise OperationalException("PriceFilter requires min_price to be >= 0")
-        self._max_price = pairlistconfig.get('max_price', 0)
+        self._max_price = pairlistconfig.get("max_price", 0)
         if self._max_price < 0:
             raise OperationalException("PriceFilter requires max_price to be >= 0")
-        self._max_value = pairlistconfig.get('max_value', 0)
+        self._max_value = pairlistconfig.get("max_value", 0)
         if self._max_value < 0:
             raise OperationalException("PriceFilter requires max_value to be >= 0")
-        self._enabled = ((self._low_price_ratio > 0) or
-                         (self._min_price > 0) or
-                         (self._max_price > 0) or
-                         (self._max_value > 0))
+        self._enabled = (
+            (self._low_price_ratio > 0)
+            or (self._min_price > 0)
+            or (self._max_price > 0)
+            or (self._max_value > 0)
+        )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
@@ -72,16 +79,17 @@
     @staticmethod
     def available_parameters() -> Dict[str, PairlistParameter]:
         return {
             "low_price_ratio": {
                 "type": "number",
                 "default": 0,
                 "description": "Low price ratio",
-                "help": ("Remove pairs where a price move of 1 price unit (pip) "
-                         "is above this ratio."),
+                "help": (
+                    "Remove pairs where a price move of 1 price unit (pip) is above this ratio."
+                ),
             },
             "min_price": {
                 "type": "number",
                 "default": 0,
                 "description": "Minimum price",
                 "help": "Remove pairs with a price below this value.",
             },
@@ -102,63 +110,75 @@
     def _validate_pair(self, pair: str, ticker: Optional[Ticker]) -> bool:
         """
         Check if one price-step (pip) is > than a certain barrier.
         :param pair: Pair that's currently validated
         :param ticker: ticker dict as returned from ccxt.fetch_ticker
         :return: True if the pair can stay, false if it should be removed
         """
-        if ticker and 'last' in ticker and ticker['last'] is not None and ticker.get('last') != 0:
-            price: float = ticker['last']
+        if ticker and "last" in ticker and ticker["last"] is not None and ticker.get("last") != 0:
+            price: float = ticker["last"]
         else:
-            self.log_once(f"Removed {pair} from whitelist, because "
-                          "ticker['last'] is empty (Usually no trade in the last 24h).",
-                          logger.info)
+            self.log_once(
+                f"Removed {pair} from whitelist, because "
+                "ticker['last'] is empty (Usually no trade in the last 24h).",
+                logger.info,
+            )
             return False
 
         # Perform low_price_ratio check.
         if self._low_price_ratio != 0:
             compare = self._exchange.price_get_one_pip(pair, price)
             changeperc = compare / price
             if changeperc > self._low_price_ratio:
-                self.log_once(f"Removed {pair} from whitelist, "
-                              f"because 1 unit is {changeperc:.3%}", logger.info)
+                self.log_once(
+                    f"Removed {pair} from whitelist, because 1 unit is {changeperc:.3%}",
+                    logger.info,
+                )
                 return False
 
         # Perform low_amount check
         if self._max_value != 0:
             market = self._exchange.markets[pair]
-            limits = market['limits']
-            if (limits['amount']['min'] is not None):
-                min_amount = limits['amount']['min']
-                min_precision = market['precision']['amount']
+            limits = market["limits"]
+            if limits["amount"]["min"] is not None:
+                min_amount = limits["amount"]["min"]
+                min_precision = market["precision"]["amount"]
 
                 min_value = min_amount * price
                 if self._exchange.precisionMode == 4:
                     # tick size
                     next_value = (min_amount + min_precision) * price
                 else:
                     # Decimal places
                     min_precision = pow(0.1, min_precision)
                     next_value = (min_amount + min_precision) * price
                 diff = next_value - min_value
 
                 if diff > self._max_value:
-                    self.log_once(f"Removed {pair} from whitelist, "
-                                  f"because min value change of {diff} > {self._max_value}.",
-                                  logger.info)
+                    self.log_once(
+                        f"Removed {pair} from whitelist, "
+                        f"because min value change of {diff} > {self._max_value}.",
+                        logger.info,
+                    )
                     return False
 
         # Perform min_price check.
         if self._min_price != 0:
             if price < self._min_price:
-                self.log_once(f"Removed {pair} from whitelist, "
-                              f"because last price < {self._min_price:.8f}", logger.info)
+                self.log_once(
+                    f"Removed {pair} from whitelist, "
+                    f"because last price < {self._min_price:.8f}",
+                    logger.info,
+                )
                 return False
 
         # Perform max_price check.
         if self._max_price != 0:
             if price > self._max_price:
-                self.log_once(f"Removed {pair} from whitelist, "
-                              f"because last price > {self._max_price:.8f}", logger.info)
+                self.log_once(
+                    f"Removed {pair} from whitelist, "
+                    f"because last price > {self._max_price:.8f}",
+                    logger.info,
+                )
                 return False
 
         return True
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/ProducerPairList.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/ProducerPairList.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """
 External Pair List provider
 
 Provides pair list from Leader data
 """
+
 import logging
 from typing import Any, Dict, List, Optional
 
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange.types import Tickers
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 
@@ -24,26 +25,33 @@
             {
                 "method": "ProducerPairList",
                 "number_assets": 5,
                 "producer_name": "default",
             }
         ],
     """
+
     is_pairlist_generator = True
 
-    def __init__(self, exchange, pairlistmanager,
-                 config: Dict[str, Any], pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Dict[str, Any],
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._num_assets: int = self._pairlistconfig.get('number_assets', 0)
-        self._producer_name = self._pairlistconfig.get('producer_name', 'default')
-        if not config.get('external_message_consumer', {}).get('enabled'):
+        self._num_assets: int = self._pairlistconfig.get("number_assets", 0)
+        self._producer_name = self._pairlistconfig.get("producer_name", "default")
+        if not config.get("external_message_consumer", {}).get("enabled"):
             raise OperationalException(
-                "ProducerPairList requires external_message_consumer to be enabled.")
+                "ProducerPairList requires external_message_consumer to be enabled."
+            )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
@@ -70,29 +78,32 @@
                 "description": "Number of assets",
                 "help": "Number of assets to use from the pairlist",
             },
             "producer_name": {
                 "type": "string",
                 "default": "default",
                 "description": "Producer name",
-                "help": ("Name of the producer to use. Requires additional "
-                         "external_message_consumer configuration.")
+                "help": (
+                    "Name of the producer to use. Requires additional "
+                    "external_message_consumer configuration."
+                ),
             },
         }
 
     def _filter_pairlist(self, pairlist: Optional[List[str]]):
         upstream_pairlist = self._pairlistmanager._dataprovider.get_producer_pairs(
-            self._producer_name)
+            self._producer_name
+        )
 
         if pairlist is None:
             pairlist = self._pairlistmanager._dataprovider.get_producer_pairs(self._producer_name)
 
         pairs = list(dict.fromkeys(pairlist + upstream_pairlist))
         if self._num_assets:
-            pairs = pairs[:self._num_assets]
+            pairs = pairs[: self._num_assets]
 
         return pairs
 
     def gen_pairlist(self, tickers: Tickers) -> List[str]:
         """
         Generate the pairlist
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/RemotePairList.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/RemotePairList.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """
 Remote PairList provider
 
 Provides pair list fetched from a remote source
 """
+
 import logging
 from pathlib import Path
 from typing import Any, Dict, List, Tuple
 
 import rapidjson
 import requests
 from cachetools import TTLCache
@@ -20,59 +21,67 @@
 from freqtrade.plugins.pairlist.pairlist_helpers import expand_pairlist
 
 
 logger = logging.getLogger(__name__)
 
 
 class RemotePairList(IPairList):
-
     is_pairlist_generator = True
 
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        if 'number_assets' not in self._pairlistconfig:
+        if "number_assets" not in self._pairlistconfig:
             raise OperationalException(
-                '`number_assets` not specified. Please check your configuration '
-                'for "pairlist.config.number_assets"')
+                "`number_assets` not specified. Please check your configuration "
+                'for "pairlist.config.number_assets"'
+            )
 
-        if 'pairlist_url' not in self._pairlistconfig:
+        if "pairlist_url" not in self._pairlistconfig:
             raise OperationalException(
-                '`pairlist_url` not specified. Please check your configuration '
-                'for "pairlist.config.pairlist_url"')
-
-        self._mode = self._pairlistconfig.get('mode', 'whitelist')
-        self._processing_mode = self._pairlistconfig.get('processing_mode', 'filter')
-        self._number_pairs = self._pairlistconfig['number_assets']
-        self._refresh_period: int = self._pairlistconfig.get('refresh_period', 1800)
-        self._keep_pairlist_on_failure = self._pairlistconfig.get('keep_pairlist_on_failure', True)
+                "`pairlist_url` not specified. Please check your configuration "
+                'for "pairlist.config.pairlist_url"'
+            )
+
+        self._mode = self._pairlistconfig.get("mode", "whitelist")
+        self._processing_mode = self._pairlistconfig.get("processing_mode", "filter")
+        self._number_pairs = self._pairlistconfig["number_assets"]
+        self._refresh_period: int = self._pairlistconfig.get("refresh_period", 1800)
+        self._keep_pairlist_on_failure = self._pairlistconfig.get("keep_pairlist_on_failure", True)
         self._pair_cache: TTLCache = TTLCache(maxsize=1, ttl=self._refresh_period)
-        self._pairlist_url = self._pairlistconfig.get('pairlist_url', '')
-        self._read_timeout = self._pairlistconfig.get('read_timeout', 60)
-        self._bearer_token = self._pairlistconfig.get('bearer_token', '')
+        self._pairlist_url = self._pairlistconfig.get("pairlist_url", "")
+        self._read_timeout = self._pairlistconfig.get("read_timeout", 60)
+        self._bearer_token = self._pairlistconfig.get("bearer_token", "")
         self._init_done = False
-        self._save_to_file = self._pairlistconfig.get('save_to_file', None)
+        self._save_to_file = self._pairlistconfig.get("save_to_file", None)
         self._last_pairlist: List[Any] = list()
 
-        if self._mode not in ['whitelist', 'blacklist']:
+        if self._mode not in ["whitelist", "blacklist"]:
             raise OperationalException(
-                '`mode` not configured correctly. Supported Modes '
-                'are "whitelist","blacklist"')
+                "`mode` not configured correctly. Supported Modes " 'are "whitelist","blacklist"'
+            )
 
-        if self._processing_mode not in ['filter', 'append']:
+        if self._processing_mode not in ["filter", "append"]:
             raise OperationalException(
-                '`processing_mode` not configured correctly. Supported Modes '
-                'are "filter","append"')
+                "`processing_mode` not configured correctly. Supported Modes "
+                'are "filter","append"'
+            )
 
-        if self._pairlist_pos == 0 and self._mode == 'blacklist':
+        if self._pairlist_pos == 0 and self._mode == "blacklist":
             raise OperationalException(
-                'A `blacklist` mode RemotePairList can not be on the first '
-                'position of your pairlist.')
+                "A `blacklist` mode RemotePairList can not be on the first "
+                "position of your pairlist."
+            )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
@@ -142,67 +151,67 @@
                 "default": "",
                 "description": "Filename to save processed pairlist to.",
                 "help": "Specify a filename to save the processed pairlist in JSON format.",
             },
         }
 
     def process_json(self, jsonparse) -> List[str]:
-
-        pairlist = jsonparse.get('pairs', [])
-        remote_refresh_period = int(jsonparse.get('refresh_period', self._refresh_period))
+        pairlist = jsonparse.get("pairs", [])
+        remote_refresh_period = int(jsonparse.get("refresh_period", self._refresh_period))
 
         if self._refresh_period < remote_refresh_period:
-            self.log_once(f'Refresh Period has been increased from {self._refresh_period}'
-                          f' to minimum allowed: {remote_refresh_period} from Remote.', logger.info)
+            self.log_once(
+                f"Refresh Period has been increased from {self._refresh_period}"
+                f" to minimum allowed: {remote_refresh_period} from Remote.",
+                logger.info,
+            )
 
             self._refresh_period = remote_refresh_period
             self._pair_cache = TTLCache(maxsize=1, ttl=remote_refresh_period)
 
         self._init_done = True
 
         return pairlist
 
     def return_last_pairlist(self) -> List[str]:
         if self._keep_pairlist_on_failure:
             pairlist = self._last_pairlist
-            self.log_once('Keeping last fetched pairlist', logger.info)
+            self.log_once("Keeping last fetched pairlist", logger.info)
         else:
             pairlist = []
 
         return pairlist
 
     def fetch_pairlist(self) -> Tuple[List[str], float]:
-
-        headers = {
-            'User-Agent': 'Freqtrade/' + __version__ + ' Remotepairlist'
-        }
+        headers = {"User-Agent": "Freqtrade/" + __version__ + " Remotepairlist"}
 
         if self._bearer_token:
-            headers['Authorization'] = f'Bearer {self._bearer_token}'
+            headers["Authorization"] = f"Bearer {self._bearer_token}"
 
         try:
-            response = requests.get(self._pairlist_url, headers=headers,
-                                    timeout=self._read_timeout)
-            content_type = response.headers.get('content-type')
+            response = requests.get(self._pairlist_url, headers=headers, timeout=self._read_timeout)
+            content_type = response.headers.get("content-type")
             time_elapsed = response.elapsed.total_seconds()
 
             if "application/json" in str(content_type):
                 jsonparse = response.json()
 
                 try:
                     pairlist = self.process_json(jsonparse)
                 except Exception as e:
-                    pairlist = self._handle_error(f'Failed processing JSON data: {type(e)}')
+                    pairlist = self._handle_error(f"Failed processing JSON data: {type(e)}")
             else:
-                pairlist = self._handle_error(f'RemotePairList is not of type JSON.'
-                                              f' {self._pairlist_url}')
+                pairlist = self._handle_error(
+                    f"RemotePairList is not of type JSON. {self._pairlist_url}"
+                )
 
         except requests.exceptions.RequestException:
-            pairlist = self._handle_error(f'Was not able to fetch pairlist from:'
-                                          f' {self._pairlist_url}')
+            pairlist = self._handle_error(
+                f"Was not able to fetch pairlist from: {self._pairlist_url}"
+            )
 
             time_elapsed = 0
 
         return pairlist, time_elapsed
 
     def _handle_error(self, error: str) -> List[str]:
         if self._init_done:
@@ -215,15 +224,15 @@
         """
         Generate the pairlist
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: List of pairs
         """
 
         if self._init_done:
-            pairlist = self._pair_cache.get('pairlist')
+            pairlist = self._pair_cache.get("pairlist")
             if pairlist == [None]:
                 # Valid but empty pairlist.
                 return []
         else:
             pairlist = []
 
         time_elapsed = 0.0
@@ -239,53 +248,51 @@
                 if file_path.exists():
                     with file_path.open() as json_file:
                         try:
                             # Load the JSON data into a dictionary
                             jsonparse = rapidjson.load(json_file, parse_mode=CONFIG_PARSE_MODE)
                             pairlist = self.process_json(jsonparse)
                         except Exception as e:
-                            pairlist = self._handle_error(f'processing JSON data: {type(e)}')
+                            pairlist = self._handle_error(f"processing JSON data: {type(e)}")
                 else:
                     pairlist = self._handle_error(f"{self._pairlist_url} does not exist.")
 
             else:
                 # Fetch Pairlist from Remote URL
                 pairlist, time_elapsed = self.fetch_pairlist()
 
         self.log_once(f"Fetched pairs: {pairlist}", logger.debug)
 
         pairlist = expand_pairlist(pairlist, list(self._exchange.get_markets().keys()))
         pairlist = self._whitelist_for_active_markets(pairlist)
-        pairlist = pairlist[:self._number_pairs]
+        pairlist = pairlist[: self._number_pairs]
 
         if pairlist:
-            self._pair_cache['pairlist'] = pairlist.copy()
+            self._pair_cache["pairlist"] = pairlist.copy()
         else:
             # If pairlist is empty, set a dummy value to avoid fetching again
-            self._pair_cache['pairlist'] = [None]
+            self._pair_cache["pairlist"] = [None]
 
         if time_elapsed != 0.0:
-            self.log_once(f'Pairlist Fetched in {time_elapsed} seconds.', logger.info)
+            self.log_once(f"Pairlist Fetched in {time_elapsed} seconds.", logger.info)
         else:
-            self.log_once('Fetched Pairlist.', logger.info)
+            self.log_once("Fetched Pairlist.", logger.info)
 
         self._last_pairlist = list(pairlist)
 
         if self._save_to_file:
             self.save_pairlist(pairlist, self._save_to_file)
 
         return pairlist
 
     def save_pairlist(self, pairlist: List[str], filename: str) -> None:
-        pairlist_data = {
-            "pairs": pairlist
-        }
+        pairlist_data = {"pairs": pairlist}
         try:
             file_path = Path(filename)
-            with file_path.open('w') as json_file:
+            with file_path.open("w") as json_file:
                 rapidjson.dump(pairlist_data, json_file)
                 logger.info(f"Processed pairlist saved to {filename}")
         except Exception as e:
             logger.error(f"Error saving processed pairlist to {filename}: {e}")
 
     def filter_pairlist(self, pairlist: List[str], tickers: Dict) -> List[str]:
         """
@@ -310,9 +317,9 @@
                 if pair not in rpl_pairlist:
                     merged_list.append(pair)
                 else:
                     filtered.append(pair)
             if filtered:
                 self.log_once(f"Blacklist - Filtered out pairs: {filtered}", logger.info)
 
-        merged_list = merged_list[:self._number_pairs]
+        merged_list = merged_list[: self._number_pairs]
         return merged_list
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/ShuffleFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/ShuffleFilter.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,63 +1,70 @@
 """
 Shuffle pair list filter
 """
+
 import logging
 import random
 from typing import Any, Dict, List, Literal
 
 from freqtrade.constants import Config
 from freqtrade.enums import RunMode
 from freqtrade.exchange import timeframe_to_seconds
 from freqtrade.exchange.types import Tickers
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 from freqtrade.util.periodic_cache import PeriodicCache
 
 
 logger = logging.getLogger(__name__)
 
-ShuffleValues = Literal['candle', 'iteration']
+ShuffleValues = Literal["candle", "iteration"]
 
 
 class ShuffleFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
         # Apply seed in backtesting mode to get comparable results,
         # but not in live modes to get a non-repeating order of pairs during live modes.
-        if config.get('runmode') in (RunMode.LIVE, RunMode.DRY_RUN):
+        if config.get("runmode") in (RunMode.LIVE, RunMode.DRY_RUN):
             self._seed = None
             logger.info("Live mode detected, not applying seed.")
         else:
-            self._seed = pairlistconfig.get('seed')
+            self._seed = pairlistconfig.get("seed")
             logger.info(f"Backtesting mode detected, applying seed value: {self._seed}")
 
         self._random = random.Random(self._seed)
-        self._shuffle_freq: ShuffleValues = pairlistconfig.get('shuffle_frequency', 'candle')
+        self._shuffle_freq: ShuffleValues = pairlistconfig.get("shuffle_frequency", "candle")
         self.__pairlist_cache = PeriodicCache(
-                    maxsize=1000, ttl=timeframe_to_seconds(self._config['timeframe']))
+            maxsize=1000, ttl=timeframe_to_seconds(self._config["timeframe"])
+        )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
         """
         return False
 
     def short_desc(self) -> str:
         """
         Short whitelist method description - used for startup-messages
         """
-        return (f"{self.name} - Shuffling pairs every {self._shuffle_freq}" +
-                (f", seed = {self._seed}." if self._seed is not None else "."))
+        return f"{self.name} - Shuffling pairs every {self._shuffle_freq}" + (
+            f", seed = {self._seed}." if self._seed is not None else "."
+        )
 
     @staticmethod
     def description() -> str:
         return "Randomize pairlist order."
 
     @staticmethod
     def available_parameters() -> Dict[str, PairlistParameter]:
@@ -83,15 +90,15 @@
         Called on each bot iteration - please use internal caching if necessary
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new whitelist
         """
         pairlist_bef = tuple(pairlist)
         pairlist_new = self.__pairlist_cache.get(pairlist_bef)
-        if pairlist_new and self._shuffle_freq == 'candle':
+        if pairlist_new and self._shuffle_freq == "candle":
             # Use cached pairlist.
             return pairlist_new
         # Shuffle is done inplace
         self._random.shuffle(pairlist)
         self.__pairlist_cache[pairlist_bef] = pairlist
 
         return pairlist
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/SpreadFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/SpreadFilter.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,33 +1,38 @@
 """
 Spread pair list filter
 """
+
 import logging
 from typing import Any, Dict, Optional
 
 from freqtrade.constants import Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.exchange.types import Ticker
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 
 
 logger = logging.getLogger(__name__)
 
 
 class SpreadFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._max_spread_ratio = pairlistconfig.get('max_spread_ratio', 0.005)
+        self._max_spread_ratio = pairlistconfig.get("max_spread_ratio", 0.005)
         self._enabled = self._max_spread_ratio != 0
 
-        if not self._exchange.get_option('tickers_have_bid_ask'):
+        if not self._exchange.get_option("tickers_have_bid_ask"):
             raise OperationalException(
                 f"{self.name} requires exchange to have bid/ask data for tickers, "
                 "which is not available for the selected exchange / trading mode."
             )
 
     @property
     def needstickers(self) -> bool:
@@ -38,16 +43,18 @@
         """
         return True
 
     def short_desc(self) -> str:
         """
         Short whitelist method description - used for startup-messages
         """
-        return (f"{self.name} - Filtering pairs with ask/bid diff above "
-                f"{self._max_spread_ratio:.2%}.")
+        return (
+            f"{self.name} - Filtering pairs with ask/bid diff above "
+            f"{self._max_spread_ratio:.2%}."
+        )
 
     @staticmethod
     def description() -> str:
         return "Filter by bid/ask difference."
 
     @staticmethod
     def available_parameters() -> Dict[str, PairlistParameter]:
@@ -63,19 +70,22 @@
     def _validate_pair(self, pair: str, ticker: Optional[Ticker]) -> bool:
         """
         Validate spread for the ticker
         :param pair: Pair that's currently validated
         :param ticker: ticker dict as returned from ccxt.fetch_ticker
         :return: True if the pair can stay, false if it should be removed
         """
-        if ticker and 'bid' in ticker and 'ask' in ticker and ticker['ask'] and ticker['bid']:
-            spread = 1 - ticker['bid'] / ticker['ask']
+        if ticker and "bid" in ticker and "ask" in ticker and ticker["ask"] and ticker["bid"]:
+            spread = 1 - ticker["bid"] / ticker["ask"]
             if spread > self._max_spread_ratio:
-                self.log_once(f"Removed {pair} from whitelist, because spread "
-                              f"{spread:.3%} > {self._max_spread_ratio:.3%}",
-                              logger.info)
+                self.log_once(
+                    f"Removed {pair} from whitelist, because spread "
+                    f"{spread:.3%} > {self._max_spread_ratio:.3%}",
+                    logger.info,
+                )
                 return False
             else:
                 return True
-        self.log_once(f"Removed {pair} from whitelist due to invalid ticker data: {ticker}",
-                      logger.info)
+        self.log_once(
+            f"Removed {pair} from whitelist due to invalid ticker data: {ticker}", logger.info
+        )
         return False
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/StaticPairList.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/StaticPairList.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,34 +1,39 @@
 """
 Static Pair List provider
 
 Provides pair white list as it configured in config
 """
+
 import logging
 from copy import deepcopy
 from typing import Any, Dict, List
 
 from freqtrade.constants import Config
 from freqtrade.exchange.types import Tickers
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 
 
 logger = logging.getLogger(__name__)
 
 
 class StaticPairList(IPairList):
-
     is_pairlist_generator = True
 
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._allow_inactive = self._pairlistconfig.get('allow_inactive', False)
+        self._allow_inactive = self._pairlistconfig.get("allow_inactive", False)
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
@@ -61,26 +66,27 @@
         """
         Generate the pairlist
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: List of pairs
         """
         if self._allow_inactive:
             return self.verify_whitelist(
-                self._config['exchange']['pair_whitelist'], logger.info, keep_invalid=True
+                self._config["exchange"]["pair_whitelist"], logger.info, keep_invalid=True
             )
         else:
             return self._whitelist_for_active_markets(
-                self.verify_whitelist(self._config['exchange']['pair_whitelist'], logger.info))
+                self.verify_whitelist(self._config["exchange"]["pair_whitelist"], logger.info)
+            )
 
     def filter_pairlist(self, pairlist: List[str], tickers: Tickers) -> List[str]:
         """
         Filters and sorts pairlist and returns the whitelist again.
         Called on each bot iteration - please use internal caching if necessary
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new whitelist
         """
         pairlist_ = deepcopy(pairlist)
-        for pair in self._config['exchange']['pair_whitelist']:
+        for pair in self._config["exchange"]["pair_whitelist"]:
             if pair not in pairlist_:
                 pairlist_.append(pair)
         return pairlist_
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/VolatilityFilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/VolatilityFilter.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Volatility pairlist filter
 """
+
 import logging
 import sys
 from datetime import timedelta
 from typing import Any, Dict, List, Optional
 
 import numpy as np
 from cachetools import TTLCache
@@ -22,54 +23,65 @@
 
 
 class VolatilityFilter(IPairList):
     """
     Filters pairs by volatility
     """
 
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._days = pairlistconfig.get('lookback_days', 10)
-        self._min_volatility = pairlistconfig.get('min_volatility', 0)
-        self._max_volatility = pairlistconfig.get('max_volatility', sys.maxsize)
-        self._refresh_period = pairlistconfig.get('refresh_period', 1440)
-        self._def_candletype = self._config['candle_type_def']
-        self._sort_direction: Optional[str] = pairlistconfig.get('sort_direction', None)
+        self._days = pairlistconfig.get("lookback_days", 10)
+        self._min_volatility = pairlistconfig.get("min_volatility", 0)
+        self._max_volatility = pairlistconfig.get("max_volatility", sys.maxsize)
+        self._refresh_period = pairlistconfig.get("refresh_period", 1440)
+        self._def_candletype = self._config["candle_type_def"]
+        self._sort_direction: Optional[str] = pairlistconfig.get("sort_direction", None)
 
         self._pair_cache: TTLCache = TTLCache(maxsize=1000, ttl=self._refresh_period)
 
-        candle_limit = exchange.ohlcv_candle_limit('1d', self._config['candle_type_def'])
+        candle_limit = exchange.ohlcv_candle_limit("1d", self._config["candle_type_def"])
         if self._days < 1:
             raise OperationalException("VolatilityFilter requires lookback_days to be >= 1")
         if self._days > candle_limit:
-            raise OperationalException("VolatilityFilter requires lookback_days to not "
-                                       f"exceed exchange max request size ({candle_limit})")
-        if self._sort_direction not in [None, 'asc', 'desc']:
-            raise OperationalException("VolatilityFilter requires sort_direction to be "
-                                       "either None (undefined), 'asc' or 'desc'")
+            raise OperationalException(
+                "VolatilityFilter requires lookback_days to not "
+                f"exceed exchange max request size ({candle_limit})"
+            )
+        if self._sort_direction not in [None, "asc", "desc"]:
+            raise OperationalException(
+                "VolatilityFilter requires sort_direction to be "
+                "either None (undefined), 'asc' or 'desc'"
+            )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty List is passed
         as tickers argument to filter_pairlist
         """
         return False
 
     def short_desc(self) -> str:
         """
         Short whitelist method description - used for startup-messages
         """
-        return (f"{self.name} - Filtering pairs with volatility range "
-                f"{self._min_volatility}-{self._max_volatility} "
-                f" the last {self._days} {plural(self._days, 'day')}.")
+        return (
+            f"{self.name} - Filtering pairs with volatility range "
+            f"{self._min_volatility}-{self._max_volatility} "
+            f" the last {self._days} {plural(self._days, 'day')}."
+        )
 
     @staticmethod
     def description() -> str:
         return "Filter pairs by their recent volatility."
 
     @staticmethod
     def available_parameters() -> Dict[str, PairlistParameter]:
@@ -95,59 +107,62 @@
             "sort_direction": {
                 "type": "option",
                 "default": None,
                 "options": ["", "asc", "desc"],
                 "description": "Sort pairlist",
                 "help": "Sort Pairlist ascending or descending by volatility.",
             },
-            **IPairList.refresh_period_parameter()
+            **IPairList.refresh_period_parameter(),
         }
 
     def filter_pairlist(self, pairlist: List[str], tickers: Tickers) -> List[str]:
         """
         Validate trading range
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new allowlist
         """
         needed_pairs: ListPairsWithTimeframes = [
-            (p, '1d', self._def_candletype) for p in pairlist if p not in self._pair_cache]
+            (p, "1d", self._def_candletype) for p in pairlist if p not in self._pair_cache
+        ]
 
         since_ms = dt_ts(dt_floor_day(dt_now()) - timedelta(days=self._days))
         candles = self._exchange.refresh_ohlcv_with_cache(needed_pairs, since_ms=since_ms)
 
         resulting_pairlist: List[str] = []
         volatilitys: Dict[str, float] = {}
         for p in pairlist:
-            daily_candles = candles.get((p, '1d', self._def_candletype), None)
+            daily_candles = candles.get((p, "1d", self._def_candletype), None)
 
             volatility_avg = self._calculate_volatility(p, daily_candles)
 
             if volatility_avg is not None:
                 if self._validate_pair_loc(p, volatility_avg):
                     resulting_pairlist.append(p)
                     volatilitys[p] = (
                         volatility_avg if volatility_avg and not np.isnan(volatility_avg) else 0
                     )
             else:
                 self.log_once(f"Removed {p} from whitelist, no candles found.", logger.info)
 
         if self._sort_direction:
-            resulting_pairlist = sorted(resulting_pairlist,
-                                        key=lambda p: volatilitys[p],
-                                        reverse=self._sort_direction == 'desc')
+            resulting_pairlist = sorted(
+                resulting_pairlist,
+                key=lambda p: volatilitys[p],
+                reverse=self._sort_direction == "desc",
+            )
         return resulting_pairlist
 
-    def _calculate_volatility(self, pair: str,  daily_candles: DataFrame) -> Optional[float]:
+    def _calculate_volatility(self, pair: str, daily_candles: DataFrame) -> Optional[float]:
         # Check symbol in cache
         if (volatility_avg := self._pair_cache.get(pair, None)) is not None:
             return volatility_avg
 
         if daily_candles is not None and not daily_candles.empty:
-            returns = (np.log(daily_candles["close"].shift(1) / daily_candles["close"]))
+            returns = np.log(daily_candles["close"].shift(1) / daily_candles["close"])
             returns.fillna(0, inplace=True)
 
             volatility_series = returns.rolling(window=self._days).std() * np.sqrt(self._days)
             volatility_avg = volatility_series.mean()
             self._pair_cache[pair] = volatility_avg
 
             return volatility_avg
@@ -161,15 +176,17 @@
         :param volatility_avg: Average volatility
         :return: True if the pair can stay, false if it should be removed
         """
 
         if self._min_volatility <= volatility_avg <= self._max_volatility:
             result = True
         else:
-            self.log_once(f"Removed {pair} from whitelist, because volatility "
-                          f"over {self._days} {plural(self._days, 'day')} "
-                          f"is: {volatility_avg:.3f} "
-                          f"which is not in the configured range of "
-                          f"{self._min_volatility}-{self._max_volatility}.",
-                          logger.info)
+            self.log_once(
+                f"Removed {pair} from whitelist, because volatility "
+                f"over {self._days} {plural(self._days, 'day')} "
+                f"is: {volatility_avg:.3f} "
+                f"which is not in the configured range of "
+                f"{self._min_volatility}-{self._max_volatility}.",
+                logger.info,
+            )
             result = False
         return result
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/VolumePairList.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/VolumePairList.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """
 Volume PairList provider
 
 Provides dynamic pair list based on trade volumes
 """
+
 import logging
 from datetime import timedelta
 from typing import Any, Dict, List, Literal
 
 from cachetools import TTLCache
 
 from freqtrade.constants import Config, ListPairsWithTimeframes
@@ -16,89 +17,97 @@
 from freqtrade.plugins.pairlist.IPairList import IPairList, PairlistParameter
 from freqtrade.util import dt_now, format_ms_time
 
 
 logger = logging.getLogger(__name__)
 
 
-SORT_VALUES = ['quoteVolume']
+SORT_VALUES = ["quoteVolume"]
 
 
 class VolumePairList(IPairList):
-
     is_pairlist_generator = True
 
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        if 'number_assets' not in self._pairlistconfig:
+        if "number_assets" not in self._pairlistconfig:
             raise OperationalException(
-                '`number_assets` not specified. Please check your configuration '
-                'for "pairlist.config.number_assets"')
+                "`number_assets` not specified. Please check your configuration "
+                'for "pairlist.config.number_assets"'
+            )
 
-        self._stake_currency = config['stake_currency']
-        self._number_pairs = self._pairlistconfig['number_assets']
-        self._sort_key: Literal['quoteVolume'] = self._pairlistconfig.get('sort_key', 'quoteVolume')
-        self._min_value = self._pairlistconfig.get('min_value', 0)
+        self._stake_currency = config["stake_currency"]
+        self._number_pairs = self._pairlistconfig["number_assets"]
+        self._sort_key: Literal["quoteVolume"] = self._pairlistconfig.get("sort_key", "quoteVolume")
+        self._min_value = self._pairlistconfig.get("min_value", 0)
         self._max_value = self._pairlistconfig.get("max_value", None)
-        self._refresh_period = self._pairlistconfig.get('refresh_period', 1800)
+        self._refresh_period = self._pairlistconfig.get("refresh_period", 1800)
         self._pair_cache: TTLCache = TTLCache(maxsize=1, ttl=self._refresh_period)
-        self._lookback_days = self._pairlistconfig.get('lookback_days', 0)
-        self._lookback_timeframe = self._pairlistconfig.get('lookback_timeframe', '1d')
-        self._lookback_period = self._pairlistconfig.get('lookback_period', 0)
-        self._def_candletype = self._config['candle_type_def']
+        self._lookback_days = self._pairlistconfig.get("lookback_days", 0)
+        self._lookback_timeframe = self._pairlistconfig.get("lookback_timeframe", "1d")
+        self._lookback_period = self._pairlistconfig.get("lookback_period", 0)
+        self._def_candletype = self._config["candle_type_def"]
 
         if (self._lookback_days > 0) & (self._lookback_period > 0):
             raise OperationalException(
-                'Ambigous configuration: lookback_days and lookback_period both set in pairlist '
-                'config. Please set lookback_days only or lookback_period and lookback_timeframe '
-                'and restart the bot.'
+                "Ambiguous configuration: lookback_days and lookback_period both set in pairlist "
+                "config. Please set lookback_days only or lookback_period and lookback_timeframe "
+                "and restart the bot."
             )
 
         # overwrite lookback timeframe and days when lookback_days is set
         if self._lookback_days > 0:
-            self._lookback_timeframe = '1d'
+            self._lookback_timeframe = "1d"
             self._lookback_period = self._lookback_days
 
         # get timeframe in minutes and seconds
         self._tf_in_min = timeframe_to_minutes(self._lookback_timeframe)
         _tf_in_sec = self._tf_in_min * 60
 
         # whether to use range lookback or not
         self._use_range = (self._tf_in_min > 0) & (self._lookback_period > 0)
 
         if self._use_range & (self._refresh_period < _tf_in_sec):
             raise OperationalException(
-                f'Refresh period of {self._refresh_period} seconds is smaller than one '
-                f'timeframe of {self._lookback_timeframe}. Please adjust refresh_period '
-                f'to at least {_tf_in_sec} and restart the bot.'
+                f"Refresh period of {self._refresh_period} seconds is smaller than one "
+                f"timeframe of {self._lookback_timeframe}. Please adjust refresh_period "
+                f"to at least {_tf_in_sec} and restart the bot."
             )
 
-        if (not self._use_range and not (
-                self._exchange.exchange_has('fetchTickers')
-                and self._exchange.get_option("tickers_have_quoteVolume"))):
+        if not self._use_range and not (
+            self._exchange.exchange_has("fetchTickers")
+            and self._exchange.get_option("tickers_have_quoteVolume")
+        ):
             raise OperationalException(
                 "Exchange does not support dynamic whitelist in this configuration. "
                 "Please edit your config and either remove Volumepairlist, "
                 "or switch to using candles. and restart the bot."
             )
 
         if not self._validate_keys(self._sort_key):
-            raise OperationalException(
-                f'key {self._sort_key} not in {SORT_VALUES}')
+            raise OperationalException(f"key {self._sort_key} not in {SORT_VALUES}")
 
         candle_limit = exchange.ohlcv_candle_limit(
-            self._lookback_timeframe, self._config['candle_type_def'])
+            self._lookback_timeframe, self._config["candle_type_def"]
+        )
         if self._lookback_period < 0:
             raise OperationalException("VolumeFilter requires lookback_period to be >= 0")
         if self._lookback_period > candle_limit:
-            raise OperationalException("VolumeFilter requires lookback_period to not "
-                                       f"exceed exchange max request size ({candle_limit})")
+            raise OperationalException(
+                "VolumeFilter requires lookback_period to not "
+                f"exceed exchange max request size ({candle_limit})"
+            )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty Dict is passed
         as tickers argument to filter_pairlist
@@ -171,122 +180,143 @@
         """
         Generate the pairlist
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: List of pairs
         """
         # Generate dynamic whitelist
         # Must always run if this pairlist is not the first in the list.
-        pairlist = self._pair_cache.get('pairlist')
+        pairlist = self._pair_cache.get("pairlist")
         if pairlist:
             # Item found - no refresh necessary
             return pairlist.copy()
         else:
             # Use fresh pairlist
             # Check if pair quote currency equals to the stake currency.
-            _pairlist = [k for k in self._exchange.get_markets(
-                quote_currencies=[self._stake_currency],
-                tradable_only=True, active_only=True).keys()]
+            _pairlist = [
+                k
+                for k in self._exchange.get_markets(
+                    quote_currencies=[self._stake_currency], tradable_only=True, active_only=True
+                ).keys()
+            ]
             # No point in testing for blacklisted pairs...
             _pairlist = self.verify_blacklist(_pairlist, logger.info)
             if not self._use_range:
                 filtered_tickers = [
-                    v for k, v in tickers.items()
-                    if (self._exchange.get_pair_quote_currency(k) == self._stake_currency
+                    v
+                    for k, v in tickers.items()
+                    if (
+                        self._exchange.get_pair_quote_currency(k) == self._stake_currency
                         and (self._use_range or v.get(self._sort_key) is not None)
-                        and v['symbol'] in _pairlist)]
-                pairlist = [s['symbol'] for s in filtered_tickers]
+                        and v["symbol"] in _pairlist
+                    )
+                ]
+                pairlist = [s["symbol"] for s in filtered_tickers]
             else:
                 pairlist = _pairlist
 
             pairlist = self.filter_pairlist(pairlist, tickers)
-            self._pair_cache['pairlist'] = pairlist.copy()
+            self._pair_cache["pairlist"] = pairlist.copy()
 
         return pairlist
 
     def filter_pairlist(self, pairlist: List[str], tickers: Dict) -> List[str]:
         """
         Filters and sorts pairlist and returns the whitelist again.
         Called on each bot iteration - please use internal caching if necessary
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new whitelist
         """
         if self._use_range:
             # Create bare minimum from tickers structure.
-            filtered_tickers: List[Dict[str, Any]] = [{'symbol': k} for k in pairlist]
+            filtered_tickers: List[Dict[str, Any]] = [{"symbol": k} for k in pairlist]
 
             # get lookback period in ms, for exchange ohlcv fetch
-            since_ms = int(timeframe_to_prev_date(
-                self._lookback_timeframe,
-                dt_now() + timedelta(
-                    minutes=-(self._lookback_period * self._tf_in_min) - self._tf_in_min)
-                    ).timestamp()) * 1000
-
-            to_ms = int(timeframe_to_prev_date(
-                            self._lookback_timeframe,
-                            dt_now() - timedelta(minutes=self._tf_in_min)
-                            ).timestamp()) * 1000
+            since_ms = (
+                int(
+                    timeframe_to_prev_date(
+                        self._lookback_timeframe,
+                        dt_now()
+                        + timedelta(
+                            minutes=-(self._lookback_period * self._tf_in_min) - self._tf_in_min
+                        ),
+                    ).timestamp()
+                )
+                * 1000
+            )
+
+            to_ms = (
+                int(
+                    timeframe_to_prev_date(
+                        self._lookback_timeframe, dt_now() - timedelta(minutes=self._tf_in_min)
+                    ).timestamp()
+                )
+                * 1000
+            )
 
             # todo: utc date output for starting date
-            self.log_once(f"Using volume range of {self._lookback_period} candles, timeframe: "
-                          f"{self._lookback_timeframe}, starting from {format_ms_time(since_ms)} "
-                          f"till {format_ms_time(to_ms)}", logger.info)
+            self.log_once(
+                f"Using volume range of {self._lookback_period} candles, timeframe: "
+                f"{self._lookback_timeframe}, starting from {format_ms_time(since_ms)} "
+                f"till {format_ms_time(to_ms)}",
+                logger.info,
+            )
             needed_pairs: ListPairsWithTimeframes = [
-                (p, self._lookback_timeframe, self._def_candletype) for p in
-                [s['symbol'] for s in filtered_tickers]
+                (p, self._lookback_timeframe, self._def_candletype)
+                for p in [s["symbol"] for s in filtered_tickers]
                 if p not in self._pair_cache
             ]
 
             candles = self._exchange.refresh_ohlcv_with_cache(needed_pairs, since_ms)
 
             for i, p in enumerate(filtered_tickers):
-                contract_size = self._exchange.markets[p['symbol']].get('contractSize', 1.0) or 1.0
-                pair_candles = candles[
-                    (p['symbol'], self._lookback_timeframe, self._def_candletype)
-                ] if (
-                    p['symbol'], self._lookback_timeframe, self._def_candletype
-                    ) in candles else None
+                contract_size = self._exchange.markets[p["symbol"]].get("contractSize", 1.0) or 1.0
+                pair_candles = (
+                    candles[(p["symbol"], self._lookback_timeframe, self._def_candletype)]
+                    if (p["symbol"], self._lookback_timeframe, self._def_candletype) in candles
+                    else None
+                )
                 # in case of candle data calculate typical price and quoteVolume for candle
                 if pair_candles is not None and not pair_candles.empty:
                     if self._exchange.get_option("ohlcv_volume_currency") == "base":
-                        pair_candles['typical_price'] = (pair_candles['high'] + pair_candles['low']
-                                                         + pair_candles['close']) / 3
+                        pair_candles["typical_price"] = (
+                            pair_candles["high"] + pair_candles["low"] + pair_candles["close"]
+                        ) / 3
 
-                        pair_candles['quoteVolume'] = (
-                            pair_candles['volume'] * pair_candles['typical_price']
-                            * contract_size
+                        pair_candles["quoteVolume"] = (
+                            pair_candles["volume"] * pair_candles["typical_price"] * contract_size
                         )
                     else:
                         # Exchange ohlcv data is in quote volume already.
-                        pair_candles['quoteVolume'] = pair_candles['volume']
+                        pair_candles["quoteVolume"] = pair_candles["volume"]
                     # ensure that a rolling sum over the lookback_period is built
                     # if pair_candles contains more candles than lookback_period
-                    quoteVolume = (pair_candles['quoteVolume']
-                                   .rolling(self._lookback_period)
-                                   .sum()
-                                   .fillna(0)
-                                   .iloc[-1])
+                    quoteVolume = (
+                        pair_candles["quoteVolume"]
+                        .rolling(self._lookback_period)
+                        .sum()
+                        .fillna(0)
+                        .iloc[-1]
+                    )
 
                     # replace quoteVolume with range quoteVolume sum calculated above
-                    filtered_tickers[i]['quoteVolume'] = quoteVolume
+                    filtered_tickers[i]["quoteVolume"] = quoteVolume
                 else:
-                    filtered_tickers[i]['quoteVolume'] = 0
+                    filtered_tickers[i]["quoteVolume"] = 0
         else:
             # Tickers mode - filter based on incoming pairlist.
             filtered_tickers = [v for k, v in tickers.items() if k in pairlist]
 
         if self._min_value > 0:
-            filtered_tickers = [
-                v for v in filtered_tickers if v[self._sort_key] > self._min_value]
+            filtered_tickers = [v for v in filtered_tickers if v[self._sort_key] > self._min_value]
         if self._max_value is not None:
-            filtered_tickers = [
-                v for v in filtered_tickers if v[self._sort_key] < self._max_value]
+            filtered_tickers = [v for v in filtered_tickers if v[self._sort_key] < self._max_value]
 
         sorted_tickers = sorted(filtered_tickers, reverse=True, key=lambda t: t[self._sort_key])
 
         # Validate whitelist to only have active market pairs
-        pairs = self._whitelist_for_active_markets([s['symbol'] for s in sorted_tickers])
+        pairs = self._whitelist_for_active_markets([s["symbol"] for s in sorted_tickers])
         pairs = self.verify_blacklist(pairs, logmethod=logger.info)
         # Limit pairlist to the requested number of pairs
-        pairs = pairs[:self._number_pairs]
+        pairs = pairs[: self._number_pairs]
 
         return pairs
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/pairlist_helpers.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/pairlist_helpers.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,53 +1,49 @@
 import re
 from typing import List
 
 from freqtrade.constants import Config
 
 
-def expand_pairlist(wildcardpl: List[str], available_pairs: List[str],
-                    keep_invalid: bool = False) -> List[str]:
+def expand_pairlist(
+    wildcardpl: List[str], available_pairs: List[str], keep_invalid: bool = False
+) -> List[str]:
     """
     Expand pairlist potentially containing wildcards based on available markets.
     This will implicitly filter all pairs in the wildcard-list which are not in available_pairs.
     :param wildcardpl: List of Pairlists, which may contain regex
     :param available_pairs: List of all available pairs (`exchange.get_markets().keys()`)
     :param keep_invalid: If sets to True, drops invalid pairs silently while expanding regexes
     :return: expanded pairlist, with Regexes from wildcardpl applied to match all available pairs.
     :raises: ValueError if a wildcard is invalid (like '*/BTC' - which should be `.*/BTC`)
     """
     result = []
     if keep_invalid:
         for pair_wc in wildcardpl:
             try:
                 comp = re.compile(pair_wc, re.IGNORECASE)
-                result_partial = [
-                    pair for pair in available_pairs if re.fullmatch(comp, pair)
-                ]
+                result_partial = [pair for pair in available_pairs if re.fullmatch(comp, pair)]
                 # Add all matching pairs.
                 # If there are no matching pairs (Pair not on exchange) keep it.
                 result += result_partial or [pair_wc]
             except re.error as err:
                 raise ValueError(f"Wildcard error in {pair_wc}, {err}")
 
-        result = [element for element in result if re.fullmatch(r'^[A-Za-z0-9:/-]+$', element)]
+        result = [element for element in result if re.fullmatch(r"^[A-Za-z0-9:/-]+$", element)]
 
     else:
         for pair_wc in wildcardpl:
             try:
                 comp = re.compile(pair_wc, re.IGNORECASE)
-                result += [
-                    pair for pair in available_pairs if re.fullmatch(comp, pair)
-                ]
+                result += [pair for pair in available_pairs if re.fullmatch(comp, pair)]
             except re.error as err:
                 raise ValueError(f"Wildcard error in {pair_wc}, {err}")
     return result
 
 
 def dynamic_expand_pairlist(config: Config, markets: List[str]) -> List[str]:
-    expanded_pairs = expand_pairlist(config['pairs'], markets)
-    if config.get('freqai', {}).get('enabled', False):
-        corr_pairlist = config['freqai']['feature_parameters']['include_corr_pairlist']
-        expanded_pairs += [pair for pair in corr_pairlist
-                           if pair not in config['pairs']]
+    expanded_pairs = expand_pairlist(config["pairs"], markets)
+    if config.get("freqai", {}).get("enabled", False):
+        corr_pairlist = config["freqai"]["feature_parameters"]["include_corr_pairlist"]
+        expanded_pairs += [pair for pair in corr_pairlist if pair not in config["pairs"]]
 
     return expanded_pairs
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlist/rangestabilityfilter.py` & `freqtrade-2024.5/freqtrade/plugins/pairlist/rangestabilityfilter.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Rate of change pairlist filter
 """
+
 import logging
 from datetime import timedelta
 from typing import Any, Dict, List, Optional
 
 from cachetools import TTLCache
 from pandas import DataFrame
 
@@ -16,38 +17,46 @@
 from freqtrade.util import dt_floor_day, dt_now, dt_ts
 
 
 logger = logging.getLogger(__name__)
 
 
 class RangeStabilityFilter(IPairList):
-
-    def __init__(self, exchange, pairlistmanager,
-                 config: Config, pairlistconfig: Dict[str, Any],
-                 pairlist_pos: int) -> None:
+    def __init__(
+        self,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: Dict[str, Any],
+        pairlist_pos: int,
+    ) -> None:
         super().__init__(exchange, pairlistmanager, config, pairlistconfig, pairlist_pos)
 
-        self._days = pairlistconfig.get('lookback_days', 10)
-        self._min_rate_of_change = pairlistconfig.get('min_rate_of_change', 0.01)
-        self._max_rate_of_change = pairlistconfig.get('max_rate_of_change')
-        self._refresh_period = pairlistconfig.get('refresh_period', 86400)
-        self._def_candletype = self._config['candle_type_def']
-        self._sort_direction: Optional[str] = pairlistconfig.get('sort_direction', None)
+        self._days = pairlistconfig.get("lookback_days", 10)
+        self._min_rate_of_change = pairlistconfig.get("min_rate_of_change", 0.01)
+        self._max_rate_of_change = pairlistconfig.get("max_rate_of_change")
+        self._refresh_period = pairlistconfig.get("refresh_period", 86400)
+        self._def_candletype = self._config["candle_type_def"]
+        self._sort_direction: Optional[str] = pairlistconfig.get("sort_direction", None)
 
         self._pair_cache: TTLCache = TTLCache(maxsize=1000, ttl=self._refresh_period)
 
-        candle_limit = exchange.ohlcv_candle_limit('1d', self._config['candle_type_def'])
+        candle_limit = exchange.ohlcv_candle_limit("1d", self._config["candle_type_def"])
         if self._days < 1:
             raise OperationalException("RangeStabilityFilter requires lookback_days to be >= 1")
         if self._days > candle_limit:
-            raise OperationalException("RangeStabilityFilter requires lookback_days to not "
-                                       f"exceed exchange max request size ({candle_limit})")
-        if self._sort_direction not in [None, 'asc', 'desc']:
-            raise OperationalException("RangeStabilityFilter requires sort_direction to be "
-                                       "either None (undefined), 'asc' or 'desc'")
+            raise OperationalException(
+                "RangeStabilityFilter requires lookback_days to not "
+                f"exceed exchange max request size ({candle_limit})"
+            )
+        if self._sort_direction not in [None, "asc", "desc"]:
+            raise OperationalException(
+                "RangeStabilityFilter requires sort_direction to be "
+                "either None (undefined), 'asc' or 'desc'"
+            )
 
     @property
     def needstickers(self) -> bool:
         """
         Boolean property defining if tickers are necessary.
         If no Pairlist requires tickers, an empty List is passed
         as tickers argument to filter_pairlist
@@ -56,18 +65,20 @@
 
     def short_desc(self) -> str:
         """
         Short whitelist method description - used for startup-messages
         """
         max_rate_desc = ""
         if self._max_rate_of_change:
-            max_rate_desc = (f" and above {self._max_rate_of_change}")
-        return (f"{self.name} - Filtering pairs with rate of change below "
-                f"{self._min_rate_of_change}{max_rate_desc} over the "
-                f"last {plural(self._days, 'day')}.")
+            max_rate_desc = f" and above {self._max_rate_of_change}"
+        return (
+            f"{self.name} - Filtering pairs with rate of change below "
+            f"{self._min_rate_of_change}{max_rate_desc} over the "
+            f"last {plural(self._days, 'day')}."
+        )
 
     @staticmethod
     def description() -> str:
         return "Filters pairs by their rate of change."
 
     @staticmethod
     def available_parameters() -> Dict[str, PairlistParameter]:
@@ -93,59 +104,61 @@
             "sort_direction": {
                 "type": "option",
                 "default": None,
                 "options": ["", "asc", "desc"],
                 "description": "Sort pairlist",
                 "help": "Sort Pairlist ascending or descending by rate of change.",
             },
-            **IPairList.refresh_period_parameter()
+            **IPairList.refresh_period_parameter(),
         }
 
     def filter_pairlist(self, pairlist: List[str], tickers: Tickers) -> List[str]:
         """
         Validate trading range
         :param pairlist: pairlist to filter or sort
         :param tickers: Tickers (from exchange.get_tickers). May be cached.
         :return: new allowlist
         """
         needed_pairs: ListPairsWithTimeframes = [
-            (p, '1d', self._def_candletype) for p in pairlist if p not in self._pair_cache]
+            (p, "1d", self._def_candletype) for p in pairlist if p not in self._pair_cache
+        ]
 
         since_ms = dt_ts(dt_floor_day(dt_now()) - timedelta(days=self._days + 1))
         candles = self._exchange.refresh_ohlcv_with_cache(needed_pairs, since_ms=since_ms)
 
         resulting_pairlist: List[str] = []
         pct_changes: Dict[str, float] = {}
 
         for p in pairlist:
-            daily_candles = candles.get((p, '1d', self._def_candletype), None)
+            daily_candles = candles.get((p, "1d", self._def_candletype), None)
 
             pct_change = self._calculate_rate_of_change(p, daily_candles)
 
             if pct_change is not None:
                 if self._validate_pair_loc(p, pct_change):
                     resulting_pairlist.append(p)
                     pct_changes[p] = pct_change
             else:
                 self.log_once(f"Removed {p} from whitelist, no candles found.", logger.info)
 
         if self._sort_direction:
-            resulting_pairlist = sorted(resulting_pairlist,
-                                        key=lambda p: pct_changes[p],
-                                        reverse=self._sort_direction == 'desc')
+            resulting_pairlist = sorted(
+                resulting_pairlist,
+                key=lambda p: pct_changes[p],
+                reverse=self._sort_direction == "desc",
+            )
         return resulting_pairlist
 
     def _calculate_rate_of_change(self, pair: str, daily_candles: DataFrame) -> Optional[float]:
         # Check symbol in cache
         if (pct_change := self._pair_cache.get(pair, None)) is not None:
             return pct_change
         if daily_candles is not None and not daily_candles.empty:
-
-            highest_high = daily_candles['high'].max()
-            lowest_low = daily_candles['low'].min()
+            highest_high = daily_candles["high"].max()
+            lowest_low = daily_candles["low"].min()
             pct_change = ((highest_high - lowest_low) / lowest_low) if lowest_low > 0 else 0
             self._pair_cache[pair] = pct_change
             return pct_change
         else:
             return None
 
     def _validate_pair_loc(self, pair: str, pct_change: float) -> bool:
@@ -154,21 +167,24 @@
         :param pair: Pair that's currently validated
         :param pct_change: Rate of change
         :return: True if the pair can stay, false if it should be removed
         """
 
         result = True
         if pct_change < self._min_rate_of_change:
-            self.log_once(f"Removed {pair} from whitelist, because rate of change "
-                          f"over {self._days} {plural(self._days, 'day')} is {pct_change:.3f}, "
-                          f"which is below the threshold of {self._min_rate_of_change}.",
-                          logger.info)
+            self.log_once(
+                f"Removed {pair} from whitelist, because rate of change "
+                f"over {self._days} {plural(self._days, 'day')} is {pct_change:.3f}, "
+                f"which is below the threshold of {self._min_rate_of_change}.",
+                logger.info,
+            )
             result = False
         if self._max_rate_of_change:
             if pct_change > self._max_rate_of_change:
                 self.log_once(
                     f"Removed {pair} from whitelist, because rate of change "
                     f"over {self._days} {plural(self._days, 'day')} is {pct_change:.3f}, "
                     f"which is above the threshold of {self._max_rate_of_change}.",
-                    logger.info)
+                    logger.info,
+                )
                 result = False
         return result
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/pairlistmanager.py` & `freqtrade-2024.5/freqtrade/plugins/pairlistmanager.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 PairList manager class
 """
+
 import logging
 from functools import partial
 from typing import Dict, List, Optional
 
 from cachetools import TTLCache, cached
 
 from freqtrade.constants import Config, ListPairsWithTimeframes
@@ -18,49 +19,49 @@
 from freqtrade.resolvers import PairListResolver
 
 
 logger = logging.getLogger(__name__)
 
 
 class PairListManager(LoggingMixin):
-
     def __init__(
-            self, exchange, config: Config, dataprovider: Optional[DataProvider] = None) -> None:
+        self, exchange, config: Config, dataprovider: Optional[DataProvider] = None
+    ) -> None:
         self._exchange = exchange
         self._config = config
-        self._whitelist = self._config['exchange'].get('pair_whitelist')
-        self._blacklist = self._config['exchange'].get('pair_blacklist', [])
+        self._whitelist = self._config["exchange"].get("pair_whitelist")
+        self._blacklist = self._config["exchange"].get("pair_blacklist", [])
         self._pairlist_handlers: List[IPairList] = []
         self._tickers_needed = False
         self._dataprovider: Optional[DataProvider] = dataprovider
-        for pairlist_handler_config in self._config.get('pairlists', []):
+        for pairlist_handler_config in self._config.get("pairlists", []):
             pairlist_handler = PairListResolver.load_pairlist(
-                pairlist_handler_config['method'],
+                pairlist_handler_config["method"],
                 exchange=exchange,
                 pairlistmanager=self,
                 config=config,
                 pairlistconfig=pairlist_handler_config,
-                pairlist_pos=len(self._pairlist_handlers)
+                pairlist_pos=len(self._pairlist_handlers),
             )
             self._tickers_needed |= pairlist_handler.needstickers
             self._pairlist_handlers.append(pairlist_handler)
 
         if not self._pairlist_handlers:
             raise OperationalException("No Pairlist Handlers defined")
 
-        if self._tickers_needed and not self._exchange.exchange_has('fetchTickers'):
+        if self._tickers_needed and not self._exchange.exchange_has("fetchTickers"):
             invalid = ". ".join([p.name for p in self._pairlist_handlers if p.needstickers])
 
             raise OperationalException(
                 "Exchange does not support fetchTickers, therefore the following pairlists "
                 "cannot be used. Please edit your config and restart the bot.\n"
                 f"{invalid}."
             )
 
-        refresh_period = config.get('pairlist_refresh_period', 3600)
+        refresh_period = config.get("pairlist_refresh_period", 3600)
         LoggingMixin.__init__(self, logger, refresh_period)
 
     @property
     def whitelist(self) -> List[str]:
         """The current whitelist"""
         return self._whitelist
 
@@ -131,16 +132,17 @@
         log_once = partial(self.log_once, logmethod=logmethod)
         for pair in pairlist.copy():
             if pair in blacklist:
                 log_once(f"Pair {pair} in your blacklist. Removing it from whitelist...")
                 pairlist.remove(pair)
         return pairlist
 
-    def verify_whitelist(self, pairlist: List[str], logmethod,
-                         keep_invalid: bool = False) -> List[str]:
+    def verify_whitelist(
+        self, pairlist: List[str], logmethod, keep_invalid: bool = False
+    ) -> List[str]:
         """
         Verify and remove items from pairlist - returning a filtered pairlist.
         Logs a warning or info depending on `aswarning`.
         Pairlist Handlers explicitly using this method shall use
         `logmethod=logger.info` to avoid spamming with warning messages
         :param pairlist: Pairlist to validate
         :param logmethod: Function that'll be called, `logger.info` or `logger.warning`
@@ -151,18 +153,20 @@
             whitelist = expand_pairlist(pairlist, self._exchange.get_markets().keys(), keep_invalid)
         except ValueError as err:
             logger.error(f"Pair whitelist contains an invalid Wildcard: {err}")
             return []
         return whitelist
 
     def create_pair_list(
-            self, pairs: List[str], timeframe: Optional[str] = None) -> ListPairsWithTimeframes:
+        self, pairs: List[str], timeframe: Optional[str] = None
+    ) -> ListPairsWithTimeframes:
         """
         Create list of pair tuples with (pair, timeframe)
         """
         return [
             (
                 pair,
-                timeframe or self._config['timeframe'],
-                self._config.get('candle_type_def', CandleType.SPOT)
-            ) for pair in pairs
+                timeframe or self._config["timeframe"],
+                self._config.get("candle_type_def", CandleType.SPOT),
+            )
+            for pair in pairs
         ]
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/protectionmanager.py` & `freqtrade-2024.5/freqtrade/plugins/protectionmanager.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Protection manager class
 """
+
 import logging
 from datetime import datetime, timezone
 from typing import Dict, List, Optional
 
 from freqtrade.constants import Config, LongShort
 from freqtrade.persistence import PairLocks
 from freqtrade.persistence.models import PairLock
@@ -12,22 +13,21 @@
 from freqtrade.resolvers import ProtectionResolver
 
 
 logger = logging.getLogger(__name__)
 
 
 class ProtectionManager:
-
     def __init__(self, config: Config, protections: List) -> None:
         self._config = config
 
         self._protection_handlers: List[IProtection] = []
         for protection_handler_config in protections:
             protection_handler = ProtectionResolver.load_protection(
-                protection_handler_config['method'],
+                protection_handler_config["method"],
                 config=config,
                 protection_config=protection_handler_config,
             )
             self._protection_handlers.append(protection_handler)
 
         if not self._protection_handlers:
             logger.info("No protection Handlers defined.")
@@ -41,35 +41,38 @@
 
     def short_desc(self) -> List[Dict]:
         """
         List of short_desc for each Pairlist Handler
         """
         return [{p.name: p.short_desc()} for p in self._protection_handlers]
 
-    def global_stop(self, now: Optional[datetime] = None,
-                    side: LongShort = 'long') -> Optional[PairLock]:
+    def global_stop(
+        self, now: Optional[datetime] = None, side: LongShort = "long"
+    ) -> Optional[PairLock]:
         if not now:
             now = datetime.now(timezone.utc)
         result = None
         for protection_handler in self._protection_handlers:
             if protection_handler.has_global_stop:
                 lock = protection_handler.global_stop(date_now=now, side=side)
                 if lock and lock.until:
                     if not PairLocks.is_global_lock(lock.until, side=lock.lock_side):
                         result = PairLocks.lock_pair(
-                            '*', lock.until, lock.reason, now=now, side=lock.lock_side)
+                            "*", lock.until, lock.reason, now=now, side=lock.lock_side
+                        )
         return result
 
-    def stop_per_pair(self, pair, now: Optional[datetime] = None,
-                      side: LongShort = 'long') -> Optional[PairLock]:
+    def stop_per_pair(
+        self, pair, now: Optional[datetime] = None, side: LongShort = "long"
+    ) -> Optional[PairLock]:
         if not now:
             now = datetime.now(timezone.utc)
         result = None
         for protection_handler in self._protection_handlers:
             if protection_handler.has_local_stop:
-                lock = protection_handler.stop_per_pair(
-                    pair=pair, date_now=now, side=side)
+                lock = protection_handler.stop_per_pair(pair=pair, date_now=now, side=side)
                 if lock and lock.until:
                     if not PairLocks.is_pair_locked(pair, lock.until, lock.lock_side):
                         result = PairLocks.lock_pair(
-                            pair, lock.until, lock.reason, now=now, side=lock.lock_side)
+                            pair, lock.until, lock.reason, now=now, side=lock.lock_side
+                        )
         return result
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/protections/cooldown_period.py` & `freqtrade-2024.5/freqtrade/plugins/protections/cooldown_period.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,36 +1,34 @@
-
 import logging
 from datetime import datetime, timedelta
 from typing import Optional
 
 from freqtrade.constants import LongShort
 from freqtrade.persistence import Trade
 from freqtrade.plugins.protections import IProtection, ProtectionReturn
 
 
 logger = logging.getLogger(__name__)
 
 
 class CooldownPeriod(IProtection):
-
     has_global_stop: bool = False
     has_local_stop: bool = True
 
     def _reason(self) -> str:
         """
         LockReason to use
         """
-        return (f'Cooldown period for {self.stop_duration_str}.')
+        return f"Cooldown period for {self.stop_duration_str}."
 
     def short_desc(self) -> str:
         """
         Short method description - used for startup-messages
         """
-        return (f"{self.name} - Cooldown period of {self.stop_duration_str}.")
+        return f"{self.name} - Cooldown period of {self.stop_duration_str}."
 
     def _cooldown_period(self, pair: str, date_now: datetime) -> Optional[ProtectionReturn]:
         """
         Get last trade for this pair
         """
         look_back_until = date_now - timedelta(minutes=self._stop_duration)
         # filters = [
@@ -62,15 +60,16 @@
         :return: Tuple of [bool, until, reason].
             If true, all pairs will be locked with <reason> until <until>
         """
         # Not implemented for cooldown period.
         return None
 
     def stop_per_pair(
-            self, pair: str, date_now: datetime, side: LongShort) -> Optional[ProtectionReturn]:
+        self, pair: str, date_now: datetime, side: LongShort
+    ) -> Optional[ProtectionReturn]:
         """
         Stops trading (position entering) for this pair
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, this pair will be locked with <reason> until <until>
         """
         return self._cooldown_period(pair, date_now)
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/protections/iprotection.py` & `freqtrade-2024.5/freqtrade/plugins/protections/iprotection.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 import logging
 from abc import ABC, abstractmethod
 from dataclasses import dataclass
 from datetime import datetime, timedelta, timezone
 from typing import Any, Dict, List, Optional
 
 from freqtrade.constants import Config, LongShort
@@ -16,73 +15,74 @@
 
 
 @dataclass
 class ProtectionReturn:
     lock: bool
     until: datetime
     reason: Optional[str]
-    lock_side: str = '*'
+    lock_side: str = "*"
 
 
 class IProtection(LoggingMixin, ABC):
-
     # Can globally stop the bot
     has_global_stop: bool = False
     # Can stop trading for one pair
     has_local_stop: bool = False
 
     def __init__(self, config: Config, protection_config: Dict[str, Any]) -> None:
         self._config = config
         self._protection_config = protection_config
         self._stop_duration_candles: Optional[int] = None
         self._lookback_period_candles: Optional[int] = None
 
-        tf_in_min = timeframe_to_minutes(config['timeframe'])
-        if 'stop_duration_candles' in protection_config:
-            self._stop_duration_candles = int(protection_config.get('stop_duration_candles', 1))
-            self._stop_duration = (tf_in_min * self._stop_duration_candles)
+        tf_in_min = timeframe_to_minutes(config["timeframe"])
+        if "stop_duration_candles" in protection_config:
+            self._stop_duration_candles = int(protection_config.get("stop_duration_candles", 1))
+            self._stop_duration = tf_in_min * self._stop_duration_candles
         else:
             self._stop_duration_candles = None
-            self._stop_duration = int(protection_config.get('stop_duration', 60))
-        if 'lookback_period_candles' in protection_config:
-            self._lookback_period_candles = int(protection_config.get('lookback_period_candles', 1))
+            self._stop_duration = int(protection_config.get("stop_duration", 60))
+        if "lookback_period_candles" in protection_config:
+            self._lookback_period_candles = int(protection_config.get("lookback_period_candles", 1))
             self._lookback_period = tf_in_min * self._lookback_period_candles
         else:
             self._lookback_period_candles = None
-            self._lookback_period = int(protection_config.get('lookback_period', 60))
+            self._lookback_period = int(protection_config.get("lookback_period", 60))
 
         LoggingMixin.__init__(self, logger)
 
     @property
     def name(self) -> str:
         return self.__class__.__name__
 
     @property
     def stop_duration_str(self) -> str:
         """
         Output configured stop duration in either candles or minutes
         """
         if self._stop_duration_candles:
-            return (f"{self._stop_duration_candles} "
-                    f"{plural(self._stop_duration_candles, 'candle', 'candles')}")
+            return (
+                f"{self._stop_duration_candles} "
+                f"{plural(self._stop_duration_candles, 'candle', 'candles')}"
+            )
         else:
-            return (f"{self._stop_duration} "
-                    f"{plural(self._stop_duration, 'minute', 'minutes')}")
+            return f"{self._stop_duration} {plural(self._stop_duration, 'minute', 'minutes')}"
 
     @property
     def lookback_period_str(self) -> str:
         """
         Output configured lookback period in either candles or minutes
         """
         if self._lookback_period_candles:
-            return (f"{self._lookback_period_candles} "
-                    f"{plural(self._lookback_period_candles, 'candle', 'candles')}")
+            return (
+                f"{self._lookback_period_candles} "
+                f"{plural(self._lookback_period_candles, 'candle', 'candles')}"
+            )
         else:
-            return (f"{self._lookback_period} "
-                    f"{plural(self._lookback_period, 'minute', 'minutes')}")
+            return f"{self._lookback_period} {plural(self._lookback_period, 'minute', 'minutes')}"
 
     @abstractmethod
     def short_desc(self) -> str:
         """
         Short method description - used for startup-messages
         -> Please overwrite in subclasses
         """
@@ -92,15 +92,16 @@
         """
         Stops trading (position entering) for all pairs
         This must evaluate to true for the whole period of the "cooldown period".
         """
 
     @abstractmethod
     def stop_per_pair(
-            self, pair: str, date_now: datetime, side: LongShort) -> Optional[ProtectionReturn]:
+        self, pair: str, date_now: datetime, side: LongShort
+    ) -> Optional[ProtectionReturn]:
         """
         Stops trading (position entering) for this pair
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, this pair will be locked with <reason> until <until>
         """
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/protections/low_profit_pairs.py` & `freqtrade-2024.5/freqtrade/plugins/protections/low_profit_pairs.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,48 +1,51 @@
-
 import logging
 from datetime import datetime, timedelta
 from typing import Any, Dict, Optional
 
 from freqtrade.constants import Config, LongShort
 from freqtrade.persistence import Trade
 from freqtrade.plugins.protections import IProtection, ProtectionReturn
 
 
 logger = logging.getLogger(__name__)
 
 
 class LowProfitPairs(IProtection):
-
     has_global_stop: bool = False
     has_local_stop: bool = True
 
     def __init__(self, config: Config, protection_config: Dict[str, Any]) -> None:
         super().__init__(config, protection_config)
 
-        self._trade_limit = protection_config.get('trade_limit', 1)
-        self._required_profit = protection_config.get('required_profit', 0.0)
-        self._only_per_side = protection_config.get('only_per_side', False)
+        self._trade_limit = protection_config.get("trade_limit", 1)
+        self._required_profit = protection_config.get("required_profit", 0.0)
+        self._only_per_side = protection_config.get("only_per_side", False)
 
     def short_desc(self) -> str:
         """
         Short method description - used for startup-messages
         """
-        return (f"{self.name} - Low Profit Protection, locks pairs with "
-                f"profit < {self._required_profit} within {self.lookback_period_str}.")
+        return (
+            f"{self.name} - Low Profit Protection, locks pairs with "
+            f"profit < {self._required_profit} within {self.lookback_period_str}."
+        )
 
     def _reason(self, profit: float) -> str:
         """
         LockReason to use
         """
-        return (f'{profit} < {self._required_profit} in {self.lookback_period_str}, '
-                f'locking for {self.stop_duration_str}.')
+        return (
+            f"{profit} < {self._required_profit} in {self.lookback_period_str}, "
+            f"locking for {self.stop_duration_str}."
+        )
 
     def _low_profit(
-            self, date_now: datetime, pair: str, side: LongShort) -> Optional[ProtectionReturn]:
+        self, date_now: datetime, pair: str, side: LongShort
+    ) -> Optional[ProtectionReturn]:
         """
         Evaluate recent trades for pair
         """
         look_back_until = date_now - timedelta(minutes=self._lookback_period)
         # filters = [
         #     Trade.is_open.is_(False),
         #     Trade.close_date > look_back_until,
@@ -53,43 +56,47 @@
         trades = Trade.get_trades_proxy(pair=pair, is_open=False, close_date=look_back_until)
         # trades = Trade.get_trades(filters).all()
         if len(trades) < self._trade_limit:
             # Not enough trades in the relevant period
             return None
 
         profit = sum(
-            trade.close_profit for trade in trades if trade.close_profit
-            and (not self._only_per_side or trade.trade_direction == side)
-            )
+            trade.close_profit
+            for trade in trades
+            if trade.close_profit and (not self._only_per_side or trade.trade_direction == side)
+        )
         if profit < self._required_profit:
             self.log_once(
                 f"Trading for {pair} stopped due to {profit:.2f} < {self._required_profit} "
-                f"within {self._lookback_period} minutes.", logger.info)
+                f"within {self._lookback_period} minutes.",
+                logger.info,
+            )
             until = self.calculate_lock_end(trades, self._stop_duration)
 
             return ProtectionReturn(
                 lock=True,
                 until=until,
                 reason=self._reason(profit),
-                lock_side=(side if self._only_per_side else '*')
+                lock_side=(side if self._only_per_side else "*"),
             )
 
         return None
 
     def global_stop(self, date_now: datetime, side: LongShort) -> Optional[ProtectionReturn]:
         """
         Stops trading (position entering) for all pairs
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, all pairs will be locked with <reason> until <until>
         """
         return None
 
     def stop_per_pair(
-            self, pair: str, date_now: datetime, side: LongShort) -> Optional[ProtectionReturn]:
+        self, pair: str, date_now: datetime, side: LongShort
+    ) -> Optional[ProtectionReturn]:
         """
         Stops trading (position entering) for this pair
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, this pair will be locked with <reason> until <until>
         """
         return self._low_profit(date_now, pair=pair, side=side)
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/protections/max_drawdown_protection.py` & `freqtrade-2024.5/freqtrade/plugins/protections/max_drawdown_protection.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 import logging
 from datetime import datetime, timedelta
 from typing import Any, Dict, Optional
 
 import pandas as pd
 
 from freqtrade.constants import Config, LongShort
@@ -11,38 +10,41 @@
 from freqtrade.plugins.protections import IProtection, ProtectionReturn
 
 
 logger = logging.getLogger(__name__)
 
 
 class MaxDrawdown(IProtection):
-
     has_global_stop: bool = True
     has_local_stop: bool = False
 
     def __init__(self, config: Config, protection_config: Dict[str, Any]) -> None:
         super().__init__(config, protection_config)
 
-        self._trade_limit = protection_config.get('trade_limit', 1)
-        self._max_allowed_drawdown = protection_config.get('max_allowed_drawdown', 0.0)
+        self._trade_limit = protection_config.get("trade_limit", 1)
+        self._max_allowed_drawdown = protection_config.get("max_allowed_drawdown", 0.0)
         # TODO: Implement checks to limit max_drawdown to sensible values
 
     def short_desc(self) -> str:
         """
         Short method description - used for startup-messages
         """
-        return (f"{self.name} - Max drawdown protection, stop trading if drawdown is > "
-                f"{self._max_allowed_drawdown} within {self.lookback_period_str}.")
+        return (
+            f"{self.name} - Max drawdown protection, stop trading if drawdown is > "
+            f"{self._max_allowed_drawdown} within {self.lookback_period_str}."
+        )
 
     def _reason(self, drawdown: float) -> str:
         """
         LockReason to use
         """
-        return (f'{drawdown} passed {self._max_allowed_drawdown} in {self.lookback_period_str}, '
-                f'locking for {self.stop_duration_str}.')
+        return (
+            f"{drawdown} passed {self._max_allowed_drawdown} in {self.lookback_period_str}, "
+            f"locking for {self.stop_duration_str}."
+        )
 
     def _max_drawdown(self, date_now: datetime) -> Optional[ProtectionReturn]:
         """
         Evaluate recent trades for drawdown ...
         """
         look_back_until = date_now - timedelta(minutes=self._lookback_period)
 
@@ -53,22 +55,25 @@
         if len(trades) < self._trade_limit:
             # Not enough trades in the relevant period
             return None
 
         # Drawdown is always positive
         try:
             # TODO: This should use absolute profit calculation, considering account balance.
-            drawdown, _, _, _, _, _ = calculate_max_drawdown(trades_df, value_col='close_profit')
+            drawdown_obj = calculate_max_drawdown(trades_df, value_col="close_profit")
+            drawdown = drawdown_obj.drawdown_abs
         except ValueError:
             return None
 
         if drawdown > self._max_allowed_drawdown:
             self.log_once(
                 f"Trading stopped due to Max Drawdown {drawdown:.2f} > {self._max_allowed_drawdown}"
-                f" within {self.lookback_period_str}.", logger.info)
+                f" within {self.lookback_period_str}.",
+                logger.info,
+            )
             until = self.calculate_lock_end(trades, self._stop_duration)
 
             return ProtectionReturn(
                 lock=True,
                 until=until,
                 reason=self._reason(drawdown),
             )
@@ -81,15 +86,16 @@
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, all pairs will be locked with <reason> until <until>
         """
         return self._max_drawdown(date_now)
 
     def stop_per_pair(
-            self, pair: str, date_now: datetime, side: LongShort) -> Optional[ProtectionReturn]:
+        self, pair: str, date_now: datetime, side: LongShort
+    ) -> Optional[ProtectionReturn]:
         """
         Stops trading (position entering) for this pair
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, this pair will be locked with <reason> until <until>
         """
         return None
```

### Comparing `freqtrade-2024.4/freqtrade/plugins/protections/stoploss_guard.py` & `freqtrade-2024.5/freqtrade/plugins/protections/stoploss_guard.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,91 +1,109 @@
-
 import logging
 from datetime import datetime, timedelta
 from typing import Any, Dict, Optional
 
 from freqtrade.constants import Config, LongShort
 from freqtrade.enums import ExitType
 from freqtrade.persistence import Trade
 from freqtrade.plugins.protections import IProtection, ProtectionReturn
 
 
 logger = logging.getLogger(__name__)
 
 
 class StoplossGuard(IProtection):
-
     has_global_stop: bool = True
     has_local_stop: bool = True
 
     def __init__(self, config: Config, protection_config: Dict[str, Any]) -> None:
         super().__init__(config, protection_config)
 
-        self._trade_limit = protection_config.get('trade_limit', 10)
-        self._disable_global_stop = protection_config.get('only_per_pair', False)
-        self._only_per_side = protection_config.get('only_per_side', False)
-        self._profit_limit = protection_config.get('required_profit', 0.0)
+        self._trade_limit = protection_config.get("trade_limit", 10)
+        self._disable_global_stop = protection_config.get("only_per_pair", False)
+        self._only_per_side = protection_config.get("only_per_side", False)
+        self._profit_limit = protection_config.get("required_profit", 0.0)
 
     def short_desc(self) -> str:
         """
         Short method description - used for startup-messages
         """
-        return (f"{self.name} - Frequent Stoploss Guard, {self._trade_limit} stoplosses "
-                f"with profit < {self._profit_limit:.2%} within {self.lookback_period_str}.")
+        return (
+            f"{self.name} - Frequent Stoploss Guard, {self._trade_limit} stoplosses "
+            f"with profit < {self._profit_limit:.2%} within {self.lookback_period_str}."
+        )
 
     def _reason(self) -> str:
         """
         LockReason to use
         """
-        return (f'{self._trade_limit} stoplosses in {self._lookback_period} min, '
-                f'locking for {self._stop_duration} min.')
-
-    def _stoploss_guard(self, date_now: datetime, pair: Optional[str],
-                        side: LongShort) -> Optional[ProtectionReturn]:
+        return (
+            f"{self._trade_limit} stoplosses in {self._lookback_period} min, "
+            f"locking for {self._stop_duration} min."
+        )
+
+    def _stoploss_guard(
+        self, date_now: datetime, pair: Optional[str], side: LongShort
+    ) -> Optional[ProtectionReturn]:
         """
         Evaluate recent trades
         """
         look_back_until = date_now - timedelta(minutes=self._lookback_period)
 
         trades1 = Trade.get_trades_proxy(pair=pair, is_open=False, close_date=look_back_until)
-        trades = [trade for trade in trades1 if (str(trade.exit_reason) in (
-            ExitType.TRAILING_STOP_LOSS.value, ExitType.STOP_LOSS.value,
-            ExitType.STOPLOSS_ON_EXCHANGE.value, ExitType.LIQUIDATION.value)
-            and trade.close_profit and trade.close_profit < self._profit_limit)]
+        trades = [
+            trade
+            for trade in trades1
+            if (
+                str(trade.exit_reason)
+                in (
+                    ExitType.TRAILING_STOP_LOSS.value,
+                    ExitType.STOP_LOSS.value,
+                    ExitType.STOPLOSS_ON_EXCHANGE.value,
+                    ExitType.LIQUIDATION.value,
+                )
+                and trade.close_profit
+                and trade.close_profit < self._profit_limit
+            )
+        ]
 
         if self._only_per_side:
             # Long or short trades only
             trades = [trade for trade in trades if trade.trade_direction == side]
 
         if len(trades) < self._trade_limit:
             return None
 
-        self.log_once(f"Trading stopped due to {self._trade_limit} "
-                      f"stoplosses within {self._lookback_period} minutes.", logger.info)
+        self.log_once(
+            f"Trading stopped due to {self._trade_limit} "
+            f"stoplosses within {self._lookback_period} minutes.",
+            logger.info,
+        )
         until = self.calculate_lock_end(trades, self._stop_duration)
         return ProtectionReturn(
             lock=True,
             until=until,
             reason=self._reason(),
-            lock_side=(side if self._only_per_side else '*')
-            )
+            lock_side=(side if self._only_per_side else "*"),
+        )
 
     def global_stop(self, date_now: datetime, side: LongShort) -> Optional[ProtectionReturn]:
         """
         Stops trading (position entering) for all pairs
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, all pairs will be locked with <reason> until <until>
         """
         if self._disable_global_stop:
             return None
         return self._stoploss_guard(date_now, None, side)
 
     def stop_per_pair(
-            self, pair: str, date_now: datetime, side: LongShort) -> Optional[ProtectionReturn]:
+        self, pair: str, date_now: datetime, side: LongShort
+    ) -> Optional[ProtectionReturn]:
         """
         Stops trading (position entering) for this pair
         This must evaluate to true for the whole period of the "cooldown period".
         :return: Tuple of [bool, until, reason].
             If true, this pair will be locked with <reason> until <until>
         """
         return self._stoploss_guard(date_now, pair, side)
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/__init__.py` & `freqtrade-2024.5/freqtrade/resolvers/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 # flake8: noqa: F401
 # isort: off
 from freqtrade.resolvers.iresolver import IResolver
 from freqtrade.resolvers.exchange_resolver import ExchangeResolver
+
 # isort: on
 # Don't import HyperoptResolver to avoid loading the whole Optimize tree
 # from freqtrade.resolvers.hyperopt_resolver import HyperOptResolver
 from freqtrade.resolvers.pairlist_resolver import PairListResolver
 from freqtrade.resolvers.protection_resolver import ProtectionResolver
 from freqtrade.resolvers.strategy_resolver import StrategyResolver
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/exchange_resolver.py` & `freqtrade-2024.5/freqtrade/resolvers/exchange_resolver.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 This module loads custom exchanges
 """
+
 import logging
 from inspect import isclass
 from typing import Any, Dict, List, Optional
 
 import freqtrade.exchange as exchanges
 from freqtrade.constants import Config, ExchangeConfig
 from freqtrade.exchange import MAP_EXCHANGE_CHILDCLASS, Exchange
@@ -14,43 +15,55 @@
 logger = logging.getLogger(__name__)
 
 
 class ExchangeResolver(IResolver):
     """
     This class contains all the logic to load a custom exchange class
     """
+
     object_type = Exchange
 
     @staticmethod
-    def load_exchange(config: Config, *, exchange_config: Optional[ExchangeConfig] = None,
-                      validate: bool = True, load_leverage_tiers: bool = False) -> Exchange:
+    def load_exchange(
+        config: Config,
+        *,
+        exchange_config: Optional[ExchangeConfig] = None,
+        validate: bool = True,
+        load_leverage_tiers: bool = False,
+    ) -> Exchange:
         """
         Load the custom class from config parameter
         :param exchange_name: name of the Exchange to load
         :param config: configuration dictionary
         """
-        exchange_name: str = config['exchange']['name']
+        exchange_name: str = config["exchange"]["name"]
         # Map exchange name to avoid duplicate classes for identical exchanges
         exchange_name = MAP_EXCHANGE_CHILDCLASS.get(exchange_name, exchange_name)
         exchange_name = exchange_name.title()
         exchange = None
         try:
             exchange = ExchangeResolver._load_exchange(
                 exchange_name,
                 kwargs={
-                    'config': config,
-                    'validate': validate,
-                    'exchange_config': exchange_config,
-                    'load_leverage_tiers': load_leverage_tiers}
+                    "config": config,
+                    "validate": validate,
+                    "exchange_config": exchange_config,
+                    "load_leverage_tiers": load_leverage_tiers,
+                },
             )
         except ImportError:
             logger.info(
-                f"No {exchange_name} specific subclass found. Using the generic class instead.")
+                f"No {exchange_name} specific subclass found. Using the generic class instead."
+            )
         if not exchange:
-            exchange = Exchange(config, validate=validate, exchange_config=exchange_config,)
+            exchange = Exchange(
+                config,
+                validate=validate,
+                exchange_config=exchange_config,
+            )
         return exchange
 
     @staticmethod
     def _load_exchange(exchange_name: str, kwargs: dict) -> Exchange:
         """
         Loads the specified exchange.
         Only checks for exchanges exported in freqtrade.exchanges
@@ -71,28 +84,31 @@
 
         raise ImportError(
             f"Impossible to load Exchange '{exchange_name}'. This class does not exist "
             "or contains Python code errors."
         )
 
     @classmethod
-    def search_all_objects(cls, config: Config, enum_failed: bool,
-                           recursive: bool = False) -> List[Dict[str, Any]]:
+    def search_all_objects(
+        cls, config: Config, enum_failed: bool, recursive: bool = False
+    ) -> List[Dict[str, Any]]:
         """
         Searches for valid objects
         :param config: Config object
         :param enum_failed: If True, will return None for modules which fail.
             Otherwise, failing modules are skipped.
         :param recursive: Recursively walk directory tree searching for strategies
         :return: List of dicts containing 'name', 'class' and 'location' entries
         """
         result = []
         for exchange_name in dir(exchanges):
             exchange = getattr(exchanges, exchange_name)
             if isclass(exchange) and issubclass(exchange, Exchange):
-                result.append({
-                    'name': exchange_name,
-                    'class': exchange,
-                    'location': exchange.__module__,
-                    'location_rel: ': exchange.__module__.replace('freqtrade.', ''),
-                })
+                result.append(
+                    {
+                        "name": exchange_name,
+                        "class": exchange,
+                        "location": exchange.__module__,
+                        "location_rel: ": exchange.__module__.replace("freqtrade.", ""),
+                    }
+                )
         return result
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/freqaimodel_resolver.py` & `freqtrade-2024.5/freqtrade/resolvers/freqaimodel_resolver.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=attribute-defined-outside-init
 
 """
 This module load a custom model for freqai
 """
+
 import logging
 from pathlib import Path
 
 from freqtrade.constants import USERPATH_FREQAIMODELS, Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.freqai.freqai_interface import IFreqaiModel
 from freqtrade.resolvers import IResolver
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/hyperopt_resolver.py` & `freqtrade-2024.5/freqtrade/resolvers/hyperopt_resolver.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=attribute-defined-outside-init
 
 """
 This module load custom hyperopt
 """
+
 import logging
 from pathlib import Path
 
 from freqtrade.constants import HYPEROPT_LOSS_BUILTIN, USERPATH_HYPEROPTS, Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.optimize.hyperopt_loss_interface import IHyperOptLoss
 from freqtrade.resolvers import IResolver
@@ -15,34 +16,35 @@
 logger = logging.getLogger(__name__)
 
 
 class HyperOptLossResolver(IResolver):
     """
     This class contains all the logic to load custom hyperopt loss class
     """
+
     object_type = IHyperOptLoss
     object_type_str = "HyperoptLoss"
     user_subdir = USERPATH_HYPEROPTS
-    initial_search_path = Path(__file__).parent.parent.joinpath('optimize/hyperopt_loss').resolve()
+    initial_search_path = Path(__file__).parent.parent.joinpath("optimize/hyperopt_loss").resolve()
 
     @staticmethod
     def load_hyperoptloss(config: Config) -> IHyperOptLoss:
         """
         Load the custom class from config parameter
         :param config: configuration dictionary
         """
 
-        hyperoptloss_name = config.get('hyperopt_loss')
+        hyperoptloss_name = config.get("hyperopt_loss")
         if not hyperoptloss_name:
             raise OperationalException(
                 "No Hyperopt loss set. Please use `--hyperopt-loss` to "
                 "specify the Hyperopt-Loss class to use.\n"
                 f"Built-in Hyperopt-loss-functions are: {', '.join(HYPEROPT_LOSS_BUILTIN)}"
             )
-        hyperoptloss = HyperOptLossResolver.load_object(hyperoptloss_name,
-                                                        config, kwargs={},
-                                                        extra_dir=config.get('hyperopt_path'))
+        hyperoptloss = HyperOptLossResolver.load_object(
+            hyperoptloss_name, config, kwargs={}, extra_dir=config.get("hyperopt_path")
+        )
 
         # Assign timeframe to be used in hyperopt
-        hyperoptloss.__class__.timeframe = str(config['timeframe'])
+        hyperoptloss.__class__.timeframe = str(config["timeframe"])
 
         return hyperoptloss
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/iresolver.py` & `freqtrade-2024.5/freqtrade/resolvers/iresolver.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=attribute-defined-outside-init
 
 """
 This module load custom objects
 """
+
 import importlib.util
 import inspect
 import logging
 import sys
 from pathlib import Path
 from typing import Any, Dict, Iterator, List, Optional, Tuple, Type, Union
 
@@ -33,46 +34,51 @@
             sys.path.remove(str_path)
 
 
 class IResolver:
     """
     This class contains all the logic to load custom classes
     """
+
     # Childclasses need to override this
     object_type: Type[Any]
     object_type_str: str
     user_subdir: Optional[str] = None
     initial_search_path: Optional[Path] = None
     # Optional config setting containing a path (strategy_path, freqaimodel_path)
     extra_path: Optional[str] = None
 
     @classmethod
-    def build_search_paths(cls, config: Config, user_subdir: Optional[str] = None,
-                           extra_dirs: Optional[List[str]] = None) -> List[Path]:
-
+    def build_search_paths(
+        cls,
+        config: Config,
+        user_subdir: Optional[str] = None,
+        extra_dirs: Optional[List[str]] = None,
+    ) -> List[Path]:
         abs_paths: List[Path] = []
         if cls.initial_search_path:
             abs_paths.append(cls.initial_search_path)
 
         if user_subdir:
-            abs_paths.insert(0, config['user_data_dir'].joinpath(user_subdir))
+            abs_paths.insert(0, config["user_data_dir"].joinpath(user_subdir))
 
         # Add extra directory to the top of the search paths
         if extra_dirs:
             for dir in extra_dirs:
                 abs_paths.insert(0, Path(dir).resolve())
 
         if cls.extra_path and (extra := config.get(cls.extra_path)):
             abs_paths.insert(0, Path(extra).resolve())
 
         return abs_paths
 
     @classmethod
-    def _get_valid_object(cls, module_path: Path, object_name: Optional[str],
-                          enum_failed: bool = False) -> Iterator[Any]:
+    def _get_valid_object(
+        cls, module_path: Path, object_name: Optional[str], enum_failed: bool = False
+    ) -> Iterator[Any]:
         """
         Generator returning objects with matching object_type and object_name in the path given.
         :param module_path: absolute path to the module
         :param object_name: Class name of the object
         :param enum_failed: If True, will return None for modules which fail.
             Otherwise, failing modules are skipped.
         :return: generator containing tuple of matching objects
@@ -86,116 +92,126 @@
             spec = importlib.util.spec_from_file_location(module_name, str(module_path))
             if not spec:
                 return iter([None])
 
             module = importlib.util.module_from_spec(spec)
             try:
                 spec.loader.exec_module(module)  # type: ignore # importlib does not use typehints
-            except (AttributeError, ModuleNotFoundError, SyntaxError,
-                    ImportError, NameError) as err:
+            except (
+                AttributeError,
+                ModuleNotFoundError,
+                SyntaxError,
+                ImportError,
+                NameError,
+            ) as err:
                 # Catch errors in case a specific module is not installed
                 logger.warning(f"Could not import {module_path} due to '{err}'")
                 if enum_failed:
                     return iter([None])
 
             valid_objects_gen = (
-                (obj, inspect.getsource(module)) for
-                name, obj in inspect.getmembers(
-                    module, inspect.isclass) if ((object_name is None or object_name == name)
-                                                 and issubclass(obj, cls.object_type)
-                                                 and obj is not cls.object_type
-                                                 and obj.__module__ == module_name
-                                                 )
+                (obj, inspect.getsource(module))
+                for name, obj in inspect.getmembers(module, inspect.isclass)
+                if (
+                    (object_name is None or object_name == name)
+                    and issubclass(obj, cls.object_type)
+                    and obj is not cls.object_type
+                    and obj.__module__ == module_name
+                )
             )
             # The __module__ check ensures we only use strategies that are defined in this folder.
             return valid_objects_gen
 
     @classmethod
-    def _search_object(cls, directory: Path, *, object_name: str, add_source: bool = False
-                       ) -> Union[Tuple[Any, Path], Tuple[None, None]]:
+    def _search_object(
+        cls, directory: Path, *, object_name: str, add_source: bool = False
+    ) -> Union[Tuple[Any, Path], Tuple[None, None]]:
         """
         Search for the objectname in the given directory
         :param directory: relative or absolute directory path
         :param object_name: ClassName of the object to load
         :return: object class
         """
         logger.debug(f"Searching for {cls.object_type.__name__} {object_name} in '{directory}'")
         for entry in directory.iterdir():
             # Only consider python files
-            if entry.suffix != '.py':
-                logger.debug('Ignoring %s', entry)
+            if entry.suffix != ".py":
+                logger.debug("Ignoring %s", entry)
                 continue
             if entry.is_symlink() and not entry.is_file():
-                logger.debug('Ignoring broken symlink %s', entry)
+                logger.debug("Ignoring broken symlink %s", entry)
                 continue
             module_path = entry.resolve()
 
             obj = next(cls._get_valid_object(module_path, object_name), None)
 
             if obj:
                 obj[0].__file__ = str(entry)
                 if add_source:
                     obj[0].__source__ = obj[1]
                 return (obj[0], module_path)
         return (None, None)
 
     @classmethod
-    def _load_object(cls, paths: List[Path], *, object_name: str, add_source: bool = False,
-                     kwargs: Dict) -> Optional[Any]:
+    def _load_object(
+        cls, paths: List[Path], *, object_name: str, add_source: bool = False, kwargs: Dict
+    ) -> Optional[Any]:
         """
         Try to load object from path list.
         """
 
         for _path in paths:
             try:
-                (module, module_path) = cls._search_object(directory=_path,
-                                                           object_name=object_name,
-                                                           add_source=add_source)
+                (module, module_path) = cls._search_object(
+                    directory=_path, object_name=object_name, add_source=add_source
+                )
                 if module:
                     logger.info(
                         f"Using resolved {cls.object_type.__name__.lower()[1:]} {object_name} "
-                        f"from '{module_path}'...")
+                        f"from '{module_path}'..."
+                    )
                     return module(**kwargs)
             except FileNotFoundError:
                 logger.warning('Path "%s" does not exist.', _path.resolve())
 
         return None
 
     @classmethod
-    def load_object(cls, object_name: str, config: Config, *, kwargs: dict,
-                    extra_dir: Optional[str] = None) -> Any:
+    def load_object(
+        cls, object_name: str, config: Config, *, kwargs: dict, extra_dir: Optional[str] = None
+    ) -> Any:
         """
         Search and loads the specified object as configured in the child class.
         :param object_name: name of the module to import
         :param config: configuration dictionary
         :param extra_dir: additional directory to search for the given pairlist
         :raises: OperationalException if the class is invalid or does not exist.
         :return: Object instance or None
         """
 
         extra_dirs: List[str] = []
         if extra_dir:
             extra_dirs.append(extra_dir)
 
-        abs_paths = cls.build_search_paths(config,
-                                           user_subdir=cls.user_subdir,
-                                           extra_dirs=extra_dirs)
+        abs_paths = cls.build_search_paths(
+            config, user_subdir=cls.user_subdir, extra_dirs=extra_dirs
+        )
 
-        found_object = cls._load_object(paths=abs_paths, object_name=object_name,
-                                        kwargs=kwargs)
+        found_object = cls._load_object(paths=abs_paths, object_name=object_name, kwargs=kwargs)
         if found_object:
             return found_object
         raise OperationalException(
             f"Impossible to load {cls.object_type_str} '{object_name}'. This class does not exist "
             "or contains Python code errors."
         )
 
     @classmethod
-    def search_all_objects(cls, config: Config, enum_failed: bool,
-                           recursive: bool = False) -> List[Dict[str, Any]]:
+    def search_all_objects(
+        cls, config: Config, enum_failed: bool, recursive: bool = False
+    ) -> List[Dict[str, Any]]:
         """
         Searches for valid objects
         :param config: Config object
         :param enum_failed: If True, will return None for modules which fail.
             Otherwise, failing modules are skipped.
         :param recursive: Recursively walk directory tree searching for strategies
         :return: List of dicts containing 'name', 'class' and 'location' entries
@@ -205,23 +221,29 @@
         abs_paths = cls.build_search_paths(config, user_subdir=cls.user_subdir)
         for path in abs_paths:
             result.extend(cls._search_all_objects(path, enum_failed, recursive))
         return result
 
     @classmethod
     def _build_rel_location(cls, directory: Path, entry: Path) -> str:
-
         builtin = cls.initial_search_path == directory
-        return f"<builtin>/{entry.relative_to(directory)}" if builtin else str(
-            entry.relative_to(directory))
+        return (
+            f"<builtin>/{entry.relative_to(directory)}"
+            if builtin
+            else str(entry.relative_to(directory))
+        )
 
     @classmethod
     def _search_all_objects(
-            cls, directory: Path, enum_failed: bool, recursive: bool = False,
-            basedir: Optional[Path] = None) -> List[Dict[str, Any]]:
+        cls,
+        directory: Path,
+        enum_failed: bool,
+        recursive: bool = False,
+        basedir: Optional[Path] = None,
+    ) -> List[Dict[str, Any]]:
         """
         Searches a directory for valid objects
         :param directory: Path to search
         :param enum_failed: If True, will return None for modules which fail.
             Otherwise, failing modules are skipped.
         :param recursive: Recursively walk directory tree searching for strategies
         :return: List of dicts containing 'name', 'class' and 'location' entries
@@ -229,28 +251,33 @@
         logger.debug(f"Searching for {cls.object_type.__name__} '{directory}'")
         objects: List[Dict[str, Any]] = []
         if not directory.is_dir():
             logger.info(f"'{directory}' is not a directory, skipping.")
             return objects
         for entry in directory.iterdir():
             if (
-                recursive and entry.is_dir()
-                and not entry.name.startswith('__')
-                and not entry.name.startswith('.')
+                recursive
+                and entry.is_dir()
+                and not entry.name.startswith("__")
+                and not entry.name.startswith(".")
             ):
-                objects.extend(cls._search_all_objects(
-                    entry, enum_failed, recursive, basedir or directory))
+                objects.extend(
+                    cls._search_all_objects(entry, enum_failed, recursive, basedir or directory)
+                )
             # Only consider python files
-            if entry.suffix != '.py':
-                logger.debug('Ignoring %s', entry)
+            if entry.suffix != ".py":
+                logger.debug("Ignoring %s", entry)
                 continue
             module_path = entry.resolve()
             logger.debug(f"Path {module_path}")
-            for obj in cls._get_valid_object(module_path, object_name=None,
-                                             enum_failed=enum_failed):
+            for obj in cls._get_valid_object(
+                module_path, object_name=None, enum_failed=enum_failed
+            ):
                 objects.append(
-                    {'name': obj[0].__name__ if obj is not None else '',
-                     'class': obj[0] if obj is not None else None,
-                     'location': entry,
-                     'location_rel': cls._build_rel_location(basedir or directory, entry),
-                     })
+                    {
+                        "name": obj[0].__name__ if obj is not None else "",
+                        "class": obj[0] if obj is not None else None,
+                        "location": entry,
+                        "location_rel": cls._build_rel_location(basedir or directory, entry),
+                    }
+                )
         return objects
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/pairlist_resolver.py` & `freqtrade-2024.5/freqtrade/resolvers/pairlist_resolver.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=attribute-defined-outside-init
 
 """
 This module load custom pairlists
 """
+
 import logging
 from pathlib import Path
 
 from freqtrade.constants import Config
 from freqtrade.plugins.pairlist.IPairList import IPairList
 from freqtrade.resolvers import IResolver
 
@@ -14,32 +15,43 @@
 logger = logging.getLogger(__name__)
 
 
 class PairListResolver(IResolver):
     """
     This class contains all the logic to load custom PairList class
     """
+
     object_type = IPairList
     object_type_str = "Pairlist"
     user_subdir = None
-    initial_search_path = Path(__file__).parent.parent.joinpath('plugins/pairlist').resolve()
+    initial_search_path = Path(__file__).parent.parent.joinpath("plugins/pairlist").resolve()
 
     @staticmethod
-    def load_pairlist(pairlist_name: str, exchange, pairlistmanager,
-                      config: Config, pairlistconfig: dict, pairlist_pos: int) -> IPairList:
+    def load_pairlist(
+        pairlist_name: str,
+        exchange,
+        pairlistmanager,
+        config: Config,
+        pairlistconfig: dict,
+        pairlist_pos: int,
+    ) -> IPairList:
         """
         Load the pairlist with pairlist_name
         :param pairlist_name: Classname of the pairlist
         :param exchange: Initialized exchange class
         :param pairlistmanager: Initialized pairlist manager
         :param config: configuration dictionary
         :param pairlistconfig: Configuration dedicated to this pairlist
         :param pairlist_pos: Position of the pairlist in the list of pairlists
         :return: initialized Pairlist class
         """
-        return PairListResolver.load_object(pairlist_name, config,
-                                            kwargs={'exchange': exchange,
-                                                    'pairlistmanager': pairlistmanager,
-                                                    'config': config,
-                                                    'pairlistconfig': pairlistconfig,
-                                                    'pairlist_pos': pairlist_pos},
-                                            )
+        return PairListResolver.load_object(
+            pairlist_name,
+            config,
+            kwargs={
+                "exchange": exchange,
+                "pairlistmanager": pairlistmanager,
+                "config": config,
+                "pairlistconfig": pairlistconfig,
+                "pairlist_pos": pairlist_pos,
+            },
+        )
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/protection_resolver.py` & `freqtrade-2024.5/freqtrade/resolvers/protection_resolver.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 This module load custom pairlists
 """
+
 import logging
 from pathlib import Path
 from typing import Dict
 
 from freqtrade.constants import Config
 from freqtrade.plugins.protections import IProtection
 from freqtrade.resolvers import IResolver
@@ -13,27 +14,32 @@
 logger = logging.getLogger(__name__)
 
 
 class ProtectionResolver(IResolver):
     """
     This class contains all the logic to load custom PairList class
     """
+
     object_type = IProtection
     object_type_str = "Protection"
     user_subdir = None
-    initial_search_path = Path(__file__).parent.parent.joinpath('plugins/protections').resolve()
+    initial_search_path = Path(__file__).parent.parent.joinpath("plugins/protections").resolve()
 
     @staticmethod
-    def load_protection(protection_name: str, config: Config,
-                        protection_config: Dict) -> IProtection:
+    def load_protection(
+        protection_name: str, config: Config, protection_config: Dict
+    ) -> IProtection:
         """
         Load the protection with protection_name
         :param protection_name: Classname of the pairlist
         :param config: configuration dictionary
         :param protection_config: Configuration dedicated to this pairlist
         :return: initialized Protection class
         """
-        return ProtectionResolver.load_object(protection_name, config,
-                                              kwargs={'config': config,
-                                                      'protection_config': protection_config,
-                                                      },
-                                              )
+        return ProtectionResolver.load_object(
+            protection_name,
+            config,
+            kwargs={
+                "config": config,
+                "protection_config": protection_config,
+            },
+        )
```

### Comparing `freqtrade-2024.4/freqtrade/resolvers/strategy_resolver.py` & `freqtrade-2024.5/freqtrade/resolvers/strategy_resolver.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=attribute-defined-outside-init
 
 """
 This module load custom strategies
 """
+
 import logging
 import tempfile
 from base64 import urlsafe_b64decode
 from inspect import getfullargspec
 from os import walk
 from pathlib import Path
 from typing import Any, List, Optional
@@ -22,69 +23,71 @@
 logger = logging.getLogger(__name__)
 
 
 class StrategyResolver(IResolver):
     """
     This class contains the logic to load custom strategy class
     """
+
     object_type = IStrategy
     object_type_str = "Strategy"
     user_subdir = USERPATH_STRATEGIES
     initial_search_path = None
     extra_path = "strategy_path"
 
     @staticmethod
     def load_strategy(config: Optional[Config] = None) -> IStrategy:
         """
         Load the custom class from config parameter
         :param config: configuration dictionary or None
         """
         config = config or {}
 
-        if not config.get('strategy'):
-            raise OperationalException("No strategy set. Please use `--strategy` to specify "
-                                       "the strategy class to use.")
+        if not config.get("strategy"):
+            raise OperationalException(
+                "No strategy set. Please use `--strategy` to specify the strategy class to use."
+            )
 
-        strategy_name = config['strategy']
+        strategy_name = config["strategy"]
         strategy: IStrategy = StrategyResolver._load_strategy(
-            strategy_name, config=config,
-            extra_dir=config.get('strategy_path'))
+            strategy_name, config=config, extra_dir=config.get("strategy_path")
+        )
         strategy.ft_load_params_from_file()
         # Set attributes
         # Check if we need to override configuration
         #             (Attribute name,                    default,     subkey)
-        attributes = [("minimal_roi",                     {"0": 10.0}),
-                      ("timeframe",                       None),
-                      ("stoploss",                        None),
-                      ("trailing_stop",                   None),
-                      ("trailing_stop_positive",          None),
-                      ("trailing_stop_positive_offset",   0.0),
-                      ("trailing_only_offset_is_reached", None),
-                      ("use_custom_stoploss",             None),
-                      ("process_only_new_candles",        None),
-                      ("order_types",                     None),
-                      ("order_time_in_force",             None),
-                      ("stake_currency",                  None),
-                      ("stake_amount",                    None),
-                      ("protections",                     None),
-                      ("startup_candle_count",            None),
-                      ("unfilledtimeout",                 None),
-                      ("use_exit_signal",                 True),
-                      ("exit_profit_only",                False),
-                      ("ignore_roi_if_entry_signal",      False),
-                      ("exit_profit_offset",              0.0),
-                      ("disable_dataframe_checks",        False),
-                      ("ignore_buying_expired_candle_after",  0),
-                      ("position_adjustment_enable",      False),
-                      ("max_entry_position_adjustment",      -1),
-                      ("max_open_trades",                    -1)
-                      ]
+        attributes = [
+            ("minimal_roi", {"0": 10.0}),
+            ("timeframe", None),
+            ("stoploss", None),
+            ("trailing_stop", None),
+            ("trailing_stop_positive", None),
+            ("trailing_stop_positive_offset", 0.0),
+            ("trailing_only_offset_is_reached", None),
+            ("use_custom_stoploss", None),
+            ("process_only_new_candles", None),
+            ("order_types", None),
+            ("order_time_in_force", None),
+            ("stake_currency", None),
+            ("stake_amount", None),
+            ("protections", None),
+            ("startup_candle_count", None),
+            ("unfilledtimeout", None),
+            ("use_exit_signal", True),
+            ("exit_profit_only", False),
+            ("ignore_roi_if_entry_signal", False),
+            ("exit_profit_offset", 0.0),
+            ("disable_dataframe_checks", False),
+            ("ignore_buying_expired_candle_after", 0),
+            ("position_adjustment_enable", False),
+            ("max_entry_position_adjustment", -1),
+            ("max_open_trades", -1),
+        ]
         for attribute, default in attributes:
-            StrategyResolver._override_attribute_helper(strategy, config,
-                                                        attribute, default)
+            StrategyResolver._override_attribute_helper(strategy, config, attribute, default)
 
         # Loop this list again to have output combined
         for attribute, _ in attributes:
             if attribute in config:
                 logger.info("Strategy using %s: %s", attribute, config[attribute])
 
         StrategyResolver._normalize_attributes(strategy)
@@ -97,203 +100,219 @@
         """
         Override attributes in the strategy.
         Prevalence:
         - Configuration
         - Strategy
         - default (if not None)
         """
-        if (attribute in config
-                and not isinstance(getattr(type(strategy), attribute, None), property)):
+        if attribute in config and not isinstance(
+            getattr(type(strategy), attribute, None), property
+        ):
             # Ensure Properties are not overwritten
             setattr(strategy, attribute, config[attribute])
-            logger.info("Override strategy '%s' with value in config file: %s.",
-                        attribute, config[attribute])
+            logger.info(
+                "Override strategy '%s' with value in config file: %s.",
+                attribute,
+                config[attribute],
+            )
         elif hasattr(strategy, attribute):
             val = getattr(strategy, attribute)
             # None's cannot exist in the config, so do not copy them
             if val is not None:
                 # max_open_trades set to -1 in the strategy will be copied as infinity in the config
-                if attribute == 'max_open_trades' and val == -1:
-                    config[attribute] = float('inf')
+                if attribute == "max_open_trades" and val == -1:
+                    config[attribute] = float("inf")
                 else:
                     config[attribute] = val
         # Explicitly check for None here as other "falsy" values are possible
         elif default is not None:
             setattr(strategy, attribute, default)
             config[attribute] = default
 
     @staticmethod
     def _normalize_attributes(strategy: IStrategy) -> IStrategy:
         """
         Normalize attributes to have the correct type.
         """
         # Sort and apply type conversions
-        if hasattr(strategy, 'minimal_roi'):
-            strategy.minimal_roi = dict(sorted(
-                {int(key): value for (key, value) in strategy.minimal_roi.items()}.items(),
-                key=lambda t: t[0]))
-        if hasattr(strategy, 'stoploss'):
+        if hasattr(strategy, "minimal_roi"):
+            strategy.minimal_roi = dict(
+                sorted(
+                    {int(key): value for (key, value) in strategy.minimal_roi.items()}.items(),
+                    key=lambda t: t[0],
+                )
+            )
+        if hasattr(strategy, "stoploss"):
             strategy.stoploss = float(strategy.stoploss)
-        if hasattr(strategy, 'max_open_trades') and strategy.max_open_trades < 0:
-            strategy.max_open_trades = float('inf')
+        if hasattr(strategy, "max_open_trades") and strategy.max_open_trades < 0:
+            strategy.max_open_trades = float("inf")
         return strategy
 
     @staticmethod
     def _strategy_sanity_validations(strategy: IStrategy):
         # Ensure necessary migrations are performed first.
         validate_migrated_strategy_settings(strategy.config)
 
         if not all(k in strategy.order_types for k in REQUIRED_ORDERTYPES):
-            raise ImportError(f"Impossible to load Strategy '{strategy.__class__.__name__}'. "
-                              f"Order-types mapping is incomplete.")
+            raise ImportError(
+                f"Impossible to load Strategy '{strategy.__class__.__name__}'. "
+                f"Order-types mapping is incomplete."
+            )
         if not all(k in strategy.order_time_in_force for k in REQUIRED_ORDERTIF):
-            raise ImportError(f"Impossible to load Strategy '{strategy.__class__.__name__}'. "
-                              f"Order-time-in-force mapping is incomplete.")
-        trading_mode = strategy.config.get('trading_mode', TradingMode.SPOT)
+            raise ImportError(
+                f"Impossible to load Strategy '{strategy.__class__.__name__}'. "
+                f"Order-time-in-force mapping is incomplete."
+            )
+        trading_mode = strategy.config.get("trading_mode", TradingMode.SPOT)
 
-        if (strategy.can_short and trading_mode == TradingMode.SPOT):
+        if strategy.can_short and trading_mode == TradingMode.SPOT:
             raise ImportError(
                 "Short strategies cannot run in spot markets. Please make sure that this "
                 "is the correct strategy and that your trading mode configuration is correct. "
                 "You can run this strategy in spot markets by setting `can_short=False`"
                 " in your strategy. Please note that short signals will be ignored in that case."
-                )
+            )
 
     @staticmethod
     def validate_strategy(strategy: IStrategy) -> IStrategy:
-        if strategy.config.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT:
+        if strategy.config.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT:
             # Require new method
-            warn_deprecated_setting(strategy, 'sell_profit_only', 'exit_profit_only', True)
-            warn_deprecated_setting(strategy, 'sell_profit_offset', 'exit_profit_offset', True)
-            warn_deprecated_setting(strategy, 'use_sell_signal', 'use_exit_signal', True)
-            warn_deprecated_setting(strategy, 'ignore_roi_if_buy_signal',
-                                    'ignore_roi_if_entry_signal', True)
+            warn_deprecated_setting(strategy, "sell_profit_only", "exit_profit_only", True)
+            warn_deprecated_setting(strategy, "sell_profit_offset", "exit_profit_offset", True)
+            warn_deprecated_setting(strategy, "use_sell_signal", "use_exit_signal", True)
+            warn_deprecated_setting(
+                strategy, "ignore_roi_if_buy_signal", "ignore_roi_if_entry_signal", True
+            )
 
-            if not check_override(strategy, IStrategy, 'populate_entry_trend'):
+            if not check_override(strategy, IStrategy, "populate_entry_trend"):
                 raise OperationalException("`populate_entry_trend` must be implemented.")
-            if not check_override(strategy, IStrategy, 'populate_exit_trend'):
+            if not check_override(strategy, IStrategy, "populate_exit_trend"):
                 raise OperationalException("`populate_exit_trend` must be implemented.")
-            if check_override(strategy, IStrategy, 'check_buy_timeout'):
-                raise OperationalException("Please migrate your implementation "
-                                           "of `check_buy_timeout` to `check_entry_timeout`.")
-            if check_override(strategy, IStrategy, 'check_sell_timeout'):
-                raise OperationalException("Please migrate your implementation "
-                                           "of `check_sell_timeout` to `check_exit_timeout`.")
+            if check_override(strategy, IStrategy, "check_buy_timeout"):
+                raise OperationalException(
+                    "Please migrate your implementation "
+                    "of `check_buy_timeout` to `check_entry_timeout`."
+                )
+            if check_override(strategy, IStrategy, "check_sell_timeout"):
+                raise OperationalException(
+                    "Please migrate your implementation "
+                    "of `check_sell_timeout` to `check_exit_timeout`."
+                )
 
-            if check_override(strategy, IStrategy, 'custom_sell'):
+            if check_override(strategy, IStrategy, "custom_sell"):
                 raise OperationalException(
-                    "Please migrate your implementation of `custom_sell` to `custom_exit`.")
+                    "Please migrate your implementation of `custom_sell` to `custom_exit`."
+                )
 
         else:
             # TODO: Implementing one of the following methods should show a deprecation warning
             #  buy_trend and sell_trend, custom_sell
-            warn_deprecated_setting(strategy, 'sell_profit_only', 'exit_profit_only')
-            warn_deprecated_setting(strategy, 'sell_profit_offset', 'exit_profit_offset')
-            warn_deprecated_setting(strategy, 'use_sell_signal', 'use_exit_signal')
-            warn_deprecated_setting(strategy, 'ignore_roi_if_buy_signal',
-                                    'ignore_roi_if_entry_signal')
-
-            if (
-                not check_override(strategy, IStrategy, 'populate_buy_trend')
-                and not check_override(strategy, IStrategy, 'populate_entry_trend')
+            warn_deprecated_setting(strategy, "sell_profit_only", "exit_profit_only")
+            warn_deprecated_setting(strategy, "sell_profit_offset", "exit_profit_offset")
+            warn_deprecated_setting(strategy, "use_sell_signal", "use_exit_signal")
+            warn_deprecated_setting(
+                strategy, "ignore_roi_if_buy_signal", "ignore_roi_if_entry_signal"
+            )
+
+            if not check_override(strategy, IStrategy, "populate_buy_trend") and not check_override(
+                strategy, IStrategy, "populate_entry_trend"
             ):
                 raise OperationalException(
-                    "`populate_entry_trend` or `populate_buy_trend` must be implemented.")
-            if (
-                not check_override(strategy, IStrategy, 'populate_sell_trend')
-                and not check_override(strategy, IStrategy, 'populate_exit_trend')
-            ):
+                    "`populate_entry_trend` or `populate_buy_trend` must be implemented."
+                )
+            if not check_override(
+                strategy, IStrategy, "populate_sell_trend"
+            ) and not check_override(strategy, IStrategy, "populate_exit_trend"):
                 raise OperationalException(
-                    "`populate_exit_trend` or `populate_sell_trend` must be implemented.")
+                    "`populate_exit_trend` or `populate_sell_trend` must be implemented."
+                )
 
             _populate_fun_len = len(getfullargspec(strategy.populate_indicators).args)
             _buy_fun_len = len(getfullargspec(strategy.populate_buy_trend).args)
             _sell_fun_len = len(getfullargspec(strategy.populate_sell_trend).args)
-            if any(x == 2 for x in [
-                _populate_fun_len,
-                _buy_fun_len,
-                _sell_fun_len
-            ]):
+            if any(x == 2 for x in [_populate_fun_len, _buy_fun_len, _sell_fun_len]):
                 raise OperationalException(
                     "Strategy Interface v1 is no longer supported. "
                     "Please update your strategy to implement "
                     "`populate_indicators`, `populate_entry_trend` and `populate_exit_trend` "
-                    "with the metadata argument. ")
+                    "with the metadata argument. "
+                )
 
-        has_after_fill = ('after_fill' in getfullargspec(strategy.custom_stoploss).args
-                          and check_override(strategy, IStrategy, 'custom_stoploss'))
+        has_after_fill = "after_fill" in getfullargspec(
+            strategy.custom_stoploss
+        ).args and check_override(strategy, IStrategy, "custom_stoploss")
         if has_after_fill:
             strategy._ft_stop_uses_after_fill = True
 
         return strategy
 
     @staticmethod
-    def _load_strategy(strategy_name: str,
-                       config: Config, extra_dir: Optional[str] = None) -> IStrategy:
+    def _load_strategy(
+        strategy_name: str, config: Config, extra_dir: Optional[str] = None
+    ) -> IStrategy:
         """
         Search and loads the specified strategy.
         :param strategy_name: name of the module to import
         :param config: configuration for the strategy
         :param extra_dir: additional directory to search for the given strategy
         :return: Strategy instance or None
         """
-        if config.get('recursive_strategy_search', False):
+        if config.get("recursive_strategy_search", False):
             extra_dirs: List[str] = [
                 path[0] for path in walk(f"{config['user_data_dir']}/{USERPATH_STRATEGIES}")
             ]  # sub-directories
         else:
             extra_dirs = []
 
         if extra_dir:
             extra_dirs.append(extra_dir)
 
-        abs_paths = StrategyResolver.build_search_paths(config,
-                                                        user_subdir=USERPATH_STRATEGIES,
-                                                        extra_dirs=extra_dirs)
+        abs_paths = StrategyResolver.build_search_paths(
+            config, user_subdir=USERPATH_STRATEGIES, extra_dirs=extra_dirs
+        )
 
         if ":" in strategy_name:
             logger.info("loading base64 encoded strategy")
             strat = strategy_name.split(":")
 
             if len(strat) == 2:
                 temp = Path(tempfile.mkdtemp("freq", "strategy"))
                 name = strat[0] + ".py"
 
-                temp.joinpath(name).write_text(urlsafe_b64decode(strat[1]).decode('utf-8'))
+                temp.joinpath(name).write_text(urlsafe_b64decode(strat[1]).decode("utf-8"))
                 temp.joinpath("__init__.py").touch()
 
                 strategy_name = strat[0]
 
                 # register temp path with the bot
                 abs_paths.insert(0, temp.resolve())
 
         strategy = StrategyResolver._load_object(
             paths=abs_paths,
             object_name=strategy_name,
             add_source=True,
-            kwargs={'config': config},
+            kwargs={"config": config},
         )
 
         if strategy:
-
             return StrategyResolver.validate_strategy(strategy)
 
         raise OperationalException(
             f"Impossible to load Strategy '{strategy_name}'. This class does not exist "
             "or contains Python code errors."
         )
 
 
 def warn_deprecated_setting(strategy: IStrategy, old: str, new: str, error=False):
     if hasattr(strategy, old):
         errormsg = f"DEPRECATED: Using '{old}' moved to '{new}'."
         if error:
             raise OperationalException(errormsg)
         logger.warning(errormsg)
-        setattr(strategy, new, getattr(strategy, f'{old}'))
+        setattr(strategy, new, getattr(strategy, f"{old}"))
 
 
 def check_override(object, parentclass, attribute):
     """
     Checks if a object overrides the parent class attribute.
     :returns: True if the object is overridden.
     """
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/api_auth.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/api_auth.py`

 * *Files 13% similar despite different names*

```diff
@@ -17,16 +17,17 @@
 ALGORITHM = "HS256"
 
 router_login = APIRouter()
 
 
 def verify_auth(api_config, username: str, password: str):
     """Verify username/password"""
-    return (secrets.compare_digest(username, api_config.get('username')) and
-            secrets.compare_digest(password, api_config.get('password')))
+    return secrets.compare_digest(username, api_config.get("username")) and secrets.compare_digest(
+        password, api_config.get("password")
+    )
 
 
 httpbasic = HTTPBasic(auto_error=False)
 security = HTTPBasic()
 oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token", auto_error=False)
 
 
@@ -34,15 +35,15 @@
     credentials_exception = HTTPException(
         status_code=status.HTTP_401_UNAUTHORIZED,
         detail="Could not validate credentials",
         headers={"WWW-Authenticate": "Bearer"},
     )
     try:
         payload = jwt.decode(token, secret_key, algorithms=[ALGORITHM])
-        username: str = payload.get("identity", {}).get('u')
+        username: str = payload.get("identity", {}).get("u")
         if username is None:
             raise credentials_exception
         if payload.get("type") != token_type:
             raise credentials_exception
 
     except jwt.PyJWTError:
         raise credentials_exception
@@ -51,29 +52,28 @@
 
 # This should be reimplemented to better realign with the existing tools provided
 # by FastAPI regarding API Tokens
 # https://github.com/tiangolo/fastapi/blob/master/fastapi/security/api_key.py
 async def validate_ws_token(
     ws: WebSocket,
     ws_token: Union[str, None] = Query(default=None, alias="token"),
-    api_config: Dict[str, Any] = Depends(get_api_config)
+    api_config: Dict[str, Any] = Depends(get_api_config),
 ):
-    secret_ws_token = api_config.get('ws_token', None)
-    secret_jwt_key = api_config.get('jwt_secret_key', 'super-secret')
+    secret_ws_token = api_config.get("ws_token", None)
+    secret_jwt_key = api_config.get("jwt_secret_key", "super-secret")
 
     # Check if ws_token is/in secret_ws_token
     if ws_token and secret_ws_token:
         is_valid_ws_token = False
         if isinstance(secret_ws_token, str):
             is_valid_ws_token = secrets.compare_digest(secret_ws_token, ws_token)
         elif isinstance(secret_ws_token, list):
-            is_valid_ws_token = any([
-                secrets.compare_digest(potential, ws_token)
-                for potential in secret_ws_token
-            ])
+            is_valid_ws_token = any(
+                [secrets.compare_digest(potential, ws_token) for potential in secret_ws_token]
+            )
 
         if is_valid_ws_token:
             return ws_token
 
     # Check if ws_token is a JWT
     try:
         user = get_user_from_token(ws_token, secret_jwt_key)
@@ -90,59 +90,64 @@
     to_encode = data.copy()
     if token_type == "access":
         expire = datetime.now(timezone.utc) + timedelta(minutes=15)
     elif token_type == "refresh":
         expire = datetime.now(timezone.utc) + timedelta(days=30)
     else:
         raise ValueError()
-    to_encode.update({
-        "exp": expire,
-        "iat": datetime.now(timezone.utc),
-        "type": token_type,
-    })
+    to_encode.update(
+        {
+            "exp": expire,
+            "iat": datetime.now(timezone.utc),
+            "type": token_type,
+        }
+    )
     encoded_jwt = jwt.encode(to_encode, secret_key, algorithm=ALGORITHM)
     return encoded_jwt
 
 
-def http_basic_or_jwt_token(form_data: HTTPBasicCredentials = Depends(httpbasic),
-                            token: str = Depends(oauth2_scheme),
-                            api_config=Depends(get_api_config)):
+def http_basic_or_jwt_token(
+    form_data: HTTPBasicCredentials = Depends(httpbasic),
+    token: str = Depends(oauth2_scheme),
+    api_config=Depends(get_api_config),
+):
     if token:
-        return get_user_from_token(token, api_config.get('jwt_secret_key', 'super-secret'))
+        return get_user_from_token(token, api_config.get("jwt_secret_key", "super-secret"))
     elif form_data and verify_auth(api_config, form_data.username, form_data.password):
         return form_data.username
 
     raise HTTPException(
         status_code=status.HTTP_401_UNAUTHORIZED,
         detail="Unauthorized",
     )
 
 
-@router_login.post('/token/login', response_model=AccessAndRefreshToken)
-def token_login(form_data: HTTPBasicCredentials = Depends(security),
-                api_config=Depends(get_api_config)):
-
+@router_login.post("/token/login", response_model=AccessAndRefreshToken)
+def token_login(
+    form_data: HTTPBasicCredentials = Depends(security), api_config=Depends(get_api_config)
+):
     if verify_auth(api_config, form_data.username, form_data.password):
-        token_data = {'identity': {'u': form_data.username}}
-        access_token = create_token(token_data, api_config.get('jwt_secret_key', 'super-secret'))
-        refresh_token = create_token(token_data, api_config.get('jwt_secret_key', 'super-secret'),
-                                     token_type="refresh")
+        token_data = {"identity": {"u": form_data.username}}
+        access_token = create_token(token_data, api_config.get("jwt_secret_key", "super-secret"))
+        refresh_token = create_token(
+            token_data, api_config.get("jwt_secret_key", "super-secret"), token_type="refresh"
+        )
         return {
             "access_token": access_token,
             "refresh_token": refresh_token,
         }
     else:
         raise HTTPException(
             status_code=status.HTTP_401_UNAUTHORIZED,
             detail="Incorrect username or password",
         )
 
 
-@router_login.post('/token/refresh', response_model=AccessToken)
+@router_login.post("/token/refresh", response_model=AccessToken)
 def token_refresh(token: str = Depends(oauth2_scheme), api_config=Depends(get_api_config)):
     # Refresh token
-    u = get_user_from_token(token, api_config.get(
-        'jwt_secret_key', 'super-secret'), 'refresh')
-    token_data = {'identity': {'u': u}}
-    access_token = create_token(token_data, api_config.get('jwt_secret_key', 'super-secret'),
-                                token_type="access")
-    return {'access_token': access_token}
+    u = get_user_from_token(token, api_config.get("jwt_secret_key", "super-secret"), "refresh")
+    token_data = {"identity": {"u": u}}
+    access_token = create_token(
+        token_data, api_config.get("jwt_secret_key", "super-secret"), token_type="access"
+    )
+    return {"access_token": access_token}
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/api_background_tasks.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/api_background_tasks.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,146 +1,177 @@
 import logging
 from copy import deepcopy
+from typing import List
 
 from fastapi import APIRouter, BackgroundTasks, Depends
 from fastapi.exceptions import HTTPException
 
 from freqtrade.constants import Config
 from freqtrade.enums import CandleType
 from freqtrade.exceptions import OperationalException
 from freqtrade.persistence import FtNoDBContext
-from freqtrade.rpc.api_server.api_schemas import (BackgroundTaskStatus, BgJobStarted,
-                                                  ExchangeModePayloadMixin, PairListsPayload,
-                                                  PairListsResponse, WhitelistEvaluateResponse)
+from freqtrade.rpc.api_server.api_schemas import (
+    BackgroundTaskStatus,
+    BgJobStarted,
+    ExchangeModePayloadMixin,
+    PairListsPayload,
+    PairListsResponse,
+    WhitelistEvaluateResponse,
+)
 from freqtrade.rpc.api_server.deps import get_config, get_exchange
 from freqtrade.rpc.api_server.webserver_bgwork import ApiBG
 
 
 logger = logging.getLogger(__name__)
 
 # Private API, protected by authentication and webserver_mode dependency
 router = APIRouter()
 
 
-@router.get('/background/{jobid}', response_model=BackgroundTaskStatus, tags=['webserver'])
+@router.get("/background", response_model=List[BackgroundTaskStatus], tags=["webserver"])
+def background_job_list():
+    return [
+        {
+            "job_id": jobid,
+            "job_category": job["category"],
+            "status": job["status"],
+            "running": job["is_running"],
+            "progress": job.get("progress"),
+            "error": job.get("error", None),
+        }
+        for jobid, job in ApiBG.jobs.items()
+    ]
+
+
+@router.get("/background/{jobid}", response_model=BackgroundTaskStatus, tags=["webserver"])
 def background_job(jobid: str):
     if not (job := ApiBG.jobs.get(jobid)):
-        raise HTTPException(status_code=404, detail='Job not found.')
+        raise HTTPException(status_code=404, detail="Job not found.")
 
     return {
-        'job_id': jobid,
-        'job_category': job['category'],
-        'status': job['status'],
-        'running': job['is_running'],
-        'progress': job.get('progress'),
-        # 'job_error': job['error'],
+        "job_id": jobid,
+        "job_category": job["category"],
+        "status": job["status"],
+        "running": job["is_running"],
+        "progress": job.get("progress"),
+        "error": job.get("error", None),
     }
 
 
-@router.get('/pairlists/available',
-            response_model=PairListsResponse, tags=['pairlists', 'webserver'])
+@router.get(
+    "/pairlists/available", response_model=PairListsResponse, tags=["pairlists", "webserver"]
+)
 def list_pairlists(config=Depends(get_config)):
     from freqtrade.resolvers import PairListResolver
-    pairlists = PairListResolver.search_all_objects(
-        config, False)
-    pairlists = sorted(pairlists, key=lambda x: x['name'])
-
-    return {'pairlists': [{
-        "name": x['name'],
-        "is_pairlist_generator": x['class'].is_pairlist_generator,
-        "params": x['class'].available_parameters(),
-        "description": x['class'].description(),
-         } for x in pairlists
-    ]}
+
+    pairlists = PairListResolver.search_all_objects(config, False)
+    pairlists = sorted(pairlists, key=lambda x: x["name"])
+
+    return {
+        "pairlists": [
+            {
+                "name": x["name"],
+                "is_pairlist_generator": x["class"].is_pairlist_generator,
+                "params": x["class"].available_parameters(),
+                "description": x["class"].description(),
+            }
+            for x in pairlists
+        ]
+    }
 
 
 def __run_pairlist(job_id: str, config_loc: Config):
     try:
-
-        ApiBG.jobs[job_id]['is_running'] = True
+        ApiBG.jobs[job_id]["is_running"] = True
         from freqtrade.plugins.pairlistmanager import PairListManager
+
         with FtNoDBContext():
             exchange = get_exchange(config_loc)
             pairlists = PairListManager(exchange, config_loc)
             pairlists.refresh_pairlist()
-            ApiBG.jobs[job_id]['result'] = {
-                    'method': pairlists.name_list,
-                    'length': len(pairlists.whitelist),
-                    'whitelist': pairlists.whitelist
-                }
-            ApiBG.jobs[job_id]['status'] = 'success'
+            ApiBG.jobs[job_id]["result"] = {
+                "method": pairlists.name_list,
+                "length": len(pairlists.whitelist),
+                "whitelist": pairlists.whitelist,
+            }
+            ApiBG.jobs[job_id]["status"] = "success"
     except (OperationalException, Exception) as e:
         logger.exception(e)
-        ApiBG.jobs[job_id]['error'] = str(e)
-        ApiBG.jobs[job_id]['status'] = 'failed'
+        ApiBG.jobs[job_id]["error"] = str(e)
+        ApiBG.jobs[job_id]["status"] = "failed"
     finally:
-        ApiBG.jobs[job_id]['is_running'] = False
+        ApiBG.jobs[job_id]["is_running"] = False
         ApiBG.pairlist_running = False
 
 
-@router.post('/pairlists/evaluate', response_model=BgJobStarted, tags=['pairlists', 'webserver'])
-def pairlists_evaluate(payload: PairListsPayload, background_tasks: BackgroundTasks,
-                       config=Depends(get_config)):
+@router.post("/pairlists/evaluate", response_model=BgJobStarted, tags=["pairlists", "webserver"])
+def pairlists_evaluate(
+    payload: PairListsPayload, background_tasks: BackgroundTasks, config=Depends(get_config)
+):
     if ApiBG.pairlist_running:
-        raise HTTPException(status_code=400, detail='Pairlist evaluation is already running.')
+        raise HTTPException(status_code=400, detail="Pairlist evaluation is already running.")
 
     config_loc = deepcopy(config)
-    config_loc['stake_currency'] = payload.stake_currency
-    config_loc['pairlists'] = payload.pairlists
+    config_loc["stake_currency"] = payload.stake_currency
+    config_loc["pairlists"] = payload.pairlists
     handleExchangePayload(payload, config_loc)
     # TODO: overwrite blacklist? make it optional and fall back to the one in config?
     # Outcome depends on the UI approach.
-    config_loc['exchange']['pair_blacklist'] = payload.blacklist
+    config_loc["exchange"]["pair_blacklist"] = payload.blacklist
     # Random job id
     job_id = ApiBG.get_job_id()
 
     ApiBG.jobs[job_id] = {
-        'category': 'pairlist',
-        'status': 'pending',
-        'progress': None,
-        'is_running': False,
-        'result': {},
-        'error': None,
+        "category": "pairlist",
+        "status": "pending",
+        "progress": None,
+        "is_running": False,
+        "result": {},
+        "error": None,
     }
     background_tasks.add_task(__run_pairlist, job_id, config_loc)
     ApiBG.pairlist_running = True
 
     return {
-        'status': 'Pairlist evaluation started in background.',
-        'job_id': job_id,
+        "status": "Pairlist evaluation started in background.",
+        "job_id": job_id,
     }
 
 
 def handleExchangePayload(payload: ExchangeModePayloadMixin, config_loc: Config):
     """
     Handle exchange and trading mode payload.
     Updates the configuration with the payload values.
     """
     if payload.exchange:
-        config_loc['exchange']['name'] = payload.exchange
+        config_loc["exchange"]["name"] = payload.exchange
     if payload.trading_mode:
-        config_loc['trading_mode'] = payload.trading_mode
-        config_loc['candle_type_def'] = CandleType.get_default(
-            config_loc.get('trading_mode', 'spot') or 'spot')
+        config_loc["trading_mode"] = payload.trading_mode
+        config_loc["candle_type_def"] = CandleType.get_default(
+            config_loc.get("trading_mode", "spot") or "spot"
+        )
     if payload.margin_mode:
-        config_loc['margin_mode'] = payload.margin_mode
+        config_loc["margin_mode"] = payload.margin_mode
 
 
-@router.get('/pairlists/evaluate/{jobid}', response_model=WhitelistEvaluateResponse,
-            tags=['pairlists', 'webserver'])
+@router.get(
+    "/pairlists/evaluate/{jobid}",
+    response_model=WhitelistEvaluateResponse,
+    tags=["pairlists", "webserver"],
+)
 def pairlists_evaluate_get(jobid: str):
     if not (job := ApiBG.jobs.get(jobid)):
-        raise HTTPException(status_code=404, detail='Job not found.')
+        raise HTTPException(status_code=404, detail="Job not found.")
 
-    if job['is_running']:
-        raise HTTPException(status_code=400, detail='Job not finished yet.')
+    if job["is_running"]:
+        raise HTTPException(status_code=400, detail="Job not finished yet.")
 
-    if error := job['error']:
+    if error := job["error"]:
         return {
-            'status': 'failed',
-            'error': error,
+            "status": "failed",
+            "error": error,
         }
 
     return {
-        'status': 'success',
-        'result': job['result'],
+        "status": "success",
+        "result": job["result"],
     }
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/api_backtest.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/api_backtest.py`

 * *Files 22% similar despite different names*

```diff
@@ -6,24 +6,33 @@
 from typing import Any, Dict, List
 
 from fastapi import APIRouter, BackgroundTasks, Depends
 from fastapi.exceptions import HTTPException
 
 from freqtrade.configuration.config_validation import validate_config_consistency
 from freqtrade.constants import Config
-from freqtrade.data.btanalysis import (delete_backtest_result, get_backtest_market_change,
-                                       get_backtest_result, get_backtest_resultlist,
-                                       load_and_merge_backtest_result, update_backtest_metadata)
+from freqtrade.data.btanalysis import (
+    delete_backtest_result,
+    get_backtest_market_change,
+    get_backtest_result,
+    get_backtest_resultlist,
+    load_and_merge_backtest_result,
+    update_backtest_metadata,
+)
 from freqtrade.enums import BacktestState
 from freqtrade.exceptions import ConfigurationError, DependencyException, OperationalException
 from freqtrade.exchange.common import remove_exchange_credentials
 from freqtrade.misc import deep_merge_dicts, is_file_in_dir
-from freqtrade.rpc.api_server.api_schemas import (BacktestHistoryEntry, BacktestMarketChange,
-                                                  BacktestMetadataUpdate, BacktestRequest,
-                                                  BacktestResponse)
+from freqtrade.rpc.api_server.api_schemas import (
+    BacktestHistoryEntry,
+    BacktestMarketChange,
+    BacktestMetadataUpdate,
+    BacktestRequest,
+    BacktestResponse,
+)
 from freqtrade.rpc.api_server.deps import get_config
 from freqtrade.rpc.api_server.webserver_bgwork import ApiBG
 from freqtrade.rpc.rpc import RPCException
 from freqtrade.types import get_BacktestResultType_default
 
 
 logger = logging.getLogger(__name__)
@@ -36,115 +45,115 @@
     from freqtrade.data.metrics import combined_dataframes_with_rel_mean
     from freqtrade.optimize.optimize_reports import generate_backtest_stats, store_backtest_stats
     from freqtrade.resolvers import StrategyResolver
 
     asyncio.set_event_loop(asyncio.new_event_loop())
     try:
         # Reload strategy
-        lastconfig = ApiBG.bt['last_config']
+        lastconfig = ApiBG.bt["last_config"]
         strat = StrategyResolver.load_strategy(btconfig)
         validate_config_consistency(btconfig)
 
         if (
-            not ApiBG.bt['bt']
-            or lastconfig.get('timeframe') != strat.timeframe
-            or lastconfig.get('timeframe_detail') != btconfig.get('timeframe_detail')
-            or lastconfig.get('timerange') != btconfig['timerange']
+            not ApiBG.bt["bt"]
+            or lastconfig.get("timeframe") != strat.timeframe
+            or lastconfig.get("timeframe_detail") != btconfig.get("timeframe_detail")
+            or lastconfig.get("timerange") != btconfig["timerange"]
         ):
             from freqtrade.optimize.backtesting import Backtesting
-            ApiBG.bt['bt'] = Backtesting(btconfig)
-            ApiBG.bt['bt'].load_bt_data_detail()
+
+            ApiBG.bt["bt"] = Backtesting(btconfig)
+            ApiBG.bt["bt"].load_bt_data_detail()
         else:
-            ApiBG.bt['bt'].config = btconfig
-            ApiBG.bt['bt'].init_backtest()
+            ApiBG.bt["bt"].config = btconfig
+            ApiBG.bt["bt"].init_backtest()
         # Only reload data if timeframe changed.
         if (
-            not ApiBG.bt['data']
-            or not ApiBG.bt['timerange']
-            or lastconfig.get('timeframe') != strat.timeframe
-            or lastconfig.get('timerange') != btconfig['timerange']
+            not ApiBG.bt["data"]
+            or not ApiBG.bt["timerange"]
+            or lastconfig.get("timeframe") != strat.timeframe
+            or lastconfig.get("timerange") != btconfig["timerange"]
         ):
-            ApiBG.bt['data'], ApiBG.bt['timerange'] = ApiBG.bt[
-                'bt'].load_bt_data()
+            ApiBG.bt["data"], ApiBG.bt["timerange"] = ApiBG.bt["bt"].load_bt_data()
 
-        lastconfig['timerange'] = btconfig['timerange']
-        lastconfig['timeframe'] = strat.timeframe
-        lastconfig['protections'] = btconfig.get('protections', [])
-        lastconfig['enable_protections'] = btconfig.get('enable_protections')
-        lastconfig['dry_run_wallet'] = btconfig.get('dry_run_wallet')
-
-        ApiBG.bt['bt'].enable_protections = btconfig.get('enable_protections', False)
-        ApiBG.bt['bt'].strategylist = [strat]
-        ApiBG.bt['bt'].results = get_BacktestResultType_default()
-        ApiBG.bt['bt'].load_prior_backtest()
+        lastconfig["timerange"] = btconfig["timerange"]
+        lastconfig["timeframe"] = strat.timeframe
+        lastconfig["protections"] = btconfig.get("protections", [])
+        lastconfig["enable_protections"] = btconfig.get("enable_protections")
+        lastconfig["dry_run_wallet"] = btconfig.get("dry_run_wallet")
+
+        ApiBG.bt["bt"].enable_protections = btconfig.get("enable_protections", False)
+        ApiBG.bt["bt"].strategylist = [strat]
+        ApiBG.bt["bt"].results = get_BacktestResultType_default()
+        ApiBG.bt["bt"].load_prior_backtest()
 
-        ApiBG.bt['bt'].abort = False
+        ApiBG.bt["bt"].abort = False
         strategy_name = strat.get_strategy_name()
-        if (ApiBG.bt['bt'].results and
-                strategy_name in ApiBG.bt['bt'].results['strategy']):
+        if ApiBG.bt["bt"].results and strategy_name in ApiBG.bt["bt"].results["strategy"]:
             # When previous result hash matches - reuse that result and skip backtesting.
-            logger.info(f'Reusing result of previous backtest for {strategy_name}')
+            logger.info(f"Reusing result of previous backtest for {strategy_name}")
         else:
-            min_date, max_date = ApiBG.bt['bt'].backtest_one_strategy(
-                strat, ApiBG.bt['data'], ApiBG.bt['timerange'])
-
-            ApiBG.bt['bt'].results = generate_backtest_stats(
-                ApiBG.bt['data'], ApiBG.bt['bt'].all_results,
-                min_date=min_date, max_date=max_date)
+            min_date, max_date = ApiBG.bt["bt"].backtest_one_strategy(
+                strat, ApiBG.bt["data"], ApiBG.bt["timerange"]
+            )
+
+            ApiBG.bt["bt"].results = generate_backtest_stats(
+                ApiBG.bt["data"], ApiBG.bt["bt"].all_results, min_date=min_date, max_date=max_date
+            )
 
-        if btconfig.get('export', 'none') == 'trades':
-            combined_res = combined_dataframes_with_rel_mean(ApiBG.bt['data'], min_date, max_date)
+        if btconfig.get("export", "none") == "trades":
+            combined_res = combined_dataframes_with_rel_mean(ApiBG.bt["data"], min_date, max_date)
             fn = store_backtest_stats(
-                btconfig['exportfilename'],
-                ApiBG.bt['bt'].results,
+                btconfig["exportfilename"],
+                ApiBG.bt["bt"].results,
                 datetime.now().strftime("%Y-%m-%d_%H-%M-%S"),
-                market_change_data=combined_res
-                )
-            ApiBG.bt['bt'].results['metadata'][strategy_name]['filename'] = str(fn.stem)
-            ApiBG.bt['bt'].results['metadata'][strategy_name]['strategy'] = strategy_name
+                market_change_data=combined_res,
+            )
+            ApiBG.bt["bt"].results["metadata"][strategy_name]["filename"] = str(fn.stem)
+            ApiBG.bt["bt"].results["metadata"][strategy_name]["strategy"] = strategy_name
 
         logger.info("Backtest finished.")
 
     except ConfigurationError as e:
         logger.error(f"Backtesting encountered a configuration Error: {e}")
 
     except (Exception, OperationalException, DependencyException) as e:
         logger.exception(f"Backtesting caused an error: {e}")
-        ApiBG.bt['bt_error'] = str(e)
+        ApiBG.bt["bt_error"] = str(e)
     finally:
         ApiBG.bgtask_running = False
 
 
-@router.post('/backtest', response_model=BacktestResponse, tags=['webserver', 'backtest'])
+@router.post("/backtest", response_model=BacktestResponse, tags=["webserver", "backtest"])
 async def api_start_backtest(
-        bt_settings: BacktestRequest, background_tasks: BackgroundTasks,
-        config=Depends(get_config)):
-    ApiBG.bt['bt_error'] = None
+    bt_settings: BacktestRequest, background_tasks: BackgroundTasks, config=Depends(get_config)
+):
+    ApiBG.bt["bt_error"] = None
     """Start backtesting if not done so already"""
     if ApiBG.bgtask_running:
-        raise RPCException('Bot Background task already running')
+        raise RPCException("Bot Background task already running")
 
-    if ':' in bt_settings.strategy:
+    if ":" in bt_settings.strategy:
         raise HTTPException(status_code=500, detail="base64 encoded strategies are not allowed.")
 
     btconfig = deepcopy(config)
-    remove_exchange_credentials(btconfig['exchange'], True)
+    remove_exchange_credentials(btconfig["exchange"], True)
     settings = dict(bt_settings)
-    if settings.get('freqai', None) is not None:
-        settings['freqai'] = dict(settings['freqai'])
+    if settings.get("freqai", None) is not None:
+        settings["freqai"] = dict(settings["freqai"])
     # Pydantic models will contain all keys, but non-provided ones are None
 
     btconfig = deep_merge_dicts(settings, btconfig, allow_null_overrides=False)
     try:
-        btconfig['stake_amount'] = float(btconfig['stake_amount'])
+        btconfig["stake_amount"] = float(btconfig["stake_amount"])
     except ValueError:
         pass
 
     # Force dry-run for backtesting
-    btconfig['dry_run'] = True
+    btconfig["dry_run"] = True
 
     # Start backtesting
     # Initialize backtesting object
 
     background_tasks.add_task(__run_backtest_bg, btconfig=btconfig)
     ApiBG.bgtask_running = True
 
@@ -153,181 +162,193 @@
         "running": True,
         "progress": 0,
         "step": str(BacktestState.STARTUP),
         "status_msg": "Backtest started",
     }
 
 
-@router.get('/backtest', response_model=BacktestResponse, tags=['webserver', 'backtest'])
+@router.get("/backtest", response_model=BacktestResponse, tags=["webserver", "backtest"])
 def api_get_backtest():
     """
     Get backtesting result.
     Returns Result after backtesting has been ran.
     """
     from freqtrade.persistence import LocalTrade
+
     if ApiBG.bgtask_running:
         return {
             "status": "running",
             "running": True,
-            "step": (ApiBG.bt['bt'].progress.action if ApiBG.bt['bt']
-                     else str(BacktestState.STARTUP)),
-            "progress": ApiBG.bt['bt'].progress.progress if ApiBG.bt['bt'] else 0,
+            "step": (
+                ApiBG.bt["bt"].progress.action if ApiBG.bt["bt"] else str(BacktestState.STARTUP)
+            ),
+            "progress": ApiBG.bt["bt"].progress.progress if ApiBG.bt["bt"] else 0,
             "trade_count": len(LocalTrade.trades),
             "status_msg": "Backtest running",
         }
 
-    if not ApiBG.bt['bt']:
+    if not ApiBG.bt["bt"]:
         return {
             "status": "not_started",
             "running": False,
             "step": "",
             "progress": 0,
-            "status_msg": "Backtest not yet executed"
+            "status_msg": "Backtest not yet executed",
         }
-    if ApiBG.bt['bt_error']:
+    if ApiBG.bt["bt_error"]:
         return {
             "status": "error",
             "running": False,
             "step": "",
             "progress": 0,
-            "status_msg": f"Backtest failed with {ApiBG.bt['bt_error']}"
+            "status_msg": f"Backtest failed with {ApiBG.bt['bt_error']}",
         }
 
     return {
         "status": "ended",
         "running": False,
         "status_msg": "Backtest ended",
         "step": "finished",
         "progress": 1,
-        "backtest_result": ApiBG.bt['bt'].results,
+        "backtest_result": ApiBG.bt["bt"].results,
     }
 
 
-@router.delete('/backtest', response_model=BacktestResponse, tags=['webserver', 'backtest'])
+@router.delete("/backtest", response_model=BacktestResponse, tags=["webserver", "backtest"])
 def api_delete_backtest():
     """Reset backtesting"""
     if ApiBG.bgtask_running:
         return {
             "status": "running",
             "running": True,
             "step": "",
             "progress": 0,
             "status_msg": "Backtest running",
         }
-    if ApiBG.bt['bt']:
-        ApiBG.bt['bt'].cleanup()
-        del ApiBG.bt['bt']
-        ApiBG.bt['bt'] = None
-        del ApiBG.bt['data']
-        ApiBG.bt['data'] = None
+    if ApiBG.bt["bt"]:
+        ApiBG.bt["bt"].cleanup()
+        del ApiBG.bt["bt"]
+        ApiBG.bt["bt"] = None
+        del ApiBG.bt["data"]
+        ApiBG.bt["data"] = None
         logger.info("Backtesting reset")
     return {
         "status": "reset",
         "running": False,
         "step": "",
         "progress": 0,
         "status_msg": "Backtest reset",
     }
 
 
-@router.get('/backtest/abort', response_model=BacktestResponse, tags=['webserver', 'backtest'])
+@router.get("/backtest/abort", response_model=BacktestResponse, tags=["webserver", "backtest"])
 def api_backtest_abort():
     if not ApiBG.bgtask_running:
         return {
             "status": "not_running",
             "running": False,
             "step": "",
             "progress": 0,
             "status_msg": "Backtest ended",
         }
-    ApiBG.bt['bt'].abort = True
+    ApiBG.bt["bt"].abort = True
     return {
         "status": "stopping",
         "running": False,
         "step": "",
         "progress": 0,
         "status_msg": "Backtest ended",
     }
 
 
-@router.get('/backtest/history', response_model=List[BacktestHistoryEntry],
-            tags=['webserver', 'backtest'])
+@router.get(
+    "/backtest/history", response_model=List[BacktestHistoryEntry], tags=["webserver", "backtest"]
+)
 def api_backtest_history(config=Depends(get_config)):
     # Get backtest result history, read from metadata files
-    return get_backtest_resultlist(config['user_data_dir'] / 'backtest_results')
+    return get_backtest_resultlist(config["user_data_dir"] / "backtest_results")
 
 
-@router.get('/backtest/history/result', response_model=BacktestResponse,
-            tags=['webserver', 'backtest'])
+@router.get(
+    "/backtest/history/result", response_model=BacktestResponse, tags=["webserver", "backtest"]
+)
 def api_backtest_history_result(filename: str, strategy: str, config=Depends(get_config)):
     # Get backtest result history, read from metadata files
-    bt_results_base: Path = config['user_data_dir'] / 'backtest_results'
-    fn = (bt_results_base / filename).with_suffix('.json')
+    bt_results_base: Path = config["user_data_dir"] / "backtest_results"
+    fn = (bt_results_base / filename).with_suffix(".json")
 
     results: Dict[str, Any] = {
-        'metadata': {},
-        'strategy': {},
-        'strategy_comparison': [],
+        "metadata": {},
+        "strategy": {},
+        "strategy_comparison": [],
     }
     if not is_file_in_dir(fn, bt_results_base):
         raise HTTPException(status_code=404, detail="File not found.")
     load_and_merge_backtest_result(strategy, fn, results)
     return {
         "status": "ended",
         "running": False,
         "step": "",
         "progress": 1,
         "status_msg": "Historic result",
         "backtest_result": results,
     }
 
 
-@router.delete('/backtest/history/{file}', response_model=List[BacktestHistoryEntry],
-               tags=['webserver', 'backtest'])
+@router.delete(
+    "/backtest/history/{file}",
+    response_model=List[BacktestHistoryEntry],
+    tags=["webserver", "backtest"],
+)
 def api_delete_backtest_history_entry(file: str, config=Depends(get_config)):
     # Get backtest result history, read from metadata files
-    bt_results_base: Path = config['user_data_dir'] / 'backtest_results'
-    file_abs = (bt_results_base / file).with_suffix('.json')
+    bt_results_base: Path = config["user_data_dir"] / "backtest_results"
+    file_abs = (bt_results_base / file).with_suffix(".json")
     # Ensure file is in backtest_results directory
     if not is_file_in_dir(file_abs, bt_results_base):
         raise HTTPException(status_code=404, detail="File not found.")
 
     delete_backtest_result(file_abs)
-    return get_backtest_resultlist(config['user_data_dir'] / 'backtest_results')
+    return get_backtest_resultlist(config["user_data_dir"] / "backtest_results")
 
 
-@router.patch('/backtest/history/{file}', response_model=List[BacktestHistoryEntry],
-              tags=['webserver', 'backtest'])
-def api_update_backtest_history_entry(file: str, body: BacktestMetadataUpdate,
-                                      config=Depends(get_config)):
+@router.patch(
+    "/backtest/history/{file}",
+    response_model=List[BacktestHistoryEntry],
+    tags=["webserver", "backtest"],
+)
+def api_update_backtest_history_entry(
+    file: str, body: BacktestMetadataUpdate, config=Depends(get_config)
+):
     # Get backtest result history, read from metadata files
-    bt_results_base: Path = config['user_data_dir'] / 'backtest_results'
-    file_abs = (bt_results_base / file).with_suffix('.json')
+    bt_results_base: Path = config["user_data_dir"] / "backtest_results"
+    file_abs = (bt_results_base / file).with_suffix(".json")
     # Ensure file is in backtest_results directory
     if not is_file_in_dir(file_abs, bt_results_base):
         raise HTTPException(status_code=404, detail="File not found.")
-    content = {
-        'notes': body.notes
-    }
+    content = {"notes": body.notes}
     try:
         update_backtest_metadata(file_abs, body.strategy, content)
     except ValueError as e:
         raise HTTPException(status_code=400, detail=str(e))
 
     return get_backtest_result(file_abs)
 
 
-@router.get('/backtest/history/{file}/market_change', response_model=BacktestMarketChange,
-            tags=['webserver', 'backtest'])
+@router.get(
+    "/backtest/history/{file}/market_change",
+    response_model=BacktestMarketChange,
+    tags=["webserver", "backtest"],
+)
 def api_get_backtest_market_change(file: str, config=Depends(get_config)):
-    bt_results_base: Path = config['user_data_dir'] / 'backtest_results'
-    file_abs = (bt_results_base / f"{file}_market_change").with_suffix('.feather')
+    bt_results_base: Path = config["user_data_dir"] / "backtest_results"
+    file_abs = (bt_results_base / f"{file}_market_change").with_suffix(".feather")
     # Ensure file is in backtest_results directory
     if not is_file_in_dir(file_abs, bt_results_base):
         raise HTTPException(status_code=404, detail="File not found.")
     df = get_backtest_market_change(file_abs)
 
     return {
-        'columns': df.columns.tolist(),
-        'data': df.values.tolist(),
-        'length': len(df),
+        "columns": df.columns.tolist(),
+        "data": df.values.tolist(),
+        "length": len(df),
     }
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/api_schemas.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/api_schemas.py`

 * *Files 1% similar despite different names*

```diff
@@ -40,14 +40,15 @@
 
 class BackgroundTaskStatus(BaseModel):
     job_id: str
     job_category: str
     status: str
     running: bool
     progress: Optional[float] = None
+    error: Optional[str] = None
 
 
 class BackgroundTaskResult(BaseModel):
     error: Optional[str] = None
     status: str
 
 
@@ -376,15 +377,15 @@
 class Locks(BaseModel):
     lock_count: int
     locks: List[LockModel]
 
 
 class LocksPayload(BaseModel):
     pair: str
-    side: str = '*'  # Default to both sides
+    side: str = "*"  # Default to both sides
     until: AwareDatetime
     reason: Optional[str] = None
 
 
 class DeleteLockRequest(BaseModel):
     pair: Optional[str] = None
     lockid: Optional[int] = None
@@ -556,24 +557,24 @@
 
 # TODO: This is a copy of BacktestHistoryEntryType
 class BacktestHistoryEntry(BaseModel):
     filename: str
     strategy: str
     run_id: str
     backtest_start_time: int
-    notes: Optional[str] = ''
+    notes: Optional[str] = ""
     backtest_start_ts: Optional[int] = None
     backtest_end_ts: Optional[int] = None
     timeframe: Optional[str] = None
     timeframe_detail: Optional[str] = None
 
 
 class BacktestMetadataUpdate(BaseModel):
     strategy: str
-    notes: str = ''
+    notes: str = ""
 
 
 class BacktestMarketChange(BaseModel):
     columns: List[str]
     length: int
     data: List[List[Any]]
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/api_v1.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/api_v1.py`

 * *Files 8% similar despite different names*

```diff
@@ -6,26 +6,53 @@
 from fastapi.exceptions import HTTPException
 
 from freqtrade import __version__
 from freqtrade.data.history import get_datahandler
 from freqtrade.enums import CandleType, TradingMode
 from freqtrade.exceptions import OperationalException
 from freqtrade.rpc import RPC
-from freqtrade.rpc.api_server.api_schemas import (AvailablePairs, Balances, BlacklistPayload,
-                                                  BlacklistResponse, Count, DailyWeeklyMonthly,
-                                                  DeleteLockRequest, DeleteTrade, Entry,
-                                                  ExchangeListResponse, Exit, ForceEnterPayload,
-                                                  ForceEnterResponse, ForceExitPayload,
-                                                  FreqAIModelListResponse, Health, Locks,
-                                                  LocksPayload, Logs, MixTag, OpenTradeSchema,
-                                                  PairCandlesRequest, PairHistory,
-                                                  PairHistoryRequest, PerformanceEntry, Ping,
-                                                  PlotConfig, Profit, ResultMsg, ShowConfig, Stats,
-                                                  StatusMsg, StrategyListResponse, StrategyResponse,
-                                                  SysInfo, Version, WhitelistResponse)
+from freqtrade.rpc.api_server.api_schemas import (
+    AvailablePairs,
+    Balances,
+    BlacklistPayload,
+    BlacklistResponse,
+    Count,
+    DailyWeeklyMonthly,
+    DeleteLockRequest,
+    DeleteTrade,
+    Entry,
+    ExchangeListResponse,
+    Exit,
+    ForceEnterPayload,
+    ForceEnterResponse,
+    ForceExitPayload,
+    FreqAIModelListResponse,
+    Health,
+    Locks,
+    LocksPayload,
+    Logs,
+    MixTag,
+    OpenTradeSchema,
+    PairCandlesRequest,
+    PairHistory,
+    PairHistoryRequest,
+    PerformanceEntry,
+    Ping,
+    PlotConfig,
+    Profit,
+    ResultMsg,
+    ShowConfig,
+    Stats,
+    StatusMsg,
+    StrategyListResponse,
+    StrategyResponse,
+    SysInfo,
+    Version,
+    WhitelistResponse,
+)
 from freqtrade.rpc.api_server.deps import get_config, get_exchange, get_rpc, get_rpc_optional
 from freqtrade.rpc.rpc import RPCException
 
 
 logger = logging.getLogger(__name__)
 
 # API version
@@ -59,365 +86,400 @@
 
 # Public API, requires no auth.
 router_public = APIRouter()
 # Private API, protected by authentication
 router = APIRouter()
 
 
-@router_public.get('/ping', response_model=Ping)
+@router_public.get("/ping", response_model=Ping)
 def ping():
     """simple ping"""
     return {"status": "pong"}
 
 
-@router.get('/version', response_model=Version, tags=['info'])
+@router.get("/version", response_model=Version, tags=["info"])
 def version():
-    """ Bot Version info"""
+    """Bot Version info"""
     return {"version": __version__}
 
 
-@router.get('/balance', response_model=Balances, tags=['info'])
+@router.get("/balance", response_model=Balances, tags=["info"])
 def balance(rpc: RPC = Depends(get_rpc), config=Depends(get_config)):
     """Account Balances"""
-    return rpc._rpc_balance(config['stake_currency'], config.get('fiat_display_currency', ''),)
+    return rpc._rpc_balance(
+        config["stake_currency"],
+        config.get("fiat_display_currency", ""),
+    )
 
 
-@router.get('/count', response_model=Count, tags=['info'])
+@router.get("/count", response_model=Count, tags=["info"])
 def count(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_count()
 
 
-@router.get('/entries', response_model=List[Entry], tags=['info'])
+@router.get("/entries", response_model=List[Entry], tags=["info"])
 def entries(pair: Optional[str] = None, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_enter_tag_performance(pair)
 
 
-@router.get('/exits', response_model=List[Exit], tags=['info'])
+@router.get("/exits", response_model=List[Exit], tags=["info"])
 def exits(pair: Optional[str] = None, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_exit_reason_performance(pair)
 
 
-@router.get('/mix_tags', response_model=List[MixTag], tags=['info'])
+@router.get("/mix_tags", response_model=List[MixTag], tags=["info"])
 def mix_tags(pair: Optional[str] = None, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_mix_tag_performance(pair)
 
 
-@router.get('/performance', response_model=List[PerformanceEntry], tags=['info'])
+@router.get("/performance", response_model=List[PerformanceEntry], tags=["info"])
 def performance(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_performance()
 
 
-@router.get('/profit', response_model=Profit, tags=['info'])
+@router.get("/profit", response_model=Profit, tags=["info"])
 def profit(rpc: RPC = Depends(get_rpc), config=Depends(get_config)):
-    return rpc._rpc_trade_statistics(config['stake_currency'],
-                                     config.get('fiat_display_currency')
-                                     )
+    return rpc._rpc_trade_statistics(config["stake_currency"], config.get("fiat_display_currency"))
 
 
-@router.get('/stats', response_model=Stats, tags=['info'])
+@router.get("/stats", response_model=Stats, tags=["info"])
 def stats(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_stats()
 
 
-@router.get('/daily', response_model=DailyWeeklyMonthly, tags=['info'])
+@router.get("/daily", response_model=DailyWeeklyMonthly, tags=["info"])
 def daily(timescale: int = 7, rpc: RPC = Depends(get_rpc), config=Depends(get_config)):
-    return rpc._rpc_timeunit_profit(timescale, config['stake_currency'],
-                                    config.get('fiat_display_currency', ''))
+    return rpc._rpc_timeunit_profit(
+        timescale, config["stake_currency"], config.get("fiat_display_currency", "")
+    )
 
 
-@router.get('/weekly', response_model=DailyWeeklyMonthly, tags=['info'])
+@router.get("/weekly", response_model=DailyWeeklyMonthly, tags=["info"])
 def weekly(timescale: int = 4, rpc: RPC = Depends(get_rpc), config=Depends(get_config)):
-    return rpc._rpc_timeunit_profit(timescale, config['stake_currency'],
-                                    config.get('fiat_display_currency', ''), 'weeks')
+    return rpc._rpc_timeunit_profit(
+        timescale, config["stake_currency"], config.get("fiat_display_currency", ""), "weeks"
+    )
 
 
-@router.get('/monthly', response_model=DailyWeeklyMonthly, tags=['info'])
+@router.get("/monthly", response_model=DailyWeeklyMonthly, tags=["info"])
 def monthly(timescale: int = 3, rpc: RPC = Depends(get_rpc), config=Depends(get_config)):
-    return rpc._rpc_timeunit_profit(timescale, config['stake_currency'],
-                                    config.get('fiat_display_currency', ''), 'months')
+    return rpc._rpc_timeunit_profit(
+        timescale, config["stake_currency"], config.get("fiat_display_currency", ""), "months"
+    )
 
 
-@router.get('/status', response_model=List[OpenTradeSchema], tags=['info'])
+@router.get("/status", response_model=List[OpenTradeSchema], tags=["info"])
 def status(rpc: RPC = Depends(get_rpc)):
     try:
         return rpc._rpc_trade_status()
     except RPCException:
         return []
 
 
 # Using the responsemodel here will cause a ~100% increase in response time (from 1s to 2s)
 # on big databases. Correct response model: response_model=TradeResponse,
-@router.get('/trades', tags=['info', 'trading'])
+@router.get("/trades", tags=["info", "trading"])
 def trades(limit: int = 500, offset: int = 0, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_trade_history(limit, offset=offset, order_by_id=True)
 
 
-@router.get('/trade/{tradeid}', response_model=OpenTradeSchema, tags=['info', 'trading'])
+@router.get("/trade/{tradeid}", response_model=OpenTradeSchema, tags=["info", "trading"])
 def trade(tradeid: int = 0, rpc: RPC = Depends(get_rpc)):
     try:
         return rpc._rpc_trade_status([tradeid])[0]
     except (RPCException, KeyError):
-        raise HTTPException(status_code=404, detail='Trade not found.')
+        raise HTTPException(status_code=404, detail="Trade not found.")
 
 
-@router.delete('/trades/{tradeid}', response_model=DeleteTrade, tags=['info', 'trading'])
+@router.delete("/trades/{tradeid}", response_model=DeleteTrade, tags=["info", "trading"])
 def trades_delete(tradeid: int, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_delete(tradeid)
 
 
-@router.delete('/trades/{tradeid}/open-order', response_model=OpenTradeSchema,  tags=['trading'])
+@router.delete("/trades/{tradeid}/open-order", response_model=OpenTradeSchema, tags=["trading"])
 def trade_cancel_open_order(tradeid: int, rpc: RPC = Depends(get_rpc)):
     rpc._rpc_cancel_open_order(tradeid)
     return rpc._rpc_trade_status([tradeid])[0]
 
 
-@router.post('/trades/{tradeid}/reload', response_model=OpenTradeSchema,  tags=['trading'])
+@router.post("/trades/{tradeid}/reload", response_model=OpenTradeSchema, tags=["trading"])
 def trade_reload(tradeid: int, rpc: RPC = Depends(get_rpc)):
     rpc._rpc_reload_trade_from_exchange(tradeid)
     return rpc._rpc_trade_status([tradeid])[0]
 
 
 # TODO: Missing response model
-@router.get('/edge', tags=['info'])
+@router.get("/edge", tags=["info"])
 def edge(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_edge()
 
 
-@router.get('/show_config', response_model=ShowConfig, tags=['info'])
+@router.get("/show_config", response_model=ShowConfig, tags=["info"])
 def show_config(rpc: Optional[RPC] = Depends(get_rpc_optional), config=Depends(get_config)):
-    state = ''
+    state = ""
     strategy_version = None
     if rpc:
         state = rpc._freqtrade.state
         strategy_version = rpc._freqtrade.strategy.version()
     resp = RPC._rpc_show_config(config, state, strategy_version)
-    resp['api_version'] = API_VERSION
+    resp["api_version"] = API_VERSION
     return resp
 
 
 # /forcebuy is deprecated with short addition. use /forceentry instead
-@router.post('/forceenter', response_model=ForceEnterResponse, tags=['trading'])
-@router.post('/forcebuy', response_model=ForceEnterResponse, tags=['trading'])
+@router.post("/forceenter", response_model=ForceEnterResponse, tags=["trading"])
+@router.post("/forcebuy", response_model=ForceEnterResponse, tags=["trading"])
 def force_entry(payload: ForceEnterPayload, rpc: RPC = Depends(get_rpc)):
     ordertype = payload.ordertype.value if payload.ordertype else None
 
-    trade = rpc._rpc_force_entry(payload.pair, payload.price, order_side=payload.side,
-                                 order_type=ordertype, stake_amount=payload.stakeamount,
-                                 enter_tag=payload.entry_tag or 'force_entry',
-                                 leverage=payload.leverage)
+    trade = rpc._rpc_force_entry(
+        payload.pair,
+        payload.price,
+        order_side=payload.side,
+        order_type=ordertype,
+        stake_amount=payload.stakeamount,
+        enter_tag=payload.entry_tag or "force_entry",
+        leverage=payload.leverage,
+    )
 
     if trade:
         return ForceEnterResponse.model_validate(trade.to_json())
     else:
         return ForceEnterResponse.model_validate(
-            {"status": f"Error entering {payload.side} trade for pair {payload.pair}."})
+            {"status": f"Error entering {payload.side} trade for pair {payload.pair}."}
+        )
 
 
 # /forcesell is deprecated with short addition. use /forceexit instead
-@router.post('/forceexit', response_model=ResultMsg, tags=['trading'])
-@router.post('/forcesell', response_model=ResultMsg, tags=['trading'])
+@router.post("/forceexit", response_model=ResultMsg, tags=["trading"])
+@router.post("/forcesell", response_model=ResultMsg, tags=["trading"])
 def forceexit(payload: ForceExitPayload, rpc: RPC = Depends(get_rpc)):
     ordertype = payload.ordertype.value if payload.ordertype else None
     return rpc._rpc_force_exit(str(payload.tradeid), ordertype, amount=payload.amount)
 
 
-@router.get('/blacklist', response_model=BlacklistResponse, tags=['info', 'pairlist'])
+@router.get("/blacklist", response_model=BlacklistResponse, tags=["info", "pairlist"])
 def blacklist(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_blacklist()
 
 
-@router.post('/blacklist', response_model=BlacklistResponse, tags=['info', 'pairlist'])
+@router.post("/blacklist", response_model=BlacklistResponse, tags=["info", "pairlist"])
 def blacklist_post(payload: BlacklistPayload, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_blacklist(payload.blacklist)
 
 
-@router.delete('/blacklist', response_model=BlacklistResponse, tags=['info', 'pairlist'])
+@router.delete("/blacklist", response_model=BlacklistResponse, tags=["info", "pairlist"])
 def blacklist_delete(pairs_to_delete: List[str] = Query([]), rpc: RPC = Depends(get_rpc)):
     """Provide a list of pairs to delete from the blacklist"""
 
     return rpc._rpc_blacklist_delete(pairs_to_delete)
 
 
-@router.get('/whitelist', response_model=WhitelistResponse, tags=['info', 'pairlist'])
+@router.get("/whitelist", response_model=WhitelistResponse, tags=["info", "pairlist"])
 def whitelist(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_whitelist()
 
 
-@router.get('/locks', response_model=Locks, tags=['info', 'locks'])
+@router.get("/locks", response_model=Locks, tags=["info", "locks"])
 def locks(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_locks()
 
 
-@router.delete('/locks/{lockid}', response_model=Locks, tags=['info', 'locks'])
+@router.delete("/locks/{lockid}", response_model=Locks, tags=["info", "locks"])
 def delete_lock(lockid: int, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_delete_lock(lockid=lockid)
 
 
-@router.post('/locks/delete', response_model=Locks, tags=['info', 'locks'])
+@router.post("/locks/delete", response_model=Locks, tags=["info", "locks"])
 def delete_lock_pair(payload: DeleteLockRequest, rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_delete_lock(lockid=payload.lockid, pair=payload.pair)
 
 
-@router.post('/locks', response_model=Locks, tags=['info', 'locks'])
+@router.post("/locks", response_model=Locks, tags=["info", "locks"])
 def add_locks(payload: List[LocksPayload], rpc: RPC = Depends(get_rpc)):
     for lock in payload:
         rpc._rpc_add_lock(lock.pair, lock.until, lock.reason, lock.side)
     return rpc._rpc_locks()
 
 
-@router.get('/logs', response_model=Logs, tags=['info'])
+@router.get("/logs", response_model=Logs, tags=["info"])
 def logs(limit: Optional[int] = None):
     return RPC._rpc_get_logs(limit)
 
 
-@router.post('/start', response_model=StatusMsg, tags=['botcontrol'])
+@router.post("/start", response_model=StatusMsg, tags=["botcontrol"])
 def start(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_start()
 
 
-@router.post('/stop', response_model=StatusMsg, tags=['botcontrol'])
+@router.post("/stop", response_model=StatusMsg, tags=["botcontrol"])
 def stop(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_stop()
 
 
-@router.post('/stopentry', response_model=StatusMsg, tags=['botcontrol'])
-@router.post('/stopbuy', response_model=StatusMsg, tags=['botcontrol'])
+@router.post("/stopentry", response_model=StatusMsg, tags=["botcontrol"])
+@router.post("/stopbuy", response_model=StatusMsg, tags=["botcontrol"])
 def stop_buy(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_stopentry()
 
 
-@router.post('/reload_config', response_model=StatusMsg, tags=['botcontrol'])
+@router.post("/reload_config", response_model=StatusMsg, tags=["botcontrol"])
 def reload_config(rpc: RPC = Depends(get_rpc)):
     return rpc._rpc_reload_config()
 
 
-@router.get('/pair_candles', response_model=PairHistory, tags=['candle data'])
+@router.get("/pair_candles", response_model=PairHistory, tags=["candle data"])
 def pair_candles(
-        pair: str, timeframe: str, limit: Optional[int] = None, rpc: RPC = Depends(get_rpc)):
+    pair: str, timeframe: str, limit: Optional[int] = None, rpc: RPC = Depends(get_rpc)
+):
     return rpc._rpc_analysed_dataframe(pair, timeframe, limit, None)
 
 
-@router.post('/pair_candles', response_model=PairHistory, tags=['candle data'])
+@router.post("/pair_candles", response_model=PairHistory, tags=["candle data"])
 def pair_candles_filtered(payload: PairCandlesRequest, rpc: RPC = Depends(get_rpc)):
     # Advanced pair_candles endpoint with column filtering
     return rpc._rpc_analysed_dataframe(
-        payload.pair, payload.timeframe, payload.limit, payload.columns)
+        payload.pair, payload.timeframe, payload.limit, payload.columns
+    )
 
 
-@router.get('/pair_history', response_model=PairHistory, tags=['candle data'])
-def pair_history(pair: str, timeframe: str, timerange: str, strategy: str,
-                 freqaimodel: Optional[str] = None,
-                 config=Depends(get_config), exchange=Depends(get_exchange)):
+@router.get("/pair_history", response_model=PairHistory, tags=["candle data"])
+def pair_history(
+    pair: str,
+    timeframe: str,
+    timerange: str,
+    strategy: str,
+    freqaimodel: Optional[str] = None,
+    config=Depends(get_config),
+    exchange=Depends(get_exchange),
+):
     # The initial call to this endpoint can be slow, as it may need to initialize
     # the exchange class.
     config = deepcopy(config)
-    config.update({
-        'strategy': strategy,
-        'timerange': timerange,
-        'freqaimodel': freqaimodel if freqaimodel else config.get('freqaimodel'),
-    })
+    config.update(
+        {
+            "strategy": strategy,
+            "timerange": timerange,
+            "freqaimodel": freqaimodel if freqaimodel else config.get("freqaimodel"),
+        }
+    )
     try:
         return RPC._rpc_analysed_history_full(config, pair, timeframe, exchange, None)
     except Exception as e:
         raise HTTPException(status_code=502, detail=str(e))
 
 
-@router.post('/pair_history', response_model=PairHistory, tags=['candle data'])
-def pair_history_filtered(payload: PairHistoryRequest,
-                          config=Depends(get_config), exchange=Depends(get_exchange)):
+@router.post("/pair_history", response_model=PairHistory, tags=["candle data"])
+def pair_history_filtered(
+    payload: PairHistoryRequest, config=Depends(get_config), exchange=Depends(get_exchange)
+):
     # The initial call to this endpoint can be slow, as it may need to initialize
     # the exchange class.
     config = deepcopy(config)
-    config.update({
-        'strategy': payload.strategy,
-        'timerange': payload.timerange,
-        'freqaimodel': payload.freqaimodel if payload.freqaimodel else config.get('freqaimodel'),
-    })
+    config.update(
+        {
+            "strategy": payload.strategy,
+            "timerange": payload.timerange,
+            "freqaimodel": (
+                payload.freqaimodel if payload.freqaimodel else config.get("freqaimodel")
+            ),
+        }
+    )
     try:
         return RPC._rpc_analysed_history_full(
-            config, payload.pair, payload.timeframe, exchange, payload.columns)
+            config, payload.pair, payload.timeframe, exchange, payload.columns
+        )
     except Exception as e:
         raise HTTPException(status_code=502, detail=str(e))
 
 
-@router.get('/plot_config', response_model=PlotConfig, tags=['candle data'])
-def plot_config(strategy: Optional[str] = None, config=Depends(get_config),
-                rpc: Optional[RPC] = Depends(get_rpc_optional)):
+@router.get("/plot_config", response_model=PlotConfig, tags=["candle data"])
+def plot_config(
+    strategy: Optional[str] = None,
+    config=Depends(get_config),
+    rpc: Optional[RPC] = Depends(get_rpc_optional),
+):
     if not strategy:
         if not rpc:
             raise RPCException("Strategy is mandatory in webserver mode.")
         return PlotConfig.model_validate(rpc._rpc_plot_config())
     else:
         config1 = deepcopy(config)
-        config1.update({
-            'strategy': strategy
-        })
+        config1.update({"strategy": strategy})
     try:
         return PlotConfig.model_validate(RPC._rpc_plot_config_with_strategy(config1))
     except Exception as e:
         raise HTTPException(status_code=502, detail=str(e))
 
 
-@router.get('/strategies', response_model=StrategyListResponse, tags=['strategy'])
+@router.get("/strategies", response_model=StrategyListResponse, tags=["strategy"])
 def list_strategies(config=Depends(get_config)):
     from freqtrade.resolvers.strategy_resolver import StrategyResolver
+
     strategies = StrategyResolver.search_all_objects(
-        config, False, config.get('recursive_strategy_search', False))
-    strategies = sorted(strategies, key=lambda x: x['name'])
+        config, False, config.get("recursive_strategy_search", False)
+    )
+    strategies = sorted(strategies, key=lambda x: x["name"])
 
-    return {'strategies': [x['name'] for x in strategies]}
+    return {"strategies": [x["name"] for x in strategies]}
 
 
-@router.get('/strategy/{strategy}', response_model=StrategyResponse, tags=['strategy'])
+@router.get("/strategy/{strategy}", response_model=StrategyResponse, tags=["strategy"])
 def get_strategy(strategy: str, config=Depends(get_config)):
     if ":" in strategy:
         raise HTTPException(status_code=500, detail="base64 encoded strategies are not allowed.")
 
     config_ = deepcopy(config)
     from freqtrade.resolvers.strategy_resolver import StrategyResolver
+
     try:
-        strategy_obj = StrategyResolver._load_strategy(strategy, config_,
-                                                       extra_dir=config_.get('strategy_path'))
+        strategy_obj = StrategyResolver._load_strategy(
+            strategy, config_, extra_dir=config_.get("strategy_path")
+        )
     except OperationalException:
-        raise HTTPException(status_code=404, detail='Strategy not found')
+        raise HTTPException(status_code=404, detail="Strategy not found")
     except Exception as e:
         raise HTTPException(status_code=502, detail=str(e))
     return {
-        'strategy': strategy_obj.get_strategy_name(),
-        'code': strategy_obj.__source__,
-        'timeframe': getattr(strategy_obj, 'timeframe', None),
+        "strategy": strategy_obj.get_strategy_name(),
+        "code": strategy_obj.__source__,
+        "timeframe": getattr(strategy_obj, "timeframe", None),
     }
 
 
-@router.get('/exchanges', response_model=ExchangeListResponse, tags=[])
+@router.get("/exchanges", response_model=ExchangeListResponse, tags=[])
 def list_exchanges(config=Depends(get_config)):
     from freqtrade.exchange import list_available_exchanges
+
     exchanges = list_available_exchanges(config)
     return {
-        'exchanges': exchanges,
+        "exchanges": exchanges,
     }
 
 
-@router.get('/freqaimodels', response_model=FreqAIModelListResponse, tags=['freqai'])
+@router.get("/freqaimodels", response_model=FreqAIModelListResponse, tags=["freqai"])
 def list_freqaimodels(config=Depends(get_config)):
     from freqtrade.resolvers.freqaimodel_resolver import FreqaiModelResolver
-    models = FreqaiModelResolver.search_all_objects(
-        config, False)
-    models = sorted(models, key=lambda x: x['name'])
 
-    return {'freqaimodels': [x['name'] for x in models]}
+    models = FreqaiModelResolver.search_all_objects(config, False)
+    models = sorted(models, key=lambda x: x["name"])
 
+    return {"freqaimodels": [x["name"] for x in models]}
 
-@router.get('/available_pairs', response_model=AvailablePairs, tags=['candle data'])
-def list_available_pairs(timeframe: Optional[str] = None, stake_currency: Optional[str] = None,
-                         candletype: Optional[CandleType] = None, config=Depends(get_config)):
 
-    dh = get_datahandler(config['datadir'], config.get('dataformat_ohlcv'))
-    trading_mode: TradingMode = config.get('trading_mode', TradingMode.SPOT)
-    pair_interval = dh.ohlcv_get_available_data(config['datadir'], trading_mode)
+@router.get("/available_pairs", response_model=AvailablePairs, tags=["candle data"])
+def list_available_pairs(
+    timeframe: Optional[str] = None,
+    stake_currency: Optional[str] = None,
+    candletype: Optional[CandleType] = None,
+    config=Depends(get_config),
+):
+    dh = get_datahandler(config["datadir"], config.get("dataformat_ohlcv"))
+    trading_mode: TradingMode = config.get("trading_mode", TradingMode.SPOT)
+    pair_interval = dh.ohlcv_get_available_data(config["datadir"], trading_mode)
 
     if timeframe:
         pair_interval = [pair for pair in pair_interval if pair[1] == timeframe]
     if stake_currency:
         pair_interval = [pair for pair in pair_interval if pair[0].endswith(stake_currency)]
     if candletype:
         pair_interval = [pair for pair in pair_interval if pair[2] == candletype]
@@ -426,22 +488,22 @@
         pair_interval = [pair for pair in pair_interval if pair[2] == candle_type]
 
     pair_interval = sorted(pair_interval, key=lambda x: x[0])
 
     pairs = list({x[0] for x in pair_interval})
     pairs.sort()
     result = {
-        'length': len(pairs),
-        'pairs': pairs,
-        'pair_interval': pair_interval,
+        "length": len(pairs),
+        "pairs": pairs,
+        "pair_interval": pair_interval,
     }
     return result
 
 
-@router.get('/sysinfo', response_model=SysInfo, tags=['info'])
+@router.get("/sysinfo", response_model=SysInfo, tags=["info"])
 def sysinfo():
     return RPC._rpc_sysinfo()
 
 
-@router.get('/health', response_model=Health, tags=['info'])
+@router.get("/health", response_model=Health, tags=["info"])
 def health(rpc: RPC = Depends(get_rpc)):
     return rpc.health()
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/api_ws.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/api_ws.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,17 +8,21 @@
 
 from freqtrade.enums import RPCMessageType, RPCRequestType
 from freqtrade.exceptions import FreqtradeException
 from freqtrade.rpc.api_server.api_auth import validate_ws_token
 from freqtrade.rpc.api_server.deps import get_message_stream, get_rpc
 from freqtrade.rpc.api_server.ws.channel import WebSocketChannel, create_channel
 from freqtrade.rpc.api_server.ws.message_stream import MessageStream
-from freqtrade.rpc.api_server.ws_schemas import (WSAnalyzedDFMessage, WSErrorMessage,
-                                                 WSMessageSchema, WSRequestSchema,
-                                                 WSWhitelistMessage)
+from freqtrade.rpc.api_server.ws_schemas import (
+    WSAnalyzedDFMessage,
+    WSErrorMessage,
+    WSMessageSchema,
+    WSRequestSchema,
+    WSWhitelistMessage,
+)
 from freqtrade.rpc.rpc import RPC
 
 
 logger = logging.getLogger(__name__)
 
 # Private router, protected by API Key authentication
 router = APIRouter()
@@ -29,41 +33,39 @@
     Iterate over the messages from the channel and process the request
     """
     async for message in channel:
         try:
             await _process_consumer_request(message, channel, rpc)
         except FreqtradeException:
             logger.exception(f"Error processing request from {channel}")
-            response = WSErrorMessage(data='Error processing request')
+            response = WSErrorMessage(data="Error processing request")
 
             await channel.send(response.dict(exclude_none=True))
 
 
 async def channel_broadcaster(channel: WebSocketChannel, message_stream: MessageStream):
     """
     Iterate over messages in the message stream and send them
     """
     async for message, ts in message_stream:
-        if channel.subscribed_to(message.get('type')):
+        if channel.subscribed_to(message.get("type")):
             # Log a warning if this channel is behind
             # on the message stream by a lot
             if (time.time() - ts) > 60:
-                logger.warning(f"Channel {channel} is behind MessageStream by 1 minute,"
-                               " this can cause a memory leak if you see this message"
-                               " often, consider reducing pair list size or amount of"
-                               " consumers.")
+                logger.warning(
+                    f"Channel {channel} is behind MessageStream by 1 minute,"
+                    " this can cause a memory leak if you see this message"
+                    " often, consider reducing pair list size or amount of"
+                    " consumers."
+                )
 
             await channel.send(message, timeout=True)
 
 
-async def _process_consumer_request(
-    request: Dict[str, Any],
-    channel: WebSocketChannel,
-    rpc: RPC
-):
+async def _process_consumer_request(request: Dict[str, Any], channel: WebSocketChannel, rpc: RPC):
     """
     Validate and handle a request from a websocket consumer
     """
     # Validate the request, makes sure it matches the schema
     try:
         websocket_request = WSRequestSchema.model_validate(request)
     except ValidationError as e:
@@ -94,30 +96,29 @@
 
         # Format response
         response = WSWhitelistMessage(data=whitelist)
         await channel.send(response.model_dump(exclude_none=True))
 
     elif type_ == RPCRequestType.ANALYZED_DF:
         # Limit the amount of candles per dataframe to 'limit' or 1500
-        limit = int(min(data.get('limit', 1500), 1500)) if data else None
-        pair = data.get('pair', None) if data else None
+        limit = int(min(data.get("limit", 1500), 1500)) if data else None
+        pair = data.get("pair", None) if data else None
 
         # For every pair in the generator, send a separate message
         for message in rpc._ws_request_analyzed_df(limit, pair):
             # Format response
             response = WSAnalyzedDFMessage(data=message)
             await channel.send(response.model_dump(exclude_none=True))
 
 
 @router.websocket("/message/ws")
 async def message_endpoint(
     websocket: WebSocket,
     token: str = Depends(validate_ws_token),
     rpc: RPC = Depends(get_rpc),
-    message_stream: MessageStream = Depends(get_message_stream)
+    message_stream: MessageStream = Depends(get_message_stream),
 ):
     if token:
         async with create_channel(websocket) as channel:
             await channel.run_channel_tasks(
-                channel_reader(channel, rpc),
-                channel_broadcaster(channel, message_stream)
+                channel_reader(channel, rpc), channel_broadcaster(channel, message_stream)
             )
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/deps.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/deps.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,57 +16,55 @@
 def get_rpc_optional() -> Optional[RPC]:
     if ApiServer._has_rpc:
         return ApiServer._rpc
     return None
 
 
 async def get_rpc() -> Optional[AsyncIterator[RPC]]:
-
     _rpc = get_rpc_optional()
     if _rpc:
         request_id = str(uuid4())
         ctx_token = _request_id_ctx_var.set(request_id)
         Trade.rollback()
         try:
             yield _rpc
         finally:
             Trade.session.remove()
             _request_id_ctx_var.reset(ctx_token)
 
     else:
-        raise RPCException('Bot is not in the correct state')
+        raise RPCException("Bot is not in the correct state")
 
 
 def get_config() -> Dict[str, Any]:
     return ApiServer._config
 
 
 def get_api_config() -> Dict[str, Any]:
-    return ApiServer._config['api_server']
+    return ApiServer._config["api_server"]
 
 
 def _generate_exchange_key(config: Config) -> str:
     """
     Exchange key - used for caching the exchange object.
     """
     return f"{config['exchange']['name']}_{config.get('trading_mode', 'spot')}"
 
 
 def get_exchange(config=Depends(get_config)):
     exchange_key = _generate_exchange_key(config)
     if not (exchange := ApiBG.exchanges.get(exchange_key)):
         from freqtrade.resolvers import ExchangeResolver
-        exchange = ExchangeResolver.load_exchange(
-            config, validate=False, load_leverage_tiers=False)
+
+        exchange = ExchangeResolver.load_exchange(config, validate=False, load_leverage_tiers=False)
         ApiBG.exchanges[exchange_key] = exchange
     return exchange
 
 
 def get_message_stream():
     return ApiServer._message_stream
 
 
 def is_webserver_mode(config=Depends(get_config)):
-    if config['runmode'] != RunMode.WEBSERVER:
-        raise HTTPException(status_code=503,
-                            detail='Bot is not in the correct state.')
+    if config["runmode"] != RunMode.WEBSERVER:
+        raise HTTPException(status_code=503, detail="Bot is not in the correct state.")
     return None
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/ui/fallback_file.html` & `freqtrade-2024.5/freqtrade/rpc/api_server/ui/fallback_file.html`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/ui/favicon.ico` & `freqtrade-2024.5/freqtrade/rpc/api_server/ui/favicon.ico`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/uvicorn_threaded.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/uvicorn_threaded.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,14 +10,15 @@
     # Reverts a change done in uvicorn 0.15.0 - which now sets the eventloop
     # via policy.
     import sys
 
     if sys.version_info >= (3, 8) and sys.platform == "win32":
         import asyncio
         import selectors
+
         selector = selectors.SelectSelector()
         loop = asyncio.SelectorEventLoop(selector)
         asyncio.set_event_loop(loop)
 
 
 class UvicornServer(uvicorn.Server):
     """
@@ -38,28 +39,27 @@
         """
         Parent implementation calls self.config.setup_event_loop(),
             but we need to create uvloop event loop manually
         """
         try:
             import uvloop  # noqa
         except ImportError:  # pragma: no cover
-
             asyncio_setup()
         else:
             asyncio.set_event_loop(uvloop.new_event_loop())
         try:
             loop = asyncio.get_running_loop()
         except RuntimeError:
             # When running in a thread, we'll not have an eventloop yet.
             loop = asyncio.new_event_loop()
         loop.run_until_complete(self.serve(sockets=sockets))
 
     @contextlib.contextmanager
     def run_in_thread(self):
-        self.thread = threading.Thread(target=self.run, name='FTUvicorn')
+        self.thread = threading.Thread(target=self.run, name="FTUvicorn")
         self.thread.start()
         while not self.started:
             time.sleep(1e-3)
 
     def cleanup(self):
         self.should_exit = True
         self.thread.join()
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/web_ui.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/web_ui.py`

 * *Files 12% similar despite different names*

```diff
@@ -5,28 +5,29 @@
 from fastapi.exceptions import HTTPException
 from starlette.responses import FileResponse
 
 
 router_ui = APIRouter()
 
 
-@router_ui.get('/favicon.ico', include_in_schema=False)
+@router_ui.get("/favicon.ico", include_in_schema=False)
 async def favicon():
-    return FileResponse(str(Path(__file__).parent / 'ui/favicon.ico'))
+    return FileResponse(str(Path(__file__).parent / "ui/favicon.ico"))
 
 
-@router_ui.get('/fallback_file.html', include_in_schema=False)
+@router_ui.get("/fallback_file.html", include_in_schema=False)
 async def fallback():
-    return FileResponse(str(Path(__file__).parent / 'ui/fallback_file.html'))
+    return FileResponse(str(Path(__file__).parent / "ui/fallback_file.html"))
 
 
-@router_ui.get('/ui_version', include_in_schema=False)
+@router_ui.get("/ui_version", include_in_schema=False)
 async def ui_version():
     from freqtrade.commands.deploy_commands import read_ui_version
-    uibase = Path(__file__).parent / 'ui/installed/'
+
+    uibase = Path(__file__).parent / "ui/installed/"
     version = read_ui_version(uibase)
 
     return {
         "version": version if version else "not_installed",
     }
 
 
@@ -36,30 +37,30 @@
         path.relative_to(base)
         return True
     except ValueError:
         pass
     return False
 
 
-@router_ui.get('/{rest_of_path:path}', include_in_schema=False)
+@router_ui.get("/{rest_of_path:path}", include_in_schema=False)
 async def index_html(rest_of_path: str):
     """
     Emulate path fallback to index.html.
     """
-    if rest_of_path.startswith('api') or rest_of_path.startswith('.'):
+    if rest_of_path.startswith("api") or rest_of_path.startswith("."):
         raise HTTPException(status_code=404, detail="Not Found")
-    uibase = Path(__file__).parent / 'ui/installed/'
+    uibase = Path(__file__).parent / "ui/installed/"
     filename = uibase / rest_of_path
     # It's security relevant to check "relative_to".
     # Without this, Directory-traversal is possible.
     media_type: Optional[str] = None
-    if filename.suffix == '.js':
+    if filename.suffix == ".js":
         # Force text/javascript for .js files - Circumvent faulty system configuration
-        media_type = 'application/javascript'
+        media_type = "application/javascript"
     if filename.is_file() and is_relative_to(filename, uibase):
         return FileResponse(str(filename), media_type=media_type)
 
-    index_file = uibase / 'index.html'
+    index_file = uibase / "index.html"
     if not index_file.is_file():
-        return FileResponse(str(uibase.parent / 'fallback_file.html'))
+        return FileResponse(str(uibase.parent / "fallback_file.html"))
     # Fall back to index.html, as indicated by vue router docs
     return FileResponse(str(index_file))
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/webserver.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/webserver.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 import logging
-from ipaddress import IPv4Address
+from ipaddress import ip_address
 from typing import Any, Optional
 
 import orjson
 import uvicorn
 from fastapi import Depends, FastAPI
 from fastapi.middleware.cors import CORSMiddleware
 from starlette.responses import JSONResponse
@@ -28,15 +28,14 @@
         Use rapidjson for responses
         Handles NaN and Inf / -Inf in a javascript way by default.
         """
         return orjson.dumps(content, option=orjson.OPT_SERIALIZE_NUMPY)
 
 
 class ApiServer(RPCHandler):
-
     __instance = None
     __initialized = False
 
     _rpc: RPC
     _has_rpc: bool = False
     _config: Config = {}
     # websocket message stuff
@@ -57,37 +56,38 @@
         if self.__initialized and (standalone or self._standalone):
             return
         self._standalone: bool = standalone
         self._server = None
 
         ApiServer.__initialized = True
 
-        api_config = self._config['api_server']
+        api_config = self._config["api_server"]
 
-        self.app = FastAPI(title="Freqtrade API",
-                           docs_url='/docs' if api_config.get('enable_openapi', False) else None,
-                           redoc_url=None,
-                           default_response_class=FTJSONResponse,
-                           )
+        self.app = FastAPI(
+            title="Freqtrade API",
+            docs_url="/docs" if api_config.get("enable_openapi", False) else None,
+            redoc_url=None,
+            default_response_class=FTJSONResponse,
+        )
         self.configure_app(self.app, self._config)
         self.start_api()
 
     def add_rpc_handler(self, rpc: RPC):
         """
         Attach rpc handler
         """
         if not ApiServer._has_rpc:
             ApiServer._rpc = rpc
             ApiServer._has_rpc = True
         else:
             # This should not happen assuming we didn't mess up.
-            raise OperationalException('RPC Handler already attached.')
+            raise OperationalException("RPC Handler already attached.")
 
     def cleanup(self) -> None:
-        """ Cleanup pending module resources """
+        """Cleanup pending module resources"""
         ApiServer._has_rpc = False
         del ApiServer._rpc
         if self._server and not self._standalone:
             logger.info("Stopping API Server")
             # self._server.force_exit, self._server.should_exit = True, True
             self._server.cleanup()
 
@@ -105,63 +105,60 @@
         """
         if ApiServer._message_stream:
             ApiServer._message_stream.publish(msg)
 
     def handle_rpc_exception(self, request, exc):
         logger.error(f"API Error calling: {exc}")
         return JSONResponse(
-            status_code=502,
-            content={'error': f"Error querying {request.url.path}: {exc.message}"}
+            status_code=502, content={"error": f"Error querying {request.url.path}: {exc.message}"}
         )
 
     def configure_app(self, app: FastAPI, config):
         from freqtrade.rpc.api_server.api_auth import http_basic_or_jwt_token, router_login
         from freqtrade.rpc.api_server.api_background_tasks import router as api_bg_tasks
         from freqtrade.rpc.api_server.api_backtest import router as api_backtest
         from freqtrade.rpc.api_server.api_v1 import router as api_v1
         from freqtrade.rpc.api_server.api_v1 import router_public as api_v1_public
         from freqtrade.rpc.api_server.api_ws import router as ws_router
         from freqtrade.rpc.api_server.deps import is_webserver_mode
         from freqtrade.rpc.api_server.web_ui import router_ui
 
         app.include_router(api_v1_public, prefix="/api/v1")
 
-        app.include_router(api_v1, prefix="/api/v1",
-                           dependencies=[Depends(http_basic_or_jwt_token)],
-                           )
-        app.include_router(api_backtest, prefix="/api/v1",
-                           dependencies=[Depends(http_basic_or_jwt_token),
-                                         Depends(is_webserver_mode)],
-                           )
-        app.include_router(api_bg_tasks, prefix="/api/v1",
-                           dependencies=[Depends(http_basic_or_jwt_token),
-                                         Depends(is_webserver_mode)],
-                           )
-        app.include_router(ws_router, prefix="/api/v1")
         app.include_router(router_login, prefix="/api/v1", tags=["auth"])
+        app.include_router(
+            api_v1,
+            prefix="/api/v1",
+            dependencies=[Depends(http_basic_or_jwt_token)],
+        )
+        app.include_router(
+            api_backtest,
+            prefix="/api/v1",
+            dependencies=[Depends(http_basic_or_jwt_token), Depends(is_webserver_mode)],
+        )
+        app.include_router(
+            api_bg_tasks,
+            prefix="/api/v1",
+            dependencies=[Depends(http_basic_or_jwt_token), Depends(is_webserver_mode)],
+        )
+        app.include_router(ws_router, prefix="/api/v1")
         # UI Router MUST be last!
-        app.include_router(router_ui, prefix='')
+        app.include_router(router_ui, prefix="")
 
         app.add_middleware(
             CORSMiddleware,
-            allow_origins=config['api_server'].get('CORS_origins', []),
+            allow_origins=config["api_server"].get("CORS_origins", []),
             allow_credentials=True,
             allow_methods=["*"],
             allow_headers=["*"],
         )
 
         app.add_exception_handler(RPCException, self.handle_rpc_exception)
-        app.add_event_handler(
-            event_type="startup",
-            func=self._api_startup_event
-        )
-        app.add_event_handler(
-            event_type="shutdown",
-            func=self._api_shutdown_event
-        )
+        app.add_event_handler(event_type="startup", func=self._api_startup_event)
+        app.add_event_handler(event_type="shutdown", func=self._api_shutdown_event)
 
     async def _api_startup_event(self):
         """
         Creates the MessageStream class on startup
         so it has access to the same event loop
         as uvicorn
         """
@@ -175,43 +172,51 @@
         if ApiServer._message_stream:
             ApiServer._message_stream = None
 
     def start_api(self):
         """
         Start API ... should be run in thread.
         """
-        rest_ip = self._config['api_server']['listen_ip_address']
-        rest_port = self._config['api_server']['listen_port']
+        rest_ip = self._config["api_server"]["listen_ip_address"]
+        rest_port = self._config["api_server"]["listen_port"]
 
-        logger.info(f'Starting HTTP Server at {rest_ip}:{rest_port}')
-        if not IPv4Address(rest_ip).is_loopback and not running_in_docker():
+        logger.info(f"Starting HTTP Server at {rest_ip}:{rest_port}")
+        if not ip_address(rest_ip).is_loopback and not running_in_docker():
             logger.warning("SECURITY WARNING - Local Rest Server listening to external connections")
-            logger.warning("SECURITY WARNING - This is insecure please set to your loopback,"
-                           "e.g 127.0.0.1 in config.json")
-
-        if not self._config['api_server'].get('password'):
-            logger.warning("SECURITY WARNING - No password for local REST Server defined. "
-                           "Please make sure that this is intentional!")
-
-        if (self._config['api_server'].get('jwt_secret_key', 'super-secret')
-                in ('super-secret, somethingrandom')):
-            logger.warning("SECURITY WARNING - `jwt_secret_key` seems to be default."
-                           "Others may be able to log into your bot.")
-
-        logger.info('Starting Local Rest Server.')
-        verbosity = self._config['api_server'].get('verbosity', 'error')
-
-        uvconfig = uvicorn.Config(self.app,
-                                  port=rest_port,
-                                  host=rest_ip,
-                                  use_colors=False,
-                                  log_config=None,
-                                  access_log=True if verbosity != 'error' else False,
-                                  ws_ping_interval=None  # We do this explicitly ourselves
-                                  )
+            logger.warning(
+                "SECURITY WARNING - This is insecure please set to your loopback,"
+                "e.g 127.0.0.1 in config.json"
+            )
+
+        if not self._config["api_server"].get("password"):
+            logger.warning(
+                "SECURITY WARNING - No password for local REST Server defined. "
+                "Please make sure that this is intentional!"
+            )
+
+        if self._config["api_server"].get("jwt_secret_key", "super-secret") in (
+            "super-secret, somethingrandom"
+        ):
+            logger.warning(
+                "SECURITY WARNING - `jwt_secret_key` seems to be default."
+                "Others may be able to log into your bot."
+            )
+
+        logger.info("Starting Local Rest Server.")
+        verbosity = self._config["api_server"].get("verbosity", "error")
+
+        uvconfig = uvicorn.Config(
+            self.app,
+            port=rest_port,
+            host=rest_ip,
+            use_colors=False,
+            log_config=None,
+            access_log=True if verbosity != "error" else False,
+            ws_ping_interval=None,  # We do this explicitly ourselves
+        )
         try:
             self._server = UvicornServer(uvconfig)
             if self._standalone:
                 self._server.run()
             else:
                 self._server.run_in_thread()
         except Exception:
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/webserver_bgwork.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/webserver_bgwork.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,31 +1,30 @@
-
 from typing import Any, Dict, Literal, Optional, TypedDict
 from uuid import uuid4
 
 from freqtrade.exchange.exchange import Exchange
 
 
 class JobsContainer(TypedDict):
-    category: Literal['pairlist']
+    category: Literal["pairlist"]
     is_running: bool
     status: str
     progress: Optional[float]
     result: Any
     error: Optional[str]
 
 
 class ApiBG:
     # Backtesting type: Backtesting
     bt: Dict[str, Any] = {
-        'bt': None,
-        'data': None,
-        'timerange': None,
-        'last_config': {},
-        'bt_error': None,
+        "bt": None,
+        "data": None,
+        "timerange": None,
+        "last_config": {},
+        "bt_error": None,
     }
     bgtask_running: bool = False
     # Exchange - only available in webserver mode.
     exchanges: Dict[str, Exchange] = {}
 
     # Generic background jobs
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/ws/channel.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/ws/channel.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,33 +6,36 @@
 from typing import Any, AsyncIterator, Deque, Dict, List, Optional, Type, Union
 from uuid import uuid4
 
 from fastapi import WebSocketDisconnect
 from websockets.exceptions import ConnectionClosed
 
 from freqtrade.rpc.api_server.ws.proxy import WebSocketProxy
-from freqtrade.rpc.api_server.ws.serializer import (HybridJSONWebSocketSerializer,
-                                                    WebSocketSerializer)
+from freqtrade.rpc.api_server.ws.serializer import (
+    HybridJSONWebSocketSerializer,
+    WebSocketSerializer,
+)
 from freqtrade.rpc.api_server.ws.types import WebSocketType
 from freqtrade.rpc.api_server.ws_schemas import WSMessageSchemaType
 
 
 logger = logging.getLogger(__name__)
 
 
 class WebSocketChannel:
     """
     Object to help facilitate managing a websocket connection
     """
+
     def __init__(
         self,
         websocket: WebSocketType,
         channel_id: Optional[str] = None,
         serializer_cls: Type[WebSocketSerializer] = HybridJSONWebSocketSerializer,
-        send_throttle: float = 0.01
+        send_throttle: float = 0.01,
     ):
         self.channel_id = channel_id if channel_id else uuid4().hex[:8]
         self._websocket = WebSocketProxy(websocket)
 
         # Internal event to signify a closed websocket
         self._closed = asyncio.Event()
         # The async tasks created for the channel
@@ -73,17 +76,15 @@
         # Only update if we have enough data
         if len(self._send_times) == self._send_times.maxlen:
             # At least 1s or twice the average of send times, with a
             # maximum of 3 seconds per message
             self._send_high_limit = min(max(self.avg_send_time * 2, 1), 3)
 
     async def send(
-        self,
-        message: Union[WSMessageSchemaType, Dict[str, Any]],
-        timeout: bool = False
+        self, message: Union[WSMessageSchemaType, Dict[str, Any]], timeout: bool = False
     ):
         """
         Send a message on the wrapped websocket. If the sending
         takes too long, it will raise a TimeoutError and
         disconnect the connection.
 
         :param message: The message to send
@@ -91,16 +92,15 @@
         """
         try:
             _ = time.time()
             # If the send times out, it will raise
             # a TimeoutError and bubble up to the
             # message_endpoint to close the connection
             await asyncio.wait_for(
-                self._wrapped_ws.send(message),
-                timeout=self._send_high_limit if timeout else None
+                self._wrapped_ws.send(message), timeout=self._send_high_limit if timeout else None
             )
             total_time = time.time() - _
             self._send_times.append(total_time)
 
             self._calc_send_limit()
         except asyncio.TimeoutError:
             logger.info(f"Connection for {self} timed out, disconnecting")
@@ -201,15 +201,15 @@
             try:
                 await task
             except (
                 asyncio.CancelledError,
                 asyncio.TimeoutError,
                 WebSocketDisconnect,
                 ConnectionClosed,
-                RuntimeError
+                RuntimeError,
             ):
                 pass
             except Exception as e:
                 logger.info(f"Encountered unknown exception: {e}", exc_info=e)
 
         self._channel_tasks = []
 
@@ -221,18 +221,15 @@
         # the first to catch any disconnects and bubble it up
         # so the connection is garbage collected right away
         while not self.is_closed():
             yield await self.recv()
 
 
 @asynccontextmanager
-async def create_channel(
-    websocket: WebSocketType,
-    **kwargs
-) -> AsyncIterator[WebSocketChannel]:
+async def create_channel(websocket: WebSocketType, **kwargs) -> AsyncIterator[WebSocketChannel]:
     """
     Context manager for safely opening and closing a WebSocketChannel
     """
     channel = WebSocketChannel(websocket, **kwargs)
     try:
         await channel.accept()
         logger.info(f"Connected to channel - {channel}")
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/ws/message_stream.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/ws/message_stream.py`

 * *Files 26% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 
 
 class MessageStream:
     """
     A message stream for consumers to subscribe to,
     and for producers to publish to.
     """
+
     def __init__(self):
         self._loop = asyncio.get_running_loop()
         self._waiter = self._loop.create_future()
 
     def publish(self, message):
         """
         Publish a message to this MessageStream
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/ws/proxy.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/ws/proxy.py`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/ws/serializer.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/ws/serializer.py`

 * *Files 15% similar despite different names*

```diff
@@ -42,19 +42,16 @@
         # RapidJSON expects strings
         return rapidjson.loads(data, object_hook=_json_object_hook)
 
 
 # Support serializing pandas DataFrames
 def _json_default(z):
     if isinstance(z, DataFrame):
-        return {
-            '__type__': 'dataframe',
-            '__value__': dataframe_to_json(z)
-        }
+        return {"__type__": "dataframe", "__value__": dataframe_to_json(z)}
     raise TypeError
 
 
 # Support deserializing JSON to pandas DataFrames
 def _json_object_hook(z):
-    if z.get('__type__') == 'dataframe':
-        return json_to_dataframe(z.get('__value__'))
+    if z.get("__type__") == "dataframe":
+        return json_to_dataframe(z.get("__value__"))
     return z
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/api_server/ws_schemas.py` & `freqtrade-2024.5/freqtrade/rpc/api_server/ws_schemas.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,15 +22,15 @@
     type: RPCMessageType
     data: Optional[Dict[str, Any]]
 
 
 class WSMessageSchema(BaseArbitraryModel):
     type: RPCMessageType
     data: Optional[Any] = None
-    model_config = ConfigDict(extra='allow')
+    model_config = ConfigDict(extra="allow")
 
 
 # ------------------------------ REQUEST SCHEMAS ----------------------------
 
 
 class WSSubscribeRequest(WSRequestSchema):
     type: RPCRequestType = RPCRequestType.SUBSCRIBE
@@ -45,14 +45,15 @@
 class WSAnalyzedDFRequest(WSRequestSchema):
     type: RPCRequestType = RPCRequestType.ANALYZED_DF
     data: Dict[str, Any] = {"limit": 1500, "pair": None}
 
 
 # ------------------------------ MESSAGE SCHEMAS ----------------------------
 
+
 class WSWhitelistMessage(WSMessageSchema):
     type: RPCMessageType = RPCMessageType.WHITELIST
     data: List[str]
 
 
 class WSAnalyzedDFMessage(WSMessageSchema):
     class AnalyzedDFData(BaseArbitraryModel):
@@ -64,8 +65,9 @@
     data: AnalyzedDFData
 
 
 class WSErrorMessage(WSMessageSchema):
     type: RPCMessageType = RPCMessageType.EXCEPTION
     data: str
 
+
 # --------------------------------------------------------------------------
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/discord.py` & `freqtrade-2024.5/freqtrade/rpc/discord.py`

 * *Files 9% similar despite different names*

```diff
@@ -6,57 +6,56 @@
 from freqtrade.rpc.webhook import Webhook
 
 
 logger = logging.getLogger(__name__)
 
 
 class Discord(Webhook):
-    def __init__(self, rpc: 'RPC', config: Config):
+    def __init__(self, rpc: "RPC", config: Config):
         self._config = config
         self.rpc = rpc
-        self.strategy = config.get('strategy', '')
-        self.timeframe = config.get('timeframe', '')
-        self.bot_name = config.get('bot_name', '')
+        self.strategy = config.get("strategy", "")
+        self.timeframe = config.get("timeframe", "")
+        self.bot_name = config.get("bot_name", "")
 
-        self._url = config['discord']['webhook_url']
-        self._format = 'json'
+        self._url = config["discord"]["webhook_url"]
+        self._format = "json"
         self._retries = 1
         self._retry_delay = 0.1
-        self._timeout = self._config['discord'].get('timeout', 10)
+        self._timeout = self._config["discord"].get("timeout", 10)
 
     def cleanup(self) -> None:
         """
         Cleanup pending module resources.
         This will do nothing for webhooks, they will simply not be called anymore
         """
         pass
 
     def send_msg(self, msg) -> None:
-
-        if (fields := self._config['discord'].get(msg['type'].value)):
+        if fields := self._config["discord"].get(msg["type"].value):
             logger.info(f"Sending discord message: {msg}")
 
-            msg['strategy'] = self.strategy
-            msg['timeframe'] = self.timeframe
-            msg['bot_name'] = self.bot_name
+            msg["strategy"] = self.strategy
+            msg["timeframe"] = self.timeframe
+            msg["bot_name"] = self.bot_name
             color = 0x0000FF
-            if msg['type'] in (RPCMessageType.EXIT, RPCMessageType.EXIT_FILL):
-                profit_ratio = msg.get('profit_ratio')
-                color = (0x00FF00 if profit_ratio > 0 else 0xFF0000)
-            title = msg['type'].value
-            if 'pair' in msg:
+            if msg["type"] in (RPCMessageType.EXIT, RPCMessageType.EXIT_FILL):
+                profit_ratio = msg.get("profit_ratio")
+                color = 0x00FF00 if profit_ratio > 0 else 0xFF0000
+            title = msg["type"].value
+            if "pair" in msg:
                 title = f"Trade: {msg['pair']} {msg['type'].value}"
-            embeds = [{
-                'title': title,
-                'color': color,
-                'fields': [],
-
-            }]
+            embeds = [
+                {
+                    "title": title,
+                    "color": color,
+                    "fields": [],
+                }
+            ]
             for f in fields:
                 for k, v in f.items():
                     v = v.format(**msg)
-                    embeds[0]['fields'].append(
-                        {'name': k, 'value': v, 'inline': True})
+                    embeds[0]["fields"].append({"name": k, "value": v, "inline": True})
 
             # Send the message to discord channel
-            payload = {'embeds': embeds}
+            payload = {"embeds": embeds}
             self._send_msg(payload)
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/external_message_consumer.py` & `freqtrade-2024.5/freqtrade/rpc/external_message_consumer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """
 ExternalMessageConsumer module
 
 Main purpose is to connect to external bot's message websocket to consume data
 from it
 """
+
 import asyncio
 import logging
 import socket
 from threading import Thread
 from typing import TYPE_CHECKING, Any, Callable, Dict, List, TypedDict, Union
 
 import websockets
@@ -15,18 +16,23 @@
 
 from freqtrade.constants import FULL_DATAFRAME_THRESHOLD
 from freqtrade.data.dataprovider import DataProvider
 from freqtrade.enums import RPCMessageType
 from freqtrade.misc import remove_entry_exit_signals
 from freqtrade.rpc.api_server.ws.channel import WebSocketChannel, create_channel
 from freqtrade.rpc.api_server.ws.message_stream import MessageStream
-from freqtrade.rpc.api_server.ws_schemas import (WSAnalyzedDFMessage, WSAnalyzedDFRequest,
-                                                 WSMessageSchema, WSRequestSchema,
-                                                 WSSubscribeRequest, WSWhitelistMessage,
-                                                 WSWhitelistRequest)
+from freqtrade.rpc.api_server.ws_schemas import (
+    WSAnalyzedDFMessage,
+    WSAnalyzedDFRequest,
+    WSMessageSchema,
+    WSRequestSchema,
+    WSSubscribeRequest,
+    WSWhitelistMessage,
+    WSWhitelistRequest,
+)
 
 
 if TYPE_CHECKING:
     import websockets.connect
 
 
 class Producer(TypedDict):
@@ -46,54 +52,50 @@
 
 class ExternalMessageConsumer:
     """
     The main controller class for consuming external messages from
     other freqtrade bot's
     """
 
-    def __init__(
-        self,
-        config: Dict[str, Any],
-        dataprovider: DataProvider
-    ):
+    def __init__(self, config: Dict[str, Any], dataprovider: DataProvider):
         self._config = config
         self._dp = dataprovider
 
         self._running = False
         self._thread = None
         self._loop = None
         self._main_task = None
         self._sub_tasks = None
 
-        self._emc_config = self._config.get('external_message_consumer', {})
+        self._emc_config = self._config.get("external_message_consumer", {})
 
-        self.enabled = self._emc_config.get('enabled', False)
-        self.producers: List[Producer] = self._emc_config.get('producers', [])
+        self.enabled = self._emc_config.get("enabled", False)
+        self.producers: List[Producer] = self._emc_config.get("producers", [])
 
-        self.wait_timeout = self._emc_config.get('wait_timeout', 30)  # in seconds
-        self.ping_timeout = self._emc_config.get('ping_timeout', 10)  # in seconds
-        self.sleep_time = self._emc_config.get('sleep_time', 10)  # in seconds
+        self.wait_timeout = self._emc_config.get("wait_timeout", 30)  # in seconds
+        self.ping_timeout = self._emc_config.get("ping_timeout", 10)  # in seconds
+        self.sleep_time = self._emc_config.get("sleep_time", 10)  # in seconds
 
         # The amount of candles per dataframe on the initial request
-        self.initial_candle_limit = self._emc_config.get('initial_candle_limit', 1500)
+        self.initial_candle_limit = self._emc_config.get("initial_candle_limit", 1500)
 
         # Message size limit, in megabytes. Default 8mb, Use bitwise operator << 20 to convert
         # as the websockets client expects bytes.
-        self.message_size_limit = (self._emc_config.get('message_size_limit', 8) << 20)
+        self.message_size_limit = self._emc_config.get("message_size_limit", 8) << 20
 
         # Setting these explicitly as they probably shouldn't be changed by a user
         # Unless we somehow integrate this with the strategy to allow creating
         # callbacks for the messages
         self.topics = [RPCMessageType.WHITELIST, RPCMessageType.ANALYZED_DF]
 
         # Allow setting data for each initial request
         self._initial_requests: List[WSRequestSchema] = [
             WSSubscribeRequest(data=self.topics),
             WSWhitelistRequest(),
-            WSAnalyzedDFRequest()
+            WSAnalyzedDFRequest(),
         ]
 
         # Specify which function to use for which RPCMessageType
         self._message_handlers: Dict[str, Callable[[str, WSMessageSchema], None]] = {
             RPCMessageType.WHITELIST: self._consume_whitelist_message,
             RPCMessageType.ANALYZED_DF: self._consume_analyzed_df_message,
         }
@@ -183,58 +185,51 @@
         and handling connection errors.
 
         :param producer: Dictionary containing producer info
         :param lock: An asyncio Lock
         """
         while self._running:
             try:
-                host, port = producer['host'], producer['port']
-                token = producer['ws_token']
-                name = producer['name']
-                scheme = 'wss' if producer.get('secure', False) else 'ws'
+                host, port = producer["host"], producer["port"]
+                token = producer["ws_token"]
+                name = producer["name"]
+                scheme = "wss" if producer.get("secure", False) else "ws"
                 ws_url = f"{scheme}://{host}:{port}/api/v1/message/ws?token={token}"
 
                 # This will raise InvalidURI if the url is bad
                 async with websockets.connect(
-                    ws_url,
-                    max_size=self.message_size_limit,
-                    ping_interval=None
+                    ws_url, max_size=self.message_size_limit, ping_interval=None
                 ) as ws:
-                    async with create_channel(
-                        ws,
-                        channel_id=name,
-                        send_throttle=0.5
-                    ) as channel:
-
+                    async with create_channel(ws, channel_id=name, send_throttle=0.5) as channel:
                         # Create the message stream for this channel
                         self._channel_streams[name] = MessageStream()
 
                         # Run the channel tasks while connected
                         await channel.run_channel_tasks(
                             self._receive_messages(channel, producer, lock),
-                            self._send_requests(channel, self._channel_streams[name])
+                            self._send_requests(channel, self._channel_streams[name]),
                         )
 
             except (websockets.exceptions.InvalidURI, ValueError) as e:
                 logger.error(f"{ws_url} is an invalid WebSocket URL - {e}")
                 break
 
             except (
                 socket.gaierror,
                 ConnectionRefusedError,
                 websockets.exceptions.InvalidStatusCode,
-                websockets.exceptions.InvalidMessage
+                websockets.exceptions.InvalidMessage,
             ) as e:
                 logger.error(f"Connection Refused - {e} retrying in {self.sleep_time}s")
                 await asyncio.sleep(self.sleep_time)
                 continue
 
             except (
                 websockets.exceptions.ConnectionClosedError,
-                websockets.exceptions.ConnectionClosedOK
+                websockets.exceptions.ConnectionClosedOK,
             ):
                 # Just keep trying to connect again indefinitely
                 await asyncio.sleep(self.sleep_time)
                 continue
 
             except Exception as e:
                 # An unforeseen error has occurred, log and continue
@@ -251,60 +246,52 @@
         # Now send any subsequent requests published to
         # this channel's stream
         async for request, _ in channel_stream:
             logger.debug(f"Sending request to channel - {channel} - {request}")
             await channel.send(request)
 
     async def _receive_messages(
-        self,
-        channel: WebSocketChannel,
-        producer: Producer,
-        lock: asyncio.Lock
+        self, channel: WebSocketChannel, producer: Producer, lock: asyncio.Lock
     ):
         """
         Loop to handle receiving messages from a Producer
 
         :param channel: The WebSocketChannel object for the WebSocket
         :param producer: Dictionary containing producer info
         :param lock: An asyncio Lock
         """
         while self._running:
             try:
-                message = await asyncio.wait_for(
-                    channel.recv(),
-                    timeout=self.wait_timeout
-                )
+                message = await asyncio.wait_for(channel.recv(), timeout=self.wait_timeout)
 
                 try:
                     async with lock:
                         # Handle the message
                         self.handle_producer_message(producer, message)
                 except Exception as e:
                     logger.exception(f"Error handling producer message: {e}")
 
             except (asyncio.TimeoutError, websockets.exceptions.ConnectionClosed):
                 # We haven't received data yet. Check the connection and continue.
                 try:
                     # ping
                     pong = await channel.ping()
-                    latency = (await asyncio.wait_for(pong, timeout=self.ping_timeout) * 1000)
+                    latency = await asyncio.wait_for(pong, timeout=self.ping_timeout) * 1000
 
                     logger.info(f"Connection to {channel} still alive, latency: {latency}ms")
                     continue
 
                 except Exception as e:
                     # Just eat the error and continue reconnecting
                     logger.warning(f"Ping error {channel} - {e} - retrying in {self.sleep_time}s")
                     logger.debug(e, exc_info=e)
                     raise
 
     def send_producer_request(
-        self,
-        producer_name: str,
-        request: Union[WSRequestSchema, Dict[str, Any]]
+        self, producer_name: str, request: Union[WSRequestSchema, Dict[str, Any]]
     ):
         """
         Publish a message to the producer's message stream to be
         sent by the channel task.
 
         :param producer_name: The name of the producer to publish the message to
         :param request: The request to send to the producer
@@ -315,15 +302,15 @@
         if channel_stream := self._channel_streams.get(producer_name):
             channel_stream.publish(request)
 
     def handle_producer_message(self, producer: Producer, message: Dict[str, Any]):
         """
         Handles external messages from a Producer
         """
-        producer_name = producer.get('name', 'default')
+        producer_name = producer.get("name", "default")
 
         try:
             producer_message = WSMessageSchema.model_validate(message)
         except ValidationError as e:
             logger.error(f"Invalid message from `{producer_name}`: {e}")
             return
 
@@ -368,44 +355,41 @@
         pair, timeframe, candle_type = key
 
         if df.empty:
             logger.debug(f"Received Empty Dataframe for {key}")
             return
 
         # If set, remove the Entry and Exit signals from the Producer
-        if self._emc_config.get('remove_entry_exit_signals', False):
+        if self._emc_config.get("remove_entry_exit_signals", False):
             df = remove_entry_exit_signals(df)
 
         logger.debug(f"Received {len(df)} candle(s) for {key}")
 
         did_append, n_missing = self._dp._add_external_df(
             pair,
             df,
             last_analyzed=la,
             timeframe=timeframe,
             candle_type=candle_type,
-            producer_name=producer_name
-            )
+            producer_name=producer_name,
+        )
 
         if not did_append:
             # We want an overlap in candles in case some data has changed
             n_missing += 1
             # Set to None for all candles if we missed a full df's worth of candles
             n_missing = n_missing if n_missing < FULL_DATAFRAME_THRESHOLD else 1500
 
-            logger.warning(f"Holes in data or no existing df, requesting {n_missing} candles "
-                           f"for {key} from `{producer_name}`")
+            logger.warning(
+                f"Holes in data or no existing df, requesting {n_missing} candles "
+                f"for {key} from `{producer_name}`"
+            )
 
             self.send_producer_request(
-                producer_name,
-                WSAnalyzedDFRequest(
-                    data={
-                        "limit": n_missing,
-                        "pair": pair
-                    }
-                )
+                producer_name, WSAnalyzedDFRequest(data={"limit": n_missing, "pair": pair})
             )
             return
 
         logger.debug(
             f"Consumed message from `{producer_name}` "
-            f"of type `RPCMessageType.ANALYZED_DF` for {key}")
+            f"of type `RPCMessageType.ANALYZED_DF` for {key}"
+        )
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/fiat_convert.py` & `freqtrade-2024.5/freqtrade/rpc/fiat_convert.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,109 +1,112 @@
 """
 Module that define classes to convert Crypto-currency to FIAT
 e.g BTC to USD
 """
 
 import logging
 from datetime import datetime
-from typing import Dict, List
+from typing import Any, Dict, List
 
 from cachetools import TTLCache
-from pycoingecko import CoinGeckoAPI
 from requests.exceptions import RequestException
 
-from freqtrade.constants import SUPPORTED_FIAT
+from freqtrade.constants import SUPPORTED_FIAT, Config
 from freqtrade.mixins.logging_mixin import LoggingMixin
+from freqtrade.util.coin_gecko import FtCoinGeckoApi
 
 
 logger = logging.getLogger(__name__)
 
 
 # Manually map symbol to ID for some common coins
 # with duplicate coingecko entries
 coingecko_mapping = {
-    'eth': 'ethereum',
-    'bnb': 'binancecoin',
-    'sol': 'solana',
-    'usdt': 'tether',
-    'busd': 'binance-usd',
-    'tusd': 'true-usd',
-    'usdc': 'usd-coin',
-    'btc': 'bitcoin'
+    "eth": "ethereum",
+    "bnb": "binancecoin",
+    "sol": "solana",
+    "usdt": "tether",
+    "busd": "binance-usd",
+    "tusd": "true-usd",
+    "usdc": "usd-coin",
+    "btc": "bitcoin",
 }
 
 
 class CryptoToFiatConverter(LoggingMixin):
     """
     Main class to initiate Crypto to FIAT.
     This object contains a list of pair Crypto, FIAT
     This object is also a Singleton
     """
+
     __instance = None
-    _coingecko: CoinGeckoAPI = None
+
     _coinlistings: List[Dict] = []
     _backoff: float = 0.0
 
-    def __new__(cls):
+    def __new__(cls, *args: Any, **kwargs: Any) -> Any:
         """
-        This class is a singleton - cannot be instantiated twice.
+        Singleton pattern to ensure only one instance is created.
         """
-        if CryptoToFiatConverter.__instance is None:
-            CryptoToFiatConverter.__instance = object.__new__(cls)
-            try:
-                # Limit retires to 1 (0 and 1)
-                # otherwise we risk bot impact if coingecko is down.
-                CryptoToFiatConverter._coingecko = CoinGeckoAPI(retries=1)
-            except BaseException:
-                CryptoToFiatConverter._coingecko = None
-        return CryptoToFiatConverter.__instance
+        if not cls.__instance:
+            cls.__instance = super().__new__(cls)
+        return cls.__instance
 
-    def __init__(self) -> None:
+    def __init__(self, config: Config) -> None:
         # Timeout: 6h
         self._pair_price: TTLCache = TTLCache(maxsize=500, ttl=6 * 60 * 60)
 
+        _coingecko_config = config.get("coingecko", {})
+        self._coingecko = FtCoinGeckoApi(
+            api_key=_coingecko_config.get("api_key", ""),
+            is_demo=_coingecko_config.get("is_demo", True),
+            retries=1,
+        )
         LoggingMixin.__init__(self, logger, 3600)
         self._load_cryptomap()
 
     def _load_cryptomap(self) -> None:
         try:
             # Use list-comprehension to ensure we get a list.
             self._coinlistings = [x for x in self._coingecko.get_coins_list()]
         except RequestException as request_exception:
             if "429" in str(request_exception):
                 logger.warning(
-                    "Too many requests for CoinGecko API, backing off and trying again later.")
+                    "Too many requests for CoinGecko API, backing off and trying again later."
+                )
                 # Set backoff timestamp to 60 seconds in the future
                 self._backoff = datetime.now().timestamp() + 60
                 return
             # If the request is not a 429 error we want to raise the normal error
             logger.error(
                 "Could not load FIAT Cryptocurrency map for the following problem: "
                 f"{request_exception}"
             )
-        except (Exception) as exception:
+        except Exception as exception:
             logger.error(
-                f"Could not load FIAT Cryptocurrency map for the following problem: {exception}")
+                f"Could not load FIAT Cryptocurrency map for the following problem: {exception}"
+            )
 
     def _get_gecko_id(self, crypto_symbol):
         if not self._coinlistings:
             if self._backoff <= datetime.now().timestamp():
                 self._load_cryptomap()
                 # Still not loaded.
                 if not self._coinlistings:
                     return None
             else:
                 return None
-        found = [x for x in self._coinlistings if x['symbol'].lower() == crypto_symbol]
+        found = [x for x in self._coinlistings if x["symbol"].lower() == crypto_symbol]
 
         if crypto_symbol in coingecko_mapping.keys():
-            found = [x for x in self._coinlistings if x['id'] == coingecko_mapping[crypto_symbol]]
+            found = [x for x in self._coinlistings if x["id"] == coingecko_mapping[crypto_symbol]]
 
         if len(found) == 1:
-            return found[0]['id']
+            return found[0]["id"]
 
         if len(found) > 0:
             # Wrong!
             logger.warning(f"Found multiple mappings in CoinGecko for {crypto_symbol}.")
             return None
 
     def convert_amount(self, crypto_amount: float, crypto_symbol: str, fiat_symbol: str) -> float:
@@ -126,34 +129,31 @@
         :param fiat_symbol: FIAT currency you want to convert to (e.g USD)
         :return: Price in FIAT
         """
         crypto_symbol = crypto_symbol.lower()
         fiat_symbol = fiat_symbol.lower()
         inverse = False
 
-        if crypto_symbol == 'usd':
+        if crypto_symbol == "usd":
             # usd corresponds to "uniswap-state-dollar" for coingecko.
             # We'll therefore need to "swap" the currencies
             logger.info(f"reversing Rates {crypto_symbol}, {fiat_symbol}")
             crypto_symbol = fiat_symbol
-            fiat_symbol = 'usd'
+            fiat_symbol = "usd"
             inverse = True
 
         symbol = f"{crypto_symbol}/{fiat_symbol}"
         # Check if the fiat conversion you want is supported
         if not self._is_supported_fiat(fiat=fiat_symbol):
-            raise ValueError(f'The fiat {fiat_symbol} is not supported.')
+            raise ValueError(f"The fiat {fiat_symbol} is not supported.")
 
         price = self._pair_price.get(symbol, None)
 
         if not price:
-            price = self._find_price(
-                crypto_symbol=crypto_symbol,
-                fiat_symbol=fiat_symbol
-            )
+            price = self._find_price(crypto_symbol=crypto_symbol, fiat_symbol=fiat_symbol)
             if inverse and price != 0.0:
                 price = 1 / price
             self._pair_price[symbol] = price
 
         return price
 
     def _is_supported_fiat(self, fiat: str) -> bool:
@@ -170,32 +170,31 @@
         Call CoinGecko API to retrieve the price in the FIAT
         :param crypto_symbol: Crypto-currency you want to convert (e.g btc)
         :param fiat_symbol: FIAT currency you want to convert to (e.g usd)
         :return: float, price of the crypto-currency in Fiat
         """
         # Check if the fiat conversion you want is supported
         if not self._is_supported_fiat(fiat=fiat_symbol):
-            raise ValueError(f'The fiat {fiat_symbol} is not supported.')
+            raise ValueError(f"The fiat {fiat_symbol} is not supported.")
 
         # No need to convert if both crypto and fiat are the same
         if crypto_symbol == fiat_symbol:
             return 1.0
 
         _gecko_id = self._get_gecko_id(crypto_symbol)
 
         if not _gecko_id:
             # return 0 for unsupported stake currencies (fiat-convert should not break the bot)
             self.log_once(
-                f"unsupported crypto-symbol {crypto_symbol.upper()} - returning 0.0",
-                logger.warning)
+                f"unsupported crypto-symbol {crypto_symbol.upper()} - returning 0.0", logger.warning
+            )
             return 0.0
 
         try:
             return float(
-                self._coingecko.get_price(
-                    ids=_gecko_id,
-                    vs_currencies=fiat_symbol
-                )[_gecko_id][fiat_symbol]
+                self._coingecko.get_price(ids=_gecko_id, vs_currencies=fiat_symbol)[_gecko_id][
+                    fiat_symbol
+                ]
             )
         except Exception as exception:
             logger.error("Error in _find_price: %s", exception)
             return 0.0
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/rpc.py` & `freqtrade-2024.5/freqtrade/rpc/rpc.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 This module contains class to define a RPC communications
 """
+
 import logging
 from abc import abstractmethod
 from datetime import date, datetime, timedelta, timezone
 from math import isnan
 from typing import Any, Dict, Generator, List, Optional, Sequence, Tuple, Union
 
 import psutil
@@ -14,17 +15,24 @@
 from pandas import DataFrame, NaT
 from sqlalchemy import func, select
 
 from freqtrade import __version__
 from freqtrade.configuration.timerange import TimeRange
 from freqtrade.constants import CANCEL_REASON, DEFAULT_DATAFRAME_COLUMNS, Config
 from freqtrade.data.history import load_data
-from freqtrade.data.metrics import calculate_expectancy, calculate_max_drawdown
-from freqtrade.enums import (CandleType, ExitCheckTuple, ExitType, MarketDirection, SignalDirection,
-                             State, TradingMode)
+from freqtrade.data.metrics import DrawDownResult, calculate_expectancy, calculate_max_drawdown
+from freqtrade.enums import (
+    CandleType,
+    ExitCheckTuple,
+    ExitType,
+    MarketDirection,
+    SignalDirection,
+    State,
+    TradingMode,
+)
 from freqtrade.exceptions import ExchangeError, PricingError
 from freqtrade.exchange import timeframe_to_minutes, timeframe_to_msecs
 from freqtrade.exchange.types import Tickers
 from freqtrade.loggers import bufferHandler
 from freqtrade.persistence import KeyStoreKeys, KeyValueStore, PairLocks, Trade
 from freqtrade.persistence.models import PairLock
 from freqtrade.plugins.pairlist.pairlist_helpers import expand_pairlist
@@ -50,112 +58,116 @@
         super().__init__(self)
         self.message = message
 
     def __str__(self):
         return self.message
 
     def __json__(self):
-        return {
-            'msg': self.message
-        }
+        return {"msg": self.message}
 
 
 class RPCHandler:
-
-    def __init__(self, rpc: 'RPC', config: Config) -> None:
+    def __init__(self, rpc: "RPC", config: Config) -> None:
         """
         Initializes RPCHandlers
         :param rpc: instance of RPC Helper class
         :param config: Configuration object
         :return: None
         """
         self._rpc = rpc
         self._config: Config = config
 
     @property
     def name(self) -> str:
-        """ Returns the lowercase name of the implementation """
+        """Returns the lowercase name of the implementation"""
         return self.__class__.__name__.lower()
 
     @abstractmethod
     def cleanup(self) -> None:
-        """ Cleanup pending module resources """
+        """Cleanup pending module resources"""
 
     @abstractmethod
     def send_msg(self, msg: RPCSendMsg) -> None:
-        """ Sends a message to all registered rpc modules """
+        """Sends a message to all registered rpc modules"""
 
 
 class RPC:
     """
     RPC class can be used to have extra feature, like bot data, and access to DB data
     """
+
     # Bind _fiat_converter if needed
     _fiat_converter: Optional[CryptoToFiatConverter] = None
 
     def __init__(self, freqtrade) -> None:
         """
         Initializes all enabled rpc modules
         :param freqtrade: Instance of a freqtrade bot
         :return: None
         """
         self._freqtrade = freqtrade
         self._config: Config = freqtrade.config
-        if self._config.get('fiat_display_currency'):
-            self._fiat_converter = CryptoToFiatConverter()
+        if self._config.get("fiat_display_currency"):
+            self._fiat_converter = CryptoToFiatConverter(self._config)
 
     @staticmethod
-    def _rpc_show_config(config, botstate: Union[State, str],
-                         strategy_version: Optional[str] = None) -> Dict[str, Any]:
+    def _rpc_show_config(
+        config, botstate: Union[State, str], strategy_version: Optional[str] = None
+    ) -> Dict[str, Any]:
         """
         Return a dict of config options.
         Explicitly does NOT return the full config to avoid leakage of sensitive
         information via rpc.
         """
         val = {
-            'version': __version__,
-            'strategy_version': strategy_version,
-            'dry_run': config['dry_run'],
-            'trading_mode': config.get('trading_mode', 'spot'),
-            'short_allowed': config.get('trading_mode', 'spot') != 'spot',
-            'stake_currency': config['stake_currency'],
-            'stake_currency_decimals': decimals_per_coin(config['stake_currency']),
-            'stake_amount': str(config['stake_amount']),
-            'available_capital': config.get('available_capital'),
-            'max_open_trades': (config.get('max_open_trades', 0)
-                                if config.get('max_open_trades', 0) != float('inf') else -1),
-            'minimal_roi': config['minimal_roi'].copy() if 'minimal_roi' in config else {},
-            'stoploss': config.get('stoploss'),
-            'stoploss_on_exchange': config.get('order_types',
-                                               {}).get('stoploss_on_exchange', False),
-            'trailing_stop': config.get('trailing_stop'),
-            'trailing_stop_positive': config.get('trailing_stop_positive'),
-            'trailing_stop_positive_offset': config.get('trailing_stop_positive_offset'),
-            'trailing_only_offset_is_reached': config.get('trailing_only_offset_is_reached'),
-            'unfilledtimeout': config.get('unfilledtimeout'),
-            'use_custom_stoploss': config.get('use_custom_stoploss'),
-            'order_types': config.get('order_types'),
-            'bot_name': config.get('bot_name', 'freqtrade'),
-            'timeframe': config.get('timeframe'),
-            'timeframe_ms': timeframe_to_msecs(config['timeframe']
-                                               ) if 'timeframe' in config else 0,
-            'timeframe_min': timeframe_to_minutes(config['timeframe']
-                                                  ) if 'timeframe' in config else 0,
-            'exchange': config['exchange']['name'],
-            'strategy': config['strategy'],
-            'force_entry_enable': config.get('force_entry_enable', False),
-            'exit_pricing': config.get('exit_pricing', {}),
-            'entry_pricing': config.get('entry_pricing', {}),
-            'state': str(botstate),
-            'runmode': config['runmode'].value,
-            'position_adjustment_enable': config.get('position_adjustment_enable', False),
-            'max_entry_position_adjustment': (
-                config.get('max_entry_position_adjustment', -1)
-                if config.get('max_entry_position_adjustment') != float('inf')
-                else -1)
+            "version": __version__,
+            "strategy_version": strategy_version,
+            "dry_run": config["dry_run"],
+            "trading_mode": config.get("trading_mode", "spot"),
+            "short_allowed": config.get("trading_mode", "spot") != "spot",
+            "stake_currency": config["stake_currency"],
+            "stake_currency_decimals": decimals_per_coin(config["stake_currency"]),
+            "stake_amount": str(config["stake_amount"]),
+            "available_capital": config.get("available_capital"),
+            "max_open_trades": (
+                config.get("max_open_trades", 0)
+                if config.get("max_open_trades", 0) != float("inf")
+                else -1
+            ),
+            "minimal_roi": config["minimal_roi"].copy() if "minimal_roi" in config else {},
+            "stoploss": config.get("stoploss"),
+            "stoploss_on_exchange": config.get("order_types", {}).get(
+                "stoploss_on_exchange", False
+            ),
+            "trailing_stop": config.get("trailing_stop"),
+            "trailing_stop_positive": config.get("trailing_stop_positive"),
+            "trailing_stop_positive_offset": config.get("trailing_stop_positive_offset"),
+            "trailing_only_offset_is_reached": config.get("trailing_only_offset_is_reached"),
+            "unfilledtimeout": config.get("unfilledtimeout"),
+            "use_custom_stoploss": config.get("use_custom_stoploss"),
+            "order_types": config.get("order_types"),
+            "bot_name": config.get("bot_name", "freqtrade"),
+            "timeframe": config.get("timeframe"),
+            "timeframe_ms": timeframe_to_msecs(config["timeframe"]) if "timeframe" in config else 0,
+            "timeframe_min": (
+                timeframe_to_minutes(config["timeframe"]) if "timeframe" in config else 0
+            ),
+            "exchange": config["exchange"]["name"],
+            "strategy": config["strategy"],
+            "force_entry_enable": config.get("force_entry_enable", False),
+            "exit_pricing": config.get("exit_pricing", {}),
+            "entry_pricing": config.get("entry_pricing", {}),
+            "state": str(botstate),
+            "runmode": config["runmode"].value,
+            "position_adjustment_enable": config.get("position_adjustment_enable", False),
+            "max_entry_position_adjustment": (
+                config.get("max_entry_position_adjustment", -1)
+                if config.get("max_entry_position_adjustment") != float("inf")
+                else -1
+            ),
         }
         return val
 
     def _rpc_trade_status(self, trade_ids: Optional[List[int]] = None) -> List[Dict[str, Any]]:
         """
         Below follows the RPC backend it is prefixed with rpc_ to raise awareness that it is
         a remotely exposed function
@@ -163,41 +175,41 @@
         # Fetch open trades
         if trade_ids:
             trades: Sequence[Trade] = Trade.get_trades(trade_filter=Trade.id.in_(trade_ids)).all()
         else:
             trades = Trade.get_open_trades()
 
         if not trades:
-            raise RPCException('no active trade')
+            raise RPCException("no active trade")
         else:
             results = []
             for trade in trades:
                 current_profit_fiat: Optional[float] = None
                 total_profit_fiat: Optional[float] = None
 
                 # prepare open orders details
                 oo_details: Optional[str] = ""
                 oo_details_lst = [
-                    f'({oo.order_type} {oo.side} rem={oo.safe_remaining:.8f})'
+                    f"({oo.order_type} {oo.side} rem={oo.safe_remaining:.8f})"
                     for oo in trade.open_orders
-                    if oo.ft_order_side not in ['stoploss']
+                    if oo.ft_order_side not in ["stoploss"]
                 ]
-                oo_details = ', '.join(oo_details_lst)
+                oo_details = ", ".join(oo_details_lst)
 
                 total_profit_abs = 0.0
                 total_profit_ratio: Optional[float] = None
                 # calculate profit and send message to user
                 if trade.is_open:
                     try:
                         current_rate = self._freqtrade.exchange.get_rate(
-                            trade.pair, side='exit', is_short=trade.is_short, refresh=False)
+                            trade.pair, side="exit", is_short=trade.is_short, refresh=False
+                        )
                     except (ExchangeError, PricingError):
                         current_rate = NAN
                     if len(trade.select_filled_orders(trade.entry_side)) > 0:
-
                         current_profit = current_profit_abs = current_profit_fiat = NAN
                         if not isnan(current_rate):
                             prof = trade.calculate_profit(current_rate)
                             current_profit = prof.profit_ratio
                             current_profit_abs = prof.profit_abs
                             total_profit_abs = prof.total_profit
                             total_profit_ratio = prof.total_profit_ratio
@@ -210,269 +222,283 @@
                     current_profit = trade.close_profit or 0.0
                     current_profit_abs = trade.close_profit_abs or 0.0
 
                 # Calculate fiat profit
                 if not isnan(current_profit_abs) and self._fiat_converter:
                     current_profit_fiat = self._fiat_converter.convert_amount(
                         current_profit_abs,
-                        self._freqtrade.config['stake_currency'],
-                        self._freqtrade.config['fiat_display_currency']
+                        self._freqtrade.config["stake_currency"],
+                        self._freqtrade.config["fiat_display_currency"],
                     )
                     total_profit_fiat = self._fiat_converter.convert_amount(
                         total_profit_abs,
-                        self._freqtrade.config['stake_currency'],
-                        self._freqtrade.config['fiat_display_currency']
+                        self._freqtrade.config["stake_currency"],
+                        self._freqtrade.config["fiat_display_currency"],
                     )
 
                 # Calculate guaranteed profit (in case of trailing stop)
                 stop_entry = trade.calculate_profit(trade.stop_loss)
 
                 stoploss_entry_dist = stop_entry.profit_abs
                 stoploss_entry_dist_ratio = stop_entry.profit_ratio
 
                 # calculate distance to stoploss
                 stoploss_current_dist = trade.stop_loss - current_rate
                 stoploss_current_dist_ratio = stoploss_current_dist / current_rate
 
                 trade_dict = trade.to_json()
-                trade_dict.update(dict(
-                    close_profit=trade.close_profit if not trade.is_open else None,
-                    current_rate=current_rate,
-                    profit_ratio=current_profit,
-                    profit_pct=round(current_profit * 100, 2),
-                    profit_abs=current_profit_abs,
-                    profit_fiat=current_profit_fiat,
-                    total_profit_abs=total_profit_abs,
-                    total_profit_fiat=total_profit_fiat,
-                    total_profit_ratio=total_profit_ratio,
-                    stoploss_current_dist=stoploss_current_dist,
-                    stoploss_current_dist_ratio=round(stoploss_current_dist_ratio, 8),
-                    stoploss_current_dist_pct=round(stoploss_current_dist_ratio * 100, 2),
-                    stoploss_entry_dist=stoploss_entry_dist,
-                    stoploss_entry_dist_ratio=round(stoploss_entry_dist_ratio, 8),
-                    open_orders=oo_details
-                ))
+                trade_dict.update(
+                    dict(
+                        close_profit=trade.close_profit if not trade.is_open else None,
+                        current_rate=current_rate,
+                        profit_ratio=current_profit,
+                        profit_pct=round(current_profit * 100, 2),
+                        profit_abs=current_profit_abs,
+                        profit_fiat=current_profit_fiat,
+                        total_profit_abs=total_profit_abs,
+                        total_profit_fiat=total_profit_fiat,
+                        total_profit_ratio=total_profit_ratio,
+                        stoploss_current_dist=stoploss_current_dist,
+                        stoploss_current_dist_ratio=round(stoploss_current_dist_ratio, 8),
+                        stoploss_current_dist_pct=round(stoploss_current_dist_ratio * 100, 2),
+                        stoploss_entry_dist=stoploss_entry_dist,
+                        stoploss_entry_dist_ratio=round(stoploss_entry_dist_ratio, 8),
+                        open_orders=oo_details,
+                    )
+                )
                 results.append(trade_dict)
             return results
 
-    def _rpc_status_table(self, stake_currency: str,
-                          fiat_display_currency: str) -> Tuple[List, List, float]:
+    def _rpc_status_table(
+        self, stake_currency: str, fiat_display_currency: str
+    ) -> Tuple[List, List, float]:
         trades: List[Trade] = Trade.get_open_trades()
-        nonspot = self._config.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT
+        nonspot = self._config.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT
         if not trades:
-            raise RPCException('no active trade')
+            raise RPCException("no active trade")
         else:
             trades_list = []
             fiat_profit_sum = NAN
             for trade in trades:
                 # calculate profit and send message to user
                 try:
                     current_rate = self._freqtrade.exchange.get_rate(
-                        trade.pair, side='exit', is_short=trade.is_short, refresh=False)
+                        trade.pair, side="exit", is_short=trade.is_short, refresh=False
+                    )
                 except (PricingError, ExchangeError):
                     current_rate = NAN
                     trade_profit = NAN
-                    profit_str = f'{NAN:.2%}'
+                    profit_str = f"{NAN:.2%}"
                 else:
                     if trade.nr_of_successful_entries > 0:
                         profit = trade.calculate_profit(current_rate)
                         trade_profit = profit.profit_abs
-                        profit_str = f'{profit.profit_ratio:.2%}'
+                        profit_str = f"{profit.profit_ratio:.2%}"
                     else:
                         trade_profit = 0.0
-                        profit_str = f'{0.0:.2f}'
-                direction_str = ('S' if trade.is_short else 'L') if nonspot else ''
+                        profit_str = f"{0.0:.2f}"
+                direction_str = ("S" if trade.is_short else "L") if nonspot else ""
                 if self._fiat_converter:
                     fiat_profit = self._fiat_converter.convert_amount(
-                        trade_profit,
-                        stake_currency,
-                        fiat_display_currency
+                        trade_profit, stake_currency, fiat_display_currency
                     )
                     if not isnan(fiat_profit):
                         profit_str += f" ({fiat_profit:.2f})"
-                        fiat_profit_sum = fiat_profit if isnan(fiat_profit_sum) \
-                            else fiat_profit_sum + fiat_profit
+                        fiat_profit_sum = (
+                            fiat_profit if isnan(fiat_profit_sum) else fiat_profit_sum + fiat_profit
+                        )
                 else:
                     profit_str += f" ({trade_profit:.2f})"
-                    fiat_profit_sum = trade_profit if isnan(fiat_profit_sum) \
-                        else fiat_profit_sum + trade_profit
+                    fiat_profit_sum = (
+                        trade_profit if isnan(fiat_profit_sum) else fiat_profit_sum + trade_profit
+                    )
 
                 active_attempt_side_symbols = [
-                    '*' if (oo and oo.ft_order_side == trade.entry_side) else '**'
+                    "*" if (oo and oo.ft_order_side == trade.entry_side) else "**"
                     for oo in trade.open_orders
                 ]
 
                 # example: '*.**.**' trying to enter, exit and exit with 3 different orders
-                active_attempt_side_symbols_str = '.'.join(active_attempt_side_symbols)
+                active_attempt_side_symbols_str = ".".join(active_attempt_side_symbols)
 
                 detail_trade = [
-                    f'{trade.id} {direction_str}',
+                    f"{trade.id} {direction_str}",
                     trade.pair + active_attempt_side_symbols_str,
                     shorten_date(dt_humanize_delta(trade.open_date_utc)),
-                    profit_str
+                    profit_str,
                 ]
 
-                if self._config.get('position_adjustment_enable', False):
-                    max_entry_str = ''
-                    if self._config.get('max_entry_position_adjustment', -1) > 0:
+                if self._config.get("position_adjustment_enable", False):
+                    max_entry_str = ""
+                    if self._config.get("max_entry_position_adjustment", -1) > 0:
                         max_entry_str = f"/{self._config['max_entry_position_adjustment'] + 1}"
                     filled_entries = trade.nr_of_successful_entries
                     detail_trade.append(f"{filled_entries}{max_entry_str}")
                 trades_list.append(detail_trade)
             profitcol = "Profit"
             if self._fiat_converter:
                 profitcol += " (" + fiat_display_currency + ")"
             else:
                 profitcol += " (" + stake_currency + ")"
 
-            columns = [
-                'ID L/S' if nonspot else 'ID',
-                'Pair',
-                'Since',
-                profitcol]
-            if self._config.get('position_adjustment_enable', False):
-                columns.append('# Entries')
+            columns = ["ID L/S" if nonspot else "ID", "Pair", "Since", profitcol]
+            if self._config.get("position_adjustment_enable", False):
+                columns.append("# Entries")
             return trades_list, columns, fiat_profit_sum
 
     def _rpc_timeunit_profit(
-            self, timescale: int,
-            stake_currency: str, fiat_display_currency: str,
-            timeunit: str = 'days') -> Dict[str, Any]:
+        self,
+        timescale: int,
+        stake_currency: str,
+        fiat_display_currency: str,
+        timeunit: str = "days",
+    ) -> Dict[str, Any]:
         """
         :param timeunit: Valid entries are 'days', 'weeks', 'months'
         """
         start_date = datetime.now(timezone.utc).date()
-        if timeunit == 'weeks':
+        if timeunit == "weeks":
             # weekly
             start_date = start_date - timedelta(days=start_date.weekday())  # Monday
-        if timeunit == 'months':
+        if timeunit == "months":
             start_date = start_date.replace(day=1)
 
         def time_offset(step: int):
-            if timeunit == 'months':
+            if timeunit == "months":
                 return relativedelta(months=step)
             return timedelta(**{timeunit: step})
 
         if not (isinstance(timescale, int) and timescale > 0):
-            raise RPCException('timescale must be an integer greater than 0')
+            raise RPCException("timescale must be an integer greater than 0")
 
         profit_units: Dict[date, Dict] = {}
         daily_stake = self._freqtrade.wallets.get_total_stake_amount()
 
         for day in range(0, timescale):
             profitday = start_date - time_offset(day)
             # Only query for necessary columns for performance reasons.
             trades = Trade.session.execute(
                 select(Trade.close_profit_abs)
-                .filter(Trade.is_open.is_(False),
-                        Trade.close_date >= profitday,
-                        Trade.close_date < (profitday + time_offset(1)))
+                .filter(
+                    Trade.is_open.is_(False),
+                    Trade.close_date >= profitday,
+                    Trade.close_date < (profitday + time_offset(1)),
+                )
                 .order_by(Trade.close_date)
             ).all()
 
             curdayprofit = sum(
-                trade.close_profit_abs for trade in trades if trade.close_profit_abs is not None)
+                trade.close_profit_abs for trade in trades if trade.close_profit_abs is not None
+            )
             # Calculate this periods starting balance
             daily_stake = daily_stake - curdayprofit
             profit_units[profitday] = {
-                'amount': curdayprofit,
-                'daily_stake': daily_stake,
-                'rel_profit': round(curdayprofit / daily_stake, 8) if daily_stake > 0 else 0,
-                'trades': len(trades),
+                "amount": curdayprofit,
+                "daily_stake": daily_stake,
+                "rel_profit": round(curdayprofit / daily_stake, 8) if daily_stake > 0 else 0,
+                "trades": len(trades),
             }
 
         data = [
             {
-                'date': key,
-                'abs_profit': value["amount"],
-                'starting_balance': value["daily_stake"],
-                'rel_profit': value["rel_profit"],
-                'fiat_value': self._fiat_converter.convert_amount(
-                    value['amount'],
-                    stake_currency,
-                    fiat_display_currency
-                ) if self._fiat_converter else 0,
-                'trade_count': value["trades"],
+                "date": key,
+                "abs_profit": value["amount"],
+                "starting_balance": value["daily_stake"],
+                "rel_profit": value["rel_profit"],
+                "fiat_value": (
+                    self._fiat_converter.convert_amount(
+                        value["amount"], stake_currency, fiat_display_currency
+                    )
+                    if self._fiat_converter
+                    else 0
+                ),
+                "trade_count": value["trades"],
             }
             for key, value in profit_units.items()
         ]
         return {
-            'stake_currency': stake_currency,
-            'fiat_display_currency': fiat_display_currency,
-            'data': data
+            "stake_currency": stake_currency,
+            "fiat_display_currency": fiat_display_currency,
+            "data": data,
         }
 
     def _rpc_trade_history(self, limit: int, offset: int = 0, order_by_id: bool = False) -> Dict:
-        """ Returns the X last trades """
+        """Returns the X last trades"""
         order_by: Any = Trade.id if order_by_id else Trade.close_date.desc()
         if limit:
             trades = Trade.session.scalars(
                 Trade.get_trades_query([Trade.is_open.is_(False)])
                 .order_by(order_by)
                 .limit(limit)
-                .offset(offset))
+                .offset(offset)
+            )
         else:
             trades = Trade.session.scalars(
-                Trade.get_trades_query([Trade.is_open.is_(False)])
-                .order_by(Trade.close_date.desc()))
+                Trade.get_trades_query([Trade.is_open.is_(False)]).order_by(Trade.close_date.desc())
+            )
 
         output = [trade.to_json() for trade in trades]
         total_trades = Trade.session.scalar(
-            select(func.count(Trade.id)).filter(Trade.is_open.is_(False)))
+            select(func.count(Trade.id)).filter(Trade.is_open.is_(False))
+        )
 
         return {
             "trades": output,
             "trades_count": len(output),
             "offset": offset,
             "total_trades": total_trades,
         }
 
     def _rpc_stats(self) -> Dict[str, Any]:
         """
         Generate generic stats for trades in database
         """
+
         def trade_win_loss(trade):
             if trade.close_profit > 0:
-                return 'wins'
+                return "wins"
             elif trade.close_profit < 0:
-                return 'losses'
+                return "losses"
             else:
-                return 'draws'
+                return "draws"
+
         trades = Trade.get_trades([Trade.is_open.is_(False)], include_orders=False)
         # Duration
-        dur: Dict[str, List[float]] = {'wins': [], 'draws': [], 'losses': []}
+        dur: Dict[str, List[float]] = {"wins": [], "draws": [], "losses": []}
         # Exit reason
         exit_reasons = {}
         for trade in trades:
             if trade.exit_reason not in exit_reasons:
-                exit_reasons[trade.exit_reason] = {'wins': 0, 'losses': 0, 'draws': 0}
+                exit_reasons[trade.exit_reason] = {"wins": 0, "losses": 0, "draws": 0}
             exit_reasons[trade.exit_reason][trade_win_loss(trade)] += 1
 
             if trade.close_date is not None and trade.open_date is not None:
                 trade_dur = (trade.close_date - trade.open_date).total_seconds()
                 dur[trade_win_loss(trade)].append(trade_dur)
 
-        wins_dur = sum(dur['wins']) / len(dur['wins']) if len(dur['wins']) > 0 else None
-        draws_dur = sum(dur['draws']) / len(dur['draws']) if len(dur['draws']) > 0 else None
-        losses_dur = sum(dur['losses']) / len(dur['losses']) if len(dur['losses']) > 0 else None
+        wins_dur = sum(dur["wins"]) / len(dur["wins"]) if len(dur["wins"]) > 0 else None
+        draws_dur = sum(dur["draws"]) / len(dur["draws"]) if len(dur["draws"]) > 0 else None
+        losses_dur = sum(dur["losses"]) / len(dur["losses"]) if len(dur["losses"]) > 0 else None
 
-        durations = {'wins': wins_dur, 'draws': draws_dur, 'losses': losses_dur}
-        return {'exit_reasons': exit_reasons, 'durations': durations}
+        durations = {"wins": wins_dur, "draws": draws_dur, "losses": losses_dur}
+        return {"exit_reasons": exit_reasons, "durations": durations}
 
     def _rpc_trade_statistics(
-            self, stake_currency: str, fiat_display_currency: str,
-            start_date: Optional[datetime] = None) -> Dict[str, Any]:
-        """ Returns cumulative profit statistics """
+        self, stake_currency: str, fiat_display_currency: str, start_date: Optional[datetime] = None
+    ) -> Dict[str, Any]:
+        """Returns cumulative profit statistics"""
 
         start_date = datetime.fromtimestamp(0) if start_date is None else start_date
 
-        trade_filter = ((Trade.is_open.is_(False) & (Trade.close_date >= start_date)) |
-                        Trade.is_open.is_(True))
-        trades: Sequence[Trade] = Trade.session.scalars(Trade.get_trades_query(
-            trade_filter, include_orders=False).order_by(Trade.id)).all()
+        trade_filter = (
+            Trade.is_open.is_(False) & (Trade.close_date >= start_date)
+        ) | Trade.is_open.is_(True)
+        trades: Sequence[Trade] = Trade.session.scalars(
+            Trade.get_trades_query(trade_filter, include_orders=False).order_by(Trade.id)
+        ).all()
 
         profit_all_coin = []
         profit_all_ratio = []
         profit_closed_coin = []
         profit_closed_ratio = []
         durations = []
         winning_trades = 0
@@ -495,522 +521,578 @@
                     winning_trades += 1
                     winning_profit += profit_abs
                 else:
                     losing_trades += 1
                     losing_profit += profit_abs
             else:
                 # Get current rate
+                if len(trade.select_filled_orders(trade.entry_side)) == 0:
+                    # Skip trades with no filled orders
+                    continue
                 try:
                     current_rate = self._freqtrade.exchange.get_rate(
-                        trade.pair, side='exit', is_short=trade.is_short, refresh=False)
+                        trade.pair, side="exit", is_short=trade.is_short, refresh=False
+                    )
                 except (PricingError, ExchangeError):
                     current_rate = NAN
-                if isnan(current_rate):
                     profit_ratio = NAN
                     profit_abs = NAN
                 else:
-                    profit = trade.calculate_profit(trade.close_rate or current_rate)
+                    _profit = trade.calculate_profit(trade.close_rate or current_rate)
 
-                    profit_ratio = profit.profit_ratio
-                    profit_abs = profit.total_profit
+                    profit_ratio = _profit.profit_ratio
+                    profit_abs = _profit.total_profit
 
             profit_all_coin.append(profit_abs)
             profit_all_ratio.append(profit_ratio)
 
         closed_trade_count = len([t for t in trades if not t.is_open])
 
         best_pair = Trade.get_best_pair(start_date)
         trading_volume = Trade.get_trading_volume(start_date)
 
         # Prepare data to display
         profit_closed_coin_sum = round(sum(profit_closed_coin), 8)
         profit_closed_ratio_mean = float(mean(profit_closed_ratio) if profit_closed_ratio else 0.0)
         profit_closed_ratio_sum = sum(profit_closed_ratio) if profit_closed_ratio else 0.0
 
-        profit_closed_fiat = self._fiat_converter.convert_amount(
-            profit_closed_coin_sum,
-            stake_currency,
-            fiat_display_currency
-        ) if self._fiat_converter else 0
+        profit_closed_fiat = (
+            self._fiat_converter.convert_amount(
+                profit_closed_coin_sum, stake_currency, fiat_display_currency
+            )
+            if self._fiat_converter
+            else 0
+        )
 
         profit_all_coin_sum = round(sum(profit_all_coin), 8)
         profit_all_ratio_mean = float(mean(profit_all_ratio) if profit_all_ratio else 0.0)
         # Doing the sum is not right - overall profit needs to be based on initial capital
         profit_all_ratio_sum = sum(profit_all_ratio) if profit_all_ratio else 0.0
         starting_balance = self._freqtrade.wallets.get_starting_balance()
         profit_closed_ratio_fromstart = 0
         profit_all_ratio_fromstart = 0
         if starting_balance:
             profit_closed_ratio_fromstart = profit_closed_coin_sum / starting_balance
             profit_all_ratio_fromstart = profit_all_coin_sum / starting_balance
 
-        profit_factor = winning_profit / abs(losing_profit) if losing_profit else float('inf')
+        profit_factor = winning_profit / abs(losing_profit) if losing_profit else float("inf")
 
         winrate = (winning_trades / closed_trade_count) if closed_trade_count > 0 else 0
 
-        trades_df = DataFrame([{'close_date': format_date(trade.close_date),
-                                'close_date_dt': trade.close_date,
-                                'profit_abs': trade.close_profit_abs}
-                               for trade in trades if not trade.is_open and trade.close_date])
+        trades_df = DataFrame(
+            [
+                {
+                    "close_date": format_date(trade.close_date),
+                    "close_date_dt": trade.close_date,
+                    "profit_abs": trade.close_profit_abs,
+                }
+                for trade in trades
+                if not trade.is_open and trade.close_date
+            ]
+        )
 
         expectancy, expectancy_ratio = calculate_expectancy(trades_df)
 
-        max_drawdown_abs = 0.0
-        max_drawdown = 0.0
-        drawdown_start: Optional[datetime] = None
-        drawdown_end: Optional[datetime] = None
-        dd_high_val = dd_low_val = 0.0
+        drawdown = DrawDownResult()
         if len(trades_df) > 0:
             try:
-                (max_drawdown_abs, drawdown_start, drawdown_end, dd_high_val, dd_low_val,
-                 max_drawdown) = calculate_max_drawdown(
-                    trades_df, value_col='profit_abs', date_col='close_date_dt',
-                    starting_balance=starting_balance)
+                drawdown = calculate_max_drawdown(
+                    trades_df,
+                    value_col="profit_abs",
+                    date_col="close_date_dt",
+                    starting_balance=starting_balance,
+                )
             except ValueError:
                 # ValueError if no losing trade.
                 pass
 
-        profit_all_fiat = self._fiat_converter.convert_amount(
-            profit_all_coin_sum,
-            stake_currency,
-            fiat_display_currency
-        ) if self._fiat_converter else 0
+        profit_all_fiat = (
+            self._fiat_converter.convert_amount(
+                profit_all_coin_sum, stake_currency, fiat_display_currency
+            )
+            if self._fiat_converter
+            else 0
+        )
 
         first_date = trades[0].open_date_utc if trades else None
         last_date = trades[-1].open_date_utc if trades else None
         num = float(len(durations) or 1)
         bot_start = KeyValueStore.get_datetime_value(KeyStoreKeys.BOT_START_TIME)
         return {
-            'profit_closed_coin': profit_closed_coin_sum,
-            'profit_closed_percent_mean': round(profit_closed_ratio_mean * 100, 2),
-            'profit_closed_ratio_mean': profit_closed_ratio_mean,
-            'profit_closed_percent_sum': round(profit_closed_ratio_sum * 100, 2),
-            'profit_closed_ratio_sum': profit_closed_ratio_sum,
-            'profit_closed_ratio': profit_closed_ratio_fromstart,
-            'profit_closed_percent': round(profit_closed_ratio_fromstart * 100, 2),
-            'profit_closed_fiat': profit_closed_fiat,
-            'profit_all_coin': profit_all_coin_sum,
-            'profit_all_percent_mean': round(profit_all_ratio_mean * 100, 2),
-            'profit_all_ratio_mean': profit_all_ratio_mean,
-            'profit_all_percent_sum': round(profit_all_ratio_sum * 100, 2),
-            'profit_all_ratio_sum': profit_all_ratio_sum,
-            'profit_all_ratio': profit_all_ratio_fromstart,
-            'profit_all_percent': round(profit_all_ratio_fromstart * 100, 2),
-            'profit_all_fiat': profit_all_fiat,
-            'trade_count': len(trades),
-            'closed_trade_count': closed_trade_count,
-            'first_trade_date': format_date(first_date),
-            'first_trade_humanized': dt_humanize_delta(first_date) if first_date else '',
-            'first_trade_timestamp': dt_ts_def(first_date, 0),
-            'latest_trade_date': format_date(last_date),
-            'latest_trade_humanized': dt_humanize_delta(last_date) if last_date else '',
-            'latest_trade_timestamp': dt_ts_def(last_date, 0),
-            'avg_duration': str(timedelta(seconds=sum(durations) / num)).split('.')[0],
-            'best_pair': best_pair[0] if best_pair else '',
-            'best_rate': round(best_pair[1] * 100, 2) if best_pair else 0,  # Deprecated
-            'best_pair_profit_ratio': best_pair[1] if best_pair else 0,
-            'winning_trades': winning_trades,
-            'losing_trades': losing_trades,
-            'profit_factor': profit_factor,
-            'winrate': winrate,
-            'expectancy': expectancy,
-            'expectancy_ratio': expectancy_ratio,
-            'max_drawdown': max_drawdown,
-            'max_drawdown_abs': max_drawdown_abs,
-            'max_drawdown_start': format_date(drawdown_start),
-            'max_drawdown_start_timestamp': dt_ts_def(drawdown_start),
-            'max_drawdown_end': format_date(drawdown_end),
-            'max_drawdown_end_timestamp': dt_ts_def(drawdown_end),
-            'drawdown_high': dd_high_val,
-            'drawdown_low': dd_low_val,
-            'trading_volume': trading_volume,
-            'bot_start_timestamp': dt_ts_def(bot_start, 0),
-            'bot_start_date': format_date(bot_start),
+            "profit_closed_coin": profit_closed_coin_sum,
+            "profit_closed_percent_mean": round(profit_closed_ratio_mean * 100, 2),
+            "profit_closed_ratio_mean": profit_closed_ratio_mean,
+            "profit_closed_percent_sum": round(profit_closed_ratio_sum * 100, 2),
+            "profit_closed_ratio_sum": profit_closed_ratio_sum,
+            "profit_closed_ratio": profit_closed_ratio_fromstart,
+            "profit_closed_percent": round(profit_closed_ratio_fromstart * 100, 2),
+            "profit_closed_fiat": profit_closed_fiat,
+            "profit_all_coin": profit_all_coin_sum,
+            "profit_all_percent_mean": round(profit_all_ratio_mean * 100, 2),
+            "profit_all_ratio_mean": profit_all_ratio_mean,
+            "profit_all_percent_sum": round(profit_all_ratio_sum * 100, 2),
+            "profit_all_ratio_sum": profit_all_ratio_sum,
+            "profit_all_ratio": profit_all_ratio_fromstart,
+            "profit_all_percent": round(profit_all_ratio_fromstart * 100, 2),
+            "profit_all_fiat": profit_all_fiat,
+            "trade_count": len(trades),
+            "closed_trade_count": closed_trade_count,
+            "first_trade_date": format_date(first_date),
+            "first_trade_humanized": dt_humanize_delta(first_date) if first_date else "",
+            "first_trade_timestamp": dt_ts_def(first_date, 0),
+            "latest_trade_date": format_date(last_date),
+            "latest_trade_humanized": dt_humanize_delta(last_date) if last_date else "",
+            "latest_trade_timestamp": dt_ts_def(last_date, 0),
+            "avg_duration": str(timedelta(seconds=sum(durations) / num)).split(".")[0],
+            "best_pair": best_pair[0] if best_pair else "",
+            "best_rate": round(best_pair[1] * 100, 2) if best_pair else 0,  # Deprecated
+            "best_pair_profit_ratio": best_pair[1] if best_pair else 0,
+            "winning_trades": winning_trades,
+            "losing_trades": losing_trades,
+            "profit_factor": profit_factor,
+            "winrate": winrate,
+            "expectancy": expectancy,
+            "expectancy_ratio": expectancy_ratio,
+            "max_drawdown": drawdown.relative_account_drawdown,
+            "max_drawdown_abs": drawdown.drawdown_abs,
+            "max_drawdown_start": format_date(drawdown.high_date),
+            "max_drawdown_start_timestamp": dt_ts_def(drawdown.high_date),
+            "max_drawdown_end": format_date(drawdown.low_date),
+            "max_drawdown_end_timestamp": dt_ts_def(drawdown.low_date),
+            "drawdown_high": drawdown.high_value,
+            "drawdown_low": drawdown.low_value,
+            "trading_volume": trading_volume,
+            "bot_start_timestamp": dt_ts_def(bot_start, 0),
+            "bot_start_date": format_date(bot_start),
         }
 
     def __balance_get_est_stake(
-            self, coin: str, stake_currency: str, amount: float,
-            balance: Wallet, tickers) -> Tuple[float, float]:
+        self, coin: str, stake_currency: str, amount: float, balance: Wallet, tickers
+    ) -> Tuple[float, float]:
         est_stake = 0.0
         est_bot_stake = 0.0
         if coin == stake_currency:
             est_stake = balance.total
-            if self._config.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT:
+            if self._config.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT:
                 # in Futures, "total" includes the locked stake, and therefore all positions
                 est_stake = balance.free
             est_bot_stake = amount
         else:
             pair = self._freqtrade.exchange.get_valid_pair_combination(coin, stake_currency)
-            rate: Optional[float] = tickers.get(pair, {}).get('last', None)
+            rate: Optional[float] = tickers.get(pair, {}).get("last", None)
             if rate:
                 if pair.startswith(stake_currency) and not pair.endswith(stake_currency):
                     rate = 1.0 / rate
                 est_stake = rate * balance.total
                 est_bot_stake = rate * amount
 
         return est_stake, est_bot_stake
 
     def _rpc_balance(self, stake_currency: str, fiat_display_currency: str) -> Dict:
-        """ Returns current account balance per crypto """
+        """Returns current account balance per crypto"""
         currencies: List[Dict] = []
         total = 0.0
         total_bot = 0.0
         try:
             tickers: Tickers = self._freqtrade.exchange.get_tickers(cached=True)
-        except (ExchangeError):
-            raise RPCException('Error getting current tickers.')
+        except ExchangeError:
+            raise RPCException("Error getting current tickers.")
 
         open_trades: List[Trade] = Trade.get_open_trades()
         open_assets: Dict[str, Trade] = {t.safe_base_currency: t for t in open_trades}
         self._freqtrade.wallets.update(require_update=False)
         starting_capital = self._freqtrade.wallets.get_starting_balance()
-        starting_cap_fiat = self._fiat_converter.convert_amount(
-            starting_capital, stake_currency, fiat_display_currency) if self._fiat_converter else 0
+        starting_cap_fiat = (
+            self._fiat_converter.convert_amount(
+                starting_capital, stake_currency, fiat_display_currency
+            )
+            if self._fiat_converter
+            else 0
+        )
         coin: str
         balance: Wallet
         for coin, balance in self._freqtrade.wallets.get_all_balances().items():
             if not balance.total:
                 continue
 
             trade = open_assets.get(coin, None)
             is_bot_managed = coin == stake_currency or trade is not None
             trade_amount = trade.amount if trade else 0
             if coin == stake_currency:
                 trade_amount = self._freqtrade.wallets.get_available_stake_amount()
 
             try:
                 est_stake, est_stake_bot = self.__balance_get_est_stake(
-                    coin, stake_currency, trade_amount, balance, tickers)
+                    coin, stake_currency, trade_amount, balance, tickers
+                )
             except ValueError:
                 continue
 
             total += est_stake
 
             if is_bot_managed:
                 total_bot += est_stake_bot
-            currencies.append({
-                'currency': coin,
-                'free': balance.free,
-                'balance': balance.total,
-                'used': balance.used,
-                'bot_owned': trade_amount,
-                'est_stake': est_stake or 0,
-                'est_stake_bot': est_stake_bot if is_bot_managed else 0,
-                'stake': stake_currency,
-                'side': 'long',
-                'leverage': 1,
-                'position': 0,
-                'is_bot_managed': is_bot_managed,
-                'is_position': False,
-            })
+            currencies.append(
+                {
+                    "currency": coin,
+                    "free": balance.free,
+                    "balance": balance.total,
+                    "used": balance.used,
+                    "bot_owned": trade_amount,
+                    "est_stake": est_stake or 0,
+                    "est_stake_bot": est_stake_bot if is_bot_managed else 0,
+                    "stake": stake_currency,
+                    "side": "long",
+                    "leverage": 1,
+                    "position": 0,
+                    "is_bot_managed": is_bot_managed,
+                    "is_position": False,
+                }
+            )
         symbol: str
         position: PositionWallet
         for symbol, position in self._freqtrade.wallets.get_all_positions().items():
             total += position.collateral
             total_bot += position.collateral
 
-            currencies.append({
-                'currency': symbol,
-                'free': 0,
-                'balance': 0,
-                'used': 0,
-                'position': position.position,
-                'est_stake': position.collateral,
-                'est_stake_bot': position.collateral,
-                'stake': stake_currency,
-                'leverage': position.leverage,
-                'side': position.side,
-                'is_bot_managed': True,
-                'is_position': True
-            })
-
-        value = self._fiat_converter.convert_amount(
-            total, stake_currency, fiat_display_currency) if self._fiat_converter else 0
-        value_bot = self._fiat_converter.convert_amount(
-            total_bot, stake_currency, fiat_display_currency) if self._fiat_converter else 0
+            currencies.append(
+                {
+                    "currency": symbol,
+                    "free": 0,
+                    "balance": 0,
+                    "used": 0,
+                    "position": position.position,
+                    "est_stake": position.collateral,
+                    "est_stake_bot": position.collateral,
+                    "stake": stake_currency,
+                    "leverage": position.leverage,
+                    "side": position.side,
+                    "is_bot_managed": True,
+                    "is_position": True,
+                }
+            )
+
+        value = (
+            self._fiat_converter.convert_amount(total, stake_currency, fiat_display_currency)
+            if self._fiat_converter
+            else 0
+        )
+        value_bot = (
+            self._fiat_converter.convert_amount(total_bot, stake_currency, fiat_display_currency)
+            if self._fiat_converter
+            else 0
+        )
 
         trade_count = len(Trade.get_trades_proxy())
         starting_capital_ratio = (total_bot / starting_capital) - 1 if starting_capital else 0.0
         starting_cap_fiat_ratio = (value_bot / starting_cap_fiat) - 1 if starting_cap_fiat else 0.0
 
         return {
-            'currencies': currencies,
-            'total': total,
-            'total_bot': total_bot,
-            'symbol': fiat_display_currency,
-            'value': value,
-            'value_bot': value_bot,
-            'stake': stake_currency,
-            'starting_capital': starting_capital,
-            'starting_capital_ratio': starting_capital_ratio,
-            'starting_capital_pct': round(starting_capital_ratio * 100, 2),
-            'starting_capital_fiat': starting_cap_fiat,
-            'starting_capital_fiat_ratio': starting_cap_fiat_ratio,
-            'starting_capital_fiat_pct': round(starting_cap_fiat_ratio * 100, 2),
-            'trade_count': trade_count,
-            'note': 'Simulated balances' if self._freqtrade.config['dry_run'] else ''
+            "currencies": currencies,
+            "total": total,
+            "total_bot": total_bot,
+            "symbol": fiat_display_currency,
+            "value": value,
+            "value_bot": value_bot,
+            "stake": stake_currency,
+            "starting_capital": starting_capital,
+            "starting_capital_ratio": starting_capital_ratio,
+            "starting_capital_pct": round(starting_capital_ratio * 100, 2),
+            "starting_capital_fiat": starting_cap_fiat,
+            "starting_capital_fiat_ratio": starting_cap_fiat_ratio,
+            "starting_capital_fiat_pct": round(starting_cap_fiat_ratio * 100, 2),
+            "trade_count": trade_count,
+            "note": "Simulated balances" if self._freqtrade.config["dry_run"] else "",
         }
 
     def _rpc_start(self) -> Dict[str, str]:
-        """ Handler for start """
+        """Handler for start"""
         if self._freqtrade.state == State.RUNNING:
-            return {'status': 'already running'}
+            return {"status": "already running"}
 
         self._freqtrade.state = State.RUNNING
-        return {'status': 'starting trader ...'}
+        return {"status": "starting trader ..."}
 
     def _rpc_stop(self) -> Dict[str, str]:
-        """ Handler for stop """
+        """Handler for stop"""
         if self._freqtrade.state == State.RUNNING:
             self._freqtrade.state = State.STOPPED
-            return {'status': 'stopping trader ...'}
+            return {"status": "stopping trader ..."}
 
-        return {'status': 'already stopped'}
+        return {"status": "already stopped"}
 
     def _rpc_reload_config(self) -> Dict[str, str]:
-        """ Handler for reload_config. """
+        """Handler for reload_config."""
         self._freqtrade.state = State.RELOAD_CONFIG
-        return {'status': 'Reloading config ...'}
+        return {"status": "Reloading config ..."}
 
     def _rpc_stopentry(self) -> Dict[str, str]:
         """
         Handler to stop buying, but handle open trades gracefully.
         """
         if self._freqtrade.state == State.RUNNING:
             # Set 'max_open_trades' to 0
-            self._freqtrade.config['max_open_trades'] = 0
+            self._freqtrade.config["max_open_trades"] = 0
             self._freqtrade.strategy.max_open_trades = 0
 
-        return {'status': 'No more entries will occur from now. Run /reload_config to reset.'}
+        return {"status": "No more entries will occur from now. Run /reload_config to reset."}
 
     def _rpc_reload_trade_from_exchange(self, trade_id: int) -> Dict[str, str]:
         """
         Handler for reload_trade_from_exchange.
         Reloads a trade from it's orders, should manual interaction have happened.
         """
         trade = Trade.get_trades(trade_filter=[Trade.id == trade_id]).first()
         if not trade:
             raise RPCException(f"Could not find trade with id {trade_id}.")
 
         self._freqtrade.handle_onexchange_order(trade)
-        return {'status': 'Reloaded from orders from exchange'}
+        return {"status": "Reloaded from orders from exchange"}
 
-    def __exec_force_exit(self, trade: Trade, ordertype: Optional[str],
-                          amount: Optional[float] = None) -> bool:
+    def __exec_force_exit(
+        self, trade: Trade, ordertype: Optional[str], amount: Optional[float] = None
+    ) -> bool:
         # Check if there is there are open orders
         trade_entry_cancelation_registry = []
         for oo in trade.open_orders:
-            trade_entry_cancelation_res = {'order_id': oo.order_id, 'cancel_state': False}
+            trade_entry_cancelation_res = {"order_id": oo.order_id, "cancel_state": False}
             order = self._freqtrade.exchange.fetch_order(oo.order_id, trade.pair)
 
-            if order['side'] == trade.entry_side:
+            if order["side"] == trade.entry_side:
                 fully_canceled = self._freqtrade.handle_cancel_enter(
-                    trade, order, oo, CANCEL_REASON['FORCE_EXIT'])
-                trade_entry_cancelation_res['cancel_state'] = fully_canceled
+                    trade, order, oo, CANCEL_REASON["FORCE_EXIT"]
+                )
+                trade_entry_cancelation_res["cancel_state"] = fully_canceled
                 trade_entry_cancelation_registry.append(trade_entry_cancelation_res)
 
-            if order['side'] == trade.exit_side:
+            if order["side"] == trade.exit_side:
                 # Cancel order - so it is placed anew with a fresh price.
-                self._freqtrade.handle_cancel_exit(
-                    trade, order, oo, CANCEL_REASON['FORCE_EXIT'])
+                self._freqtrade.handle_cancel_exit(trade, order, oo, CANCEL_REASON["FORCE_EXIT"])
 
-        if all(tocr['cancel_state'] is False for tocr in trade_entry_cancelation_registry):
+        if all(tocr["cancel_state"] is False for tocr in trade_entry_cancelation_registry):
             if trade.has_open_orders:
                 # Order cancellation failed, so we can't exit.
                 return False
             # Get current rate and execute sell
             current_rate = self._freqtrade.exchange.get_rate(
-                trade.pair, side='exit', is_short=trade.is_short, refresh=True)
+                trade.pair, side="exit", is_short=trade.is_short, refresh=True
+            )
             exit_check = ExitCheckTuple(exit_type=ExitType.FORCE_EXIT)
             order_type = ordertype or self._freqtrade.strategy.order_types.get(
-                "force_exit", self._freqtrade.strategy.order_types["exit"])
+                "force_exit", self._freqtrade.strategy.order_types["exit"]
+            )
             sub_amount: Optional[float] = None
             if amount and amount < trade.amount:
                 # Partial exit ...
                 min_exit_stake = self._freqtrade.exchange.get_min_pair_stake_amount(
-                    trade.pair, current_rate, trade.stop_loss_pct)
+                    trade.pair, current_rate, trade.stop_loss_pct
+                )
                 remaining = (trade.amount - amount) * current_rate
                 if remaining < min_exit_stake:
-                    raise RPCException(f'Remaining amount of {remaining} would be too small.')
+                    raise RPCException(f"Remaining amount of {remaining} would be too small.")
                 sub_amount = amount
 
             self._freqtrade.execute_trade_exit(
-                trade, current_rate, exit_check, ordertype=order_type,
-                sub_trade_amt=sub_amount)
+                trade, current_rate, exit_check, ordertype=order_type, sub_trade_amt=sub_amount
+            )
 
             return True
         return False
 
-    def _rpc_force_exit(self, trade_id: str, ordertype: Optional[str] = None, *,
-                        amount: Optional[float] = None) -> Dict[str, str]:
+    def _rpc_force_exit(
+        self, trade_id: str, ordertype: Optional[str] = None, *, amount: Optional[float] = None
+    ) -> Dict[str, str]:
         """
         Handler for forceexit <id>.
         Sells the given trade at current price
         """
 
         if self._freqtrade.state != State.RUNNING:
-            raise RPCException('trader is not running')
+            raise RPCException("trader is not running")
 
         with self._freqtrade._exit_lock:
-            if trade_id == 'all':
+            if trade_id == "all":
                 # Execute exit for all open orders
                 for trade in Trade.get_open_trades():
                     self.__exec_force_exit(trade, ordertype)
                 Trade.commit()
                 self._freqtrade.wallets.update()
-                return {'result': 'Created exit orders for all open trades.'}
+                return {"result": "Created exit orders for all open trades."}
 
             # Query for trade
             trade = Trade.get_trades(
-                trade_filter=[Trade.id == trade_id, Trade.is_open.is_(True), ]
+                trade_filter=[
+                    Trade.id == trade_id,
+                    Trade.is_open.is_(True),
+                ]
             ).first()
             if not trade:
-                logger.warning('force_exit: Invalid argument received')
-                raise RPCException('invalid argument')
+                logger.warning("force_exit: Invalid argument received")
+                raise RPCException("invalid argument")
 
             result = self.__exec_force_exit(trade, ordertype, amount)
             Trade.commit()
             self._freqtrade.wallets.update()
             if not result:
-                raise RPCException('Failed to exit trade.')
-            return {'result': f'Created exit order for trade {trade_id}.'}
+                raise RPCException("Failed to exit trade.")
+            return {"result": f"Created exit order for trade {trade_id}."}
 
     def _force_entry_validations(self, pair: str, order_side: SignalDirection):
-        if not self._freqtrade.config.get('force_entry_enable', False):
-            raise RPCException('Force_entry not enabled.')
+        if not self._freqtrade.config.get("force_entry_enable", False):
+            raise RPCException("Force_entry not enabled.")
 
         if self._freqtrade.state != State.RUNNING:
-            raise RPCException('trader is not running')
+            raise RPCException("trader is not running")
 
         if order_side == SignalDirection.SHORT and self._freqtrade.trading_mode == TradingMode.SPOT:
             raise RPCException("Can't go short on Spot markets.")
 
         if pair not in self._freqtrade.exchange.get_markets(tradable_only=True):
-            raise RPCException('Symbol does not exist or market is not active.')
+            raise RPCException("Symbol does not exist or market is not active.")
         # Check if pair quote currency equals to the stake currency.
-        stake_currency = self._freqtrade.config.get('stake_currency')
+        stake_currency = self._freqtrade.config.get("stake_currency")
         if not self._freqtrade.exchange.get_pair_quote_currency(pair) == stake_currency:
             raise RPCException(
-                f'Wrong pair selected. Only pairs with stake-currency {stake_currency} allowed.')
+                f"Wrong pair selected. Only pairs with stake-currency {stake_currency} allowed."
+            )
 
-    def _rpc_force_entry(self, pair: str, price: Optional[float], *,
-                         order_type: Optional[str] = None,
-                         order_side: SignalDirection = SignalDirection.LONG,
-                         stake_amount: Optional[float] = None,
-                         enter_tag: Optional[str] = 'force_entry',
-                         leverage: Optional[float] = None) -> Optional[Trade]:
+    def _rpc_force_entry(
+        self,
+        pair: str,
+        price: Optional[float],
+        *,
+        order_type: Optional[str] = None,
+        order_side: SignalDirection = SignalDirection.LONG,
+        stake_amount: Optional[float] = None,
+        enter_tag: Optional[str] = "force_entry",
+        leverage: Optional[float] = None,
+    ) -> Optional[Trade]:
         """
         Handler for forcebuy <asset> <price>
         Buys a pair trade at the given or current price
         """
         self._force_entry_validations(pair, order_side)
 
         # check if valid pair
 
         # check if pair already has an open pair
         trade: Optional[Trade] = Trade.get_trades(
-            [Trade.is_open.is_(True), Trade.pair == pair]).first()
-        is_short = (order_side == SignalDirection.SHORT)
+            [Trade.is_open.is_(True), Trade.pair == pair]
+        ).first()
+        is_short = order_side == SignalDirection.SHORT
         if trade:
             is_short = trade.is_short
             if not self._freqtrade.strategy.position_adjustment_enable:
                 raise RPCException(f"position for {pair} already open - id: {trade.id}")
             if trade.has_open_orders:
-                raise RPCException(f"position for {pair} already open - id: {trade.id} "
-                                   f"and has open order {','.join(trade.open_orders_ids)}")
+                raise RPCException(
+                    f"position for {pair} already open - id: {trade.id} "
+                    f"and has open order {','.join(trade.open_orders_ids)}"
+                )
         else:
-            if Trade.get_open_trade_count() >= self._config['max_open_trades']:
+            if Trade.get_open_trade_count() >= self._config["max_open_trades"]:
                 raise RPCException("Maximum number of trades is reached.")
 
         if not stake_amount:
             # gen stake amount
             stake_amount = self._freqtrade.wallets.get_trade_stake_amount(
-                pair, self._config['max_open_trades'])
+                pair, self._config["max_open_trades"]
+            )
 
         # execute buy
         if not order_type:
             order_type = self._freqtrade.strategy.order_types.get(
-                'force_entry', self._freqtrade.strategy.order_types['entry'])
+                "force_entry", self._freqtrade.strategy.order_types["entry"]
+            )
         with self._freqtrade._exit_lock:
-            if self._freqtrade.execute_entry(pair, stake_amount, price,
-                                             ordertype=order_type, trade=trade,
-                                             is_short=is_short,
-                                             enter_tag=enter_tag,
-                                             leverage_=leverage,
-                                             mode='pos_adjust' if trade else 'initial'
-                                             ):
+            if self._freqtrade.execute_entry(
+                pair,
+                stake_amount,
+                price,
+                ordertype=order_type,
+                trade=trade,
+                is_short=is_short,
+                enter_tag=enter_tag,
+                leverage_=leverage,
+                mode="pos_adjust" if trade else "initial",
+            ):
                 Trade.commit()
                 trade = Trade.get_trades([Trade.is_open.is_(True), Trade.pair == pair]).first()
                 return trade
             else:
-                raise RPCException(f'Failed to enter position for {pair}.')
+                raise RPCException(f"Failed to enter position for {pair}.")
 
     def _rpc_cancel_open_order(self, trade_id: int):
         if self._freqtrade.state != State.RUNNING:
-            raise RPCException('trader is not running')
+            raise RPCException("trader is not running")
         with self._freqtrade._exit_lock:
             # Query for trade
             trade = Trade.get_trades(
-                trade_filter=[Trade.id == trade_id, Trade.is_open.is_(True), ]
+                trade_filter=[
+                    Trade.id == trade_id,
+                    Trade.is_open.is_(True),
+                ]
             ).first()
             if not trade:
-                logger.warning('cancel_open_order: Invalid trade_id received.')
-                raise RPCException('Invalid trade_id.')
+                logger.warning("cancel_open_order: Invalid trade_id received.")
+                raise RPCException("Invalid trade_id.")
             if not trade.has_open_orders:
-                logger.warning('cancel_open_order: No open order for trade_id.')
-                raise RPCException('No open order for trade_id.')
+                logger.warning("cancel_open_order: No open order for trade_id.")
+                raise RPCException("No open order for trade_id.")
 
             for open_order in trade.open_orders:
                 try:
                     order = self._freqtrade.exchange.fetch_order(open_order.order_id, trade.pair)
                 except ExchangeError as e:
                     logger.info(f"Cannot query order for {trade} due to {e}.", exc_info=True)
                     raise RPCException("Order not found.")
                 self._freqtrade.handle_cancel_order(
-                    order, open_order, trade, CANCEL_REASON['USER_CANCEL'])
+                    order, open_order, trade, CANCEL_REASON["USER_CANCEL"]
+                )
             Trade.commit()
 
     def _rpc_delete(self, trade_id: int) -> Dict[str, Union[str, int]]:
         """
         Handler for delete <id>.
         Delete the given trade and close eventually existing open orders.
         """
         with self._freqtrade._exit_lock:
             c_count = 0
             trade = Trade.get_trades(trade_filter=[Trade.id == trade_id]).first()
             if not trade:
-                logger.warning('delete trade: Invalid argument received')
-                raise RPCException('invalid argument')
+                logger.warning("delete trade: Invalid argument received")
+                raise RPCException("invalid argument")
 
             # Try cancelling regular order if that exists
             for open_order in trade.open_orders:
                 try:
                     self._freqtrade.exchange.cancel_order(open_order.order_id, trade.pair)
                     c_count += 1
-                except (ExchangeError):
+                except ExchangeError:
                     pass
 
             # cancel stoploss on exchange orders ...
-            if (self._freqtrade.strategy.order_types.get('stoploss_on_exchange')
-                    and trade.has_open_sl_orders):
-
+            if (
+                self._freqtrade.strategy.order_types.get("stoploss_on_exchange")
+                and trade.has_open_sl_orders
+            ):
                 for oslo in trade.open_sl_orders:
                     try:
                         self._freqtrade.exchange.cancel_stoploss_order(oslo.order_id, trade.pair)
                         c_count += 1
-                    except (ExchangeError):
+                    except ExchangeError:
                         pass
 
             trade.delete()
             self._freqtrade.wallets.update()
             return {
-                'result': 'success',
-                'trade_id': trade_id,
-                'result_msg': f'Deleted trade {trade_id}. Closed {c_count} open orders.',
-                'cancel_order_count': c_count,
+                "result": "success",
+                "trade_id": trade_id,
+                "result_msg": f"Deleted trade {trade_id}. Closed {c_count} open orders.",
+                "cancel_order_count": c_count,
             }
 
     def _rpc_list_custom_data(self, trade_id: int, key: Optional[str]) -> List[Dict[str, Any]]:
         # Query for trade
         trade = Trade.get_trades(trade_filter=[Trade.id == trade_id]).first()
         if trade is None:
             return []
@@ -1020,21 +1102,21 @@
             data = trade.get_custom_data(key=key)
             if data:
                 custom_data = [data]
         else:
             custom_data = trade.get_all_custom_data()
         return [
             {
-                'id': data_entry.id,
-                'ft_trade_id': data_entry.ft_trade_id,
-                'cd_key': data_entry.cd_key,
-                'cd_type': data_entry.cd_type,
-                'cd_value': data_entry.cd_value,
-                'created_at': data_entry.created_at,
-                'updated_at': data_entry.updated_at
+                "id": data_entry.id,
+                "ft_trade_id": data_entry.ft_trade_id,
+                "cd_key": data_entry.cd_key,
+                "cd_type": data_entry.cd_type,
+                "cd_value": data_entry.cd_value,
+                "created_at": data_entry.created_at,
+                "updated_at": data_entry.updated_at,
             }
             for data_entry in custom_data
         ]
 
     def _rpc_performance(self) -> List[Dict[str, Any]]:
         """
         Handler for performance.
@@ -1064,38 +1146,39 @@
         Shows a performance statistic from finished trades
         """
         mix_tags = Trade.get_mix_tag_performance(pair)
 
         return mix_tags
 
     def _rpc_count(self) -> Dict[str, float]:
-        """ Returns the number of trades running """
+        """Returns the number of trades running"""
         if self._freqtrade.state != State.RUNNING:
-            raise RPCException('trader is not running')
+            raise RPCException("trader is not running")
 
         trades = Trade.get_open_trades()
         return {
-            'current': len(trades),
-            'max': (int(self._freqtrade.config['max_open_trades'])
-                    if self._freqtrade.config['max_open_trades'] != float('inf') else -1),
-            'total_stake': sum((trade.open_rate * trade.amount) for trade in trades)
+            "current": len(trades),
+            "max": (
+                int(self._freqtrade.config["max_open_trades"])
+                if self._freqtrade.config["max_open_trades"] != float("inf")
+                else -1
+            ),
+            "total_stake": sum((trade.open_rate * trade.amount) for trade in trades),
         }
 
     def _rpc_locks(self) -> Dict[str, Any]:
-        """ Returns the  current locks """
+        """Returns the  current locks"""
 
         locks = PairLocks.get_pair_locks(None)
-        return {
-            'lock_count': len(locks),
-            'locks': [lock.to_json() for lock in locks]
-        }
+        return {"lock_count": len(locks), "locks": [lock.to_json() for lock in locks]}
 
-    def _rpc_delete_lock(self, lockid: Optional[int] = None,
-                         pair: Optional[str] = None) -> Dict[str, Any]:
-        """ Delete specific lock(s) """
+    def _rpc_delete_lock(
+        self, lockid: Optional[int] = None, pair: Optional[str] = None
+    ) -> Dict[str, Any]:
+        """Delete specific lock(s)"""
         locks: Sequence[PairLock] = []
 
         if pair:
             locks = PairLocks.get_pair_locks(pair)
         if lockid:
             locks = PairLock.session.scalars(select(PairLock).filter(PairLock.id == lockid)).all()
 
@@ -1104,293 +1187,299 @@
             lock.lock_end_time = datetime.now(timezone.utc)
 
         Trade.commit()
 
         return self._rpc_locks()
 
     def _rpc_add_lock(
-            self, pair: str, until: datetime, reason: Optional[str], side: str) -> PairLock:
+        self, pair: str, until: datetime, reason: Optional[str], side: str
+    ) -> PairLock:
         lock = PairLocks.lock_pair(
             pair=pair,
             until=until,
             reason=reason,
             side=side,
         )
         return lock
 
     def _rpc_whitelist(self) -> Dict:
-        """ Returns the currently active whitelist"""
-        res = {'method': self._freqtrade.pairlists.name_list,
-               'length': len(self._freqtrade.active_pair_whitelist),
-               'whitelist': self._freqtrade.active_pair_whitelist
-               }
+        """Returns the currently active whitelist"""
+        res = {
+            "method": self._freqtrade.pairlists.name_list,
+            "length": len(self._freqtrade.active_pair_whitelist),
+            "whitelist": self._freqtrade.active_pair_whitelist,
+        }
         return res
 
     def _rpc_blacklist_delete(self, delete: List[str]) -> Dict:
-        """ Removes pairs from currently active blacklist """
+        """Removes pairs from currently active blacklist"""
         errors = {}
         for pair in delete:
             if pair in self._freqtrade.pairlists.blacklist:
                 self._freqtrade.pairlists.blacklist.remove(pair)
             else:
-                errors[pair] = {
-                    'error_msg': f"Pair {pair} is not in the current blacklist."
-                }
+                errors[pair] = {"error_msg": f"Pair {pair} is not in the current blacklist."}
         resp = self._rpc_blacklist()
-        resp['errors'] = errors
+        resp["errors"] = errors
         return resp
 
     def _rpc_blacklist(self, add: Optional[List[str]] = None) -> Dict:
-        """ Returns the currently active blacklist"""
+        """Returns the currently active blacklist"""
         errors = {}
         if add:
             for pair in add:
                 if pair not in self._freqtrade.pairlists.blacklist:
                     try:
                         expand_pairlist([pair], self._freqtrade.exchange.get_markets().keys())
                         self._freqtrade.pairlists.blacklist.append(pair)
 
                     except ValueError:
-                        errors[pair] = {
-                            'error_msg': f'Pair {pair} is not a valid wildcard.'}
+                        errors[pair] = {"error_msg": f"Pair {pair} is not a valid wildcard."}
                 else:
-                    errors[pair] = {
-                        'error_msg': f'Pair {pair} already in pairlist.'}
+                    errors[pair] = {"error_msg": f"Pair {pair} already in pairlist."}
 
-        res = {'method': self._freqtrade.pairlists.name_list,
-               'length': len(self._freqtrade.pairlists.blacklist),
-               'blacklist': self._freqtrade.pairlists.blacklist,
-               'blacklist_expanded': self._freqtrade.pairlists.expanded_blacklist,
-               'errors': errors,
-               }
+        res = {
+            "method": self._freqtrade.pairlists.name_list,
+            "length": len(self._freqtrade.pairlists.blacklist),
+            "blacklist": self._freqtrade.pairlists.blacklist,
+            "blacklist_expanded": self._freqtrade.pairlists.expanded_blacklist,
+            "errors": errors,
+        }
         return res
 
     @staticmethod
     def _rpc_get_logs(limit: Optional[int]) -> Dict[str, Any]:
         """Returns the last X logs"""
         if limit:
             buffer = bufferHandler.buffer[-limit:]
         else:
             buffer = bufferHandler.buffer
-        records = [[format_date(datetime.fromtimestamp(r.created)),
-                   r.created * 1000, r.name, r.levelname,
-                   r.message + ('\n' + r.exc_text if r.exc_text else '')]
-                   for r in buffer]
+        records = [
+            [
+                format_date(datetime.fromtimestamp(r.created)),
+                r.created * 1000,
+                r.name,
+                r.levelname,
+                r.message + ("\n" + r.exc_text if r.exc_text else ""),
+            ]
+            for r in buffer
+        ]
 
         # Log format:
         # [logtime-formatted, logepoch, logger-name, loglevel, message \n + exception]
         # e.g. ["2020-08-27 11:35:01", 1598520901097.9397,
         #       "freqtrade.worker", "INFO", "Starting worker develop"]
 
-        return {'log_count': len(records), 'logs': records}
+        return {"log_count": len(records), "logs": records}
 
     def _rpc_edge(self) -> List[Dict[str, Any]]:
-        """ Returns information related to Edge """
+        """Returns information related to Edge"""
         if not self._freqtrade.edge:
-            raise RPCException('Edge is not enabled.')
+            raise RPCException("Edge is not enabled.")
         return self._freqtrade.edge.accepted_pairs()
 
     @staticmethod
     def _convert_dataframe_to_dict(
-            strategy: str, pair: str, timeframe: str, dataframe: DataFrame,
-            last_analyzed: datetime, selected_cols: Optional[List[str]]) -> Dict[str, Any]:
+        strategy: str,
+        pair: str,
+        timeframe: str,
+        dataframe: DataFrame,
+        last_analyzed: datetime,
+        selected_cols: Optional[List[str]],
+    ) -> Dict[str, Any]:
         has_content = len(dataframe) != 0
         dataframe_columns = list(dataframe.columns)
         signals = {
-            'enter_long': 0,
-            'exit_long': 0,
-            'enter_short': 0,
-            'exit_short': 0,
+            "enter_long": 0,
+            "exit_long": 0,
+            "enter_short": 0,
+            "exit_short": 0,
         }
         if has_content:
             if selected_cols is not None:
                 # Ensure OHLCV columns are always present
                 cols_set = set(DEFAULT_DATAFRAME_COLUMNS + list(signals.keys()) + selected_cols)
                 df_cols = [col for col in dataframe_columns if col in cols_set]
                 dataframe = dataframe.loc[:, df_cols]
 
-            dataframe.loc[:, '__date_ts'] = dataframe.loc[:, 'date'].astype(int64) // 1000 // 1000
+            dataframe.loc[:, "__date_ts"] = dataframe.loc[:, "date"].astype(int64) // 1000 // 1000
             # Move signal close to separate column when signal for easy plotting
             for sig_type in signals.keys():
                 if sig_type in dataframe.columns:
-                    mask = (dataframe[sig_type] == 1)
+                    mask = dataframe[sig_type] == 1
                     signals[sig_type] = int(mask.sum())
-                    dataframe.loc[mask, f'_{sig_type}_signal_close'] = dataframe.loc[mask, 'close']
+                    dataframe.loc[mask, f"_{sig_type}_signal_close"] = dataframe.loc[mask, "close"]
 
             # band-aid until this is fixed:
             # https://github.com/pandas-dev/pandas/issues/45836
-            datetime_types = ['datetime', 'datetime64', 'datetime64[ns, UTC]']
+            datetime_types = ["datetime", "datetime64", "datetime64[ns, UTC]"]
             date_columns = dataframe.select_dtypes(include=datetime_types)
             for date_column in date_columns:
                 # replace NaT with `None`
                 dataframe[date_column] = dataframe[date_column].astype(object).replace({NaT: None})
 
             dataframe = dataframe.replace({inf: None, -inf: None, NAN: None})
 
         res = {
-            'pair': pair,
-            'timeframe': timeframe,
-            'timeframe_ms': timeframe_to_msecs(timeframe),
-            'strategy': strategy,
-            'all_columns': dataframe_columns,
-            'columns': list(dataframe.columns),
-            'data': dataframe.values.tolist(),
-            'length': len(dataframe),
-            'buy_signals': signals['enter_long'],  # Deprecated
-            'sell_signals': signals['exit_long'],  # Deprecated
-            'enter_long_signals': signals['enter_long'],
-            'exit_long_signals': signals['exit_long'],
-            'enter_short_signals': signals['enter_short'],
-            'exit_short_signals': signals['exit_short'],
-            'last_analyzed': last_analyzed,
-            'last_analyzed_ts': int(last_analyzed.timestamp()),
-            'data_start': '',
-            'data_start_ts': 0,
-            'data_stop': '',
-            'data_stop_ts': 0,
+            "pair": pair,
+            "timeframe": timeframe,
+            "timeframe_ms": timeframe_to_msecs(timeframe),
+            "strategy": strategy,
+            "all_columns": dataframe_columns,
+            "columns": list(dataframe.columns),
+            "data": dataframe.values.tolist(),
+            "length": len(dataframe),
+            "buy_signals": signals["enter_long"],  # Deprecated
+            "sell_signals": signals["exit_long"],  # Deprecated
+            "enter_long_signals": signals["enter_long"],
+            "exit_long_signals": signals["exit_long"],
+            "enter_short_signals": signals["enter_short"],
+            "exit_short_signals": signals["exit_short"],
+            "last_analyzed": last_analyzed,
+            "last_analyzed_ts": int(last_analyzed.timestamp()),
+            "data_start": "",
+            "data_start_ts": 0,
+            "data_stop": "",
+            "data_stop_ts": 0,
         }
         if has_content:
-            res.update({
-                'data_start': str(dataframe.iloc[0]['date']),
-                'data_start_ts': int(dataframe.iloc[0]['__date_ts']),
-                'data_stop': str(dataframe.iloc[-1]['date']),
-                'data_stop_ts': int(dataframe.iloc[-1]['__date_ts']),
-            })
+            res.update(
+                {
+                    "data_start": str(dataframe.iloc[0]["date"]),
+                    "data_start_ts": int(dataframe.iloc[0]["__date_ts"]),
+                    "data_stop": str(dataframe.iloc[-1]["date"]),
+                    "data_stop_ts": int(dataframe.iloc[-1]["__date_ts"]),
+                }
+            )
         return res
 
     def _rpc_analysed_dataframe(
-            self, pair: str, timeframe: str, limit: Optional[int],
-            selected_cols: Optional[List[str]]) -> Dict[str, Any]:
-        """ Analyzed dataframe in Dict form """
+        self, pair: str, timeframe: str, limit: Optional[int], selected_cols: Optional[List[str]]
+    ) -> Dict[str, Any]:
+        """Analyzed dataframe in Dict form"""
 
         _data, last_analyzed = self.__rpc_analysed_dataframe_raw(pair, timeframe, limit)
         return RPC._convert_dataframe_to_dict(
-            self._freqtrade.config['strategy'], pair, timeframe, _data, last_analyzed,
-            selected_cols
+            self._freqtrade.config["strategy"], pair, timeframe, _data, last_analyzed, selected_cols
         )
 
     def __rpc_analysed_dataframe_raw(
-        self,
-        pair: str,
-        timeframe: str,
-        limit: Optional[int]
+        self, pair: str, timeframe: str, limit: Optional[int]
     ) -> Tuple[DataFrame, datetime]:
         """
         Get the dataframe and last analyze from the dataprovider
 
         :param pair: The pair to get
         :param timeframe: The timeframe of data to get
         :param limit: The amount of candles in the dataframe
         """
-        _data, last_analyzed = self._freqtrade.dataprovider.get_analyzed_dataframe(
-            pair, timeframe)
+        _data, last_analyzed = self._freqtrade.dataprovider.get_analyzed_dataframe(pair, timeframe)
         _data = _data.copy()
 
         if limit:
             _data = _data.iloc[-limit:]
 
         return _data, last_analyzed
 
     def _ws_all_analysed_dataframes(
-        self,
-        pairlist: List[str],
-        limit: Optional[int]
+        self, pairlist: List[str], limit: Optional[int]
     ) -> Generator[Dict[str, Any], None, None]:
         """
         Get the analysed dataframes of each pair in the pairlist.
         If specified, only return the most recent `limit` candles for
         each dataframe.
 
         :param pairlist: A list of pairs to get
         :param limit: If an integer, limits the size of dataframe
                       If a list of string date times, only returns those candles
         :returns: A generator of dictionaries with the key, dataframe, and last analyzed timestamp
         """
-        timeframe = self._freqtrade.config['timeframe']
-        candle_type = self._freqtrade.config.get('candle_type_def', CandleType.SPOT)
+        timeframe = self._freqtrade.config["timeframe"]
+        candle_type = self._freqtrade.config.get("candle_type_def", CandleType.SPOT)
 
         for pair in pairlist:
             dataframe, last_analyzed = self.__rpc_analysed_dataframe_raw(pair, timeframe, limit)
 
-            yield {
-                "key": (pair, timeframe, candle_type),
-                "df": dataframe,
-                "la": last_analyzed
-            }
+            yield {"key": (pair, timeframe, candle_type), "df": dataframe, "la": last_analyzed}
 
-    def _ws_request_analyzed_df(
-        self,
-        limit: Optional[int] = None,
-        pair: Optional[str] = None
-    ):
-        """ Historical Analyzed Dataframes for WebSocket """
+    def _ws_request_analyzed_df(self, limit: Optional[int] = None, pair: Optional[str] = None):
+        """Historical Analyzed Dataframes for WebSocket"""
         pairlist = [pair] if pair else self._freqtrade.active_pair_whitelist
 
         return self._ws_all_analysed_dataframes(pairlist, limit)
 
     def _ws_request_whitelist(self):
-        """ Whitelist data for WebSocket """
+        """Whitelist data for WebSocket"""
         return self._freqtrade.active_pair_whitelist
 
     @staticmethod
-    def _rpc_analysed_history_full(config: Config, pair: str, timeframe: str,
-                                   exchange, selected_cols: Optional[List[str]]) -> Dict[str, Any]:
-        timerange_parsed = TimeRange.parse_timerange(config.get('timerange'))
+    def _rpc_analysed_history_full(
+        config: Config, pair: str, timeframe: str, exchange, selected_cols: Optional[List[str]]
+    ) -> Dict[str, Any]:
+        timerange_parsed = TimeRange.parse_timerange(config.get("timerange"))
 
         from freqtrade.data.converter import trim_dataframe
         from freqtrade.data.dataprovider import DataProvider
         from freqtrade.resolvers.strategy_resolver import StrategyResolver
 
         strategy = StrategyResolver.load_strategy(config)
         startup_candles = strategy.startup_candle_count
 
         _data = load_data(
             datadir=config["datadir"],
             pairs=[pair],
             timeframe=timeframe,
             timerange=timerange_parsed,
-            data_format=config['dataformat_ohlcv'],
-            candle_type=config.get('candle_type_def', CandleType.SPOT),
+            data_format=config["dataformat_ohlcv"],
+            candle_type=config.get("candle_type_def", CandleType.SPOT),
             startup_candles=startup_candles,
         )
         if pair not in _data:
             raise RPCException(
-                f"No data for {pair}, {timeframe} in {config.get('timerange')} found.")
+                f"No data for {pair}, {timeframe} in {config.get('timerange')} found."
+            )
 
         strategy.dp = DataProvider(config, exchange=exchange, pairlists=None)
         strategy.ft_bot_start()
 
-        df_analyzed = strategy.analyze_ticker(_data[pair], {'pair': pair})
+        df_analyzed = strategy.analyze_ticker(_data[pair], {"pair": pair})
         df_analyzed = trim_dataframe(df_analyzed, timerange_parsed, startup_candles=startup_candles)
 
-        return RPC._convert_dataframe_to_dict(strategy.get_strategy_name(), pair, timeframe,
-                                              df_analyzed.copy(), dt_now(),
-                                              selected_cols)
+        return RPC._convert_dataframe_to_dict(
+            strategy.get_strategy_name(),
+            pair,
+            timeframe,
+            df_analyzed.copy(),
+            dt_now(),
+            selected_cols,
+        )
 
     def _rpc_plot_config(self) -> Dict[str, Any]:
-        if (self._freqtrade.strategy.plot_config and
-                'subplots' not in self._freqtrade.strategy.plot_config):
-            self._freqtrade.strategy.plot_config['subplots'] = {}
+        if (
+            self._freqtrade.strategy.plot_config
+            and "subplots" not in self._freqtrade.strategy.plot_config
+        ):
+            self._freqtrade.strategy.plot_config["subplots"] = {}
         return self._freqtrade.strategy.plot_config
 
     @staticmethod
     def _rpc_plot_config_with_strategy(config: Config) -> Dict[str, Any]:
-
         from freqtrade.resolvers.strategy_resolver import StrategyResolver
+
         strategy = StrategyResolver.load_strategy(config)
 
-        if (strategy.plot_config and 'subplots' not in strategy.plot_config):
-            strategy.plot_config['subplots'] = {}
+        if strategy.plot_config and "subplots" not in strategy.plot_config:
+            strategy.plot_config["subplots"] = {}
         return strategy.plot_config
 
     @staticmethod
     def _rpc_sysinfo() -> Dict[str, Any]:
         return {
             "cpu_pct": psutil.cpu_percent(interval=1, percpu=True),
-            "ram_pct": psutil.virtual_memory().percent
+            "ram_pct": psutil.virtual_memory().percent,
         }
 
     def health(self) -> Dict[str, Optional[Union[str, int]]]:
         last_p = self._freqtrade.last_process
         res: Dict[str, Union[None, str, int]] = {
             "last_process": None,
             "last_process_loc": None,
@@ -1400,32 +1489,38 @@
             "bot_start_ts": None,
             "bot_startup": None,
             "bot_startup_loc": None,
             "bot_startup_ts": None,
         }
 
         if last_p is not None:
-            res.update({
-                "last_process": str(last_p),
-                "last_process_loc": format_date(last_p.astimezone(tzlocal())),
-                "last_process_ts": int(last_p.timestamp()),
-            })
-
-        if (bot_start := KeyValueStore.get_datetime_value(KeyStoreKeys.BOT_START_TIME)):
-            res.update({
-                "bot_start": str(bot_start),
-                "bot_start_loc": format_date(bot_start.astimezone(tzlocal())),
-                "bot_start_ts": int(bot_start.timestamp()),
-            })
-        if (bot_startup := KeyValueStore.get_datetime_value(KeyStoreKeys.STARTUP_TIME)):
-            res.update({
-                "bot_startup": str(bot_startup),
-                "bot_startup_loc": format_date(bot_startup.astimezone(tzlocal())),
-                "bot_startup_ts": int(bot_startup.timestamp()),
-            })
+            res.update(
+                {
+                    "last_process": str(last_p),
+                    "last_process_loc": format_date(last_p.astimezone(tzlocal())),
+                    "last_process_ts": int(last_p.timestamp()),
+                }
+            )
+
+        if bot_start := KeyValueStore.get_datetime_value(KeyStoreKeys.BOT_START_TIME):
+            res.update(
+                {
+                    "bot_start": str(bot_start),
+                    "bot_start_loc": format_date(bot_start.astimezone(tzlocal())),
+                    "bot_start_ts": int(bot_start.timestamp()),
+                }
+            )
+        if bot_startup := KeyValueStore.get_datetime_value(KeyStoreKeys.STARTUP_TIME):
+            res.update(
+                {
+                    "bot_startup": str(bot_startup),
+                    "bot_startup_loc": format_date(bot_startup.astimezone(tzlocal())),
+                    "bot_startup_ts": int(bot_startup.timestamp()),
+                }
+            )
 
         return res
 
     def _update_market_direction(self, direction: MarketDirection) -> None:
         self._freqtrade.strategy.market_direction = direction
 
     def _get_market_direction(self) -> MarketDirection:
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/rpc_manager.py` & `freqtrade-2024.5/freqtrade/rpc/rpc_manager.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 This module contains class to manage RPC communications (Telegram, API, ...)
 """
+
 import logging
 from collections import deque
 from typing import List
 
 from freqtrade.constants import Config
 from freqtrade.enums import NO_ECHO_MESSAGES, RPCMessageType
 from freqtrade.rpc import RPC, RPCHandler
@@ -16,116 +17,127 @@
 
 class RPCManager:
     """
     Class to manage RPC objects (Telegram, API, ...)
     """
 
     def __init__(self, freqtrade) -> None:
-        """ Initializes all enabled rpc modules """
+        """Initializes all enabled rpc modules"""
         self.registered_modules: List[RPCHandler] = []
         self._rpc = RPC(freqtrade)
         config = freqtrade.config
         # Enable telegram
-        if config.get('telegram', {}).get('enabled', False):
-            logger.info('Enabling rpc.telegram ...')
+        if config.get("telegram", {}).get("enabled", False):
+            logger.info("Enabling rpc.telegram ...")
             from freqtrade.rpc.telegram import Telegram
+
             self.registered_modules.append(Telegram(self._rpc, config))
 
         # Enable discord
-        if config.get('discord', {}).get('enabled', False):
-            logger.info('Enabling rpc.discord ...')
+        if config.get("discord", {}).get("enabled", False):
+            logger.info("Enabling rpc.discord ...")
             from freqtrade.rpc.discord import Discord
+
             self.registered_modules.append(Discord(self._rpc, config))
 
         # Enable Webhook
-        if config.get('webhook', {}).get('enabled', False):
-            logger.info('Enabling rpc.webhook ...')
+        if config.get("webhook", {}).get("enabled", False):
+            logger.info("Enabling rpc.webhook ...")
             from freqtrade.rpc.webhook import Webhook
+
             self.registered_modules.append(Webhook(self._rpc, config))
 
         # Enable local rest api server for cmd line control
-        if config.get('api_server', {}).get('enabled', False):
-            logger.info('Enabling rpc.api_server')
+        if config.get("api_server", {}).get("enabled", False):
+            logger.info("Enabling rpc.api_server")
             from freqtrade.rpc.api_server import ApiServer
+
             apiserver = ApiServer(config)
             apiserver.add_rpc_handler(self._rpc)
             self.registered_modules.append(apiserver)
 
     def cleanup(self) -> None:
-        """ Stops all enabled rpc modules """
-        logger.info('Cleaning up rpc modules ...')
+        """Stops all enabled rpc modules"""
+        logger.info("Cleaning up rpc modules ...")
         while self.registered_modules:
             mod = self.registered_modules.pop()
-            logger.info('Cleaning up rpc.%s ...', mod.name)
+            logger.info("Cleaning up rpc.%s ...", mod.name)
             mod.cleanup()
             del mod
 
     def send_msg(self, msg: RPCSendMsg) -> None:
         """
         Send given message to all registered rpc modules.
         A message consists of one or more key value pairs of strings.
         e.g.:
         {
             'status': 'stopping bot'
         }
         """
-        if msg.get('type') not in NO_ECHO_MESSAGES:
-            logger.info('Sending rpc message: %s', msg)
+        if msg.get("type") not in NO_ECHO_MESSAGES:
+            logger.info("Sending rpc message: %s", msg)
         for mod in self.registered_modules:
-            logger.debug('Forwarding message to rpc.%s', mod.name)
+            logger.debug("Forwarding message to rpc.%s", mod.name)
             try:
                 mod.send_msg(msg)
             except NotImplementedError:
                 logger.error(f"Message type '{msg['type']}' not implemented by handler {mod.name}.")
             except Exception:
-                logger.exception('Exception occurred within RPC module %s', mod.name)
+                logger.exception("Exception occurred within RPC module %s", mod.name)
 
     def process_msg_queue(self, queue: deque) -> None:
         """
         Process all messages in the queue.
         """
         while queue:
             msg = queue.popleft()
-            logger.info('Sending rpc strategy_msg: %s', msg)
+            logger.info("Sending rpc strategy_msg: %s", msg)
             for mod in self.registered_modules:
-                if mod._config.get(mod.name, {}).get('allow_custom_messages', False):
-                    mod.send_msg({
-                        'type': RPCMessageType.STRATEGY_MSG,
-                        'msg': msg,
-                    })
+                if mod._config.get(mod.name, {}).get("allow_custom_messages", False):
+                    mod.send_msg(
+                        {
+                            "type": RPCMessageType.STRATEGY_MSG,
+                            "msg": msg,
+                        }
+                    )
 
     def startup_messages(self, config: Config, pairlist, protections) -> None:
-        if config['dry_run']:
-            self.send_msg({
-                'type': RPCMessageType.WARNING,
-                'status': 'Dry run is enabled. All trades are simulated.'
-            })
-        stake_currency = config['stake_currency']
-        stake_amount = config['stake_amount']
-        minimal_roi = config['minimal_roi']
-        stoploss = config['stoploss']
-        trailing_stop = config['trailing_stop']
-        timeframe = config['timeframe']
-        exchange_name = config['exchange']['name']
-        strategy_name = config.get('strategy', '')
-        pos_adjust_enabled = 'On' if config['position_adjustment_enable'] else 'Off'
-        self.send_msg({
-            'type': RPCMessageType.STARTUP,
-            'status': f'*Exchange:* `{exchange_name}`\n'
-                      f'*Stake per trade:* `{stake_amount} {stake_currency}`\n'
-                      f'*Minimum ROI:* `{minimal_roi}`\n'
-                      f'*{"Trailing " if trailing_stop else ""}Stoploss:* `{stoploss}`\n'
-                      f'*Position adjustment:* `{pos_adjust_enabled}`\n'
-                      f'*Timeframe:* `{timeframe}`\n'
-                      f'*Strategy:* `{strategy_name}`'
-        })
-        self.send_msg({
-            'type': RPCMessageType.STARTUP,
-            'status': f'Searching for {stake_currency} pairs to buy and sell '
-                      f'based on {pairlist.short_desc()}'
-        })
+        if config["dry_run"]:
+            self.send_msg(
+                {
+                    "type": RPCMessageType.WARNING,
+                    "status": "Dry run is enabled. All trades are simulated.",
+                }
+            )
+        stake_currency = config["stake_currency"]
+        stake_amount = config["stake_amount"]
+        minimal_roi = config["minimal_roi"]
+        stoploss = config["stoploss"]
+        trailing_stop = config["trailing_stop"]
+        timeframe = config["timeframe"]
+        exchange_name = config["exchange"]["name"]
+        strategy_name = config.get("strategy", "")
+        pos_adjust_enabled = "On" if config["position_adjustment_enable"] else "Off"
+        self.send_msg(
+            {
+                "type": RPCMessageType.STARTUP,
+                "status": f"*Exchange:* `{exchange_name}`\n"
+                f"*Stake per trade:* `{stake_amount} {stake_currency}`\n"
+                f"*Minimum ROI:* `{minimal_roi}`\n"
+                f"*{'Trailing ' if trailing_stop else ''}Stoploss:* `{stoploss}`\n"
+                f"*Position adjustment:* `{pos_adjust_enabled}`\n"
+                f"*Timeframe:* `{timeframe}`\n"
+                f"*Strategy:* `{strategy_name}`",
+            }
+        )
+        self.send_msg(
+            {
+                "type": RPCMessageType.STARTUP,
+                "status": f"Searching for {stake_currency} pairs to buy and sell "
+                f"based on {pairlist.short_desc()}",
+            }
+        )
         if len(protections.name_list) > 0:
-            prots = '\n'.join([p for prot in protections.short_desc() for k, p in prot.items()])
-            self.send_msg({
-                'type': RPCMessageType.STARTUP,
-                'status': f'Using Protections: \n{prots}'
-            })
+            prots = "\n".join([p for prot in protections.short_desc() for k, p in prot.items()])
+            self.send_msg(
+                {"type": RPCMessageType.STARTUP, "status": f"Using Protections: \n{prots}"}
+            )
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/rpc_types.py` & `freqtrade-2024.5/freqtrade/rpc/rpc_types.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,20 +11,22 @@
 class RPCSendMsgBase(TypedDict):
     pass
     # ty1pe: Literal[RPCMessageType]
 
 
 class RPCStatusMsg(RPCSendMsgBase):
     """Used for Status, Startup and Warning messages"""
+
     type: Literal[RPCMessageType.STATUS, RPCMessageType.STARTUP, RPCMessageType.WARNING]
     status: str
 
 
 class RPCStrategyMsg(RPCSendMsgBase):
     """Used for Status, Startup and Warning messages"""
+
     type: Literal[RPCMessageType.STRATEGY_MSG]
     msg: str
 
 
 class RPCProtectionMsg(RPCSendMsgBase):
     type: Literal[RPCMessageType.PROTECTION_TRIGGER, RPCMessageType.PROTECTION_TRIGGER_GLOBAL]
     id: int
@@ -104,20 +106,22 @@
     key: PairWithTimeframe
     df: Any
     la: datetime
 
 
 class RPCAnalyzedDFMsg(RPCSendMsgBase):
     """New Analyzed dataframe message"""
+
     type: Literal[RPCMessageType.ANALYZED_DF]
     data: _AnalyzedDFData
 
 
 class RPCNewCandleMsg(RPCSendMsgBase):
     """New candle ping message, issued once per new candle/pair"""
+
     type: Literal[RPCMessageType.NEW_CANDLE]
     data: PairWithTimeframe
 
 
 RPCOrderMsg = Union[RPCEntryMsg, RPCExitMsg, RPCExitCancelMsg, RPCCancelMsg]
 
 
@@ -127,9 +131,9 @@
     RPCProtectionMsg,
     RPCWhitelistMsg,
     RPCEntryMsg,
     RPCCancelMsg,
     RPCExitMsg,
     RPCExitCancelMsg,
     RPCAnalyzedDFMsg,
-    RPCNewCandleMsg
-    ]
+    RPCNewCandleMsg,
+]
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/telegram.py` & `freqtrade-2024.5/freqtrade/rpc/telegram.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # pragma pylint: disable=unused-argument, unused-variable, protected-access, invalid-name
 
 """
 This module manage Telegram communication
 """
+
 import asyncio
 import json
 import logging
 import re
 from copy import deepcopy
 from dataclasses import dataclass
 from datetime import date, datetime, timedelta
@@ -14,16 +15,22 @@
 from html import escape
 from itertools import chain
 from math import isnan
 from threading import Thread
 from typing import Any, Callable, Coroutine, Dict, List, Literal, Optional, Union
 
 from tabulate import tabulate
-from telegram import (CallbackQuery, InlineKeyboardButton, InlineKeyboardMarkup, KeyboardButton,
-                      ReplyKeyboardMarkup, Update)
+from telegram import (
+    CallbackQuery,
+    InlineKeyboardButton,
+    InlineKeyboardMarkup,
+    KeyboardButton,
+    ReplyKeyboardMarkup,
+    Update,
+)
 from telegram.constants import MessageLimit, ParseMode
 from telegram.error import BadRequest, NetworkError, TelegramError
 from telegram.ext import Application, CallbackContext, CallbackQueryHandler, CommandHandler
 from telegram.helpers import escape_markdown
 
 from freqtrade.__init__ import __version__
 from freqtrade.constants import DUST_PER_COIN, Config
@@ -37,26 +44,27 @@
 
 
 MAX_MESSAGE_LENGTH = MessageLimit.MAX_TEXT_LENGTH
 
 
 logger = logging.getLogger(__name__)
 
-logger.debug('Included module rpc.telegram ...')
+logger.debug("Included module rpc.telegram ...")
 
 
 def safe_async_db(func: Callable[..., Any]):
     """
     Decorator to safely handle sessions when switching async context
     :param func: function to decorate
     :return: decorated function
     """
+
     @wraps(func)
     def wrapper(*args, **kwargs):
-        """ Decorator logic """
+        """Decorator logic"""
         try:
             return func(*args, **kwargs)
         finally:
             Trade.session.remove()
 
     return wrapper
 
@@ -76,48 +84,44 @@
     Decorator to check if the message comes from the correct chat_id
     :param command_handler: Telegram CommandHandler
     :return: decorated function
     """
 
     @wraps(command_handler)
     async def wrapper(self, *args, **kwargs):
-        """ Decorator logic """
-        update = kwargs.get('update') or args[0]
+        """Decorator logic"""
+        update = kwargs.get("update") or args[0]
 
         # Reject unauthorized messages
         if update.callback_query:
             cchat_id = int(update.callback_query.message.chat.id)
         else:
             cchat_id = int(update.message.chat_id)
 
-        chat_id = int(self._config['telegram']['chat_id'])
+        chat_id = int(self._config["telegram"]["chat_id"])
         if cchat_id != chat_id:
-            logger.info(f'Rejected unauthorized message from: {update.message.chat_id}')
+            logger.info(f"Rejected unauthorized message from: {update.message.chat_id}")
             return wrapper
         # Rollback session to avoid getting data stored in a transaction.
         Trade.rollback()
-        logger.debug(
-            'Executing handler: %s for chat_id: %s',
-            command_handler.__name__,
-            chat_id
-        )
+        logger.debug("Executing handler: %s for chat_id: %s", command_handler.__name__, chat_id)
         try:
             return await command_handler(self, *args, **kwargs)
         except RPCException as e:
             await self._send_msg(str(e))
         except BaseException:
-            logger.exception('Exception occurred within Telegram module')
+            logger.exception("Exception occurred within Telegram module")
         finally:
             Trade.session.remove()
 
     return wrapper
 
 
 class Telegram(RPCHandler):
-    """  This class handles all telegram communication """
+    """This class handles all telegram communication"""
 
     def __init__(self, rpc: RPC, config: Config) -> None:
         """
         Init the Telegram call, and init the super class RPCHandler
         :param rpc: instance of RPC Helper class
         :param config: Configuration object
         :return: None
@@ -129,68 +133,100 @@
         self._init_keyboard()
         self._start_thread()
 
     def _start_thread(self):
         """
         Creates and starts the polling thread
         """
-        self._thread = Thread(target=self._init, name='FTTelegram')
+        self._thread = Thread(target=self._init, name="FTTelegram")
         self._thread.start()
 
     def _init_keyboard(self) -> None:
         """
         Validates the keyboard configuration from telegram config
         section.
         """
         self._keyboard: List[List[Union[str, KeyboardButton]]] = [
-            ['/daily', '/profit', '/balance'],
-            ['/status', '/status table', '/performance'],
-            ['/count', '/start', '/stop', '/help']
+            ["/daily", "/profit", "/balance"],
+            ["/status", "/status table", "/performance"],
+            ["/count", "/start", "/stop", "/help"],
         ]
         # do not allow commands with mandatory arguments and critical cmds
         # TODO: DRY! - its not good to list all valid cmds here. But otherwise
         #       this needs refactoring of the whole telegram module (same
         #       problem in _help()).
         valid_keys: List[str] = [
-            r'/start$', r'/stop$', r'/status$', r'/status table$',
-            r'/trades$', r'/performance$', r'/buys', r'/entries',
-            r'/sells', r'/exits', r'/mix_tags',
-            r'/daily$', r'/daily \d+$', r'/profit$', r'/profit \d+',
-            r'/stats$', r'/count$', r'/locks$', r'/balance$',
-            r'/stopbuy$', r'/stopentry$', r'/reload_config$', r'/show_config$',
-            r'/logs$', r'/whitelist$', r'/whitelist(\ssorted|\sbaseonly)+$',
-            r'/blacklist$', r'/bl_delete$',
-            r'/weekly$', r'/weekly \d+$', r'/monthly$', r'/monthly \d+$',
-            r'/forcebuy$', r'/forcelong$', r'/forceshort$',
-            r'/forcesell$', r'/forceexit$',
-            r'/edge$', r'/health$', r'/help$', r'/version$', r'/marketdir (long|short|even|none)$',
-            r'/marketdir$'
+            r"/start$",
+            r"/stop$",
+            r"/status$",
+            r"/status table$",
+            r"/trades$",
+            r"/performance$",
+            r"/buys",
+            r"/entries",
+            r"/sells",
+            r"/exits",
+            r"/mix_tags",
+            r"/daily$",
+            r"/daily \d+$",
+            r"/profit$",
+            r"/profit \d+",
+            r"/stats$",
+            r"/count$",
+            r"/locks$",
+            r"/balance$",
+            r"/stopbuy$",
+            r"/stopentry$",
+            r"/reload_config$",
+            r"/show_config$",
+            r"/logs$",
+            r"/whitelist$",
+            r"/whitelist(\ssorted|\sbaseonly)+$",
+            r"/blacklist$",
+            r"/bl_delete$",
+            r"/weekly$",
+            r"/weekly \d+$",
+            r"/monthly$",
+            r"/monthly \d+$",
+            r"/forcebuy$",
+            r"/forcelong$",
+            r"/forceshort$",
+            r"/forcesell$",
+            r"/forceexit$",
+            r"/edge$",
+            r"/health$",
+            r"/help$",
+            r"/version$",
+            r"/marketdir (long|short|even|none)$",
+            r"/marketdir$",
         ]
         # Create keys for generation
-        valid_keys_print = [k.replace('$', '') for k in valid_keys]
+        valid_keys_print = [k.replace("$", "") for k in valid_keys]
 
         # custom keyboard specified in config.json
-        cust_keyboard = self._config['telegram'].get('keyboard', [])
+        cust_keyboard = self._config["telegram"].get("keyboard", [])
         if cust_keyboard:
             combined = "(" + ")|(".join(valid_keys) + ")"
             # check for valid shortcuts
-            invalid_keys = [b for b in chain.from_iterable(cust_keyboard)
-                            if not re.match(combined, b)]
+            invalid_keys = [
+                b for b in chain.from_iterable(cust_keyboard) if not re.match(combined, b)
+            ]
             if len(invalid_keys):
-                err_msg = ('config.telegram.keyboard: Invalid commands for '
-                           f'custom Telegram keyboard: {invalid_keys}'
-                           f'\nvalid commands are: {valid_keys_print}')
+                err_msg = (
+                    "config.telegram.keyboard: Invalid commands for "
+                    f"custom Telegram keyboard: {invalid_keys}"
+                    f"\nvalid commands are: {valid_keys_print}"
+                )
                 raise OperationalException(err_msg)
             else:
                 self._keyboard = cust_keyboard
-                logger.info('using custom keyboard from '
-                            f'config.json: {self._keyboard}')
+                logger.info(f"using custom keyboard from config.json: {self._keyboard}")
 
     def _init_telegram_app(self):
-        return Application.builder().token(self._config['telegram']['token']).build()
+        return Application.builder().token(self._config["telegram"]["token"]).build()
 
     def _init(self) -> None:
         """
         Initializes this module with the given config,
         registers all known command handlers
         and starts polling for message updates
         Runs in a separate thread.
@@ -201,80 +237,85 @@
             self._loop = asyncio.new_event_loop()
             asyncio.set_event_loop(self._loop)
 
         self._app = self._init_telegram_app()
 
         # Register command handler and start telegram message polling
         handles = [
-            CommandHandler('status', self._status),
-            CommandHandler('profit', self._profit),
-            CommandHandler('balance', self._balance),
-            CommandHandler('start', self._start),
-            CommandHandler('stop', self._stop),
-            CommandHandler(['forcesell', 'forceexit', 'fx'], self._force_exit),
-            CommandHandler(['forcebuy', 'forcelong'], partial(
-                self._force_enter, order_side=SignalDirection.LONG)),
-            CommandHandler('forceshort', partial(
-                self._force_enter, order_side=SignalDirection.SHORT)),
-            CommandHandler('reload_trade', self._reload_trade_from_exchange),
-            CommandHandler('trades', self._trades),
-            CommandHandler('delete', self._delete_trade),
-            CommandHandler(['coo', 'cancel_open_order'], self._cancel_open_order),
-            CommandHandler('performance', self._performance),
-            CommandHandler(['buys', 'entries'], self._enter_tag_performance),
-            CommandHandler(['sells', 'exits'], self._exit_reason_performance),
-            CommandHandler('mix_tags', self._mix_tag_performance),
-            CommandHandler('stats', self._stats),
-            CommandHandler('daily', self._daily),
-            CommandHandler('weekly', self._weekly),
-            CommandHandler('monthly', self._monthly),
-            CommandHandler('count', self._count),
-            CommandHandler('locks', self._locks),
-            CommandHandler(['unlock', 'delete_locks'], self._delete_locks),
-            CommandHandler(['reload_config', 'reload_conf'], self._reload_config),
-            CommandHandler(['show_config', 'show_conf'], self._show_config),
-            CommandHandler(['stopbuy', 'stopentry'], self._stopentry),
-            CommandHandler('whitelist', self._whitelist),
-            CommandHandler('blacklist', self._blacklist),
-            CommandHandler(['blacklist_delete', 'bl_delete'], self._blacklist_delete),
-            CommandHandler('logs', self._logs),
-            CommandHandler('edge', self._edge),
-            CommandHandler('health', self._health),
-            CommandHandler('help', self._help),
-            CommandHandler('version', self._version),
-            CommandHandler('marketdir', self._changemarketdir),
-            CommandHandler('order', self._order),
-            CommandHandler('list_custom_data', self._list_custom_data),
+            CommandHandler("status", self._status),
+            CommandHandler("profit", self._profit),
+            CommandHandler("balance", self._balance),
+            CommandHandler("start", self._start),
+            CommandHandler("stop", self._stop),
+            CommandHandler(["forcesell", "forceexit", "fx"], self._force_exit),
+            CommandHandler(
+                ["forcebuy", "forcelong"],
+                partial(self._force_enter, order_side=SignalDirection.LONG),
+            ),
+            CommandHandler(
+                "forceshort", partial(self._force_enter, order_side=SignalDirection.SHORT)
+            ),
+            CommandHandler("reload_trade", self._reload_trade_from_exchange),
+            CommandHandler("trades", self._trades),
+            CommandHandler("delete", self._delete_trade),
+            CommandHandler(["coo", "cancel_open_order"], self._cancel_open_order),
+            CommandHandler("performance", self._performance),
+            CommandHandler(["buys", "entries"], self._enter_tag_performance),
+            CommandHandler(["sells", "exits"], self._exit_reason_performance),
+            CommandHandler("mix_tags", self._mix_tag_performance),
+            CommandHandler("stats", self._stats),
+            CommandHandler("daily", self._daily),
+            CommandHandler("weekly", self._weekly),
+            CommandHandler("monthly", self._monthly),
+            CommandHandler("count", self._count),
+            CommandHandler("locks", self._locks),
+            CommandHandler(["unlock", "delete_locks"], self._delete_locks),
+            CommandHandler(["reload_config", "reload_conf"], self._reload_config),
+            CommandHandler(["show_config", "show_conf"], self._show_config),
+            CommandHandler(["stopbuy", "stopentry"], self._stopentry),
+            CommandHandler("whitelist", self._whitelist),
+            CommandHandler("blacklist", self._blacklist),
+            CommandHandler(["blacklist_delete", "bl_delete"], self._blacklist_delete),
+            CommandHandler("logs", self._logs),
+            CommandHandler("edge", self._edge),
+            CommandHandler("health", self._health),
+            CommandHandler("help", self._help),
+            CommandHandler("version", self._version),
+            CommandHandler("marketdir", self._changemarketdir),
+            CommandHandler("order", self._order),
+            CommandHandler("list_custom_data", self._list_custom_data),
         ]
         callbacks = [
-            CallbackQueryHandler(self._status_table, pattern='update_status_table'),
-            CallbackQueryHandler(self._daily, pattern='update_daily'),
-            CallbackQueryHandler(self._weekly, pattern='update_weekly'),
-            CallbackQueryHandler(self._monthly, pattern='update_monthly'),
-            CallbackQueryHandler(self._profit, pattern='update_profit'),
-            CallbackQueryHandler(self._balance, pattern='update_balance'),
-            CallbackQueryHandler(self._performance, pattern='update_performance'),
-            CallbackQueryHandler(self._enter_tag_performance,
-                                 pattern='update_enter_tag_performance'),
-            CallbackQueryHandler(self._exit_reason_performance,
-                                 pattern='update_exit_reason_performance'),
-            CallbackQueryHandler(self._mix_tag_performance, pattern='update_mix_tag_performance'),
-            CallbackQueryHandler(self._count, pattern='update_count'),
+            CallbackQueryHandler(self._status_table, pattern="update_status_table"),
+            CallbackQueryHandler(self._daily, pattern="update_daily"),
+            CallbackQueryHandler(self._weekly, pattern="update_weekly"),
+            CallbackQueryHandler(self._monthly, pattern="update_monthly"),
+            CallbackQueryHandler(self._profit, pattern="update_profit"),
+            CallbackQueryHandler(self._balance, pattern="update_balance"),
+            CallbackQueryHandler(self._performance, pattern="update_performance"),
+            CallbackQueryHandler(
+                self._enter_tag_performance, pattern="update_enter_tag_performance"
+            ),
+            CallbackQueryHandler(
+                self._exit_reason_performance, pattern="update_exit_reason_performance"
+            ),
+            CallbackQueryHandler(self._mix_tag_performance, pattern="update_mix_tag_performance"),
+            CallbackQueryHandler(self._count, pattern="update_count"),
             CallbackQueryHandler(self._force_exit_inline, pattern=r"force_exit__\S+"),
             CallbackQueryHandler(self._force_enter_inline, pattern=r"force_enter__\S+"),
         ]
         for handle in handles:
             self._app.add_handler(handle)
 
         for callback in callbacks:
             self._app.add_handler(callback)
 
         logger.info(
-            'rpc.telegram is listening for following commands: %s',
-            [[x for x in sorted(h.commands)] for h in handles]
+            "rpc.telegram is listening for following commands: %s",
+            [[x for x in sorted(h.commands)] for h in handles],
         )
         self._loop.run_until_complete(self._startup_telegram())
 
     async def _startup_telegram(self) -> None:
         await self._app.initialize()
         await self._app.start()
         if self._app.updater:
@@ -310,278 +351,291 @@
         Extracts the exchange name from the given message.
         :param msg: The message to extract the exchange name from.
         :return: The exchange name.
         """
         return f"{msg['exchange']}{' (dry)' if self._config['dry_run'] else ''}"
 
     def _add_analyzed_candle(self, pair: str) -> str:
-        candle_val = self._config['telegram'].get(
-            'notification_settings', {}).get('show_candle', 'off')
-        if candle_val != 'off':
-            if candle_val == 'ohlc':
+        candle_val = (
+            self._config["telegram"].get("notification_settings", {}).get("show_candle", "off")
+        )
+        if candle_val != "off":
+            if candle_val == "ohlc":
                 analyzed_df, _ = self._rpc._freqtrade.dataprovider.get_analyzed_dataframe(
-                    pair, self._config['timeframe'])
+                    pair, self._config["timeframe"]
+                )
                 candle = analyzed_df.iloc[-1].squeeze() if len(analyzed_df) > 0 else None
                 if candle is not None:
                     return (
                         f"*Candle OHLC*: `{candle['open']}, {candle['high']}, "
                         f"{candle['low']}, {candle['close']}`\n"
                     )
 
-        return ''
+        return ""
 
     def _format_entry_msg(self, msg: RPCEntryMsg) -> str:
-
-        is_fill = msg['type'] in [RPCMessageType.ENTRY_FILL]
-        emoji = '\N{CHECK MARK}' if is_fill else '\N{LARGE BLUE CIRCLE}'
+        is_fill = msg["type"] in [RPCMessageType.ENTRY_FILL]
+        emoji = "\N{CHECK MARK}" if is_fill else "\N{LARGE BLUE CIRCLE}"
 
         terminology = {
-            '1_enter': 'New Trade',
-            '1_entered': 'New Trade filled',
-            'x_enter': 'Increasing position',
-            'x_entered': 'Position increase filled',
+            "1_enter": "New Trade",
+            "1_entered": "New Trade filled",
+            "x_enter": "Increasing position",
+            "x_entered": "Position increase filled",
         }
 
         key = f"{'x' if msg['sub_trade'] else '1'}_{'entered' if is_fill else 'enter'}"
         wording = terminology[key]
 
         message = (
             f"{emoji} *{self._exchange_from_msg(msg)}:*"
             f" {wording} (#{msg['trade_id']})\n"
             f"*Pair:* `{msg['pair']}`\n"
         )
-        message += self._add_analyzed_candle(msg['pair'])
-        message += f"*Enter Tag:* `{msg['enter_tag']}`\n" if msg.get('enter_tag') else ""
+        message += self._add_analyzed_candle(msg["pair"])
+        message += f"*Enter Tag:* `{msg['enter_tag']}`\n" if msg.get("enter_tag") else ""
         message += f"*Amount:* `{round_value(msg['amount'], 8)}`\n"
         message += f"*Direction:* `{msg['direction']}"
-        if msg.get('leverage') and msg.get('leverage', 1.0) != 1.0:
+        if msg.get("leverage") and msg.get("leverage", 1.0) != 1.0:
             message += f" ({msg['leverage']:.3g}x)"
         message += "`\n"
         message += f"*Open Rate:* `{round_value(msg['open_rate'], 8)} {msg['quote_currency']}`\n"
-        if msg['type'] == RPCMessageType.ENTRY and msg['current_rate']:
+        if msg["type"] == RPCMessageType.ENTRY and msg["current_rate"]:
             message += (
                 f"*Current Rate:* `{round_value(msg['current_rate'], 8)} {msg['quote_currency']}`\n"
             )
 
-        profit_fiat_extra = self.__format_profit_fiat(msg, 'stake_amount')  # type: ignore
-        total = fmt_coin(msg['stake_amount'], msg['quote_currency'])
+        profit_fiat_extra = self.__format_profit_fiat(msg, "stake_amount")  # type: ignore
+        total = fmt_coin(msg["stake_amount"], msg["quote_currency"])
 
         message += f"*{'New ' if msg['sub_trade'] else ''}Total:* `{total}{profit_fiat_extra}`"
 
         return message
 
     def _format_exit_msg(self, msg: RPCExitMsg) -> str:
-        duration = msg['close_date'].replace(
-            microsecond=0) - msg['open_date'].replace(microsecond=0)
+        duration = msg["close_date"].replace(microsecond=0) - msg["open_date"].replace(
+            microsecond=0
+        )
         duration_min = duration.total_seconds() / 60
 
-        leverage_text = (f" ({msg['leverage']:.3g}x)"
-                         if msg.get('leverage') and msg.get('leverage', 1.0) != 1.0
-                         else "")
+        leverage_text = (
+            f" ({msg['leverage']:.3g}x)"
+            if msg.get("leverage") and msg.get("leverage", 1.0) != 1.0
+            else ""
+        )
 
-        profit_fiat_extra = self.__format_profit_fiat(msg, 'profit_amount')
+        profit_fiat_extra = self.__format_profit_fiat(msg, "profit_amount")
 
         profit_extra = (
             f" ({msg['gain']}: {fmt_coin(msg['profit_amount'], msg['quote_currency'])}"
-            f"{profit_fiat_extra})")
+            f"{profit_fiat_extra})"
+        )
 
-        is_fill = msg['type'] == RPCMessageType.EXIT_FILL
-        is_sub_trade = msg.get('sub_trade')
-        is_sub_profit = msg['profit_amount'] != msg.get('cumulative_profit')
-        is_final_exit = msg.get('is_final_exit', False) and is_sub_profit
-        profit_prefix = 'Sub ' if is_sub_trade else ''
-        cp_extra = ''
-        exit_wording = 'Exited' if is_fill else 'Exiting'
+        is_fill = msg["type"] == RPCMessageType.EXIT_FILL
+        is_sub_trade = msg.get("sub_trade")
+        is_sub_profit = msg["profit_amount"] != msg.get("cumulative_profit")
+        is_final_exit = msg.get("is_final_exit", False) and is_sub_profit
+        profit_prefix = "Sub " if is_sub_trade else ""
+        cp_extra = ""
+        exit_wording = "Exited" if is_fill else "Exiting"
         if is_sub_trade or is_final_exit:
-            cp_fiat = self.__format_profit_fiat(msg, 'cumulative_profit')
+            cp_fiat = self.__format_profit_fiat(msg, "cumulative_profit")
 
             if is_final_exit:
-                profit_prefix = 'Sub '
+                profit_prefix = "Sub "
                 cp_extra = (
                     f"*Final Profit:* `{msg['final_profit_ratio']:.2%} "
                     f"({msg['cumulative_profit']:.8f} {msg['quote_currency']}{cp_fiat})`\n"
                 )
             else:
                 exit_wording = f"Partially {exit_wording.lower()}"
-                if msg['cumulative_profit']:
+                if msg["cumulative_profit"]:
                     cp_extra = (
                         f"*Cumulative Profit:* `"
                         f"{fmt_coin(msg['cumulative_profit'], msg['stake_currency'])}{cp_fiat}`\n"
                     )
-        enter_tag = f"*Enter Tag:* `{msg['enter_tag']}`\n" if msg.get('enter_tag') else ""
+        enter_tag = f"*Enter Tag:* `{msg['enter_tag']}`\n" if msg.get("enter_tag") else ""
         message = (
             f"{self._get_exit_emoji(msg)} *{self._exchange_from_msg(msg)}:* "
             f"{exit_wording} {msg['pair']} (#{msg['trade_id']})\n"
             f"{self._add_analyzed_candle(msg['pair'])}"
             f"*{f'{profit_prefix}Profit' if is_fill else f'Unrealized {profit_prefix}Profit'}:* "
             f"`{msg['profit_ratio']:.2%}{profit_extra}`\n"
             f"{cp_extra}"
             f"{enter_tag}"
             f"*Exit Reason:* `{msg['exit_reason']}`\n"
             f"*Direction:* `{msg['direction']}"
             f"{leverage_text}`\n"
             f"*Amount:* `{round_value(msg['amount'], 8)}`\n"
             f"*Open Rate:* `{fmt_coin(msg['open_rate'], msg['quote_currency'])}`\n"
         )
-        if msg['type'] == RPCMessageType.EXIT and msg['current_rate']:
+        if msg["type"] == RPCMessageType.EXIT and msg["current_rate"]:
             message += f"*Current Rate:* `{fmt_coin(msg['current_rate'], msg['quote_currency'])}`\n"
-            if msg['order_rate']:
+            if msg["order_rate"]:
                 message += f"*Exit Rate:* `{fmt_coin(msg['order_rate'], msg['quote_currency'])}`"
-        elif msg['type'] == RPCMessageType.EXIT_FILL:
+        elif msg["type"] == RPCMessageType.EXIT_FILL:
             message += f"*Exit Rate:* `{fmt_coin(msg['close_rate'], msg['quote_currency'])}`"
 
         if is_sub_trade:
-            stake_amount_fiat = self.__format_profit_fiat(msg, 'stake_amount')
+            stake_amount_fiat = self.__format_profit_fiat(msg, "stake_amount")
 
-            rem = fmt_coin(msg['stake_amount'], msg['quote_currency'])
+            rem = fmt_coin(msg["stake_amount"], msg["quote_currency"])
             message += f"\n*Remaining:* `{rem}{stake_amount_fiat}`"
         else:
             message += f"\n*Duration:* `{duration} ({duration_min:.1f} min)`"
         return message
 
     def __format_profit_fiat(
-            self,
-            msg: RPCExitMsg,
-            key: Literal['stake_amount', 'profit_amount', 'cumulative_profit']
+        self, msg: RPCExitMsg, key: Literal["stake_amount", "profit_amount", "cumulative_profit"]
     ) -> str:
         """
         Format Fiat currency to append to regular profit output
         """
-        profit_fiat_extra = ''
-        if self._rpc._fiat_converter and (fiat_currency := msg.get('fiat_currency')):
+        profit_fiat_extra = ""
+        if self._rpc._fiat_converter and (fiat_currency := msg.get("fiat_currency")):
             profit_fiat = self._rpc._fiat_converter.convert_amount(
-                    msg[key], msg['stake_currency'], fiat_currency)
+                msg[key], msg["stake_currency"], fiat_currency
+            )
             profit_fiat_extra = f" / {profit_fiat:.3f} {fiat_currency}"
         return profit_fiat_extra
 
     def compose_message(self, msg: RPCSendMsg) -> Optional[str]:
-        if msg['type'] == RPCMessageType.ENTRY or msg['type'] == RPCMessageType.ENTRY_FILL:
+        if msg["type"] == RPCMessageType.ENTRY or msg["type"] == RPCMessageType.ENTRY_FILL:
             message = self._format_entry_msg(msg)
 
-        elif msg['type'] == RPCMessageType.EXIT or msg['type'] == RPCMessageType.EXIT_FILL:
+        elif msg["type"] == RPCMessageType.EXIT or msg["type"] == RPCMessageType.EXIT_FILL:
             message = self._format_exit_msg(msg)
 
         elif (
-            msg['type'] == RPCMessageType.ENTRY_CANCEL
-            or msg['type'] == RPCMessageType.EXIT_CANCEL
+            msg["type"] == RPCMessageType.ENTRY_CANCEL or msg["type"] == RPCMessageType.EXIT_CANCEL
         ):
-            message_side = 'enter' if msg['type'] == RPCMessageType.ENTRY_CANCEL else 'exit'
-            message = (f"\N{WARNING SIGN} *{self._exchange_from_msg(msg)}:* "
-                       f"Cancelling {'partial ' if msg.get('sub_trade') else ''}"
-                       f"{message_side} Order for {msg['pair']} "
-                       f"(#{msg['trade_id']}). Reason: {msg['reason']}.")
+            message_side = "enter" if msg["type"] == RPCMessageType.ENTRY_CANCEL else "exit"
+            message = (
+                f"\N{WARNING SIGN} *{self._exchange_from_msg(msg)}:* "
+                f"Cancelling {'partial ' if msg.get('sub_trade') else ''}"
+                f"{message_side} Order for {msg['pair']} "
+                f"(#{msg['trade_id']}). Reason: {msg['reason']}."
+            )
 
-        elif msg['type'] == RPCMessageType.PROTECTION_TRIGGER:
+        elif msg["type"] == RPCMessageType.PROTECTION_TRIGGER:
             message = (
                 f"*Protection* triggered due to {msg['reason']}. "
                 f"`{msg['pair']}` will be locked until `{msg['lock_end_time']}`."
             )
 
-        elif msg['type'] == RPCMessageType.PROTECTION_TRIGGER_GLOBAL:
+        elif msg["type"] == RPCMessageType.PROTECTION_TRIGGER_GLOBAL:
             message = (
                 f"*Protection* triggered due to {msg['reason']}. "
                 f"*All pairs* will be locked until `{msg['lock_end_time']}`."
             )
 
-        elif msg['type'] == RPCMessageType.STATUS:
+        elif msg["type"] == RPCMessageType.STATUS:
             message = f"*Status:* `{msg['status']}`"
 
-        elif msg['type'] == RPCMessageType.WARNING:
+        elif msg["type"] == RPCMessageType.WARNING:
             message = f"\N{WARNING SIGN} *Warning:* `{msg['status']}`"
-        elif msg['type'] == RPCMessageType.EXCEPTION:
+        elif msg["type"] == RPCMessageType.EXCEPTION:
             # Errors will contain exceptions, which are wrapped in triple ticks.
             message = f"\N{WARNING SIGN} *ERROR:* \n {msg['status']}"
 
-        elif msg['type'] == RPCMessageType.STARTUP:
+        elif msg["type"] == RPCMessageType.STARTUP:
             message = f"{msg['status']}"
-        elif msg['type'] == RPCMessageType.STRATEGY_MSG:
+        elif msg["type"] == RPCMessageType.STRATEGY_MSG:
             message = f"{msg['msg']}"
         else:
-            logger.debug("Unknown message type: %s", msg['type'])
+            logger.debug("Unknown message type: %s", msg["type"])
             return None
         return message
 
     def send_msg(self, msg: RPCSendMsg) -> None:
-        """ Send a message to telegram channel """
+        """Send a message to telegram channel"""
 
-        default_noti = 'on'
+        default_noti = "on"
 
-        msg_type = msg['type']
-        noti = ''
-        if msg['type'] == RPCMessageType.EXIT:
-            sell_noti = self._config['telegram'] \
-                .get('notification_settings', {}).get(str(msg_type), {})
+        msg_type = msg["type"]
+        noti = ""
+        if msg["type"] == RPCMessageType.EXIT:
+            sell_noti = (
+                self._config["telegram"].get("notification_settings", {}).get(str(msg_type), {})
+            )
             # For backward compatibility sell still can be string
             if isinstance(sell_noti, str):
                 noti = sell_noti
             else:
-                noti = sell_noti.get(str(msg['exit_reason']), default_noti)
+                noti = sell_noti.get(str(msg["exit_reason"]), default_noti)
         else:
-            noti = self._config['telegram'] \
-                .get('notification_settings', {}).get(str(msg_type), default_noti)
+            noti = (
+                self._config["telegram"]
+                .get("notification_settings", {})
+                .get(str(msg_type), default_noti)
+            )
 
-        if noti == 'off':
+        if noti == "off":
             logger.info(f"Notification '{msg_type}' not sent.")
             # Notification disabled
             return
 
         message = self.compose_message(deepcopy(msg))
         if message:
             asyncio.run_coroutine_threadsafe(
-                self._send_msg(message, disable_notification=(noti == 'silent')),
-                self._loop)
+                self._send_msg(message, disable_notification=(noti == "silent")), self._loop
+            )
 
     def _get_exit_emoji(self, msg):
         """
         Get emoji for exit-messages
         """
 
-        if float(msg['profit_ratio']) >= 0.05:
+        if float(msg["profit_ratio"]) >= 0.05:
             return "\N{ROCKET}"
-        elif float(msg['profit_ratio']) >= 0.0:
+        elif float(msg["profit_ratio"]) >= 0.0:
             return "\N{EIGHT SPOKED ASTERISK}"
-        elif msg['exit_reason'] == "stop_loss":
+        elif msg["exit_reason"] == "stop_loss":
             return "\N{WARNING SIGN}"
         else:
             return "\N{CROSS MARK}"
 
     def _prepare_order_details(self, filled_orders: List, quote_currency: str, is_open: bool):
         """
         Prepare details of trade with entry adjustment enabled
         """
         lines_detail: List[str] = []
         if len(filled_orders) > 0:
             first_avg = filled_orders[0]["safe_price"]
         order_nr = 0
         for order in filled_orders:
             lines: List[str] = []
-            if order['is_open'] is True:
+            if order["is_open"] is True:
                 continue
             order_nr += 1
-            wording = 'Entry' if order['ft_is_entry'] else 'Exit'
+            wording = "Entry" if order["ft_is_entry"] else "Exit"
 
             cur_entry_amount = order["filled"] or order["amount"]
             cur_entry_average = order["safe_price"]
             lines.append("  ")
             lines.append(f"*{wording} #{order_nr}:*")
             if order_nr == 1:
                 lines.append(
                     f"*Amount:* {round_value(cur_entry_amount, 8)} "
                     f"({fmt_coin(order['cost'], quote_currency)})"
                 )
                 lines.append(f"*Average Price:* {round_value(cur_entry_average, 8)}")
             else:
                 # TODO: This calculation ignores fees.
-                price_to_1st_entry = ((cur_entry_average - first_avg) / first_avg)
+                price_to_1st_entry = (cur_entry_average - first_avg) / first_avg
                 if is_open:
                     lines.append("({})".format(dt_humanize_delta(order["order_filled_date"])))
-                lines.append(f"*Amount:* {round_value(cur_entry_amount, 8)} "
-                             f"({fmt_coin(order['cost'], quote_currency)})")
-                lines.append(f"*Average {wording} Price:* {round_value(cur_entry_average, 8)} "
-                             f"({price_to_1st_entry:.2%} from 1st entry rate)")
+                lines.append(
+                    f"*Amount:* {round_value(cur_entry_amount, 8)} "
+                    f"({fmt_coin(order['cost'], quote_currency)})"
+                )
+                lines.append(
+                    f"*Average {wording} Price:* {round_value(cur_entry_average, 8)} "
+                    f"({price_to_1st_entry:.2%} from 1st entry rate)"
+                )
                 lines.append(f"*Order Filled:* {order['order_filled_date']}")
 
             lines_detail.append("\n".join(lines))
 
         return lines_detail
 
     @authorized_only
@@ -596,50 +650,49 @@
 
         trade_ids = []
         if context.args and len(context.args) > 0:
             trade_ids = [int(i) for i in context.args if i.isnumeric()]
 
         results = self._rpc._rpc_trade_status(trade_ids=trade_ids)
         for r in results:
-            lines = [
-                "*Order List for Trade #*`{trade_id}`"
-            ]
+            lines = ["*Order List for Trade #*`{trade_id}`"]
 
             lines_detail = self._prepare_order_details(
-                r['orders'], r['quote_currency'], r['is_open'])
+                r["orders"], r["quote_currency"], r["is_open"]
+            )
             lines.extend(lines_detail if lines_detail else "")
             await self.__send_order_msg(lines, r)
 
     async def __send_order_msg(self, lines: List[str], r: Dict[str, Any]) -> None:
         """
         Send status message.
         """
-        msg = ''
+        msg = ""
 
         for line in lines:
             if line:
                 if (len(msg) + len(line) + 1) < MAX_MESSAGE_LENGTH:
-                    msg += line + '\n'
+                    msg += line + "\n"
                 else:
                     await self._send_msg(msg.format(**r))
-                    msg = "*Order List for Trade #*`{trade_id}` - continued\n" + line + '\n'
+                    msg = "*Order List for Trade #*`{trade_id}` - continued\n" + line + "\n"
 
         await self._send_msg(msg.format(**r))
 
     @authorized_only
     async def _status(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /status.
         Returns the current TradeThread status
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
 
-        if context.args and 'table' in context.args:
+        if context.args and "table" in context.args:
             await self._status_table(update, context)
             return
         else:
             await self._status_msg(update, context)
 
     async def _status_msg(self, update: Update, context: CallbackContext) -> None:
         """
@@ -649,410 +702,461 @@
         # Check if there's at least one numerical ID provided.
         # If so, try to get only these trades.
         trade_ids = []
         if context.args and len(context.args) > 0:
             trade_ids = [int(i) for i in context.args if i.isnumeric()]
 
         results = self._rpc._rpc_trade_status(trade_ids=trade_ids)
-        position_adjust = self._config.get('position_adjustment_enable', False)
-        max_entries = self._config.get('max_entry_position_adjustment', -1)
+        position_adjust = self._config.get("position_adjustment_enable", False)
+        max_entries = self._config.get("max_entry_position_adjustment", -1)
         for r in results:
-            r['open_date_hum'] = dt_humanize_delta(r['open_date'])
-            r['num_entries'] = len([o for o in r['orders'] if o['ft_is_entry']])
-            r['num_exits'] = len([o for o in r['orders'] if not o['ft_is_entry']
-                                 and not o['ft_order_side'] == 'stoploss'])
-            r['exit_reason'] = r.get('exit_reason', "")
-            r['stake_amount_r'] = fmt_coin(r['stake_amount'], r['quote_currency'])
-            r['max_stake_amount_r'] = fmt_coin(
-                r['max_stake_amount'] or r['stake_amount'], r['quote_currency'])
-            r['profit_abs_r'] = fmt_coin(r['profit_abs'], r['quote_currency'])
-            r['realized_profit_r'] = fmt_coin(r['realized_profit'], r['quote_currency'])
-            r['total_profit_abs_r'] = fmt_coin(
-                r['total_profit_abs'], r['quote_currency'])
+            r["open_date_hum"] = dt_humanize_delta(r["open_date"])
+            r["num_entries"] = len([o for o in r["orders"] if o["ft_is_entry"]])
+            r["num_exits"] = len(
+                [
+                    o
+                    for o in r["orders"]
+                    if not o["ft_is_entry"] and not o["ft_order_side"] == "stoploss"
+                ]
+            )
+            r["exit_reason"] = r.get("exit_reason", "")
+            r["stake_amount_r"] = fmt_coin(r["stake_amount"], r["quote_currency"])
+            r["max_stake_amount_r"] = fmt_coin(
+                r["max_stake_amount"] or r["stake_amount"], r["quote_currency"]
+            )
+            r["profit_abs_r"] = fmt_coin(r["profit_abs"], r["quote_currency"])
+            r["realized_profit_r"] = fmt_coin(r["realized_profit"], r["quote_currency"])
+            r["total_profit_abs_r"] = fmt_coin(r["total_profit_abs"], r["quote_currency"])
             lines = [
-                "*Trade ID:* `{trade_id}`" +
-                (" `(since {open_date_hum})`" if r['is_open'] else ""),
+                "*Trade ID:* `{trade_id}`" + (" `(since {open_date_hum})`" if r["is_open"] else ""),
                 "*Current Pair:* {pair}",
-                f"*Direction:* {'`Short`' if r.get('is_short') else '`Long`'}"
-                + " ` ({leverage}x)`" if r.get('leverage') else "",
+                (
+                    f"*Direction:* {'`Short`' if r.get('is_short') else '`Long`'}"
+                    + " ` ({leverage}x)`"
+                    if r.get("leverage")
+                    else ""
+                ),
                 "*Amount:* `{amount} ({stake_amount_r})`",
                 "*Total invested:* `{max_stake_amount_r}`" if position_adjust else "",
-                "*Enter Tag:* `{enter_tag}`" if r['enter_tag'] else "",
-                "*Exit Reason:* `{exit_reason}`" if r['exit_reason'] else "",
+                "*Enter Tag:* `{enter_tag}`" if r["enter_tag"] else "",
+                "*Exit Reason:* `{exit_reason}`" if r["exit_reason"] else "",
             ]
 
             if position_adjust:
-                max_buy_str = (f"/{max_entries + 1}" if (max_entries > 0) else "")
-                lines.extend([
-                    "*Number of Entries:* `{num_entries}" + max_buy_str + "`",
-                    "*Number of Exits:* `{num_exits}`"
-                ])
-
-            lines.extend([
-                f"*Open Rate:* `{round_value(r['open_rate'], 8)}`",
-                f"*Close Rate:* `{round_value(r['close_rate'], 8)}`" if r['close_rate'] else "",
-                "*Open Date:* `{open_date}`",
-                "*Close Date:* `{close_date}`" if r['close_date'] else "",
-                f" \n*Current Rate:* `{round_value(r['current_rate'], 8)}`" if r['is_open'] else "",
-                ("*Unrealized Profit:* " if r['is_open'] else "*Close Profit: *")
-                + "`{profit_ratio:.2%}` `({profit_abs_r})`",
-            ])
-
-            if r['is_open']:
-                if r.get('realized_profit'):
-                    lines.extend([
-                        "*Realized Profit:* `{realized_profit_ratio:.2%} ({realized_profit_r})`",
-                        "*Total Profit:* `{total_profit_ratio:.2%} ({total_profit_abs_r})`"
-                    ])
+                max_buy_str = f"/{max_entries + 1}" if (max_entries > 0) else ""
+                lines.extend(
+                    [
+                        "*Number of Entries:* `{num_entries}" + max_buy_str + "`",
+                        "*Number of Exits:* `{num_exits}`",
+                    ]
+                )
+
+            lines.extend(
+                [
+                    f"*Open Rate:* `{round_value(r['open_rate'], 8)}`",
+                    f"*Close Rate:* `{round_value(r['close_rate'], 8)}`" if r["close_rate"] else "",
+                    "*Open Date:* `{open_date}`",
+                    "*Close Date:* `{close_date}`" if r["close_date"] else "",
+                    (
+                        f" \n*Current Rate:* `{round_value(r['current_rate'], 8)}`"
+                        if r["is_open"]
+                        else ""
+                    ),
+                    ("*Unrealized Profit:* " if r["is_open"] else "*Close Profit: *")
+                    + "`{profit_ratio:.2%}` `({profit_abs_r})`",
+                ]
+            )
+
+            if r["is_open"]:
+                if r.get("realized_profit"):
+                    lines.extend(
+                        [
+                            "*Realized Profit:* `{realized_profit_ratio:.2%} "
+                            "({realized_profit_r})`",
+                            "*Total Profit:* `{total_profit_ratio:.2%} ({total_profit_abs_r})`",
+                        ]
+                    )
 
                 # Append empty line to improve readability
                 lines.append(" ")
-                if (r['stop_loss_abs'] != r['initial_stop_loss_abs']
-                        and r['initial_stop_loss_ratio'] is not None):
+                if (
+                    r["stop_loss_abs"] != r["initial_stop_loss_abs"]
+                    and r["initial_stop_loss_ratio"] is not None
+                ):
                     # Adding initial stoploss only if it is different from stoploss
-                    lines.append("*Initial Stoploss:* `{initial_stop_loss_abs:.8f}` "
-                                 "`({initial_stop_loss_ratio:.2%})`")
+                    lines.append(
+                        "*Initial Stoploss:* `{initial_stop_loss_abs:.8f}` "
+                        "`({initial_stop_loss_ratio:.2%})`"
+                    )
 
                 # Adding stoploss and stoploss percentage only if it is not None
-                lines.append(f"*Stoploss:* `{round_value(r['stop_loss_abs'], 8)}` " +
-                             ("`({stop_loss_ratio:.2%})`" if r['stop_loss_ratio'] else ""))
-                lines.append(f"*Stoploss distance:* `{round_value(r['stoploss_current_dist'], 8)}` "
-                             "`({stoploss_current_dist_ratio:.2%})`")
-                if r.get('open_orders'):
+                lines.append(
+                    f"*Stoploss:* `{round_value(r['stop_loss_abs'], 8)}` "
+                    + ("`({stop_loss_ratio:.2%})`" if r["stop_loss_ratio"] else "")
+                )
+                lines.append(
+                    f"*Stoploss distance:* `{round_value(r['stoploss_current_dist'], 8)}` "
+                    "`({stoploss_current_dist_ratio:.2%})`"
+                )
+                if r.get("open_orders"):
                     lines.append(
                         "*Open Order:* `{open_orders}`"
-                        + ("- `{exit_order_status}`" if r['exit_order_status'] else ""))
+                        + ("- `{exit_order_status}`" if r["exit_order_status"] else "")
+                    )
 
             await self.__send_status_msg(lines, r)
 
     async def __send_status_msg(self, lines: List[str], r: Dict[str, Any]) -> None:
         """
         Send status message.
         """
-        msg = ''
+        msg = ""
 
         for line in lines:
             if line:
                 if (len(msg) + len(line) + 1) < MAX_MESSAGE_LENGTH:
-                    msg += line + '\n'
+                    msg += line + "\n"
                 else:
                     await self._send_msg(msg.format(**r))
-                    msg = "*Trade ID:* `{trade_id}` - continued\n" + line + '\n'
+                    msg = "*Trade ID:* `{trade_id}` - continued\n" + line + "\n"
 
         await self._send_msg(msg.format(**r))
 
     @authorized_only
     async def _status_table(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /status table.
         Returns the current TradeThread status in table format
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
-        fiat_currency = self._config.get('fiat_display_currency', '')
+        fiat_currency = self._config.get("fiat_display_currency", "")
         statlist, head, fiat_profit_sum = self._rpc._rpc_status_table(
-            self._config['stake_currency'], fiat_currency)
+            self._config["stake_currency"], fiat_currency
+        )
 
         show_total = not isnan(fiat_profit_sum) and len(statlist) > 1
         max_trades_per_msg = 50
         """
         Calculate the number of messages of 50 trades per message
         0.99 is used to make sure that there are no extra (empty) messages
         As an example with 50 trades, there will be int(50/50 + 0.99) = 1 message
         """
         messages_count = max(int(len(statlist) / max_trades_per_msg + 0.99), 1)
         for i in range(0, messages_count):
-            trades = statlist[i * max_trades_per_msg:(i + 1) * max_trades_per_msg]
+            trades = statlist[i * max_trades_per_msg : (i + 1) * max_trades_per_msg]
             if show_total and i == messages_count - 1:
                 # append total line
                 trades.append(["Total", "", "", f"{fiat_profit_sum:.2f} {fiat_currency}"])
 
-            message = tabulate(trades,
-                               headers=head,
-                               tablefmt='simple')
+            message = tabulate(trades, headers=head, tablefmt="simple")
             if show_total and i == messages_count - 1:
                 # insert separators line between Total
                 lines = message.split("\n")
                 message = "\n".join(lines[:-1] + [lines[1]] + [lines[-1]])
-            await self._send_msg(f"<pre>{message}</pre>", parse_mode=ParseMode.HTML,
-                                 reload_able=True, callback_path="update_status_table",
-                                 query=update.callback_query)
+            await self._send_msg(
+                f"<pre>{message}</pre>",
+                parse_mode=ParseMode.HTML,
+                reload_able=True,
+                callback_path="update_status_table",
+                query=update.callback_query,
+            )
 
     async def _timeunit_stats(self, update: Update, context: CallbackContext, unit: str) -> None:
         """
         Handler for /daily <n>
         Returns a daily profit (in BTC) over the last n days.
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
 
         vals = {
-            'days': TimeunitMappings('Day', 'Daily', 'days', 'update_daily', 7, '%Y-%m-%d'),
-            'weeks': TimeunitMappings('Monday', 'Weekly', 'weeks (starting from Monday)',
-                                      'update_weekly', 8, '%Y-%m-%d'),
-            'months': TimeunitMappings('Month', 'Monthly', 'months', 'update_monthly', 6, '%Y-%m'),
+            "days": TimeunitMappings("Day", "Daily", "days", "update_daily", 7, "%Y-%m-%d"),
+            "weeks": TimeunitMappings(
+                "Monday", "Weekly", "weeks (starting from Monday)", "update_weekly", 8, "%Y-%m-%d"
+            ),
+            "months": TimeunitMappings("Month", "Monthly", "months", "update_monthly", 6, "%Y-%m"),
         }
         val = vals[unit]
 
-        stake_cur = self._config['stake_currency']
-        fiat_disp_cur = self._config.get('fiat_display_currency', '')
+        stake_cur = self._config["stake_currency"]
+        fiat_disp_cur = self._config.get("fiat_display_currency", "")
         try:
             timescale = int(context.args[0]) if context.args else val.default
         except (TypeError, ValueError, IndexError):
             timescale = val.default
-        stats = self._rpc._rpc_timeunit_profit(
-            timescale,
-            stake_cur,
-            fiat_disp_cur,
-            unit
-        )
+        stats = self._rpc._rpc_timeunit_profit(timescale, stake_cur, fiat_disp_cur, unit)
         stats_tab = tabulate(
-            [[f"{period['date']:{val.dateformat}} ({period['trade_count']})",
-              f"{fmt_coin(period['abs_profit'], stats['stake_currency'])}",
-              f"{period['fiat_value']:.2f} {stats['fiat_display_currency']}",
-              f"{period['rel_profit']:.2%}",
-              ] for period in stats['data']],
+            [
+                [
+                    f"{period['date']:{val.dateformat}} ({period['trade_count']})",
+                    f"{fmt_coin(period['abs_profit'], stats['stake_currency'])}",
+                    f"{period['fiat_value']:.2f} {stats['fiat_display_currency']}",
+                    f"{period['rel_profit']:.2%}",
+                ]
+                for period in stats["data"]
+            ],
             headers=[
                 f"{val.header} (count)",
-                f'{stake_cur}',
-                f'{fiat_disp_cur}',
-                'Profit %',
-                'Trades',
+                f"{stake_cur}",
+                f"{fiat_disp_cur}",
+                "Profit %",
+                "Trades",
             ],
-            tablefmt='simple')
+            tablefmt="simple",
+        )
         message = (
-            f'<b>{val.message} Profit over the last {timescale} {val.message2}</b>:\n'
-            f'<pre>{stats_tab}</pre>'
+            f"<b>{val.message} Profit over the last {timescale} {val.message2}</b>:\n"
+            f"<pre>{stats_tab}</pre>"
+        )
+        await self._send_msg(
+            message,
+            parse_mode=ParseMode.HTML,
+            reload_able=True,
+            callback_path=val.callback,
+            query=update.callback_query,
         )
-        await self._send_msg(message, parse_mode=ParseMode.HTML, reload_able=True,
-                             callback_path=val.callback, query=update.callback_query)
 
     @authorized_only
     async def _daily(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /daily <n>
         Returns a daily profit (in BTC) over the last n days.
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
-        await self._timeunit_stats(update, context, 'days')
+        await self._timeunit_stats(update, context, "days")
 
     @authorized_only
     async def _weekly(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /weekly <n>
         Returns a weekly profit (in BTC) over the last n weeks.
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
-        await self._timeunit_stats(update, context, 'weeks')
+        await self._timeunit_stats(update, context, "weeks")
 
     @authorized_only
     async def _monthly(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /monthly <n>
         Returns a monthly profit (in BTC) over the last n months.
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
-        await self._timeunit_stats(update, context, 'months')
+        await self._timeunit_stats(update, context, "months")
 
     @authorized_only
     async def _profit(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /profit.
         Returns a cumulative profit statistics.
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
-        stake_cur = self._config['stake_currency']
-        fiat_disp_cur = self._config.get('fiat_display_currency', '')
+        stake_cur = self._config["stake_currency"]
+        fiat_disp_cur = self._config.get("fiat_display_currency", "")
 
         start_date = datetime.fromtimestamp(0)
         timescale = None
         try:
             if context.args:
                 timescale = int(context.args[0]) - 1
                 today_start = datetime.combine(date.today(), datetime.min.time())
                 start_date = today_start - timedelta(days=timescale)
         except (TypeError, ValueError, IndexError):
             pass
 
-        stats = self._rpc._rpc_trade_statistics(
-            stake_cur,
-            fiat_disp_cur,
-            start_date)
-        profit_closed_coin = stats['profit_closed_coin']
-        profit_closed_ratio_mean = stats['profit_closed_ratio_mean']
-        profit_closed_percent = stats['profit_closed_percent']
-        profit_closed_fiat = stats['profit_closed_fiat']
-        profit_all_coin = stats['profit_all_coin']
-        profit_all_ratio_mean = stats['profit_all_ratio_mean']
-        profit_all_percent = stats['profit_all_percent']
-        profit_all_fiat = stats['profit_all_fiat']
-        trade_count = stats['trade_count']
+        stats = self._rpc._rpc_trade_statistics(stake_cur, fiat_disp_cur, start_date)
+        profit_closed_coin = stats["profit_closed_coin"]
+        profit_closed_ratio_mean = stats["profit_closed_ratio_mean"]
+        profit_closed_percent = stats["profit_closed_percent"]
+        profit_closed_fiat = stats["profit_closed_fiat"]
+        profit_all_coin = stats["profit_all_coin"]
+        profit_all_ratio_mean = stats["profit_all_ratio_mean"]
+        profit_all_percent = stats["profit_all_percent"]
+        profit_all_fiat = stats["profit_all_fiat"]
+        trade_count = stats["trade_count"]
         first_trade_date = f"{stats['first_trade_humanized']} ({stats['first_trade_date']})"
         latest_trade_date = f"{stats['latest_trade_humanized']} ({stats['latest_trade_date']})"
-        avg_duration = stats['avg_duration']
-        best_pair = stats['best_pair']
-        best_pair_profit_ratio = stats['best_pair_profit_ratio']
-        winrate = stats['winrate']
-        expectancy = stats['expectancy']
-        expectancy_ratio = stats['expectancy_ratio']
+        avg_duration = stats["avg_duration"]
+        best_pair = stats["best_pair"]
+        best_pair_profit_ratio = stats["best_pair_profit_ratio"]
+        winrate = stats["winrate"]
+        expectancy = stats["expectancy"]
+        expectancy_ratio = stats["expectancy_ratio"]
 
-        if stats['trade_count'] == 0:
+        if stats["trade_count"] == 0:
             markdown_msg = f"No trades yet.\n*Bot started:* `{stats['bot_start_date']}`"
         else:
             # Message to display
-            if stats['closed_trade_count'] > 0:
-                markdown_msg = ("*ROI:* Closed trades\n"
-                                f" `{fmt_coin(profit_closed_coin, stake_cur)} "
-                                f"({profit_closed_ratio_mean:.2%}) "
-                                f"({profit_closed_percent} \N{GREEK CAPITAL LETTER SIGMA}%)`\n"
-                                f" `{fmt_coin(profit_closed_fiat, fiat_disp_cur)}`\n")
+            if stats["closed_trade_count"] > 0:
+                markdown_msg = (
+                    "*ROI:* Closed trades\n"
+                    f" `{fmt_coin(profit_closed_coin, stake_cur)} "
+                    f"({profit_closed_ratio_mean:.2%}) "
+                    f"({profit_closed_percent} \N{GREEK CAPITAL LETTER SIGMA}%)`\n"
+                    f" `{fmt_coin(profit_closed_fiat, fiat_disp_cur)}`\n"
+                )
             else:
                 markdown_msg = "`No closed trade` \n"
-
+            fiat_all_trades = (
+                f" `{fmt_coin(profit_all_fiat, fiat_disp_cur)}`\n" if fiat_disp_cur else ""
+            )
             markdown_msg += (
                 f"*ROI:* All trades\n"
                 f" `{fmt_coin(profit_all_coin, stake_cur)} "
                 f"({profit_all_ratio_mean:.2%}) "
                 f"({profit_all_percent} \N{GREEK CAPITAL LETTER SIGMA}%)`\n"
-                f" `{fmt_coin(profit_all_fiat, fiat_disp_cur)}`\n"
+                f"{fiat_all_trades}"
                 f"*Total Trade Count:* `{trade_count}`\n"
                 f"*Bot started:* `{stats['bot_start_date']}`\n"
                 f"*{'First Trade opened' if not timescale else 'Showing Profit since'}:* "
                 f"`{first_trade_date}`\n"
                 f"*Latest Trade opened:* `{latest_trade_date}`\n"
                 f"*Win / Loss:* `{stats['winning_trades']} / {stats['losing_trades']}`\n"
                 f"*Winrate:* `{winrate:.2%}`\n"
                 f"*Expectancy (Ratio):* `{expectancy:.2f} ({expectancy_ratio:.2f})`"
             )
-            if stats['closed_trade_count'] > 0:
+            if stats["closed_trade_count"] > 0:
                 markdown_msg += (
                     f"\n*Avg. Duration:* `{avg_duration}`\n"
                     f"*Best Performing:* `{best_pair}: {best_pair_profit_ratio:.2%}`\n"
                     f"*Trading volume:* `{fmt_coin(stats['trading_volume'], stake_cur)}`\n"
                     f"*Profit factor:* `{stats['profit_factor']:.2f}`\n"
                     f"*Max Drawdown:* `{stats['max_drawdown']:.2%} "
                     f"({fmt_coin(stats['max_drawdown_abs'], stake_cur)})`\n"
                     f"    from `{stats['max_drawdown_start']} "
                     f"({fmt_coin(stats['drawdown_high'], stake_cur)})`\n"
                     f"    to `{stats['max_drawdown_end']} "
                     f"({fmt_coin(stats['drawdown_low'], stake_cur)})`\n"
                 )
-        await self._send_msg(markdown_msg, reload_able=True, callback_path="update_profit",
-                             query=update.callback_query)
+        await self._send_msg(
+            markdown_msg,
+            reload_able=True,
+            callback_path="update_profit",
+            query=update.callback_query,
+        )
 
     @authorized_only
     async def _stats(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /stats
         Show stats of recent trades
         """
         stats = self._rpc._rpc_stats()
 
         reason_map = {
-            'roi': 'ROI',
-            'stop_loss': 'Stoploss',
-            'trailing_stop_loss': 'Trail. Stop',
-            'stoploss_on_exchange': 'Stoploss',
-            'exit_signal': 'Exit Signal',
-            'force_exit': 'Force Exit',
-            'emergency_exit': 'Emergency Exit',
+            "roi": "ROI",
+            "stop_loss": "Stoploss",
+            "trailing_stop_loss": "Trail. Stop",
+            "stoploss_on_exchange": "Stoploss",
+            "exit_signal": "Exit Signal",
+            "force_exit": "Force Exit",
+            "emergency_exit": "Emergency Exit",
         }
         exit_reasons_tabulate = [
-            [
-                reason_map.get(reason, reason),
-                sum(count.values()),
-                count['wins'],
-                count['losses']
-            ] for reason, count in stats['exit_reasons'].items()
+            [reason_map.get(reason, reason), sum(count.values()), count["wins"], count["losses"]]
+            for reason, count in stats["exit_reasons"].items()
         ]
-        exit_reasons_msg = 'No trades yet.'
+        exit_reasons_msg = "No trades yet."
         for reason in chunks(exit_reasons_tabulate, 25):
-            exit_reasons_msg = tabulate(
-                reason,
-                headers=['Exit Reason', 'Exits', 'Wins', 'Losses']
-            )
+            exit_reasons_msg = tabulate(reason, headers=["Exit Reason", "Exits", "Wins", "Losses"])
             if len(exit_reasons_tabulate) > 25:
                 await self._send_msg(f"```\n{exit_reasons_msg}```", ParseMode.MARKDOWN)
-                exit_reasons_msg = ''
+                exit_reasons_msg = ""
 
-        durations = stats['durations']
+        durations = stats["durations"]
         duration_msg = tabulate(
             [
-                ['Wins', str(timedelta(seconds=durations['wins']))
-                 if durations['wins'] is not None else 'N/A'],
-                ['Losses', str(timedelta(seconds=durations['losses']))
-                 if durations['losses'] is not None else 'N/A']
+                [
+                    "Wins",
+                    (
+                        str(timedelta(seconds=durations["wins"]))
+                        if durations["wins"] is not None
+                        else "N/A"
+                    ),
+                ],
+                [
+                    "Losses",
+                    (
+                        str(timedelta(seconds=durations["losses"]))
+                        if durations["losses"] is not None
+                        else "N/A"
+                    ),
+                ],
             ],
-            headers=['', 'Avg. Duration']
+            headers=["", "Avg. Duration"],
         )
-        msg = (f"""```\n{exit_reasons_msg}```\n```\n{duration_msg}```""")
+        msg = f"""```\n{exit_reasons_msg}```\n```\n{duration_msg}```"""
 
         await self._send_msg(msg, ParseMode.MARKDOWN)
 
     @authorized_only
     async def _balance(self, update: Update, context: CallbackContext) -> None:
-        """ Handler for /balance """
-        full_result = context.args and 'full' in context.args
-        result = self._rpc._rpc_balance(self._config['stake_currency'],
-                                        self._config.get('fiat_display_currency', ''))
+        """Handler for /balance"""
+        full_result = context.args and "full" in context.args
+        result = self._rpc._rpc_balance(
+            self._config["stake_currency"], self._config.get("fiat_display_currency", "")
+        )
 
-        balance_dust_level = self._config['telegram'].get('balance_dust_level', 0.0)
+        balance_dust_level = self._config["telegram"].get("balance_dust_level", 0.0)
         if not balance_dust_level:
-            balance_dust_level = DUST_PER_COIN.get(self._config['stake_currency'], 1.0)
+            balance_dust_level = DUST_PER_COIN.get(self._config["stake_currency"], 1.0)
 
-        output = ''
-        if self._config['dry_run']:
+        output = ""
+        if self._config["dry_run"]:
             output += "*Warning:* Simulated balances in Dry Mode.\n"
-        starting_cap = fmt_coin(result['starting_capital'], self._config['stake_currency'])
+        starting_cap = fmt_coin(result["starting_capital"], self._config["stake_currency"])
         output += f"Starting capital: `{starting_cap}`"
-        starting_cap_fiat = fmt_coin(
-            result['starting_capital_fiat'], self._config['fiat_display_currency']
-        ) if result['starting_capital_fiat'] > 0 else ''
-        output += (f" `, {starting_cap_fiat}`.\n"
-                   ) if result['starting_capital_fiat'] > 0 else '.\n'
+        starting_cap_fiat = (
+            fmt_coin(result["starting_capital_fiat"], self._config["fiat_display_currency"])
+            if result["starting_capital_fiat"] > 0
+            else ""
+        )
+        output += (f" `, {starting_cap_fiat}`.\n") if result["starting_capital_fiat"] > 0 else ".\n"
 
         total_dust_balance = 0
         total_dust_currencies = 0
-        for curr in result['currencies']:
-            curr_output = ''
-            if (
-                (curr['is_position'] or curr['est_stake'] > balance_dust_level)
-                and (full_result or curr['is_bot_managed'])
+        for curr in result["currencies"]:
+            curr_output = ""
+            if (curr["is_position"] or curr["est_stake"] > balance_dust_level) and (
+                full_result or curr["is_bot_managed"]
             ):
-                if curr['is_position']:
+                if curr["is_position"]:
                     curr_output = (
                         f"*{curr['currency']}:*\n"
                         f"\t`{curr['side']}: {curr['position']:.8f}`\n"
                         f"\t`Leverage: {curr['leverage']:.1f}`\n"
                         f"\t`Est. {curr['stake']}: "
-                        f"{fmt_coin(curr['est_stake'], curr['stake'], False)}`\n")
+                        f"{fmt_coin(curr['est_stake'], curr['stake'], False)}`\n"
+                    )
                 else:
                     est_stake = fmt_coin(
-                        curr['est_stake' if full_result else 'est_stake_bot'], curr['stake'], False)
+                        curr["est_stake" if full_result else "est_stake_bot"], curr["stake"], False
+                    )
 
                     curr_output = (
                         f"*{curr['currency']}:*\n"
                         f"\t`Available: {curr['free']:.8f}`\n"
                         f"\t`Balance: {curr['balance']:.8f}`\n"
                         f"\t`Pending: {curr['used']:.8f}`\n"
                         f"\t`Bot Owned: {curr['bot_owned']:.8f}`\n"
-                        f"\t`Est. {curr['stake']}: {est_stake}`\n")
+                        f"\t`Est. {curr['stake']}: {est_stake}`\n"
+                    )
 
-            elif curr['est_stake'] <= balance_dust_level:
-                total_dust_balance += curr['est_stake']
+            elif curr["est_stake"] <= balance_dust_level:
+                total_dust_balance += curr["est_stake"]
                 total_dust_currencies += 1
 
             # Handle overflowing message length
             if len(output + curr_output) >= MAX_MESSAGE_LENGTH:
                 await self._send_msg(output)
                 output = curr_output
             else:
@@ -1060,29 +1164,31 @@
 
         if total_dust_balance > 0:
             output += (
                 f"*{total_dust_currencies} Other "
                 f"{plural(total_dust_currencies, 'Currency', 'Currencies')} "
                 f"(< {balance_dust_level} {result['stake']}):*\n"
                 f"\t`Est. {result['stake']}: "
-                f"{fmt_coin(total_dust_balance, result['stake'], False)}`\n")
-        tc = result['trade_count'] > 0
-        stake_improve = f" `({result['starting_capital_ratio']:.2%})`" if tc else ''
-        fiat_val = f" `({result['starting_capital_fiat_ratio']:.2%})`" if tc else ''
-        value = fmt_coin(
-            result['value' if full_result else 'value_bot'], result['symbol'], False)
+                f"{fmt_coin(total_dust_balance, result['stake'], False)}`\n"
+            )
+        tc = result["trade_count"] > 0
+        stake_improve = f" `({result['starting_capital_ratio']:.2%})`" if tc else ""
+        fiat_val = f" `({result['starting_capital_fiat_ratio']:.2%})`" if tc else ""
+        value = fmt_coin(result["value" if full_result else "value_bot"], result["symbol"], False)
         total_stake = fmt_coin(
-            result['total' if full_result else 'total_bot'], result['stake'], False)
+            result["total" if full_result else "total_bot"], result["stake"], False
+        )
         output += (
             f"\n*Estimated Value{' (Bot managed assets only)' if not full_result else ''}*:\n"
             f"\t`{result['stake']}: {total_stake}`{stake_improve}\n"
             f"\t`{result['symbol']}: {value}`{fiat_val}\n"
         )
-        await self._send_msg(output, reload_able=True, callback_path="update_balance",
-                             query=update.callback_query)
+        await self._send_msg(
+            output, reload_able=True, callback_path="update_balance", query=update.callback_query
+        )
 
     @authorized_only
     async def _start(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /start.
         Starts TradeThread
         :param bot: telegram bot
@@ -1149,161 +1255,176 @@
         :return: None
         """
 
         if context.args:
             trade_id = context.args[0]
             await self._force_exit_action(trade_id)
         else:
-            fiat_currency = self._config.get('fiat_display_currency', '')
+            fiat_currency = self._config.get("fiat_display_currency", "")
             try:
                 statlist, _, _ = self._rpc._rpc_status_table(
-                    self._config['stake_currency'], fiat_currency)
+                    self._config["stake_currency"], fiat_currency
+                )
             except RPCException:
-                await self._send_msg(msg='No open trade found.')
+                await self._send_msg(msg="No open trade found.")
                 return
             trades = []
             for trade in statlist:
                 trades.append((trade[0], f"{trade[0]} {trade[1]} {trade[2]} {trade[3]}"))
 
             trade_buttons = [
                 InlineKeyboardButton(text=trade[1], callback_data=f"force_exit__{trade[0]}")
-                for trade in trades]
+                for trade in trades
+            ]
             buttons_aligned = self._layout_inline_keyboard_onecol(trade_buttons)
 
-            buttons_aligned.append([InlineKeyboardButton(
-                text='Cancel', callback_data='force_exit__cancel')])
+            buttons_aligned.append(
+                [InlineKeyboardButton(text="Cancel", callback_data="force_exit__cancel")]
+            )
             await self._send_msg(msg="Which trade?", keyboard=buttons_aligned)
 
     async def _force_exit_action(self, trade_id: str):
-        if trade_id != 'cancel':
+        if trade_id != "cancel":
             try:
                 loop = asyncio.get_running_loop()
                 # Workaround to avoid nested loops
                 await loop.run_in_executor(None, safe_async_db(self._rpc._rpc_force_exit), trade_id)
             except RPCException as e:
                 await self._send_msg(str(e))
 
     async def _force_exit_inline(self, update: Update, _: CallbackContext) -> None:
         if update.callback_query:
             query = update.callback_query
-            if query.data and '__' in query.data:
+            if query.data and "__" in query.data:
                 # Input data is "force_exit__<tradid|cancel>"
-                trade_id = query.data.split("__")[1].split(' ')[0]
-                if trade_id == 'cancel':
+                trade_id = query.data.split("__")[1].split(" ")[0]
+                if trade_id == "cancel":
                     await query.answer()
                     await query.edit_message_text(text="Force exit canceled.")
                     return
                 trade: Optional[Trade] = Trade.get_trades(trade_filter=Trade.id == trade_id).first()
                 await query.answer()
                 if trade:
                     await query.edit_message_text(
-                        text=f"Manually exiting Trade #{trade_id}, {trade.pair}")
+                        text=f"Manually exiting Trade #{trade_id}, {trade.pair}"
+                    )
                     await self._force_exit_action(trade_id)
                 else:
                     await query.edit_message_text(text=f"Trade {trade_id} not found.")
 
     async def _force_enter_action(self, pair, price: Optional[float], order_side: SignalDirection):
-        if pair != 'cancel':
+        if pair != "cancel":
             try:
+
                 @safe_async_db
                 def _force_enter():
                     self._rpc._rpc_force_entry(pair, price, order_side=order_side)
+
                 loop = asyncio.get_running_loop()
                 # Workaround to avoid nested loops
                 await loop.run_in_executor(None, _force_enter)
             except RPCException as e:
                 logger.exception("Forcebuy error!")
                 await self._send_msg(str(e), ParseMode.HTML)
 
     async def _force_enter_inline(self, update: Update, _: CallbackContext) -> None:
         if update.callback_query:
             query = update.callback_query
-            if query.data and '__' in query.data:
+            if query.data and "__" in query.data:
                 # Input data is "force_enter__<pair|cancel>_<side>"
                 payload = query.data.split("__")[1]
-                if payload == 'cancel':
+                if payload == "cancel":
                     await query.answer()
                     await query.edit_message_text(text="Force enter canceled.")
                     return
-                if payload and '_||_' in payload:
-                    pair, side = payload.split('_||_')
+                if payload and "_||_" in payload:
+                    pair, side = payload.split("_||_")
                     order_side = SignalDirection(side)
                     await query.answer()
                     await query.edit_message_text(text=f"Manually entering {order_side} for {pair}")
                     await self._force_enter_action(pair, None, order_side)
 
     @staticmethod
     def _layout_inline_keyboard(
-            buttons: List[InlineKeyboardButton], cols=3) -> List[List[InlineKeyboardButton]]:
-        return [buttons[i:i + cols] for i in range(0, len(buttons), cols)]
+        buttons: List[InlineKeyboardButton], cols=3
+    ) -> List[List[InlineKeyboardButton]]:
+        return [buttons[i : i + cols] for i in range(0, len(buttons), cols)]
 
     @staticmethod
     def _layout_inline_keyboard_onecol(
-            buttons: List[InlineKeyboardButton], cols=1) -> List[List[InlineKeyboardButton]]:
-        return [buttons[i:i + cols] for i in range(0, len(buttons), cols)]
+        buttons: List[InlineKeyboardButton], cols=1
+    ) -> List[List[InlineKeyboardButton]]:
+        return [buttons[i : i + cols] for i in range(0, len(buttons), cols)]
 
     @authorized_only
     async def _force_enter(
-            self, update: Update, context: CallbackContext, order_side: SignalDirection) -> None:
+        self, update: Update, context: CallbackContext, order_side: SignalDirection
+    ) -> None:
         """
         Handler for /forcelong <asset> <price> and `/forceshort <asset> <price>
         Buys a pair trade at the given or current price
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
         if context.args:
             pair = context.args[0]
             price = float(context.args[1]) if len(context.args) > 1 else None
             await self._force_enter_action(pair, price, order_side)
         else:
-            whitelist = self._rpc._rpc_whitelist()['whitelist']
+            whitelist = self._rpc._rpc_whitelist()["whitelist"]
             pair_buttons = [
                 InlineKeyboardButton(
                     text=pair, callback_data=f"force_enter__{pair}_||_{order_side}"
-                ) for pair in sorted(whitelist)
+                )
+                for pair in sorted(whitelist)
             ]
             buttons_aligned = self._layout_inline_keyboard(pair_buttons)
 
-            buttons_aligned.append([InlineKeyboardButton(text='Cancel',
-                                                         callback_data='force_enter__cancel')])
-            await self._send_msg(msg="Which pair?",
-                                 keyboard=buttons_aligned,
-                                 query=update.callback_query)
+            buttons_aligned.append(
+                [InlineKeyboardButton(text="Cancel", callback_data="force_enter__cancel")]
+            )
+            await self._send_msg(
+                msg="Which pair?", keyboard=buttons_aligned, query=update.callback_query
+            )
 
     @authorized_only
     async def _trades(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /trades <n>
         Returns last n recent trades.
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
-        stake_cur = self._config['stake_currency']
+        stake_cur = self._config["stake_currency"]
         try:
             nrecent = int(context.args[0]) if context.args else 10
         except (TypeError, ValueError, IndexError):
             nrecent = 10
-        trades = self._rpc._rpc_trade_history(
-            nrecent
-        )
+        trades = self._rpc._rpc_trade_history(nrecent)
         trades_tab = tabulate(
-            [[dt_humanize_delta(dt_from_ts(trade['close_timestamp'])),
-                trade['pair'] + " (#" + str(trade['trade_id']) + ")",
-                f"{(trade['close_profit']):.2%} ({trade['close_profit_abs']})"]
-                for trade in trades['trades']],
+            [
+                [
+                    dt_humanize_delta(dt_from_ts(trade["close_timestamp"])),
+                    trade["pair"] + " (#" + str(trade["trade_id"]) + ")",
+                    f"{(trade['close_profit']):.2%} ({trade['close_profit_abs']})",
+                ]
+                for trade in trades["trades"]
+            ],
             headers=[
-                'Close Date',
-                'Pair (ID)',
-                f'Profit ({stake_cur})',
+                "Close Date",
+                "Pair (ID)",
+                f"Profit ({stake_cur})",
             ],
-            tablefmt='simple')
-        message = (f"<b>{min(trades['trades_count'], nrecent)} recent trades</b>:\n"
-                   + (f"<pre>{trades_tab}</pre>" if trades['trades_count'] > 0 else ''))
+            tablefmt="simple",
+        )
+        message = f"<b>{min(trades['trades_count'], nrecent)} recent trades</b>:\n" + (
+            f"<pre>{trades_tab}</pre>" if trades["trades_count"] > 0 else ""
+        )
         await self._send_msg(message, parse_mode=ParseMode.HTML)
 
     @authorized_only
     async def _delete_trade(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /delete <id>.
         Delete the given trade
@@ -1313,15 +1434,15 @@
         """
         if not context.args or len(context.args) == 0:
             raise RPCException("Trade-id not set.")
         trade_id = int(context.args[0])
         msg = self._rpc._rpc_delete(trade_id)
         await self._send_msg(
             f"`{msg['result_msg']}`\n"
-            'Please make sure to take care of this asset on the exchange manually.'
+            "Please make sure to take care of this asset on the exchange manually."
         )
 
     @authorized_only
     async def _cancel_open_order(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /cancel_open_order <id>.
         Cancel open order for tradeid
@@ -1329,15 +1450,15 @@
         :param update: message update
         :return: None
         """
         if not context.args or len(context.args) == 0:
             raise RPCException("Trade-id not set.")
         trade_id = int(context.args[0])
         self._rpc._rpc_cancel_open_order(trade_id)
-        await self._send_msg('Open order canceled.')
+        await self._send_msg("Open order canceled.")
 
     @authorized_only
     async def _performance(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /performance.
         Shows a performance statistic from finished trades
         :param bot: telegram bot
@@ -1347,25 +1468,30 @@
         trades = self._rpc._rpc_performance()
         output = "<b>Performance:</b>\n"
         for i, trade in enumerate(trades):
             stat_line = (
                 f"{i + 1}.\t <code>{trade['pair']}\t"
                 f"{fmt_coin(trade['profit_abs'], self._config['stake_currency'])} "
                 f"({trade['profit_ratio']:.2%}) "
-                f"({trade['count']})</code>\n")
+                f"({trade['count']})</code>\n"
+            )
 
             if len(output + stat_line) >= MAX_MESSAGE_LENGTH:
                 await self._send_msg(output, parse_mode=ParseMode.HTML)
                 output = stat_line
             else:
                 output += stat_line
 
-        await self._send_msg(output, parse_mode=ParseMode.HTML,
-                             reload_able=True, callback_path="update_performance",
-                             query=update.callback_query)
+        await self._send_msg(
+            output,
+            parse_mode=ParseMode.HTML,
+            reload_able=True,
+            callback_path="update_performance",
+            query=update.callback_query,
+        )
 
     @authorized_only
     async def _enter_tag_performance(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /entries PAIR .
         Shows a performance statistic from finished trades
         :param bot: telegram bot
@@ -1379,25 +1505,30 @@
         trades = self._rpc._rpc_enter_tag_performance(pair)
         output = "*Entry Tag Performance:*\n"
         for i, trade in enumerate(trades):
             stat_line = (
                 f"{i + 1}.\t `{trade['enter_tag']}\t"
                 f"{fmt_coin(trade['profit_abs'], self._config['stake_currency'])} "
                 f"({trade['profit_ratio']:.2%}) "
-                f"({trade['count']})`\n")
+                f"({trade['count']})`\n"
+            )
 
             if len(output + stat_line) >= MAX_MESSAGE_LENGTH:
                 await self._send_msg(output, parse_mode=ParseMode.MARKDOWN)
                 output = stat_line
             else:
                 output += stat_line
 
-        await self._send_msg(output, parse_mode=ParseMode.MARKDOWN,
-                             reload_able=True, callback_path="update_enter_tag_performance",
-                             query=update.callback_query)
+        await self._send_msg(
+            output,
+            parse_mode=ParseMode.MARKDOWN,
+            reload_able=True,
+            callback_path="update_enter_tag_performance",
+            query=update.callback_query,
+        )
 
     @authorized_only
     async def _exit_reason_performance(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /exits.
         Shows a performance statistic from finished trades
         :param bot: telegram bot
@@ -1411,25 +1542,30 @@
         trades = self._rpc._rpc_exit_reason_performance(pair)
         output = "*Exit Reason Performance:*\n"
         for i, trade in enumerate(trades):
             stat_line = (
                 f"{i + 1}.\t `{trade['exit_reason']}\t"
                 f"{fmt_coin(trade['profit_abs'], self._config['stake_currency'])} "
                 f"({trade['profit_ratio']:.2%}) "
-                f"({trade['count']})`\n")
+                f"({trade['count']})`\n"
+            )
 
             if len(output + stat_line) >= MAX_MESSAGE_LENGTH:
                 await self._send_msg(output, parse_mode=ParseMode.MARKDOWN)
                 output = stat_line
             else:
                 output += stat_line
 
-        await self._send_msg(output, parse_mode=ParseMode.MARKDOWN,
-                             reload_able=True, callback_path="update_exit_reason_performance",
-                             query=update.callback_query)
+        await self._send_msg(
+            output,
+            parse_mode=ParseMode.MARKDOWN,
+            reload_able=True,
+            callback_path="update_exit_reason_performance",
+            query=update.callback_query,
+        )
 
     @authorized_only
     async def _mix_tag_performance(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /mix_tags.
         Shows a performance statistic from finished trades
         :param bot: telegram bot
@@ -1443,63 +1579,75 @@
         trades = self._rpc._rpc_mix_tag_performance(pair)
         output = "*Mix Tag Performance:*\n"
         for i, trade in enumerate(trades):
             stat_line = (
                 f"{i + 1}.\t `{trade['mix_tag']}\t"
                 f"{fmt_coin(trade['profit_abs'], self._config['stake_currency'])} "
                 f"({trade['profit_ratio']:.2%}) "
-                f"({trade['count']})`\n")
+                f"({trade['count']})`\n"
+            )
 
             if len(output + stat_line) >= MAX_MESSAGE_LENGTH:
                 await self._send_msg(output, parse_mode=ParseMode.MARKDOWN)
                 output = stat_line
             else:
                 output += stat_line
 
-        await self._send_msg(output, parse_mode=ParseMode.MARKDOWN,
-                             reload_able=True, callback_path="update_mix_tag_performance",
-                             query=update.callback_query)
+        await self._send_msg(
+            output,
+            parse_mode=ParseMode.MARKDOWN,
+            reload_able=True,
+            callback_path="update_mix_tag_performance",
+            query=update.callback_query,
+        )
 
     @authorized_only
     async def _count(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /count.
         Returns the number of trades running
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
         counts = self._rpc._rpc_count()
-        message = tabulate({k: [v] for k, v in counts.items()},
-                           headers=['current', 'max', 'total stake'],
-                           tablefmt='simple')
+        message = tabulate(
+            {k: [v] for k, v in counts.items()},
+            headers=["current", "max", "total stake"],
+            tablefmt="simple",
+        )
         message = f"<pre>{message}</pre>"
         logger.debug(message)
-        await self._send_msg(message, parse_mode=ParseMode.HTML,
-                             reload_able=True, callback_path="update_count",
-                             query=update.callback_query)
+        await self._send_msg(
+            message,
+            parse_mode=ParseMode.HTML,
+            reload_able=True,
+            callback_path="update_count",
+            query=update.callback_query,
+        )
 
     @authorized_only
     async def _locks(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /locks.
         Returns the currently active locks
         """
         rpc_locks = self._rpc._rpc_locks()
-        if not rpc_locks['locks']:
-            await self._send_msg('No active locks.', parse_mode=ParseMode.HTML)
+        if not rpc_locks["locks"]:
+            await self._send_msg("No active locks.", parse_mode=ParseMode.HTML)
 
-        for locks in chunks(rpc_locks['locks'], 25):
-            message = tabulate([[
-                lock['id'],
-                lock['pair'],
-                lock['lock_end_time'],
-                lock['reason']] for lock in locks],
-                headers=['ID', 'Pair', 'Until', 'Reason'],
-                tablefmt='simple')
+        for locks in chunks(rpc_locks["locks"], 25):
+            message = tabulate(
+                [
+                    [lock["id"], lock["pair"], lock["lock_end_time"], lock["reason"]]
+                    for lock in locks
+                ],
+                headers=["ID", "Pair", "Until", "Reason"],
+                tablefmt="simple",
+            )
             message = f"<pre>{escape(message)}</pre>"
             logger.debug(message)
             await self._send_msg(message, parse_mode=ParseMode.HTML)
 
     @authorized_only
     async def _delete_locks(self, update: Update, context: CallbackContext) -> None:
         """
@@ -1524,17 +1672,17 @@
         Handler for /whitelist
         Shows the currently active whitelist
         """
         whitelist = self._rpc._rpc_whitelist()
 
         if context.args:
             if "sorted" in context.args:
-                whitelist['whitelist'] = sorted(whitelist['whitelist'])
+                whitelist["whitelist"] = sorted(whitelist["whitelist"])
             if "baseonly" in context.args:
-                whitelist['whitelist'] = [pair.split("/")[0] for pair in whitelist['whitelist']]
+                whitelist["whitelist"] = [pair.split("/")[0] for pair in whitelist["whitelist"]]
 
         message = f"Using whitelist `{whitelist['method']}` with {whitelist['length']} pairs\n"
         message += f"`{', '.join(whitelist['whitelist'])}`"
 
         logger.debug(message)
         await self._send_msg(message)
 
@@ -1544,18 +1692,18 @@
         Handler for /blacklist
         Shows the currently active blacklist
         """
         await self.send_blacklist_msg(self._rpc._rpc_blacklist(context.args))
 
     async def send_blacklist_msg(self, blacklist: Dict):
         errmsgs = []
-        for _, error in blacklist['errors'].items():
+        for _, error in blacklist["errors"].items():
             errmsgs.append(f"Error: {error['error_msg']}")
         if errmsgs:
-            await self._send_msg('\n'.join(errmsgs))
+            await self._send_msg("\n".join(errmsgs))
 
         message = f"Blacklist contains {blacklist['length']} pairs\n"
         message += f"`{', '.join(blacklist['blacklist'])}`"
 
         logger.debug(message)
         await self._send_msg(message)
 
@@ -1573,68 +1721,72 @@
         Handler for /logs
         Shows the latest logs
         """
         try:
             limit = int(context.args[0]) if context.args else 10
         except (TypeError, ValueError, IndexError):
             limit = 10
-        logs = RPC._rpc_get_logs(limit)['logs']
-        msgs = ''
+        logs = RPC._rpc_get_logs(limit)["logs"]
+        msgs = ""
         msg_template = "*{}* {}: {} \\- `{}`"
         for logrec in logs:
-            msg = msg_template.format(escape_markdown(logrec[0], version=2),
-                                      escape_markdown(logrec[2], version=2),
-                                      escape_markdown(logrec[3], version=2),
-                                      escape_markdown(logrec[4], version=2))
+            msg = msg_template.format(
+                escape_markdown(logrec[0], version=2),
+                escape_markdown(logrec[2], version=2),
+                escape_markdown(logrec[3], version=2),
+                escape_markdown(logrec[4], version=2),
+            )
             if len(msgs + msg) + 10 >= MAX_MESSAGE_LENGTH:
                 # Send message immediately if it would become too long
                 await self._send_msg(msgs, parse_mode=ParseMode.MARKDOWN_V2)
-                msgs = msg + '\n'
+                msgs = msg + "\n"
             else:
                 # Append message to messages to send
-                msgs += msg + '\n'
+                msgs += msg + "\n"
 
         if msgs:
             await self._send_msg(msgs, parse_mode=ParseMode.MARKDOWN_V2)
 
     @authorized_only
     async def _edge(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /edge
         Shows information related to Edge
         """
         edge_pairs = self._rpc._rpc_edge()
         if not edge_pairs:
-            message = '<b>Edge only validated following pairs:</b>'
+            message = "<b>Edge only validated following pairs:</b>"
             await self._send_msg(message, parse_mode=ParseMode.HTML)
 
         for chunk in chunks(edge_pairs, 25):
-            edge_pairs_tab = tabulate(chunk, headers='keys', tablefmt='simple')
-            message = (f'<b>Edge only validated following pairs:</b>\n'
-                       f'<pre>{edge_pairs_tab}</pre>')
+            edge_pairs_tab = tabulate(chunk, headers="keys", tablefmt="simple")
+            message = f"<b>Edge only validated following pairs:</b>\n<pre>{edge_pairs_tab}</pre>"
 
             await self._send_msg(message, parse_mode=ParseMode.HTML)
 
     @authorized_only
     async def _help(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /help.
         Show commands of the bot
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
-        force_enter_text = ("*/forcelong <pair> [<rate>]:* `Instantly buys the given pair. "
-                            "Optionally takes a rate at which to buy "
-                            "(only applies to limit orders).` \n"
-                            )
+        force_enter_text = (
+            "*/forcelong <pair> [<rate>]:* `Instantly buys the given pair. "
+            "Optionally takes a rate at which to buy "
+            "(only applies to limit orders).` \n"
+        )
         if self._rpc._freqtrade.trading_mode != TradingMode.SPOT:
-            force_enter_text += ("*/forceshort <pair> [<rate>]:* `Instantly shorts the given pair. "
-                                 "Optionally takes a rate at which to sell "
-                                 "(only applies to limit orders).` \n")
+            force_enter_text += (
+                "*/forceshort <pair> [<rate>]:* `Instantly shorts the given pair. "
+                "Optionally takes a rate at which to sell "
+                "(only applies to limit orders).` \n"
+            )
         message = (
             "_Bot Control_\n"
             "------------\n"
             "*/start:* `Starts the trader`\n"
             "*/stop:* Stops the trader\n"
             "*/stopentry:* `Stops entering, but handles open trades gracefully` \n"
             "*/forceexit <trade_id>|all:* `Instantly exits the given trade or all trades, "
@@ -1642,24 +1794,22 @@
             "*/fx <trade_id>|all:* `Alias to /forceexit`\n"
             f"{force_enter_text if self._config.get('force_entry_enable', False) else ''}"
             "*/delete <trade_id>:* `Instantly delete the given trade in the database`\n"
             "*/reload_trade <trade_id>:* `Relade trade from exchange Orders`\n"
             "*/cancel_open_order <trade_id>:* `Cancels open orders for trade. "
             "Only valid when the trade has open orders.`\n"
             "*/coo <trade_id>|all:* `Alias to /cancel_open_order`\n"
-
             "*/whitelist [sorted] [baseonly]:* `Show current whitelist. Optionally in "
             "order and/or only displaying the base currency of each pairing.`\n"
             "*/blacklist [pair]:* `Show current blacklist, or adds one or more pairs "
             "to the blacklist.` \n"
             "*/blacklist_delete [pairs]| /bl_delete [pairs]:* "
             "`Delete pair / pattern from blacklist. Will reset on reload_conf.` \n"
             "*/reload_config:* `Reload configuration file` \n"
             "*/unlock <pair|id>:* `Unlock this Pair (or this lock id if it's numeric)`\n"
-
             "_Current state_\n"
             "------------\n"
             "*/show_config:* `Show running configuration` \n"
             "*/locks:* `Show currently locked pairs`\n"
             "*/balance:* `Show bot managed balance per currency`\n"
             "*/balance total:* `Show account balance per currency`\n"
             "*/logs [limit]:* `Show latest logs - defaults to 10` \n"
@@ -1667,15 +1817,14 @@
             "*/edge:* `Shows validated pairs by Edge if it is enabled` \n"
             "*/health* `Show latest process timestamp - defaults to 1970-01-01 00:00:00` \n"
             "*/marketdir [long | short | even | none]:* `Updates the user managed variable "
             "that represents the current market direction. If no direction is provided `"
             "`the currently set market direction will be output.` \n"
             "*/list_custom_data <trade_id> <key>:* `List custom_data for Trade ID & Key combo.`\n"
             "`If no Key is supplied it will list all key-value pairs found for that Trade ID.`"
-
             "_Statistics_\n"
             "------------\n"
             "*/status <trade_id>|[table]:* `Lists all open trades`\n"
             "         *<trade_id> :* `Lists one or more specific trades.`\n"
             "                        `Separate multiple <trade_id> with a blank space.`\n"
             "         *table :* `will display trades in a table`\n"
             "                `pending buy orders are marked with an asterisk (*)`\n"
@@ -1690,15 +1839,15 @@
             "*/daily <n>:* `Shows profit or loss per day, over the last n days`\n"
             "*/weekly <n>:* `Shows statistics per week, over the last n weeks`\n"
             "*/monthly <n>:* `Shows statistics per month, over the last n months`\n"
             "*/stats:* `Shows Wins / losses by Sell reason as well as "
             "Avg. holding durations for buys and sells.`\n"
             "*/help:* `This help message`\n"
             "*/version:* `Show version`\n"
-            )
+        )
 
         await self._send_msg(message, parse_mode=ParseMode.MARKDOWN)
 
     @authorized_only
     async def _health(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /health
@@ -1716,43 +1865,43 @@
         Handler for /version.
         Show version information
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
         strategy_version = self._rpc._freqtrade.strategy.version()
-        version_string = f'*Version:* `{__version__}`'
+        version_string = f"*Version:* `{__version__}`"
         if strategy_version is not None:
-            version_string += f'\n*Strategy version: * `{strategy_version}`'
+            version_string += f"\n*Strategy version: * `{strategy_version}`"
 
         await self._send_msg(version_string)
 
     @authorized_only
     async def _show_config(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /show_config.
         Show config information information
         :param bot: telegram bot
         :param update: message update
         :return: None
         """
         val = RPC._rpc_show_config(self._config, self._rpc._freqtrade.state)
 
-        if val['trailing_stop']:
+        if val["trailing_stop"]:
             sl_info = (
                 f"*Initial Stoploss:* `{val['stoploss']}`\n"
                 f"*Trailing stop positive:* `{val['trailing_stop_positive']}`\n"
                 f"*Trailing stop offset:* `{val['trailing_stop_positive_offset']}`\n"
                 f"*Only trail above offset:* `{val['trailing_only_offset_is_reached']}`\n"
             )
 
         else:
             sl_info = f"*Stoploss:* `{val['stoploss']}`\n"
 
-        if val['position_adjustment_enable']:
+        if val["position_adjustment_enable"]:
             pa_info = (
                 f"*Position adjustment:* On\n"
                 f"*Max enter position adjustment:* `{val['max_entry_position_adjustment']}`\n"
             )
         else:
             pa_info = "*Position adjustment:* Off\n"
 
@@ -1786,26 +1935,24 @@
                 raise RPCException("Trade-id not set.")
             trade_id = int(context.args[0])
             key = None if len(context.args) < 2 else str(context.args[1])
 
             results = self._rpc._rpc_list_custom_data(trade_id, key)
             messages = []
             if len(results) > 0:
-                messages.append(
-                    'Found custom-data entr' + ('ies: ' if len(results) > 1 else 'y: ')
-                )
+                messages.append("Found custom-data entr" + ("ies: " if len(results) > 1 else "y: "))
                 for result in results:
                     lines = [
                         f"*Key:* `{result['cd_key']}`",
                         f"*ID:* `{result['id']}`",
                         f"*Trade ID:* `{result['ft_trade_id']}`",
                         f"*Type:* `{result['cd_type']}`",
                         f"*Value:* `{result['cd_value']}`",
                         f"*Create Date:* `{format_date(result['created_at'])}`",
-                        f"*Update Date:* `{format_date(result['updated_at'])}`"
+                        f"*Update Date:* `{format_date(result['updated_at'])}`",
                     ]
                     # Filter empty lines using list-comprehension
                     messages.append("\n".join([line for line in lines if line]))
                 for msg in messages:
                     if len(msg) > MAX_MESSAGE_LENGTH:
                         msg = "Message dropped because length exceeds "
                         msg += f"maximum allowed characters: {MAX_MESSAGE_LENGTH}"
@@ -1815,94 +1962,106 @@
                 message = f"Didn't find any custom-data entries for Trade ID: `{trade_id}`"
                 message += f" and Key: `{key}`." if key is not None else ""
                 await self._send_msg(message)
 
         except RPCException as e:
             await self._send_msg(str(e))
 
-    async def _update_msg(self, query: CallbackQuery, msg: str, callback_path: str = "",
-                          reload_able: bool = False, parse_mode: str = ParseMode.MARKDOWN) -> None:
+    async def _update_msg(
+        self,
+        query: CallbackQuery,
+        msg: str,
+        callback_path: str = "",
+        reload_able: bool = False,
+        parse_mode: str = ParseMode.MARKDOWN,
+    ) -> None:
         if reload_able:
-            reply_markup = InlineKeyboardMarkup([
-                [InlineKeyboardButton("Refresh", callback_data=callback_path)],
-            ])
+            reply_markup = InlineKeyboardMarkup(
+                [
+                    [InlineKeyboardButton("Refresh", callback_data=callback_path)],
+                ]
+            )
         else:
             reply_markup = InlineKeyboardMarkup([[]])
         msg += f"\nUpdated: {datetime.now().ctime()}"
         if not query.message:
             return
 
         try:
             await query.edit_message_text(
-                text=msg,
-                parse_mode=parse_mode,
-                reply_markup=reply_markup
+                text=msg, parse_mode=parse_mode, reply_markup=reply_markup
             )
         except BadRequest as e:
-            if 'not modified' in e.message.lower():
+            if "not modified" in e.message.lower():
                 pass
             else:
-                logger.warning('TelegramError: %s', e.message)
+                logger.warning("TelegramError: %s", e.message)
         except TelegramError as telegram_err:
-            logger.warning('TelegramError: %s! Giving up on that message.', telegram_err.message)
+            logger.warning("TelegramError: %s! Giving up on that message.", telegram_err.message)
 
-    async def _send_msg(self, msg: str, parse_mode: str = ParseMode.MARKDOWN,
-                        disable_notification: bool = False,
-                        keyboard: Optional[List[List[InlineKeyboardButton]]] = None,
-                        callback_path: str = "",
-                        reload_able: bool = False,
-                        query: Optional[CallbackQuery] = None) -> None:
+    async def _send_msg(
+        self,
+        msg: str,
+        parse_mode: str = ParseMode.MARKDOWN,
+        disable_notification: bool = False,
+        keyboard: Optional[List[List[InlineKeyboardButton]]] = None,
+        callback_path: str = "",
+        reload_able: bool = False,
+        query: Optional[CallbackQuery] = None,
+    ) -> None:
         """
         Send given markdown message
         :param msg: message
         :param bot: alternative bot
         :param parse_mode: telegram parse mode
         :return: None
         """
         reply_markup: Union[InlineKeyboardMarkup, ReplyKeyboardMarkup]
         if query:
-            await self._update_msg(query=query, msg=msg, parse_mode=parse_mode,
-                                   callback_path=callback_path, reload_able=reload_able)
+            await self._update_msg(
+                query=query,
+                msg=msg,
+                parse_mode=parse_mode,
+                callback_path=callback_path,
+                reload_able=reload_able,
+            )
             return
-        if reload_able and self._config['telegram'].get('reload', True):
-            reply_markup = InlineKeyboardMarkup([
-                [InlineKeyboardButton("Refresh", callback_data=callback_path)]])
+        if reload_able and self._config["telegram"].get("reload", True):
+            reply_markup = InlineKeyboardMarkup(
+                [[InlineKeyboardButton("Refresh", callback_data=callback_path)]]
+            )
         else:
             if keyboard is not None:
                 reply_markup = InlineKeyboardMarkup(keyboard)
             else:
                 reply_markup = ReplyKeyboardMarkup(self._keyboard, resize_keyboard=True)
         try:
             try:
                 await self._app.bot.send_message(
-                    self._config['telegram']['chat_id'],
+                    self._config["telegram"]["chat_id"],
                     text=msg,
                     parse_mode=parse_mode,
                     reply_markup=reply_markup,
                     disable_notification=disable_notification,
                 )
             except NetworkError as network_err:
                 # Sometimes the telegram server resets the current connection,
                 # if this is the case we send the message again.
                 logger.warning(
-                    'Telegram NetworkError: %s! Trying one more time.',
-                    network_err.message
+                    "Telegram NetworkError: %s! Trying one more time.", network_err.message
                 )
                 await self._app.bot.send_message(
-                    self._config['telegram']['chat_id'],
+                    self._config["telegram"]["chat_id"],
                     text=msg,
                     parse_mode=parse_mode,
                     reply_markup=reply_markup,
                     disable_notification=disable_notification,
                 )
         except TelegramError as telegram_err:
-            logger.warning(
-                'TelegramError: %s! Giving up on that message.',
-                telegram_err.message
-            )
+            logger.warning("TelegramError: %s! Giving up on that message.", telegram_err.message)
 
     @authorized_only
     async def _changemarketdir(self, update: Update, context: CallbackContext) -> None:
         """
         Handler for /marketdir.
         Updates the bot's market_direction
         :param bot: telegram bot
@@ -1920,18 +2079,24 @@
             elif new_market_dir_arg == "even":
                 new_market_dir = MarketDirection.EVEN
             elif new_market_dir_arg == "none":
                 new_market_dir = MarketDirection.NONE
 
             if new_market_dir is not None:
                 self._rpc._update_market_direction(new_market_dir)
-                await self._send_msg("Successfully updated market direction"
-                                     f" from *{old_market_dir}* to *{new_market_dir}*.")
+                await self._send_msg(
+                    "Successfully updated market direction"
+                    f" from *{old_market_dir}* to *{new_market_dir}*."
+                )
             else:
-                raise RPCException("Invalid market direction provided. \n"
-                                   "Valid market directions: *long, short, even, none*")
+                raise RPCException(
+                    "Invalid market direction provided. \n"
+                    "Valid market directions: *long, short, even, none*"
+                )
         elif context.args is not None and len(context.args) == 0:
             old_market_dir = self._rpc._get_market_direction()
             await self._send_msg(f"Currently set market direction: *{old_market_dir}*")
         else:
-            raise RPCException("Invalid usage of command /marketdir. \n"
-                               "Usage: */marketdir [short |  long | even | none]*")
+            raise RPCException(
+                "Invalid usage of command /marketdir. \n"
+                "Usage: */marketdir [short |  long | even | none]*"
+            )
```

### Comparing `freqtrade-2024.4/freqtrade/rpc/webhook.py` & `freqtrade-2024.5/freqtrade/rpc/webhook.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,101 +1,107 @@
 """
 This module manages webhook communication
 """
+
 import logging
 import time
 from typing import Any, Dict, Optional
 
 from requests import RequestException, post
 
 from freqtrade.constants import Config
 from freqtrade.enums import RPCMessageType
 from freqtrade.rpc import RPC, RPCHandler
 from freqtrade.rpc.rpc_types import RPCSendMsg
 
 
 logger = logging.getLogger(__name__)
 
-logger.debug('Included module rpc.webhook ...')
+logger.debug("Included module rpc.webhook ...")
 
 
 class Webhook(RPCHandler):
-    """  This class handles all webhook communication """
+    """This class handles all webhook communication"""
 
     def __init__(self, rpc: RPC, config: Config) -> None:
         """
         Init the Webhook class, and init the super class RPCHandler
         :param rpc: instance of RPC Helper class
         :param config: Configuration object
         :return: None
         """
         super().__init__(rpc, config)
 
-        self._url = self._config['webhook']['url']
-        self._format = self._config['webhook'].get('format', 'form')
-        self._retries = self._config['webhook'].get('retries', 0)
-        self._retry_delay = self._config['webhook'].get('retry_delay', 0.1)
-        self._timeout = self._config['webhook'].get('timeout', 10)
+        self._url = self._config["webhook"]["url"]
+        self._format = self._config["webhook"].get("format", "form")
+        self._retries = self._config["webhook"].get("retries", 0)
+        self._retry_delay = self._config["webhook"].get("retry_delay", 0.1)
+        self._timeout = self._config["webhook"].get("timeout", 10)
 
     def cleanup(self) -> None:
         """
         Cleanup pending module resources.
         This will do nothing for webhooks, they will simply not be called anymore
         """
         pass
 
     def _get_value_dict(self, msg: RPCSendMsg) -> Optional[Dict[str, Any]]:
-        whconfig = self._config['webhook']
-        if msg['type'].value in whconfig:
+        whconfig = self._config["webhook"]
+        if msg["type"].value in whconfig:
             # Explicit types should have priority
-            valuedict = whconfig.get(msg['type'].value)
+            valuedict = whconfig.get(msg["type"].value)
         # Deprecated 2022.10 - only keep generic method.
-        elif msg['type'] in [RPCMessageType.ENTRY]:
-            valuedict = whconfig.get('webhookentry')
-        elif msg['type'] in [RPCMessageType.ENTRY_CANCEL]:
-            valuedict = whconfig.get('webhookentrycancel')
-        elif msg['type'] in [RPCMessageType.ENTRY_FILL]:
-            valuedict = whconfig.get('webhookentryfill')
-        elif msg['type'] == RPCMessageType.EXIT:
-            valuedict = whconfig.get('webhookexit')
-        elif msg['type'] == RPCMessageType.EXIT_FILL:
-            valuedict = whconfig.get('webhookexitfill')
-        elif msg['type'] == RPCMessageType.EXIT_CANCEL:
-            valuedict = whconfig.get('webhookexitcancel')
-        elif msg['type'] in (RPCMessageType.STATUS,
-                             RPCMessageType.STARTUP,
-                             RPCMessageType.EXCEPTION,
-                             RPCMessageType.WARNING):
-            valuedict = whconfig.get('webhookstatus')
-        elif msg['type'] in (
-                RPCMessageType.PROTECTION_TRIGGER,
-                RPCMessageType.PROTECTION_TRIGGER_GLOBAL,
-                RPCMessageType.WHITELIST,
-                RPCMessageType.ANALYZED_DF,
-                RPCMessageType.NEW_CANDLE,
-                RPCMessageType.STRATEGY_MSG):
+        elif msg["type"] in [RPCMessageType.ENTRY]:
+            valuedict = whconfig.get("webhookentry")
+        elif msg["type"] in [RPCMessageType.ENTRY_CANCEL]:
+            valuedict = whconfig.get("webhookentrycancel")
+        elif msg["type"] in [RPCMessageType.ENTRY_FILL]:
+            valuedict = whconfig.get("webhookentryfill")
+        elif msg["type"] == RPCMessageType.EXIT:
+            valuedict = whconfig.get("webhookexit")
+        elif msg["type"] == RPCMessageType.EXIT_FILL:
+            valuedict = whconfig.get("webhookexitfill")
+        elif msg["type"] == RPCMessageType.EXIT_CANCEL:
+            valuedict = whconfig.get("webhookexitcancel")
+        elif msg["type"] in (
+            RPCMessageType.STATUS,
+            RPCMessageType.STARTUP,
+            RPCMessageType.EXCEPTION,
+            RPCMessageType.WARNING,
+        ):
+            valuedict = whconfig.get("webhookstatus")
+        elif msg["type"] in (
+            RPCMessageType.PROTECTION_TRIGGER,
+            RPCMessageType.PROTECTION_TRIGGER_GLOBAL,
+            RPCMessageType.WHITELIST,
+            RPCMessageType.ANALYZED_DF,
+            RPCMessageType.NEW_CANDLE,
+            RPCMessageType.STRATEGY_MSG,
+        ):
             # Don't fail for non-implemented types
             return None
         return valuedict
 
     def send_msg(self, msg: RPCSendMsg) -> None:
-        """ Send a message to telegram channel """
+        """Send a message to telegram channel"""
         try:
-
             valuedict = self._get_value_dict(msg)
 
             if not valuedict:
-                logger.debug("Message type '%s' not configured for webhooks", msg['type'])
+                logger.debug("Message type '%s' not configured for webhooks", msg["type"])
                 return
 
             payload = {key: value.format(**msg) for (key, value) in valuedict.items()}
             self._send_msg(payload)
         except KeyError as exc:
-            logger.exception("Problem calling Webhook. Please check your webhook configuration. "
-                             "Exception: %s", exc)
+            logger.exception(
+                "Problem calling Webhook. Please check your webhook configuration. "
+                "Exception: %s",
+                exc,
+            )
 
     def _send_msg(self, payload: dict) -> None:
         """do the actual call to the webhook"""
 
         success = False
         attempts = 0
         while not success and attempts <= self._retries:
@@ -103,24 +109,27 @@
                 if self._retry_delay:
                     time.sleep(self._retry_delay)
                 logger.info("Retrying webhook...")
 
             attempts += 1
 
             try:
-                if self._format == 'form':
+                if self._format == "form":
                     response = post(self._url, data=payload, timeout=self._timeout)
-                elif self._format == 'json':
+                elif self._format == "json":
                     response = post(self._url, json=payload, timeout=self._timeout)
-                elif self._format == 'raw':
-                    response = post(self._url, data=payload['data'],
-                                    headers={'Content-Type': 'text/plain'},
-                                    timeout=self._timeout)
+                elif self._format == "raw":
+                    response = post(
+                        self._url,
+                        data=payload["data"],
+                        headers={"Content-Type": "text/plain"},
+                        timeout=self._timeout,
+                    )
                 else:
-                    raise NotImplementedError(f'Unknown format: {self._format}')
+                    raise NotImplementedError(f"Unknown format: {self._format}")
 
                 # Throw a RequestException if the post was not successful
                 response.raise_for_status()
                 success = True
 
             except RequestException as exc:
                 logger.warning("Could not call webhook url. Exception: %s", exc)
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/__init__.py` & `freqtrade-2024.5/freqtrade/strategy/__init__.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,9 +1,22 @@
 # flake8: noqa: F401
-from freqtrade.exchange import (timeframe_to_minutes, timeframe_to_msecs, timeframe_to_next_date,
-                                timeframe_to_prev_date, timeframe_to_seconds)
+from freqtrade.exchange import (
+    timeframe_to_minutes,
+    timeframe_to_msecs,
+    timeframe_to_next_date,
+    timeframe_to_prev_date,
+    timeframe_to_seconds,
+)
 from freqtrade.strategy.informative_decorator import informative
 from freqtrade.strategy.interface import IStrategy
-from freqtrade.strategy.parameters import (BooleanParameter, CategoricalParameter, DecimalParameter,
-                                           IntParameter, RealParameter)
-from freqtrade.strategy.strategy_helper import (merge_informative_pair, stoploss_from_absolute,
-                                                stoploss_from_open)
+from freqtrade.strategy.parameters import (
+    BooleanParameter,
+    CategoricalParameter,
+    DecimalParameter,
+    IntParameter,
+    RealParameter,
+)
+from freqtrade.strategy.strategy_helper import (
+    merge_informative_pair,
+    stoploss_from_absolute,
+    stoploss_from_open,
+)
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/hyper.py` & `freqtrade-2024.5/freqtrade/strategy/hyper.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 """
 IHyperStrategy interface, hyperoptable Parameter class.
 This module defines a base class for auto-hyperoptable strategies.
 """
+
 import logging
 from pathlib import Path
 from typing import Any, Dict, Iterator, List, Optional, Tuple, Type, Union
 
 from freqtrade.constants import Config
 from freqtrade.exceptions import OperationalException
 from freqtrade.misc import deep_merge_dicts
@@ -28,109 +29,117 @@
         """
         self.config = config
         self.ft_buy_params: List[BaseParameter] = []
         self.ft_sell_params: List[BaseParameter] = []
         self.ft_protection_params: List[BaseParameter] = []
 
         params = self.load_params_from_file()
-        params = params.get('params', {})
+        params = params.get("params", {})
         self._ft_params_from_file = params
         # Init/loading of parameters is done as part of ft_bot_start().
 
     def enumerate_parameters(
-            self, category: Optional[str] = None) -> Iterator[Tuple[str, BaseParameter]]:
+        self, category: Optional[str] = None
+    ) -> Iterator[Tuple[str, BaseParameter]]:
         """
         Find all optimizable parameters and return (name, attr) iterator.
         :param category:
         :return:
         """
-        if category not in ('buy', 'sell', 'protection', None):
+        if category not in ("buy", "sell", "protection", None):
             raise OperationalException(
-                'Category must be one of: "buy", "sell", "protection", None.')
+                'Category must be one of: "buy", "sell", "protection", None.'
+            )
 
         if category is None:
             params = self.ft_buy_params + self.ft_sell_params + self.ft_protection_params
         else:
             params = getattr(self, f"ft_{category}_params")
 
         for par in params:
             yield par.name, par
 
     @classmethod
     def detect_all_parameters(cls) -> Dict:
-        """ Detect all parameters and return them as a list"""
+        """Detect all parameters and return them as a list"""
         params: Dict[str, Any] = {
-            'buy': list(detect_parameters(cls, 'buy')),
-            'sell': list(detect_parameters(cls, 'sell')),
-            'protection': list(detect_parameters(cls, 'protection')),
+            "buy": list(detect_parameters(cls, "buy")),
+            "sell": list(detect_parameters(cls, "sell")),
+            "protection": list(detect_parameters(cls, "protection")),
         }
-        params.update({
-            'count': len(params['buy'] + params['sell'] + params['protection'])
-        })
+        params.update({"count": len(params["buy"] + params["sell"] + params["protection"])})
 
         return params
 
     def ft_load_params_from_file(self) -> None:
         """
         Load Parameters from parameter file
         Should/must run before config values are loaded in strategy_resolver.
         """
         if self._ft_params_from_file:
             # Set parameters from Hyperopt results file
             params = self._ft_params_from_file
-            self.minimal_roi = params.get('roi', getattr(self, 'minimal_roi', {}))
+            self.minimal_roi = params.get("roi", getattr(self, "minimal_roi", {}))
 
-            self.stoploss = params.get('stoploss', {}).get(
-                'stoploss', getattr(self, 'stoploss', -0.1))
-            self.max_open_trades = params.get('max_open_trades', {}).get(
-                'max_open_trades', getattr(self, 'max_open_trades', -1))
-            trailing = params.get('trailing', {})
+            self.stoploss = params.get("stoploss", {}).get(
+                "stoploss", getattr(self, "stoploss", -0.1)
+            )
+            self.max_open_trades = params.get("max_open_trades", {}).get(
+                "max_open_trades", getattr(self, "max_open_trades", -1)
+            )
+            trailing = params.get("trailing", {})
             self.trailing_stop = trailing.get(
-                'trailing_stop', getattr(self, 'trailing_stop', False))
+                "trailing_stop", getattr(self, "trailing_stop", False)
+            )
             self.trailing_stop_positive = trailing.get(
-                'trailing_stop_positive', getattr(self, 'trailing_stop_positive', None))
+                "trailing_stop_positive", getattr(self, "trailing_stop_positive", None)
+            )
             self.trailing_stop_positive_offset = trailing.get(
-                'trailing_stop_positive_offset',
-                getattr(self, 'trailing_stop_positive_offset', 0))
+                "trailing_stop_positive_offset", getattr(self, "trailing_stop_positive_offset", 0)
+            )
             self.trailing_only_offset_is_reached = trailing.get(
-                'trailing_only_offset_is_reached',
-                getattr(self, 'trailing_only_offset_is_reached', 0.0))
+                "trailing_only_offset_is_reached",
+                getattr(self, "trailing_only_offset_is_reached", 0.0),
+            )
 
     def ft_load_hyper_params(self, hyperopt: bool = False) -> None:
         """
         Load Hyperoptable parameters
         Prevalence:
         * Parameters from parameter file
         * Parameters defined in parameters objects (buy_params, sell_params, ...)
         * Parameter defaults
         """
 
-        buy_params = deep_merge_dicts(self._ft_params_from_file.get('buy', {}),
-                                      getattr(self, 'buy_params', {}))
-        sell_params = deep_merge_dicts(self._ft_params_from_file.get('sell', {}),
-                                       getattr(self, 'sell_params', {}))
-        protection_params = deep_merge_dicts(self._ft_params_from_file.get('protection', {}),
-                                             getattr(self, 'protection_params', {}))
-
-        self._ft_load_params(buy_params, 'buy', hyperopt)
-        self._ft_load_params(sell_params, 'sell', hyperopt)
-        self._ft_load_params(protection_params, 'protection', hyperopt)
+        buy_params = deep_merge_dicts(
+            self._ft_params_from_file.get("buy", {}), getattr(self, "buy_params", {})
+        )
+        sell_params = deep_merge_dicts(
+            self._ft_params_from_file.get("sell", {}), getattr(self, "sell_params", {})
+        )
+        protection_params = deep_merge_dicts(
+            self._ft_params_from_file.get("protection", {}), getattr(self, "protection_params", {})
+        )
+
+        self._ft_load_params(buy_params, "buy", hyperopt)
+        self._ft_load_params(sell_params, "sell", hyperopt)
+        self._ft_load_params(protection_params, "protection", hyperopt)
 
     def load_params_from_file(self) -> Dict:
-        filename_str = getattr(self, '__file__', '')
+        filename_str = getattr(self, "__file__", "")
         if not filename_str:
             return {}
-        filename = Path(filename_str).with_suffix('.json')
+        filename = Path(filename_str).with_suffix(".json")
 
         if filename.is_file():
             logger.info(f"Loading parameters from file {filename}")
             try:
                 params = HyperoptTools.load_params(filename)
-                if params.get('strategy_name') != self.__class__.__name__:
-                    raise OperationalException('Invalid parameter file provided.')
+                if params.get("strategy_name") != self.__class__.__name__:
+                    raise OperationalException("Invalid parameter file provided.")
                 return params
             except ValueError:
                 logger.warning("Invalid parameter file format.")
                 return {}
         logger.info("Found no parameter file.")
 
         return {}
@@ -151,50 +160,56 @@
                 attr.category = space
 
             param_container.append(attr)
 
             if params and attr_name in params:
                 if attr.load:
                     attr.value = params[attr_name]
-                    logger.info(f'Strategy Parameter: {attr_name} = {attr.value}')
+                    logger.info(f"Strategy Parameter: {attr_name} = {attr.value}")
                 else:
-                    logger.warning(f'Parameter "{attr_name}" exists, but is disabled. '
-                                   f'Default value "{attr.value}" used.')
+                    logger.warning(
+                        f'Parameter "{attr_name}" exists, but is disabled. '
+                        f'Default value "{attr.value}" used.'
+                    )
             else:
-                logger.info(f'Strategy Parameter(default): {attr_name} = {attr.value}')
+                logger.info(f"Strategy Parameter(default): {attr_name} = {attr.value}")
 
     def get_no_optimize_params(self) -> Dict[str, Dict]:
         """
         Returns list of Parameters that are not part of the current optimize job
         """
         params: Dict[str, Dict] = {
-            'buy': {},
-            'sell': {},
-            'protection': {},
+            "buy": {},
+            "sell": {},
+            "protection": {},
         }
         for name, p in self.enumerate_parameters():
             if p.category and (not p.optimize or not p.in_space):
                 params[p.category][name] = p.value
         return params
 
 
 def detect_parameters(
-        obj: Union[HyperStrategyMixin, Type[HyperStrategyMixin]],
-        category: str
-        ) -> Iterator[Tuple[str, BaseParameter]]:
+    obj: Union[HyperStrategyMixin, Type[HyperStrategyMixin]], category: str
+) -> Iterator[Tuple[str, BaseParameter]]:
     """
     Detect all parameters for 'category' for "obj"
     :param obj: Strategy object or class
     :param category: category - usually `'buy', 'sell', 'protection',...
     """
     for attr_name in dir(obj):
-        if not attr_name.startswith('__'):  # Ignore internals, not strictly necessary.
+        if not attr_name.startswith("__"):  # Ignore internals, not strictly necessary.
             attr = getattr(obj, attr_name)
             if issubclass(attr.__class__, BaseParameter):
-                if (attr_name.startswith(category + '_')
-                        and attr.category is not None and attr.category != category):
+                if (
+                    attr_name.startswith(category + "_")
+                    and attr.category is not None
+                    and attr.category != category
+                ):
                     raise OperationalException(
-                        f'Inconclusive parameter name {attr_name}, category: {attr.category}.')
+                        f"Inconclusive parameter name {attr_name}, category: {attr.category}."
+                    )
 
-                if (category == attr.category or
-                        (attr_name.startswith(category + '_') and attr.category is None)):
+                if category == attr.category or (
+                    attr_name.startswith(category + "_") and attr.category is None
+                ):
                     yield attr_name, attr
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/informative_decorator.py` & `freqtrade-2024.5/freqtrade/strategy/informative_decorator.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,19 +16,22 @@
     asset: Optional[str]
     timeframe: str
     fmt: Union[str, Callable[[Any], str], None]
     ffill: bool
     candle_type: Optional[CandleType]
 
 
-def informative(timeframe: str, asset: str = '',
-                fmt: Optional[Union[str, Callable[[Any], str]]] = None,
-                *,
-                candle_type: Optional[Union[CandleType, str]] = None,
-                ffill: bool = True) -> Callable[[PopulateIndicators], PopulateIndicators]:
+def informative(
+    timeframe: str,
+    asset: str = "",
+    fmt: Optional[Union[str, Callable[[Any], str]]] = None,
+    *,
+    candle_type: Optional[Union[CandleType, str]] = None,
+    ffill: bool = True,
+) -> Callable[[PopulateIndicators], PopulateIndicators]:
     """
     A decorator for populate_indicators_Nn(self, dataframe, metadata), allowing these functions to
     define informative indicators.
 
     Example usage:
 
         @informative('1h')
@@ -58,93 +61,105 @@
     _asset = asset
     _timeframe = timeframe
     _fmt = fmt
     _ffill = ffill
     _candle_type = CandleType.from_string(candle_type) if candle_type else None
 
     def decorator(fn: PopulateIndicators):
-        informative_pairs = getattr(fn, '_ft_informative', [])
+        informative_pairs = getattr(fn, "_ft_informative", [])
         informative_pairs.append(InformativeData(_asset, _timeframe, _fmt, _ffill, _candle_type))
-        setattr(fn, '_ft_informative', informative_pairs)  # noqa: B010
+        setattr(fn, "_ft_informative", informative_pairs)  # noqa: B010
         return fn
+
     return decorator
 
 
 def __get_pair_formats(market: Optional[Dict[str, Any]]) -> Dict[str, str]:
     if not market:
         return {}
-    base = market['base']
-    quote = market['quote']
+    base = market["base"]
+    quote = market["quote"]
     return {
-        'base': base.lower(),
-        'BASE': base.upper(),
-        'quote': quote.lower(),
-        'QUOTE': quote.upper(),
+        "base": base.lower(),
+        "BASE": base.upper(),
+        "quote": quote.lower(),
+        "QUOTE": quote.upper(),
     }
 
 
 def _format_pair_name(config, pair: str, market: Optional[Dict[str, Any]] = None) -> str:
     return pair.format(
-        stake_currency=config['stake_currency'],
-        stake=config['stake_currency'],
+        stake_currency=config["stake_currency"],
+        stake=config["stake_currency"],
         **__get_pair_formats(market),
     ).upper()
 
 
-def _create_and_merge_informative_pair(strategy, dataframe: DataFrame, metadata: dict,
-                                       inf_data: InformativeData,
-                                       populate_indicators: PopulateIndicators):
-    asset = inf_data.asset or ''
+def _create_and_merge_informative_pair(
+    strategy,
+    dataframe: DataFrame,
+    metadata: dict,
+    inf_data: InformativeData,
+    populate_indicators: PopulateIndicators,
+):
+    asset = inf_data.asset or ""
     timeframe = inf_data.timeframe
     fmt = inf_data.fmt
     candle_type = inf_data.candle_type
 
     config = strategy.config
 
     if asset:
         # Insert stake currency if needed.
-        market1 = strategy.dp.market(metadata['pair'])
+        market1 = strategy.dp.market(metadata["pair"])
         asset = _format_pair_name(config, asset, market1)
     else:
         # Not specifying an asset will define informative dataframe for current pair.
-        asset = metadata['pair']
+        asset = metadata["pair"]
 
     market = strategy.dp.market(asset)
     if market is None:
-        raise OperationalException(f'Market {asset} is not available.')
+        raise OperationalException(f"Market {asset} is not available.")
 
     # Default format. This optimizes for the common case: informative pairs using same stake
     # currency. When quote currency matches stake currency, column name will omit base currency.
     # This allows easily reconfiguring strategy to use different base currency. In a rare case
     # where it is desired to keep quote currency in column name at all times user should specify
     # fmt='{base}_{quote}_{column}_{timeframe}' format or similar.
     if not fmt:
-        fmt = '{column}_{timeframe}'                # Informatives of current pair
+        fmt = "{column}_{timeframe}"  # Informatives of current pair
         if inf_data.asset:
-            fmt = '{base}_{quote}_' + fmt           # Informatives of other pairs
+            fmt = "{base}_{quote}_" + fmt  # Informatives of other pairs
 
-    inf_metadata = {'pair': asset, 'timeframe': timeframe}
+    inf_metadata = {"pair": asset, "timeframe": timeframe}
     inf_dataframe = strategy.dp.get_pair_dataframe(asset, timeframe, candle_type)
     inf_dataframe = populate_indicators(strategy, inf_dataframe, inf_metadata)
 
     formatter: Any = None
     if callable(fmt):
-        formatter = fmt             # A custom user-specified formatter function.
+        formatter = fmt  # A custom user-specified formatter function.
     else:
-        formatter = fmt.format      # A default string formatter.
+        formatter = fmt.format  # A default string formatter.
 
     fmt_args = {
         **__get_pair_formats(market),
-        'asset': asset,
-        'timeframe': timeframe,
+        "asset": asset,
+        "timeframe": timeframe,
     }
-    inf_dataframe.rename(columns=lambda column: formatter(column=column, **fmt_args),
-                         inplace=True)
+    inf_dataframe.rename(columns=lambda column: formatter(column=column, **fmt_args), inplace=True)
 
-    date_column = formatter(column='date', **fmt_args)
+    date_column = formatter(column="date", **fmt_args)
     if date_column in dataframe.columns:
-        raise OperationalException(f'Duplicate column name {date_column} exists in '
-                                   f'dataframe! Ensure column names are unique!')
-    dataframe = merge_informative_pair(dataframe, inf_dataframe, strategy.timeframe, timeframe,
-                                       ffill=inf_data.ffill, append_timeframe=False,
-                                       date_column=date_column)
+        raise OperationalException(
+            f"Duplicate column name {date_column} exists in "
+            f"dataframe! Ensure column names are unique!"
+        )
+    dataframe = merge_informative_pair(
+        dataframe,
+        inf_dataframe,
+        strategy.timeframe,
+        timeframe,
+        ffill=inf_data.ffill,
+        append_timeframe=False,
+        date_column=date_column,
+    )
     return dataframe
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/interface.py` & `freqtrade-2024.5/freqtrade/strategy/interface.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,43 @@
 """
 IStrategy interface
 This module defines the interface to apply for strategies
 """
+
 import logging
 from abc import ABC, abstractmethod
 from datetime import datetime, timedelta, timezone
 from typing import Dict, List, Optional, Tuple, Union
 
 from pandas import DataFrame
 
 from freqtrade.constants import CUSTOM_TAG_MAX_LENGTH, Config, IntOrInf, ListPairsWithTimeframes
 from freqtrade.data.dataprovider import DataProvider
-from freqtrade.enums import (CandleType, ExitCheckTuple, ExitType, MarketDirection, RunMode,
-                             SignalDirection, SignalTagType, SignalType, TradingMode)
+from freqtrade.enums import (
+    CandleType,
+    ExitCheckTuple,
+    ExitType,
+    MarketDirection,
+    RunMode,
+    SignalDirection,
+    SignalTagType,
+    SignalType,
+    TradingMode,
+)
 from freqtrade.exceptions import OperationalException, StrategyError
 from freqtrade.exchange import timeframe_to_minutes, timeframe_to_next_date, timeframe_to_seconds
 from freqtrade.misc import remove_entry_exit_signals
 from freqtrade.persistence import Order, PairLocks, Trade
 from freqtrade.strategy.hyper import HyperStrategyMixin
-from freqtrade.strategy.informative_decorator import (InformativeData, PopulateIndicators,
-                                                      _create_and_merge_informative_pair,
-                                                      _format_pair_name)
+from freqtrade.strategy.informative_decorator import (
+    InformativeData,
+    PopulateIndicators,
+    _create_and_merge_informative_pair,
+    _format_pair_name,
+)
 from freqtrade.strategy.strategy_wrapper import strategy_safe_wrapper
 from freqtrade.util import dt_now
 from freqtrade.wallets import Wallets
 
 
 logger = logging.getLogger(__name__)
 
@@ -35,14 +48,15 @@
     Defines the mandatory structure must follow any custom strategies
 
     Attributes you can use:
         minimal_roi -> Dict: Minimal ROI designed for the strategy
         stoploss -> float: optimal stoploss designed for the strategy
         timeframe -> str: value of the timeframe to use with the strategy
     """
+
     # Strategy interface version
     # Default to version 2
     # Version 1 is the initial interface without metadata dict - deprecated and no longer supported.
     # Version 2 populate_* include metadata dict
     # Version 3 - First version with short and leverage support
     INTERFACE_VERSION: int = 3
 
@@ -50,15 +64,15 @@
     # associated minimal roi
     minimal_roi: Dict = {}
 
     # associated stoploss
     stoploss: float
 
     # max open trades for the strategy
-    max_open_trades:  IntOrInf
+    max_open_trades: IntOrInf
 
     # trailing stoploss
     trailing_stop: bool = False
     trailing_stop_positive: Optional[float] = None
     trailing_stop_positive_offset: float = 0.0
     trailing_only_offset_is_reached = False
     use_custom_stoploss: bool = False
@@ -67,25 +81,25 @@
     can_short: bool = False
 
     # associated timeframe
     timeframe: str
 
     # Optional order types
     order_types: Dict = {
-        'entry': 'limit',
-        'exit': 'limit',
-        'stoploss': 'limit',
-        'stoploss_on_exchange': False,
-        'stoploss_on_exchange_interval': 60,
+        "entry": "limit",
+        "exit": "limit",
+        "stoploss": "limit",
+        "stoploss_on_exchange": False,
+        "stoploss_on_exchange_interval": 60,
     }
 
     # Optional time in force
     order_time_in_force: Dict = {
-        'entry': 'GTC',
-        'exit': 'GTC',
+        "entry": "GTC",
+        "exit": "GTC",
     }
 
     # run "populate_indicators" only for new candle
     process_only_new_candles: bool = True
 
     use_exit_signal: bool
     exit_profit_only: bool
@@ -112,15 +126,15 @@
     # the dataprovider (dp) (access to other candles, historic data, ...)
     # and wallets - access to the current balance.
     dp: DataProvider
     wallets: Optional[Wallets] = None
     # Filled from configuration
     stake_currency: str
     # container variable for strategy source code
-    __source__: str = ''
+    __source__: str = ""
 
     # Definition of plot_config. See plotting documentation for more details.
     plot_config: Dict = {}
 
     # A self set parameter that represents the market direction. filled from configuration
     market_direction: MarketDirection = MarketDirection.NONE
 
@@ -132,51 +146,54 @@
 
         # Gather informative pairs from @informative-decorated methods.
         self._ft_informative: List[Tuple[InformativeData, PopulateIndicators]] = []
         for attr_name in dir(self.__class__):
             cls_method = getattr(self.__class__, attr_name)
             if not callable(cls_method):
                 continue
-            informative_data_list = getattr(cls_method, '_ft_informative', None)
+            informative_data_list = getattr(cls_method, "_ft_informative", None)
             if not isinstance(informative_data_list, list):
                 # Type check is required because mocker would return a mock object that evaluates to
                 # True, confusing this code.
                 continue
             strategy_timeframe_minutes = timeframe_to_minutes(self.timeframe)
             for informative_data in informative_data_list:
                 if timeframe_to_minutes(informative_data.timeframe) < strategy_timeframe_minutes:
-                    raise OperationalException('Informative timeframe must be equal or higher than '
-                                               'strategy timeframe!')
+                    raise OperationalException(
+                        "Informative timeframe must be equal or higher than strategy timeframe!"
+                    )
                 if not informative_data.candle_type:
-                    informative_data.candle_type = config['candle_type_def']
+                    informative_data.candle_type = config["candle_type_def"]
                 self._ft_informative.append((informative_data, cls_method))
 
     def load_freqAI_model(self) -> None:
-        if self.config.get('freqai', {}).get('enabled', False):
+        if self.config.get("freqai", {}).get("enabled", False):
             # Import here to avoid importing this if freqAI is disabled
             from freqtrade.freqai.utils import download_all_data_for_training
             from freqtrade.resolvers.freqaimodel_resolver import FreqaiModelResolver
+
             self.freqai = FreqaiModelResolver.load_freqaimodel(self.config)
             self.freqai_info = self.config["freqai"]
 
             # download the desired data in dry/live
-            if self.config.get('runmode') in (RunMode.DRY_RUN, RunMode.LIVE):
+            if self.config.get("runmode") in (RunMode.DRY_RUN, RunMode.LIVE):
                 logger.info(
                     "Downloading all training data for all pairs in whitelist and "
                     "corr_pairlist, this may take a while if the data is not "
                     "already on disk."
                 )
                 download_all_data_for_training(self.dp, self.config)
         else:
             # Gracious failures if freqAI is disabled but "start" is called.
             class DummyClass:
                 def start(self, *args, **kwargs):
                     raise OperationalException(
-                        'freqAI is not enabled. '
-                        'Please enable it in your config to use this strategy.')
+                        "freqAI is not enabled. "
+                        "Please enable it in your config to use this strategy."
+                    )
 
                 def shutdown(self, *args, **kwargs):
                     pass
 
             self.freqai = DummyClass()  # type: ignore
 
     def ft_bot_start(self, **kwargs) -> None:
@@ -184,15 +201,15 @@
         Strategy init - runs after dataprovider has been added.
         Must call bot_start()
         """
         self.load_freqAI_model()
 
         strategy_safe_wrapper(self.bot_start)()
 
-        self.ft_load_hyper_params(self.config.get('runmode') == RunMode.HYPEROPT)
+        self.ft_load_hyper_params(self.config.get("runmode") == RunMode.HYPEROPT)
 
     def ft_bot_cleanup(self) -> None:
         """
         Clean up FreqAI and child threads
         """
         self.freqai.shutdown()
 
@@ -256,23 +273,25 @@
         Might be used to perform pair-independent tasks
         (e.g. gather some remote resource for comparison)
         :param current_time: datetime object, containing the current datetime
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         """
         pass
 
-    def check_buy_timeout(self, pair: str, trade: Trade, order: Order,
-                          current_time: datetime, **kwargs) -> bool:
+    def check_buy_timeout(
+        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs
+    ) -> bool:
         """
         DEPRECATED: Please use `check_entry_timeout` instead.
         """
         return False
 
-    def check_entry_timeout(self, pair: str, trade: Trade, order: Order,
-                            current_time: datetime, **kwargs) -> bool:
+    def check_entry_timeout(
+        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs
+    ) -> bool:
         """
         Check entry timeout function callback.
         This method can be used to override the entry-timeout.
         It is called whenever a limit entry order has been created,
         and is not yet fully filled.
         Configuration options in `unfilledtimeout` will be verified before this,
         so ensure to set these timeouts high enough.
@@ -282,25 +301,28 @@
         :param trade: Trade object.
         :param order: Order object.
         :param current_time: datetime object, containing the current datetime
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return bool: When True is returned, then the entry order is cancelled.
         """
         return self.check_buy_timeout(
-            pair=pair, trade=trade, order=order, current_time=current_time)
+            pair=pair, trade=trade, order=order, current_time=current_time
+        )
 
-    def check_sell_timeout(self, pair: str, trade: Trade, order: Order,
-                           current_time: datetime, **kwargs) -> bool:
+    def check_sell_timeout(
+        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs
+    ) -> bool:
         """
         DEPRECATED: Please use `check_exit_timeout` instead.
         """
         return False
 
-    def check_exit_timeout(self, pair: str, trade: Trade, order: Order,
-                           current_time: datetime, **kwargs) -> bool:
+    def check_exit_timeout(
+        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs
+    ) -> bool:
         """
         Check exit timeout function callback.
         This method can be used to override the exit-timeout.
         It is called whenever a limit exit order has been created,
         and is not yet fully filled.
         Configuration options in `unfilledtimeout` will be verified before this,
         so ensure to set these timeouts high enough.
@@ -310,19 +332,29 @@
         :param trade: Trade object.
         :param order: Order object
         :param current_time: datetime object, containing the current datetime
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return bool: When True is returned, then the exit-order is cancelled.
         """
         return self.check_sell_timeout(
-            pair=pair, trade=trade, order=order, current_time=current_time)
+            pair=pair, trade=trade, order=order, current_time=current_time
+        )
 
-    def confirm_trade_entry(self, pair: str, order_type: str, amount: float, rate: float,
-                            time_in_force: str, current_time: datetime, entry_tag: Optional[str],
-                            side: str, **kwargs) -> bool:
+    def confirm_trade_entry(
+        self,
+        pair: str,
+        order_type: str,
+        amount: float,
+        rate: float,
+        time_in_force: str,
+        current_time: datetime,
+        entry_tag: Optional[str],
+        side: str,
+        **kwargs,
+    ) -> bool:
         """
         Called right before placing a entry order.
         Timing for this function is critical, so avoid doing heavy computations or
         network requests in this method.
 
         For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/
 
@@ -339,17 +371,26 @@
         :param side: 'long' or 'short' - indicating the direction of the proposed trade
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return bool: When True is returned, then the buy-order is placed on the exchange.
             False aborts the process
         """
         return True
 
-    def confirm_trade_exit(self, pair: str, trade: Trade, order_type: str, amount: float,
-                           rate: float, time_in_force: str, exit_reason: str,
-                           current_time: datetime, **kwargs) -> bool:
+    def confirm_trade_exit(
+        self,
+        pair: str,
+        trade: Trade,
+        order_type: str,
+        amount: float,
+        rate: float,
+        time_in_force: str,
+        exit_reason: str,
+        current_time: datetime,
+        **kwargs,
+    ) -> bool:
         """
         Called right before placing a regular exit order.
         Timing for this function is critical, so avoid doing heavy computations or
         network requests in this method.
 
         For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/
 
@@ -368,29 +409,38 @@
         :param current_time: datetime object, containing the current datetime
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return bool: When True, then the exit-order is placed on the exchange.
             False aborts the process
         """
         return True
 
-    def order_filled(self, pair: str, trade: Trade, order: Order,
-                     current_time: datetime, **kwargs) -> None:
+    def order_filled(
+        self, pair: str, trade: Trade, order: Order, current_time: datetime, **kwargs
+    ) -> None:
         """
         Called right after an order fills.
         Will be called for all order types (entry, exit, stoploss, position adjustment).
         :param pair: Pair for trade
         :param trade: trade object.
         :param order: Order object.
         :param current_time: datetime object, containing the current datetime
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         """
         pass
 
-    def custom_stoploss(self, pair: str, trade: Trade, current_time: datetime, current_rate: float,
-                        current_profit: float, after_fill: bool, **kwargs) -> Optional[float]:
+    def custom_stoploss(
+        self,
+        pair: str,
+        trade: Trade,
+        current_time: datetime,
+        current_rate: float,
+        current_profit: float,
+        after_fill: bool,
+        **kwargs,
+    ) -> Optional[float]:
         """
         Custom stoploss logic, returning the new distance relative to current_rate (as ratio).
         e.g. returning -0.05 would create a stoploss 5% below current_rate.
         The custom stoploss can never be below self.stoploss, which serves as a hard maximum loss.
 
         For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/
 
@@ -404,17 +454,24 @@
         :param current_profit: Current profit (as ratio), calculated based on current_rate.
         :param after_fill: True if the stoploss is called after the order was filled.
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return float: New stoploss value, relative to the current_rate
         """
         return self.stoploss
 
-    def custom_entry_price(self, pair: str, trade: Optional[Trade],
-                           current_time: datetime, proposed_rate: float,
-                           entry_tag: Optional[str], side: str, **kwargs) -> float:
+    def custom_entry_price(
+        self,
+        pair: str,
+        trade: Optional[Trade],
+        current_time: datetime,
+        proposed_rate: float,
+        entry_tag: Optional[str],
+        side: str,
+        **kwargs,
+    ) -> float:
         """
         Custom entry price logic, returning the new entry price.
 
         For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/
 
         When not implemented by a strategy, returns None, orderbook is used to set entry price
 
@@ -425,17 +482,24 @@
         :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.
         :param side: 'long' or 'short' - indicating the direction of the proposed trade
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return float: New entry price value if provided
         """
         return proposed_rate
 
-    def custom_exit_price(self, pair: str, trade: Trade,
-                          current_time: datetime, proposed_rate: float,
-                          current_profit: float, exit_tag: Optional[str], **kwargs) -> float:
+    def custom_exit_price(
+        self,
+        pair: str,
+        trade: Trade,
+        current_time: datetime,
+        proposed_rate: float,
+        current_profit: float,
+        exit_tag: Optional[str],
+        **kwargs,
+    ) -> float:
         """
         Custom exit price logic, returning the new exit price.
 
         For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/
 
         When not implemented by a strategy, returns None, orderbook is used to set exit price
 
@@ -446,16 +510,23 @@
         :param current_profit: Current profit (as ratio), calculated based on current_rate.
         :param exit_tag: Exit reason.
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return float: New exit price value if provided
         """
         return proposed_rate
 
-    def custom_sell(self, pair: str, trade: Trade, current_time: datetime, current_rate: float,
-                    current_profit: float, **kwargs) -> Optional[Union[str, bool]]:
+    def custom_sell(
+        self,
+        pair: str,
+        trade: Trade,
+        current_time: datetime,
+        current_rate: float,
+        current_profit: float,
+        **kwargs,
+    ) -> Optional[Union[str, bool]]:
         """
         DEPRECATED - please use custom_exit instead.
         Custom exit signal logic indicating that specified position should be sold. Returning a
         string or True from this method is equal to setting exit signal on a candle at specified
         time. This method is not called when exit signal is set.
 
         This method should be overridden to create exit signals that depend on trade parameters. For
@@ -471,16 +542,23 @@
         :param current_profit: Current profit (as ratio), calculated based on current_rate.
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return: To execute exit, return a string with custom exit reason or True. Otherwise return
         None or False.
         """
         return None
 
-    def custom_exit(self, pair: str, trade: Trade, current_time: datetime, current_rate: float,
-                    current_profit: float, **kwargs) -> Optional[Union[str, bool]]:
+    def custom_exit(
+        self,
+        pair: str,
+        trade: Trade,
+        current_time: datetime,
+        current_rate: float,
+        current_profit: float,
+        **kwargs,
+    ) -> Optional[Union[str, bool]]:
         """
         Custom exit signal logic indicating that specified position should be sold. Returning a
         string or True from this method is equal to setting exit signal on a candle at specified
         time. This method is not called when exit signal is set.
 
         This method should be overridden to create exit signals that depend on trade parameters. For
         example you could implement an exit relative to the candle when the trade was opened,
@@ -495,18 +573,27 @@
         :param current_profit: Current profit (as ratio), calculated based on current_rate.
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return: To execute exit, return a string with custom exit reason or True. Otherwise return
         None or False.
         """
         return self.custom_sell(pair, trade, current_time, current_rate, current_profit, **kwargs)
 
-    def custom_stake_amount(self, pair: str, current_time: datetime, current_rate: float,
-                            proposed_stake: float, min_stake: Optional[float], max_stake: float,
-                            leverage: float, entry_tag: Optional[str], side: str,
-                            **kwargs) -> float:
+    def custom_stake_amount(
+        self,
+        pair: str,
+        current_time: datetime,
+        current_rate: float,
+        proposed_stake: float,
+        min_stake: Optional[float],
+        max_stake: float,
+        leverage: float,
+        entry_tag: Optional[str],
+        side: str,
+        **kwargs,
+    ) -> float:
         """
         Customize stake size for each new trade.
 
         :param pair: Pair that's currently analyzed
         :param current_time: datetime object, containing the current datetime
         :param current_rate: Rate, calculated based on pricing settings in exit_pricing.
         :param proposed_stake: A stake amount proposed by the bot.
@@ -515,21 +602,28 @@
         :param leverage: Leverage selected for this trade.
         :param entry_tag: Optional entry_tag (buy_tag) if provided with the buy signal.
         :param side: 'long' or 'short' - indicating the direction of the proposed trade
         :return: A stake size, which is between min_stake and max_stake.
         """
         return proposed_stake
 
-    def adjust_trade_position(self, trade: Trade, current_time: datetime,
-                              current_rate: float, current_profit: float,
-                              min_stake: Optional[float], max_stake: float,
-                              current_entry_rate: float, current_exit_rate: float,
-                              current_entry_profit: float, current_exit_profit: float,
-                              **kwargs
-                              ) -> Union[Optional[float], Tuple[Optional[float], Optional[str]]]:
+    def adjust_trade_position(
+        self,
+        trade: Trade,
+        current_time: datetime,
+        current_rate: float,
+        current_profit: float,
+        min_stake: Optional[float],
+        max_stake: float,
+        current_entry_rate: float,
+        current_exit_rate: float,
+        current_entry_profit: float,
+        current_exit_profit: float,
+        **kwargs,
+    ) -> Union[Optional[float], Tuple[Optional[float], Optional[str]]]:
         """
         Custom trade adjustment logic, returning the stake amount that a trade should be
         increased or decreased.
         This means extra entry or exit orders with additional fees.
         Only called when `position_adjustment_enable` is set to True.
 
         For full documentation please go to https://www.freqtrade.io/en/latest/strategy-advanced/
@@ -551,17 +645,26 @@
         :return float: Stake amount to adjust your trade,
                        Positive values to increase position, Negative values to decrease position.
                        Return None for no action.
                        Optionally, return a tuple with a 2nd element with an order reason
         """
         return None
 
-    def adjust_entry_price(self, trade: Trade, order: Optional[Order], pair: str,
-                           current_time: datetime, proposed_rate: float, current_order_rate: float,
-                           entry_tag: Optional[str], side: str, **kwargs) -> float:
+    def adjust_entry_price(
+        self,
+        trade: Trade,
+        order: Optional[Order],
+        pair: str,
+        current_time: datetime,
+        proposed_rate: float,
+        current_order_rate: float,
+        entry_tag: Optional[str],
+        side: str,
+        **kwargs,
+    ) -> float:
         """
         Entry price re-adjustment logic, returning the user desired limit price.
         This only executes when a order was already placed, still open (unfilled fully or partially)
         and not timed out on subsequent candles after entry trigger.
 
         For full documentation please go to https://www.freqtrade.io/en/latest/strategy-callbacks/
 
@@ -579,17 +682,25 @@
         :param side: 'long' or 'short' - indicating the direction of the proposed trade
         :param **kwargs: Ensure to keep this here so updates to this won't break your strategy.
         :return float: New entry price value if provided
 
         """
         return current_order_rate
 
-    def leverage(self, pair: str, current_time: datetime, current_rate: float,
-                 proposed_leverage: float, max_leverage: float, entry_tag: Optional[str],
-                 side: str, **kwargs) -> float:
+    def leverage(
+        self,
+        pair: str,
+        current_time: datetime,
+        current_rate: float,
+        proposed_leverage: float,
+        max_leverage: float,
+        entry_tag: Optional[str],
+        side: str,
+        **kwargs,
+    ) -> float:
         """
         Customize leverage for each new trade. This method is only called in futures mode.
 
         :param pair: Pair that's currently analyzed
         :param current_time: datetime object, containing the current datetime
         :param current_rate: Rate, calculated based on pricing settings in exit_pricing.
         :param proposed_leverage: A leverage proposed by the bot.
@@ -615,33 +726,39 @@
 
     def version(self) -> Optional[str]:
         """
         Returns version of the strategy.
         """
         return None
 
-    def populate_any_indicators(self, pair: str, df: DataFrame, tf: str,
-                                informative: Optional[DataFrame] = None,
-                                set_generalized_indicators: bool = False) -> DataFrame:
+    def populate_any_indicators(
+        self,
+        pair: str,
+        df: DataFrame,
+        tf: str,
+        informative: Optional[DataFrame] = None,
+        set_generalized_indicators: bool = False,
+    ) -> DataFrame:
         """
         DEPRECATED - USE FEATURE ENGINEERING FUNCTIONS INSTEAD
         Function designed to automatically generate, name and merge features
         from user indicated timeframes in the configuration file. User can add
         additional features here, but must follow the naming convention.
         This method is *only* used in FreqaiDataKitchen class and therefore
         it is only called if FreqAI is active.
         :param pair: pair to be used as informative
         :param df: strategy dataframe which will receive merges from informatives
         :param tf: timeframe of the dataframe which will modify the feature names
         :param informative: the dataframe associated with the informative pair
         """
         return df
 
-    def feature_engineering_expand_all(self, dataframe: DataFrame, period: int,
-                                       metadata: Dict, **kwargs) -> DataFrame:
+    def feature_engineering_expand_all(
+        self, dataframe: DataFrame, period: int, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This function will automatically expand the defined features on the config defined
         `indicator_periods_candles`, `include_timeframes`, `include_shifted_candles`, and
         `include_corr_pairs`. In other words, a single feature defined in this function
         will automatically expand to a total of
         `indicator_periods_candles` * `include_timeframes` * `include_shifted_candles` *
@@ -660,15 +777,16 @@
         :param period: period of the indicator - usage example:
         :param metadata: metadata of current pair
         dataframe["%-ema-period"] = ta.EMA(dataframe, timeperiod=period)
         """
         return dataframe
 
     def feature_engineering_expand_basic(
-            self, dataframe: DataFrame, metadata: Dict, **kwargs) -> DataFrame:
+        self, dataframe: DataFrame, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This function will automatically expand the defined features on the config defined
         `include_timeframes`, `include_shifted_candles`, and `include_corr_pairs`.
         In other words, a single feature defined in this function
         will automatically expand to a total of
         `include_timeframes` * `include_shifted_candles` * `include_corr_pairs`
@@ -690,15 +808,16 @@
         :param metadata: metadata of current pair
         dataframe["%-pct-change"] = dataframe["close"].pct_change()
         dataframe["%-ema-200"] = ta.EMA(dataframe, timeperiod=200)
         """
         return dataframe
 
     def feature_engineering_standard(
-            self, dataframe: DataFrame, metadata: Dict, **kwargs) -> DataFrame:
+        self, dataframe: DataFrame, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This optional function will be called once with the dataframe of the base timeframe.
         This is the final function to be called, which means that the dataframe entering this
         function will contain all the features and columns created by all other
         freqai_feature_engineering_* functions.
 
@@ -730,57 +849,69 @@
 
         :param dataframe: strategy dataframe which will receive the targets
         :param metadata: metadata of current pair
         usage example: dataframe["&-target"] = dataframe["close"].shift(-1) / dataframe["close"]
         """
         return dataframe
 
-###
-# END - Intended to be overridden by strategy
-###
+    ###
+    # END - Intended to be overridden by strategy
+    ###
 
     _ft_stop_uses_after_fill = False
 
     def _adjust_trade_position_internal(
-            self, trade: Trade, current_time: datetime,
-            current_rate: float, current_profit: float,
-            min_stake: Optional[float], max_stake: float,
-            current_entry_rate: float, current_exit_rate: float,
-            current_entry_profit: float, current_exit_profit: float,
-            **kwargs
+        self,
+        trade: Trade,
+        current_time: datetime,
+        current_rate: float,
+        current_profit: float,
+        min_stake: Optional[float],
+        max_stake: float,
+        current_entry_rate: float,
+        current_exit_rate: float,
+        current_entry_profit: float,
+        current_exit_profit: float,
+        **kwargs,
     ) -> Tuple[Optional[float], str]:
         """
         wrapper around adjust_trade_position to handle the return value
         """
-        resp = strategy_safe_wrapper(self.adjust_trade_position,
-                                     default_retval=(None, ''), supress_error=True)(
-            trade=trade, current_time=current_time,
-            current_rate=current_rate, current_profit=current_profit,
-            min_stake=min_stake, max_stake=max_stake,
-            current_entry_rate=current_entry_rate, current_exit_rate=current_exit_rate,
-            current_entry_profit=current_entry_profit, current_exit_profit=current_exit_profit,
-            **kwargs
+        resp = strategy_safe_wrapper(
+            self.adjust_trade_position, default_retval=(None, ""), supress_error=True
+        )(
+            trade=trade,
+            current_time=current_time,
+            current_rate=current_rate,
+            current_profit=current_profit,
+            min_stake=min_stake,
+            max_stake=max_stake,
+            current_entry_rate=current_entry_rate,
+            current_exit_rate=current_exit_rate,
+            current_entry_profit=current_entry_profit,
+            current_exit_profit=current_exit_profit,
+            **kwargs,
         )
-        order_tag = ''
+        order_tag = ""
         if isinstance(resp, tuple):
             if len(resp) >= 1:
                 stake_amount = resp[0]
             if len(resp) > 1:
-                order_tag = resp[1] or ''
+                order_tag = resp[1] or ""
         else:
             stake_amount = resp
         return stake_amount, order_tag
 
     def __informative_pairs_freqai(self) -> ListPairsWithTimeframes:
         """
         Create informative-pairs needed for FreqAI
         """
-        if self.config.get('freqai', {}).get('enabled', False):
+        if self.config.get("freqai", {}).get("enabled", False):
             whitelist_pairs = self.dp.current_whitelist()
-            candle_type = self.config.get('candle_type_def', CandleType.SPOT)
+            candle_type = self.config.get("candle_type_def", CandleType.SPOT)
             corr_pairs = self.config["freqai"]["feature_parameters"]["include_corr_pairlist"]
             informative_pairs = []
             for tf in self.config["freqai"]["feature_parameters"]["include_timeframes"]:
                 for pair in set(whitelist_pairs + corr_pairs):
                     informative_pairs.append((pair, tf, candle_type))
             return informative_pairs
 
@@ -789,25 +920,35 @@
     def gather_informative_pairs(self) -> ListPairsWithTimeframes:
         """
         Internal method which gathers all informative pairs (user or automatically defined).
         """
         informative_pairs = self.informative_pairs()
         # Compatibility code for 2 tuple informative pairs
         informative_pairs = [
-            (p[0], p[1], CandleType.from_string(p[2]) if len(
-                p) > 2 and p[2] != '' else self.config.get('candle_type_def', CandleType.SPOT))
-            for p in informative_pairs]
+            (
+                p[0],
+                p[1],
+                (
+                    CandleType.from_string(p[2])
+                    if len(p) > 2 and p[2] != ""
+                    else self.config.get("candle_type_def", CandleType.SPOT)
+                ),
+            )
+            for p in informative_pairs
+        ]
         for inf_data, _ in self._ft_informative:
             # Get default candle type if not provided explicitly.
-            candle_type = (inf_data.candle_type if inf_data.candle_type
-                           else self.config.get('candle_type_def', CandleType.SPOT))
+            candle_type = (
+                inf_data.candle_type
+                if inf_data.candle_type
+                else self.config.get("candle_type_def", CandleType.SPOT)
+            )
             if inf_data.asset:
                 if any(s in inf_data.asset for s in ("{BASE}", "{base}")):
                     for pair in self.dp.current_whitelist():
-
                         pair_tf = (
                             _format_pair_name(self.config, inf_data.asset, self.dp.market(pair)),
                             inf_data.timeframe,
                             candle_type,
                         )
                         informative_pairs.append(pair_tf)
 
@@ -826,16 +967,17 @@
 
     def get_strategy_name(self) -> str:
         """
         Returns strategy class name
         """
         return self.__class__.__name__
 
-    def lock_pair(self, pair: str, until: datetime,
-                  reason: Optional[str] = None, side: str = '*') -> None:
+    def lock_pair(
+        self, pair: str, until: datetime, reason: Optional[str] = None, side: str = "*"
+    ) -> None:
         """
         Locks pair until a given timestamp happens.
         Locked pairs are not analyzed, and are prevented from opening new trades.
         Locks can only count up (allowing users to lock pairs for a longer period of time).
         To remove a lock from a pair, use `unlock_pair()`
         :param pair: Pair to lock
         :param until: datetime in UTC until the pair should be blocked from opening new trades.
@@ -859,16 +1001,17 @@
         Unlocks all pairs previously locked using lock_pair with specified reason.
         Not used by freqtrade itself, but intended to be used if users lock pairs
         manually from within the strategy, to allow an easy way to unlock pairs.
         :param reason: Unlock pairs to allow trading again
         """
         PairLocks.unlock_reason(reason, datetime.now(timezone.utc))
 
-    def is_pair_locked(self, pair: str, *, candle_date: Optional[datetime] = None,
-                       side: str = '*') -> bool:
+    def is_pair_locked(
+        self, pair: str, *, candle_date: Optional[datetime] = None, side: str = "*"
+    ) -> bool:
         """
         Checks if a pair is currently locked
         The 2nd, optional parameter ensures that locks are applied until the new candle arrives,
         and not stop at 14:00:00 - while the next candle arrives at 14:00:02 leaving a gap
         of 2 seconds for an entry order to happen on an old signal.
         :param pair: "Pair to check"
         :param candle_date: Date of the last candle. Optional, defaults to current date
@@ -903,27 +1046,26 @@
         Parses the given candle (OHLCV) data and returns a populated DataFrame
         add several TA indicators and buy signal to it
         WARNING: Used internally only, may skip analysis if `process_only_new_candles` is set.
         :param dataframe: Dataframe containing data from exchange
         :param metadata: Metadata dictionary with additional data (e.g. 'pair')
         :return: DataFrame of candle (OHLCV) data with indicator data and signals added
         """
-        pair = str(metadata.get('pair'))
+        pair = str(metadata.get("pair"))
 
-        new_candle = self._last_candle_seen_per_pair.get(pair, None) != dataframe.iloc[-1]['date']
+        new_candle = self._last_candle_seen_per_pair.get(pair, None) != dataframe.iloc[-1]["date"]
         # Test if seen this pair and last candle before.
         # always run if process_only_new_candles is set to false
         if not self.process_only_new_candles or new_candle:
-
             # Defs that only make change on new candle data.
             dataframe = self.analyze_ticker(dataframe, metadata)
 
-            self._last_candle_seen_per_pair[pair] = dataframe.iloc[-1]['date']
+            self._last_candle_seen_per_pair[pair] = dataframe.iloc[-1]["date"]
 
-            candle_type = self.config.get('candle_type_def', CandleType.SPOT)
+            candle_type = self.config.get("candle_type_def", CandleType.SPOT)
             self.dp._set_cached_df(pair, self.timeframe, dataframe, candle_type=candle_type)
             self.dp._emit_df((pair, self.timeframe, candle_type), dataframe, new_candle)
 
         else:
             logger.debug("Skipping TA Analysis for already analyzed candle")
             dataframe = remove_entry_exit_signals(dataframe)
 
@@ -935,58 +1077,58 @@
         """
         Fetch data for this pair from dataprovider and analyze.
         Stores the dataframe into the dataprovider.
         The analyzed dataframe is then accessible via `dp.get_analyzed_dataframe()`.
         :param pair: Pair to analyze.
         """
         dataframe = self.dp.ohlcv(
-            pair, self.timeframe, candle_type=self.config.get('candle_type_def', CandleType.SPOT)
+            pair, self.timeframe, candle_type=self.config.get("candle_type_def", CandleType.SPOT)
         )
         if not isinstance(dataframe, DataFrame) or dataframe.empty:
-            logger.warning('Empty candle (OHLCV) data for pair %s', pair)
+            logger.warning("Empty candle (OHLCV) data for pair %s", pair)
             return
 
         try:
             df_len, df_close, df_date = self.preserve_df(dataframe)
 
-            dataframe = strategy_safe_wrapper(
-                self._analyze_ticker_internal, message=""
-            )(dataframe, {'pair': pair})
+            dataframe = strategy_safe_wrapper(self._analyze_ticker_internal, message="")(
+                dataframe, {"pair": pair}
+            )
 
             self.assert_df(dataframe, df_len, df_close, df_date)
         except StrategyError as error:
             logger.warning(f"Unable to analyze candle (OHLCV) data for pair {pair}: {error}")
             return
 
         if dataframe.empty:
-            logger.warning('Empty dataframe for pair %s', pair)
+            logger.warning("Empty dataframe for pair %s", pair)
             return
 
     def analyze(self, pairs: List[str]) -> None:
         """
         Analyze all pairs using analyze_pair().
         :param pairs: List of pairs to analyze
         """
         for pair in pairs:
             self.analyze_pair(pair)
 
     @staticmethod
     def preserve_df(dataframe: DataFrame) -> Tuple[int, float, datetime]:
-        """ keep some data for dataframes """
+        """keep some data for dataframes"""
         return len(dataframe), dataframe["close"].iloc[-1], dataframe["date"].iloc[-1]
 
     def assert_df(self, dataframe: DataFrame, df_len: int, df_close: float, df_date: datetime):
         """
         Ensure dataframe (length, last candle) was not modified, and has all elements we need.
         """
         message_template = "Dataframe returned from strategy has mismatching {}."
         message = ""
         if dataframe is None:
             message = "No dataframe returned (return statement missing?)."
-        elif 'enter_long' not in dataframe:
+        elif "enter_long" not in dataframe:
             message = "enter_long/buy column not set."
         elif df_len != len(dataframe):
             message = message_template.format("length")
         elif df_close != dataframe["close"].iloc[-1]:
             message = message_template.format("last close price")
         elif df_date != dataframe["date"].iloc[-1]:
             message = message_template.format("last date")
@@ -1008,39 +1150,36 @@
         Used by Bot to get the signal to enter, or exit
         :param pair: pair in format ANT/BTC
         :param timeframe: timeframe to use
         :param dataframe: Analyzed dataframe to get signal from.
         :return: (None, None) or (Dataframe, latest_date) - corresponding to the last candle
         """
         if not isinstance(dataframe, DataFrame) or dataframe.empty:
-            logger.warning(f'Empty candle (OHLCV) data for pair {pair}')
+            logger.warning(f"Empty candle (OHLCV) data for pair {pair}")
             return None, None
 
-        latest_date = dataframe['date'].max()
-        latest = dataframe.loc[dataframe['date'] == latest_date].iloc[-1]
+        latest_date = dataframe["date"].max()
+        latest = dataframe.loc[dataframe["date"] == latest_date].iloc[-1]
         # Explicitly convert to datetime object to ensure the below comparison does not fail
         latest_date = latest_date.to_pydatetime()
 
         # Check if dataframe is out of date
         timeframe_minutes = timeframe_to_minutes(timeframe)
-        offset = self.config.get('exchange', {}).get('outdated_offset', 5)
+        offset = self.config.get("exchange", {}).get("outdated_offset", 5)
         if latest_date < (dt_now() - timedelta(minutes=timeframe_minutes * 2 + offset)):
             logger.warning(
-                'Outdated history for pair %s. Last tick is %s minutes old',
-                pair, int((dt_now() - latest_date).total_seconds() // 60)
+                "Outdated history for pair %s. Last tick is %s minutes old",
+                pair,
+                int((dt_now() - latest_date).total_seconds() // 60),
             )
             return None, None
         return latest, latest_date
 
     def get_exit_signal(
-        self,
-        pair: str,
-        timeframe: str,
-        dataframe: DataFrame,
-        is_short: Optional[bool] = None
+        self, pair: str, timeframe: str, dataframe: DataFrame, is_short: Optional[bool] = None
     ) -> Tuple[bool, bool, Optional[str]]:
         """
         Calculates current exit signal based based on the dataframe
         columns of the dataframe.
         Used by Bot to get the signal to exit.
         depending on is_short, looks at "short" or "long" columns.
         :param pair: pair in format ANT/BTC
@@ -1058,18 +1197,17 @@
             exit_ = latest.get(SignalType.EXIT_SHORT.value, 0) == 1
 
         else:
             enter = latest[SignalType.ENTER_LONG.value] == 1
             exit_ = latest.get(SignalType.EXIT_LONG.value, 0) == 1
         exit_tag = latest.get(SignalTagType.EXIT_TAG.value, None)
         # Tags can be None, which does not resolve to False.
-        exit_tag = exit_tag if isinstance(exit_tag, str) and exit_tag != 'nan' else None
+        exit_tag = exit_tag if isinstance(exit_tag, str) and exit_tag != "nan" else None
 
-        logger.debug(f"exit-trigger: {latest['date']} (pair={pair}) "
-                     f"enter={enter} exit={exit_}")
+        logger.debug(f"exit-trigger: {latest['date']} (pair={pair}) enter={enter} exit={exit_}")
 
         return enter, exit_, exit_tag
 
     def get_entry_signal(
         self,
         pair: str,
         timeframe: str,
@@ -1094,53 +1232,62 @@
         exit_short = latest.get(SignalType.EXIT_SHORT.value, 0) == 1
 
         enter_signal: Optional[SignalDirection] = None
         enter_tag: Optional[str] = None
         if enter_long == 1 and not any([exit_long, enter_short]):
             enter_signal = SignalDirection.LONG
             enter_tag = latest.get(SignalTagType.ENTER_TAG.value, None)
-        if (self.config.get('trading_mode', TradingMode.SPOT) != TradingMode.SPOT
-                and self.can_short
-                and enter_short == 1 and not any([exit_short, enter_long])):
+        if (
+            self.config.get("trading_mode", TradingMode.SPOT) != TradingMode.SPOT
+            and self.can_short
+            and enter_short == 1
+            and not any([exit_short, enter_long])
+        ):
             enter_signal = SignalDirection.SHORT
             enter_tag = latest.get(SignalTagType.ENTER_TAG.value, None)
 
-        enter_tag = enter_tag if isinstance(enter_tag, str) and enter_tag != 'nan' else None
+        enter_tag = enter_tag if isinstance(enter_tag, str) and enter_tag != "nan" else None
 
         timeframe_seconds = timeframe_to_seconds(timeframe)
 
         if self.ignore_expired_candle(
             latest_date=latest_date,
             current_time=dt_now(),
             timeframe_seconds=timeframe_seconds,
-            enter=bool(enter_signal)
+            enter=bool(enter_signal),
         ):
             return None, enter_tag
 
-        logger.debug(f"entry trigger: {latest['date']} (pair={pair}) "
-                     f"enter={enter_long} enter_tag_value={enter_tag}")
+        logger.debug(
+            f"entry trigger: {latest['date']} (pair={pair}) "
+            f"enter={enter_long} enter_tag_value={enter_tag}"
+        )
         return enter_signal, enter_tag
 
     def ignore_expired_candle(
-        self,
-        latest_date: datetime,
-        current_time: datetime,
-        timeframe_seconds: int,
-        enter: bool
+        self, latest_date: datetime, current_time: datetime, timeframe_seconds: int, enter: bool
     ):
         if self.ignore_buying_expired_candle_after and enter:
             time_delta = current_time - (latest_date + timedelta(seconds=timeframe_seconds))
             return time_delta.total_seconds() > self.ignore_buying_expired_candle_after
         else:
             return False
 
-    def should_exit(self, trade: Trade, rate: float, current_time: datetime, *,
-                    enter: bool, exit_: bool,
-                    low: Optional[float] = None, high: Optional[float] = None,
-                    force_stoploss: float = 0) -> List[ExitCheckTuple]:
+    def should_exit(
+        self,
+        trade: Trade,
+        rate: float,
+        current_time: datetime,
+        *,
+        enter: bool,
+        exit_: bool,
+        low: Optional[float] = None,
+        high: Optional[float] = None,
+        force_stoploss: float = 0,
+    ) -> List[ExitCheckTuple]:
         """
         This function evaluates if one of the conditions required to trigger an exit order
         has been reached, which can either be a stop-loss, ROI or exit-signal.
         :param low: Only used during backtesting to simulate (long)stoploss/(short)ROI
         :param high: Only used during backtesting, to simulate (short)stoploss/(long)ROI
         :param force_stoploss: Externally provided stoploss
         :return: List of exit reasons - or empty list.
@@ -1152,81 +1299,98 @@
         if low is not None or high is not None:
             # Set current rate to high for backtesting ROI exits
             current_rate_best = (low if trade.is_short else high) or rate
             current_profit_best = trade.calc_profit_ratio(current_rate_best)
 
         trade.adjust_min_max_rates(high or current_rate, low or current_rate)
 
-        stoplossflag = self.ft_stoploss_reached(current_rate=current_rate, trade=trade,
-                                                current_time=current_time,
-                                                current_profit=current_profit,
-                                                force_stoploss=force_stoploss, low=low, high=high)
+        stoplossflag = self.ft_stoploss_reached(
+            current_rate=current_rate,
+            trade=trade,
+            current_time=current_time,
+            current_profit=current_profit,
+            force_stoploss=force_stoploss,
+            low=low,
+            high=high,
+        )
 
         # if enter signal and ignore_roi is set, we don't need to evaluate min_roi.
-        roi_reached = (not (enter and self.ignore_roi_if_entry_signal)
-                       and self.min_roi_reached(trade=trade, current_profit=current_profit_best,
-                                                current_time=current_time))
+        roi_reached = not (enter and self.ignore_roi_if_entry_signal) and self.min_roi_reached(
+            trade=trade, current_profit=current_profit_best, current_time=current_time
+        )
 
         exit_signal = ExitType.NONE
-        custom_reason = ''
+        custom_reason = ""
 
         if self.use_exit_signal:
             if exit_ and not enter:
                 exit_signal = ExitType.EXIT_SIGNAL
             else:
                 reason_cust = strategy_safe_wrapper(self.custom_exit, default_retval=False)(
-                    pair=trade.pair, trade=trade, current_time=current_time,
-                    current_rate=current_rate, current_profit=current_profit)
+                    pair=trade.pair,
+                    trade=trade,
+                    current_time=current_time,
+                    current_rate=current_rate,
+                    current_profit=current_profit,
+                )
                 if reason_cust:
                     exit_signal = ExitType.CUSTOM_EXIT
                     if isinstance(reason_cust, str):
                         custom_reason = reason_cust
                         if len(reason_cust) > CUSTOM_TAG_MAX_LENGTH:
-                            logger.warning(f'Custom exit reason returned from '
-                                           f'custom_exit is too long and was trimmed'
-                                           f'to {CUSTOM_TAG_MAX_LENGTH} characters.')
+                            logger.warning(
+                                f"Custom exit reason returned from "
+                                f"custom_exit is too long and was trimmed"
+                                f"to {CUSTOM_TAG_MAX_LENGTH} characters."
+                            )
                             custom_reason = reason_cust[:CUSTOM_TAG_MAX_LENGTH]
                     else:
-                        custom_reason = ''
-            if (
-                exit_signal == ExitType.CUSTOM_EXIT
-                or (exit_signal == ExitType.EXIT_SIGNAL
-                    and (not self.exit_profit_only or current_profit > self.exit_profit_offset))
+                        custom_reason = ""
+            if exit_signal == ExitType.CUSTOM_EXIT or (
+                exit_signal == ExitType.EXIT_SIGNAL
+                and (not self.exit_profit_only or current_profit > self.exit_profit_offset)
             ):
-                logger.debug(f"{trade.pair} - Sell signal received. "
-                             f"exit_type=ExitType.{exit_signal.name}" +
-                             (f", custom_reason={custom_reason}" if custom_reason else ""))
+                logger.debug(
+                    f"{trade.pair} - Sell signal received. "
+                    f"exit_type=ExitType.{exit_signal.name}"
+                    + (f", custom_reason={custom_reason}" if custom_reason else "")
+                )
                 exits.append(ExitCheckTuple(exit_type=exit_signal, exit_reason=custom_reason))
 
         # Sequence:
         # Exit-signal
         # Stoploss
         # ROI
         # Trailing stoploss
 
         if stoplossflag.exit_type in (ExitType.STOP_LOSS, ExitType.LIQUIDATION):
-
             logger.debug(f"{trade.pair} - Stoploss hit. exit_type={stoplossflag.exit_type}")
             exits.append(stoplossflag)
 
         if roi_reached:
             logger.debug(f"{trade.pair} - Required profit reached. exit_type=ExitType.ROI")
             exits.append(ExitCheckTuple(exit_type=ExitType.ROI))
 
         if stoplossflag.exit_type == ExitType.TRAILING_STOP_LOSS:
-
             logger.debug(f"{trade.pair} - Trailing stoploss hit.")
             exits.append(stoplossflag)
 
         return exits
 
-    def ft_stoploss_adjust(self, current_rate: float, trade: Trade,
-                           current_time: datetime, current_profit: float,
-                           force_stoploss: float, low: Optional[float] = None,
-                           high: Optional[float] = None, after_fill: bool = False) -> None:
+    def ft_stoploss_adjust(
+        self,
+        current_rate: float,
+        trade: Trade,
+        current_time: datetime,
+        current_profit: float,
+        force_stoploss: float,
+        low: Optional[float] = None,
+        high: Optional[float] = None,
+        after_fill: bool = False,
+    ) -> None:
         """
         Adjust stop-loss dynamically if configured to do so.
         :param current_profit: current profit as ratio
         :param low: Low value of this candle, only set in backtesting
         :param high: High value of this candle, only set in backtesting
         """
         if after_fill and not self._ft_stop_uses_after_fill:
@@ -1234,97 +1398,116 @@
             return
 
         stop_loss_value = force_stoploss if force_stoploss else self.stoploss
 
         # Initiate stoploss with open_rate. Does nothing if stoploss is already set.
         trade.adjust_stop_loss(trade.open_rate, stop_loss_value, initial=True)
 
-        dir_correct = (trade.stop_loss < (low or current_rate)
-                       if not trade.is_short else
-                       trade.stop_loss > (high or current_rate)
-                       )
+        dir_correct = (
+            trade.stop_loss < (low or current_rate)
+            if not trade.is_short
+            else trade.stop_loss > (high or current_rate)
+        )
 
         # Make sure current_profit is calculated using high for backtesting.
-        bound = (low if trade.is_short else high)
+        bound = low if trade.is_short else high
         bound_profit = current_profit if not bound else trade.calc_profit_ratio(bound)
         if self.use_custom_stoploss and dir_correct:
             stop_loss_value_custom = strategy_safe_wrapper(
                 self.custom_stoploss, default_retval=None, supress_error=True
-                    )(pair=trade.pair, trade=trade,
-                        current_time=current_time,
-                        current_rate=(bound or current_rate),
-                        current_profit=bound_profit,
-                        after_fill=after_fill)
+            )(
+                pair=trade.pair,
+                trade=trade,
+                current_time=current_time,
+                current_rate=(bound or current_rate),
+                current_profit=bound_profit,
+                after_fill=after_fill,
+            )
             # Sanity check - error cases will return None
             if stop_loss_value_custom:
                 stop_loss_value = stop_loss_value_custom
-                trade.adjust_stop_loss(bound or current_rate, stop_loss_value,
-                                       allow_refresh=after_fill)
+                trade.adjust_stop_loss(
+                    bound or current_rate, stop_loss_value, allow_refresh=after_fill
+                )
             else:
                 logger.debug("CustomStoploss function did not return valid stoploss")
 
         if self.trailing_stop and dir_correct:
             # trailing stoploss handling
             sl_offset = self.trailing_stop_positive_offset
             # Make sure current_profit is calculated using high for backtesting.
 
             # Don't update stoploss if trailing_only_offset_is_reached is true.
             if not (self.trailing_only_offset_is_reached and bound_profit < sl_offset):
                 # Specific handling for trailing_stop_positive
                 if self.trailing_stop_positive is not None and bound_profit > sl_offset:
                     stop_loss_value = self.trailing_stop_positive
-                    logger.debug(f"{trade.pair} - Using positive stoploss: {stop_loss_value} "
-                                 f"offset: {sl_offset:.4g} profit: {bound_profit:.2%}")
+                    logger.debug(
+                        f"{trade.pair} - Using positive stoploss: {stop_loss_value} "
+                        f"offset: {sl_offset:.4g} profit: {bound_profit:.2%}"
+                    )
 
                 trade.adjust_stop_loss(bound or current_rate, stop_loss_value)
 
-    def ft_stoploss_reached(self, current_rate: float, trade: Trade,
-                            current_time: datetime, current_profit: float,
-                            force_stoploss: float, low: Optional[float] = None,
-                            high: Optional[float] = None) -> ExitCheckTuple:
+    def ft_stoploss_reached(
+        self,
+        current_rate: float,
+        trade: Trade,
+        current_time: datetime,
+        current_profit: float,
+        force_stoploss: float,
+        low: Optional[float] = None,
+        high: Optional[float] = None,
+    ) -> ExitCheckTuple:
         """
         Based on current profit of the trade and configured (trailing) stoploss,
         decides to exit or not
         :param current_profit: current profit as ratio
         :param low: Low value of this candle, only set in backtesting
         :param high: High value of this candle, only set in backtesting
         """
-        self.ft_stoploss_adjust(current_rate, trade, current_time, current_profit,
-                                force_stoploss, low, high)
+        self.ft_stoploss_adjust(
+            current_rate, trade, current_time, current_profit, force_stoploss, low, high
+        )
 
-        sl_higher_long = (trade.stop_loss >= (low or current_rate) and not trade.is_short)
-        sl_lower_short = (trade.stop_loss <= (high or current_rate) and trade.is_short)
-        liq_higher_long = (trade.liquidation_price
-                           and trade.liquidation_price >= (low or current_rate)
-                           and not trade.is_short)
-        liq_lower_short = (trade.liquidation_price
-                           and trade.liquidation_price <= (high or current_rate)
-                           and trade.is_short)
+        sl_higher_long = trade.stop_loss >= (low or current_rate) and not trade.is_short
+        sl_lower_short = trade.stop_loss <= (high or current_rate) and trade.is_short
+        liq_higher_long = (
+            trade.liquidation_price
+            and trade.liquidation_price >= (low or current_rate)
+            and not trade.is_short
+        )
+        liq_lower_short = (
+            trade.liquidation_price
+            and trade.liquidation_price <= (high or current_rate)
+            and trade.is_short
+        )
 
         # evaluate if the stoploss was hit if stoploss is not on exchange
         # in Dry-Run, this handles stoploss logic as well, as the logic will not be different to
         # regular stoploss handling.
-        if ((sl_higher_long or sl_lower_short) and
-                (not self.order_types.get('stoploss_on_exchange') or self.config['dry_run'])):
-
+        if (sl_higher_long or sl_lower_short) and (
+            not self.order_types.get("stoploss_on_exchange") or self.config["dry_run"]
+        ):
             exit_type = ExitType.STOP_LOSS
 
             # If initial stoploss is not the same as current one then it is trailing.
             if trade.is_stop_loss_trailing:
                 exit_type = ExitType.TRAILING_STOP_LOSS
                 logger.debug(
                     f"{trade.pair} - HIT STOP: current price at "
                     f"{((high if trade.is_short else low) or current_rate):.6f}, "
                     f"stoploss is {trade.stop_loss:.6f}, "
                     f"initial stoploss was at {trade.initial_stop_loss:.6f}, "
-                    f"trade opened at {trade.open_rate:.6f}")
+                    f"trade opened at {trade.open_rate:.6f}"
+                )
 
             return ExitCheckTuple(exit_type=exit_type)
 
-        if (liq_higher_long or liq_lower_short):
+        if liq_higher_long or liq_lower_short:
             logger.debug(f"{trade.pair} - Liquidation price hit. exit_type=ExitType.LIQUIDATION")
             return ExitCheckTuple(exit_type=ExitType.LIQUIDATION)
 
         return ExitCheckTuple(exit_type=ExitType.NONE)
 
     def min_roi_reached_entry(self, trade_dur: int) -> Tuple[Optional[int], Optional[float]]:
         """
@@ -1350,50 +1533,53 @@
         trade_dur = int((current_time.timestamp() - trade.open_date_utc.timestamp()) // 60)
         _, roi = self.min_roi_reached_entry(trade_dur)
         if roi is None:
             return False
         else:
             return current_profit > roi
 
-    def ft_check_timed_out(self, trade: Trade, order: Order,
-                           current_time: datetime) -> bool:
+    def ft_check_timed_out(self, trade: Trade, order: Order, current_time: datetime) -> bool:
         """
         FT Internal method.
         Check if timeout is active, and if the order is still open and timed out
         """
-        side = 'entry' if order.ft_order_side == trade.entry_side else 'exit'
+        side = "entry" if order.ft_order_side == trade.entry_side else "exit"
 
-        timeout = self.config.get('unfilledtimeout', {}).get(side)
+        timeout = self.config.get("unfilledtimeout", {}).get(side)
         if timeout is not None:
-            timeout_unit = self.config.get('unfilledtimeout', {}).get('unit', 'minutes')
+            timeout_unit = self.config.get("unfilledtimeout", {}).get("unit", "minutes")
             timeout_kwargs = {timeout_unit: -timeout}
             timeout_threshold = current_time + timedelta(**timeout_kwargs)
-            timedout = (order.status == 'open' and order.order_date_utc < timeout_threshold)
+            timedout = order.status == "open" and order.order_date_utc < timeout_threshold
             if timedout:
                 return True
-        time_method = (self.check_exit_timeout if order.ft_order_side == trade.exit_side
-                       else self.check_entry_timeout)
+        time_method = (
+            self.check_exit_timeout
+            if order.ft_order_side == trade.exit_side
+            else self.check_entry_timeout
+        )
 
-        return strategy_safe_wrapper(time_method,
-                                     default_retval=False)(
-                                        pair=trade.pair, trade=trade, order=order,
-                                        current_time=current_time)
+        return strategy_safe_wrapper(time_method, default_retval=False)(
+            pair=trade.pair, trade=trade, order=order, current_time=current_time
+        )
 
     def advise_all_indicators(self, data: Dict[str, DataFrame]) -> Dict[str, DataFrame]:
         """
         Populates indicators for given candle (OHLCV) data (for multiple pairs)
         Does not run advise_entry or advise_exit!
         Used by optimize operations only, not during dry / live runs.
         Using .copy() to get a fresh copy of the dataframe for every strategy run.
         Also copy on output to avoid PerformanceWarnings pandas 1.3.0 started to show.
         Has positive effects on memory usage for whatever reason - also when
         using only one strategy.
         """
-        return {pair: self.advise_indicators(pair_data.copy(), {'pair': pair}).copy()
-                for pair, pair_data in data.items()}
+        return {
+            pair: self.advise_indicators(pair_data.copy(), {"pair": pair}).copy()
+            for pair, pair_data in data.items()
+        }
 
     def ft_advise_signals(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
         """
         Call advise_entry and advise_exit and return the resulting dataframe.
         :param dataframe: Dataframe containing data from exchange, as well as pre-calculated
                           indicators
         :param metadata: Metadata dictionary with additional data (e.g. 'pair')
@@ -1414,15 +1600,16 @@
         :return: a Dataframe with all mandatory indicators for the strategies
         """
         logger.debug(f"Populating indicators for pair {metadata.get('pair')}.")
 
         # call populate_indicators_Nm() which were tagged with @informative decorator.
         for inf_data, populate_fn in self._ft_informative:
             dataframe = _create_and_merge_informative_pair(
-                self, dataframe, metadata, inf_data, populate_fn)
+                self, dataframe, metadata, inf_data, populate_fn
+            )
 
         return self.populate_indicators(dataframe, metadata)
 
     def advise_entry(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
         """
         Based on TA indicators, populates the entry order signal for the given dataframe
         This method should not be overridden.
@@ -1430,30 +1617,30 @@
         :param metadata: Additional information dictionary, with details like the
             currently traded pair
         :return: DataFrame with buy column
         """
 
         logger.debug(f"Populating enter signals for pair {metadata.get('pair')}.")
         # Initialize column to work around Pandas bug #56503.
-        dataframe.loc[:, 'enter_tag'] = ''
+        dataframe.loc[:, "enter_tag"] = ""
         df = self.populate_entry_trend(dataframe, metadata)
-        if 'enter_long' not in df.columns:
-            df = df.rename({'buy': 'enter_long', 'buy_tag': 'enter_tag'}, axis='columns')
+        if "enter_long" not in df.columns:
+            df = df.rename({"buy": "enter_long", "buy_tag": "enter_tag"}, axis="columns")
 
         return df
 
     def advise_exit(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
         """
         Based on TA indicators, populates the exit order signal for the given dataframe
         This method should not be overridden.
         :param dataframe: DataFrame
         :param metadata: Additional information dictionary, with details like the
             currently traded pair
         :return: DataFrame with exit column
         """
         # Initialize column to work around Pandas bug #56503.
-        dataframe.loc[:, 'exit_tag'] = ''
+        dataframe.loc[:, "exit_tag"] = ""
         logger.debug(f"Populating exit signals for pair {metadata.get('pair')}.")
         df = self.populate_exit_trend(dataframe, metadata)
-        if 'exit_long' not in df.columns:
-            df = df.rename({'sell': 'exit_long'}, axis='columns')
+        if "exit_long" not in df.columns:
+            df = df.rename({"sell": "exit_long"}, axis="columns")
         return df
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/parameters.py` & `freqtrade-2024.5/freqtrade/strategy/parameters.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,138 +1,167 @@
 """
 IHyperStrategy interface, hyperoptable Parameter class.
 This module defines a base class for auto-hyperoptable strategies.
 """
+
 import logging
 from abc import ABC, abstractmethod
 from contextlib import suppress
 from typing import Any, Optional, Sequence, Union
 
 from freqtrade.enums import HyperoptState
 from freqtrade.optimize.hyperopt_tools import HyperoptStateContainer
 
 
 with suppress(ImportError):
-    from skopt.space import Integer, Real, Categorical
+    from skopt.space import Categorical, Integer, Real
+
     from freqtrade.optimize.space import SKDecimal
 
 from freqtrade.exceptions import OperationalException
 
 
 logger = logging.getLogger(__name__)
 
 
 class BaseParameter(ABC):
     """
     Defines a parameter that can be optimized by hyperopt.
     """
+
     category: Optional[str]
     default: Any
     value: Any
     in_space: bool = False
     name: str
 
-    def __init__(self, *, default: Any, space: Optional[str] = None,
-                 optimize: bool = True, load: bool = True, **kwargs):
+    def __init__(
+        self,
+        *,
+        default: Any,
+        space: Optional[str] = None,
+        optimize: bool = True,
+        load: bool = True,
+        **kwargs,
+    ):
         """
         Initialize hyperopt-optimizable parameter.
         :param space: A parameter category. Can be 'buy' or 'sell'. This parameter is optional if
          parameter field
          name is prefixed with 'buy_' or 'sell_'.
         :param optimize: Include parameter in hyperopt optimizations.
         :param load: Load parameter value from {space}_params.
         :param kwargs: Extra parameters to skopt.space.(Integer|Real|Categorical).
         """
-        if 'name' in kwargs:
+        if "name" in kwargs:
             raise OperationalException(
-                'Name is determined by parameter field name and can not be specified manually.')
+                "Name is determined by parameter field name and can not be specified manually."
+            )
         self.category = space
         self._space_params = kwargs
         self.value = default
         self.optimize = optimize
         self.load = load
 
     def __repr__(self):
-        return f'{self.__class__.__name__}({self.value})'
+        return f"{self.__class__.__name__}({self.value})"
 
     @abstractmethod
-    def get_space(self, name: str) -> Union['Integer', 'Real', 'SKDecimal', 'Categorical']:
+    def get_space(self, name: str) -> Union["Integer", "Real", "SKDecimal", "Categorical"]:
         """
         Get-space - will be used by Hyperopt to get the hyperopt Space
         """
 
     def can_optimize(self):
         return (
             self.in_space
             and self.optimize
             and HyperoptStateContainer.state != HyperoptState.OPTIMIZE
         )
 
 
 class NumericParameter(BaseParameter):
-    """ Internal parameter used for Numeric purposes """
+    """Internal parameter used for Numeric purposes"""
+
     float_or_int = Union[int, float]
     default: float_or_int
     value: float_or_int
 
-    def __init__(self, low: Union[float_or_int, Sequence[float_or_int]],
-                 high: Optional[float_or_int] = None, *, default: float_or_int,
-                 space: Optional[str] = None, optimize: bool = True, load: bool = True, **kwargs):
+    def __init__(
+        self,
+        low: Union[float_or_int, Sequence[float_or_int]],
+        high: Optional[float_or_int] = None,
+        *,
+        default: float_or_int,
+        space: Optional[str] = None,
+        optimize: bool = True,
+        load: bool = True,
+        **kwargs,
+    ):
         """
         Initialize hyperopt-optimizable numeric parameter.
         Cannot be instantiated, but provides the validation for other numeric parameters
         :param low: Lower end (inclusive) of optimization space or [low, high].
         :param high: Upper end (inclusive) of optimization space.
                      Must be none of entire range is passed first parameter.
         :param default: A default value.
         :param space: A parameter category. Can be 'buy' or 'sell'. This parameter is optional if
                       parameter fieldname is prefixed with 'buy_' or 'sell_'.
         :param optimize: Include parameter in hyperopt optimizations.
         :param load: Load parameter value from {space}_params.
         :param kwargs: Extra parameters to skopt.space.*.
         """
         if high is not None and isinstance(low, Sequence):
-            raise OperationalException(f'{self.__class__.__name__} space invalid.')
+            raise OperationalException(f"{self.__class__.__name__} space invalid.")
         if high is None or isinstance(low, Sequence):
             if not isinstance(low, Sequence) or len(low) != 2:
-                raise OperationalException(f'{self.__class__.__name__} space must be [low, high]')
+                raise OperationalException(f"{self.__class__.__name__} space must be [low, high]")
             self.low, self.high = low
         else:
             self.low = low
             self.high = high
 
-        super().__init__(default=default, space=space, optimize=optimize,
-                         load=load, **kwargs)
+        super().__init__(default=default, space=space, optimize=optimize, load=load, **kwargs)
 
 
 class IntParameter(NumericParameter):
     default: int
     value: int
     low: int
     high: int
 
-    def __init__(self, low: Union[int, Sequence[int]], high: Optional[int] = None, *, default: int,
-                 space: Optional[str] = None, optimize: bool = True, load: bool = True, **kwargs):
+    def __init__(
+        self,
+        low: Union[int, Sequence[int]],
+        high: Optional[int] = None,
+        *,
+        default: int,
+        space: Optional[str] = None,
+        optimize: bool = True,
+        load: bool = True,
+        **kwargs,
+    ):
         """
         Initialize hyperopt-optimizable integer parameter.
         :param low: Lower end (inclusive) of optimization space or [low, high].
         :param high: Upper end (inclusive) of optimization space.
                      Must be none of entire range is passed first parameter.
         :param default: A default value.
         :param space: A parameter category. Can be 'buy' or 'sell'. This parameter is optional if
                       parameter fieldname is prefixed with 'buy_' or 'sell_'.
         :param optimize: Include parameter in hyperopt optimizations.
         :param load: Load parameter value from {space}_params.
         :param kwargs: Extra parameters to skopt.space.Integer.
         """
 
-        super().__init__(low=low, high=high, default=default, space=space, optimize=optimize,
-                         load=load, **kwargs)
+        super().__init__(
+            low=low, high=high, default=default, space=space, optimize=optimize, load=load, **kwargs
+        )
 
-    def get_space(self, name: str) -> 'Integer':
+    def get_space(self, name: str) -> "Integer":
         """
         Create skopt optimization space.
         :param name: A name of parameter field.
         """
         return Integer(low=self.low, high=self.high, name=name, **self._space_params)
 
     @property
@@ -150,47 +179,65 @@
             return range(self.value, self.value + 1)
 
 
 class RealParameter(NumericParameter):
     default: float
     value: float
 
-    def __init__(self, low: Union[float, Sequence[float]], high: Optional[float] = None, *,
-                 default: float, space: Optional[str] = None, optimize: bool = True,
-                 load: bool = True, **kwargs):
+    def __init__(
+        self,
+        low: Union[float, Sequence[float]],
+        high: Optional[float] = None,
+        *,
+        default: float,
+        space: Optional[str] = None,
+        optimize: bool = True,
+        load: bool = True,
+        **kwargs,
+    ):
         """
         Initialize hyperopt-optimizable floating point parameter with unlimited precision.
         :param low: Lower end (inclusive) of optimization space or [low, high].
         :param high: Upper end (inclusive) of optimization space.
                      Must be none if entire range is passed first parameter.
         :param default: A default value.
         :param space: A parameter category. Can be 'buy' or 'sell'. This parameter is optional if
                       parameter fieldname is prefixed with 'buy_' or 'sell_'.
         :param optimize: Include parameter in hyperopt optimizations.
         :param load: Load parameter value from {space}_params.
         :param kwargs: Extra parameters to skopt.space.Real.
         """
-        super().__init__(low=low, high=high, default=default, space=space, optimize=optimize,
-                         load=load, **kwargs)
+        super().__init__(
+            low=low, high=high, default=default, space=space, optimize=optimize, load=load, **kwargs
+        )
 
-    def get_space(self, name: str) -> 'Real':
+    def get_space(self, name: str) -> "Real":
         """
         Create skopt optimization space.
         :param name: A name of parameter field.
         """
         return Real(low=self.low, high=self.high, name=name, **self._space_params)
 
 
 class DecimalParameter(NumericParameter):
     default: float
     value: float
 
-    def __init__(self, low: Union[float, Sequence[float]], high: Optional[float] = None, *,
-                 default: float, decimals: int = 3, space: Optional[str] = None,
-                 optimize: bool = True, load: bool = True, **kwargs):
+    def __init__(
+        self,
+        low: Union[float, Sequence[float]],
+        high: Optional[float] = None,
+        *,
+        default: float,
+        decimals: int = 3,
+        space: Optional[str] = None,
+        optimize: bool = True,
+        load: bool = True,
+        **kwargs,
+    ):
         """
         Initialize hyperopt-optimizable decimal parameter with a limited precision.
         :param low: Lower end (inclusive) of optimization space or [low, high].
         :param high: Upper end (inclusive) of optimization space.
                      Must be none if entire range is passed first parameter.
         :param default: A default value.
         :param decimals: A number of decimals after floating point to be included in testing.
@@ -199,24 +246,26 @@
         :param optimize: Include parameter in hyperopt optimizations.
         :param load: Load parameter value from {space}_params.
         :param kwargs: Extra parameters to skopt.space.Integer.
         """
         self._decimals = decimals
         default = round(default, self._decimals)
 
-        super().__init__(low=low, high=high, default=default, space=space, optimize=optimize,
-                         load=load, **kwargs)
+        super().__init__(
+            low=low, high=high, default=default, space=space, optimize=optimize, load=load, **kwargs
+        )
 
-    def get_space(self, name: str) -> 'SKDecimal':
+    def get_space(self, name: str) -> "SKDecimal":
         """
         Create skopt optimization space.
         :param name: A name of parameter field.
         """
-        return SKDecimal(low=self.low, high=self.high, decimals=self._decimals, name=name,
-                         **self._space_params)
+        return SKDecimal(
+            low=self.low, high=self.high, decimals=self._decimals, name=name, **self._space_params
+        )
 
     @property
     def range(self):
         """
         Get each value in this space as list.
         Returns a List from low to high (inclusive) in Hyperopt mode.
         Returns a List with 1 item (`value`) in "non-hyperopt" mode, to avoid
@@ -231,36 +280,44 @@
 
 
 class CategoricalParameter(BaseParameter):
     default: Any
     value: Any
     opt_range: Sequence[Any]
 
-    def __init__(self, categories: Sequence[Any], *, default: Optional[Any] = None,
-                 space: Optional[str] = None, optimize: bool = True, load: bool = True, **kwargs):
+    def __init__(
+        self,
+        categories: Sequence[Any],
+        *,
+        default: Optional[Any] = None,
+        space: Optional[str] = None,
+        optimize: bool = True,
+        load: bool = True,
+        **kwargs,
+    ):
         """
         Initialize hyperopt-optimizable parameter.
         :param categories: Optimization space, [a, b, ...].
         :param default: A default value. If not specified, first item from specified space will be
          used.
         :param space: A parameter category. Can be 'buy' or 'sell'. This parameter is optional if
          parameter field
          name is prefixed with 'buy_' or 'sell_'.
         :param optimize: Include parameter in hyperopt optimizations.
         :param load: Load parameter value from {space}_params.
         :param kwargs: Extra parameters to skopt.space.Categorical.
         """
         if len(categories) < 2:
             raise OperationalException(
-                'CategoricalParameter space must be [a, b, ...] (at least two parameters)')
+                "CategoricalParameter space must be [a, b, ...] (at least two parameters)"
+            )
         self.opt_range = categories
-        super().__init__(default=default, space=space, optimize=optimize,
-                         load=load, **kwargs)
+        super().__init__(default=default, space=space, optimize=optimize, load=load, **kwargs)
 
-    def get_space(self, name: str) -> 'Categorical':
+    def get_space(self, name: str) -> "Categorical":
         """
         Create skopt optimization space.
         :param name: A name of parameter field.
         """
         return Categorical(self.opt_range, name=name, **self._space_params)
 
     @property
@@ -274,26 +331,38 @@
         if self.can_optimize():
             return self.opt_range
         else:
             return [self.value]
 
 
 class BooleanParameter(CategoricalParameter):
-
-    def __init__(self, *, default: Optional[Any] = None,
-                 space: Optional[str] = None, optimize: bool = True, load: bool = True, **kwargs):
+    def __init__(
+        self,
+        *,
+        default: Optional[Any] = None,
+        space: Optional[str] = None,
+        optimize: bool = True,
+        load: bool = True,
+        **kwargs,
+    ):
         """
         Initialize hyperopt-optimizable Boolean Parameter.
         It's a shortcut to `CategoricalParameter([True, False])`.
         :param default: A default value. If not specified, first item from specified space will be
          used.
         :param space: A parameter category. Can be 'buy' or 'sell'. This parameter is optional if
          parameter field
          name is prefixed with 'buy_' or 'sell_'.
         :param optimize: Include parameter in hyperopt optimizations.
         :param load: Load parameter value from {space}_params.
         :param kwargs: Extra parameters to skopt.space.Categorical.
         """
 
         categories = [True, False]
-        super().__init__(categories=categories, default=default, space=space, optimize=optimize,
-                         load=load, **kwargs)
+        super().__init__(
+            categories=categories,
+            default=default,
+            space=space,
+            optimize=optimize,
+            load=load,
+            **kwargs,
+        )
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/strategy_helper.py` & `freqtrade-2024.5/freqtrade/strategy/strategy_helper.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,24 @@
 from typing import Optional
 
 import pandas as pd
 
 from freqtrade.exchange import timeframe_to_minutes
 
 
-def merge_informative_pair(dataframe: pd.DataFrame, informative: pd.DataFrame,
-                           timeframe: str, timeframe_inf: str, ffill: bool = True,
-                           append_timeframe: bool = True,
-                           date_column: str = 'date',
-                           suffix: Optional[str] = None) -> pd.DataFrame:
+def merge_informative_pair(
+    dataframe: pd.DataFrame,
+    informative: pd.DataFrame,
+    timeframe: str,
+    timeframe_inf: str,
+    ffill: bool = True,
+    append_timeframe: bool = True,
+    date_column: str = "date",
+    suffix: Optional[str] = None,
+) -> pd.DataFrame:
     """
     Correctly merge informative samples to the original dataframe, avoiding lookahead bias.
 
     Since dates are candle open dates, merging a 15m candle that starts at 15:00, and a
     1h candle that starts at 15:00 will result in all candles to know the close at 16:00
     which they should not know.
 
@@ -37,67 +42,73 @@
     :raise: ValueError if the secondary timeframe is shorter than the dataframe timeframe
     """
     informative = informative.copy()
     minutes_inf = timeframe_to_minutes(timeframe_inf)
     minutes = timeframe_to_minutes(timeframe)
     if minutes == minutes_inf:
         # No need to forwardshift if the timeframes are identical
-        informative['date_merge'] = informative[date_column]
+        informative["date_merge"] = informative[date_column]
     elif minutes < minutes_inf:
         # Subtract "small" timeframe so merging is not delayed by 1 small candle
         # Detailed explanation in https://github.com/freqtrade/freqtrade/issues/4073
         if not informative.empty:
-            if timeframe_inf == '1M':
-                informative['date_merge'] = (
-                    (informative[date_column] + pd.offsets.MonthBegin(1))
-                    - pd.to_timedelta(minutes, 'm')
-                )
+            if timeframe_inf == "1M":
+                informative["date_merge"] = (
+                    informative[date_column] + pd.offsets.MonthBegin(1)
+                ) - pd.to_timedelta(minutes, "m")
             else:
-                informative['date_merge'] = (
-                    informative[date_column] + pd.to_timedelta(minutes_inf, 'm') -
-                    pd.to_timedelta(minutes, 'm')
+                informative["date_merge"] = (
+                    informative[date_column]
+                    + pd.to_timedelta(minutes_inf, "m")
+                    - pd.to_timedelta(minutes, "m")
                 )
         else:
-            informative['date_merge'] = informative[date_column]
+            informative["date_merge"] = informative[date_column]
     else:
-        raise ValueError("Tried to merge a faster timeframe to a slower timeframe."
-                         "This would create new rows, and can throw off your regular indicators.")
+        raise ValueError(
+            "Tried to merge a faster timeframe to a slower timeframe."
+            "This would create new rows, and can throw off your regular indicators."
+        )
 
     # Rename columns to be unique
-    date_merge = 'date_merge'
+    date_merge = "date_merge"
     if suffix and append_timeframe:
         raise ValueError("You can not specify `append_timeframe` as True and a `suffix`.")
     elif append_timeframe:
-        date_merge = f'date_merge_{timeframe_inf}'
+        date_merge = f"date_merge_{timeframe_inf}"
         informative.columns = [f"{col}_{timeframe_inf}" for col in informative.columns]
 
     elif suffix:
-        date_merge = f'date_merge_{suffix}'
+        date_merge = f"date_merge_{suffix}"
         informative.columns = [f"{col}_{suffix}" for col in informative.columns]
 
     # Combine the 2 dataframes
     # all indicators on the informative sample MUST be calculated before this point
     if ffill:
         # https://pandas.pydata.org/docs/user_guide/merging.html#timeseries-friendly-merging
         # merge_ordered - ffill method is 2.5x faster than separate ffill()
-        dataframe = pd.merge_ordered(dataframe, informative, fill_method="ffill", left_on='date',
-                                     right_on=date_merge, how='left')
+        dataframe = pd.merge_ordered(
+            dataframe,
+            informative,
+            fill_method="ffill",
+            left_on="date",
+            right_on=date_merge,
+            how="left",
+        )
     else:
-        dataframe = pd.merge(dataframe, informative, left_on='date',
-                             right_on=date_merge, how='left')
+        dataframe = pd.merge(
+            dataframe, informative, left_on="date", right_on=date_merge, how="left"
+        )
     dataframe = dataframe.drop(date_merge, axis=1)
 
     return dataframe
 
 
 def stoploss_from_open(
-    open_relative_stop: float,
-    current_profit: float,
-    is_short: bool = False,
-    leverage: float = 1.0
+    open_relative_stop: float, current_profit: float, is_short: bool = False, leverage: float = 1.0
 ) -> float:
     """
     Given the current profit, and a desired stop loss value relative to the trade entry price,
     return a stop loss value that is relative to the current price, and which can be
     returned from `custom_stoploss`.
 
     The requested stop can be positive for a stop above the open price, or negative for
@@ -125,16 +136,17 @@
         stoploss = 1 - ((1 + open_relative_stop / leverage) / (1 + _current_profit))
 
     # negative stoploss values indicate the requested stop price is higher/lower
     # (long/short) than the current price
     return max(stoploss * leverage, 0.0)
 
 
-def stoploss_from_absolute(stop_rate: float, current_rate: float, is_short: bool = False,
-                           leverage: float = 1.0) -> float:
+def stoploss_from_absolute(
+    stop_rate: float, current_rate: float, is_short: bool = False, leverage: float = 1.0
+) -> float:
     """
     Given current price and desired stop price, return a stop loss value that is relative to current
     price.
 
     The requested stop can be positive for a stop above the open price, or negative for
     a stop below the open price. The return value is always >= 0.
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/strategy_wrapper.py` & `freqtrade-2024.5/freqtrade/strategy/strategy_wrapper.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,42 +5,36 @@
 
 from freqtrade.exceptions import StrategyError
 
 
 logger = logging.getLogger(__name__)
 
 
-F = TypeVar('F', bound=Callable[..., Any])
+F = TypeVar("F", bound=Callable[..., Any])
 
 
 def strategy_safe_wrapper(f: F, message: str = "", default_retval=None, supress_error=False) -> F:
     """
     Wrapper around user-provided methods and functions.
     Caches all exceptions and returns either the default_retval (if it's not None) or raises
     a StrategyError exception, which then needs to be handled by the calling method.
     """
+
     @wraps(f)
     def wrapper(*args, **kwargs):
         try:
-            if 'trade' in kwargs:
+            if "trade" in kwargs:
                 # Protect accidental modifications from within the strategy
-                kwargs['trade'] = deepcopy(kwargs['trade'])
+                kwargs["trade"] = deepcopy(kwargs["trade"])
             return f(*args, **kwargs)
         except ValueError as error:
-            logger.warning(
-                f"{message}"
-                f"Strategy caused the following exception: {error}"
-                f"{f}"
-            )
+            logger.warning(f"{message}Strategy caused the following exception: {error}{f}")
             if default_retval is None and not supress_error:
                 raise StrategyError(str(error)) from error
             return default_retval
         except Exception as error:
-            logger.exception(
-                f"{message}"
-                f"Unexpected error {error} calling {f}"
-            )
+            logger.exception(f"{message}Unexpected error {error} calling {f}")
             if default_retval is None and not supress_error:
                 raise StrategyError(str(error)) from error
             return default_retval
 
     return cast(F, wrapper)
```

### Comparing `freqtrade-2024.4/freqtrade/strategy/strategyupdater.py` & `freqtrade-2024.5/freqtrade/strategy/strategyupdater.py`

 * *Files 20% similar despite different names*

```diff
@@ -4,77 +4,75 @@
 import ast_comments
 
 from freqtrade.constants import Config
 
 
 class StrategyUpdater:
     name_mapping = {
-        'ticker_interval': 'timeframe',
-        'buy': 'enter_long',
-        'sell': 'exit_long',
-        'buy_tag': 'enter_tag',
-        'sell_reason': 'exit_reason',
-
-        'sell_signal': 'exit_signal',
-        'custom_sell': 'custom_exit',
-        'force_sell': 'force_exit',
-        'emergency_sell': 'emergency_exit',
-
+        "ticker_interval": "timeframe",
+        "buy": "enter_long",
+        "sell": "exit_long",
+        "buy_tag": "enter_tag",
+        "sell_reason": "exit_reason",
+        "sell_signal": "exit_signal",
+        "custom_sell": "custom_exit",
+        "force_sell": "force_exit",
+        "emergency_sell": "emergency_exit",
         # Strategy/config settings:
-        'use_sell_signal': 'use_exit_signal',
-        'sell_profit_only': 'exit_profit_only',
-        'sell_profit_offset': 'exit_profit_offset',
-        'ignore_roi_if_buy_signal': 'ignore_roi_if_entry_signal',
-        'forcebuy_enable': 'force_entry_enable',
+        "use_sell_signal": "use_exit_signal",
+        "sell_profit_only": "exit_profit_only",
+        "sell_profit_offset": "exit_profit_offset",
+        "ignore_roi_if_buy_signal": "ignore_roi_if_entry_signal",
+        "forcebuy_enable": "force_entry_enable",
     }
 
     function_mapping = {
-        'populate_buy_trend': 'populate_entry_trend',
-        'populate_sell_trend': 'populate_exit_trend',
-        'custom_sell': 'custom_exit',
-        'check_buy_timeout': 'check_entry_timeout',
-        'check_sell_timeout': 'check_exit_timeout',
+        "populate_buy_trend": "populate_entry_trend",
+        "populate_sell_trend": "populate_exit_trend",
+        "custom_sell": "custom_exit",
+        "check_buy_timeout": "check_entry_timeout",
+        "check_sell_timeout": "check_exit_timeout",
         # '': '',
     }
     # order_time_in_force, order_types, unfilledtimeout
     otif_ot_unfilledtimeout = {
-        'buy': 'entry',
-        'sell': 'exit',
+        "buy": "entry",
+        "sell": "exit",
     }
 
     # create a dictionary that maps the old column names to the new ones
-    rename_dict = {'buy': 'enter_long', 'sell': 'exit_long', 'buy_tag': 'enter_tag'}
+    rename_dict = {"buy": "enter_long", "sell": "exit_long", "buy_tag": "enter_tag"}
 
     def start(self, config: Config, strategy_obj: dict) -> None:
         """
         Run strategy updater
         It updates a strategy to v3 with the help of the ast-module
         :return: None
         """
 
-        source_file = strategy_obj['location']
-        strategies_backup_folder = Path.joinpath(config['user_data_dir'], "strategies_orig_updater")
-        target_file = Path.joinpath(strategies_backup_folder, strategy_obj['location_rel'])
+        source_file = strategy_obj["location"]
+        strategies_backup_folder = Path.joinpath(config["user_data_dir"], "strategies_orig_updater")
+        target_file = Path.joinpath(strategies_backup_folder, strategy_obj["location_rel"])
 
         # read the file
-        with Path(source_file).open('r') as f:
+        with Path(source_file).open("r") as f:
             old_code = f.read()
         if not strategies_backup_folder.is_dir():
             Path(strategies_backup_folder).mkdir(parents=True, exist_ok=True)
 
         # backup original
         # => currently no date after the filename,
         # could get overridden pretty fast if this is fired twice!
         # The folder is always the same and the file name too (currently).
         shutil.copy(source_file, target_file)
 
         # update the code
         new_code = self.update_code(old_code)
         # write the modified code to the destination folder
-        with Path(source_file).open('w') as f:
+        with Path(source_file).open("w") as f:
             f.write(new_code)
 
     # define the function to update the code
     def update_code(self, code):
         # parse the code into an AST
         tree = ast_comments.parse(code)
 
@@ -102,15 +100,14 @@
 
         return ast_comments.unparse(tree)
 
 
 # Here we go through each respective node, slice, elt, key ... to replace outdated entries.
 class NameUpdater(ast_comments.NodeTransformer):
     def generic_visit(self, node):
-
         # space is not yet transferred from buy/sell to entry/exit and thereby has to be skipped.
         if isinstance(node, ast_comments.keyword):
             if node.arg == "space":
                 return node
 
         # from here on this is the original function.
         for field, old_value in ast_comments.iter_fields(node):
@@ -176,45 +173,46 @@
     def visit_FunctionDef(self, node):
         node.name = self.check_dict(StrategyUpdater.function_mapping, node.name)
         self.generic_visit(node)
         return node
 
     def visit_Attribute(self, node):
         if (
-                isinstance(node.value, ast_comments.Name)
-                and node.value.id == 'trade'
-                and node.attr == 'nr_of_successful_buys'
+            isinstance(node.value, ast_comments.Name)
+            and node.value.id == "trade"
+            and node.attr == "nr_of_successful_buys"
         ):
-            node.attr = 'nr_of_successful_entries'
+            node.attr = "nr_of_successful_entries"
         return node
 
     def visit_ClassDef(self, node):
         # check if the class is derived from IStrategy
-        if any(isinstance(base, ast_comments.Name) and
-               base.id == 'IStrategy' for base in node.bases):
+        if any(
+            isinstance(base, ast_comments.Name) and base.id == "IStrategy" for base in node.bases
+        ):
             # check if the INTERFACE_VERSION variable exists
             has_interface_version = any(
-                isinstance(child, ast_comments.Assign) and
-                isinstance(child.targets[0], ast_comments.Name) and
-                child.targets[0].id == 'INTERFACE_VERSION'
+                isinstance(child, ast_comments.Assign)
+                and isinstance(child.targets[0], ast_comments.Name)
+                and child.targets[0].id == "INTERFACE_VERSION"
                 for child in node.body
             )
 
             # if the INTERFACE_VERSION variable does not exist, add it as the first child
             if not has_interface_version:
-                node.body.insert(0, ast_comments.parse('INTERFACE_VERSION = 3').body[0])
+                node.body.insert(0, ast_comments.parse("INTERFACE_VERSION = 3").body[0])
             # otherwise, update its value to 3
             else:
                 for child in node.body:
                     if (
-                            isinstance(child, ast_comments.Assign)
-                            and isinstance(child.targets[0], ast_comments.Name)
-                            and child.targets[0].id == 'INTERFACE_VERSION'
+                        isinstance(child, ast_comments.Assign)
+                        and isinstance(child.targets[0], ast_comments.Name)
+                        and child.targets[0].id == "INTERFACE_VERSION"
                     ):
-                        child.value = ast_comments.parse('3').body[0].value
+                        child.value = ast_comments.parse("3").body[0].value
         self.generic_visit(node)
         return node
 
     def visit_Subscript(self, node):
         if isinstance(node.slice, ast_comments.Constant):
             if node.slice.value in StrategyUpdater.rename_dict:
                 # Replace the slice attributes with the values from rename_dict
```

### Comparing `freqtrade-2024.4/freqtrade/templates/FreqaiExampleHybridStrategy.py` & `freqtrade-2024.5/freqtrade/templates/FreqaiExampleHybridStrategy.py`

 * *Files 5% similar despite different names*

```diff
@@ -57,51 +57,53 @@
         }
     },
 
     Thanks to @smarmau and @johanvulgt for developing and sharing the strategy.
     """
 
     minimal_roi = {
+        # "120": 0.0,  # exit after 120 minutes at break even
         "60": 0.01,
         "30": 0.02,
-        "0": 0.04
+        "0": 0.04,
     }
 
     plot_config = {
-        'main_plot': {
-            'tema': {},
+        "main_plot": {
+            "tema": {},
         },
-        'subplots': {
+        "subplots": {
             "MACD": {
-                'macd': {'color': 'blue'},
-                'macdsignal': {'color': 'orange'},
+                "macd": {"color": "blue"},
+                "macdsignal": {"color": "orange"},
             },
             "RSI": {
-                'rsi': {'color': 'red'},
+                "rsi": {"color": "red"},
             },
             "Up_or_down": {
-                '&s-up_or_down': {'color': 'green'},
-            }
-        }
+                "&s-up_or_down": {"color": "green"},
+            },
+        },
     }
 
     process_only_new_candles = True
     stoploss = -0.05
     use_exit_signal = True
     startup_candle_count: int = 30
     can_short = True
 
     # Hyperoptable parameters
-    buy_rsi = IntParameter(low=1, high=50, default=30, space='buy', optimize=True, load=True)
-    sell_rsi = IntParameter(low=50, high=100, default=70, space='sell', optimize=True, load=True)
-    short_rsi = IntParameter(low=51, high=100, default=70, space='sell', optimize=True, load=True)
-    exit_short_rsi = IntParameter(low=1, high=50, default=30, space='buy', optimize=True, load=True)
-
-    def feature_engineering_expand_all(self, dataframe: DataFrame, period: int,
-                                       metadata: Dict, **kwargs) -> DataFrame:
+    buy_rsi = IntParameter(low=1, high=50, default=30, space="buy", optimize=True, load=True)
+    sell_rsi = IntParameter(low=50, high=100, default=70, space="sell", optimize=True, load=True)
+    short_rsi = IntParameter(low=51, high=100, default=70, space="sell", optimize=True, load=True)
+    exit_short_rsi = IntParameter(low=1, high=50, default=30, space="buy", optimize=True, load=True)
+
+    def feature_engineering_expand_all(
+        self, dataframe: DataFrame, period: int, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This function will automatically expand the defined features on the config defined
         `indicator_periods_candles`, `include_timeframes`, `include_shifted_candles`, and
         `include_corr_pairs`. In other words, a single feature defined in this function
         will automatically expand to a total of
         `indicator_periods_candles` * `include_timeframes` * `include_shifted_candles` *
@@ -132,31 +134,29 @@
             qtpylib.typical_price(dataframe), window=period, stds=2.2
         )
         dataframe["bb_lowerband-period"] = bollinger["lower"]
         dataframe["bb_middleband-period"] = bollinger["mid"]
         dataframe["bb_upperband-period"] = bollinger["upper"]
 
         dataframe["%-bb_width-period"] = (
-            dataframe["bb_upperband-period"]
-            - dataframe["bb_lowerband-period"]
+            dataframe["bb_upperband-period"] - dataframe["bb_lowerband-period"]
         ) / dataframe["bb_middleband-period"]
-        dataframe["%-close-bb_lower-period"] = (
-            dataframe["close"] / dataframe["bb_lowerband-period"]
-        )
+        dataframe["%-close-bb_lower-period"] = dataframe["close"] / dataframe["bb_lowerband-period"]
 
         dataframe["%-roc-period"] = ta.ROC(dataframe, timeperiod=period)
 
         dataframe["%-relative_volume-period"] = (
             dataframe["volume"] / dataframe["volume"].rolling(period).mean()
         )
 
         return dataframe
 
     def feature_engineering_expand_basic(
-            self, dataframe: DataFrame, metadata: Dict, **kwargs) -> DataFrame:
+        self, dataframe: DataFrame, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This function will automatically expand the defined features on the config defined
         `include_timeframes`, `include_shifted_candles`, and `include_corr_pairs`.
         In other words, a single feature defined in this function
         will automatically expand to a total of
         `include_timeframes` * `include_shifted_candles` * `include_corr_pairs`
@@ -181,15 +181,16 @@
         """
         dataframe["%-pct-change"] = dataframe["close"].pct_change()
         dataframe["%-raw_volume"] = dataframe["volume"]
         dataframe["%-raw_price"] = dataframe["close"]
         return dataframe
 
     def feature_engineering_standard(
-            self, dataframe: DataFrame, metadata: Dict, **kwargs) -> DataFrame:
+        self, dataframe: DataFrame, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This optional function will be called once with the dataframe of the base timeframe.
         This is the final function to be called, which means that the dataframe entering this
         function will contain all the features and columns created by all other
         freqai_feature_engineering_* functions.
 
@@ -222,96 +223,99 @@
         https://www.freqtrade.io/en/latest/freqai-feature-engineering
 
         :param dataframe: strategy dataframe which will receive the targets
         :param metadata: metadata of current pair
         usage example: dataframe["&-target"] = dataframe["close"].shift(-1) / dataframe["close"]
         """
         self.freqai.class_names = ["down", "up"]
-        dataframe['&s-up_or_down'] = np.where(dataframe["close"].shift(-50) >
-                                              dataframe["close"], 'up', 'down')
+        dataframe["&s-up_or_down"] = np.where(
+            dataframe["close"].shift(-50) > dataframe["close"], "up", "down"
+        )
 
         return dataframe
 
     def populate_indicators(self, dataframe: DataFrame, metadata: dict) -> DataFrame:  # noqa: C901
-
         # User creates their own custom strat here. Present example is a supertrend
         # based strategy.
 
         dataframe = self.freqai.start(dataframe, metadata, self)
 
         # TA indicators to combine with the Freqai targets
         # RSI
-        dataframe['rsi'] = ta.RSI(dataframe)
+        dataframe["rsi"] = ta.RSI(dataframe)
 
         # Bollinger Bands
         bollinger = qtpylib.bollinger_bands(qtpylib.typical_price(dataframe), window=20, stds=2)
-        dataframe['bb_lowerband'] = bollinger['lower']
-        dataframe['bb_middleband'] = bollinger['mid']
-        dataframe['bb_upperband'] = bollinger['upper']
-        dataframe["bb_percent"] = (
-            (dataframe["close"] - dataframe["bb_lowerband"]) /
-            (dataframe["bb_upperband"] - dataframe["bb_lowerband"])
-        )
-        dataframe["bb_width"] = (
-            (dataframe["bb_upperband"] - dataframe["bb_lowerband"]) / dataframe["bb_middleband"]
+        dataframe["bb_lowerband"] = bollinger["lower"]
+        dataframe["bb_middleband"] = bollinger["mid"]
+        dataframe["bb_upperband"] = bollinger["upper"]
+        dataframe["bb_percent"] = (dataframe["close"] - dataframe["bb_lowerband"]) / (
+            dataframe["bb_upperband"] - dataframe["bb_lowerband"]
         )
+        dataframe["bb_width"] = (dataframe["bb_upperband"] - dataframe["bb_lowerband"]) / dataframe[
+            "bb_middleband"
+        ]
 
         # TEMA - Triple Exponential Moving Average
-        dataframe['tema'] = ta.TEMA(dataframe, timeperiod=9)
+        dataframe["tema"] = ta.TEMA(dataframe, timeperiod=9)
 
         return dataframe
 
     def populate_entry_trend(self, df: DataFrame, metadata: dict) -> DataFrame:
-
         df.loc[
             (
                 # Signal: RSI crosses above 30
-                (qtpylib.crossed_above(df['rsi'], self.buy_rsi.value)) &
-                (df['tema'] <= df['bb_middleband']) &  # Guard: tema below BB middle
-                (df['tema'] > df['tema'].shift(1)) &  # Guard: tema is raising
-                (df['volume'] > 0) &  # Make sure Volume is not 0
-                (df['do_predict'] == 1) &  # Make sure Freqai is confident in the prediction
+                (qtpylib.crossed_above(df["rsi"], self.buy_rsi.value))
+                & (df["tema"] <= df["bb_middleband"])  # Guard: tema below BB middle
+                & (df["tema"] > df["tema"].shift(1))  # Guard: tema is raising
+                & (df["volume"] > 0)  # Make sure Volume is not 0
+                & (df["do_predict"] == 1)  # Make sure Freqai is confident in the prediction
+                &
                 # Only enter trade if Freqai thinks the trend is in this direction
-                (df['&s-up_or_down'] == 'up')
+                (df["&s-up_or_down"] == "up")
             ),
-            'enter_long'] = 1
+            "enter_long",
+        ] = 1
 
         df.loc[
             (
                 # Signal: RSI crosses above 70
-                (qtpylib.crossed_above(df['rsi'], self.short_rsi.value)) &
-                (df['tema'] > df['bb_middleband']) &  # Guard: tema above BB middle
-                (df['tema'] < df['tema'].shift(1)) &  # Guard: tema is falling
-                (df['volume'] > 0) &  # Make sure Volume is not 0
-                (df['do_predict'] == 1) &  # Make sure Freqai is confident in the prediction
+                (qtpylib.crossed_above(df["rsi"], self.short_rsi.value))
+                & (df["tema"] > df["bb_middleband"])  # Guard: tema above BB middle
+                & (df["tema"] < df["tema"].shift(1))  # Guard: tema is falling
+                & (df["volume"] > 0)  # Make sure Volume is not 0
+                & (df["do_predict"] == 1)  # Make sure Freqai is confident in the prediction
+                &
                 # Only enter trade if Freqai thinks the trend is in this direction
-                (df['&s-up_or_down'] == 'down')
+                (df["&s-up_or_down"] == "down")
             ),
-            'enter_short'] = 1
+            "enter_short",
+        ] = 1
 
         return df
 
     def populate_exit_trend(self, df: DataFrame, metadata: dict) -> DataFrame:
-
         df.loc[
             (
                 # Signal: RSI crosses above 70
-                (qtpylib.crossed_above(df['rsi'], self.sell_rsi.value)) &
-                (df['tema'] > df['bb_middleband']) &  # Guard: tema above BB middle
-                (df['tema'] < df['tema'].shift(1)) &  # Guard: tema is falling
-                (df['volume'] > 0)  # Make sure Volume is not 0
+                (qtpylib.crossed_above(df["rsi"], self.sell_rsi.value))
+                & (df["tema"] > df["bb_middleband"])  # Guard: tema above BB middle
+                & (df["tema"] < df["tema"].shift(1))  # Guard: tema is falling
+                & (df["volume"] > 0)  # Make sure Volume is not 0
             ),
-
-            'exit_long'] = 1
+            "exit_long",
+        ] = 1
 
         df.loc[
             (
                 # Signal: RSI crosses above 30
-                (qtpylib.crossed_above(df['rsi'], self.exit_short_rsi.value)) &
+                (qtpylib.crossed_above(df["rsi"], self.exit_short_rsi.value))
+                &
                 # Guard: tema below BB middle
-                (df['tema'] <= df['bb_middleband']) &
-                (df['tema'] > df['tema'].shift(1)) &  # Guard: tema is raising
-                (df['volume'] > 0)  # Make sure Volume is not 0
+                (df["tema"] <= df["bb_middleband"])
+                & (df["tema"] > df["tema"].shift(1))  # Guard: tema is raising
+                & (df["volume"] > 0)  # Make sure Volume is not 0
             ),
-            'exit_short'] = 1
+            "exit_short",
+        ] = 1
 
         return df
```

### Comparing `freqtrade-2024.4/freqtrade/templates/FreqaiExampleStrategy.py` & `freqtrade-2024.5/freqtrade/templates/FreqaiExampleStrategy.py`

 * *Files 2% similar despite different names*

```diff
@@ -41,16 +41,17 @@
     process_only_new_candles = True
     stoploss = -0.05
     use_exit_signal = True
     # this is the maximum period fed to talib (timeframe independent)
     startup_candle_count: int = 40
     can_short = True
 
-    def feature_engineering_expand_all(self, dataframe: DataFrame, period: int,
-                                       metadata: Dict, **kwargs) -> DataFrame:
+    def feature_engineering_expand_all(
+        self, dataframe: DataFrame, period: int, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This function will automatically expand the defined features on the config defined
         `indicator_periods_candles`, `include_timeframes`, `include_shifted_candles`, and
         `include_corr_pairs`. In other words, a single feature defined in this function
         will automatically expand to a total of
         `indicator_periods_candles` * `include_timeframes` * `include_shifted_candles` *
@@ -85,31 +86,29 @@
             qtpylib.typical_price(dataframe), window=period, stds=2.2
         )
         dataframe["bb_lowerband-period"] = bollinger["lower"]
         dataframe["bb_middleband-period"] = bollinger["mid"]
         dataframe["bb_upperband-period"] = bollinger["upper"]
 
         dataframe["%-bb_width-period"] = (
-            dataframe["bb_upperband-period"]
-            - dataframe["bb_lowerband-period"]
+            dataframe["bb_upperband-period"] - dataframe["bb_lowerband-period"]
         ) / dataframe["bb_middleband-period"]
-        dataframe["%-close-bb_lower-period"] = (
-            dataframe["close"] / dataframe["bb_lowerband-period"]
-        )
+        dataframe["%-close-bb_lower-period"] = dataframe["close"] / dataframe["bb_lowerband-period"]
 
         dataframe["%-roc-period"] = ta.ROC(dataframe, timeperiod=period)
 
         dataframe["%-relative_volume-period"] = (
             dataframe["volume"] / dataframe["volume"].rolling(period).mean()
         )
 
         return dataframe
 
     def feature_engineering_expand_basic(
-            self, dataframe: DataFrame, metadata: Dict, **kwargs) -> DataFrame:
+        self, dataframe: DataFrame, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This function will automatically expand the defined features on the config defined
         `include_timeframes`, `include_shifted_candles`, and `include_corr_pairs`.
         In other words, a single feature defined in this function
         will automatically expand to a total of
         `include_timeframes` * `include_shifted_candles` * `include_corr_pairs`
@@ -138,15 +137,16 @@
         """
         dataframe["%-pct-change"] = dataframe["close"].pct_change()
         dataframe["%-raw_volume"] = dataframe["volume"]
         dataframe["%-raw_price"] = dataframe["close"]
         return dataframe
 
     def feature_engineering_standard(
-            self, dataframe: DataFrame, metadata: Dict, **kwargs) -> DataFrame:
+        self, dataframe: DataFrame, metadata: Dict, **kwargs
+    ) -> DataFrame:
         """
         *Only functional with FreqAI enabled strategies*
         This optional function will be called once with the dataframe of the base timeframe.
         This is the final function to be called, which means that the dataframe entering this
         function will contain all the features and columns created by all other
         freqai_feature_engineering_* functions.
 
@@ -193,15 +193,15 @@
         dataframe["&-s_close"] = (
             dataframe["close"]
             .shift(-self.freqai_info["feature_parameters"]["label_period_candles"])
             .rolling(self.freqai_info["feature_parameters"]["label_period_candles"])
             .mean()
             / dataframe["close"]
             - 1
-            )
+        )
 
         # Classifiers are typically set up with strings as targets:
         # df['&s-up_or_down'] = np.where( df["close"].shift(-100) >
         #                                 df["close"], 'up', 'down')
 
         # If user wishes to use multiple targets, they can add more by
         # appending more columns with '&'. User should keep in mind that multi targets
@@ -220,62 +220,54 @@
         #     .rolling(self.freqai_info["feature_parameters"]["label_period_candles"])
         #     .min()
         # )
 
         return dataframe
 
     def populate_indicators(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
-
         # All indicators must be populated by feature_engineering_*() functions
 
         # the model will return all labels created by user in `set_freqai_targets()`
         # (& appended targets), an indication of whether or not the prediction should be accepted,
         # the target mean/std values for each of the labels created by user in
         # `set_freqai_targets()` for each training period.
 
         dataframe = self.freqai.start(dataframe, metadata, self)
 
         return dataframe
 
     def populate_entry_trend(self, df: DataFrame, metadata: dict) -> DataFrame:
-
         enter_long_conditions = [
             df["do_predict"] == 1,
             df["&-s_close"] > 0.01,
-            ]
+        ]
 
         if enter_long_conditions:
             df.loc[
                 reduce(lambda x, y: x & y, enter_long_conditions), ["enter_long", "enter_tag"]
             ] = (1, "long")
 
         enter_short_conditions = [
             df["do_predict"] == 1,
             df["&-s_close"] < -0.01,
-            ]
+        ]
 
         if enter_short_conditions:
             df.loc[
                 reduce(lambda x, y: x & y, enter_short_conditions), ["enter_short", "enter_tag"]
             ] = (1, "short")
 
         return df
 
     def populate_exit_trend(self, df: DataFrame, metadata: dict) -> DataFrame:
-        exit_long_conditions = [
-            df["do_predict"] == 1,
-            df["&-s_close"] < 0
-            ]
+        exit_long_conditions = [df["do_predict"] == 1, df["&-s_close"] < 0]
         if exit_long_conditions:
             df.loc[reduce(lambda x, y: x & y, exit_long_conditions), "exit_long"] = 1
 
-        exit_short_conditions = [
-            df["do_predict"] == 1,
-            df["&-s_close"] > 0
-            ]
+        exit_short_conditions = [df["do_predict"] == 1, df["&-s_close"] > 0]
         if exit_short_conditions:
             df.loc[reduce(lambda x, y: x & y, exit_short_conditions), "exit_short"] = 1
 
         return df
 
     def confirm_trade_entry(
         self,
@@ -285,15 +277,14 @@
         rate: float,
         time_in_force: str,
         current_time,
         entry_tag,
         side: str,
         **kwargs,
     ) -> bool:
-
         df, _ = self.dp.get_analyzed_dataframe(pair, self.timeframe)
         last_candle = df.iloc[-1].squeeze()
 
         if side == "long":
             if rate > (last_candle["close"] * (1 + 0.0025)):
                 return False
         else:
```

### Comparing `freqtrade-2024.4/freqtrade/templates/base_config.json.j2` & `freqtrade-2024.5/freqtrade/templates/base_config.json.j2`

 * *Files 4% similar despite different names*

```diff
@@ -6,15 +6,16 @@
             "refresh_period": 1800
         }' %}
 {
     "max_open_trades": {{ max_open_trades }},
     "stake_currency": "{{ stake_currency }}",
     "stake_amount": {{ stake_amount }},
     "tradable_balance_ratio": 0.99,
-    "fiat_display_currency": "{{ fiat_display_currency }}",{{ ('\n    "timeframe": "' + timeframe + '",') if timeframe else '' }}
+{{- ('\n    "fiat_display_currency": "' + fiat_display_currency + '",') if fiat_display_currency else ''}}
+{{- ('\n    "timeframe": "' + timeframe + '",') if timeframe else '' }}
     "dry_run": {{ dry_run | lower }},
     "dry_run_wallet": 1000,
     "cancel_open_orders_on_exit": false,
     "trading_mode": "{{ trading_mode }}",
     "margin_mode": "{{ margin_mode }}",
     "unfilledtimeout": {
         "entry": 10,
```

### Comparing `freqtrade-2024.4/freqtrade/templates/base_strategy.py.j2` & `freqtrade-2024.5/freqtrade/templates/base_strategy.py.j2`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/templates/sample_hyperopt_loss.py` & `freqtrade-2024.5/freqtrade/templates/sample_hyperopt_loss.py`

 * *Files 9% similar despite different names*

```diff
@@ -31,22 +31,28 @@
     This is intended to give you some inspiration for your own loss function.
 
     The Function needs to return a number (float) - which becomes smaller for better backtest
     results.
     """
 
     @staticmethod
-    def hyperopt_loss_function(results: DataFrame, trade_count: int,
-                               min_date: datetime, max_date: datetime,
-                               config: Config, processed: Dict[str, DataFrame],
-                               *args, **kwargs) -> float:
+    def hyperopt_loss_function(
+        results: DataFrame,
+        trade_count: int,
+        min_date: datetime,
+        max_date: datetime,
+        config: Config,
+        processed: Dict[str, DataFrame],
+        *args,
+        **kwargs,
+    ) -> float:
         """
         Objective function, returns smaller number for better results
         """
-        total_profit = results['profit_ratio'].sum()
-        trade_duration = results['trade_duration'].mean()
+        total_profit = results["profit_ratio"].sum()
+        trade_duration = results["trade_duration"].mean()
 
-        trade_loss = 1 - 0.25 * exp(-(trade_count - TARGET_TRADES) ** 2 / 10 ** 5.8)
+        trade_loss = 1 - 0.25 * exp(-((trade_count - TARGET_TRADES) ** 2) / 10**5.8)
         profit_loss = max(0, 1 - total_profit / EXPECTED_MAX_PROFIT)
         duration_loss = 0.4 * min(trade_duration / MAX_ACCEPTED_TRADE_DURATION, 1)
         result = trade_loss + profit_loss + duration_loss
         return result
```

### Comparing `freqtrade-2024.4/freqtrade/templates/sample_strategy.py` & `freqtrade-2024.5/freqtrade/templates/sample_strategy.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,16 +3,21 @@
 # isort: skip_file
 # --- Do not remove these libs ---
 import numpy as np  # noqa
 import pandas as pd  # noqa
 from pandas import DataFrame
 from typing import Optional, Union
 
-from freqtrade.strategy import (BooleanParameter, CategoricalParameter, DecimalParameter,
-                                IStrategy, IntParameter)
+from freqtrade.strategy import (
+    BooleanParameter,
+    CategoricalParameter,
+    DecimalParameter,
+    IStrategy,
+    IntParameter,
+)
 
 # --------------------------------
 # Add your lib to import here
 import talib.abstract as ta
 import freqtrade.vendor.qtpylib.indicators as qtpylib
 
 
@@ -30,87 +35,86 @@
 
     You must keep:
     - the lib in the section "Do not remove these libs"
     - the methods: populate_indicators, populate_entry_trend, populate_exit_trend
     You should keep:
     - timeframe, minimal_roi, stoploss, trailing_*
     """
+
     # Strategy interface version - allow new iterations of the strategy interface.
     # Check the documentation or the Sample strategy to get the latest version.
     INTERFACE_VERSION = 3
 
     # Can this strategy go short?
     can_short: bool = False
 
     # Minimal ROI designed for the strategy.
     # This attribute will be overridden if the config file contains "minimal_roi".
     minimal_roi = {
+        # "120": 0.0,  # exit after 120 minutes at break even
         "60": 0.01,
         "30": 0.02,
-        "0": 0.04
+        "0": 0.04,
     }
 
     # Optimal stoploss designed for the strategy.
     # This attribute will be overridden if the config file contains "stoploss".
     stoploss = -0.10
 
     # Trailing stoploss
     trailing_stop = False
     # trailing_only_offset_is_reached = False
     # trailing_stop_positive = 0.01
     # trailing_stop_positive_offset = 0.0  # Disabled / not configured
 
     # Optimal timeframe for the strategy.
-    timeframe = '5m'
+    timeframe = "5m"
 
     # Run "populate_indicators()" only for new candle.
     process_only_new_candles = True
 
     # These values can be overridden in the config.
     use_exit_signal = True
     exit_profit_only = False
     ignore_roi_if_entry_signal = False
 
     # Hyperoptable parameters
-    buy_rsi = IntParameter(low=1, high=50, default=30, space='buy', optimize=True, load=True)
-    sell_rsi = IntParameter(low=50, high=100, default=70, space='sell', optimize=True, load=True)
-    short_rsi = IntParameter(low=51, high=100, default=70, space='sell', optimize=True, load=True)
-    exit_short_rsi = IntParameter(low=1, high=50, default=30, space='buy', optimize=True, load=True)
+    buy_rsi = IntParameter(low=1, high=50, default=30, space="buy", optimize=True, load=True)
+    sell_rsi = IntParameter(low=50, high=100, default=70, space="sell", optimize=True, load=True)
+    short_rsi = IntParameter(low=51, high=100, default=70, space="sell", optimize=True, load=True)
+    exit_short_rsi = IntParameter(low=1, high=50, default=30, space="buy", optimize=True, load=True)
 
     # Number of candles the strategy requires before producing valid signals
     startup_candle_count: int = 200
 
     # Optional order type mapping.
     order_types = {
-        'entry': 'limit',
-        'exit': 'limit',
-        'stoploss': 'market',
-        'stoploss_on_exchange': False
+        "entry": "limit",
+        "exit": "limit",
+        "stoploss": "market",
+        "stoploss_on_exchange": False,
     }
 
     # Optional order time in force.
-    order_time_in_force = {
-        'entry': 'GTC',
-        'exit': 'GTC'
-    }
+    order_time_in_force = {"entry": "GTC", "exit": "GTC"}
 
     plot_config = {
-        'main_plot': {
-            'tema': {},
-            'sar': {'color': 'white'},
+        "main_plot": {
+            "tema": {},
+            "sar": {"color": "white"},
         },
-        'subplots': {
+        "subplots": {
             "MACD": {
-                'macd': {'color': 'blue'},
-                'macdsignal': {'color': 'orange'},
+                "macd": {"color": "blue"},
+                "macdsignal": {"color": "orange"},
             },
             "RSI": {
-                'rsi': {'color': 'red'},
-            }
-        }
+                "rsi": {"color": "red"},
+            },
+        },
     }
 
     def informative_pairs(self):
         """
         Define additional, informative pair/interval combinations to be cached from the exchange.
         These pair/interval combinations are non-tradeable, unless they are part
         of the whitelist as well.
@@ -134,15 +138,15 @@
         :return: a Dataframe with all mandatory indicators for the strategies
         """
 
         # Momentum Indicators
         # ------------------------------------
 
         # ADX
-        dataframe['adx'] = ta.ADX(dataframe)
+        dataframe["adx"] = ta.ADX(dataframe)
 
         # # Plus Directional Indicator / Movement
         # dataframe['plus_dm'] = ta.PLUS_DM(dataframe)
         # dataframe['plus_di'] = ta.PLUS_DI(dataframe)
 
         # # Minus Directional Indicator / Movement
         # dataframe['minus_dm'] = ta.MINUS_DM(dataframe)
@@ -173,15 +177,15 @@
         # # Ultimate Oscillator
         # dataframe['uo'] = ta.ULTOSC(dataframe)
 
         # # Commodity Channel Index: values [Oversold:-100, Overbought:100]
         # dataframe['cci'] = ta.CCI(dataframe)
 
         # RSI
-        dataframe['rsi'] = ta.RSI(dataframe)
+        dataframe["rsi"] = ta.RSI(dataframe)
 
         # # Inverse Fisher transform on RSI: values [-1.0, 1.0] (https://goo.gl/2JGGoy)
         # rsi = 0.1 * (dataframe['rsi'] - 50)
         # dataframe['fisher_rsi'] = (np.exp(2 * rsi) - 1) / (np.exp(2 * rsi) + 1)
 
         # # Inverse Fisher transform on RSI normalized: values [0.0, 100.0] (https://goo.gl/2JGGoy)
         # dataframe['fisher_rsi_norma'] = 50 * (dataframe['fisher_rsi'] + 1)
@@ -189,51 +193,50 @@
         # # Stochastic Slow
         # stoch = ta.STOCH(dataframe)
         # dataframe['slowd'] = stoch['slowd']
         # dataframe['slowk'] = stoch['slowk']
 
         # Stochastic Fast
         stoch_fast = ta.STOCHF(dataframe)
-        dataframe['fastd'] = stoch_fast['fastd']
-        dataframe['fastk'] = stoch_fast['fastk']
+        dataframe["fastd"] = stoch_fast["fastd"]
+        dataframe["fastk"] = stoch_fast["fastk"]
 
         # # Stochastic RSI
         # Please read https://github.com/freqtrade/freqtrade/issues/2961 before using this.
         # STOCHRSI is NOT aligned with tradingview, which may result in non-expected results.
         # stoch_rsi = ta.STOCHRSI(dataframe)
         # dataframe['fastd_rsi'] = stoch_rsi['fastd']
         # dataframe['fastk_rsi'] = stoch_rsi['fastk']
 
         # MACD
         macd = ta.MACD(dataframe)
-        dataframe['macd'] = macd['macd']
-        dataframe['macdsignal'] = macd['macdsignal']
-        dataframe['macdhist'] = macd['macdhist']
+        dataframe["macd"] = macd["macd"]
+        dataframe["macdsignal"] = macd["macdsignal"]
+        dataframe["macdhist"] = macd["macdhist"]
 
         # MFI
-        dataframe['mfi'] = ta.MFI(dataframe)
+        dataframe["mfi"] = ta.MFI(dataframe)
 
         # # ROC
         # dataframe['roc'] = ta.ROC(dataframe)
 
         # Overlap Studies
         # ------------------------------------
 
         # Bollinger Bands
         bollinger = qtpylib.bollinger_bands(qtpylib.typical_price(dataframe), window=20, stds=2)
-        dataframe['bb_lowerband'] = bollinger['lower']
-        dataframe['bb_middleband'] = bollinger['mid']
-        dataframe['bb_upperband'] = bollinger['upper']
-        dataframe["bb_percent"] = (
-            (dataframe["close"] - dataframe["bb_lowerband"]) /
-            (dataframe["bb_upperband"] - dataframe["bb_lowerband"])
-        )
-        dataframe["bb_width"] = (
-            (dataframe["bb_upperband"] - dataframe["bb_lowerband"]) / dataframe["bb_middleband"]
+        dataframe["bb_lowerband"] = bollinger["lower"]
+        dataframe["bb_middleband"] = bollinger["mid"]
+        dataframe["bb_upperband"] = bollinger["upper"]
+        dataframe["bb_percent"] = (dataframe["close"] - dataframe["bb_lowerband"]) / (
+            dataframe["bb_upperband"] - dataframe["bb_lowerband"]
         )
+        dataframe["bb_width"] = (dataframe["bb_upperband"] - dataframe["bb_lowerband"]) / dataframe[
+            "bb_middleband"
+        ]
 
         # Bollinger Bands - Weighted (EMA based instead of SMA)
         # weighted_bollinger = qtpylib.weighted_bollinger_bands(
         #     qtpylib.typical_price(dataframe), window=20, stds=2
         # )
         # dataframe["wbb_upperband"] = weighted_bollinger["upper"]
         # dataframe["wbb_lowerband"] = weighted_bollinger["lower"]
@@ -260,25 +263,25 @@
         # dataframe['sma5'] = ta.SMA(dataframe, timeperiod=5)
         # dataframe['sma10'] = ta.SMA(dataframe, timeperiod=10)
         # dataframe['sma21'] = ta.SMA(dataframe, timeperiod=21)
         # dataframe['sma50'] = ta.SMA(dataframe, timeperiod=50)
         # dataframe['sma100'] = ta.SMA(dataframe, timeperiod=100)
 
         # Parabolic SAR
-        dataframe['sar'] = ta.SAR(dataframe)
+        dataframe["sar"] = ta.SAR(dataframe)
 
         # TEMA - Triple Exponential Moving Average
-        dataframe['tema'] = ta.TEMA(dataframe, timeperiod=9)
+        dataframe["tema"] = ta.TEMA(dataframe, timeperiod=9)
 
         # Cycle Indicator
         # ------------------------------------
         # Hilbert Transform Indicator - SineWave
         hilbert = ta.HT_SINE(dataframe)
-        dataframe['htsine'] = hilbert['sine']
-        dataframe['htleadsine'] = hilbert['leadsine']
+        dataframe["htsine"] = hilbert["sine"]
+        dataframe["htleadsine"] = hilbert["leadsine"]
 
         # Pattern Recognition - Bullish candlestick patterns
         # ------------------------------------
         # # Hammer: values [0, 100]
         # dataframe['CDLHAMMER'] = ta.CDLHAMMER(dataframe)
         # # Inverted Hammer: values [0, 100]
         # dataframe['CDLINVERTEDHAMMER'] = ta.CDLINVERTEDHAMMER(dataframe)
@@ -349,56 +352,60 @@
         :param dataframe: DataFrame
         :param metadata: Additional information, like the currently traded pair
         :return: DataFrame with entry columns populated
         """
         dataframe.loc[
             (
                 # Signal: RSI crosses above 30
-                (qtpylib.crossed_above(dataframe['rsi'], self.buy_rsi.value)) &
-                (dataframe['tema'] <= dataframe['bb_middleband']) &  # Guard: tema below BB middle
-                (dataframe['tema'] > dataframe['tema'].shift(1)) &  # Guard: tema is raising
-                (dataframe['volume'] > 0)  # Make sure Volume is not 0
+                (qtpylib.crossed_above(dataframe["rsi"], self.buy_rsi.value))
+                & (dataframe["tema"] <= dataframe["bb_middleband"])  # Guard: tema below BB middle
+                & (dataframe["tema"] > dataframe["tema"].shift(1))  # Guard: tema is raising
+                & (dataframe["volume"] > 0)  # Make sure Volume is not 0
             ),
-            'enter_long'] = 1
+            "enter_long",
+        ] = 1
 
         dataframe.loc[
             (
                 # Signal: RSI crosses above 70
-                (qtpylib.crossed_above(dataframe['rsi'], self.short_rsi.value)) &
-                (dataframe['tema'] > dataframe['bb_middleband']) &  # Guard: tema above BB middle
-                (dataframe['tema'] < dataframe['tema'].shift(1)) &  # Guard: tema is falling
-                (dataframe['volume'] > 0)  # Make sure Volume is not 0
+                (qtpylib.crossed_above(dataframe["rsi"], self.short_rsi.value))
+                & (dataframe["tema"] > dataframe["bb_middleband"])  # Guard: tema above BB middle
+                & (dataframe["tema"] < dataframe["tema"].shift(1))  # Guard: tema is falling
+                & (dataframe["volume"] > 0)  # Make sure Volume is not 0
             ),
-            'enter_short'] = 1
+            "enter_short",
+        ] = 1
 
         return dataframe
 
     def populate_exit_trend(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
         """
         Based on TA indicators, populates the exit signal for the given dataframe
         :param dataframe: DataFrame
         :param metadata: Additional information, like the currently traded pair
         :return: DataFrame with exit columns populated
         """
         dataframe.loc[
             (
                 # Signal: RSI crosses above 70
-                (qtpylib.crossed_above(dataframe['rsi'], self.sell_rsi.value)) &
-                (dataframe['tema'] > dataframe['bb_middleband']) &  # Guard: tema above BB middle
-                (dataframe['tema'] < dataframe['tema'].shift(1)) &  # Guard: tema is falling
-                (dataframe['volume'] > 0)  # Make sure Volume is not 0
+                (qtpylib.crossed_above(dataframe["rsi"], self.sell_rsi.value))
+                & (dataframe["tema"] > dataframe["bb_middleband"])  # Guard: tema above BB middle
+                & (dataframe["tema"] < dataframe["tema"].shift(1))  # Guard: tema is falling
+                & (dataframe["volume"] > 0)  # Make sure Volume is not 0
             ),
-
-            'exit_long'] = 1
+            "exit_long",
+        ] = 1
 
         dataframe.loc[
             (
                 # Signal: RSI crosses above 30
-                (qtpylib.crossed_above(dataframe['rsi'], self.exit_short_rsi.value)) &
+                (qtpylib.crossed_above(dataframe["rsi"], self.exit_short_rsi.value))
+                &
                 # Guard: tema below BB middle
-                (dataframe['tema'] <= dataframe['bb_middleband']) &
-                (dataframe['tema'] > dataframe['tema'].shift(1)) &  # Guard: tema is raising
-                (dataframe['volume'] > 0)  # Make sure Volume is not 0
+                (dataframe["tema"] <= dataframe["bb_middleband"])
+                & (dataframe["tema"] > dataframe["tema"].shift(1))  # Guard: tema is raising
+                & (dataframe["volume"] > 0)  # Make sure Volume is not 0
             ),
-            'exit_short'] = 1
+            "exit_short",
+        ] = 1
 
         return dataframe
```

### Comparing `freqtrade-2024.4/freqtrade/templates/strategy_analysis_example.ipynb` & `freqtrade-2024.5/freqtrade/templates/strategy_analysis_example.ipynb`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/indicators_full.j2` & `freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/indicators_full.j2`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/templates/strategy_subtemplates/strategy_methods_advanced.j2` & `freqtrade-2024.5/freqtrade/templates/strategy_subtemplates/strategy_methods_advanced.j2`

 * *Files identical despite different names*

### Comparing `freqtrade-2024.4/freqtrade/types/backtest_result_type.py` & `freqtrade-2024.5/freqtrade/types/backtest_result_type.py`

 * *Files 17% similar despite different names*

```diff
@@ -12,17 +12,17 @@
     metadata: Dict[str, Any]  # BacktestMetadataType
     strategy: Dict[str, Any]
     strategy_comparison: List[Any]
 
 
 def get_BacktestResultType_default() -> BacktestResultType:
     return {
-        'metadata': {},
-        'strategy': {},
-        'strategy_comparison': [],
+        "metadata": {},
+        "strategy": {},
+        "strategy_comparison": [],
     }
 
 
 class BacktestHistoryEntryType(BacktestMetadataType):
     filename: str
     strategy: str
     notes: str
```

### Comparing `freqtrade-2024.4/freqtrade/util/datetime_helpers.py` & `freqtrade-2024.5/freqtrade/util/datetime_helpers.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,16 +9,23 @@
 
 
 def dt_now() -> datetime:
     """Return the current datetime in UTC."""
     return datetime.now(timezone.utc)
 
 
-def dt_utc(year: int, month: int, day: int, hour: int = 0, minute: int = 0, second: int = 0,
-           microsecond: int = 0) -> datetime:
+def dt_utc(
+    year: int,
+    month: int,
+    day: int,
+    hour: int = 0,
+    minute: int = 0,
+    second: int = 0,
+    microsecond: int = 0,
+) -> datetime:
     """Return a datetime in UTC."""
     return datetime(year, month, day, hour, minute, second, microsecond, tzinfo=timezone.utc)
 
 
 def dt_ts(dt: Optional[datetime] = None) -> int:
     """
     Return dt in ms as a timestamp in UTC.
@@ -65,19 +72,19 @@
     return datetime.fromtimestamp(timestamp, tz=timezone.utc)
 
 
 def shorten_date(_date: str) -> str:
     """
     Trim the date so it fits on small screens
     """
-    new_date = re.sub('seconds?', 'sec', _date)
-    new_date = re.sub('minutes?', 'min', new_date)
-    new_date = re.sub('hours?', 'h', new_date)
-    new_date = re.sub('days?', 'd', new_date)
-    new_date = re.sub('^an?', '1', new_date)
+    new_date = re.sub("seconds?", "sec", _date)
+    new_date = re.sub("minutes?", "min", new_date)
+    new_date = re.sub("hours?", "h", new_date)
+    new_date = re.sub("days?", "d", new_date)
+    new_date = re.sub("^an?", "1", new_date)
     return new_date
 
 
 def dt_humanize_delta(dt: datetime):
     """
     Return a humanized string for the given timedelta.
     """
@@ -88,16 +95,16 @@
     """
     Return a formatted date string.
     Returns an empty string if date is None.
     :param date: datetime to format
     """
     if date:
         return date.strftime(DATETIME_PRINT_FORMAT)
-    return ''
+    return ""
 
 
 def format_ms_time(date: Union[int, float]) -> str:
     """
     convert MS date to readable format.
     : epoch-string in ms
     """
-    return dt_from_ts(date).strftime('%Y-%m-%dT%H:%M:%S')
+    return dt_from_ts(date).strftime("%Y-%m-%dT%H:%M:%S")
```

### Comparing `freqtrade-2024.4/freqtrade/util/formatters.py` & `freqtrade-2024.5/freqtrade/util/formatters.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 def strip_trailing_zeros(value: str) -> str:
     """
     Strip trailing zeros from a string
     :param value: Value to be stripped
     :return: Stripped value
     """
-    return value.rstrip('0').rstrip('.')
+    return value.rstrip("0").rstrip(".")
 
 
 def round_value(value: float, decimals: int, keep_trailing_zeros=False) -> str:
     """
     Round value to given decimals
     :param value: Value to be rounded
     :param decimals: Number of decimals to round to
@@ -29,16 +29,15 @@
     """
     val = f"{value:.{decimals}f}"
     if not keep_trailing_zeros:
         val = strip_trailing_zeros(val)
     return val
 
 
-def fmt_coin(
-        value: float, coin: str, show_coin_name=True, keep_trailing_zeros=False) -> str:
+def fmt_coin(value: float, coin: str, show_coin_name=True, keep_trailing_zeros=False) -> str:
     """
     Format price value for this coin
     :param value: Value to be printed
     :param coin: Which coin are we printing the price / value for
     :param show_coin_name: Return string in format: "222.22 USDT" or "222.22"
     :param keep_trailing_zeros: Keep trailing zeros "222.200" vs. "222.2"
     :return: Formatted / rounded value (with or without coin name)
```

### Comparing `freqtrade-2024.4/freqtrade/util/measure_time.py` & `freqtrade-2024.5/freqtrade/util/measure_time.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,16 +8,18 @@
 logger = logging.getLogger(__name__)
 
 
 class MeasureTime:
     """
     Measure the time of a block of code and call a callback if the time limit is exceeded.
     """
+
     def __init__(
-            self, callback: Callable[[float, float], None], time_limit: float, ttl: int = 3600 * 4):
+        self, callback: Callable[[float, float], None], time_limit: float, ttl: int = 3600 * 4
+    ):
         """
         :param callback: The callback to call if the time limit is exceeded.
             This callback will be called once every "ttl" seconds,
             with the parameters "duration" (in seconds) and
             "time limit" - representing the passed in time limit.
         :param time_limit: The time limit in seconds.
         :param ttl: The time to live of the cache in seconds.
@@ -28,16 +30,16 @@
         self.__cache: TTLCache = TTLCache(maxsize=1, ttl=ttl)
 
     def __enter__(self):
         self._start = time.time()
 
     def __exit__(self, *args):
         end = time.time()
-        if self.__cache.get('value'):
+        if self.__cache.get("value"):
             return
         duration = end - self._start
 
         if duration < self._time_limit:
             return
         self._callback(duration, self._time_limit)
 
-        self.__cache['value'] = True
+        self.__cache["value"] = True
```

### Comparing `freqtrade-2024.4/freqtrade/util/migrations/binance_mig.py` & `freqtrade-2024.5/freqtrade/util/migrations/binance_mig.py`

 * *Files 15% similar despite different names*

```diff
@@ -10,70 +10,70 @@
 from freqtrade.persistence.trade_model import Trade
 
 
 logger = logging.getLogger(__name__)
 
 
 def migrate_binance_futures_names(config: Config):
-
-    if (
-        not (config.get('trading_mode', TradingMode.SPOT) == TradingMode.FUTURES
-             and config['exchange']['name'] == 'binance')
+    if not (
+        config.get("trading_mode", TradingMode.SPOT) == TradingMode.FUTURES
+        and config["exchange"]["name"] == "binance"
     ):
         # only act on new futures
         return
     import ccxt
+
     if version.parse("2.6.26") > version.parse(ccxt.__version__):
         raise OperationalException(
             "Please follow the update instructions in the docs "
-            f"({DOCS_LINK}/updating/) to install a compatible ccxt version.")
+            f"({DOCS_LINK}/updating/) to install a compatible ccxt version."
+        )
     _migrate_binance_futures_db(config)
     migrate_binance_futures_data(config)
 
 
 def _migrate_binance_futures_db(config: Config):
-    logger.warning('Migrating binance futures pairs in database.')
-    trades = Trade.get_trades([Trade.exchange == 'binance', Trade.trading_mode == 'FUTURES']).all()
+    logger.warning("Migrating binance futures pairs in database.")
+    trades = Trade.get_trades([Trade.exchange == "binance", Trade.trading_mode == "FUTURES"]).all()
     for trade in trades:
-        if ':' in trade.pair:
+        if ":" in trade.pair:
             # already migrated
             continue
         new_pair = f"{trade.pair}:{trade.stake_currency}"
         trade.pair = new_pair
 
         for order in trade.orders:
             order.ft_pair = new_pair
             # Should symbol be migrated too?
             # order.symbol = new_pair
     Trade.commit()
-    pls = PairLock.session.scalars(select(PairLock).filter(PairLock.pair.notlike('%:%'))).all()
+    pls = PairLock.session.scalars(select(PairLock).filter(PairLock.pair.notlike("%:%"))).all()
     for pl in pls:
         pl.pair = f"{pl.pair}:{config['stake_currency']}"
     # print(pls)
     # pls.update({'pair': concat(PairLock.pair,':USDT')})
     Trade.commit()
-    logger.warning('Done migrating binance futures pairs in database.')
+    logger.warning("Done migrating binance futures pairs in database.")
 
 
 def migrate_binance_futures_data(config: Config):
-
-    if (
-        not (config.get('trading_mode', TradingMode.SPOT) == TradingMode.FUTURES
-             and config['exchange']['name'] == 'binance')
+    if not (
+        config.get("trading_mode", TradingMode.SPOT) == TradingMode.FUTURES
+        and config["exchange"]["name"] == "binance"
     ):
         # only act on new futures
         return
 
     from freqtrade.data.history import get_datahandler
-    dhc = get_datahandler(config['datadir'], config['dataformat_ohlcv'])
+
+    dhc = get_datahandler(config["datadir"], config["dataformat_ohlcv"])
 
     paircombs = dhc.ohlcv_get_available_data(
-        config['datadir'],
-        config.get('trading_mode', TradingMode.SPOT)
-        )
+        config["datadir"], config.get("trading_mode", TradingMode.SPOT)
+    )
 
     for pair, timeframe, candle_type in paircombs:
-        if ':' in pair:
+        if ":" in pair:
             # already migrated
             continue
         new_pair = f"{pair}:{config['stake_currency']}"
         dhc.rename_futures_data(pair, new_pair, timeframe, candle_type)
```

### Comparing `freqtrade-2024.4/freqtrade/util/migrations/funding_rate_mig.py` & `freqtrade-2024.5/freqtrade/util/migrations/funding_rate_mig.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,21 +7,20 @@
 from freqtrade.exchange import Exchange
 
 
 logger = logging.getLogger(__name__)
 
 
 def migrate_funding_fee_timeframe(config: Config, exchange: Optional[Exchange]):
-    if (
-        config.get('trading_mode', TradingMode.SPOT) != TradingMode.FUTURES
-    ):
+    if config.get("trading_mode", TradingMode.SPOT) != TradingMode.FUTURES:
         # only act on futures
         return
 
     if not exchange:
         from freqtrade.resolvers import ExchangeResolver
+
         exchange = ExchangeResolver.load_exchange(config, validate=False)
 
-    ff_timeframe = exchange.get_option('funding_fee_timeframe')
+    ff_timeframe = exchange.get_option("funding_fee_timeframe")
 
-    dhc = get_datahandler(config['datadir'], config['dataformat_ohlcv'])
+    dhc = get_datahandler(config["datadir"], config["dataformat_ohlcv"])
     dhc.fix_funding_fee_timeframe(ff_timeframe)
```

### Comparing `freqtrade-2024.4/freqtrade/util/periodic_cache.py` & `freqtrade-2024.5/freqtrade/util/periodic_cache.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,12 +8,12 @@
     Special cache that expires at "straight" times
     A timer with ttl of 3600 (1h) will expire at every full hour (:00).
     """
 
     def __init__(self, maxsize, ttl, getsizeof=None):
         def local_timer():
             ts = datetime.now(timezone.utc).timestamp()
-            offset = (ts % ttl)
+            offset = ts % ttl
             return ts - offset
 
         # Init with smlight offset
         super().__init__(maxsize=maxsize, ttl=ttl - 1e-5, timer=local_timer, getsizeof=getsizeof)
```

### Comparing `freqtrade-2024.4/freqtrade/util/template_renderer.py` & `freqtrade-2024.5/freqtrade/util/template_renderer.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 """
 Jinja2 rendering utils, used to generate new strategy and configurations.
 """
 
-
 from typing import Dict, Optional
 
 
 def render_template(templatefile: str, arguments: Dict) -> str:
-
     from jinja2 import Environment, PackageLoader, select_autoescape
 
     env = Environment(
-        loader=PackageLoader('freqtrade', 'templates'),
-        autoescape=select_autoescape(['html', 'xml'])
+        loader=PackageLoader("freqtrade", "templates"),
+        autoescape=select_autoescape(["html", "xml"]),
     )
     template = env.get_template(templatefile)
     return template.render(**arguments)
 
 
-def render_template_with_fallback(templatefile: str, templatefallbackfile: str,
-                                  arguments: Optional[Dict] = None) -> str:
+def render_template_with_fallback(
+    templatefile: str, templatefallbackfile: str, arguments: Optional[Dict] = None
+) -> str:
     """
     Use templatefile if possible, otherwise fall back to templatefallbackfile
     """
     from jinja2.exceptions import TemplateNotFound
+
     if arguments is None:
         arguments = {}
     try:
         return render_template(templatefile, arguments)
     except TemplateNotFound:
         return render_template(templatefallbackfile, arguments)
```

### Comparing `freqtrade-2024.4/freqtrade/vendor/qtpylib/indicators.py` & `freqtrade-2024.5/freqtrade/vendor/qtpylib/indicators.py`

 * *Files 12% similar despite different names*

```diff
@@ -38,15 +38,15 @@
 
 def numpy_rolling_series(func):
     def func_wrapper(data, window, as_source=False):
         series = data.values if isinstance(data, pd.Series) else data
 
         new_series = np.empty(len(series)) * np.nan
         calculated = func(series, window)
-        new_series[-len(calculated):] = calculated
+        new_series[-len(calculated) :] = calculated
 
         if as_source and isinstance(data, pd.Series):
             return pd.Series(index=data.index, data=new_series)
 
         return new_series
 
     return func_wrapper
@@ -61,509 +61,537 @@
 def numpy_rolling_std(data, window, as_source=False):
     return np.std(numpy_rolling_window(data, window), axis=-1, ddof=1)
 
 
 # ---------------------------------------------
 
 
-def session(df, start='17:00', end='16:00'):
-    """ remove previous globex day from df """
+def session(df, start="17:00", end="16:00"):
+    """remove previous globex day from df"""
     if df.empty:
         return df
 
     # get start/end/now as decimals
-    int_start = list(map(int, start.split(':')))
+    int_start = list(map(int, start.split(":")))
     int_start = (int_start[0] + int_start[1] - 1 / 100) - 0.0001
-    int_end = list(map(int, end.split(':')))
+    int_end = list(map(int, end.split(":")))
     int_end = int_end[0] + int_end[1] / 100
-    int_now = (df[-1:].index.hour[0] + (df[:1].index.minute[0]) / 100)
+    int_now = df[-1:].index.hour[0] + (df[:1].index.minute[0]) / 100
 
     # same-dat session?
     is_same_day = int_end > int_start
 
     # set pointers
-    curr = prev = df[-1:].index[0].strftime('%Y-%m-%d')
+    curr = prev = df[-1:].index[0].strftime("%Y-%m-%d")
 
     # globex/forex session
     if not is_same_day:
-        prev = (datetime.strptime(curr, '%Y-%m-%d') -
-                timedelta(1)).strftime('%Y-%m-%d')
+        prev = (datetime.strptime(curr, "%Y-%m-%d") - timedelta(1)).strftime("%Y-%m-%d")
 
     # slice
     if int_now >= int_start:
-        df = df[df.index >= curr + ' ' + start]
+        df = df[df.index >= curr + " " + start]
     else:
-        df = df[df.index >= prev + ' ' + start]
+        df = df[df.index >= prev + " " + start]
 
     return df.copy()
 
+
 # ---------------------------------------------
 
 
 def heikinashi(bars):
     bars = bars.copy()
-    bars['ha_close'] = (bars['open'] + bars['high'] +
-                        bars['low'] + bars['close']) / 4
+    bars["ha_close"] = (bars["open"] + bars["high"] + bars["low"] + bars["close"]) / 4
 
     # ha open
-    bars.at[0, 'ha_open'] = (bars.at[0, 'open'] + bars.at[0, 'close']) / 2
+    bars.at[0, "ha_open"] = (bars.at[0, "open"] + bars.at[0, "close"]) / 2
     for i in range(1, len(bars)):
-        bars.at[i, 'ha_open'] = (bars.at[i - 1, 'ha_open'] + bars.at[i - 1, 'ha_close']) / 2
+        bars.at[i, "ha_open"] = (bars.at[i - 1, "ha_open"] + bars.at[i - 1, "ha_close"]) / 2
 
-    bars['ha_high'] = bars.loc[:, ['high', 'ha_open', 'ha_close']].max(axis=1)
-    bars['ha_low'] = bars.loc[:, ['low', 'ha_open', 'ha_close']].min(axis=1)
+    bars["ha_high"] = bars.loc[:, ["high", "ha_open", "ha_close"]].max(axis=1)
+    bars["ha_low"] = bars.loc[:, ["low", "ha_open", "ha_close"]].min(axis=1)
 
-    return pd.DataFrame(index=bars.index,
-                        data={'open': bars['ha_open'],
-                              'high': bars['ha_high'],
-                              'low': bars['ha_low'],
-                              'close': bars['ha_close']})
+    return pd.DataFrame(
+        index=bars.index,
+        data={
+            "open": bars["ha_open"],
+            "high": bars["ha_high"],
+            "low": bars["ha_low"],
+            "close": bars["ha_close"],
+        },
+    )
 
-# ---------------------------------------------
 
+# ---------------------------------------------
 
-def tdi(series, rsi_lookback=13, rsi_smooth_len=2,
-        rsi_signal_len=7, bb_lookback=34, bb_std=1.6185):
 
+def tdi(series, rsi_lookback=13, rsi_smooth_len=2, rsi_signal_len=7, bb_lookback=34, bb_std=1.6185):
     rsi_data = rsi(series, rsi_lookback)
     rsi_smooth = sma(rsi_data, rsi_smooth_len)
     rsi_signal = sma(rsi_data, rsi_signal_len)
 
     bb_series = bollinger_bands(rsi_data, bb_lookback, bb_std)
 
-    return pd.DataFrame(index=series.index, data={
-        "rsi": rsi_data,
-        "rsi_signal": rsi_signal,
-        "rsi_smooth": rsi_smooth,
-        "rsi_bb_upper": bb_series['upper'],
-        "rsi_bb_lower": bb_series['lower'],
-        "rsi_bb_mid": bb_series['mid']
-    })
+    return pd.DataFrame(
+        index=series.index,
+        data={
+            "rsi": rsi_data,
+            "rsi_signal": rsi_signal,
+            "rsi_smooth": rsi_smooth,
+            "rsi_bb_upper": bb_series["upper"],
+            "rsi_bb_lower": bb_series["lower"],
+            "rsi_bb_mid": bb_series["mid"],
+        },
+    )
+
 
 # ---------------------------------------------
 
 
 def awesome_oscillator(df, weighted=False, fast=5, slow=34):
-    midprice = (df['high'] + df['low']) / 2
+    midprice = (df["high"] + df["low"]) / 2
 
     if weighted:
         ao = (midprice.ewm(fast).mean() - midprice.ewm(slow).mean()).values
     else:
-        ao = numpy_rolling_mean(midprice, fast) - \
-            numpy_rolling_mean(midprice, slow)
+        ao = numpy_rolling_mean(midprice, fast) - numpy_rolling_mean(midprice, slow)
 
     return pd.Series(index=df.index, data=ao)
 
 
 # ---------------------------------------------
 
+
 def nans(length=1):
     mtx = np.empty(length)
     mtx[:] = np.nan
     return mtx
 
 
 # ---------------------------------------------
 
+
 def typical_price(bars):
-    res = (bars['high'] + bars['low'] + bars['close']) / 3.
+    res = (bars["high"] + bars["low"] + bars["close"]) / 3.0
     return pd.Series(index=bars.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def mid_price(bars):
-    res = (bars['high'] + bars['low']) / 2.
+    res = (bars["high"] + bars["low"]) / 2.0
     return pd.Series(index=bars.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def ibs(bars):
-    """ Internal bar strength """
-    res = np.round((bars['close'] - bars['low']) /
-                   (bars['high'] - bars['low']), 2)
+    """Internal bar strength"""
+    res = np.round((bars["close"] - bars["low"]) / (bars["high"] - bars["low"]), 2)
     return pd.Series(index=bars.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def true_range(bars):
-    return pd.DataFrame({
-        "hl": bars['high'] - bars['low'],
-        "hc": abs(bars['high'] - bars['close'].shift(1)),
-        "lc": abs(bars['low'] - bars['close'].shift(1))
-    }).max(axis=1)
+    return pd.DataFrame(
+        {
+            "hl": bars["high"] - bars["low"],
+            "hc": abs(bars["high"] - bars["close"].shift(1)),
+            "lc": abs(bars["low"] - bars["close"].shift(1)),
+        }
+    ).max(axis=1)
 
 
 # ---------------------------------------------
 
+
 def atr(bars, window=14, exp=False):
     tr = true_range(bars)
 
     if exp:
         res = rolling_weighted_mean(tr, window)
     else:
         res = rolling_mean(tr, window)
 
     return pd.Series(res)
 
 
 # ---------------------------------------------
 
+
 def crossed(series1, series2, direction=None):
     if isinstance(series1, np.ndarray):
         series1 = pd.Series(series1)
 
     if isinstance(series2, (float, int, np.ndarray, np.integer, np.floating)):
         series2 = pd.Series(index=series1.index, data=series2)
 
     if direction is None or direction == "above":
-        above = pd.Series((series1 > series2) & (
-            series1.shift(1) <= series2.shift(1)))
+        above = pd.Series((series1 > series2) & (series1.shift(1) <= series2.shift(1)))
 
     if direction is None or direction == "below":
-        below = pd.Series((series1 < series2) & (
-            series1.shift(1) >= series2.shift(1)))
+        below = pd.Series((series1 < series2) & (series1.shift(1) >= series2.shift(1)))
 
     if direction is None:
         return above | below
 
     return above if direction == "above" else below
 
 
 def crossed_above(series1, series2):
     return crossed(series1, series2, "above")
 
 
 def crossed_below(series1, series2):
     return crossed(series1, series2, "below")
 
+
 # ---------------------------------------------
 
 
 def rolling_std(series, window=200, min_periods=None):
     min_periods = window if min_periods is None else min_periods
     if min_periods == window and len(series) > window:
         return numpy_rolling_std(series, window, True)
     else:
         try:
             return series.rolling(window=window, min_periods=min_periods).std()
         except Exception as e:  # noqa: F841
             return pd.Series(series).rolling(window=window, min_periods=min_periods).std()
 
+
 # ---------------------------------------------
 
 
 def rolling_mean(series, window=200, min_periods=None):
     min_periods = window if min_periods is None else min_periods
     if min_periods == window and len(series) > window:
         return numpy_rolling_mean(series, window, True)
     else:
         try:
             return series.rolling(window=window, min_periods=min_periods).mean()
         except Exception as e:  # noqa: F841
             return pd.Series(series).rolling(window=window, min_periods=min_periods).mean()
 
+
 # ---------------------------------------------
 
 
 def rolling_min(series, window=14, min_periods=None):
     min_periods = window if min_periods is None else min_periods
     try:
         return series.rolling(window=window, min_periods=min_periods).min()
     except Exception as e:  # noqa: F841
         return pd.Series(series).rolling(window=window, min_periods=min_periods).min()
 
 
 # ---------------------------------------------
 
+
 def rolling_max(series, window=14, min_periods=None):
     min_periods = window if min_periods is None else min_periods
     try:
         return series.rolling(window=window, min_periods=min_periods).max()
     except Exception as e:  # noqa: F841
         return pd.Series(series).rolling(window=window, min_periods=min_periods).max()
 
 
 # ---------------------------------------------
 
+
 def rolling_weighted_mean(series, window=200, min_periods=None):
     min_periods = window if min_periods is None else min_periods
     try:
         return series.ewm(span=window, min_periods=min_periods).mean()
     except Exception as e:  # noqa: F841
         return pd.ewma(series, span=window, min_periods=min_periods)
 
 
 # ---------------------------------------------
 
+
 def hull_moving_average(series, window=200, min_periods=None):
     min_periods = window if min_periods is None else min_periods
-    ma = (2 * rolling_weighted_mean(series, window / 2, min_periods)) - \
-        rolling_weighted_mean(series, window, min_periods)
+    ma = (2 * rolling_weighted_mean(series, window / 2, min_periods)) - rolling_weighted_mean(
+        series, window, min_periods
+    )
     return rolling_weighted_mean(ma, np.sqrt(window), min_periods)
 
 
 # ---------------------------------------------
 
+
 def sma(series, window=200, min_periods=None):
     return rolling_mean(series, window=window, min_periods=min_periods)
 
 
 # ---------------------------------------------
 
+
 def wma(series, window=200, min_periods=None):
     return rolling_weighted_mean(series, window=window, min_periods=min_periods)
 
 
 # ---------------------------------------------
 
+
 def hma(series, window=200, min_periods=None):
     return hull_moving_average(series, window=window, min_periods=min_periods)
 
 
 # ---------------------------------------------
 
+
 def vwap(bars):
     """
     calculate vwap of entire time series
     (input can be pandas series or numpy array)
     bars are usually mid [ (h+l)/2 ] or typical [ (h+l+c)/3 ]
     """
-    raise ValueError("using `qtpylib.vwap` facilitates lookahead bias. Please use "
-                     "`qtpylib.rolling_vwap` instead, which calculates vwap in a rolling manner.")
+    raise ValueError(
+        "using `qtpylib.vwap` facilitates lookahead bias. Please use "
+        "`qtpylib.rolling_vwap` instead, which calculates vwap in a rolling manner."
+    )
     # typical = ((bars['high'] + bars['low'] + bars['close']) / 3).values
     # volume = bars['volume'].values
 
     # return pd.Series(index=bars.index,
     #                  data=np.cumsum(volume * typical) / np.cumsum(volume))
 
 
 # ---------------------------------------------
 
+
 def rolling_vwap(bars, window=200, min_periods=None):
     """
     calculate vwap using moving window
     (input can be pandas series or numpy array)
     bars are usually mid [ (h+l)/2 ] or typical [ (h+l+c)/3 ]
     """
     min_periods = window if min_periods is None else min_periods
 
-    typical = ((bars['high'] + bars['low'] + bars['close']) / 3)
-    volume = bars['volume']
+    typical = (bars["high"] + bars["low"] + bars["close"]) / 3
+    volume = bars["volume"]
 
-    left = (volume * typical).rolling(window=window,
-                                      min_periods=min_periods).sum()
+    left = (volume * typical).rolling(window=window, min_periods=min_periods).sum()
     right = volume.rolling(window=window, min_periods=min_periods).sum()
 
-    return pd.Series(index=bars.index, data=(left / right)
-                     ).replace([np.inf, -np.inf], float('NaN')).ffill()
+    return (
+        pd.Series(index=bars.index, data=(left / right))
+        .replace([np.inf, -np.inf], float("NaN"))
+        .ffill()
+    )
 
 
 # ---------------------------------------------
 
+
 def rsi(series, window=14):
     """
     compute the n period relative strength indicator
     """
 
     # 100-(100/relative_strength)
     deltas = np.diff(series)
-    seed = deltas[:window + 1]
+    seed = deltas[: window + 1]
 
     # default values
     ups = seed[seed > 0].sum() / window
     downs = -seed[seed < 0].sum() / window
     rsival = np.zeros_like(series)
-    rsival[:window] = 100. - 100. / (1. + ups / downs)
+    rsival[:window] = 100.0 - 100.0 / (1.0 + ups / downs)
 
     # period values
     for i in range(window, len(series)):
         delta = deltas[i - 1]
         if delta > 0:
             upval = delta
             downval = 0
         else:
             upval = 0
             downval = -delta
 
         ups = (ups * (window - 1) + upval) / window
-        downs = (downs * (window - 1.) + downval) / window
-        rsival[i] = 100. - 100. / (1. + ups / downs)
+        downs = (downs * (window - 1.0) + downval) / window
+        rsival[i] = 100.0 - 100.0 / (1.0 + ups / downs)
 
     # return rsival
     return pd.Series(index=series.index, data=rsival)
 
 
 # ---------------------------------------------
 
+
 def macd(series, fast=3, slow=10, smooth=16):
     """
     compute the MACD (Moving Average Convergence/Divergence)
     using a fast and slow exponential moving avg'
     return value is emaslow, emafast, macd which are len(x) arrays
     """
-    macd_line = rolling_weighted_mean(series, window=fast) - \
-        rolling_weighted_mean(series, window=slow)
+    macd_line = rolling_weighted_mean(series, window=fast) - rolling_weighted_mean(
+        series, window=slow
+    )
     signal = rolling_weighted_mean(macd_line, window=smooth)
     histogram = macd_line - signal
     # return macd_line, signal, histogram
-    return pd.DataFrame(index=series.index, data={
-        'macd': macd_line.values,
-        'signal': signal.values,
-        'histogram': histogram.values
-    })
+    return pd.DataFrame(
+        index=series.index,
+        data={"macd": macd_line.values, "signal": signal.values, "histogram": histogram.values},
+    )
 
 
 # ---------------------------------------------
 
+
 def bollinger_bands(series, window=20, stds=2):
     ma = rolling_mean(series, window=window, min_periods=1)
     std = rolling_std(series, window=window, min_periods=1)
     upper = ma + std * stds
     lower = ma - std * stds
 
-    return pd.DataFrame(index=series.index, data={
-        'upper': upper,
-        'mid': ma,
-        'lower': lower
-    })
+    return pd.DataFrame(index=series.index, data={"upper": upper, "mid": ma, "lower": lower})
 
 
 # ---------------------------------------------
 
+
 def weighted_bollinger_bands(series, window=20, stds=2):
     ema = rolling_weighted_mean(series, window=window)
     std = rolling_std(series, window=window)
     upper = ema + std * stds
     lower = ema - std * stds
 
-    return pd.DataFrame(index=series.index, data={
-        'upper': upper.values,
-        'mid': ema.values,
-        'lower': lower.values
-    })
+    return pd.DataFrame(
+        index=series.index, data={"upper": upper.values, "mid": ema.values, "lower": lower.values}
+    )
 
 
 # ---------------------------------------------
 
+
 def returns(series):
     try:
-        res = (series / series.shift(1) -
-               1).replace([np.inf, -np.inf], float('NaN'))
+        res = (series / series.shift(1) - 1).replace([np.inf, -np.inf], float("NaN"))
     except Exception as e:  # noqa: F841
         res = nans(len(series))
 
     return pd.Series(index=series.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def log_returns(series):
     try:
-        res = np.log(series / series.shift(1)
-                     ).replace([np.inf, -np.inf], float('NaN'))
+        res = np.log(series / series.shift(1)).replace([np.inf, -np.inf], float("NaN"))
     except Exception as e:  # noqa: F841
         res = nans(len(series))
 
     return pd.Series(index=series.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def implied_volatility(series, window=252):
     try:
-        logret = np.log(series / series.shift(1)
-                        ).replace([np.inf, -np.inf], float('NaN'))
+        logret = np.log(series / series.shift(1)).replace([np.inf, -np.inf], float("NaN"))
         res = numpy_rolling_std(logret, window) * np.sqrt(window)
     except Exception as e:  # noqa: F841
         res = nans(len(series))
 
     return pd.Series(index=series.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def keltner_channel(bars, window=14, atrs=2):
     typical_mean = rolling_mean(typical_price(bars), window)
     atrval = atr(bars, window) * atrs
 
     upper = typical_mean + atrval
     lower = typical_mean - atrval
 
-    return pd.DataFrame(index=bars.index, data={
-        'upper': upper.values,
-        'mid': typical_mean.values,
-        'lower': lower.values
-    })
+    return pd.DataFrame(
+        index=bars.index,
+        data={"upper": upper.values, "mid": typical_mean.values, "lower": lower.values},
+    )
 
 
 # ---------------------------------------------
 
+
 def roc(series, window=14):
     """
     compute rate of change
     """
     res = (series - series.shift(window)) / series.shift(window)
     return pd.Series(index=series.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def cci(series, window=14):
     """
     compute commodity channel index
     """
     price = typical_price(series)
     typical_mean = rolling_mean(price, window)
-    res = (price - typical_mean) / (.015 * np.std(typical_mean))
+    res = (price - typical_mean) / (0.015 * np.std(typical_mean))
     return pd.Series(index=series.index, data=res)
 
 
 # ---------------------------------------------
 
+
 def stoch(df, window=14, d=3, k=3, fast=False):
     """
     compute the n period relative strength indicator
     http://excelta.blogspot.co.il/2013/09/stochastic-oscillator-technical.html
     """
 
     my_df = pd.DataFrame(index=df.index)
 
-    my_df['rolling_max'] = df['high'].rolling(window).max()
-    my_df['rolling_min'] = df['low'].rolling(window).min()
+    my_df["rolling_max"] = df["high"].rolling(window).max()
+    my_df["rolling_min"] = df["low"].rolling(window).min()
 
-    my_df['fast_k'] = (
-        100 * (df['close'] - my_df['rolling_min']) /
-        (my_df['rolling_max'] - my_df['rolling_min'])
+    my_df["fast_k"] = (
+        100 * (df["close"] - my_df["rolling_min"]) / (my_df["rolling_max"] - my_df["rolling_min"])
     )
-    my_df['fast_d'] = my_df['fast_k'].rolling(d).mean()
+    my_df["fast_d"] = my_df["fast_k"].rolling(d).mean()
 
     if fast:
-        return my_df.loc[:, ['fast_k', 'fast_d']]
+        return my_df.loc[:, ["fast_k", "fast_d"]]
+
+    my_df["slow_k"] = my_df["fast_k"].rolling(k).mean()
+    my_df["slow_d"] = my_df["slow_k"].rolling(d).mean()
 
-    my_df['slow_k'] = my_df['fast_k'].rolling(k).mean()
-    my_df['slow_d'] = my_df['slow_k'].rolling(d).mean()
+    return my_df.loc[:, ["slow_k", "slow_d"]]
 
-    return my_df.loc[:, ['slow_k', 'slow_d']]
 
 # ---------------------------------------------
 
 
 def zlma(series, window=20, min_periods=None, kind="ema"):
     """
     John Ehlers' Zero lag (exponential) moving average
     https://en.wikipedia.org/wiki/Zero_lag_exponential_moving_average
     """
     min_periods = window if min_periods is None else min_periods
 
     lag = (window - 1) // 2
     series = 2 * series - series.shift(lag)
-    if kind in ['ewm', 'ema']:
+    if kind in ["ewm", "ema"]:
         return wma(series, lag, min_periods)
     elif kind == "hma":
         return hma(series, lag, min_periods)
     return sma(series, lag, min_periods)
 
 
 def zlema(series, window, min_periods=None):
@@ -573,37 +601,38 @@
 def zlsma(series, window, min_periods=None):
     return zlma(series, window, min_periods, kind="sma")
 
 
 def zlhma(series, window, min_periods=None):
     return zlma(series, window, min_periods, kind="hma")
 
+
 # ---------------------------------------------
 
 
-def zscore(bars, window=20, stds=1, col='close'):
-    """ get zscore of price """
+def zscore(bars, window=20, stds=1, col="close"):
+    """get zscore of price"""
     std = numpy_rolling_std(bars[col], window)
     mean = numpy_rolling_mean(bars[col], window)
     return (bars[col] - mean) / (std * stds)
 
+
 # ---------------------------------------------
 
 
 def pvt(bars):
-    """ Price Volume Trend """
-    trend = ((bars['close'] - bars['close'].shift(1)) /
-             bars['close'].shift(1)) * bars['volume']
+    """Price Volume Trend"""
+    trend = ((bars["close"] - bars["close"].shift(1)) / bars["close"].shift(1)) * bars["volume"]
     return trend.cumsum()
 
 
 def chopiness(bars, window=14):
     atrsum = true_range(bars).rolling(window).sum()
-    highs = bars['high'].rolling(window).max()
-    lows = bars['low'].rolling(window).min()
+    highs = bars["high"].rolling(window).max()
+    lows = bars["low"].rolling(window).min()
     return 100 * np.log10(atrsum / (highs - lows)) / np.log10(window)
 
 
 # =============================================
 
 
 PandasObject.session = session
```

### Comparing `freqtrade-2024.4/freqtrade/wallets.py` & `freqtrade-2024.5/freqtrade/wallets.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # pragma pylint: disable=W0603
-""" Wallet """
+"""Wallet"""
 
 import logging
 from copy import deepcopy
 from datetime import datetime, timedelta
 from typing import Dict, NamedTuple, Optional
 
 from freqtrade.constants import UNLIMITED_STAKE_AMOUNT, Config, IntOrInf
@@ -27,26 +27,25 @@
 
 
 class PositionWallet(NamedTuple):
     symbol: str
     position: float = 0
     leverage: float = 0
     collateral: float = 0
-    side: str = 'long'
+    side: str = "long"
 
 
 class Wallets:
-
     def __init__(self, config: Config, exchange: Exchange, is_backtest: bool = False) -> None:
         self._config = config
         self._is_backtest = is_backtest
         self._exchange = exchange
         self._wallets: Dict[str, Wallet] = {}
         self._positions: Dict[str, PositionWallet] = {}
-        self.start_cap = config['dry_run_wallet']
+        self.start_cap = config["dry_run_wallet"]
         self._last_wallet_refresh: Optional[datetime] = None
         self.update()
 
     def get_free(self, currency: str) -> float:
         balance = self._wallets.get(currency)
         if balance and balance.free:
             return balance.free
@@ -84,83 +83,80 @@
         else:
             # Backtest mode
             tot_profit = LocalTrade.total_profit
         tot_profit += sum(trade.realized_profit for trade in open_trades)
         tot_in_trades = sum(trade.stake_amount for trade in open_trades)
         used_stake = 0.0
 
-        if self._config.get('trading_mode', 'spot') != TradingMode.FUTURES:
+        if self._config.get("trading_mode", "spot") != TradingMode.FUTURES:
             current_stake = self.start_cap + tot_profit - tot_in_trades
             total_stake = current_stake
             for trade in open_trades:
                 curr = self._exchange.get_pair_base_currency(trade.pair)
-                _wallets[curr] = Wallet(
-                    curr,
-                    trade.amount,
-                    0,
-                    trade.amount
-                )
+                _wallets[curr] = Wallet(curr, trade.amount, 0, trade.amount)
         else:
             tot_in_trades = 0
             for position in open_trades:
                 # size = self._exchange._contracts_to_amount(position.pair, position['contracts'])
                 size = position.amount
                 collateral = position.stake_amount
                 leverage = position.leverage
                 tot_in_trades += collateral
                 _positions[position.pair] = PositionWallet(
-                    position.pair, position=size,
+                    position.pair,
+                    position=size,
                     leverage=leverage,
                     collateral=collateral,
-                    side=position.trade_direction
+                    side=position.trade_direction,
                 )
             current_stake = self.start_cap + tot_profit - tot_in_trades
             used_stake = tot_in_trades
             total_stake = current_stake + tot_in_trades
 
-        _wallets[self._config['stake_currency']] = Wallet(
-            currency=self._config['stake_currency'],
+        _wallets[self._config["stake_currency"]] = Wallet(
+            currency=self._config["stake_currency"],
             free=current_stake,
             used=used_stake,
-            total=total_stake
+            total=total_stake,
         )
         self._wallets = _wallets
         self._positions = _positions
 
     def _update_live(self) -> None:
         balances = self._exchange.get_balances()
 
         for currency in balances:
             if isinstance(balances[currency], dict):
                 self._wallets[currency] = Wallet(
                     currency,
-                    balances[currency].get('free'),
-                    balances[currency].get('used'),
-                    balances[currency].get('total')
+                    balances[currency].get("free"),
+                    balances[currency].get("used"),
+                    balances[currency].get("total"),
                 )
         # Remove currencies no longer in get_balances output
         for currency in deepcopy(self._wallets):
             if currency not in balances:
                 del self._wallets[currency]
 
         positions = self._exchange.fetch_positions()
         self._positions = {}
         for position in positions:
-            symbol = position['symbol']
-            if position['side'] is None or position['collateral'] == 0.0:
+            symbol = position["symbol"]
+            if position["side"] is None or position["collateral"] == 0.0:
                 # Position is not open ...
                 continue
-            size = self._exchange._contracts_to_amount(symbol, position['contracts'])
-            collateral = safe_value_fallback(position, 'collateral', 'initialMargin', 0.0)
-            leverage = position['leverage']
+            size = self._exchange._contracts_to_amount(symbol, position["contracts"])
+            collateral = safe_value_fallback(position, "collateral", "initialMargin", 0.0)
+            leverage = position["leverage"]
             self._positions[symbol] = PositionWallet(
-                symbol, position=size,
+                symbol,
+                position=size,
                 leverage=leverage,
                 collateral=collateral,
-                side=position['side']
+                side=position["side"],
             )
 
     def update(self, require_update: bool = True) -> None:
         """
         Updates wallets from the configured version.
         By default, updates from the exchange.
         Update-skipping should only be used for user-invoked /balance calls, since
@@ -169,20 +165,20 @@
         """
         now = dt_now()
         if (
             require_update
             or self._last_wallet_refresh is None
             or (self._last_wallet_refresh + timedelta(seconds=3600) < now)
         ):
-            if (not self._config['dry_run'] or self._config.get('runmode') == RunMode.LIVE):
+            if not self._config["dry_run"] or self._config.get("runmode") == RunMode.LIVE:
                 self._update_live()
             else:
                 self._update_dry()
             if not self._is_backtest:
-                logger.info('Wallets synced.')
+                logger.info("Wallets synced.")
             self._last_wallet_refresh = dt_now()
 
     def get_all_balances(self) -> Dict[str, Wallet]:
         return self._wallets
 
     def get_all_positions(self) -> Dict[str, PositionWallet]:
         return self._positions
@@ -218,55 +214,57 @@
 
     def get_starting_balance(self) -> float:
         """
         Retrieves starting balance - based on either available capital,
         or by using current balance subtracting
         """
         if "available_capital" in self._config:
-            return self._config['available_capital']
+            return self._config["available_capital"]
         else:
             tot_profit = Trade.get_total_closed_profit()
             open_stakes = Trade.total_open_trades_stakes()
-            available_balance = self.get_free(self._config['stake_currency'])
+            available_balance = self.get_free(self._config["stake_currency"])
             return available_balance - tot_profit + open_stakes
 
     def get_total_stake_amount(self):
         """
         Return the total currently available balance in stake currency, including tied up stake and
         respecting tradable_balance_ratio.
         Calculated as
         (<open_trade stakes> + free amount) * tradable_balance_ratio
         """
         val_tied_up = Trade.total_open_trades_stakes()
         if "available_capital" in self._config:
-            starting_balance = self._config['available_capital']
+            starting_balance = self._config["available_capital"]
             tot_profit = Trade.get_total_closed_profit()
             available_amount = starting_balance + tot_profit
 
         else:
             # Ensure <tradable_balance_ratio>% is used from the overall balance
             # Otherwise we'd risk lowering stakes with each open trade.
             # (tied up + current free) * ratio) - tied up
-            available_amount = ((val_tied_up + self.get_free(self._config['stake_currency'])) *
-                                self._config['tradable_balance_ratio'])
+            available_amount = (
+                val_tied_up + self.get_free(self._config["stake_currency"])
+            ) * self._config["tradable_balance_ratio"]
         return available_amount
 
     def get_available_stake_amount(self) -> float:
         """
         Return the total currently available balance in stake currency,
         respecting tradable_balance_ratio.
         Calculated as
         (<open_trade stakes> + free amount) * tradable_balance_ratio - <open_trade stakes>
         """
 
-        free = self.get_free(self._config['stake_currency'])
+        free = self.get_free(self._config["stake_currency"])
         return min(self.get_total_stake_amount() - Trade.total_open_trades_stakes(), free)
 
-    def _calculate_unlimited_stake_amount(self, available_amount: float,
-                                          val_tied_up: float, max_open_trades: IntOrInf) -> float:
+    def _calculate_unlimited_stake_amount(
+        self, available_amount: float, val_tied_up: float, max_open_trades: IntOrInf
+    ) -> float:
         """
         Calculate stake amount for "unlimited" stake amount
         :return: 0 if max number of trades reached, else stake_amount to use.
         """
         if max_open_trades == 0:
             return 0
 
@@ -278,32 +276,33 @@
         """
         Check if stake amount can be fulfilled with the available balance
         for the stake currency
         :return: float: Stake amount
         :raise: DependencyException if balance is lower than stake-amount
         """
 
-        if self._config['amend_last_stake_amount']:
+        if self._config["amend_last_stake_amount"]:
             # Remaining amount needs to be at least stake_amount * last_stake_amount_min_ratio
             # Otherwise the remaining amount is too low to trade.
-            if available_amount > (stake_amount * self._config['last_stake_amount_min_ratio']):
+            if available_amount > (stake_amount * self._config["last_stake_amount_min_ratio"]):
                 stake_amount = min(stake_amount, available_amount)
             else:
                 stake_amount = 0
 
         if available_amount < stake_amount:
             raise DependencyException(
                 f"Available balance ({available_amount} {self._config['stake_currency']}) is "
                 f"lower than stake amount ({stake_amount} {self._config['stake_currency']})"
             )
 
         return stake_amount
 
     def get_trade_stake_amount(
-            self, pair: str, max_open_trades: IntOrInf, edge=None, update: bool = True) -> float:
+        self, pair: str, max_open_trades: IntOrInf, edge=None, update: bool = True
+    ) -> float:
         """
         Calculate stake amount for the trade
         :return: float: Stake amount
         :raise: DependencyException if the available stake amount is too low
         """
         stake_amount: float
         # Ensure wallets are up-to-date.
@@ -311,43 +310,51 @@
             self.update()
         val_tied_up = Trade.total_open_trades_stakes()
         available_amount = self.get_available_stake_amount()
 
         if edge:
             stake_amount = edge.stake_amount(
                 pair,
-                self.get_free(self._config['stake_currency']),
-                self.get_total(self._config['stake_currency']),
-                val_tied_up
+                self.get_free(self._config["stake_currency"]),
+                self.get_total(self._config["stake_currency"]),
+                val_tied_up,
             )
         else:
-            stake_amount = self._config['stake_amount']
+            stake_amount = self._config["stake_amount"]
             if stake_amount == UNLIMITED_STAKE_AMOUNT:
                 stake_amount = self._calculate_unlimited_stake_amount(
-                    available_amount, val_tied_up, max_open_trades)
+                    available_amount, val_tied_up, max_open_trades
+                )
 
         return self._check_available_stake_amount(stake_amount, available_amount)
 
-    def validate_stake_amount(self, pair: str, stake_amount: Optional[float],
-                              min_stake_amount: Optional[float], max_stake_amount: float,
-                              trade_amount: Optional[float]):
+    def validate_stake_amount(
+        self,
+        pair: str,
+        stake_amount: Optional[float],
+        min_stake_amount: Optional[float],
+        max_stake_amount: float,
+        trade_amount: Optional[float],
+    ):
         if not stake_amount:
             logger.debug(f"Stake amount is {stake_amount}, ignoring possible trade for {pair}.")
             return 0
 
         max_allowed_stake = min(max_stake_amount, self.get_available_stake_amount())
         if trade_amount:
             # if in a trade, then the resulting trade size cannot go beyond the max stake
             # Otherwise we could no longer exit.
             max_allowed_stake = min(max_allowed_stake, max_stake_amount - trade_amount)
 
         if min_stake_amount is not None and min_stake_amount > max_allowed_stake:
             if not self._is_backtest:
-                logger.warning("Minimum stake amount > available balance. "
-                               f"{min_stake_amount} > {max_allowed_stake}")
+                logger.warning(
+                    "Minimum stake amount > available balance. "
+                    f"{min_stake_amount} > {max_allowed_stake}"
+                )
             return 0
         if min_stake_amount is not None and stake_amount < min_stake_amount:
             if not self._is_backtest:
                 logger.info(
                     f"Stake amount for pair {pair} is too small "
                     f"({stake_amount} < {min_stake_amount}), adjusting to {min_stake_amount}."
                 )
```

### Comparing `freqtrade-2024.4/freqtrade/worker.py` & `freqtrade-2024.5/freqtrade/worker.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 """
 Main Freqtrade worker class.
 """
+
 import logging
 import time
 import traceback
 from os import getpid
 from typing import Any, Callable, Dict, Optional
 
 import sdnotify
@@ -48,21 +49,23 @@
         if reconfig or self._config is None:
             # Load configuration
             self._config = Configuration(self._args, None).get_config()
 
         # Init the instance of the bot
         self.freqtrade = FreqtradeBot(self._config)
 
-        internals_config = self._config.get('internals', {})
-        self._throttle_secs = internals_config.get('process_throttle_secs',
-                                                   PROCESS_THROTTLE_SECS)
-        self._heartbeat_interval = internals_config.get('heartbeat_interval', 60)
-
-        self._sd_notify = sdnotify.SystemdNotifier() if \
-            self._config.get('internals', {}).get('sd_notify', False) else None
+        internals_config = self._config.get("internals", {})
+        self._throttle_secs = internals_config.get("process_throttle_secs", PROCESS_THROTTLE_SECS)
+        self._heartbeat_interval = internals_config.get("heartbeat_interval", 60)
+
+        self._sd_notify = (
+            sdnotify.SystemdNotifier()
+            if self._config.get("internals", {}).get("sd_notify", False)
+            else None
+        )
 
     def _notify(self, message: str) -> None:
         """
         Removes the need to verify in all occurrences if sd_notify is enabled
         :param message: Message to send to systemd if it's enabled.
         """
         if self._sd_notify:
@@ -82,20 +85,20 @@
         :param old_state: the previous service state from the previous call
         :return: current service state
         """
         state = self.freqtrade.state
 
         # Log state transition
         if state != old_state:
-
             if old_state != State.RELOAD_CONFIG:
-                self.freqtrade.notify_status(f'{state.name.lower()}')
+                self.freqtrade.notify_status(f"{state.name.lower()}")
 
             logger.info(
-                f"Changing state{f' from {old_state.name}' if old_state else ''} to: {state.name}")
+                f"Changing state{f' from {old_state.name}' if old_state else ''} to: {state.name}"
+            )
             if state == State.RUNNING:
                 self.freqtrade.startup()
 
             if state == State.STOPPED:
                 self.freqtrade.check_for_open_trades()
 
             # Reset heartbeat timestamp to log the heartbeat message at
@@ -109,34 +112,44 @@
             self._throttle(func=self._process_stopped, throttle_secs=self._throttle_secs)
 
         elif state == State.RUNNING:
             # Ping systemd watchdog before throttling
             self._notify("WATCHDOG=1\nSTATUS=State: RUNNING.")
 
             # Use an offset of 1s to ensure a new candle has been issued
-            self._throttle(func=self._process_running, throttle_secs=self._throttle_secs,
-                           timeframe=self._config['timeframe'] if self._config else None,
-                           timeframe_offset=1)
+            self._throttle(
+                func=self._process_running,
+                throttle_secs=self._throttle_secs,
+                timeframe=self._config["timeframe"] if self._config else None,
+                timeframe_offset=1,
+            )
 
         if self._heartbeat_interval:
             now = time.time()
             if (now - self._heartbeat_msg) > self._heartbeat_interval:
                 version = __version__
                 strategy_version = self.freqtrade.strategy.version()
-                if (strategy_version is not None):
-                    version += ', strategy_version: ' + strategy_version
-                logger.info(f"Bot heartbeat. PID={getpid()}, "
-                            f"version='{version}', state='{state.name}'")
+                if strategy_version is not None:
+                    version += ", strategy_version: " + strategy_version
+                logger.info(
+                    f"Bot heartbeat. PID={getpid()}, version='{version}', state='{state.name}'"
+                )
                 self._heartbeat_msg = now
 
         return state
 
-    def _throttle(self, func: Callable[..., Any], throttle_secs: float,
-                  timeframe: Optional[str] = None, timeframe_offset: float = 1.0,
-                  *args, **kwargs) -> Any:
+    def _throttle(
+        self,
+        func: Callable[..., Any],
+        throttle_secs: float,
+        timeframe: Optional[str] = None,
+        timeframe_offset: float = 1.0,
+        *args,
+        **kwargs,
+    ) -> Any:
         """
         Throttles the given callable that it
         takes at least `min_secs` to finish execution.
         :param func: Any callable
         :param throttle_secs: throttling iteration execution time limit in seconds
         :param timeframe: ensure iteration is executed at the beginning of the next candle.
         :param timeframe_offset: offset in seconds to apply to the next candle time.
@@ -156,18 +169,19 @@
             if next_tft < sleep_duration and sleep_duration < next_tf_with_offset:
                 # Avoid hitting a new loop between the new candle and the candle with offset
                 sleep_duration = next_tf_with_offset
             sleep_duration = min(sleep_duration, next_tf_with_offset)
         sleep_duration = max(sleep_duration, 0.0)
         # next_iter = datetime.now(timezone.utc) + timedelta(seconds=sleep_duration)
 
-        logger.debug(f"Throttling with '{func.__name__}()': sleep for {sleep_duration:.2f} s, "
-                     f"last iteration took {time_passed:.2f} s."
-                     #  f"next: {next_iter}"
-                     )
+        logger.debug(
+            f"Throttling with '{func.__name__}()': sleep for {sleep_duration:.2f} s, "
+            f"last iteration took {time_passed:.2f} s."
+            #  f"next: {next_iter}"
+        )
         self._sleep(sleep_duration)
         return result
 
     @staticmethod
     def _sleep(sleep_duration: float) -> None:
         """Local sleep method - to improve testability"""
         time.sleep(sleep_duration)
@@ -179,22 +193,21 @@
         try:
             self.freqtrade.process()
         except TemporaryError as error:
             logger.warning(f"Error: {error}, retrying in {RETRY_TIMEOUT} seconds...")
             time.sleep(RETRY_TIMEOUT)
         except OperationalException:
             tb = traceback.format_exc()
-            hint = 'Issue `/start` if you think it is safe to restart.'
+            hint = "Issue `/start` if you think it is safe to restart."
 
             self.freqtrade.notify_status(
-                f'*OperationalException:*\n```\n{tb}```\n {hint}',
-                msg_type=RPCMessageType.EXCEPTION
+                f"*OperationalException:*\n```\n{tb}```\n {hint}", msg_type=RPCMessageType.EXCEPTION
             )
 
-            logger.exception('OperationalException. Stopping trader ...')
+            logger.exception("OperationalException. Stopping trader ...")
             self.freqtrade.state = State.STOPPED
 
     def _reconfigure(self) -> None:
         """
         Cleans up current freqtradebot instance, reloads the configuration and
         replaces it with the new instance
         """
@@ -203,19 +216,19 @@
 
         # Clean up current freqtrade modules
         self.freqtrade.cleanup()
 
         # Load and validate config and create new instance of the bot
         self._init(True)
 
-        self.freqtrade.notify_status('config reloaded')
+        self.freqtrade.notify_status("config reloaded")
 
         # Tell systemd that we completed reconfiguration
         self._notify("READY=1")
 
     def exit(self) -> None:
         # Tell systemd that we are exiting now
         self._notify("STOPPING=1")
 
         if self.freqtrade:
-            self.freqtrade.notify_status('process died')
+            self.freqtrade.notify_status("process died")
             self.freqtrade.cleanup()
```

### Comparing `freqtrade-2024.4/freqtrade.egg-info/PKG-INFO` & `freqtrade-2024.5/freqtrade.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: freqtrade
-Version: 2024.4
+Version: 2024.5
 Summary: Freqtrade - Crypto Trading Bot
 Home-page: https://github.com/freqtrade/freqtrade
 Author: Freqtrade Team
 Author-email: Freqtrade Team <freqtrade@protonmail.com>
 License: GPLv3
 Project-URL: Homepage, https://github.com/freqtrade/freqtrade
 Project-URL: Documentation, https://freqtrade.io
@@ -18,15 +18,15 @@
 Classifier: Programming Language :: Python :: 3.12
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: Unix
 Classifier: Topic :: Office/Business :: Financial :: Investment
 Requires-Python: >=3.9
 Description-Content-Type: text/markdown
 License-File: LICENSE
-Requires-Dist: ccxt>=4.2.47
+Requires-Dist: ccxt>=4.3.24
 Requires-Dist: SQLAlchemy>=2.0.6
 Requires-Dist: python-telegram-bot>=20.1
 Requires-Dist: humanize>=4.0.0
 Requires-Dist: cachetools
 Requires-Dist: requests
 Requires-Dist: httpx>=0.24.1
 Requires-Dist: urllib3
@@ -200,14 +200,15 @@
 
 ## Supported Exchange marketplaces
 
 Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.
 
 - [X] [Binance](https://www.binance.com/)
 - [X] [Bitmart](https://bitmart.com/)
+- [X] [BingX](https://bingx.com/invite/0EM9RX)
 - [X] [Gate.io](https://www.gate.io/ref/6266643)
 - [X] [HTX](https://www.htx.com/) (Former Huobi)
 - [X] [Kraken](https://kraken.com/)
 - [X] [OKX](https://okx.com/) (Former OKEX)
 - [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_
 
 ### Supported Futures Exchanges (experimental)
```

### Comparing `freqtrade-2024.4/freqtrade.egg-info/SOURCES.txt` & `freqtrade-2024.5/freqtrade.egg-info/SOURCES.txt`

 * *Files 0% similar despite different names*

```diff
@@ -304,14 +304,15 @@
 freqtrade/templates/subtemplates/exchange_kraken.j2
 freqtrade/templates/subtemplates/exchange_kucoin.j2
 freqtrade/templates/subtemplates/exchange_okex.j2
 freqtrade/types/__init__.py
 freqtrade/types/backtest_result_type.py
 freqtrade/types/valid_exchanges_type.py
 freqtrade/util/__init__.py
+freqtrade/util/coin_gecko.py
 freqtrade/util/datetime_helpers.py
 freqtrade/util/formatters.py
 freqtrade/util/ft_precise.py
 freqtrade/util/gc_setup.py
 freqtrade/util/measure_time.py
 freqtrade/util/periodic_cache.py
 freqtrade/util/template_renderer.py
```

### Comparing `freqtrade-2024.4/freqtrade.egg-info/requires.txt` & `freqtrade-2024.5/freqtrade.egg-info/requires.txt`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-ccxt>=4.2.47
+ccxt>=4.3.24
 SQLAlchemy>=2.0.6
 python-telegram-bot>=20.1
 humanize>=4.0.0
 cachetools
 requests
 httpx>=0.24.1
 urllib3
```

### Comparing `freqtrade-2024.4/pyproject.toml` & `freqtrade-2024.5/pyproject.toml`

 * *Files 4% similar despite different names*

```diff
@@ -71,17 +71,19 @@
   # Exclude vendor directory
   | vendor
 )
 '''
 
 [tool.isort]
 line_length = 100
-multi_line_output=0
+profile = "black"
+# multi_line_output=3
 lines_after_imports=2
 skip_glob = ["**/.env*", "**/env/*", "**/.venv/*", "**/docs/*", "**/user_data/*"]
+known_first_party = ["freqtrade_client"]
 
 [tool.pytest.ini_options]
 asyncio_mode = "auto"
 addopts = "--dist loadscope"
 
 [tool.mypy]
 ignore_missing_imports = true
@@ -124,23 +126,25 @@
   "C90",    # mccabe
   # "B",    # bugbear
   # "N",    # pep8-naming
   "F",      # pyflakes
   "E",      # pycodestyle
   "W",      # pycodestyle
   "UP",     # pyupgrade
+  "I",      # isort
   "TID",    # flake8-tidy-imports
   # "EXE",  # flake8-executable
   # "C4",     # flake8-comprehensions
   "YTT",    # flake8-2020
   # "S",    # flake8-bandit
   # "DTZ",  # flake8-datetimez
   # "RSE",  # flake8-raise
   # "TCH",  # flake8-type-checking
   "PTH",    # flake8-use-pathlib
+  # "RUF",    # ruff
 ]
 
 extend-ignore = [
   "E241",  # Multiple spaces after comma
   "E272",  # Multiple spaces before keyword
   "E221",  # Multiple spaces before operator
   "B007",  # Loop control variable not used
@@ -152,25 +156,29 @@
 [tool.ruff.lint.per-file-ignores]
 "tests/*" = ["S"]
 
 [tool.ruff.lint.flake8-bugbear]
 # Allow default arguments like, e.g., `data: List[str] = fastapi.Query(None)`.
 extend-immutable-calls = ["fastapi.Depends", "fastapi.Query"]
 
+[tool.ruff.lint.isort]
+lines-after-imports = 2
+known-first-party = ["freqtrade_client"]
+
 [tool.flake8]
 # Default from https://flake8.pycqa.org/en/latest/user/options.html#cmdoption-flake8-ignore
 # minus E226
-ignore = ["E121","E123","E126","E24","E704","W503","W504"]
+ignore = ["E121","E123","E126","E24", "E203","E704","W503","W504"]
 max-line-length = 100
 max-complexity = 12
 exclude = [
     ".git",
     "__pycache__",
     ".eggs",
     "user_data",
     ".venv",
     ".env",
 ]
 
 [tool.codespell]
 ignore-words-list = "coo,fo,strat,zar,selectin"
-skip="*.svg,./user_data,./freqtrade/rpc/api_server/ui/installed"
+skip="*.svg,./user_data,freqtrade/rpc/api_server/ui/installed,freqtrade/exchange/*.json"
```

