# Comparing `tmp/mpyl-1.6.6-py3-none-any.whl.zip` & `tmp/mpyl-1.6.7-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,121 +1,121 @@
-Zip file size: 261879 bytes, number of entries: 119
--rw-r--r--  2.0 unx     1200 b- defN 24-May-01 12:32 mpyl/__init__.py
--rw-r--r--  2.0 unx      215 b- defN 24-May-01 12:32 mpyl/__main__.py
--rw-r--r--  2.0 unx     7630 b- defN 24-May-01 12:32 mpyl/build.py
--rw-r--r--  2.0 unx      304 b- defN 24-May-01 12:32 mpyl/constants.py
--rw-r--r--  2.0 unx    21281 b- defN 24-May-01 12:32 mpyl/project.py
--rw-r--r--  2.0 unx      997 b- defN 24-May-01 12:32 mpyl/project_execution.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-01 12:32 mpyl/py.typed
--rw-r--r--  2.0 unx     1038 b- defN 24-May-01 12:32 mpyl/run_plan.py
--rw-r--r--  2.0 unx     2370 b- defN 24-May-01 12:32 mpyl/validation.py
--rw-r--r--  2.0 unx       60 b- defN 24-May-01 12:32 mpyl/artifacts/__init__.py
--rw-r--r--  2.0 unx     9222 b- defN 24-May-01 12:32 mpyl/artifacts/build_artifacts.py
--rw-r--r--  2.0 unx     3512 b- defN 24-May-01 12:32 mpyl/cli/__init__.py
--rw-r--r--  2.0 unx    17847 b- defN 24-May-01 12:32 mpyl/cli/build.py
--rw-r--r--  2.0 unx      614 b- defN 24-May-01 12:32 mpyl/cli/health.py
--rw-r--r--  2.0 unx     2417 b- defN 24-May-01 12:32 mpyl/cli/meta_info.py
--rw-r--r--  2.0 unx     8536 b- defN 24-May-01 12:32 mpyl/cli/projects.py
--rw-r--r--  2.0 unx       34 b- defN 24-May-01 12:32 mpyl/cli/commands/__init__.py
--rw-r--r--  2.0 unx      425 b- defN 24-May-01 12:32 mpyl/cli/commands/build/__init__.py
--rw-r--r--  2.0 unx     1261 b- defN 24-May-01 12:32 mpyl/cli/commands/build/artifacts.py
--rw-r--r--  2.0 unx     4524 b- defN 24-May-01 12:32 mpyl/cli/commands/build/jenkins.py
--rw-r--r--  2.0 unx       38 b- defN 24-May-01 12:32 mpyl/cli/commands/health/__init__.py
--rw-r--r--  2.0 unx     8248 b- defN 24-May-01 12:32 mpyl/cli/commands/health/checks.py
--rw-r--r--  2.0 unx       52 b- defN 24-May-01 12:32 mpyl/cli/commands/projects/__init__.py
--rw-r--r--  2.0 unx     1771 b- defN 24-May-01 12:32 mpyl/cli/commands/projects/formatting.py
--rw-r--r--  2.0 unx     6356 b- defN 24-May-01 12:32 mpyl/cli/commands/projects/lint.py
--rw-r--r--  2.0 unx      659 b- defN 24-May-01 12:32 mpyl/cli/commands/projects/upgrade.py
--rw-r--r--  2.0 unx      620 b- defN 24-May-01 12:32 mpyl/projects/__init__.py
--rw-r--r--  2.0 unx     2006 b- defN 24-May-01 12:32 mpyl/projects/find.py
--rw-r--r--  2.0 unx    12121 b- defN 24-May-01 12:32 mpyl/projects/versioning.py
--rw-r--r--  2.0 unx      345 b- defN 24-May-01 12:32 mpyl/projects/releases/releases.txt
--rw-r--r--  2.0 unx       92 b- defN 24-May-01 12:32 mpyl/reporting/__init__.py
--rw-r--r--  2.0 unx       76 b- defN 24-May-01 12:32 mpyl/reporting/formatting/__init__.py
--rw-r--r--  2.0 unx     5797 b- defN 24-May-01 12:32 mpyl/reporting/formatting/markdown.py
--rw-r--r--  2.0 unx     1340 b- defN 24-May-01 12:32 mpyl/reporting/formatting/text.py
--rw-r--r--  2.0 unx     1139 b- defN 24-May-01 12:32 mpyl/reporting/targets/__init__.py
--rw-r--r--  2.0 unx     8932 b- defN 24-May-01 12:32 mpyl/reporting/targets/github.py
--rw-r--r--  2.0 unx     9568 b- defN 24-May-01 12:32 mpyl/reporting/targets/jira.py
--rw-r--r--  2.0 unx     8064 b- defN 24-May-01 12:32 mpyl/reporting/targets/slack.py
--rw-r--r--  2.0 unx    11326 b- defN 24-May-01 12:32 mpyl/schema/k8s_api_core.schema.yml
--rw-r--r--  2.0 unx    14733 b- defN 24-May-01 12:32 mpyl/schema/mpyl_config.schema.yml
--rw-r--r--  2.0 unx    24934 b- defN 24-May-01 12:32 mpyl/schema/project.schema.yml
--rw-r--r--  2.0 unx     3296 b- defN 24-May-01 12:32 mpyl/schema/run_properties.schema.yml
--rw-r--r--  2.0 unx        0 b- defN 24-May-01 12:32 mpyl/stages/__init__.py
--rw-r--r--  2.0 unx    12809 b- defN 24-May-01 12:32 mpyl/stages/discovery.py
--rw-r--r--  2.0 unx     6456 b- defN 24-May-01 12:32 mpyl/steps/__init__.py
--rw-r--r--  2.0 unx     2686 b- defN 24-May-01 12:32 mpyl/steps/collection.py
--rw-r--r--  2.0 unx     8465 b- defN 24-May-01 12:32 mpyl/steps/models.py
--rw-r--r--  2.0 unx     4320 b- defN 24-May-01 12:32 mpyl/steps/run.py
--rw-r--r--  2.0 unx     3853 b- defN 24-May-01 12:32 mpyl/steps/run_properties.py
--rw-r--r--  2.0 unx     9692 b- defN 24-May-01 12:32 mpyl/steps/steps.py
--rw-r--r--  2.0 unx       80 b- defN 24-May-01 12:32 mpyl/steps/build/__init__.py
--rw-r--r--  2.0 unx     5034 b- defN 24-May-01 12:32 mpyl/steps/build/docker_build.py
--rw-r--r--  2.0 unx     1195 b- defN 24-May-01 12:32 mpyl/steps/build/echo.py
--rw-r--r--  2.0 unx     2192 b- defN 24-May-01 12:32 mpyl/steps/build/post_docker_build.py
--rw-r--r--  2.0 unx     2714 b- defN 24-May-01 12:32 mpyl/steps/build/sbt.py
--rw-r--r--  2.0 unx      884 b- defN 24-May-01 12:32 mpyl/steps/build/skip.py
--rw-r--r--  2.0 unx       82 b- defN 24-May-01 12:32 mpyl/steps/deploy/__init__.py
--rw-r--r--  2.0 unx     2172 b- defN 24-May-01 12:32 mpyl/steps/deploy/bpm_deploy.py
--rw-r--r--  2.0 unx     7596 b- defN 24-May-01 12:32 mpyl/steps/deploy/dagster.py
--rw-r--r--  2.0 unx     1078 b- defN 24-May-01 12:32 mpyl/steps/deploy/echo.py
--rw-r--r--  2.0 unx     1533 b- defN 24-May-01 12:32 mpyl/steps/deploy/ephemeral_docker_deploy.py
--rw-r--r--  2.0 unx     3221 b- defN 24-May-01 12:32 mpyl/steps/deploy/kubernetes.py
--rw-r--r--  2.0 unx     1115 b- defN 24-May-01 12:32 mpyl/steps/deploy/kubernetes_job.py
--rw-r--r--  2.0 unx     1188 b- defN 24-May-01 12:32 mpyl/steps/deploy/kubernetes_spark_job.py
--rw-r--r--  2.0 unx     2442 b- defN 24-May-01 12:32 mpyl/steps/deploy/bpm/__init__.py
--rw-r--r--  2.0 unx     1731 b- defN 24-May-01 12:32 mpyl/steps/deploy/bpm/camunda_modeler_client.py
--rw-r--r--  2.0 unx     2280 b- defN 24-May-01 12:32 mpyl/steps/deploy/bpm/cluster.py
--rw-r--r--  2.0 unx     1818 b- defN 24-May-01 12:32 mpyl/steps/deploy/bpm/modeler.py
--rw-r--r--  2.0 unx    11433 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/__init__.py
--rw-r--r--  2.0 unx    28949 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/chart.py
--rw-r--r--  2.0 unx     1276 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/deploy_config.py
--rw-r--r--  2.0 unx     5080 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/helm.py
--rw-r--r--  2.0 unx     1594 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/rancher.py
--rw-r--r--  2.0 unx     4868 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/__init__.py
--rw-r--r--  2.0 unx     3368 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/dagster.py
--rw-r--r--  2.0 unx     2260 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/prometheus.py
--rw-r--r--  2.0 unx      616 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/sealed_secret.py
--rw-r--r--  2.0 unx     5895 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/spark.py
--rw-r--r--  2.0 unx     2800 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/traefik.py
--rw-r--r--  2.0 unx   582312 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_prometheuses.schema.yml
--rw-r--r--  2.0 unx    39299 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_servicemonitors.schema.yml
--rw-r--r--  2.0 unx   168371 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_scheduledsparkapplications.schema.yml
--rw-r--r--  2.0 unx   151469 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_sparkapplications.schema.yml
--rw-r--r--  2.0 unx    11703 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml
--rw-r--r--  2.0 unx    42950 b- defN 24-May-01 12:32 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml
--rw-r--r--  2.0 unx       90 b- defN 24-May-01 12:32 mpyl/steps/postdeploy/__init__.py
--rw-r--r--  2.0 unx     8519 b- defN 24-May-01 12:32 mpyl/steps/postdeploy/cypress_test.py
--rw-r--r--  2.0 unx       78 b- defN 24-May-01 12:32 mpyl/steps/test/__init__.py
--rw-r--r--  2.0 unx     1574 b- defN 24-May-01 12:32 mpyl/steps/test/after_test.py
--rw-r--r--  2.0 unx     4153 b- defN 24-May-01 12:32 mpyl/steps/test/before_test.py
--rw-r--r--  2.0 unx     4652 b- defN 24-May-01 12:32 mpyl/steps/test/dockertest.py
--rw-r--r--  2.0 unx     1937 b- defN 24-May-01 12:32 mpyl/steps/test/echo.py
--rw-r--r--  2.0 unx     3636 b- defN 24-May-01 12:32 mpyl/steps/test/sbt.py
--rw-r--r--  2.0 unx      878 b- defN 24-May-01 12:32 mpyl/steps/test/skip.py
--rw-r--r--  2.0 unx      346 b- defN 24-May-01 12:32 mpyl/utilities/__init__.py
--rw-r--r--  2.0 unx     3502 b- defN 24-May-01 12:32 mpyl/utilities/bpm/__init__.py
--rw-r--r--  2.0 unx      953 b- defN 24-May-01 12:32 mpyl/utilities/cypress/__init__.py
--rw-r--r--  2.0 unx     1068 b- defN 24-May-01 12:32 mpyl/utilities/dagster/__init__.py
--rw-r--r--  2.0 unx    13237 b- defN 24-May-01 12:32 mpyl/utilities/docker/__init__.py
--rw-r--r--  2.0 unx     1938 b- defN 24-May-01 12:32 mpyl/utilities/github/__init__.py
--rw-r--r--  2.0 unx     1034 b- defN 24-May-01 12:32 mpyl/utilities/helm/__init__.py
--rw-r--r--  2.0 unx     2786 b- defN 24-May-01 12:32 mpyl/utilities/http_client/__init__.py
--rw-r--r--  2.0 unx      692 b- defN 24-May-01 12:32 mpyl/utilities/http_client/exceptions.py
--rw-r--r--  2.0 unx     1566 b- defN 24-May-01 12:32 mpyl/utilities/jenkins/__init__.py
--rw-r--r--  2.0 unx     7910 b- defN 24-May-01 12:32 mpyl/utilities/jenkins/runner.py
--rw-r--r--  2.0 unx     1598 b- defN 24-May-01 12:32 mpyl/utilities/junit/__init__.py
--rw-r--r--  2.0 unx      318 b- defN 24-May-01 12:32 mpyl/utilities/logging/__init__.py
--rw-r--r--  2.0 unx     1003 b- defN 24-May-01 12:32 mpyl/utilities/parallel/__init__.py
--rw-r--r--  2.0 unx      870 b- defN 24-May-01 12:32 mpyl/utilities/pyaml_env/__init__.py
--rw-r--r--  2.0 unx     9632 b- defN 24-May-01 12:32 mpyl/utilities/repo/__init__.py
--rw-r--r--  2.0 unx     1589 b- defN 24-May-01 12:32 mpyl/utilities/sbt/__init__.py
--rw-r--r--  2.0 unx     2573 b- defN 24-May-01 12:32 mpyl/utilities/subprocess/__init__.py
--rw-r--r--  2.0 unx      868 b- defN 24-May-01 12:32 mpyl/utilities/yaml/__init__.py
--rw-r--r--  2.0 unx    11357 b- defN 24-May-01 12:33 mpyl-1.6.6.dist-info/LICENSE
--rw-r--r--  2.0 unx     6195 b- defN 24-May-01 12:33 mpyl-1.6.6.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-01 12:33 mpyl-1.6.6.dist-info/WHEEL
--rw-r--r--  2.0 unx       35 b- defN 24-May-01 12:33 mpyl-1.6.6.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        5 b- defN 24-May-01 12:33 mpyl-1.6.6.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    10589 b- defN 24-May-01 12:33 mpyl-1.6.6.dist-info/RECORD
-119 files, 1463152 bytes uncompressed, 245033 bytes compressed:  83.3%
+Zip file size: 262091 bytes, number of entries: 119
+-rw-r--r--  2.0 unx     1200 b- defN 24-May-30 08:54 mpyl/__init__.py
+-rw-r--r--  2.0 unx      215 b- defN 24-May-30 08:54 mpyl/__main__.py
+-rw-r--r--  2.0 unx     6384 b- defN 24-May-30 08:54 mpyl/build.py
+-rw-r--r--  2.0 unx      304 b- defN 24-May-30 08:54 mpyl/constants.py
+-rw-r--r--  2.0 unx    21281 b- defN 24-May-30 08:54 mpyl/project.py
+-rw-r--r--  2.0 unx      997 b- defN 24-May-30 08:54 mpyl/project_execution.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-30 08:54 mpyl/py.typed
+-rw-r--r--  2.0 unx     2796 b- defN 24-May-30 08:54 mpyl/run_plan.py
+-rw-r--r--  2.0 unx     2370 b- defN 24-May-30 08:54 mpyl/validation.py
+-rw-r--r--  2.0 unx       60 b- defN 24-May-30 08:54 mpyl/artifacts/__init__.py
+-rw-r--r--  2.0 unx     9222 b- defN 24-May-30 08:54 mpyl/artifacts/build_artifacts.py
+-rw-r--r--  2.0 unx     3513 b- defN 24-May-30 08:54 mpyl/cli/__init__.py
+-rw-r--r--  2.0 unx    17847 b- defN 24-May-30 08:54 mpyl/cli/build.py
+-rw-r--r--  2.0 unx      614 b- defN 24-May-30 08:54 mpyl/cli/health.py
+-rw-r--r--  2.0 unx     2417 b- defN 24-May-30 08:54 mpyl/cli/meta_info.py
+-rw-r--r--  2.0 unx     9013 b- defN 24-May-30 08:54 mpyl/cli/projects.py
+-rw-r--r--  2.0 unx       34 b- defN 24-May-30 08:54 mpyl/cli/commands/__init__.py
+-rw-r--r--  2.0 unx      425 b- defN 24-May-30 08:54 mpyl/cli/commands/build/__init__.py
+-rw-r--r--  2.0 unx     1261 b- defN 24-May-30 08:54 mpyl/cli/commands/build/artifacts.py
+-rw-r--r--  2.0 unx     4524 b- defN 24-May-30 08:54 mpyl/cli/commands/build/jenkins.py
+-rw-r--r--  2.0 unx       38 b- defN 24-May-30 08:54 mpyl/cli/commands/health/__init__.py
+-rw-r--r--  2.0 unx     8248 b- defN 24-May-30 08:54 mpyl/cli/commands/health/checks.py
+-rw-r--r--  2.0 unx       52 b- defN 24-May-30 08:54 mpyl/cli/commands/projects/__init__.py
+-rw-r--r--  2.0 unx     1771 b- defN 24-May-30 08:54 mpyl/cli/commands/projects/formatting.py
+-rw-r--r--  2.0 unx     6813 b- defN 24-May-30 08:54 mpyl/cli/commands/projects/lint.py
+-rw-r--r--  2.0 unx      659 b- defN 24-May-30 08:54 mpyl/cli/commands/projects/upgrade.py
+-rw-r--r--  2.0 unx      620 b- defN 24-May-30 08:54 mpyl/projects/__init__.py
+-rw-r--r--  2.0 unx     2006 b- defN 24-May-30 08:54 mpyl/projects/find.py
+-rw-r--r--  2.0 unx    12121 b- defN 24-May-30 08:54 mpyl/projects/versioning.py
+-rw-r--r--  2.0 unx      351 b- defN 24-May-30 08:54 mpyl/projects/releases/releases.txt
+-rw-r--r--  2.0 unx       92 b- defN 24-May-30 08:54 mpyl/reporting/__init__.py
+-rw-r--r--  2.0 unx       76 b- defN 24-May-30 08:54 mpyl/reporting/formatting/__init__.py
+-rw-r--r--  2.0 unx     5831 b- defN 24-May-30 08:54 mpyl/reporting/formatting/markdown.py
+-rw-r--r--  2.0 unx     1340 b- defN 24-May-30 08:54 mpyl/reporting/formatting/text.py
+-rw-r--r--  2.0 unx     1139 b- defN 24-May-30 08:54 mpyl/reporting/targets/__init__.py
+-rw-r--r--  2.0 unx     8932 b- defN 24-May-30 08:54 mpyl/reporting/targets/github.py
+-rw-r--r--  2.0 unx     9568 b- defN 24-May-30 08:54 mpyl/reporting/targets/jira.py
+-rw-r--r--  2.0 unx     8064 b- defN 24-May-30 08:54 mpyl/reporting/targets/slack.py
+-rw-r--r--  2.0 unx    11326 b- defN 24-May-30 08:54 mpyl/schema/k8s_api_core.schema.yml
+-rw-r--r--  2.0 unx    14733 b- defN 24-May-30 08:54 mpyl/schema/mpyl_config.schema.yml
+-rw-r--r--  2.0 unx    24934 b- defN 24-May-30 08:54 mpyl/schema/project.schema.yml
+-rw-r--r--  2.0 unx     3296 b- defN 24-May-30 08:54 mpyl/schema/run_properties.schema.yml
+-rw-r--r--  2.0 unx        0 b- defN 24-May-30 08:54 mpyl/stages/__init__.py
+-rw-r--r--  2.0 unx    12955 b- defN 24-May-30 08:54 mpyl/stages/discovery.py
+-rw-r--r--  2.0 unx     6456 b- defN 24-May-30 08:54 mpyl/steps/__init__.py
+-rw-r--r--  2.0 unx     2686 b- defN 24-May-30 08:54 mpyl/steps/collection.py
+-rw-r--r--  2.0 unx     8196 b- defN 24-May-30 08:54 mpyl/steps/models.py
+-rw-r--r--  2.0 unx     3861 b- defN 24-May-30 08:54 mpyl/steps/run.py
+-rw-r--r--  2.0 unx     3853 b- defN 24-May-30 08:54 mpyl/steps/run_properties.py
+-rw-r--r--  2.0 unx     9692 b- defN 24-May-30 08:54 mpyl/steps/steps.py
+-rw-r--r--  2.0 unx       80 b- defN 24-May-30 08:54 mpyl/steps/build/__init__.py
+-rw-r--r--  2.0 unx     5034 b- defN 24-May-30 08:54 mpyl/steps/build/docker_build.py
+-rw-r--r--  2.0 unx     1195 b- defN 24-May-30 08:54 mpyl/steps/build/echo.py
+-rw-r--r--  2.0 unx     2192 b- defN 24-May-30 08:54 mpyl/steps/build/post_docker_build.py
+-rw-r--r--  2.0 unx     2714 b- defN 24-May-30 08:54 mpyl/steps/build/sbt.py
+-rw-r--r--  2.0 unx      884 b- defN 24-May-30 08:54 mpyl/steps/build/skip.py
+-rw-r--r--  2.0 unx       82 b- defN 24-May-30 08:54 mpyl/steps/deploy/__init__.py
+-rw-r--r--  2.0 unx     2119 b- defN 24-May-30 08:54 mpyl/steps/deploy/bpm_deploy.py
+-rw-r--r--  2.0 unx     7596 b- defN 24-May-30 08:54 mpyl/steps/deploy/dagster.py
+-rw-r--r--  2.0 unx     1078 b- defN 24-May-30 08:54 mpyl/steps/deploy/echo.py
+-rw-r--r--  2.0 unx     1533 b- defN 24-May-30 08:54 mpyl/steps/deploy/ephemeral_docker_deploy.py
+-rw-r--r--  2.0 unx     3221 b- defN 24-May-30 08:54 mpyl/steps/deploy/kubernetes.py
+-rw-r--r--  2.0 unx     1115 b- defN 24-May-30 08:54 mpyl/steps/deploy/kubernetes_job.py
+-rw-r--r--  2.0 unx     1188 b- defN 24-May-30 08:54 mpyl/steps/deploy/kubernetes_spark_job.py
+-rw-r--r--  2.0 unx     2486 b- defN 24-May-30 08:54 mpyl/steps/deploy/bpm/__init__.py
+-rw-r--r--  2.0 unx     1880 b- defN 24-May-30 08:54 mpyl/steps/deploy/bpm/camunda_modeler_client.py
+-rw-r--r--  2.0 unx     2280 b- defN 24-May-30 08:54 mpyl/steps/deploy/bpm/cluster.py
+-rw-r--r--  2.0 unx     2342 b- defN 24-May-30 08:54 mpyl/steps/deploy/bpm/modeler.py
+-rw-r--r--  2.0 unx    11433 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/__init__.py
+-rw-r--r--  2.0 unx    29220 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/chart.py
+-rw-r--r--  2.0 unx     1276 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/deploy_config.py
+-rw-r--r--  2.0 unx     5080 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/helm.py
+-rw-r--r--  2.0 unx     1594 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/rancher.py
+-rw-r--r--  2.0 unx     4868 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/__init__.py
+-rw-r--r--  2.0 unx     3368 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/dagster.py
+-rw-r--r--  2.0 unx     2260 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/prometheus.py
+-rw-r--r--  2.0 unx      616 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/sealed_secret.py
+-rw-r--r--  2.0 unx     5895 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/spark.py
+-rw-r--r--  2.0 unx     2800 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/traefik.py
+-rw-r--r--  2.0 unx   582312 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_prometheuses.schema.yml
+-rw-r--r--  2.0 unx    39299 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_servicemonitors.schema.yml
+-rw-r--r--  2.0 unx   168371 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_scheduledsparkapplications.schema.yml
+-rw-r--r--  2.0 unx   151469 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_sparkapplications.schema.yml
+-rw-r--r--  2.0 unx    11703 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml
+-rw-r--r--  2.0 unx    42950 b- defN 24-May-30 08:54 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml
+-rw-r--r--  2.0 unx       90 b- defN 24-May-30 08:54 mpyl/steps/postdeploy/__init__.py
+-rw-r--r--  2.0 unx     8519 b- defN 24-May-30 08:54 mpyl/steps/postdeploy/cypress_test.py
+-rw-r--r--  2.0 unx       78 b- defN 24-May-30 08:54 mpyl/steps/test/__init__.py
+-rw-r--r--  2.0 unx     1574 b- defN 24-May-30 08:54 mpyl/steps/test/after_test.py
+-rw-r--r--  2.0 unx     4153 b- defN 24-May-30 08:54 mpyl/steps/test/before_test.py
+-rw-r--r--  2.0 unx     4652 b- defN 24-May-30 08:54 mpyl/steps/test/dockertest.py
+-rw-r--r--  2.0 unx     1937 b- defN 24-May-30 08:54 mpyl/steps/test/echo.py
+-rw-r--r--  2.0 unx     3636 b- defN 24-May-30 08:54 mpyl/steps/test/sbt.py
+-rw-r--r--  2.0 unx      878 b- defN 24-May-30 08:54 mpyl/steps/test/skip.py
+-rw-r--r--  2.0 unx      346 b- defN 24-May-30 08:54 mpyl/utilities/__init__.py
+-rw-r--r--  2.0 unx     3635 b- defN 24-May-30 08:54 mpyl/utilities/bpm/__init__.py
+-rw-r--r--  2.0 unx     1002 b- defN 24-May-30 08:54 mpyl/utilities/cypress/__init__.py
+-rw-r--r--  2.0 unx     1068 b- defN 24-May-30 08:54 mpyl/utilities/dagster/__init__.py
+-rw-r--r--  2.0 unx    13237 b- defN 24-May-30 08:54 mpyl/utilities/docker/__init__.py
+-rw-r--r--  2.0 unx     1938 b- defN 24-May-30 08:54 mpyl/utilities/github/__init__.py
+-rw-r--r--  2.0 unx     1034 b- defN 24-May-30 08:54 mpyl/utilities/helm/__init__.py
+-rw-r--r--  2.0 unx     2786 b- defN 24-May-30 08:54 mpyl/utilities/http_client/__init__.py
+-rw-r--r--  2.0 unx      692 b- defN 24-May-30 08:54 mpyl/utilities/http_client/exceptions.py
+-rw-r--r--  2.0 unx     1566 b- defN 24-May-30 08:54 mpyl/utilities/jenkins/__init__.py
+-rw-r--r--  2.0 unx     7910 b- defN 24-May-30 08:54 mpyl/utilities/jenkins/runner.py
+-rw-r--r--  2.0 unx     1598 b- defN 24-May-30 08:54 mpyl/utilities/junit/__init__.py
+-rw-r--r--  2.0 unx      318 b- defN 24-May-30 08:54 mpyl/utilities/logging/__init__.py
+-rw-r--r--  2.0 unx     1003 b- defN 24-May-30 08:54 mpyl/utilities/parallel/__init__.py
+-rw-r--r--  2.0 unx      870 b- defN 24-May-30 08:54 mpyl/utilities/pyaml_env/__init__.py
+-rw-r--r--  2.0 unx     9632 b- defN 24-May-30 08:54 mpyl/utilities/repo/__init__.py
+-rw-r--r--  2.0 unx     1589 b- defN 24-May-30 08:54 mpyl/utilities/sbt/__init__.py
+-rw-r--r--  2.0 unx     2372 b- defN 24-May-30 08:54 mpyl/utilities/subprocess/__init__.py
+-rw-r--r--  2.0 unx      868 b- defN 24-May-30 08:54 mpyl/utilities/yaml/__init__.py
+-rw-r--r--  2.0 unx    11357 b- defN 24-May-30 08:55 mpyl-1.6.7.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6195 b- defN 24-May-30 08:55 mpyl-1.6.7.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-30 08:55 mpyl-1.6.7.dist-info/WHEEL
+-rw-r--r--  2.0 unx       35 b- defN 24-May-30 08:55 mpyl-1.6.7.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        5 b- defN 24-May-30 08:55 mpyl-1.6.7.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    10590 b- defN 24-May-30 08:55 mpyl-1.6.7.dist-info/RECORD
+119 files, 1464974 bytes uncompressed, 245245 bytes compressed:  83.3%
```

## zipnote {}

```diff
@@ -333,26 +333,26 @@
 
 Filename: mpyl/utilities/subprocess/__init__.py
 Comment: 
 
 Filename: mpyl/utilities/yaml/__init__.py
 Comment: 
 
-Filename: mpyl-1.6.6.dist-info/LICENSE
+Filename: mpyl-1.6.7.dist-info/LICENSE
 Comment: 
 
-Filename: mpyl-1.6.6.dist-info/METADATA
+Filename: mpyl-1.6.7.dist-info/METADATA
 Comment: 
 
-Filename: mpyl-1.6.6.dist-info/WHEEL
+Filename: mpyl-1.6.7.dist-info/WHEEL
 Comment: 
 
-Filename: mpyl-1.6.6.dist-info/entry_points.txt
+Filename: mpyl-1.6.7.dist-info/entry_points.txt
 Comment: 
 
-Filename: mpyl-1.6.6.dist-info/top_level.txt
+Filename: mpyl-1.6.7.dist-info/top_level.txt
 Comment: 
 
-Filename: mpyl-1.6.6.dist-info/RECORD
+Filename: mpyl-1.6.7.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mpyl/build.py

```diff
@@ -8,15 +8,15 @@
 
 from jsonschema import ValidationError
 from rich.console import Console
 from rich.logging import RichHandler
 from rich.markdown import Markdown
 
 from .cli import CliContext, MpylCliParameters
-from .constants import DEFAULT_RUN_PROPERTIES_FILE_NAME, RUN_ARTIFACTS_FOLDER
+from .constants import RUN_ARTIFACTS_FOLDER
 from .reporting.formatting.markdown import (
     execution_plan_as_markdown,
     run_result_to_markdown,
 )
 from .reporting.targets import Reporter
 from .steps import deploy
 from .steps.collection import StepsCollection
@@ -32,82 +32,47 @@
     run_properties = construct_run_properties(
         config=obj.config,
         properties=obj.run_properties,
         cli_parameters=cli_params,
         explain_run_plan=explain_run_plan,
     )
     console = obj.console
+    logger = logging.getLogger("mpyl")
 
-    def write_run_plan_as_json():
-        """Write the run plan as a simple JSON file to be used by Github Actions"""
-        simple_run_plan: dict[str, list[dict[str, Union[str, bool]]]] = dict(
-            {
-                stage.name: [
-                    {
-                        "service": project_execution.project.name,
-                        "path": project_execution.project.path,
-                        "base": project_execution.project.root_path,
-                        "cached": project_execution.cached,
-                        "maintainers": project_execution.project.maintainer,
-                    }
-                    for project_execution in project_executions
-                ]
-                for stage, project_executions in run_properties.run_plan.items()
-            }
-        )
-        run_plan_file = Path(RUN_ARTIFACTS_FOLDER) / "run_plan.json"
-        os.makedirs(os.path.dirname(run_plan_file), exist_ok=True)
-        with open(run_plan_file, "w", encoding="utf-8") as file:
-            console.print(f"Writing simple JSON run plan to: {run_plan_file}")
-            json.dump(simple_run_plan, file)
-
-    write_run_plan_as_json()
-
-    console.print(f"MPyL log level is set to {run_properties.console.log_level}")
-    branch = obj.repo.get_branch
-    main_branch = obj.repo.main_branch
-    tag = cli_params.tag or run_properties.versioning.tag
-
-    if tag is None:
-        if run_properties.versioning.branch and not obj.repo.get_branch:
-            console.print("Current branch is detached.")
-        else:
-            console.log(
-                Markdown(
-                    f"Branch not specified at `build.versioning.branch` in _{DEFAULT_RUN_PROPERTIES_FILE_NAME}_, "
-                    f"falling back to git: _{obj.repo.get_branch}_"
-                )
-            )
+    # Write the run plan as a simple JSON file to be used by Github Actions
+    simple_run_plan: dict[str, list[dict[str, Union[str, bool, list[str]]]]] = dict(
+        {
+            stage.name: [
+                {
+                    "service": project_execution.project.name,
+                    "path": project_execution.project.path,
+                    "base": project_execution.project.root_path,
+                    "cached": project_execution.cached,
+                    "maintainers": project_execution.project.maintainer,
+                }
+                for project_execution in project_executions
+            ]
+            for stage, project_executions in run_properties.run_plan.full_plan.items()
+        }
+    )
+    run_plan_file = Path(RUN_ARTIFACTS_FOLDER) / "run_plan.json"
+    os.makedirs(os.path.dirname(run_plan_file), exist_ok=True)
+    with open(run_plan_file, "w", encoding="utf-8") as file:
+        logger.info(f"Writing simple JSON run plan to: {run_plan_file}")
+        json.dump(simple_run_plan, file)
 
-        if branch == main_branch:
-            console.log(f"On main branch ({branch}), cannot determine build status")
-            return
-
-    version = run_properties.versioning
-    revision = version.revision or obj.repo.get_sha
-    base_revision = obj.repo.base_revision
-    if tag:
-        console.print(Markdown(f"**Tag:** `{version.tag}` at `{revision}`. "))
-    else:
-        base_revision_specification = (
-            f"`{main_branch}` at `{base_revision}`"
-            if base_revision
-            else f"not present. Earliest revision: `{obj.repo.root_commit_hex}` (grafted)."
-        )
-        console.print(
-            Markdown(f"**Branch:** `{branch}`. Base {base_revision_specification}. ")
-        )
+    logger.info(f"MPyL log level is set to {run_properties.console.log_level}")
 
     result = RunResult(run_properties=run_properties)
-    if result.has_run_plan_projects:
+    if result.has_projects_to_run(include_cached_projects=True):
         console.print(
             Markdown("**Execution plan:**  \n" + execution_plan_as_markdown(result))
         )
     else:
-        console.print("No changes detected, nothing to do.")
+        logger.info("No changes detected, nothing to do.")
 
 
 FORMAT = "%(name)s  %(message)s"
 
 
 def run_mpyl(
     run_properties: RunProperties,
@@ -133,15 +98,15 @@
         ],
     )
     print(f"Log level is set to {log_level}")
     logger = logging.getLogger("mpyl")
     try:
         run_result = RunResult(run_properties=run_properties)
 
-        if not run_result.has_run_plan_projects:
+        if not run_result.has_projects_to_run(include_cached_projects=False):
             logger.info("Nothing to do. Exiting..")
             return run_result
 
         logger.info("Run plan:")
         console.print(Markdown(f"\n\n{run_result_to_markdown(run_result)}"))
 
         if reporter:
@@ -150,18 +115,19 @@
             steps = Steps(
                 logger=logger,
                 properties=run_properties,
                 steps_collection=StepsCollection(logger=logger),
             )
 
             run_result = run_build(
-                run_result,
-                steps,
-                reporter,
-                cli_parameters.dryrun or cli_parameters.local,
+                logger=logger,
+                accumulator=run_result,
+                executor=steps,
+                reporter=reporter,
+                dry_run=cli_parameters.dryrun or cli_parameters.local,
             )
         except ValidationError as exc:
             console.log(
                 f'Schema validation failed {exc.message} at `{".".join(map(str, exc.path))}`'
             )
             raise exc
         except ExecutionException as exc:
@@ -175,41 +141,42 @@
     except Exception as exc:
         console.log(f"Unexpected exception: {exc}")
         console.print_exception()
         raise exc
 
 
 def run_build(
+    logger: logging.Logger,
     accumulator: RunResult,
     executor: Steps,
     reporter: Optional[Reporter] = None,
     dry_run: bool = True,
 ):
     try:
-        for stage, project_executions in accumulator.run_plan.items():
+        for stage, project_executions in accumulator.run_plan.selected_plan.items():
             for project_execution in project_executions:
                 if project_execution.cached:
-                    logging.info(
+                    logger.info(
                         f"Skipping {project_execution.name} for stage {stage.name} because it is cached"
                     )
                     result = StepResult(
                         stage=stage,
                         project=project_execution.project,
                         output=Output(success=True, message="This step was cached"),
                     )
                 else:
                     result = executor.execute(stage.name, project_execution, dry_run)
                 accumulator.append(result)
                 if reporter:
                     reporter.send_report(accumulator)
 
                 if not result.output.success and stage.name == deploy.STAGE_NAME:
-                    logging.warning(f"Deployment failed for {project_execution.name}")
+                    logger.warning(f"Deployment failed for {project_execution.name}")
                     return accumulator
 
             if accumulator.failed_results:
-                logging.warning(f"One of the builds failed at Stage {stage.name}")
+                logger.warning(f"One of the builds failed at Stage {stage.name}")
                 return accumulator
         return accumulator
     except ExecutionException as exc:
         accumulator.exception = exc
         return accumulator
```

## mpyl/run_plan.py

```diff
@@ -4,35 +4,80 @@
 
 from .project import Project, Stage
 from .project_execution import ProjectExecution
 
 
 @dataclass(frozen=True)
 class RunPlan:
-    plan: dict[Stage, set[ProjectExecution]]
+    full_plan: dict[Stage, set[ProjectExecution]]
+    selected_plan: dict[Stage, set[ProjectExecution]]
 
-    @staticmethod
-    def empty() -> "RunPlan":
-        return RunPlan({})
+    @classmethod
+    def empty(cls) -> "RunPlan":
+        return cls(full_plan={}, selected_plan={})
+
+    @classmethod
+    def from_plan(cls, plan: dict[Stage, set[ProjectExecution]]) -> "RunPlan":
+        return cls(full_plan=plan, selected_plan=plan)
 
-    def get(self, stage: Stage) -> set[ProjectExecution]:
-        return self.plan.get(stage, set())
+    def select_stage(self, stage: Stage) -> "RunPlan":
+        return RunPlan(
+            full_plan=self.full_plan,
+            selected_plan={stage: self.get_projects_for_stage(stage)},
+        )
 
-    def add_stage(self, stage: Stage, executions: set[ProjectExecution]):
-        self.plan.update({stage: executions})
+    def select_projects(self, projects: set[Project]) -> "RunPlan":
+        selected_plan = {}
 
-    def update(self, run_plan: "RunPlan"):
-        self.plan.update(run_plan.plan)
+        for stage, executions in self.selected_plan.items():
+            selected_plan[stage] = {e for e in executions if e.project in projects}
 
-    def items(self):
-        return self.plan.items()
+        return RunPlan(
+            full_plan=self.full_plan,
+            selected_plan=selected_plan,
+        )
 
-    def for_stage(self, stage: Stage) -> "RunPlan":
-        return RunPlan({stage: self.get(stage)})
+    def update(self, run_plan: "RunPlan"):
+        self.full_plan.update(run_plan.full_plan)
+        self.selected_plan.update(run_plan.selected_plan)
 
-    def for_projects(self, projects: set[Project]):
-        return RunPlan(
-            {
-                stage: {e for e in executions if e.project in projects}
-                for stage, executions in self.plan.items()
-            }
+    def has_projects_to_run(
+        self, include_cached_projects: bool, use_full_plan: bool = False
+    ) -> bool:
+        return any(
+            include_cached_projects or not project_execution.cached
+            for project_execution in self.get_all_projects(use_full_plan)
         )
+
+    def get_all_projects(self, use_full_plan: bool = False) -> set[ProjectExecution]:
+        def flatten(plan: dict[Stage, set[ProjectExecution]]):
+            return {
+                project_execution
+                for project_executions in plan.values()
+                for project_execution in project_executions
+            }
+
+        if use_full_plan:
+            return flatten(self.full_plan)
+        return flatten(self.selected_plan)
+
+    def get_projects_for_stage(
+        self, stage: Stage, use_full_plan: bool = False
+    ) -> set[ProjectExecution]:
+        if use_full_plan:
+            return self.full_plan.get(stage, set())
+        return self.selected_plan.get(stage, set())
+
+    def get_projects_for_stage_name(
+        self, stage_name: str, use_full_plan: bool = False
+    ) -> set[ProjectExecution]:
+        def find_stage(plan: dict[Stage, set[ProjectExecution]]):
+            iterator = (
+                project_executions
+                for stage, project_executions in plan.items()
+                if stage.name == stage_name
+            )
+            return next(iterator, set())
+
+        if use_full_plan:
+            return find_stage(self.full_plan)
+        return find_stage(self.selected_plan)
```

## mpyl/cli/__init__.py

```diff
@@ -1,8 +1,9 @@
 """Command Line Interface parsing for MPyL"""
+
 import asyncio
 import importlib
 import logging
 from dataclasses import dataclass
 from importlib.metadata import version as version_meta
 from pathlib import Path
 from typing import Optional
```

## mpyl/cli/projects.py

```diff
@@ -1,8 +1,9 @@
 """Commands related to projects and how they relate"""
+
 import sys
 from dataclasses import dataclass
 from pathlib import Path
 
 import click
 from click import ParamType, Argument
 from click.shell_completion import CompletionItem
@@ -19,14 +20,15 @@
 from ..cli.commands.projects.lint import (
     _check_and_load_projects,
     _assert_unique_project_names,
     _assert_correct_project_linkup,
     _lint_whitelisting_rules,
     __detail_wrong_substitutions,
     _assert_project_ids,
+    _assert_no_self_dependencies,
 )
 from ..cli.commands.projects.upgrade import check_upgrade
 from ..constants import DEFAULT_CONFIG_FILE_NAME
 from ..project import load_project, Project, Target, get_project_root_dir
 from ..projects.versioning import (
     check_upgrades_needed,
     upgrade_file,
@@ -143,14 +145,15 @@
         obj.cli.console.print([file.value for file in complete])
         return
     print_project(obj.cli.repo, obj.cli.console, project_path)
 
 
 @projects.command(help="Validate the yaml of changed projects against their schema")
 @click.pass_obj
+# pylint: disable=too-many-branches
 def lint(obj: ProjectsContext):
     loaded_projects = _check_and_load_projects(
         console=obj.cli.console,
         repo=obj.cli.repo,
         project_paths=obj.cli.repo.find_projects(obj.filter),
         strict=True,
     )
@@ -216,14 +219,25 @@
         else:
             for project, diff in wrong_whitelists:
                 console.log(
                     f"  ❌ Project {project.name} has undefined whitelists: {diff}"
                 )
                 failed = True
 
+    projects_with_self_dependencies = _assert_no_self_dependencies(
+        console, all_projects
+    )
+
+    if len(projects_with_self_dependencies) == 0:
+        console.print("  ✅ No project with a dependency on itself found")
+    else:
+        for project in projects_with_self_dependencies:
+            console.print(f"  ❌ Project {project.name} has a dependency on itself")
+        failed = True
+
     if failed:
         click.get_current_context().exit(1)
 
 
 @projects.command(help="Upgrade projects to conform with the latest schema")
 @click.option(
     "--apply",
```

## mpyl/cli/commands/projects/lint.py

```diff
@@ -1,8 +1,9 @@
 """Helper methods for linting projects for correctness are found here"""
+
 import itertools
 from dataclasses import dataclass
 from pathlib import Path
 from typing import Optional
 
 import click
 import jsonschema
@@ -174,7 +175,21 @@
                         ]
                     )
                 )
                 if diff := whitelists.difference(defined_whitelists):
                     wrong_whitelists.append((project, diff))
 
     return wrong_whitelists
+
+
+def _assert_no_self_dependencies(console: Console, all_projects: list[Project]):
+    console.print("")
+    console.print("Checking for projects depending on themselves:")
+
+    projects_with_self_dependencies = []
+
+    for project in all_projects:
+        if project.dependencies:
+            if project.name in project.dependencies.all().keys():
+                projects_with_self_dependencies.append(project)
+
+    return projects_with_self_dependencies
```

## mpyl/projects/releases/releases.txt

```diff
@@ -46,8 +46,9 @@
 1.5.1
 1.6.0
 1.6.1
 1.6.2
 1.6.3
 1.6.4
 1.6.5
-1.6.6
+1.6.6
+1.6.7
```

## mpyl/reporting/formatting/markdown.py

```diff
@@ -1,10 +1,11 @@
 """
 Markdown run result formatters
 """
+
 import operator
 from typing import cast, Optional
 
 from ...project import Stage
 from ...project_execution import ProjectExecution
 from ...steps import Output, ArtifactType
 from ...steps.deploy.k8s import DeployedHelmAppSpec
@@ -40,29 +41,31 @@
     if found_result:
         project_name = __add_link_if_service(project_name, found_result.output)
         encapsulation = "*" if found_result.output.success else "~~"
 
     return f"{encapsulation}{project_name}{' (cached)' if project_execution.cached else ''}{encapsulation}"
 
 
-def __to_oneliner(result: list[StepResult], plan: set[ProjectExecution]) -> str:
+def __to_oneliner(
+    result: list[StepResult], plan: Optional[set[ProjectExecution]]
+) -> str:
     project_names: list[str] = []
     if plan:
         sorted_plans = sorted(plan, key=operator.attrgetter("name"))
         for project_execution in sorted_plans:
             project_names.append(wrap_project_name(project_execution, result))
     else:
         project_names = list(map(lambda r: f"_{r.project.name}_", result))
 
     return f'{", ".join(project_names)}'
 
 
 def markdown_for_stage(run_result: RunResult, stage: Stage):
     step_results: list[StepResult] = run_result.results_for_stage(stage)
-    plan = run_result.plan_for_stage(stage)
+    plan = run_result.run_plan.get_projects_for_stage(stage)
     if not step_results and not plan:
         return ""
 
     result = f"{stage.icon} {stage.name.capitalize()}:  \n{__to_oneliner(step_results, plan)}  \n"
     test_artifacts: dict[str, JunitTestSpec] = _collect_test_specs(step_results)
     test_results: dict[str, TestRunSummary] = _collect_test_results(test_artifacts)
```

## mpyl/stages/discovery.py

```diff
@@ -23,26 +23,28 @@
 
 @dataclass(frozen=True)
 class DeploySet:
     all_projects: set[Project]
     projects_to_deploy: set[Project]
 
 
-def file_belongs_to_project(
-    logger: logging.Logger, project: Project, path: str
-) -> bool:
-    startswith: bool = path.startswith(project.root_path)
-    if startswith:
+def file_belongs_to_project(project: Project, path: str) -> bool:
+    return path.startswith(project.root_path)
+
+
+def is_file_in_project(logger: logging.Logger, project: Project, path: str) -> bool:
+    if file_belongs_to_project(project, path):
         logger.debug(
-            f"Project {project.name}: {path} touched project root {project.root_path}"
+            f"Project {project.name} added to the run plan because project file was modified: {path}"
         )
-    return startswith
+        return True
+    return False
 
 
-def is_dependency_modified(
+def is_file_a_dependency(
     logger: logging.Logger,
     project: Project,
     stage: str,
     path: str,
     steps: Optional[StepsCollection],
 ) -> bool:
     deps = project.dependencies
@@ -53,15 +55,15 @@
         dep_stage
         for dep_stage, dependencies in deps.all().items()
         if len([d for d in dependencies if path.startswith(d)]) > 0
     }
 
     if stage in touched_stages:
         logger.debug(
-            f"Project {project.name}: {path} touched one of the dependencies for stage {stage}"
+            f"Project {project.name} added to the run plan because a {stage} dependency was modified: {path}"
         )
         return True
 
     step_name = project.stages.for_stage(stage)
     if step_name is None or steps is None:
         logger.debug(
             f"Project {project.name}: the step for stage {stage} is not defined or not found"
@@ -76,16 +78,16 @@
     required_artifact = executor.required_artifact
     if required_artifact != ArtifactType.NONE:
         producing_stage = steps.get_stage_for_producing_artifact(
             project, required_artifact
         )
         if producing_stage is not None and producing_stage in touched_stages:
             logger.debug(
-                f"Project {project.name}: producing stage {producing_stage} for required artifact {required_artifact} "
-                f"is touched"
+                f"Project {project.name} added to the run plan because producing stage {producing_stage} for required "
+                f"artifact {required_artifact} is modified"
             )
             return True
 
     return False
 
 
 def is_project_cached_for_stage(
@@ -136,21 +138,20 @@
         logger.debug(f"Hashed changes for the current run: {hashed_changes}")
         cached = True
 
     return cached
 
 
 def _hash_changes_in_project(
-    logger: logging.Logger,
     project: Project,
     changeset: Changeset,
 ) -> Optional[str]:
     files_to_hash = set(
         filter(
-            lambda changed_file: file_belongs_to_project(logger, project, changed_file),
+            lambda changed_file: file_belongs_to_project(project, changed_file),
             changeset.files_touched(status={"A", "M", "R", "C"}),
         )
     )
 
     if len(files_to_hash) == 0:
         return None
 
@@ -172,17 +173,15 @@
     projects: set[Project],
     stage: str,
     changeset: Changeset,
 ) -> set[ProjectExecution]:
     def to_project_execution(
         project: Project,
     ) -> ProjectExecution:
-        hashed_changes = _hash_changes_in_project(
-            logger=logger, project=project, changeset=changeset
-        )
+        hashed_changes = _hash_changes_in_project(project=project, changeset=changeset)
 
         return ProjectExecution.create(
             project=project,
             cached=is_project_cached_for_stage(
                 logger=logger,
                 project=project.name,
                 stage=stage,
@@ -205,39 +204,40 @@
     def build_project_execution(
         project: Project,
     ) -> Optional[ProjectExecution]:
         if project.stages.for_stage(stage) is None:
             return None
 
         is_any_dependency_modified = any(
-            is_dependency_modified(logger, project, stage, changed_file, steps)
+            is_file_a_dependency(logger, project, stage, changed_file, steps)
             for changed_file in changeset.files_touched()
         )
         is_project_modified = any(
-            file_belongs_to_project(logger, project, changed_file)
+            is_file_in_project(logger, project, changed_file)
             for changed_file in changeset.files_touched()
         )
 
         if is_any_dependency_modified:
             logger.debug(
-                f"Project {project} will execute stage {stage} because a dependency was modified"
+                f"Project {project.name} will execute stage {stage} because (at least) one of its dependencies was "
+                f"modified"
             )
 
             if is_project_modified:
                 hashed_changes = _hash_changes_in_project(
-                    logger=logger, project=project, changeset=changeset
+                    project=project, changeset=changeset
                 )
             else:
                 hashed_changes = None
 
             return ProjectExecution.run(project, hashed_changes)
 
         if is_project_modified:
             hashed_changes = _hash_changes_in_project(
-                logger=logger, project=project, changeset=changeset
+                project=project, changeset=changeset
             )
 
             return ProjectExecution.create(
                 project=project,
                 cached=is_project_cached_for_stage(
                     logger=logger,
                     project=project.name,
@@ -270,19 +270,24 @@
     selected_stage: Optional[Stage] = None,
     changed_files_path: Optional[str] = None,
 ) -> RunPlan:
     run_plan_file = Path(RUN_ARTIFACTS_FOLDER) / "run_plan.pickle"
 
     existing_run_plan = _load_existing_run_plan(logger, run_plan_file)
     if existing_run_plan:
-        return _filter_existing_run_plan(
-            run_plan=existing_run_plan,
-            selected_stage=selected_stage,
-            selected_projects=selected_projects,
-        )
+        logger.debug(f"Run plan: {existing_run_plan}")
+        if selected_stage:
+            existing_run_plan = existing_run_plan.select_stage(selected_stage)
+            logger.info(f"Selected stage: {selected_stage.name}")
+            logger.debug(f"Run plan: {existing_run_plan}")
+        if selected_projects:
+            existing_run_plan = existing_run_plan.select_projects(selected_projects)
+            logger.info(f"Selected projects: {set(p.name for p in selected_projects)}")
+            logger.debug(f"Run plan: {existing_run_plan}")
+        return existing_run_plan
 
     run_plan = _discover_run_plan(
         logger=logger,
         repository=repository,
         all_projects=all_projects,
         all_stages=all_stages,
         build_all=build_all,
@@ -293,57 +298,39 @@
         changed_files_path=changed_files_path,
     )
 
     _store_run_plan(logger, run_plan, run_plan_file)
     return run_plan
 
 
-def _filter_existing_run_plan(
-    run_plan: RunPlan,
-    selected_stage: Optional[Stage],
-    selected_projects: set[Project],
-) -> RunPlan:
-    filtered_run_plan = run_plan
-
-    if selected_stage:
-        filtered_run_plan = filtered_run_plan.for_stage(selected_stage)
-
-    if selected_projects:
-        filtered_run_plan = filtered_run_plan.for_projects(selected_projects)
-
-    return filtered_run_plan
-
-
 # pylint: disable=too-many-arguments
 def _discover_run_plan(
     logger: logging.Logger,
     repository: Repository,
     all_projects: set[Project],
     all_stages: list[Stage],
     build_all: bool,
     local: bool,
     selected_projects: set[Project],
     selected_stage: Optional[Stage],
     tag: Optional[str] = None,
     changed_files_path: Optional[str] = None,
 ) -> RunPlan:
     logger.info("Discovering run plan...")
-    run_plan: RunPlan = RunPlan.empty()
     changeset = _get_changes(
         logger=logger,
         repo=repository,
         local=local,
         tag=tag,
         changed_files_path=changed_files_path,
     )
 
-    for stage in all_stages:
-        if selected_stage and stage != selected_stage:
-            continue
+    plan = {}
 
+    def add_projects_to_plan(stage: Stage):
         if build_all:
             project_executions = to_project_executions(
                 logger=logger,
                 projects=for_stage(all_projects, stage),
                 stage=stage.name,
                 changeset=changeset,
             )
@@ -362,17 +349,23 @@
                 changeset=changeset,
                 steps=StepsCollection(logger=logging.getLogger()),
             )
 
         logger.debug(
             f"Will execute projects for stage {stage.name}: {[p.name for p in project_executions]}"
         )
-        run_plan.add_stage(stage, project_executions)
+        plan.update({stage: project_executions})
 
-    return run_plan
+    if selected_stage:
+        add_projects_to_plan(selected_stage)
+    else:
+        for stage in all_stages:
+            add_projects_to_plan(stage)
+
+    return RunPlan.from_plan(plan)
 
 
 def for_stage(projects: set[Project], stage: Stage) -> set[Project]:
     return {p for p in projects if p.stages.for_stage(stage.name)}
 
 
 def _get_changes(
```

## mpyl/steps/models.py

```diff
@@ -4,15 +4,14 @@
 from dataclasses import dataclass
 from enum import Enum
 from pathlib import Path
 from typing import Optional, cast, Type
 
 from ruamel.yaml import YAML, yaml_object  # type: ignore
 
-from . import deploy
 from ..project import Project, Stage, Target
 from ..project_execution import ProjectExecution
 from ..run_plan import RunPlan
 from ..validation import validate
 
 yaml = YAML()
 
@@ -166,22 +165,14 @@
             stages=[
                 Stage(stage["name"], stage["icon"])
                 for stage in run_properties["stages"]
             ],
             projects=all_projects,
         )
 
-    @property
-    def projects_to_deploy(self) -> set[ProjectExecution]:
-        return next(
-            project_execution
-            for stage, project_execution in self.run_plan.items()
-            if stage.name == deploy.STAGE_NAME
-        )
-
     def to_stage(self, stage_name: str) -> Stage:
         stage_by_name = next(stage for stage in self.stages if stage.name == stage_name)
         if stage_by_name:
             return stage_by_name
         raise ValueError(f"Stage {stage_name} not found")
```

## mpyl/steps/run.py

```diff
@@ -4,15 +4,14 @@
 
 import operator
 from typing import Optional
 
 from .models import RunProperties
 from .steps import StepResult, ExecutionException
 from ..project import Stage
-from ..project_execution import ProjectExecution
 from ..run_plan import RunPlan
 
 
 class RunResult:
     _run_plan: RunPlan
     _results: list[StepResult]
     _run_properties: RunProperties
@@ -43,15 +42,15 @@
 
         return failed_results if len(failed_results) > 0 else None
 
     @property
     def progress_fraction(self) -> float:
         unfinished = 0
         finished = 0
-        for stage, project_executions in self.run_plan.items():
+        for stage, project_executions in self.run_plan.selected_plan.items():
             finished_project_names = set(
                 map(lambda r: r.project.name, self.results_for_stage(stage))
             )
             for project_execution in project_executions:
                 if (
                     project_execution.name in finished_project_names
                     or project_execution.cached
@@ -78,25 +77,16 @@
     def run_properties(self) -> RunProperties:
         return self._run_properties
 
     @property
     def run_plan(self) -> RunPlan:
         return self._run_plan
 
-    @property
-    def has_run_plan_projects(self) -> bool:
-        """
-        We create a ProjectExecution for every project that is changed in the branch we're building, HOWEVER we also
-        know per-project whether it's cached or not. In this function we should read that value to exclude projects
-        that don't need rebuilding.
-        """
-        return not all(
-            len(project_execution) == 0
-            for stage, project_execution in self.run_plan.items()
-        )
+    def has_projects_to_run(self, include_cached_projects: bool = True) -> bool:
+        return self.run_plan.has_projects_to_run(include_cached_projects)
 
     @property
     def results(self) -> list[StepResult]:
         return self._results
 
     def append(self, result: StepResult):
         self._results.append(result)
@@ -119,25 +109,24 @@
 
     @property
     def has_results(self):
         return len(self._results) > 0
 
     @property
     def is_in_progress(self):
-        return self.has_run_plan_projects and self.is_success and not self.is_finished
+        return (
+            self.run_plan.has_projects_to_run(include_cached_projects=False)
+            and self.is_success
+            and not self.is_finished
+        )
 
     def _results_success(self):
         return not self.has_results or all(r.output.success for r in self._results)
 
     @staticmethod
     def sort_chronologically(results: list[StepResult]) -> list[StepResult]:
         return sorted(results, key=operator.attrgetter("timestamp"))
 
     def results_for_stage(self, stage: Stage) -> list[StepResult]:
         return RunResult.sort_chronologically(
             [res for res in self._results if res.stage == stage]
         )
-
-    def plan_for_stage(self, stage: Stage) -> set[ProjectExecution]:
-        plan: Optional[set[ProjectExecution]] = self.run_plan.get(stage)
-
-        return plan or set()
```

## mpyl/steps/deploy/bpm_deploy.py

```diff
@@ -25,16 +25,15 @@
             # TO DO: create bpm artifact:
             # https://vandebron.atlassian.net/browse/BPMN-293
         )
 
     def execute(self, step_input: Input) -> Output:
         bpm_deploy_results = []
         camunda_config = CamundaConfig.from_config(
-            step_input.run_properties.config,
-            step_input.run_properties.target,
+            step_input.run_properties,
             step_input.project_execution.project,
         )
 
         project_name = step_input.project_execution.project.name
         docker_result = deploy_to_cluster(self._logger, project_name, camunda_config)
         bpm_deploy_results.append(docker_result)
         if docker_result.success:
```

## mpyl/steps/deploy/bpm/__init__.py

```diff
@@ -39,17 +39,18 @@
     credentials = config.modeler_credentials.to_dict()
     camunda_client = CamundaModelerClient(
         config.modeler_api.base_url,
         config.modeler_api.token_url,
         credentials,
     )
     bpm_file_path = config.depolyment_path.bpm_diagram_folder_path
+    pr_number = config.pr_number
     try:
         deploy_diagram_to_modeler(
-            logger, bpm_file_path, config.project_id, camunda_client
+            logger, bpm_file_path, config.project_id, camunda_client, pr_number
         )
     except AuthorizationError:
         return Output(
             success=False,
             message=f"Authorization Error for project {project_name}",
             produced_artifact=None,
         )
```

## mpyl/steps/deploy/bpm/camunda_modeler_client.py

```diff
@@ -43,7 +43,11 @@
     def get_files(self, data):
         endpoint = "files/search"
         return self.http.post(endpoint=endpoint, json=data).json()
 
     def update_file_in_modeler(self, file_id, data):
         endpoint = f"files/{file_id}"
         return self.http.patch(endpoint=endpoint, json=data).json()
+
+    def create_milestone_in_modeler(self, data):
+        endpoint = "milestones"
+        return self.http.post(endpoint=endpoint, json=data).json()
```

## mpyl/steps/deploy/bpm/modeler.py

```diff
@@ -1,29 +1,35 @@
 """Camunda modeler related methods to deploy diagrams"""
 
 import os
+from datetime import datetime
 from logging import Logger
 from collections import namedtuple
 from .camunda_modeler_client import CamundaModelerClient
 
 File = namedtuple("File", ["name", "file_id", "revision"])
 
 
 def deploy_diagram_to_modeler(
-    logger: Logger, bpm_file_path: str, project_id: str, client: CamundaModelerClient
+    logger: Logger,
+    bpm_file_path: str,
+    project_id: str,
+    client: CamundaModelerClient,
+    pr_number: str,
 ) -> None:
     for file_name in (
         [fn for fn in os.listdir(bpm_file_path) if fn.endswith(".bpmn")]
         if os.path.isdir(bpm_file_path)
         else []
     ):
         logger.info(f"Updating diagram: {file_name}")
         file_info = get_file_data(file_name, project_id, client)
         file_path = os.path.join(bpm_file_path, file_name)
         update_diagram(file_path, file_info, client)
+        create_milestone(file_info, pr_number, client)
 
 
 def get_file_data(
     file_name: str, project_id: str, client: CamundaModelerClient
 ) -> File:
     search_name = file_name.replace("-", " ").rstrip(".bpmn")
     request = {
@@ -53,7 +59,21 @@
     if content is not None:
         request = {
             "name": file_data.name,
             "content": content,
             "revision": file_data.revision,
         }
         client.update_file_in_modeler(file_data.file_id, request)
+
+
+def create_milestone(
+    file_data: File, pr_number: str, client: CamundaModelerClient
+) -> None:
+    current_date_time = datetime.now()
+    formatted_date_time = current_date_time.strftime("%Y%m%d%H%M")
+    milestone_name = formatted_date_time + "-" + pr_number
+    request = {
+        "name": milestone_name,
+        "fileId": file_data.file_id,
+    }
+
+    client.create_milestone_in_modeler(request)
```

## mpyl/steps/deploy/k8s/chart.py

```diff
@@ -1,11 +1,12 @@
 """
 Data classes for the composition of Custom Resource Definitions.
 More info: https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/
 """
+
 import itertools
 from dataclasses import dataclass
 from typing import Optional
 
 from kubernetes.client import (
     V1Deployment,
     V1Container,
@@ -55,14 +56,15 @@
     V1SparkApplication,
 )
 from .resources.traefik import (
     V1AlphaIngressRoute,
     V1AlphaMiddleware,
     HostWrapper,
 )  # pylint: disable = no-name-in-module
+from ... import deploy
 from ...models import Input
 from ....project import (
     Project,
     KeyValueProperty,
     Probe,
     Deployment,
     TargetProperty,
@@ -415,28 +417,28 @@
             metadata=self._to_object_meta(),
             schedule=self._get_job().cron.get_value(self.target)["schedule"],
             body=to_spark_body(
                 project_name=self.release_name,
                 env_vars=get_env_variables(self.project, self.target),
                 spark=self._get_job().spark,
                 image=self._get_image(),
-                command=self.project.kubernetes.command.get_value(self.target).split(
-                    " "
-                )
-                if self.project.kubernetes.command
-                else None,
+                command=(
+                    self.project.kubernetes.command.get_value(self.target).split(" ")
+                    if self.project.kubernetes.command
+                    else None
+                ),
                 env_secret_key_refs={
                     s.key: {"key": s.key, "name": self.release_name}
                     for s in self.sealed_secrets
                 },
-                num_replicas=self.project.kubernetes.resources.instances.get_value(
-                    self.target
-                )
-                if self.project.kubernetes.resources.instances
-                else 1,
+                num_replicas=(
+                    self.project.kubernetes.resources.instances.get_value(self.target)
+                    if self.project.kubernetes.resources.instances
+                    else 1
+                ),
             ),
         )
 
     def to_spark_config_map(self) -> V1ConfigMap:
         return V1ConfigMap(
             api_version="v1",
             kind="ConfigMap",
@@ -495,17 +497,19 @@
             )
 
         return [
             HostWrapper(
                 traefik_host=host,
                 name=self.release_name,
                 index=idx,
-                service_port=host.service_port
-                if host.service_port
-                else self.__find_default_port(),
+                service_port=(
+                    host.service_port
+                    if host.service_port
+                    else self.__find_default_port()
+                ),
                 white_lists=to_white_list(host.whitelists),
                 tls=host.tls.get_value(self.target) if host.tls else None,
                 insecure=host.insecure,
             )
             for idx, host in enumerate(hosts if hosts else default_hosts)
         ]
 
@@ -699,28 +703,31 @@
     def _get_env_vars(self):
         raw_env_vars = self.extract_raw_env(self.target, self.env)
         pr_identifier = (
             None
             if self.step_input.run_properties.versioning.tag
             else self.step_input.run_properties.versioning.pr_number
         )
+
         processed_env_vars = substitute_namespaces(
-            raw_env_vars,
-            {project.to_name for project in self.step_input.run_properties.projects},
-            {
+            env_vars=raw_env_vars,
+            all_projects={
+                project.to_name for project in self.step_input.run_properties.projects
+            },
+            projects_to_deploy={
                 project_execution.project.to_name
-                for project_execution in self.step_input.run_properties.projects_to_deploy
+                for project_execution in self.step_input.run_properties.run_plan.get_projects_for_stage_name(
+                    deploy.STAGE_NAME, use_full_plan=True
+                )
             },
-            pr_identifier,
+            pr_identifier=pr_identifier,
         )
-
         env_vars = [
             V1EnvVar(name=key, value=value) for key, value in processed_env_vars.items()
         ]
-
         secrets = self._create_secret_env_vars(self.secrets)
 
         return env_vars + self.get_sealed_secret_as_env_vars() + secrets
 
     @property
     def is_cron_job(self) -> bool:
         return self._get_job().cron is not None
```

## mpyl/utilities/bpm/__init__.py

```diff
@@ -1,12 +1,14 @@
 """Configuration required for running bpm"""
 
 import os
 from dataclasses import dataclass
-from ...project import Project, Target, TargetProperty
+
+from ...steps.models import RunProperties
+from ...project import Project, TargetProperty
 
 
 @dataclass(frozen=True)
 class CamundaModelerAPI:
     base_url: str
     token_url: str
 
@@ -80,31 +82,33 @@
 @dataclass(frozen=True)
 class CamundaConfig:
     modeler_api: CamundaModelerAPI
     modeler_credentials: CamundaModelerCredentials
     zeebe_credentials: CamundaZeebeCredentials
     depolyment_path: CamundaDeploymentPath
     project_id: str
+    pr_number: str
 
     @staticmethod
-    def from_config(config: dict, target: Target, project: Project):
-        camunda_config = config.get("camunda")
+    def from_config(properties: RunProperties, project: Project):
+        camunda_config = properties.config.get("camunda")
         if not camunda_config:
             raise KeyError("Camunda section needs to be defined in mpyl_config.yml")
 
         modeler_urls = camunda_config.get("modelerAPI")
         modeler_credentials = camunda_config.get("modelerCredentials")
         zeebe_credentials = TargetProperty.from_config(
             camunda_config.get("zeebeCredentials")
-        ).get_value(target)
+        ).get_value(properties.target)
         deploy_path = camunda_config.get("camundaDeploymentPath")
         return CamundaConfig(
             modeler_api=CamundaModelerAPI.from_config(modeler_urls),
             modeler_credentials=CamundaModelerCredentials.from_config(
                 modeler_credentials
             ),
             zeebe_credentials=CamundaZeebeCredentials.from_config(zeebe_credentials),
             depolyment_path=CamundaDeploymentPath.from_config(
                 deploy_path, project.root_path
             ),
             project_id=str(project.bpm.project_id),
+            pr_number=str(properties.versioning.pr_number),
         )
```

## mpyl/utilities/cypress/__init__.py

```diff
@@ -13,17 +13,20 @@
 
     @staticmethod
     def from_config(config: dict):
         cypress_config = config.get("cypress")
         if not cypress_config:
             raise KeyError("Cypress section needs to be defined in mpyl_config.yml")
 
+        ci_build_id = (
+            cypress_config.get("ciBuildId", None)
+            or f"local{str(uuid.uuid4().int)[:10]}"
+        ).replace(" ", "")
+
         return CypressConfig(
             cypress_source_code_path=cypress_config.get("cypressSourceCodePath"),
             record_key=cypress_config.get("recordKey"),
             kubectl_config_path=cypress_config.get(
                 "kubectlConfigPath", "~/.kube/config"
             ),
-            ci_build_id=cypress_config.get(
-                "ciBuildId", f"local{str(uuid.uuid4().int)[:10]}"
-            ).replace(" ", ""),
+            ci_build_id=ci_build_id,
         )
```

## mpyl/utilities/subprocess/__init__.py

```diff
@@ -38,24 +38,20 @@
 
         with subprocess.Popen(command, stdout=subprocess.PIPE, text=True) as process:
             if not process.stdout:
                 raise RuntimeError(
                     f"Process {command_argument} does not have an stdout"
                 )
 
-            for line in iter(process.stdout.readline, ""):
-                if line:
-                    stripped_line = line.rstrip()
-                    if use_print:
-                        print(stripped_line)
-                    else:
-                        logger.info(try_parse_ansi(stripped_line))
+            for line in process.stdout:
+                if use_print:
+                    print(line)
+                else:
+                    logger.info(try_parse_ansi(line))
 
-                if process.poll() is not None:
-                    break
             success = process.wait() == 0
             if not success:
                 if process.stderr:
                     logger.warning(f"{SUBPROCESS_FAILED} with {process.stderr.read()}")
                 return Output(success=False, message=SUBPROCESS_FAILED)
 
             return Output(success=True, message="Subprocess executed successfully")
```

## Comparing `mpyl-1.6.6.dist-info/LICENSE` & `mpyl-1.6.7.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mpyl-1.6.6.dist-info/METADATA` & `mpyl-1.6.7.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mpyl
-Version: 1.6.6
+Version: 1.6.7
 Summary: Modular Pipeline Library
 Home-page: https://vandebron.github.io/mpyl
 Author: Vandebron Energie BV
 Project-URL: Documentation, https://vandebron.github.io/mpyl
 Project-URL: Source, https://github.com/Vandebron/mpyl
 Project-URL: Tracker, https://github.com/Vandebron/mpyl/issues
 Classifier: Topic :: Software Development :: Build Tools
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: mpyl Version: 1.6.6 Summary: Modular Pipeline
+Metadata-Version: 2.1 Name: mpyl Version: 1.6.7 Summary: Modular Pipeline
 Library Home-page: https://vandebron.github.io/mpyl Author: Vandebron Energie
 BV Project-URL: Documentation, https://vandebron.github.io/mpyl Project-URL:
 Source, https://github.com/Vandebron/mpyl Project-URL: Tracker, https://
 github.com/Vandebron/mpyl/issues Classifier: Topic :: Software Development ::
 Build Tools Classifier: Topic :: Utilities Classifier: Development Status :: 4
 - Beta Classifier: Environment :: Console Classifier: Intended Audience ::
 Developers Classifier: Operating System :: OS Independent Classifier:
```

## Comparing `mpyl-1.6.6.dist-info/RECORD` & `mpyl-1.6.7.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,77 +1,77 @@
 mpyl/__init__.py,sha256=HlZIRNAbavyw8lK4tDqSdSRTQE3aFkibc3n0pkrqaQc,1200
 mpyl/__main__.py,sha256=2c9boQJDUA6b8p2umOych7HHlwmBdmsIQDLZcE_pBdo,215
-mpyl/build.py,sha256=9lC93QNhm9NigF0c96WYAgbJ2eVf8kqa4EWIGZC6v9A,7630
+mpyl/build.py,sha256=g8re11FT7ZNKK8EGGW1HBfvrcpNBGL4S_MkS51WmmrM,6384
 mpyl/constants.py,sha256=jIcpytI9cpIB7dFo87ct8G6BaGevsDC2pNpvXE0ugkA,304
 mpyl/project.py,sha256=kGVtqf5bVjiR1OS8ZYJs-32luLLQWabF5Hia-dNobIs,21281
 mpyl/project_execution.py,sha256=6e8YTqEgbvReZMAqC4WUzghlQA_3EKwqHLPhsem7lCw,997
 mpyl/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mpyl/run_plan.py,sha256=mtuhBo4JisQYmsUuM4PbT5Jtz7smE8UzsaFE44Oee1Q,1038
+mpyl/run_plan.py,sha256=1NOd42ett8HTux2l2KKeKIQWdQ2-GWozBrLfshBSfDY,2796
 mpyl/validation.py,sha256=Cps5Y_kPD2asBY13wG4G1xxrrM2Xi_EWr37sFXK9f18,2370
 mpyl/artifacts/__init__.py,sha256=0KjD4BVqH5WVi9Rma5R6FsJN9hAcc5u-gNRRYUn945s,60
 mpyl/artifacts/build_artifacts.py,sha256=qm7E2fvSgApCDXZskMPf0ATk1pGBooegFsoyM957k2A,9222
-mpyl/cli/__init__.py,sha256=W0cVhHL0_HrQqtyg-t-TCoD5eYnpcSCNPU8sR6p8eO4,3512
+mpyl/cli/__init__.py,sha256=6HRmnyrjKkW-l3evobfue179o4OIlyCMfLkpS4GSkMI,3513
 mpyl/cli/build.py,sha256=_Ch5oyWeXqllM8mpFSsKhqRyfSC1fJRmFz0d8neBKvQ,17847
 mpyl/cli/health.py,sha256=z0dMZcVM0tZlKKHzCX5qgdIczaDaPx1_JI4SCh6S91A,614
 mpyl/cli/meta_info.py,sha256=a4-M9D_aaddup4Z2gF34WkmsHBzxQECJb8UNit0q6Po,2417
-mpyl/cli/projects.py,sha256=uIbUSKaa-dWNuiClyy3nVi4r6DUbzP5n8cUZeVD_c7M,8536
+mpyl/cli/projects.py,sha256=qtcBKCcJ0rV1MtVbxHMm2Asd8kcoMQLC0VqybSHLn0A,9013
 mpyl/cli/commands/__init__.py,sha256=DaL5q4ibFJT7EMlgcQBSpAaaQNiBqnSJZ2WIKtPzLJk,34
 mpyl/cli/commands/build/__init__.py,sha256=yvYblWUNG8vEvU-CT2NSNX6aLUxcKU1Ndw2ZHWZez50,425
 mpyl/cli/commands/build/artifacts.py,sha256=RfprLCJtEzyoy0QlCvyK7boOu8uPZBzGlmUbnStYzHk,1261
 mpyl/cli/commands/build/jenkins.py,sha256=_NQn_5hr2luKhrmWI5_u-nusxSn4QvDrgLHPKeHGO0Q,4524
 mpyl/cli/commands/health/__init__.py,sha256=Bx6QcWIN-EadbpSe1XAXs1aYCD7Ad8_t3lWRlGDsIr0,38
 mpyl/cli/commands/health/checks.py,sha256=Stx0XCJWFVfmh-BWDWeIGMANTSUCJyFW_0advr1d7tQ,8248
 mpyl/cli/commands/projects/__init__.py,sha256=ZJtZz1CwcJerE3K-wz6DeWzxBUKP5gEHgQTkwpnvXhY,52
 mpyl/cli/commands/projects/formatting.py,sha256=Ph1ZMF1XE880XOXM54G_3MEFjjZN4wabQOtmJLJXR9E,1771
-mpyl/cli/commands/projects/lint.py,sha256=t3HICC4jYjT4UgjjFhI0riJJO58QWFCK1n5cpqInhtY,6356
+mpyl/cli/commands/projects/lint.py,sha256=0tbbCzmn_DH02KzucRuq3Bl6nd994Swnfc0E2sO5tLM,6813
 mpyl/cli/commands/projects/upgrade.py,sha256=4TUv-IyNzmL-Ehc1R05zAyU6gvOILnaoYs9ASVZjHt4,659
 mpyl/projects/__init__.py,sha256=31HPF5jDZK5UkQT8Zw0V0QSJLqzp8f2zFiWd-QkDjRE,620
 mpyl/projects/find.py,sha256=gQwSu4F0FzWDn6YJWBDuo97OZfL3Fj_iQKAARX0b6oY,2006
 mpyl/projects/versioning.py,sha256=vFet-3hp-toe_tDRYQ-9M321UXzBGvuAS4oLMXVvPTg,12121
-mpyl/projects/releases/releases.txt,sha256=5ILpITACHRZZh22joapyfXy_3GLLsSXK6_K-tNcNNTM,345
+mpyl/projects/releases/releases.txt,sha256=bcq22FKxze4yZItOSMZ_bGekpT9N62OsGrijyT3D2q4,351
 mpyl/reporting/__init__.py,sha256=vRvt_67opWXCfe_zYZChT-YhjoPOahAjLagoaVzOcFM,92
 mpyl/reporting/formatting/__init__.py,sha256=GAvYJpHT2SMQxjiLCSqFy57PNWsGI_Ow2bFnA8cX08k,76
-mpyl/reporting/formatting/markdown.py,sha256=ZoM3Ep_m-wsqP3afTq8pybk3G7viP4MRFPD-fLtmEjI,5797
+mpyl/reporting/formatting/markdown.py,sha256=td9JXmQv1COyYTmXo-7FB41NNTIedgWLvpkCCjF_SGg,5831
 mpyl/reporting/formatting/text.py,sha256=-_GFebP6KffJA1eS3RvGFHsH7k8EOkkvjVcnRlqNFYo,1340
 mpyl/reporting/targets/__init__.py,sha256=31UWFweqJqvlE3WZBb2CMBIAnmJJRZpVBwpW-ma4MzA,1139
 mpyl/reporting/targets/github.py,sha256=IOjnWqV6QO6wAWMuVB8Nbxws7U9sUqBhgVJSJEzFkgE,8932
 mpyl/reporting/targets/jira.py,sha256=PE60WdezLBEvq8rbcpQEg0XgQ8MFmFX8agtB9SolISc,9568
 mpyl/reporting/targets/slack.py,sha256=fcvywqWCkdzVl0YWe1jGGq52jC5ePxQg9Qw8_YByTjk,8064
 mpyl/schema/k8s_api_core.schema.yml,sha256=9bPsgRIHa2AvJjXUDqSjEgIpU-tb2YXAAt64wD4YqBo,11326
 mpyl/schema/mpyl_config.schema.yml,sha256=ZUTlKRQrnZXtVnEXRFniZFxAD_8ScLHKeeG9FB9FrBA,14733
 mpyl/schema/project.schema.yml,sha256=CMDT-P4aEOkqJx2Z_pmC_V9r1PtA8D1NwT39l-NeCBk,24934
 mpyl/schema/run_properties.schema.yml,sha256=hsBJcz9_n9PBAYbSSWsOvJdPIrhJv_B9JQdx0lVfUf4,3296
 mpyl/stages/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mpyl/stages/discovery.py,sha256=vZkJmWm6T7ZtjxymroLS1i3VeMhcwDcwG1-ywiLO1Eo,12809
+mpyl/stages/discovery.py,sha256=hLZXv6VjhDW5fxyojgPmPCq0KhpR9s6hfKZBx1_4nco,12955
 mpyl/steps/__init__.py,sha256=CwtgCMMbTJZjIiu4RVZonfEpqwMb2WqU4nHnqA-TCEM,6456
 mpyl/steps/collection.py,sha256=12848xJvrCuNBtf7U33EHw733BuTTZPAZzSOW0PSoX0,2686
-mpyl/steps/models.py,sha256=fcpbUKupe-sXEjgxWSxUG4rohpogL8EvBF2P4EKtbGE,8465
-mpyl/steps/run.py,sha256=3xn3rRczDh5l5P4YU9Bu9SO0pE1-jU1F1vE1rKTdfq4,4320
+mpyl/steps/models.py,sha256=gDq8N6m0dHoF6hV5snpnZEkJ2rO98YY_A678MKXNkYk,8196
+mpyl/steps/run.py,sha256=a3B07_0uaXTUQ7TE36-d6yQDIX4zcLzDnJQsi40z5jw,3861
 mpyl/steps/run_properties.py,sha256=ICrbx27RxyxLO5u8O5m84yEks7cZhijE5h_mIfyFes0,3853
 mpyl/steps/steps.py,sha256=-mvIAYw9DdpvXNXjhiM7LqJxAfOHtPQRQndxw8MqOeg,9692
 mpyl/steps/build/__init__.py,sha256=Q5BL1Bv5PrZkYBNbQvVNTL-n4Xq88qwtc3PtYunrc5c,80
 mpyl/steps/build/docker_build.py,sha256=6HZnL9PtdXAFVfblwf9R9E-_GzaE2K4xWICPV3YOY0E,5034
 mpyl/steps/build/echo.py,sha256=T5uJ0L43bVNZenJtVr4j0HgIMDr10v5Oaypu9W1VHG8,1195
 mpyl/steps/build/post_docker_build.py,sha256=aWlGo9ib4pGJwme6m97t5ORvuWNYSQAo0ssLMo_qjzI,2192
 mpyl/steps/build/sbt.py,sha256=riIyv5tY3hQdCXVbxsxzGoPMIG_0CsNY5EAsqOsyNvs,2714
 mpyl/steps/build/skip.py,sha256=71QJYYjJ5HL8Q2a9pB8ai9mTzTrL7yWQ_-DD2pLWRao,884
 mpyl/steps/deploy/__init__.py,sha256=PApoomqJGBtOt-08vVKjHVJTs2JHRWWF93Y2wFI0lN0,82
-mpyl/steps/deploy/bpm_deploy.py,sha256=iicjNYYhY7QL5JVENQrk2Dgduzjvd2r1b0qyGXa6jdg,2172
+mpyl/steps/deploy/bpm_deploy.py,sha256=7Kr7jyy86RiC7JlIDe0Gm-zrDjQV33RivMGKXrLIDKU,2119
 mpyl/steps/deploy/dagster.py,sha256=wpb5FAait7ZXvjucf0ZlAnrELsQwmr5Y23SLwODQ1ZM,7596
 mpyl/steps/deploy/echo.py,sha256=Z6iL3icoxteiFWQkTppHfQAuP7B18lcu3ZJZqg6ssaM,1078
 mpyl/steps/deploy/ephemeral_docker_deploy.py,sha256=Wvz5C5CNaD0jdMTj8LZgZ325Ih0NeRl8_o8mc1Y8RQI,1533
 mpyl/steps/deploy/kubernetes.py,sha256=HzsLU7Ucowr2D_PIYFTPFADXTHDPdJF-g4N639h6mz4,3221
 mpyl/steps/deploy/kubernetes_job.py,sha256=r2pBuEMJ-WOcfHH3HZzQ5wG3tqwGSBnbB5ByapbwQvw,1115
 mpyl/steps/deploy/kubernetes_spark_job.py,sha256=_PJXQtnQ4TRgQj73vWEw6W6kIxD2DYCCo2Z0jjppfy4,1188
-mpyl/steps/deploy/bpm/__init__.py,sha256=PHHUkyRXkVEuJhcRDlazefAGmm4WaoK8akYlD3nDJ7E,2442
-mpyl/steps/deploy/bpm/camunda_modeler_client.py,sha256=soUEuALHeOTcZZv5P955TK_1O7S44Of7nVnO_CES8xw,1731
+mpyl/steps/deploy/bpm/__init__.py,sha256=IUFMYk5b1HSnL5NSTR-q_YcVGS02ejRnzU3c4FyzTV4,2486
+mpyl/steps/deploy/bpm/camunda_modeler_client.py,sha256=z41sz67Uzc0PjaPsitlV79P2TcS5IuZUd3wtDJF_xBk,1880
 mpyl/steps/deploy/bpm/cluster.py,sha256=0z0LxiwnVEGQD3cxBJlZt87wztXiyz1LBLt-6P_lnTQ,2280
-mpyl/steps/deploy/bpm/modeler.py,sha256=0rhWFwvhW2Zoe9Qm-oeAROC55WDxHcrFgGNBJPRvyWw,1818
+mpyl/steps/deploy/bpm/modeler.py,sha256=FFL14toOGOF8N39wSTXqNW-SZ0NUeGwbZ0MVtILTeU4,2342
 mpyl/steps/deploy/k8s/__init__.py,sha256=l5RxShdkdXs2nTTNK7GvWmciTyqwvuPhDV2-dERjLUY,11433
-mpyl/steps/deploy/k8s/chart.py,sha256=K0pPYS6NfNxLtDZMhNZk2Cdz3PeZCrm46VWjKthtx6k,28949
+mpyl/steps/deploy/k8s/chart.py,sha256=o5K_fDaaTvzCtfrpRiRfN8cGAxYdPVq0PWaXR-4sBJo,29220
 mpyl/steps/deploy/k8s/deploy_config.py,sha256=haNB4oBieRLUVgFTCB-J1xcYJSaCX3EeqeqSCDvvSJ0,1276
 mpyl/steps/deploy/k8s/helm.py,sha256=VQ474ZRpwPvQS9XtILEWdoZdtHV_Q7GhCmNoSFL7lXQ,5080
 mpyl/steps/deploy/k8s/rancher.py,sha256=lJsPWM0l9EWH7YkH4QO6Hk38ZigQ42V7EHNmOvEDw5k,1594
 mpyl/steps/deploy/k8s/resources/__init__.py,sha256=Kn31han_zOgVMW9ElN47YEqi4RlZG63LJcklISxl4Ew,4868
 mpyl/steps/deploy/k8s/resources/dagster.py,sha256=NuN_EMduakIEIEv-c2i-cI0lfHXjlxDVCszIo3gQvNc,3368
 mpyl/steps/deploy/k8s/resources/prometheus.py,sha256=TKhgHbl8i8wbGgYWjZ5S6OnQ1l0P0oLN1EypJL5Sw00,2260
 mpyl/steps/deploy/k8s/resources/sealed_secret.py,sha256=af8zae2HVCnT51aEq_3kKVHp86gf8UpzDWM87jSQoJ4,616
@@ -89,31 +89,31 @@
 mpyl/steps/test/after_test.py,sha256=VCVWogXbuyaKOMu8jjOJWpZovBU7r4DgFSZQPY0xUIA,1574
 mpyl/steps/test/before_test.py,sha256=RgoNlwnzWM8O7cOPR6rE7_Z8E6M6cYmXFFuU9Au4wtI,4153
 mpyl/steps/test/dockertest.py,sha256=aXITeWyZR14v4cGiCd-hE-5efyjnnXcfI7Rjn28rpCM,4652
 mpyl/steps/test/echo.py,sha256=0wfvRbmyFIHvrPjSzlVRGCzAvaTOFbFJzWqIQs3obLQ,1937
 mpyl/steps/test/sbt.py,sha256=KxMLcHIN72oEV3j3hn8O3X-IHycap3BY-omxXDTzrGc,3636
 mpyl/steps/test/skip.py,sha256=WNoF2MXBH8sBgc0gVo5Ityc753vIFtMjKpiPwLOIlOM,878
 mpyl/utilities/__init__.py,sha256=-FhhMEriPoXTlrxyF9D48XpgjRfRy_KeLGkGAUsqre8,346
-mpyl/utilities/bpm/__init__.py,sha256=LgTBb_e--XZ3107RVe1pZ6K5uThPidbFG4wZN0vKINM,3502
-mpyl/utilities/cypress/__init__.py,sha256=VQZtP7hiFhRNr0jIAutomuL0yjdEY1mWQLqhzC1ZRVA,953
+mpyl/utilities/bpm/__init__.py,sha256=LwKm95jBukQnRJZeep12Zb5z_gEeAeTH9BbNVc_Dq2c,3635
+mpyl/utilities/cypress/__init__.py,sha256=noupFN9WpfwulTkIDxb3rbcif69KlDnDrNWMHhigTQM,1002
 mpyl/utilities/dagster/__init__.py,sha256=33zcIJaNyeXAy-o_eDcRjLOLsc8wKquxj4Ffppvgu_c,1068
 mpyl/utilities/docker/__init__.py,sha256=JIw48UE0yfCryvTEYWsbHC87Zl-JVPmztNdgKW1BkmE,13237
 mpyl/utilities/github/__init__.py,sha256=9BGCEw96HOHkQGWpZmBbmPrduCH2Zj0idNKLeZPQK2A,1938
 mpyl/utilities/helm/__init__.py,sha256=PrC06s5DEQ7USeMwxzJqzrNtzGaIroD79fqjMpuqa-c,1034
 mpyl/utilities/http_client/__init__.py,sha256=BftHKe-qd1ymDjfb5gmQm3MeLfix-iQqUpz1-Pjnq8M,2786
 mpyl/utilities/http_client/exceptions.py,sha256=Uy1y2FvxwstvlNJXsoxp0O9hqxm09iq9Ao9XjI3gpoE,692
 mpyl/utilities/jenkins/__init__.py,sha256=8MCGdWLCX0oU2FhIfYHM2GIxPKX9lr6sUgdCpSbz_zE,1566
 mpyl/utilities/jenkins/runner.py,sha256=Vfc92TeYVtG_o5oOtTZSW1x91m1JEmkFC1SyvVyrpTs,7910
 mpyl/utilities/junit/__init__.py,sha256=BYNX6l0NG_8RrRPUyKS6cqpEb2myXTzv2Z8nCej_CYg,1598
 mpyl/utilities/logging/__init__.py,sha256=CgcGcy44WdScwOo4ncONIUcm47EA1SUMZrXHe4qjepk,318
 mpyl/utilities/parallel/__init__.py,sha256=3pyODnVMj_ecFvzGgh6wmJn95XlxWi91pau3-6A_Hmo,1003
 mpyl/utilities/pyaml_env/__init__.py,sha256=NqinyF-ULX69X48pgLpcmm46JB0o2nPxERi5bruMs48,870
 mpyl/utilities/repo/__init__.py,sha256=Yy100mBhyzrj7YhS-sk2f_b2KkkX9C54itLhohkp_AE,9632
 mpyl/utilities/sbt/__init__.py,sha256=JJf1FU8JSyQhKaR78OEAup1VBXOLqNKf3tROtp54gAM,1589
-mpyl/utilities/subprocess/__init__.py,sha256=UeaVmVF1spnkLKnNWzF_9GMVM2WJ4WwOPeb2T6NdlAc,2573
+mpyl/utilities/subprocess/__init__.py,sha256=Y0SK5FlJiucevRzgJfTU8AGzyUaRHvSJfXI6-ulqUX0,2372
 mpyl/utilities/yaml/__init__.py,sha256=gjNnyh_TwgOfGGIZa5hN5VzRibuzlo1L1dOHeCD1CW4,868
-mpyl-1.6.6.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-mpyl-1.6.6.dist-info/METADATA,sha256=cCVxOZceMTx1za8DDfcV-KFnGb0LNY0mwFY2nPxQLNg,6195
-mpyl-1.6.6.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-mpyl-1.6.6.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
-mpyl-1.6.6.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
-mpyl-1.6.6.dist-info/RECORD,,
+mpyl-1.6.7.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+mpyl-1.6.7.dist-info/METADATA,sha256=Q03eD7UxVTavlq9hWnKSQOl7GgR_rR64i6eIv7cwbec,6195
+mpyl-1.6.7.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+mpyl-1.6.7.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
+mpyl-1.6.7.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
+mpyl-1.6.7.dist-info/RECORD,,
```

