# Comparing `tmp/scAtlasVAE-1.0.3a5-py3-none-any.whl.zip` & `tmp/scAtlasVAE-1.0.3a6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,17 +1,17 @@
-Zip file size: 57047 bytes, number of entries: 34
+Zip file size: 58919 bytes, number of entries: 34
 -rw-r--r--  2.0 unx      890 b- defN 24-Jan-04 15:25 scatlasvae/__init__.py
 -rw-r--r--  2.0 unx     1420 b- defN 23-Nov-22 14:20 scatlasvae/_metadata.py
--rw-r--r--  2.0 unx       19 b- defN 24-Apr-11 08:08 scatlasvae/_version.py
+-rw-r--r--  2.0 unx       19 b- defN 24-May-07 04:55 scatlasvae/_version.py
 -rw-r--r--  2.0 unx       74 b- defN 24-Feb-14 07:00 scatlasvae/data/__init__.py
 -rw-r--r--  2.0 unx     1549 b- defN 24-Feb-14 07:03 scatlasvae/data/_dataloader.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-04 13:38 scatlasvae/externals/__init__.py
 -rw-r--r--  2.0 unx     1924 b- defN 23-Dec-04 13:38 scatlasvae/externals/_trvae_mmd_loss.py
 -rw-r--r--  2.0 unx       86 b- defN 23-Nov-24 03:53 scatlasvae/model/__init__.py
--rw-r--r--  2.0 unx    93694 b- defN 24-Apr-11 07:58 scatlasvae/model/_gex_model.py
+-rw-r--r--  2.0 unx    95069 b- defN 24-May-30 06:52 scatlasvae/model/_gex_model.py
 -rw-r--r--  2.0 unx    31170 b- defN 24-Mar-15 04:57 scatlasvae/model/_primitives.py
 -rw-r--r--  2.0 unx       41 b- defN 23-Nov-22 14:14 scatlasvae/pipeline/__init__.py
 -rw-r--r--  2.0 unx     8777 b- defN 23-Dec-04 13:45 scatlasvae/pipeline/_pipeline.py
 -rw-r--r--  2.0 unx      127 b- defN 23-Nov-22 14:24 scatlasvae/preprocessing/__init__.py
 -rw-r--r--  2.0 unx     3255 b- defN 24-Apr-09 07:43 scatlasvae/preprocessing/_infercnv.py
 -rw-r--r--  2.0 unx    35547 b- defN 24-Jan-02 15:36 scatlasvae/preprocessing/_preprocess.py
 -rw-r--r--  2.0 unx       78 b- defN 24-Jan-05 06:06 scatlasvae/tools/__init__.py
@@ -20,17 +20,17 @@
 -rw-r--r--  2.0 unx      162 b- defN 24-Jan-04 15:28 scatlasvae/utils/__init__.py
 -rw-r--r--  2.0 unx      439 b- defN 23-Nov-22 14:22 scatlasvae/utils/_compat.py
 -rw-r--r--  2.0 unx     2356 b- defN 23-Nov-22 14:12 scatlasvae/utils/_decorators.py
 -rw-r--r--  2.0 unx     4339 b- defN 24-Jan-04 15:29 scatlasvae/utils/_definitions.py
 -rw-r--r--  2.0 unx    10679 b- defN 23-Nov-22 14:21 scatlasvae/utils/_distributions.py
 -rw-r--r--  2.0 unx     4791 b- defN 24-Mar-21 12:50 scatlasvae/utils/_logger.py
 -rw-r--r--  2.0 unx     7995 b- defN 24-Mar-22 07:27 scatlasvae/utils/_loss.py
--rw-r--r--  2.0 unx     5680 b- defN 23-Nov-22 14:18 scatlasvae/utils/_parallelizer.py
+-rw-r--r--  2.0 unx    11078 b- defN 24-May-25 13:42 scatlasvae/utils/_parallelizer.py
 -rw-r--r--  2.0 unx     1081 b- defN 23-Nov-22 14:12 scatlasvae/utils/_tensor_utils.py
 -rw-r--r--  2.0 unx     6611 b- defN 24-Mar-22 04:24 scatlasvae/utils/_utilities.py
--rw-r--r--  2.0 unx     1522 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/LICENSE
--rw-r--r--  2.0 unx     1355 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/WHEEL
--rw-r--r--  2.0 unx       39 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/dependency_links.txt
--rw-r--r--  2.0 unx       11 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2941 b- defN 24-Apr-11 12:05 scAtlasVAE-1.0.3a5.dist-info/RECORD
-34 files, 239504 bytes uncompressed, 52289 bytes compressed:  78.2%
+-rw-r--r--  2.0 unx     1522 b- defN 24-May-30 08:15 scAtlasVAE-1.0.3a6.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1355 b- defN 24-May-30 08:15 scAtlasVAE-1.0.3a6.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-30 08:15 scAtlasVAE-1.0.3a6.dist-info/WHEEL
+-rw-r--r--  2.0 unx       39 b- defN 24-May-30 08:14 scAtlasVAE-1.0.3a6.dist-info/dependency_links.txt
+-rw-r--r--  2.0 unx       11 b- defN 24-May-30 08:14 scAtlasVAE-1.0.3a6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2942 b- defN 24-May-30 08:15 scAtlasVAE-1.0.3a6.dist-info/RECORD
+34 files, 246278 bytes uncompressed, 54161 bytes compressed:  78.0%
```

## zipnote {}

```diff
@@ -78,26 +78,26 @@
 
 Filename: scatlasvae/utils/_tensor_utils.py
 Comment: 
 
 Filename: scatlasvae/utils/_utilities.py
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a5.dist-info/LICENSE
+Filename: scAtlasVAE-1.0.3a6.dist-info/LICENSE
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a5.dist-info/METADATA
+Filename: scAtlasVAE-1.0.3a6.dist-info/METADATA
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a5.dist-info/WHEEL
+Filename: scAtlasVAE-1.0.3a6.dist-info/WHEEL
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a5.dist-info/dependency_links.txt
+Filename: scAtlasVAE-1.0.3a6.dist-info/dependency_links.txt
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a5.dist-info/top_level.txt
+Filename: scAtlasVAE-1.0.3a6.dist-info/top_level.txt
 Comment: 
 
-Filename: scAtlasVAE-1.0.3a5.dist-info/RECORD
+Filename: scAtlasVAE-1.0.3a6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## scatlasvae/_version.py

```diff
@@ -1 +1 @@
-version = '1.0.3a5'
+version = '1.0.3a6'
```

## scatlasvae/model/_gex_model.py

```diff
@@ -53,15 +53,16 @@
     :param hidden_stacks: List[int]. Number of hidden units in each layer. Default: [128] (one hidden layer with 128 units)
     :param n_latent: int. Number of latent dimensions. Default: 10
     :param n_batch: int. Number of batch. Default: 0
     :param n_label: int. Number of label. Default: 0
     :param n_additional_batch: Optional[Iterable[int]]. Number of categorical covariate. Default: None
     :param batch_key: str. Batch key in adata.obs. Default: None
     :param label_key: str. Label key in adata.obs. Default: None
-    :param dispersion: Literal["gene", "gene-batch", "gene-cell"]. Dispersion method. Default: "gene-cell"
+    :param dispersion: Literal["gene", "gene-batch", "gene-cell"]. Dispersion modeling method. Default: "gene-cell"
+    :param rna_dropout: Literal["gene", "cell"]. RNA dropout modeling method. Default: "gene" models dropout at the gene level. Alternative: "cell" models dropout at the cell level.
     :param log_variational: bool. If True, log the variational distribution. Default: True
     :param total_variational: bool. If True, normalize the counts with library size. Default: False
     :param bias: bool. If True, use bias in the linear layer. Default: True
     :param use_batch_norm: bool. If True, use batch normalization. Default: True
     :param use_layer_norm: bool. If True, use layer normalization. Default: False
     :param batch_hidden_dim: int. Number of hidden units in the batch embedding layer. Default: 8
     :param batch_embedding: Literal["embedding", "onehot"]. Batch embedding method. Default: "batch_embedding"
@@ -92,19 +93,20 @@
        adata: Optional[sc.AnnData] = None,
        hidden_stacks: List[int] = [128],
        n_latent: int = 10,
        n_batch: int = 0,
        n_label: int = 0,
        n_additional_batch: Optional[Iterable[int]] = None,
        n_additional_label: Optional[Iterable[int]] = None,
-       batch_key = None,
-       additional_batch_keys = None, #TODO: deprecate in the future
-       label_key = None,
-       additional_label_keys = None, #TODO: deprecate in the future
+       batch_key: Union[str, Iterable[str]] = None,
+       additional_batch_keys: Iterable[str] = None, #TODO: deprecate in the future
+       label_key: Union[str, Iterable[str]] = None,
+       additional_label_keys: Iterable[str] = None, #TODO: deprecate in the future
        dispersion:  Literal["gene", "gene-batch", "gene-cell"] = "gene-cell",
+       rna_dropout: Literal["gene", "cell"] = "gene",
        log_variational: bool = True,
        total_variational: bool = False,
        bias: bool = True,
        use_batch_norm: bool = True,
        use_layer_norm: bool = False,
        batch_hidden_dim: int = 8,
        batch_embedding: Literal["embedding", "onehot"] = "embedding",
@@ -131,14 +133,20 @@
             device = get_default_device()
         
         super(scAtlasVAE, self).__init__()
         if adata.X.dtype != np.int32 and reconstruction_method in ['zinb', 'nb']:
             mw("adata.X is not of type np.int32. \n" + \
                 " "*40 + "\tCheck whether you are using raw count matrix.")
             # adata.X = adata.X.astype(np.int32)
+        if adata.is_view:
+            mw("adata is a view of another AnnData object. \n" + \
+                " "*40 + "This may cause slower training. \n" + \
+                " "*40 + "Use adata=adata.copy() to create a new AnnData object."
+            )
+
 
         self.adata = adata
         self.in_dim = adata.shape[1] if adata else -1
         self.n_hidden = hidden_stacks[-1]
         self.n_latent = n_latent
         self.n_additional_batch = n_additional_batch
         self.n_additional_label = n_additional_label
@@ -155,23 +163,25 @@
         self.batch_key = batch_key if isinstance(batch_key, str) else batch_key[0] if batch_key is not None and isinstance(batch_key, Iterable) else None
         self.batch_category = None 
         self.batch_category_summary = None 
         if additional_batch_keys is None:
             self.additional_batch_keys = None if isinstance(batch_key, str) or (isinstance(batch_key, Iterable) and len(batch_key) == 1) else batch_key[1:] if batch_key is not None else None
         else: 
             #TODO: deprecate in the future
+            mw("additional_batch_keys is going to be deprecated. Use batch_key as a List instead.")
             self.additional_batch_keys = additional_batch_keys
 
         self.additional_batch_category = None 
         self.additional_batch_category_summary = None 
 
         if additional_label_keys is None:
             self.additional_label_keys = None if isinstance(label_key, str) or (isinstance(label_key, Iterable) and len(label_key) == 1) else label_key[1:] if label_key is not None else None
         else:
             #TODO: deprecate in the future
+            mw("additional_label_keys is going to be deprecated. Use label_key as a List instead.")
             self.additional_label_keys = additional_label_keys
             
         self.additional_label_category = None 
         self.additional_label_category_summary = None 
 
 
         self.n_batch = n_batch
@@ -184,43 +194,50 @@
         self.reconstruction_method = reconstruction_method
         self.constrain_latent_embedding = constrain_latent_embedding
         self.constrain_latent_method = constrain_latent_method
         self.constrain_latent_key = constrain_latent_key
         self.constrain_n_label = constrain_n_label
         self.constrain_n_batch = constrain_n_batch
         self.low_memory_initialization = low_memory_initialization
+        if self.low_memory_initialization:
+            mw(
+                "low_memory_initialization is set to True. \n" + \
+                " "*40 + "This will reduce the memory usage during initialization,\n" + \
+                " "*40 + "but may significantly slow down the training and \n" + \
+                " "*40 + "not fully tested for all functionalities."
+            )
         self.device=device
 
         self.initialize_dataset()
 
         self.batch_embedding = batch_embedding
         if batch_embedding == "onehot":
             batch_hidden_dim = self.n_batch
         self.batch_hidden_dim = batch_hidden_dim
         self.inject_batch = inject_batch
         self.inject_label = inject_label
         self.inject_additional_batch = inject_additional_batch
         self.encode_libsize = encode_libsize
         self.decode_libsize = decode_libsize
         self.dispersion = dispersion
+        self.rna_dropout = rna_dropout
 
         
 
 
         self.fcargs = dict(
             bias           = bias,
             dropout_rate   = dropout_rate,
             use_batch_norm = use_batch_norm,
             use_layer_norm = use_layer_norm,
             activation_fn  = activation_fn,
             device         = device
         )
 
 
-
         #############################
         # Model Trainable Variables #
         #############################
 
         if self.dispersion == "gene":
             self.px_rate = torch.nn.Parameter(torch.randn(self.in_dim))
         elif self.dispersion == "gene-batch":
@@ -291,15 +308,19 @@
         )
 
         self.px_rna_rate_decoder = nn.Linear(self.n_hidden, self.in_dim)
         self.px_rna_scale_decoder = nn.Sequential(
             nn.Linear(self.n_hidden, self.in_dim),
             nn.Softmax(dim=-1)
         )
-        self.px_rna_dropout_decoder = Linear(self.n_hidden, self.in_dim, init='final')
+
+        if self.rna_dropout == "gene":
+            self.px_rna_dropout_decoder = Linear(self.n_hidden, self.in_dim, init='final')
+        elif self.rna_dropout == "cell":
+            self.px_rna_dropout_decoder = Linear(self.n_hidden, 1, init='final')
 
         if self.n_label > 0:
             self.fc = nn.Sequential(
                 nn.Linear(self.n_latent, self.n_label)
             )
 
         if self.n_additional_label is not None:
@@ -1325,15 +1346,15 @@
             x = self._dataset[x.cpu().numpy()]
             batch_index = None
             label_index = None
             if self.n_batch > 0 or self.n_label > 0:
                 if not isinstance(x, Iterable) and len(x) > 1:
                     raise ValueError()
                 if self.n_batch > 0 and self.n_label > 0:
-                    X, batch_index, label_index = get_k_elements(x,0), get_k_elements(x,1), get_k_elements(batch_data,2)
+                    X, batch_index, label_index = get_k_elements(x,0), get_k_elements(x,1), get_k_elements(x,2)
                 elif self.n_batch > 0:
                     X, batch_index = get_k_elements(x,0), get_k_elements(x,1)
                 elif self.n_label > 0:
                     X, label_index = get_k_elements(x,0), get_k_elements(x,1)
 
             if self.n_label > 0:
                 label_index = torch.tensor(label_index)
@@ -1444,15 +1465,15 @@
     def get_reconstructed_expression(self, k = 'px_rna_scale_orig', n_per_batch=256,show_progress=True) -> np.ndarray:
         self.eval()
         Zs = []
         X = self.as_dataloader(subset_indices = list(range(len(self._dataset))), shuffle=False, n_per_batch=n_per_batch)
         predictions = []
         additional_predictions = []
         if show_progress:
-            pbar = get_tqdm()(X, desc="Predicting Labels", bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')
+            pbar = get_tqdm()(X, desc="Reconstructing gene expression", bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')
 
         for x in X:
             X, P, batch_index, label_index, additional_label_index, additional_batch_index, lib_size = self._prepare_batch(x)
 
             _,R,_ = self.forward(
                 X,
                 lib_size,
```

## scatlasvae/utils/_parallelizer.py

```diff
@@ -7,14 +7,24 @@
     Any, Callable, Optional, Sequence, Union, Iterable
 )
 from joblib import delayed, Parallel
 import numpy as np
 from scipy.sparse import issparse
 import pandas as pd 
 
+from tqdm.contrib.concurrent import process_map, thread_map
+from tqdm.asyncio import tqdm as asyn_tqdm
+from multiprocessing import cpu_count
+import itertools 
+import scipy
+from scipy.sparse import csr_matrix
+from typing import Sequence, Tuple, Union, Optional, Callable
+# from ..utils._compat import Literal
+
+
 class Parallelizer:
     def __init__(self, n_jobs:int):
         self.n_jobs = self.get_n_jobs(n_jobs=n_jobs)
         self._msg_shown = False 
         
     def get_n_jobs(self, n_jobs):
         if n_jobs is None or (n_jobs < 0 and os.cpu_count() + 1 + n_jobs <= 0):
@@ -127,15 +137,15 @@
 
             res = np.array(res) if reduce_as_array else res
             if thread is not None:
                 thread.join()
 
             return res if reduce_func is None else reduce_func(res)
         return wrapper
-    
+
 def parallel_leiden_computation(
     X: np.ndarray,
     n_neighbors_list: Iterable[int] = (30, 50, 70, 90),
     resolution_list: Iterable[float] = (0.4, 0.6, 0.8, 1.0, 1.2),
 ):
     def par_func(data, queue=None):
         out = {}
@@ -158,7 +168,145 @@
         reduce_func=lambda x: x
     )()
     return pd.DataFrame(
         list(map(lambda x: list(x.values())[0], result)), 
         columns=list(map(lambda x: list(x.keys())[0], result))
     )
 
+
+class ParallelPairwiseCalculator:
+    def __init__(self, 
+        pairwise_func: Callable,
+        n_jobs=None, 
+        block_size: int = 50,
+        backend: str = "thread",
+        cutoff: float = 0.0,
+        dtype = np.uint8
+    ):
+        self.pairwise_func = pairwise_func
+        self.n_jobs = n_jobs if n_jobs else cpu_count()
+        self.block_size = block_size
+        self.backend = backend
+        self.cutoff = cutoff
+        self.DTYPE = dtype
+        
+    @staticmethod
+    def _block_iter(
+        seqs1: Sequence[str],
+        seqs2: Optional[Sequence[str]] = None,
+        block_size: Optional[int] = 50,
+    ):
+        """Iterate over sequences in blocks.
+
+        Parameters
+        ----------
+        seqs1
+            array containing (unique) sequences
+        seqs2
+            array containing other sequences. If `None` compute
+            the square matrix of `seqs1` and iterate over the upper triangle (including
+            the diagonal) only.
+        block_size
+            side length of a block (will have `block_size ** 2` elements.)
+
+        Yields
+        ------
+        seqs1
+            subset of length `block_size` of seqs1
+        seqs2
+            subset of length `block_size` of seqs2. If seqs2 is None, this will
+            be `None` if the block is on the diagonal, or a subset of seqs1 otherwise.
+        origin
+            (row, col) coordinates of the origin of the block.
+        """
+        square_mat = seqs2 is None
+        if square_mat:
+            seqs2 = seqs1
+        for row in range(0, len(seqs1), block_size):
+            start_col = row if square_mat else 0
+            for col in range(start_col, len(seqs2), block_size):
+                if row == col and square_mat:
+                    # block on the diagonal.
+                    # yield None for seqs2 to indicate that we only want the upper
+                    # diagonal.
+                    yield seqs1[row : row + block_size], None, (row, row)
+                else:
+                    yield seqs1[row : row + block_size], seqs2[
+                        col : col + block_size
+                    ], (row, col)
+
+    def _calculate(self, seqs1, seqs2, origin):
+        origin_row, origin_col = origin
+        if seqs2 is not None:
+            # compute the full matrix
+            coord_iterator = itertools.product(enumerate(seqs1), enumerate(seqs2))
+        else:
+            # compute only upper triangle in this case
+            coord_iterator = itertools.combinations_with_replacement(
+                enumerate(seqs1), r=2
+            )
+
+        result = []
+        for (row, s1), (col, s2) in coord_iterator:
+            d = self.pairwise_func(s1, s2)
+            if self.cutoff < 0 or d <= self.cutoff:
+                result.append((d + 1, origin_row + row, origin_col + col))
+
+        return result
+
+    def calculate(self, seqs: Sequence[str], seqs2: Optional[Sequence[str]] = None):
+        blocks = list(self._block_iter(seqs, seqs2, self.block_size))
+        if self.backend == "thread":
+            block_results = thread_map(
+                self._calculate,
+                *zip(*blocks),
+                max_workers=self.n_jobs if self.n_jobs is not None else cpu_count(),
+                chunksize=50,
+                tqdm_class=asyn_tqdm,
+                total=len(blocks),
+            )
+        elif self.backend == "process":
+            block_results = process_map(
+                self._calculate,
+                *zip(*blocks),
+                max_workers=self.n_jobs if self.n_jobs is not None else cpu_count(),
+                chunksize=50,
+                tqdm_class=asyn_tqdm,
+                total=len(blocks),
+            )
+        else:
+            raise ValueError("Invalid backend. Must be one of 'thread' or 'process'.")
+        try:
+            dists, rows, cols = zip(*itertools.chain(*block_results))
+        except ValueError:
+            # happens when there is no match at all
+            dists, rows, cols = (), (), ()
+
+        shape = (len(seqs), len(seqs2)) if seqs2 is not None else (len(seqs), len(seqs))
+        score_mat = scipy.sparse.coo_matrix(
+            (dists, (rows, cols)), dtype=self.DTYPE, shape=shape
+        )
+        score_mat.eliminate_zeros()
+        score_mat = score_mat.tocsr()
+
+        if seqs2 is None:
+            score_mat = self.squarify(score_mat)
+
+        return score_mat
+
+    @staticmethod
+    def squarify(triangular_matrix: csr_matrix) -> csr_matrix:
+        """Mirror a triangular matrix at the diagonal to make it a square matrix.
+
+        The input matrix *must* be upper triangular to begin with, otherwise
+        the results will be incorrect. No guard rails!
+        """
+        assert (
+            triangular_matrix.shape[0] == triangular_matrix.shape[1]
+        ), "needs to be square matrix"
+        # The matrix is already upper diagonal. Use the transpose method, see
+        # https://stackoverflow.com/a/58806735/2340703.
+        return (
+            triangular_matrix
+            + triangular_matrix.T
+            - scipy.sparse.diags(triangular_matrix.diagonal())
+        )
```

## Comparing `scAtlasVAE-1.0.3a5.dist-info/LICENSE` & `scAtlasVAE-1.0.3a6.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `scAtlasVAE-1.0.3a5.dist-info/METADATA` & `scAtlasVAE-1.0.3a6.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: scAtlasVAE
-Version: 1.0.3a5
+Version: 1.0.3a6
 Summary: scAtlasVAE: a deep learning framework for atlas-scale scRNA-seq integration and analysis
 Home-page: https://github.com/WanluLiuLab/scAtlasVAE
 Author: Ziwei Xue
 Author-email: xueziweisz@gmail.com
 License: UNKNOWN
 Download-URL: https://github.com/WanluLiuLab/scAtlasVAE
 Platform: UNKNOWN
```

## Comparing `scAtlasVAE-1.0.3a5.dist-info/RECORD` & `scAtlasVAE-1.0.3a6.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 scatlasvae/__init__.py,sha256=RLkNezvb5hYNMAZAYwsR3WXz6tNiM2mhceuvU2m1V9o,890
 scatlasvae/_metadata.py,sha256=YKuaQknWHvdKviwVf3XcxuIX9xEV7raH_hMSxTXpyKg,1420
-scatlasvae/_version.py,sha256=x2CsG9w3-5OiQ9EoKgi-8fvFOO-06ZXoq9WvrZNiLlE,19
+scatlasvae/_version.py,sha256=MiZ2mTw62uLxMEXdBTYsZgEXrqB8rdyAtBR78T5rRN4,19
 scatlasvae/data/__init__.py,sha256=DRGPdhwDwndVwF029g9ITqgrxSiX0kTdm_6wZshyRgQ,74
 scatlasvae/data/_dataloader.py,sha256=3z02t6ufCxjZvQRYNXfKYE8Pl2sXzyGFSTWGqPsV6IU,1549
 scatlasvae/externals/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 scatlasvae/externals/_trvae_mmd_loss.py,sha256=kNRkIDk4Aid1vb9dEmXii0F6HRhLYEkar3k_KfRyjk4,1924
 scatlasvae/model/__init__.py,sha256=y_Vu4dtOU0crMGYbg4in9cqFw3W71AhtNs8dMd-Hd4Y,86
-scatlasvae/model/_gex_model.py,sha256=Ip-XVexUn2T-3RObANSKAc2r8mVfujokHVavBq9m2SM,93694
+scatlasvae/model/_gex_model.py,sha256=EznlWR6vtS28mUBCNmt_crJbyH63RUPYcTSkhfykVrQ,95069
 scatlasvae/model/_primitives.py,sha256=i0sQY4rU5eaMuswzcvZHVz6JHpsRrVvbVp2u2QemdsY,31170
 scatlasvae/pipeline/__init__.py,sha256=Gj_IP3ZGzWXcQcwf9wVJN9sxCL3LBik_GkKe77bQ4uw,41
 scatlasvae/pipeline/_pipeline.py,sha256=dvEfsFxeLskGPDg1rIUZE8USIxsqo-CC7gCVwDb8Bnc,8777
 scatlasvae/preprocessing/__init__.py,sha256=LJWHQgT8w93fDVVa5e-5DFv0UEph3wv-P6Oqeb4xOP8,127
 scatlasvae/preprocessing/_infercnv.py,sha256=Yp1bJSchtZ-4rMcjro6Ax8PfRuWYStbEvQtXIYuQXqY,3255
 scatlasvae/preprocessing/_preprocess.py,sha256=nES1QPOx1ee2lTM-W_qjEyly0IAoQ8SZd-3vI3urCM0,35547
 scatlasvae/tools/__init__.py,sha256=eyRiflnSSm25qdZo5cmqECvdSX8TLPYLr4MBgrhEqog,78
@@ -19,16 +19,16 @@
 scatlasvae/utils/__init__.py,sha256=4TrTG_fljOG5Yuw7MEkw9OZJJA7CAoKrciDluHLhCxk,162
 scatlasvae/utils/_compat.py,sha256=5c7_RZ7UzkCS5nTQHFNUoAWVgNqCBmJqtdh8By57KVo,439
 scatlasvae/utils/_decorators.py,sha256=f4wXwLojOqiEi2LvXKOHqNZw9HtXMaKQm-kGLX9fELQ,2356
 scatlasvae/utils/_definitions.py,sha256=5CXPI1ikSx7FInKhZ-YwnvvuCIpa8f6OP2ddKZAl-qQ,4339
 scatlasvae/utils/_distributions.py,sha256=-Ige2YaFToBf9R68LS57g-TsdUK4s4Cm6zPC_EZBmq4,10679
 scatlasvae/utils/_logger.py,sha256=05cqq-6jTFyY13vrJhNWlu2Ryt-DXrbz6NpWGgVomQ0,4791
 scatlasvae/utils/_loss.py,sha256=DkaxjFBwmt-U435HfoXL06zWlai_Psm1dj-5B-j6vRQ,7995
-scatlasvae/utils/_parallelizer.py,sha256=BAX_FMAlifrbhp356te-GFuHIYUO5aDChlFMGM_qY1Y,5680
+scatlasvae/utils/_parallelizer.py,sha256=B_Ifu-s7F6RjQ72CC5WIyvzyQCuKdbS_FPNYXhIouWY,11078
 scatlasvae/utils/_tensor_utils.py,sha256=RSwy0czCGgGFdk8mvQplK_DL4VN0zA-M81f3zFfSdCU,1081
 scatlasvae/utils/_utilities.py,sha256=L-V1XnxsBsCHgaFCZlQ2Wyt6NzeeZuTWCQPumDYkQd0,6611
-scAtlasVAE-1.0.3a5.dist-info/LICENSE,sha256=iIPK3YfcATgHwXIjFIPvNF0FUR7vP-S2mOJmlv5H0lI,1522
-scAtlasVAE-1.0.3a5.dist-info/METADATA,sha256=N2cRNDjxmoxNG438dQV0WMgP2OG3HKTGRj816ethQCY,1355
-scAtlasVAE-1.0.3a5.dist-info/WHEEL,sha256=Xo9-1PvkuimrydujYJAjF7pCkriuXBpUPEjma1nZyJ0,92
-scAtlasVAE-1.0.3a5.dist-info/dependency_links.txt,sha256=ruee1cEBfajPwjguNMor_ix7qykV-lvgrkqssMcjBXQ,39
-scAtlasVAE-1.0.3a5.dist-info/top_level.txt,sha256=CEiwZxZLLn_PrRCJEi6VHH2UvdtCzoB4i9WeEGf5IMY,11
-scAtlasVAE-1.0.3a5.dist-info/RECORD,,
+scAtlasVAE-1.0.3a6.dist-info/LICENSE,sha256=iIPK3YfcATgHwXIjFIPvNF0FUR7vP-S2mOJmlv5H0lI,1522
+scAtlasVAE-1.0.3a6.dist-info/METADATA,sha256=2KfFB28rSsjChZIl7ypeka3IeZgWb7nl9AO52ZG4lo0,1355
+scAtlasVAE-1.0.3a6.dist-info/WHEEL,sha256=Xo9-1PvkuimrydujYJAjF7pCkriuXBpUPEjma1nZyJ0,92
+scAtlasVAE-1.0.3a6.dist-info/dependency_links.txt,sha256=ruee1cEBfajPwjguNMor_ix7qykV-lvgrkqssMcjBXQ,39
+scAtlasVAE-1.0.3a6.dist-info/top_level.txt,sha256=CEiwZxZLLn_PrRCJEi6VHH2UvdtCzoB4i9WeEGf5IMY,11
+scAtlasVAE-1.0.3a6.dist-info/RECORD,,
```

