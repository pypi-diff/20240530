# Comparing `tmp/pyemaps-1.0.8.tar.gz` & `tmp/pyemaps-1.0.9.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "C:\Users\sharon\dev_space\pyemaps_root\pyemaps\dist\.tmp-wkakk_qf\pyemaps-1.0.8.tar", last modified: Tue Nov  7 16:10:05 2023, max compression
+gzip compressed data, was "C:\Users\sharon\dev_space\pyemaps_root\pyemaps\dist\.tmp-vz3dwt8p\pyemaps-1.0.9.tar", last modified: Wed May 29 23:04:42 2024, max compression
```

## Comparing `pyemaps-1.0.8.tar` & `pyemaps-1.0.9.tar`

### file list

```diff
@@ -1,122 +1,122 @@
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/
--rw-rw-rw-   0        0        0    47330 2023-11-03 16:04:27.000000 pyemaps-1.0.8/COPYING
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/CifFile/
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/CifFile/src/
--rw-rw-rw-   0        0        0   152727 2022-08-25 21:11:57.000000 pyemaps-1.0.8/CifFile/src/CifFile_module.py
--rw-rw-rw-   0        0        0   117625 2022-08-25 21:11:57.000000 pyemaps-1.0.8/CifFile/src/StarFile.py
--rw-rw-rw-   0        0        0     2905 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/TypeContentsParser.py
--rw-rw-rw-   0        0        0    14238 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/YappsStarParser_1_0.py
--rw-rw-rw-   0        0        0    14246 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/YappsStarParser_1_1.py
--rw-rw-rw-   0        0        0    21486 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/YappsStarParser_2_0.py
--rw-rw-rw-   0        0        0    22321 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/YappsStarParser_STAR2.py
--rw-rw-rw-   0        0        0      447 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/__init__.py
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/CifFile/src/drel/
--rw-rw-rw-   0        0        0       13 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/drel/__init__.py
--rw-rw-rw-   0        0        0    16879 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/drel/drel_ast_yacc.py
--rw-rw-rw-   0        0        0     4645 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/drel/drel_lex.py
--rw-rw-rw-   0        0        0     4383 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/drel/drel_runtime.py
--rw-rw-rw-   0        0        0    81599 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/drel/parsetab.py
--rw-rw-rw-   0        0        0    29728 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/drel/py_from_ast.py
--rw-rw-rw-   0        0        0    82535 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/parsetab.py
--rw-rw-rw-   0        0        0    14038 2022-08-25 21:11:58.000000 pyemaps-1.0.8/CifFile/src/yapps3_compiled_rt.py
--rw-rw-rw-   0        0        0      273 2023-11-03 16:04:27.000000 pyemaps-1.0.8/MANIFEST.in
--rw-rw-rw-   0        0        0      885 2023-11-07 16:10:05.000000 pyemaps-1.0.8/PKG-INFO
--rw-rw-rw-   0        0        0      101 2023-11-03 16:04:27.000000 pyemaps-1.0.8/README.md
--rw-rw-rw-   0        0        0     3052 2023-11-03 16:04:27.000000 pyemaps-1.0.8/__config__.py
--rw-rw-rw-   0        0        0     6876 2023-11-03 16:05:11.000000 pyemaps-1.0.8/__init__.py
--rw-rw-rw-   0        0        0     4634 2023-11-03 16:04:27.000000 pyemaps-1.0.8/__main__.py
--rw-rw-rw-   0        0        0       21 2023-11-07 16:10:03.000000 pyemaps-1.0.8/__version__.py
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/cdata/
--rw-rw-rw-   0        0        0      143 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Aluminium.xtl
--rw-rw-rw-   0        0        0      273 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/AluminiumOxide.xtl
--rw-rw-rw-   0        0        0      147 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Aluminium_FCC.xtl
--rw-rw-rw-   0        0        0      364 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/BariumTitanate_180k.xtl
--rw-rw-rw-   0        0        0      450 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/BariumTitanate_270k.xtl
--rw-rw-rw-   0        0        0      452 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/BariumTitanate_Tetra.xtl
--rw-rw-rw-   0        0        0     2221 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/BiMnO3.xtl
--rw-rw-rw-   0        0        0      528 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Boron_Tetra.xtl
--rw-rw-rw-   0        0        0      278 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/CadmiumSelenide_Hex.xtl
--rw-rw-rw-   0        0        0      197 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/CadmiumSulfide_Cubic.xtl
--rw-rw-rw-   0        0        0      276 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/CadmiumSulfide_Hex.xtl
--rw-rw-rw-   0        0        0      146 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Chromium_BCC.xtl
--rw-rw-rw-   0        0        0      276 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/CoSb3_Skutterudite.xtl
--rw-rw-rw-   0        0        0      269 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/CopperOxide.xtl
--rw-rw-rw-   0        0        0      144 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Copper_FCC.xtl
--rw-rw-rw-   0        0        0      272 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Cu2O_Cuprite.xtl
--rw-rw-rw-   0        0        0      131 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Diamond.xtl
--rw-rw-rw-   0        0        0      626 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/ErbiumPyrogermanate.xtl
--rw-rw-rw-   0        0        0      198 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/FePd_Tetra.xtl
--rw-rw-rw-   0        0        0      672 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/FeS2_Pyrite.xtl
--rw-rw-rw-   0        0        0      205 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/GalliumAntimonide.xtl
--rw-rw-rw-   0        0        0      201 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/GalliumArsenide.xtl
--rw-rw-rw-   0        0        0      240 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/GalliumNitride.xtl
--rw-rw-rw-   0        0        0      132 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Germanium.xtl
--rw-rw-rw-   0        0        0      142 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Gold_FCC.xtl
--rw-rw-rw-   0        0        0      202 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/IndiumArsenide.xtl
--rw-rw-rw-   0        0        0      271 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/LaMnO3.xtl
--rw-rw-rw-   0        0        0      594 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/LeadZirconateTitanate.xtl
--rw-rw-rw-   0        0        0      965 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Li2MnO3.xtl
--rw-rw-rw-   0        0        0      239 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/NaFeO2.xtl
--rw-rw-rw-   0        0        0      165 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Nb3Sn.xtl
--rw-rw-rw-   0        0        0     3751 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Pentacene.xtl
--rw-rw-rw-   0        0        0      797 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/SiAlONa.xtl
--rw-rw-rw-   0        0        0      113 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Silicon.xtl
--rw-rw-rw-   0        0        0      362 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/StrontiumTitanate.xtl
--rw-rw-rw-   0        0        0      277 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/TelluriumDioxide.xtl
--rw-rw-rw-   0        0        0      272 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/TinDioxide_RT.xtl
--rw-rw-rw-   0        0        0      280 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/TitaniumDioxide_Anatase.xtl
--rw-rw-rw-   0        0        0      281 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/TitaniumDioxide_Rutile.xtl
--rw-rw-rw-   0        0        0      277 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/TungstenDiselenide.xtl
--rw-rw-rw-   0        0        0      366 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/VanadiumDioxide_RT.xtl
--rw-rw-rw-   0        0        0      160 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/ZincOxide.xtl
--rw-rw-rw-   0        0        0      144 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/Zinc_HCP.xtl
--rw-rw-rw-   0        0        0      203 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/ZirconiumNitride.xtl
--rw-rw-rw-   0        0        0      353 2023-11-03 16:04:27.000000 pyemaps-1.0.8/cdata/limno2.xtl
--rw-rw-rw-   0        0        0    42129 2023-11-03 16:04:27.000000 pyemaps-1.0.8/crystals.py
--rw-rw-rw-   0        0        0     2618 2023-11-03 16:04:27.000000 pyemaps-1.0.8/ddiffs.py
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/diffract/
--rw-rw-rw-   0        0        0     1595 2023-11-05 16:47:47.000000 pyemaps-1.0.8/diffract/__init__.py
--rw-rw-rw-   0        0        0    28900 2023-11-03 16:04:27.000000 pyemaps-1.0.8/diffract/bloch_dec.py
--rw-rw-rw-   0        0        0     6927 2023-11-03 16:04:27.000000 pyemaps-1.0.8/diffract/csf_dec.py
--rw-rw-rw-   0        0        0    15879 2023-11-03 16:04:27.000000 pyemaps-1.0.8/diffract/dif_dec.py
--rw-rw-rw-   0        0        0     5020 2023-11-03 16:04:27.000000 pyemaps-1.0.8/diffract/dpgen_dec.py
--rw-rw-rw-   0        0        0     7159 2023-11-03 16:04:27.000000 pyemaps-1.0.8/diffract/mxtal_dec.py
--rw-rw-rw-   0        0        0     3327 2023-11-03 16:04:27.000000 pyemaps-1.0.8/diffract/powder_dec.py
--rw-rw-rw-   0        0        0     2436 2023-11-03 16:04:27.000000 pyemaps-1.0.8/diffract/stereo_dec.py
--rw-rw-rw-   0        0        0    23201 2023-11-03 16:04:27.000000 pyemaps-1.0.8/display.py
--rw-rw-rw-   0        0        0    27443 2023-11-03 16:04:27.000000 pyemaps-1.0.8/emcontrols.py
--rw-rw-rw-   0        0        0     7412 2023-11-03 16:04:27.000000 pyemaps-1.0.8/errors.py
--rw-rw-rw-   0        0        0    33222 2023-11-03 16:04:27.000000 pyemaps-1.0.8/fileutils.py
--rw-rw-rw-   0        0        0    31629 2023-11-03 16:04:27.000000 pyemaps-1.0.8/kdiffs.py
--rw-rw-rw-   0        0        0     1020 2023-11-03 16:04:27.000000 pyemaps-1.0.8/license.txt
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/pyemaps.egg-info/
--rw-rw-rw-   0        0        0      885 2023-11-07 16:10:05.000000 pyemaps-1.0.8/pyemaps.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     2704 2023-11-07 16:10:05.000000 pyemaps-1.0.8/pyemaps.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2023-11-07 16:10:05.000000 pyemaps-1.0.8/pyemaps.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0       45 2023-11-07 16:10:05.000000 pyemaps-1.0.8/pyemaps.egg-info/requires.txt
--rw-rw-rw-   0        0        0        8 2023-11-07 16:10:05.000000 pyemaps-1.0.8/pyemaps.egg-info/top_level.txt
--rw-rw-rw-   0        0        0      119 2023-11-03 16:04:27.000000 pyemaps-1.0.8/pyproject.toml
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/samples/
--rw-rw-rw-   0        0        0     2149 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/adf.py
--rw-rw-rw-   0        0        0   160008 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/al.img
--rw-rw-rw-   0        0        0     2131 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/al_dpgen.py
--rw-rw-rw-   0        0        0     4119 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/al_ediom.py
--rw-rw-rw-   0        0        0     7439 2023-11-06 22:15:27.000000 pyemaps-1.0.8/samples/dm_diff.py
--rw-rw-rw-   0        0        0     2137 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/powder.py
--rw-rw-rw-   0        0        0     3610 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_bloch.py
--rw-rw-rw-   0        0        0     1676 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_constructor.py
--rw-rw-rw-   0        0        0     1862 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_csf.py
--rw-rw-rw-   0        0        0     3953 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_dif.py
--rw-rw-rw-   0        0        0     1698 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_lacbed.py
--rw-rw-rw-   0        0        0     2691 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_pyemaps.py
--rw-rw-rw-   0        0        0     3884 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_scm.py
--rw-rw-rw-   0        0        0     3280 2023-11-03 16:04:27.000000 pyemaps-1.0.8/samples/si_stereo.py
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/scattering/
--rw-rw-rw-   0        0        0      884 2023-11-03 16:05:11.000000 pyemaps-1.0.8/scattering/__init__.py
--rw-rw-rw-   0        0        0      184 2023-11-03 16:04:27.000000 pyemaps-1.0.8/scattering/sct_dec.py
--rw-rw-rw-   0        0        0      751 2023-11-07 16:10:05.000000 pyemaps-1.0.8/setup.cfg
--rw-rw-rw-   0        0        0     6417 2023-11-07 15:28:02.000000 pyemaps-1.0.8/setup.py
-drwxrwxrwx   0        0        0        0 2023-11-07 16:10:05.000000 pyemaps-1.0.8/spg/
--rw-rw-rw-   0        0        0      817 2023-11-03 16:05:11.000000 pyemaps-1.0.8/spg/__init__.py
--rw-rw-rw-   0        0        0      791 2023-11-03 16:04:27.000000 pyemaps-1.0.8/spg/spg_dec.py
--rw-rw-rw-   0        0        0    29836 2023-11-03 16:05:11.000000 pyemaps-1.0.8/stackimg.py
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/
+-rw-rw-rw-   0        0        0    41861 2023-11-09 21:26:53.000000 pyemaps-1.0.9/COPYING
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/CifFile/
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/CifFile/src/
+-rw-rw-rw-   0        0        0   155844 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/CifFile_module.py
+-rw-rw-rw-   0        0        0   120121 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/StarFile.py
+-rw-rw-rw-   0        0        0     2987 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/TypeContentsParser.py
+-rw-rw-rw-   0        0        0    14527 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/YappsStarParser_1_0.py
+-rw-rw-rw-   0        0        0    14534 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/YappsStarParser_1_1.py
+-rw-rw-rw-   0        0        0    21855 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/YappsStarParser_2_0.py
+-rw-rw-rw-   0        0        0    22703 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/YappsStarParser_STAR2.py
+-rw-rw-rw-   0        0        0      454 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/__init__.py
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/CifFile/src/drel/
+-rw-rw-rw-   0        0        0       14 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/drel/__init__.py
+-rw-rw-rw-   0        0        0    17461 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/drel/drel_ast_yacc.py
+-rw-rw-rw-   0        0        0     4873 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/drel/drel_lex.py
+-rw-rw-rw-   0        0        0     4509 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/drel/drel_runtime.py
+-rw-rw-rw-   0        0        0    81784 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/drel/parsetab.py
+-rw-rw-rw-   0        0        0    30356 2023-11-09 21:26:53.000000 pyemaps-1.0.9/CifFile/src/drel/py_from_ast.py
+-rw-rw-rw-   0        0        0    82720 2023-11-09 21:26:54.000000 pyemaps-1.0.9/CifFile/src/parsetab.py
+-rw-rw-rw-   0        0        0    14428 2023-11-09 21:26:54.000000 pyemaps-1.0.9/CifFile/src/yapps3_compiled_rt.py
+-rw-rw-rw-   0        0        0      273 2023-11-03 16:04:27.000000 pyemaps-1.0.9/MANIFEST.in
+-rw-rw-rw-   0        0        0    10038 2024-05-29 23:04:42.000000 pyemaps-1.0.9/PKG-INFO
+-rw-rw-rw-   0        0        0     9081 2024-05-29 21:35:05.000000 pyemaps-1.0.9/README.md
+-rw-rw-rw-   0        0        0     3052 2023-11-03 16:04:27.000000 pyemaps-1.0.9/__config__.py
+-rw-rw-rw-   0        0        0     6889 2024-05-29 21:35:05.000000 pyemaps-1.0.9/__init__.py
+-rw-rw-rw-   0        0        0     4634 2023-11-03 16:04:27.000000 pyemaps-1.0.9/__main__.py
+-rw-rw-rw-   0        0        0       21 2024-05-29 23:04:39.000000 pyemaps-1.0.9/__version__.py
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/cdata/
+-rw-rw-rw-   0        0        0      143 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Aluminium.xtl
+-rw-rw-rw-   0        0        0      273 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/AluminiumOxide.xtl
+-rw-rw-rw-   0        0        0      147 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Aluminium_FCC.xtl
+-rw-rw-rw-   0        0        0      364 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/BariumTitanate_180k.xtl
+-rw-rw-rw-   0        0        0      450 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/BariumTitanate_270k.xtl
+-rw-rw-rw-   0        0        0      452 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/BariumTitanate_Tetra.xtl
+-rw-rw-rw-   0        0        0     2221 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/BiMnO3.xtl
+-rw-rw-rw-   0        0        0      528 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Boron_Tetra.xtl
+-rw-rw-rw-   0        0        0      278 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/CadmiumSelenide_Hex.xtl
+-rw-rw-rw-   0        0        0      197 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/CadmiumSulfide_Cubic.xtl
+-rw-rw-rw-   0        0        0      276 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/CadmiumSulfide_Hex.xtl
+-rw-rw-rw-   0        0        0      146 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Chromium_BCC.xtl
+-rw-rw-rw-   0        0        0      276 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/CoSb3_Skutterudite.xtl
+-rw-rw-rw-   0        0        0      269 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/CopperOxide.xtl
+-rw-rw-rw-   0        0        0      144 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Copper_FCC.xtl
+-rw-rw-rw-   0        0        0      272 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Cu2O_Cuprite.xtl
+-rw-rw-rw-   0        0        0      131 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Diamond.xtl
+-rw-rw-rw-   0        0        0      626 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/ErbiumPyrogermanate.xtl
+-rw-rw-rw-   0        0        0      198 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/FePd_Tetra.xtl
+-rw-rw-rw-   0        0        0      672 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/FeS2_Pyrite.xtl
+-rw-rw-rw-   0        0        0      205 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/GalliumAntimonide.xtl
+-rw-rw-rw-   0        0        0      201 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/GalliumArsenide.xtl
+-rw-rw-rw-   0        0        0      240 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/GalliumNitride.xtl
+-rw-rw-rw-   0        0        0      132 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Germanium.xtl
+-rw-rw-rw-   0        0        0      142 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Gold_FCC.xtl
+-rw-rw-rw-   0        0        0      202 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/IndiumArsenide.xtl
+-rw-rw-rw-   0        0        0      271 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/LaMnO3.xtl
+-rw-rw-rw-   0        0        0      594 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/LeadZirconateTitanate.xtl
+-rw-rw-rw-   0        0        0      965 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Li2MnO3.xtl
+-rw-rw-rw-   0        0        0      239 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/NaFeO2.xtl
+-rw-rw-rw-   0        0        0      165 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Nb3Sn.xtl
+-rw-rw-rw-   0        0        0     3751 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Pentacene.xtl
+-rw-rw-rw-   0        0        0      797 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/SiAlONa.xtl
+-rw-rw-rw-   0        0        0      113 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Silicon.xtl
+-rw-rw-rw-   0        0        0      362 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/StrontiumTitanate.xtl
+-rw-rw-rw-   0        0        0      277 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/TelluriumDioxide.xtl
+-rw-rw-rw-   0        0        0      272 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/TinDioxide_RT.xtl
+-rw-rw-rw-   0        0        0      280 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/TitaniumDioxide_Anatase.xtl
+-rw-rw-rw-   0        0        0      281 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/TitaniumDioxide_Rutile.xtl
+-rw-rw-rw-   0        0        0      277 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/TungstenDiselenide.xtl
+-rw-rw-rw-   0        0        0      366 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/VanadiumDioxide_RT.xtl
+-rw-rw-rw-   0        0        0      160 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/ZincOxide.xtl
+-rw-rw-rw-   0        0        0      144 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/Zinc_HCP.xtl
+-rw-rw-rw-   0        0        0      203 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/ZirconiumNitride.xtl
+-rw-rw-rw-   0        0        0      353 2023-11-03 16:04:27.000000 pyemaps-1.0.9/cdata/limno2.xtl
+-rw-rw-rw-   0        0        0    42129 2023-11-03 16:04:27.000000 pyemaps-1.0.9/crystals.py
+-rw-rw-rw-   0        0        0     2618 2023-11-03 16:04:27.000000 pyemaps-1.0.9/ddiffs.py
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/diffract/
+-rw-rw-rw-   0        0        0     1595 2023-11-07 16:52:26.000000 pyemaps-1.0.9/diffract/__init__.py
+-rw-rw-rw-   0        0        0    29790 2023-11-09 21:26:54.000000 pyemaps-1.0.9/diffract/bloch_dec.py
+-rw-rw-rw-   0        0        0     7817 2023-11-09 21:26:54.000000 pyemaps-1.0.9/diffract/csf_dec.py
+-rw-rw-rw-   0        0        0    16753 2023-11-09 21:26:54.000000 pyemaps-1.0.9/diffract/dif_dec.py
+-rw-rw-rw-   0        0        0     5908 2023-11-09 21:26:54.000000 pyemaps-1.0.9/diffract/dpgen_dec.py
+-rw-rw-rw-   0        0        0     8047 2023-11-09 21:26:54.000000 pyemaps-1.0.9/diffract/mxtal_dec.py
+-rw-rw-rw-   0        0        0     4215 2023-11-09 21:26:54.000000 pyemaps-1.0.9/diffract/powder_dec.py
+-rw-rw-rw-   0        0        0     3326 2023-11-09 21:26:54.000000 pyemaps-1.0.9/diffract/stereo_dec.py
+-rw-rw-rw-   0        0        0    24055 2024-05-29 21:35:05.000000 pyemaps-1.0.9/display.py
+-rw-rw-rw-   0        0        0    27443 2023-11-03 16:04:27.000000 pyemaps-1.0.9/emcontrols.py
+-rw-rw-rw-   0        0        0     7412 2023-11-03 16:04:27.000000 pyemaps-1.0.9/errors.py
+-rw-rw-rw-   0        0        0    33222 2023-11-03 16:04:27.000000 pyemaps-1.0.9/fileutils.py
+-rw-rw-rw-   0        0        0    31629 2023-11-03 16:04:27.000000 pyemaps-1.0.9/kdiffs.py
+-rw-rw-rw-   0        0        0     1020 2023-11-03 16:04:27.000000 pyemaps-1.0.9/license.txt
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/pyemaps.egg-info/
+-rw-rw-rw-   0        0        0    10038 2024-05-29 23:04:42.000000 pyemaps-1.0.9/pyemaps.egg-info/PKG-INFO
+-rw-rw-rw-   0        0        0     2704 2024-05-29 23:04:42.000000 pyemaps-1.0.9/pyemaps.egg-info/SOURCES.txt
+-rw-rw-rw-   0        0        0        1 2024-05-29 23:04:42.000000 pyemaps-1.0.9/pyemaps.egg-info/dependency_links.txt
+-rw-rw-rw-   0        0        0       45 2024-05-29 23:04:42.000000 pyemaps-1.0.9/pyemaps.egg-info/requires.txt
+-rw-rw-rw-   0        0        0        8 2024-05-29 23:04:42.000000 pyemaps-1.0.9/pyemaps.egg-info/top_level.txt
+-rw-rw-rw-   0        0        0      119 2023-11-03 16:04:27.000000 pyemaps-1.0.9/pyproject.toml
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/samples/
+-rw-rw-rw-   0        0        0     2149 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/adf.py
+-rw-rw-rw-   0        0        0   160008 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/al.img
+-rw-rw-rw-   0        0        0     2131 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/al_dpgen.py
+-rw-rw-rw-   0        0        0     4119 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/al_ediom.py
+-rw-rw-rw-   0        0        0     7439 2023-11-07 16:52:26.000000 pyemaps-1.0.9/samples/dm_diff.py
+-rw-rw-rw-   0        0        0     1367 2024-05-29 21:35:05.000000 pyemaps-1.0.9/samples/powder.py
+-rw-rw-rw-   0        0        0     3610 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_bloch.py
+-rw-rw-rw-   0        0        0     1676 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_constructor.py
+-rw-rw-rw-   0        0        0     1862 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_csf.py
+-rw-rw-rw-   0        0        0     3953 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_dif.py
+-rw-rw-rw-   0        0        0     1698 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_lacbed.py
+-rw-rw-rw-   0        0        0     2691 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_pyemaps.py
+-rw-rw-rw-   0        0        0     3884 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_scm.py
+-rw-rw-rw-   0        0        0     3280 2023-11-03 16:04:27.000000 pyemaps-1.0.9/samples/si_stereo.py
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/scattering/
+-rw-rw-rw-   0        0        0      848 2023-11-09 21:26:54.000000 pyemaps-1.0.9/scattering/__init__.py
+-rw-rw-rw-   0        0        0     1074 2023-11-09 21:26:54.000000 pyemaps-1.0.9/scattering/sct_dec.py
+-rw-rw-rw-   0        0        0      676 2024-05-29 23:04:42.000000 pyemaps-1.0.9/setup.cfg
+-rw-rw-rw-   0        0        0     7696 2023-11-09 21:26:54.000000 pyemaps-1.0.9/setup.py
+drwxrwxrwx   0        0        0        0 2024-05-29 23:04:42.000000 pyemaps-1.0.9/spg/
+-rw-rw-rw-   0        0        0      817 2023-11-07 16:52:26.000000 pyemaps-1.0.9/spg/__init__.py
+-rw-rw-rw-   0        0        0     1681 2023-11-09 21:26:54.000000 pyemaps-1.0.9/spg/spg_dec.py
+-rw-rw-rw-   0        0        0    29803 2023-11-09 21:26:54.000000 pyemaps-1.0.9/stackimg.py
```

### Comparing `pyemaps-1.0.8/COPYING` & `pyemaps-1.0.9/COPYING`

 * *Files 3% similar despite different names*

```diff
@@ -792,69 +792,7 @@
 relationship of agency, partnership, or joint venture between ANSTO
 and Licensee. This License Agreement does not grant permission to use
 ANSTO trademarks or trade name in a trademark sense to endorse or
 promote products or services of Licensee, or any third party.
 
 By copying, installing or otherwise using PyCIFRW, Licensee agrees
 to be bound by the terms and conditions of this License Agreement.
-
-## Intel Simplified Software License (Version April 2018)
-
-Copyright (c) 2018 Intel Corporation.
-
-Use and Redistribution.  You may use and redistribute the software (the “Software”), without modification, provided the following conditions are met:
-
-* Redistributions must reproduce the above copyright notice and the
-following terms of use in the Software and in the documentation and/or other materials provided with the distribution.
-* Neither the name of Intel nor the names of its suppliers may be used to 
-  endorse or promote products derived from this Software without specific
-  prior written permission.
-* No reverse engineering, decompilation, or disassembly of this Software
-  is permitted.
-
-Limited patent license.  Intel grants you a world-wide, royalty-free,
-non-exclusive license under patents it now or hereafter owns or controls to
-make, have made, use, import, offer to sell and sell (“Utilize”) this Software,
-but solely to the extent that any such patent is necessary to Utilize the 
-Software alone. The patent license shall not apply to any combinations
-which include this software.  No hardware per se is licensed hereunder.
-
-Third party and other Intel programs.  “Third Party Programs” are the files listed in the “third-party-programs.txt” text file that is included with the Software and may include Intel programs under separate license terms. Third Party Programs, even if included with the distribution of the Materials, are governed by separate license terms and those license terms solely govern your use of those programs.  
-
-DISCLAIMER.  THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT ARE DISCLAIMED. THIS SOFTWARE IS NOT INTENDED FOR USE IN SYSTEMS OR APPLICATIONS WHERE FAILURE OF THE SOFTWARE MAY CAUSE PERSONAL INJURY OR DEATH AND YOU AGREE THAT YOU ARE FULLY RESPONSIBLE FOR ANY CLAIMS, COSTS, DAMAGES, EXPENSES, AND ATTORNEYS’ FEES ARISING OUT OF ANY SUCH USE, EVEN IF ANY CLAIM ALLEGES THAT INTEL WAS NEGLIGENT REGARDING THE DESIGN OR MANUFACTURE OF THE MATERIALS.
-
-LIMITATION OF LIABILITY. IN NO EVENT WILL INTEL BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. YOU AGREE TO INDEMNIFY AND HOLD INTEL HARMLESS AGAINST ANY CLAIMS AND EXPENSES RESULTING FROM YOUR USE OR UNAUTHORIZED USE OF THE SOFTWARE.
-
-No support.  Intel may make changes to the Software, at any time without notice, and is not obligated to support, update or provide training for the Software. 
-
-Termination. Intel may terminate your right to use the Software in the event of your breach of this Agreement and you fail to cure the breach within a reasonable period of time.
-
-Feedback.  Should you provide Intel with comments, modifications, corrections, enhancements or other input (“Feedback”) related to the Software Intel will be free to use, disclose, reproduce, license or otherwise distribute or exploit the Feedback in its sole discretion without any obligations or restrictions of any kind, including without limitation, intellectual property rights or licensing obligations.
-
-Compliance with laws.  You agree to comply with all relevant laws and regulations governing your use, transfer, import or export (or prohibition thereof) of the Software.
-
-Governing law.  All disputes will be governed by the laws of the United States of America and the State of Delaware without reference to conflict of law principles and subject to the exclusive jurisdiction of the state or federal courts sitting in the State of Delaware, and each party agrees that it submits to the personal jurisdiction and venue of those courts and waives any objections. The United Nations Convention on Contracts for the International Sale of Goods (1980) is specifically excluded and will not apply to the Software.
-
-## SWIG Simplified BSD License
-
-SWIG is free software: you can redistribute it and/or modify it
-under the terms of the GNU General Public License as published by
-the Free Software Foundation, either version 3 of the License, or
-(at your option) any later version. See the LICENSE-GPL file for
-the full terms of the GNU General Public license version 3.
-
-Portions of SWIG are also licensed under the terms of the licenses
-in the file LICENSE-UNIVERSITIES. You must observe the terms of
-these licenses, as well as the terms of the GNU General Public License,
-when you distribute SWIG.
-
-The SWIG library and examples, under the Lib and Examples top level 
-directories, are distributed under the following terms:
-
-  You may copy, modify, distribute, and make derivative works based on
-  this software, in source code or object code form, without
-  restriction. If you distribute the software to others, you may do
-  so according to the terms of your choice. This software is offered as
-  is, without warranty of any kind.
-
-See the COPYRIGHT file for a list of contributors to SWIG and their
-copyright notices.
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `pyemaps-1.0.8/CifFile/src/CifFile_module.py` & `pyemaps-1.0.9/CifFile/src/CifFile_module.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,3117 +1,3117 @@
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-try:
-    from cStringIO import StringIO
-except ImportError:
-    from io import StringIO
-
-# Python 2,3 compatibility
-try:
-    from urllib import urlopen         # for arbitrary opening
-    from urlparse import urlparse, urljoin
-except:
-    from urllib.request import urlopen
-    from urllib.parse import urlparse, urljoin
-
-# The unicode type does not exist in Python3 as the str type
-# encompasses unicode.  PyCIFRW tests for 'unicode' would fail
-# Suggestions for a better approach welcome.
-#
-# long type no longer exists in Python3, so we alias to int
-#
-if isinstance(u"abc",str):   #Python3
-    unicode = str
-    long = int
-
-__copyright = """
-PYCIFRW License Agreement (Python License, Version 2)
------------------------------------------------------
-
-1. This LICENSE AGREEMENT is between the Australian Nuclear Science
-and Technology Organisation ("ANSTO"), and the Individual or
-Organization ("Licensee") accessing and otherwise using this software
-("PyCIFRW") in source or binary form and its associated documentation.
-
-2. Subject to the terms and conditions of this License Agreement,
-ANSTO hereby grants Licensee a nonexclusive, royalty-free, world-wide
-license to reproduce, analyze, test, perform and/or display publicly,
-prepare derivative works, distribute, and otherwise use PyCIFRW alone
-or in any derivative version, provided, however, that this License
-Agreement and ANSTO's notice of copyright, i.e., "Copyright (c)
-2001-2014 ANSTO; All Rights Reserved" are retained in PyCIFRW alone or
-in any derivative version prepared by Licensee.
-
-3. In the event Licensee prepares a derivative work that is based on
-or incorporates PyCIFRW or any part thereof, and wants to make the
-derivative work available to others as provided herein, then Licensee
-hereby agrees to include in any such work a brief summary of the
-changes made to PyCIFRW.
-
-4. ANSTO is making PyCIFRW available to Licensee on an "AS IS"
-basis. ANSTO MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
-IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, ANSTO MAKES NO AND
-DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
-FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYCIFRW WILL NOT
-INFRINGE ANY THIRD PARTY RIGHTS.
-
-5. ANSTO SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYCIFRW
-FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A
-RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYCIFRW, OR ANY
-DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
-
-6. This License Agreement will automatically terminate upon a material
-breach of its terms and conditions.
-
-7. Nothing in this License Agreement shall be deemed to create any
-relationship of agency, partnership, or joint venture between ANSTO
-and Licensee. This License Agreement does not grant permission to use
-ANSTO trademarks or trade name in a trademark sense to endorse or
-promote products or services of Licensee, or any third party.
-
-8. By copying, installing or otherwise using PyCIFRW, Licensee agrees
-to be bound by the terms and conditions of this License Agreement.
-
-"""
-
-
-import re,sys
-from . import StarFile
-from .StarFile import StarList  #put in global scope for exec statement
-try:
-    import numpy                   #put in global scope for exec statement
-    from .drel import drel_runtime  #put in global scope for exec statement
-except ImportError:
-    pass                       #will fail when using dictionaries for calcs
-from copy import copy          #must be in global scope for exec statement
-
-def track_recursion(in_this_func):
-    """Keep an eye on a function call to make sure that the key argument hasn't been
-    seen before"""
-    def wrapper(*args,**kwargs):
-        key_arg = args[1]
-        if key_arg in wrapper.called_list:
-            print('Recursion watch: %s already called %d times' % (key_arg,wrapper.called_list.count(key_arg)))
-            raise CifRecursionError( key_arg,wrapper.called_list[:])    #failure
-        if len(wrapper.called_list) == 0:   #first time
-            wrapper.stored_use_defaults = kwargs.get("allow_defaults",False)
-            print('All recursive calls will set allow_defaults to ' + repr(wrapper.stored_use_defaults))
-        else:
-            kwargs["allow_defaults"] = wrapper.stored_use_defaults
-        wrapper.called_list.append(key_arg)
-        print('Recursion watch: call stack: ' + repr(wrapper.called_list))
-        try:
-            result = in_this_func(*args,**kwargs)
-        except StarFile.StarDerivationError as s:
-            if len(wrapper.called_list) == 1: #no more
-                raise StarFile.StarDerivationFailure(wrapper.called_list[0])
-            else:
-                raise
-        finally:
-            wrapper.called_list.pop()
-            if len(wrapper.called_list) == 0:
-                wrapper.stored_used_defaults = 'error'
-        return result
-    wrapper.called_list = []
-    return wrapper
-
-class CifBlock(StarFile.StarBlock):
-    """
-    A class to hold a single block of a CIF file.  A `CifBlock` object can be treated as
-    a Python dictionary, in particular, individual items can be accessed using square
-    brackets e.g. `b['_a_dataname']`.  All other Python dictionary methods are also
-    available (e.g. `keys()`, `values()`).  Looped datanames will return a list of values.
-
-    ## Initialisation
-
-    When provided, `data` should be another `CifBlock` whose contents will be copied to
-    this block.
-
-    * if `strict` is set, maximum name lengths will be enforced
-
-    * `maxoutlength` is the maximum length for output lines
-
-    * `wraplength` is the ideal length to make output lines
-
-    * When set, `overwrite` allows the values of datanames to be changed (otherwise an error
-    is raised).
-
-    * `compat_mode` will allow deprecated behaviour of creating single-dataname loops using
-    the syntax `a[_dataname] = [1,2,3,4]`.  This should now be done by calling `CreateLoop`
-    after setting the dataitem value.
-    """
-    def __init__(self,data = (), strict = 1, compat_mode=False, **kwargs):
-        """When provided, `data` should be another CifBlock whose contents will be copied to
-        this block.
-
-        * if `strict` is set, maximum name lengths will be enforced
-
-        * `maxoutlength` is the maximum length for output lines
-
-        * `wraplength` is the ideal length to make output lines
-
-        * When set, `overwrite` allows the values of datanames to be changed (otherwise an error
-        is raised).
-
-        * `compat_mode` will allow deprecated behaviour of creating single-dataname loops using
-        the syntax `a[_dataname] = [1,2,3,4]`.  This should now be done by calling `CreateLoop`
-        after setting the dataitem value.
-        """
-        if strict: maxnamelength=75
-        else:
-           maxnamelength=-1
-        super(CifBlock,self).__init__(data=data,maxnamelength=maxnamelength,**kwargs)
-        self.dictionary = None   #DDL dictionary referring to this block
-        self.compat_mode = compat_mode   #old-style behaviour of setitem
-
-    def RemoveCifItem(self,itemname):
-        """Remove `itemname` from the CifBlock"""
-        self.RemoveItem(itemname)
-
-    def __setitem__(self,key,value):
-        self.AddItem(key,value)
-        # for backwards compatibility make a single-element loop
-        if self.compat_mode:
-            if isinstance(value,(tuple,list)) and not isinstance(value,StarFile.StarList):
-                 # single element loop
-                 self.CreateLoop([key])
-
-    def copy(self):
-        newblock = super(CifBlock,self).copy()
-        return self.copy.im_class(newblock)   #catch inheritance
-
-    def AddCifItem(self,data):
-        """ *DEPRECATED*. Use `AddItem` instead."""
-        # we accept only tuples, strings and lists!!
-        if not (isinstance(data[0],(unicode,tuple,list,str))):
-                  raise TypeError('Cif datanames are either a string, tuple or list')
-        # we catch single item loops as well...
-        if isinstance(data[0],(unicode,str)):
-            self.AddSingleCifItem(data[0],list(data[1]))
-            if isinstance(data[1],(tuple,list)) and not isinstance(data[1],StarFile.StarList):  # a single element loop
-                self.CreateLoop([data[0]])
-            return
-        # otherwise, we loop over the datanames
-        keyvals = zip(data[0][0],[list(a) for a in data[1][0]])
-        [self.AddSingleCifItem(a,b) for a,b in keyvals]
-        # and create the loop
-        self.CreateLoop(data[0][0])
-
-    def AddSingleCifItem(self,key,value):
-        """*Deprecated*. Use `AddItem` instead"""
-        """Add a single data item. If it is part of a loop, a separate call should be made"""
-        self.AddItem(key,value)
-
-    def loopnames(self):
-        return [self.loops[a] for a in self.loops]
-
-
-class CifFile(StarFile.StarFile):
-    def __init__(self,datasource=None,strict=1,standard='CIF',**kwargs):
-        super(CifFile,self).__init__(datasource=datasource,standard=standard, **kwargs)
-        self.strict = strict
-        self.header_comment = \
-"""
-##########################################################################
-#               Crystallographic Information Format file
-#               Produced by PyCifRW module
-#
-#  This is a CIF file.  CIF has been adopted by the International
-#  Union of Crystallography as the standard for data archiving and
-#  transmission.
-#
-#  For information on this file format, follow the CIF links at
-#  http://www.iucr.org
-##########################################################################
-"""
-
-
-class CifError(Exception):
-    def __init__(self,value):
-        self.value = value
-    def __str__(self):
-        return '\nCif Format error: '+ self.value
-
-class ValidCifError(Exception):
-    def __init__(self,value):
-        self.value = value
-    def __str__(self):
-        return '\nCif Validity error: ' + self.value
-
-class CifRecursionError(Exception):
-    def __init__(self,key_value,call_stack):
-        self.key_value = key_value
-        self.call_stack = call_stack
-    def __str__(self):
-        return "Derivation has recursed, %s seen twice (call stack %s)" % (self.key_value,repr(self.call_stack))
-
-
-class DicBlock(StarFile.StarBlock):
-    """A definition block within a dictionary, which allows imports
-    to be transparently followed"""
-
-    def __init__(self,*args,**kwargs):
-        super(DicBlock,self).__init__(*args,**kwargs)
-        self._import_cache = {}
-        
-    def __getitem__(self,dataname):
-        value = None
-        if super(DicBlock,self).has_key("_import.get") and self._import_cache:
-            value = self.follow_import(super(DicBlock,self).__getitem__("_import.get"),dataname) 
-        try:
-            final_value = super(DicBlock,self).__getitem__(dataname)
-        except KeyError:    #not there
-            final_value = value
-        if final_value is None:
-            raise KeyError("%s not found" % dataname)
-        return final_value
-
-    def has_key(self,key):
-        try:
-            self[key]
-        except KeyError:
-            return False
-        return True
-    
-    def add_dict_cache(self,name,cached):
-        """Add a loaded dictionary to this block's cache"""
-        self._import_cache[name]=cached
-        
-    def follow_import(self,import_info,dataname):
-        """Find the dataname values from the imported dictionary. `import_info`
-        is a list of import locations"""
-        latest_value = None
-        for import_ref in import_info:
-            file_loc = import_ref["file"]
-            if file_loc not in self._import_cache:
-                raise ValueError("Dictionary for import %s not found" % file_loc)
-            import_from = self._import_cache[file_loc]
-            miss = import_ref.get('miss','Exit')
-            target_key = import_ref["save"]
-            try:
-                import_target = import_from[target_key]
-            except KeyError:
-                if miss == 'Exit':
-                    raise CifError('Import frame %s not found in %s' % (target_key,file_loc))
-                else: continue
-            # now import appropriately
-            mode = import_ref.get("mode",'Contents').lower()
-            if mode == "contents":   #only this is used at this level
-                latest_value = import_target.get(dataname,latest_value)
-        return latest_value
-    
-class CifDic(StarFile.StarFile):
-    """Create a Cif Dictionary object from the provided source, which can
-    be a filename/URL or a emapsCifFile.  Optional arguments (relevant to DDLm
-    only):
-
-    * do_minimum (Boolean):
-         Do not set up the dREL system for auto-calculation or perform
-         imports.  This implies do_imports=False and do_dREL=False
-
-    * do_imports = No/Full/Contents/All:
-         If not 'No', intepret _import.get statements for
-         Full mode/Contents mode/Both respectively. See also option 'heavy'
-
-    * do_dREL = True/False:
-         Parse and convert all dREL methods to Python. Implies do_imports=All
-
-    * heavy = True/False:
-         (Experimental). If True, importation overwrites definitions. If False,
-         attributes are resolved dynamically.
-    """
-    def __init__(self,dic,do_minimum=False,do_imports='All', do_dREL=True,
-                 grammar='auto',heavy=True,**kwargs):
-        self.do_minimum = do_minimum
-        if do_minimum:
-            do_imports = 'No'
-            do_dREL = False
-        if do_dREL: do_imports = 'All'
-        if heavy == 'Light' and do_imports not in ('contents','No'):
-            raise(ValueError,"Light imports only available for mode 'contents'")
-        self.template_cache = {}    #for DDLm imports
-        self.ddlm_functions = {}    #for DDLm functions
-        self.switch_numpy(False)    #no Numpy arrays returned
-        super(CifDic,self).__init__(datasource=dic,grammar=grammar,blocktype=DicBlock,**kwargs)
-        self.standard = 'Dic'    #for correct output order
-        self.scoping = 'dictionary'
-        (self.dicname,self.diclang) = self.dic_determine()
-        print('%s is a %s dictionary' % (self.dicname,self.diclang))
-        self.scopes_mandatory = {}
-        self.scopes_naughty = {}
-        self._import_dics = []   #Non-empty for DDLm only
-        # rename and expand out definitions using "_name" in DDL dictionaries
-        if self.diclang == "DDL1":
-            self.DDL1_normalise()   #this removes any non-definition entries
-        self.create_def_block_table() #From now on, [] uses definition_id
-        if self.diclang == "DDL1":
-            self.ddl1_cat_load()
-        elif self.diclang == "DDL2":
-            self.DDL2_normalise()   #iron out some DDL2 tricky bits
-        elif self.diclang == "DDLm":
-            self.scoping = 'dictionary'   #expose all save frames
-            if do_imports is not 'No':
-                self.obtain_imports(import_mode=do_imports,heavy=heavy)#recursively calls this routine
-            self.create_alias_table()
-            self.create_cat_obj_table()
-            self.create_cat_key_table()
-            if do_dREL:
-                print('Doing full dictionary initialisation')
-                self.initialise_drel()
-        self.add_category_info(full=do_dREL)
-        # initialise type information
-        self.typedic={}
-        self.primdic = {}   #typecode<->primitive type translation
-        self.add_type_info()
-        self.install_validation_functions()
-
-    def dic_determine(self):
-        if "on_this_dictionary" in self:
-            self.master_block = super(CifDic,self).__getitem__("on_this_dictionary")
-            self.def_id_spec = "_name"
-            self.cat_id_spec = "_category.id"   #we add this ourselves
-            self.type_spec = "_type"
-            self.enum_spec = "_enumeration"
-            self.cat_spec = "_category"
-            self.esd_spec = "_type_conditions"
-            self.must_loop_spec = "_list"
-            self.must_exist_spec = "_list_mandatory"
-            self.list_ref_spec = "_list_reference"
-            self.key_spec = "_list_mandatory"
-            self.unique_spec = "_list_uniqueness"
-            self.child_spec = "_list_link_child"
-            self.parent_spec = "_list_link_parent"
-            self.related_func = "_related_function"
-            self.related_item = "_related_item"
-            self.primitive_type = "_type"
-            self.dep_spec = "xxx"
-            self.cat_list = []   #to save searching all the time
-            name = super(CifDic,self).__getitem__("on_this_dictionary")["_dictionary_name"]
-            version = super(CifDic,self).__getitem__("on_this_dictionary")["_dictionary_version"]
-            return (name+version,"DDL1")
-        elif len(self.get_roots()) == 1:              # DDL2/DDLm
-            self.master_block = super(CifDic,self).__getitem__(self.get_roots()[0][0])
-            # now change to dictionary scoping
-            self.scoping = 'dictionary'
-            name = self.master_block["_dictionary.title"]
-            version = self.master_block["_dictionary.version"]
-            if self.master_block.has_key("_dictionary.class"):   #DDLm
-                self.enum_spec = '_enumeration_set.state'
-                self.key_spec = '_category.key_id'
-                self.must_exist_spec = None
-                self.cat_spec = '_name.category_id'
-                self.primitive_type = '_type.contents'
-                self.cat_id_spec = "_definition.id"
-                self.def_id_spec = "_definition.id"
-                return(name+version,"DDLm")
-            else:   #DDL2
-                self.cat_id_spec = "_category.id"
-                self.def_id_spec = "_item.name"
-                self.key_spec = "_category_mandatory.name"
-                self.type_spec = "_item_type.code"
-                self.enum_spec = "_item_enumeration.value"
-                self.esd_spec = "_item_type_conditions.code"
-                self.cat_spec = "_item.category_id"
-                self.loop_spec = "there_is_no_loop_spec!"
-                self.must_loop_spec = "xxx"
-                self.must_exist_spec = "_item.mandatory_code"
-                self.child_spec = "_item_linked.child_name"
-                self.parent_spec = "_item_linked.parent_name"
-                self.related_func = "_item_related.function_code"
-                self.related_item = "_item_related.related_name"
-                self.unique_spec = "_category_key.name"
-                self.list_ref_spec = "xxx"
-                self.primitive_type = "_type"
-                self.dep_spec = "_item_dependent.dependent_name"
-                return (name+version,"DDL2")
-        else:
-            raise CifError("Unable to determine dictionary DDL version")
-
-    def DDL1_normalise(self):
-        # switch off block name collision checks
-        self.standard = None
-        # add default type information in DDL2 style
-        # initial types and constructs
-        base_types = ["char","numb","null"]
-        prim_types = base_types[:]
-        base_constructs = [".*",
-            '(-?(([0-9]*[.][0-9]+)|([0-9]+)[.]?)([(][0-9]+[)])?([eEdD][+-]?[0-9]+)?)|\\?|\\.',
-            "\"\" "]
-        for key,value in self.items():
-           newnames = [key]  #keep by default
-           if "_name" in value:
-               real_name = value["_name"]
-               if isinstance(real_name,list):        #looped values
-                   for looped_name in real_name:
-                      new_value = value.copy()
-                      new_value["_name"] = looped_name  #only looped name
-                      self[looped_name] = new_value
-                   newnames = real_name
-               else:
-                      self[real_name] = value
-                      newnames = [real_name]
-           # delete the old one
-           if key not in newnames:
-              del self[key]
-        # loop again to normalise the contents of each definition
-        for key,value in self.items():
-           #unlock the block
-           save_overwrite = value.overwrite
-           value.overwrite = True
-           # deal with a missing _list, _type_conditions
-           if "_list" not in value: value["_list"] = 'no'
-           if "_type_conditions" not in value: value["_type_conditions"] = 'none'
-           # deal with enumeration ranges
-           if "_enumeration_range" in value:
-               max,min = self.getmaxmin(value["_enumeration_range"])
-               if min == ".":
-                   self[key].AddLoopItem((("_item_range.maximum","_item_range.minimum"),((max,max),(max,min))))
-               elif max == ".":
-                   self[key].AddLoopItem((("_item_range.maximum","_item_range.minimum"),((max,min),(min,min))))
-               else:
-                   self[key].AddLoopItem((("_item_range.maximum","_item_range.minimum"),((max,max,min),(max,min,min))))
-           #add any type construct information
-           if "_type_construct" in value:
-               base_types.append(value["_name"]+"_type")   #ie dataname_type
-               base_constructs.append(value["_type_construct"]+"$")
-               prim_types.append(value["_type"])     #keep a record
-               value["_type"] = base_types[-1]   #the new type name
-
-        #make categories conform with ddl2
-        #note that we must remove everything from the last underscore
-           if value.get("_category",None) == "category_overview":
-                last_under = value["_name"].rindex("_")
-                catid = value["_name"][1:last_under]
-                value["_category.id"] = catid  #remove square bracks
-                if catid not in self.cat_list: self.cat_list.append(catid)
-           value.overwrite = save_overwrite
-        # we now add any missing categories before filling in the rest of the
-        # information
-        for key,value in self.items():
-            #print('processing ddl1 definition %s' % key)
-            if "_category" in self[key]:
-                if self[key]["_category"] not in self.cat_list:
-                    # rogue category, add it in
-                    newcat = self[key]["_category"]
-                    fake_name = "_" + newcat + "_[]"
-                    newcatdata = CifBlock()
-                    newcatdata["_category"] = "category_overview"
-                    newcatdata["_category.id"] = newcat
-                    newcatdata["_type"] = "null"
-                    self[fake_name] = newcatdata
-                    self.cat_list.append(newcat)
-        # write out the type information in DDL2 style
-        self.master_block.AddLoopItem((
-            ("_item_type_list.code","_item_type_list.construct",
-              "_item_type_list.primitive_code"),
-            (base_types,base_constructs,prim_types)
-            ))
-
-    def ddl1_cat_load(self):
-        deflist = self.keys()       #slight optimization
-        cat_mand_dic = {}
-        cat_unique_dic = {}
-        # a function to extract any necessary information from each definition
-        def get_cat_info(single_def):
-            if self[single_def].get(self.must_exist_spec)=='yes':
-                thiscat = self[single_def]["_category"]
-                curval = cat_mand_dic.get(thiscat,[])
-                curval.append(single_def)
-                cat_mand_dic[thiscat] = curval
-            # now the unique items...
-            # cif_core.dic throws us a curly one: the value of list_uniqueness is
-            # not the same as the defined item for publ_body_label, so we have
-            # to collect both together.  We assume a non-listed entry, which
-            # is true for all current (May 2005) ddl1 dictionaries.
-            if self[single_def].get(self.unique_spec,None)!=None:
-                thiscat = self[single_def]["_category"]
-                new_unique = self[single_def][self.unique_spec]
-                uis = cat_unique_dic.get(thiscat,[])
-                if single_def not in uis: uis.append(single_def)
-                if new_unique not in uis: uis.append(new_unique)
-                cat_unique_dic[thiscat] = uis
-
-        [get_cat_info(a) for a in deflist] # apply the above function
-        for cat in cat_mand_dic.keys():
-            self[cat]["_category_mandatory.name"] = cat_mand_dic[cat]
-        for cat in cat_unique_dic.keys():
-            self[cat]["_category_key.name"] = cat_unique_dic[cat]
-
-    def create_pcloop(self,definition):
-        old_children = self[definition].get('_item_linked.child_name',[])
-        old_parents = self[definition].get('_item_linked.parent_name',[])
-        if isinstance(old_children,unicode):
-             old_children = [old_children]
-        if isinstance(old_parents,unicode):
-             old_parents = [old_parents]
-        if (len(old_children)==0 and len(old_parents)==0) or \
-           (len(old_children) > 1 and len(old_parents)>1):
-             return
-        if len(old_children)==0:
-             old_children = [definition]*len(old_parents)
-        if len(old_parents)==0:
-             old_parents = [definition]*len(old_children)
-        newloop = CifLoopBlock(dimension=1)
-        newloop.AddLoopItem(('_item_linked.parent_name',old_parents))
-        newloop.AddLoopItem(('_item_linked.child_name',old_children))
-        try:
-            del self[definition]['_item_linked.parent_name']
-            del self[definition]['_item_linked.child_name']
-        except KeyError:
-            pass
-        self[definition].insert_loop(newloop)
-
-
-
-    def DDL2_normalise(self):
-       listed_defs = filter(lambda a:isinstance(self[a].get('_item.name'),list),self.keys())
-       # now filter out all the single element lists!
-       dodgy_defs = filter(lambda a:len(self[a]['_item.name']) > 1, listed_defs)
-       for item_def in dodgy_defs:
-                # print("DDL2 norm: processing %s" % item_def)
-                thisdef = self[item_def]
-                packet_no = thisdef['_item.name'].index(item_def)
-                realcat = thisdef['_item.category_id'][packet_no]
-                realmand = thisdef['_item.mandatory_code'][packet_no]
-                # first add in all the missing categories
-                # we don't replace the entry in the list corresponding to the
-                # current item, as that would wipe out the information we want
-                for child_no in range(len(thisdef['_item.name'])):
-                    if child_no == packet_no: continue
-                    child_name = thisdef['_item.name'][child_no]
-                    child_cat = thisdef['_item.category_id'][child_no]
-                    child_mand = thisdef['_item.mandatory_code'][child_no]
-                    if child_name not in self:
-                        self[child_name] = CifBlock()
-                        self[child_name]['_item.name'] = child_name
-                    self[child_name]['_item.category_id'] = child_cat
-                    self[child_name]['_item.mandatory_code'] = child_mand
-                self[item_def]['_item.name'] = item_def
-                self[item_def]['_item.category_id'] = realcat
-                self[item_def]['_item.mandatory_code'] = realmand
-
-       target_defs = [a for a in self.keys() if '_item_linked.child_name' in self[a] or \
-                                     '_item_linked.parent_name' in self[a]]
-       # now dodgy_defs contains all definition blocks with more than one child/parent link
-       for item_def in dodgy_defs: self.create_pcloop(item_def)           #regularise appearance
-       for item_def in dodgy_defs:
-             print('Processing %s' % item_def)
-             thisdef = self[item_def]
-             child_list = thisdef['_item_linked.child_name']
-             parents = thisdef['_item_linked.parent_name']
-             # for each parent, find the list of children.
-             family = list(zip(parents,child_list))
-             notmychildren = family         #We aim to remove non-children
-             # Loop over the parents, relocating as necessary
-             while len(notmychildren):
-                # get all children of first entry
-                mychildren = [a for a in family if a[0]==notmychildren[0][0]]
-                print("Parent %s: %d children" % (notmychildren[0][0],len(mychildren)))
-                for parent,child in mychildren:   #parent is the same for all
-                         # Make sure that we simply add in the new entry for the child, not replace it,
-                         # otherwise we might spoil the child entry loop structure
-                         try:
-                             childloop = self[child].GetLoop('_item_linked.parent_name')
-                         except KeyError:
-                             print('Creating new parent entry %s for definition %s' % (parent,child))
-                             self[child]['_item_linked.parent_name'] = [parent]
-                             childloop = self[child].GetLoop('_item_linked.parent_name')
-                             childloop.AddLoopItem(('_item_linked.child_name',[child]))
-                             continue
-                         else:
-                             # A parent loop already exists and so will a child loop due to the
-                             # call to create_pcloop above
-                             pars = [a for a in childloop if getattr(a,'_item_linked.child_name','')==child]
-                             goodpars = [a for a in pars if getattr(a,'_item_linked.parent_name','')==parent]
-                             if len(goodpars)>0:   #no need to add it
-                                 print('Skipping duplicated parent - child entry in %s: %s - %s' % (child,parent,child))
-                                 continue
-                             print('Adding %s to %s entry' % (parent,child))
-                             newpacket = childloop.GetPacket(0)   #essentially a copy, I hope
-                             setattr(newpacket,'_item_linked.child_name',child)
-                             setattr(newpacket,'_item_linked.parent_name',parent)
-                             childloop.AddPacket(newpacket)
-                #
-                # Make sure the parent also points to the children.  We get
-                # the current entry, then add our
-                # new values if they are not there already
-                #
-                parent_name = mychildren[0][0]
-                old_children = self[parent_name].get('_item_linked.child_name',[])
-                old_parents = self[parent_name].get('_item_linked.parent_name',[])
-                oldfamily = zip(old_parents,old_children)
-                newfamily = []
-                print('Old parents -> %s' % repr(old_parents))
-                for jj, childname in mychildren:
-                    alreadythere = [a for a in oldfamily if a[0]==parent_name and a[1] ==childname]
-                    if len(alreadythere)>0: continue
-                    'Adding new child %s to parent definition at %s' % (childname,parent_name)
-                    old_children.append(childname)
-                    old_parents.append(parent_name)
-                # Now output the loop, blowing away previous definitions.  If there is something
-                # else in this category, we are destroying it.
-                newloop = CifLoopBlock(dimension=1)
-                newloop.AddLoopItem(('_item_linked.parent_name',old_parents))
-                newloop.AddLoopItem(('_item_linked.child_name',old_children))
-                del self[parent_name]['_item_linked.parent_name']
-                del self[parent_name]['_item_linked.child_name']
-                self[parent_name].insert_loop(newloop)
-                print('New parents -> %s' % repr(self[parent_name]['_item_linked.parent_name']))
-                # now make a new,smaller list
-                notmychildren = [a for a in notmychildren if a[0]!=mychildren[0][0]]
-
-       # now flatten any single element lists
-       single_defs = filter(lambda a:len(self[a]['_item.name'])==1,listed_defs)
-       for flat_def in single_defs:
-           flat_keys = self[flat_def].GetLoop('_item.name').keys()
-           for flat_key in flat_keys: self[flat_def][flat_key] = self[flat_def][flat_key][0]
-       # now deal with the multiple lists
-       # next we do aliases
-       all_aliases = [a for a in self.keys() if self[a].has_key('_item_aliases.alias_name')]
-       for aliased in all_aliases:
-          my_aliases = listify(self[aliased]['_item_aliases.alias_name'])
-          for alias in my_aliases:
-              self[alias] = self[aliased].copy()   #we are going to delete stuff...
-              del self[alias]["_item_aliases.alias_name"]
-
-    def ddlm_parse_valid(self):
-        if "_dictionary_valid.application" not in self.master_block:
-            return
-        for scope_pack in self.master_block.GetLoop("_dictionary_valid.application"):
-            scope = getattr(scope_pack,"_dictionary_valid.application")
-            valid_info = getattr(scope_pack,"_dictionary_valid.attributes")
-            if scope[1] == "Mandatory":
-                self.scopes_mandatory[scope[0]] = self.expand_category_opt(valid_info)
-            elif scope[1] == "Prohibited":
-                self.scopes_naughty[scope[0]] = self.expand_category_opt(valid_info)
-
-    def obtain_imports(self,import_mode,heavy=False):
-        """Collate import information"""
-        self._import_dics = []
-        import_frames = list([(a,self[a]['_import.get']) for a in self.keys() if '_import.get' in self[a]])
-        print('Import mode %s applied to following frames' % import_mode)
-        print(str([a[0] for a in import_frames]))
-        if import_mode != 'All':
-           for i in range(len(import_frames)):
-                import_frames[i] = (import_frames[i][0],[a for a in import_frames[i][1] if a.get('mode','Contents').lower() == import_mode.lower()])
-           print('Importing following frames in mode %s' % import_mode)
-           print(str(import_frames))
-        #resolve all references
-        for parent_block,import_list in import_frames:
-          for import_ref in import_list:
-            file_loc = import_ref["file"]
-            full_uri = self.resolve_path(file_loc)
-            if full_uri not in self.template_cache:
-                dic_as_cif = CifFile(full_uri,grammar=self.grammar)
-                self.template_cache[full_uri] = CifDic(dic_as_cif,do_imports=import_mode,heavy=heavy,do_dREL=False)  #this will recurse internal imports
-                print('Added %s to cached dictionaries' % full_uri)
-            import_from = self.template_cache[full_uri]
-            dupl = import_ref.get('dupl','Exit')
-            miss = import_ref.get('miss','Exit')
-            target_key = import_ref["save"]
-            try:
-                import_target = import_from[target_key]
-            except KeyError:
-                if miss == 'Exit':
-                   raise CifError('Import frame %s not found in %s' % (target_key,full_uri))
-                else: continue
-            # now import appropriately
-            mode = import_ref.get("mode",'Contents').lower()
-            if target_key in self and mode=='full':  #so blockname will be duplicated
-                if dupl == 'Exit':
-                    raise CifError('Import frame %s already in dictionary' % target_key)
-                elif dupl == 'Ignore':
-                    continue
-            if heavy:
-                self.ddlm_import(parent_block,import_from,import_target,target_key,mode)
-            else:
-                self.ddlm_import_light(parent_block,import_from,import_target,target_key,file_loc,mode)
-                
-    def ddlm_import(self,parent_block,import_from,import_target,target_key,mode='All'):
-            """Import other dictionaries in place"""
-            if mode == 'contents':   #merge attributes only
-                self[parent_block].merge(import_target)
-            elif mode =="full":
-                # Do the syntactic merge
-                syntactic_head = self[self.get_parent(parent_block)] #root frame if no nesting
-                from_cat_head = import_target['_name.object_id']
-                child_frames = import_from.ddlm_all_children(from_cat_head)
-                 # Check for Head merging Head
-                if self[parent_block].get('_definition.class','Datum')=='Head' and \
-                   import_target.get('_definition.class','Datum')=='Head':
-                      head_to_head = True
-                else:
-                      head_to_head = False
-                      child_frames.remove(from_cat_head)
-                # As we are in syntax land, we call the CifFile methods
-                child_blocks = list([import_from.block_id_table[a.lower()] for a in child_frames])
-                child_blocks = super(CifDic,import_from).makebc(child_blocks)
-                # Prune out any datablocks that have identical definitions
-                from_defs = dict([(a,child_blocks[a].get('_definition.id','').lower()) for a in child_blocks.keys()])
-                double_defs = list([b for b in from_defs.items() if self.has_key(b[1])])
-                print('Definitions for %s superseded' % repr(double_defs))
-                for b in double_defs:
-                    del child_blocks[b[0]]
-                super(CifDic,self).merge_fast(child_blocks,parent=syntactic_head)      #
-                print('Syntactic merge of %s (%d defs) in %s mode, now have %d defs' % (target_key,len(child_frames),
-                   mode,len(self)))
-                # Now the semantic merge
-                # First expand our definition <-> blockname tree
-                self.create_def_block_table()
-                merging_cat = self[parent_block]['_name.object_id']      #new parent
-                if head_to_head:
-                    child_frames = self.ddlm_immediate_children(from_cat_head)    #old children
-                    #the new parent is the importing category for all old children
-                    for f in child_frames:
-                        self[f].overwrite = True
-                        self[f]['_name.category_id'] = merging_cat
-                        self[f].overwrite = False
-                    # remove the old head
-                    del self[from_cat_head]
-                    print('Semantic merge: %d defs reparented from %s to %s' % (len(child_frames),from_cat_head,merging_cat))
-                else:  #imported category is only child
-                    from_frame = import_from[target_key]['_definition.id'] #so we can find it
-                    child_frame = [d for d in self.keys() if self[d]['_definition.id']==from_frame][0]
-                    self[child_frame]['_name.category_id'] = merging_cat
-                    print('Semantic merge: category for %s : now %s' % (from_frame,merging_cat))
-            # it will never happen again...
-            del self[parent_block]["_import.get"]
-
-    def resolve_path(self,file_loc):
-        url_comps = urlparse(file_loc)
-        if url_comps[0]: return file_loc    #already full URI
-        new_url = urljoin(self.my_uri,file_loc)
-        #print("Transformed %s to %s for import " % (file_loc,new_url))
-        return new_url
-
-    def ddlm_import_light(self,parent_block,import_from,import_target,target_key,file_loc,mode='All'):
-        """Register the imported dictionaries but do not alter any definitions. `parent_block`
-        contains the id of the block that is importing. `import_target` is the block that
-        should be imported. `import_from` is the CifFile that contains the definitions."""
-        if mode == 'contents':   #merge attributes only
-            self[parent_block].add_dict_cache(file_loc,import_from)
-        elif mode =="full":
-             # Check for Head merging Head
-            if self[parent_block].get('_definition.class','Datum')=='Head' and \
-               import_target.get('_definition.class','Datum')=='Head':
-                   head_to_head = True
-            else:
-                   head_to_head = False
-            # Figure out the actual definition ID
-            head_id = import_target["_definition.id"]
-            # Adjust parent information
-            merging_cat = self[parent_block]['_name.object_id']
-            from_cat_head = import_target['_name.object_id']
-            if not head_to_head:   # imported category is only child
-                import_target["_name.category_id"]=merging_cat
-            self._import_dics = [(import_from,head_id)]+self._import_dics #prepend
-
-    def lookup_imports(self,key):
-        """Check the list of imported dictionaries for this definition"""
-        for one_dic,head_def in self._import_dics:
-            from_cat_head = one_dic[head_def]['_name.object_id']
-            possible_keys = one_dic.ddlm_all_children(from_cat_head)
-            if key in possible_keys:
-                return one_dic[key]
-        raise KeyError("%s not found in import dictionaries" % key)
-        
-
-
-    def create_def_block_table(self):
-        """ Create an internal table matching definition to block id """
-        proto_table = [(super(CifDic,self).__getitem__(a),a) for a in super(CifDic,self).keys()]
-        # now get the actual ids instead of blocks
-        proto_table = list([(a[0].get(self.cat_id_spec,a[0].get(self.def_id_spec,a[1])),a[1]) for a in proto_table])
-        # remove non-definitions
-        if self.diclang != "DDL1":
-            top_blocks = list([a[0].lower() for a in self.get_roots()])
-        else:
-            top_blocks = ["on_this_dictionary"]
-        # catch dodgy duplicates
-        uniques = set([a[0] for a in proto_table])
-        if len(uniques)<len(proto_table):
-            def_names = list([a[0] for a in proto_table])
-            dodgy = [a for a in def_names if def_names.count(a)>1]
-            raise CifError('Duplicate definitions in dictionary:' + repr(dodgy))
-        self.block_id_table = dict([(a[0].lower(),a[1].lower()) for a in proto_table if a[1].lower() not in top_blocks])
-
-    def __getitem__(self,key):
-        """Access a datablock by definition id, after the lookup has been created"""
-        try:
-            return super(CifDic,self).__getitem__(self.block_id_table[key.lower()])
-        except AttributeError:   #block_id_table not present yet
-            return super(CifDic,self).__getitem__(key)
-        except KeyError: # key is missing
-            try: # print(Definition for %s not found, reverting to CifFile' % key)
-                return super(CifDic,self).__getitem__(key)
-            except KeyError: # try imports
-                return self.lookup_imports(key)
-
-    def __setitem__(self,key,value):
-        """Add a new definition block"""
-        super(CifDic,self).__setitem__(key,value)
-        try:
-            self.block_id_table[value['_definition.id']]=key
-        except AttributeError:   #does not exist yet
-            pass
-
-    def NewBlock(self,*args,**kwargs):
-        newname = super(CifDic,self).NewBlock(*args,**kwargs)
-        try:
-            self.block_id_table[self[newname]['_definition.id']]=newname
-        except AttributeError: #no block_id table
-            pass
-                
-    def __delitem__(self,key):
-        """Remove a definition"""
-        try:
-            super(CifDic,self).__delitem__(self.block_id_table[key.lower()])
-            del self.block_id_table[key.lower()]
-        except (AttributeError,KeyError):   #block_id_table not present yet
-            super(CifDic,self).__delitem__(key)
-            return
-        # fix other datastructures
-        # cat_obj table
-
-    def keys(self):
-        """Return all definitions"""
-        try:
-            return self.block_id_table.keys()
-        except AttributeError:
-            return super(CifDic,self).keys()
-
-    def has_key(self,key):
-        return key in self
-
-    def __contains__(self,key):
-        try:
-            return key.lower() in self.block_id_table
-        except AttributeError:
-            return super(CifDic,self).__contains__(key)
-
-    def items(self):
-        """Return (key,value) pairs"""
-        return list([(a,self[a]) for a in self.keys()])
-
-    def unlock(self):
-        """Allow overwriting of all definitions in this collection"""
-        for a in self.keys():
-            self[a].overwrite=True
-
-    def lock(self):
-        """Disallow changes in definitions"""
-        for a in self.keys():
-            self[a].overwrite=False
-
-    def rename(self,oldname,newname,blockname_as_well=True):
-        """Change a _definition.id from oldname to newname, and if `blockname_as_well` is True,
-        change the underlying blockname too."""
-        if blockname_as_well:
-            super(CifDic,self).rename(self.block_id_table[oldname.lower()],newname)
-            self.block_id_table[newname.lower()]=newname
-            if oldname.lower() in self.block_id_table: #not removed
-               del self.block_id_table[oldname.lower()]
-        else:
-            self.block_id_table[newname.lower()]=self.block_id_table[oldname.lower()]
-            del self.block_id_table[oldname.lower()]
-            return
-
-    def get_root_category(self):
-        """Get the single 'Head' category of this dictionary"""
-        root_cats = [r for r in self.keys() if self[r].get('_definition.class','Datum')=='Head']
-        if len(root_cats)>1 or len(root_cats)==0:
-            raise CifError("Cannot determine a unique Head category, got" % repr(root_cats))
-        return root_cats[0]
-
-    def ddlm_immediate_children(self,catname):
-        """Return a list of datanames for the immediate children of catname.  These are
-        semantic children (i.e. based on _name.category_id), not structural children as
-        in the case of StarFile.get_immediate_children"""
-
-        straight_children = [a for a in self.keys() if self[a].get('_name.category_id','').lower() == catname.lower()]
-        return list(straight_children)
-
-    def ddlm_all_children(self,catname):
-        """Return a list of all children, including the `catname`"""
-        all_children = self.ddlm_immediate_children(catname)
-        cat_children = [a for a in all_children if self[a].get('_definition.scope','Item') == 'Category']
-        for c in cat_children:
-            all_children.remove(c)
-            all_children += self.ddlm_all_children(c)
-        return all_children + [catname]
-
-    def is_semantic_child(self,parent,maybe_child):
-        """Return true if `maybe_child` is a child of `parent`"""
-        all_children = self.ddlm_all_children(parent)
-        return maybe_child in all_children
-
-    def ddlm_danglers(self):
-        """Return a list of definitions that do not have a category defined
-        for them, or are children of an unattached category"""
-        top_block = self.get_root_category()
-        connected = set(self.ddlm_all_children(top_block))
-        all_keys = set(self.keys())
-        unconnected = all_keys - connected
-        return list(unconnected)
-
-    def get_ddlm_parent(self,itemname):
-        """Get the parent category of itemname"""
-        parent = self[itemname].get('_name.category_id','')
-        if parent == '':  # use the top block by default
-            raise CifError("%s has no parent" % itemname)
-        return parent
-
-    def expand_category_opt(self,name_list):
-        """Return a list of all non-category items in a category or return the name
-           if the name is not a category"""
-        new_list = []
-        for name in name_list:
-          if self.get(name,{}).get('_definition.scope','Item') == 'Category':
-            new_list += self.expand_category_opt([a for a in self.keys() if \
-                     self[a].get('_name.category_id','').lower() == name.lower()])
-          else:
-            new_list.append(name)
-        return new_list
-
-    def get_categories(self):
-        """Return a list of category names"""
-        return list([c for c in self.keys() if self[c].get("_definition.scope")=='Category'])
-
-    def names_in_cat(self,cat,names_only=False):
-        names = [a for a in self.keys() if self[a].get('_name.category_id','').lower()==cat.lower()]
-        if not names_only:
-            return list([a for a in names if self[a].get('_definition.scope','Item')=='Item'])
-        else:
-            return list([self[a]["_name.object_id"] for a in names])
-
-
-
-    def create_alias_table(self):
-        """Populate an alias table that we can look up when searching for a dataname"""
-        all_aliases = [a for a in self.keys() if '_alias.definition_id' in self[a]]
-        self.alias_table = dict([[a,self[a]['_alias.definition_id']] for a in all_aliases])
-
-    def create_cat_obj_table(self):
-        """Populate a table indexed by (cat,obj) and returning the correct dataname"""
-        base_table = dict([((self[a].get('_name.category_id','').lower(),self[a].get('_name.object_id','').lower()),[self[a].get('_definition.id','')]) \
-                           for a in self.keys() if self[a].get('_definition.scope','Item')=='Item'])
-        loopable = self.get_loopable_cats()
-        loopers = [self.ddlm_immediate_children(a) for a in loopable]
-        print('Loopable cats:' + repr(loopable))
-        loop_children = [[b for b in a if b.lower() in loopable ] for a in loopers]
-        expand_list = dict([(a,b) for a,b in zip(loopable,loop_children) if len(b)>0])
-        print("Expansion list:" + repr(expand_list))
-        extra_table = {}   #for debugging we keep it separate from base_table until the end
-        def expand_base_table(parent_cat,child_cats):
-            extra_names = []
-            # first deal with all the child categories
-            for child_cat in child_cats:
-              nn = []
-              if child_cat in expand_list:  # a nested category: grab its names
-                nn = expand_base_table(child_cat,expand_list[child_cat])
-                # store child names
-                extra_names += nn
-              # add all child names to the table
-              child_names = [(self[n]['_name.object_id'].lower(),self[n]['_definition.id']) \
-                             for n in self.names_in_cat(child_cat) if self[n].get('_type.purpose','') != 'Key']
-              child_names += extra_names
-              extra_table.update(dict([((parent_cat,obj),[name]) for obj,name in child_names if (parent_cat,name) not in extra_table]))
-            # and the repeated ones get appended instead
-            repeats = [a for a in child_names if a in extra_table]
-            for obj,name in repeats:
-                extra_table[(parent_cat,obj)] += [name]
-            # and finally, add our own names to the return list
-            child_names += [(self[n]['_name.object_id'].lower(),self[n]['_definition.id']) \
-                            for n in self.names_in_cat(parent_cat) if self[n].get('_type.purpose','')!='Key']
-            return child_names
-        [expand_base_table(parent,child) for parent,child in expand_list.items()]
-        print('Expansion cat/obj values: ' + repr(extra_table))
-        # append repeated ones
-        non_repeats = dict([a for a in extra_table.items() if a[0] not in base_table])
-        repeats = [a for a in extra_table.keys() if a in base_table]
-        base_table.update(non_repeats)
-        for k in repeats:
-            base_table[k] += extra_table[k]
-        self.cat_obj_lookup_table = base_table
-        self.loop_expand_list = expand_list
-
-    def get_loopable_cats(self):
-        """A short utility function which returns a list of looped categories. This
-        is preferred to a fixed attribute as that fixed attribute would need to be
-        updated after any edits"""
-        return [a.lower() for a in self.keys() if self[a].get('_definition.class','')=='Loop']
-
-    def create_cat_key_table(self):
-        """Create a utility table with a list of keys applicable to each category. A key is
-        a compound key, that is, it is a list"""
-        self.cat_key_table = dict([(c,[listify(self[c].get("_category_key.name",
-            [self[c].get("_category.key_id")]))]) for c in self.get_loopable_cats()])
-        def collect_keys(parent_cat,child_cats):
-                kk = []
-                for child_cat in child_cats:
-                    if child_cat in self.loop_expand_list:
-                        kk += collect_keys(child_cat)
-                    # add these keys to our list
-                    kk += [listify(self[child_cat].get('_category_key.name',[self[child_cat].get('_category.key_id')]))]
-                self.cat_key_table[parent_cat] = self.cat_key_table[parent_cat] + kk
-                return kk
-        for k,v in self.loop_expand_list.items():
-            collect_keys(k,v)
-        print('Keys for categories' + repr(self.cat_key_table))
-
-    def add_type_info(self):
-        if "_item_type_list.construct" in self.master_block:
-            types = self.master_block["_item_type_list.code"]
-            prim_types = self.master_block["_item_type_list.primitive_code"]
-            constructs = list([a + "$" for a in self.master_block["_item_type_list.construct"]])
-            # add in \r wherever we see \n, and change \{ to \\{
-            def regex_fiddle(mm_regex):
-                brack_match = r"((.*\[.+)(\\{)(.*\].*))"
-                ret_match = r"((.*\[.+)(\\n)(.*\].*))"
-                fixed_regexp = mm_regex[:]  #copy
-                # fix the brackets
-                bm = re.match(brack_match,mm_regex)
-                if bm != None:
-                    fixed_regexp = bm.expand(r"\2\\\\{\4")
-                # fix missing \r
-                rm = re.match(ret_match,fixed_regexp)
-                if rm != None:
-                    fixed_regexp = rm.expand(r"\2\3\\r\4")
-                #print("Regexp %s becomes %s" % (mm_regex,fixed_regexp))
-                return fixed_regexp
-            constructs = map(regex_fiddle,constructs)
-            for typecode,construct in zip(types,constructs):
-                self.typedic[typecode] = re.compile(construct,re.MULTILINE|re.DOTALL)
-            # now make a primitive <-> type construct mapping
-            for typecode,primtype in zip(types,prim_types):
-                self.primdic[typecode] = primtype
-
-    def add_category_info(self,full=True):
-        if self.diclang == "DDLm":
-            catblocks = [c for c in self.keys() if self[c].get('_definition.scope')=='Category']
-            looped_cats = [a for a in catblocks if self[a].get('_definition.class','Set') == 'Loop']
-            self.parent_lookup = {}
-            for one_cat in looped_cats:
-                parent_cat = one_cat
-                parent_def = self[parent_cat]
-                next_up = parent_def['_name.category_id'].lower()
-                while next_up in self and self[next_up].get('_definition.class','Set') == 'Loop':
-                    parent_def = self[next_up]
-                    parent_cat = next_up
-                    next_up = parent_def['_name.category_id'].lower()
-                self.parent_lookup[one_cat] = parent_cat
-
-            if full:
-                self.key_equivs = {}
-                for one_cat in looped_cats:   #follow them up
-                    lower_keys = listify(self[one_cat]['_category_key.name'])
-                    start_keys = lower_keys[:]
-                    while len(lower_keys)>0:
-                        this_cat = self[lower_keys[0]]['_name.category_id']
-                        parent = [a for a in looped_cats if self[this_cat]['_name.category_id'].lower()==a]
-                        #print(Processing %s, keys %s, parent %s" % (this_cat,repr(lower_keys),repr(parent)))
-                        if len(parent)>1:
-                            raise CifError("Category %s has more than one parent: %s" % (one_cat,repr(parent)))
-                        if len(parent)==0: break
-                        parent = parent[0]
-                        parent_keys = listify(self[parent]['_category_key.name'])
-                        linked_keys = [self[l]["_name.linked_item_id"] for l in lower_keys]
-                        # sanity check
-                        if set(parent_keys) != set(linked_keys):
-                            raise CifError("Parent keys and linked keys are different! %s/%s" % (parent_keys,linked_keys))
-                            # now add in our information
-                        for parent,child in zip(linked_keys,start_keys):
-                            self.key_equivs[child] = self.key_equivs.get(child,[])+[parent]
-                        lower_keys = linked_keys  #preserves order of start keys
-
-        else:
-            self.parent_lookup = {}
-            self.key_equivs = {}
-
-    def change_category_name(self,oldname,newname):
-        self.unlock()
-        """Change the category name from [[oldname]] to [[newname]]"""
-        if oldname not in self:
-            raise KeyError('Cannot rename non-existent category %s to %s' % (oldname,newname))
-        if newname in self:
-            raise KeyError('Cannot rename %s to %s as %s already exists' % (oldname,newname,oldname))
-        child_defs = self.ddlm_immediate_children(oldname)
-        self.rename(oldname,newname)   #NB no name integrity checks
-        self[newname]['_name.object_id']=newname
-        self[newname]['_definition.id']=newname
-        for child_def in child_defs:
-            self[child_def]['_name.category_id'] = newname
-            if self[child_def].get('_definition.scope','Item')=='Item':
-                newid = self.create_catobj_name(newname,self[child_def]['_name.object_id'])
-                self[child_def]['_definition.id']=newid
-                self.rename(child_def,newid[1:])  #no underscore at the beginning
-        self.lock()
-
-    def create_catobj_name(self,cat,obj):
-        """Combine category and object in approved fashion to create id"""
-        return ('_'+cat+'.'+obj)
-
-    def change_category(self,itemname,catname):
-        """Move itemname into catname, return new handle"""
-        defid = self[itemname]
-        if defid['_name.category_id'].lower()==catname.lower():
-            print('Already in category, no change')
-            return itemname
-        if catname not in self:    #don't have it
-            print('No such category %s' % catname)
-            return itemname
-        self.unlock()
-        objid = defid['_name.object_id']
-        defid['_name.category_id'] = catname
-        newid = itemname # stays the same for categories
-        if defid.get('_definition.scope','Item') == 'Item':
-            newid = self.create_catobj_name(catname,objid)
-            defid['_definition.id']= newid
-            self.rename(itemname,newid)
-        self.set_parent(catname,newid)
-        self.lock()
-        return newid
-
-    def change_name(self,one_def,newobj):
-        """Change the object_id of one_def to newobj. This is not used for
-        categories, but can be used for dictionaries"""
-        if '_dictionary.title' not in self[one_def]:  #a dictionary block
-            newid = self.create_catobj_name(self[one_def]['_name.category_id'],newobj)
-            self.unlock()
-            self.rename(one_def,newid)
-            self[newid]['_definition.id']=newid
-            self[newid]['_name.object_id']=newobj
-        else:
-            self.unlock()
-            newid = newobj
-            self.rename(one_def,newobj)
-            self[newid]['_dictionary.title'] = newid
-        self.lock()
-        return newid
-
-    # Note that our semantic parent is given by catparent, but our syntactic parent is
-    # always just the root block
-    def add_category(self,catname,catparent=None,is_loop=True,allow_dangler=False):
-        """Add a new category to the dictionary with name [[catname]].
-           If [[catparent]] is None, the category will be a child of
-           the topmost 'Head' category or else the top data block. If
-           [[is_loop]] is false, a Set category is created. If [[allow_dangler]]
-           is true, the parent category does not have to exist."""
-        if catname in self:
-            raise CifError('Attempt to add existing category %s' % catname)
-        self.unlock()
-        syntactic_root = self.get_roots()[0][0]
-        if catparent is None:
-            semantic_root = [a for a in self.keys() if self[a].get('_definition.class',None)=='Head']
-            if len(semantic_root)>0:
-                semantic_root = semantic_root[0]
-            else:
-                semantic_root = syntactic_root
-        else:
-            semantic_root = catparent
-        realname = super(CifDic,self).NewBlock(catname,parent=syntactic_root)
-        self.block_id_table[catname.lower()]=realname
-        self[catname]['_name.object_id'] = catname
-        if not allow_dangler or catparent is None:
-            self[catname]['_name.category_id'] = self[semantic_root]['_name.object_id']
-        else:
-            self[catname]['_name.category_id'] = catparent
-        self[catname]['_definition.id'] = catname
-        self[catname]['_definition.scope'] = 'Category'
-        if is_loop:
-            self[catname]['_definition.class'] = 'Loop'
-        else:
-            self[catname]['_definition.class'] = 'Set'
-        self[catname]['_description.text'] = 'No definition provided'
-        self.lock()
-        return catname
-
-    def add_definition(self,itemname,catparent,def_text='PLEASE DEFINE ME',allow_dangler=False):
-        """Add itemname to category [[catparent]]. If itemname contains periods,
-        all text before the final period is ignored. If [[allow_dangler]] is True,
-        no check for a parent category is made."""
-        self.unlock()
-        if '.' in itemname:
-            objname = itemname.split('.')[-1]
-        else:
-            objname = itemname
-        objname = objname.strip('_')
-        if not allow_dangler and (catparent not in self or self[catparent]['_definition.scope']!='Category'):
-            raise CifError('No category %s in dictionary' % catparent)
-        fullname = '_'+catparent.lower()+'.'+objname
-        print('New name: %s' % fullname)
-        syntactic_root = self.get_roots()[0][0]
-        realname = super(CifDic,self).NewBlock(fullname, fix=False, parent=syntactic_root) #low-level change
-        # update our dictionary structures
-        self.block_id_table[fullname]=realname
-        self[fullname]['_definition.id']=fullname
-        self[fullname]['_name.object_id']=objname
-        self[fullname]['_name.category_id']=catparent
-        self[fullname]['_definition.class']='Datum'
-        self[fullname]['_description.text']=def_text
-        return realname
-
-    def remove_definition(self,defname):
-        """Remove a definition from the dictionary."""
-        if defname not in self:
-            return
-        if self[defname].get('_definition.scope')=='Category':
-            children = self.ddlm_immediate_children(defname)
-            [self.remove_definition(a) for a in children]
-            cat_id = self[defname]['_definition.id'].lower()
-        del self[defname]
-
-    def get_cat_obj(self,name):
-        """Return (cat,obj) tuple. [[name]] must contain only a single period"""
-        cat,obj = name.split('.')
-        return (cat.strip('_'),obj)
-
-    def get_name_by_cat_obj(self,category,object,give_default=False):
-        """Return the dataname corresponding to the given category and object"""
-        if category[0] == '_':    #accidentally left in
-           true_cat = category[1:].lower()
-        else:
-           true_cat = category.lower()
-        try:
-            return self.cat_obj_lookup_table[(true_cat,object.lower())][0]
-        except KeyError:
-            if give_default:
-               return '_'+true_cat+'.'+object
-        raise KeyError('No such category,object in the dictionary: %s %s' % (true_cat,object))
-
-
-    def WriteOut(self,**kwargs):
-        myblockorder = self.get_full_child_list()
-        self.set_grammar(self.grammar)
-        self.standard = 'Dic'
-        return super(CifDic,self).WriteOut(blockorder = myblockorder,**kwargs)
-
-    def get_full_child_list(self):
-        """Return a list of definition blocks in order parent-child-child-child-parent-child..."""
-        top_block = self.get_roots()[0][0]
-        root_cat = [a for a in self.keys() if self[a].get('_definition.class','Datum')=='Head']
-        if len(root_cat) == 1:
-            all_names = [top_block] + self.recurse_child_list(root_cat[0])
-            unrooted = self.ddlm_danglers()
-            double_names =  set(unrooted).intersection(set(all_names))
-            if len(double_names)>0:
-                raise CifError('Names are children of internal and external categories:%s' % repr(double_names))
-            remaining = unrooted[:]
-            for no_root in unrooted:
-                if self[no_root].get('_definition.scope','Item')=='Category':
-                    all_names += [no_root]
-                    remaining.remove(no_root)
-                    these_children = [n for n in unrooted if self[n]['_name.category_id'].lower()==no_root.lower()]
-                    all_names += these_children
-                    [remaining.remove(n) for n in these_children]
-            # now sort by category
-            ext_cats = set([self[r].get('_name.category_id',self.cat_from_name(r)).lower() for r in remaining])
-            for e in ext_cats:
-                cat_items = [r for r in remaining if self[r].get('_name.category_id',self.cat_from_name(r)).lower() == e]
-                [remaining.remove(n) for n in cat_items]
-                all_names += cat_items
-            if len(remaining)>0:
-                print('WARNING: following items do not seem to belong to a category??')
-                print(repr(remaining))
-                all_names += remaining
-            print('Final block order: ' + repr(all_names))
-            return all_names
-        raise ValueError('Dictionary contains no/multiple Head categories, please print as plain CIF instead')
-
-    def cat_from_name(self,one_name):
-        """Guess the category from the name. This should be used only when this is not important semantic information,
-        for example, when printing out"""
-        (cat,obj) = one_name.split(".")
-        if cat[0] == "_": cat = cat[1:]
-        return cat
-
-    def recurse_child_list(self,parentname):
-        """Recursively expand the logical child list of [[parentname]]"""
-        final_list = [parentname]
-        child_blocks = [a for a in self.child_table.keys() if self[a].get('_name.category_id','').lower() == parentname.lower()]
-        child_blocks.sort()    #we love alphabetical order
-        child_items = [a for a in child_blocks if self[a].get('_definition.scope','Item') == 'Item']
-        final_list += child_items
-        child_cats = [a for a in child_blocks if self[a].get('_definition.scope','Item') == 'Category']
-        for child_cat in child_cats:
-            final_list += self.recurse_child_list(child_cat)
-        return final_list
-
-
-
-    def get_key_pack(self,category,value,data):
-        keyname = self[category][self.unique_spec]
-        onepack = data.GetPackKey(keyname,value)
-        return onepack
-
-    def get_number_with_esd(numstring):
-        numb_re = '((-?(([0-9]*[.]([0-9]+))|([0-9]+)[.]?))([(][0-9]+[)])?([eEdD][+-]?[0-9]+)?)|(\\?)|(\\.)'
-        our_match = re.match(numb_re,numstring)
-        if our_match:
-            a,base_num,b,c,dad,dbd,esd,exp,q,dot = our_match.groups()
-            # print("Debug: {} -> {!r}".format(numstring, our_match.groups()))
-        else:
-            return None,None
-        if dot or q: return None,None     #a dot or question mark
-        if exp:          #has exponent
-           exp = exp.replace("d","e")     # mop up old fashioned numbers
-           exp = exp.replace("D","e")
-           base_num = base_num + exp
-        # print("Debug: have %s for base_num from %s" % (base_num,numstring))
-        base_num = float(base_num)
-        # work out esd, if present.
-        if esd:
-            esd = float(esd[1:-1])    # no brackets
-            if dad:                   # decimal point + digits
-                esd = esd * (10 ** (-1* len(dad)))
-            if exp:
-                esd = esd * (10 ** (float(exp[1:])))
-        return base_num,esd
-
-    def getmaxmin(self,rangeexp):
-        regexp = '(-?(([0-9]*[.]([0-9]+))|([0-9]+)[.]?)([eEdD][+-]?[0-9]+)?)*'
-        regexp = regexp + ":" + regexp
-        regexp = re.match(regexp,rangeexp)
-        try:
-            minimum = regexp.group(1)
-            maximum = regexp.group(7)
-        except AttributeError:
-            print("Can't match %s" % rangeexp)
-        if minimum == None: minimum = "."
-        else: minimum = float(minimum)
-        if maximum == None: maximum = "."
-        else: maximum = float(maximum)
-        return maximum,minimum
-
-    def initialise_drel(self):
-        """Parse drel functions and prepare data structures in dictionary"""
-        self.ddlm_parse_valid() #extract validity information from data block
-        self.transform_drel()   #parse the drel functions
-        self.add_drel_funcs()   #put the drel functions into the namespace
-
-    def transform_drel(self):
-        from .drel import drel_ast_yacc
-        from .drel import py_from_ast
-        import traceback
-        parser = drel_ast_yacc.parser
-        lexer = drel_ast_yacc.lexer
-        my_namespace = self.keys()
-        my_namespace = dict(zip(my_namespace,my_namespace))
-        # we provide a table of loopable categories {cat_name:((key1,key2..),[item_name,...]),...})
-        loopable_cats = self.get_loopable_cats()
-        loop_keys = [listify(self[a]["_category_key.name"]) for a in loopable_cats]
-        loop_keys = [[self[a]['_name.object_id'] for a in b] for b in loop_keys]
-        cat_names = [self.names_in_cat(a,names_only=True) for a in loopable_cats]
-        loop_info = dict(zip(loopable_cats,zip(loop_keys,cat_names)))
-        # parser.listable_items = [a for a in self.keys() if "*" in self[a].get("_type.dimension","")]
-        derivable_list = [a for a in self.keys() if "_method.expression" in self[a] \
-                              and self[a].get("_name.category_id","")!= "function"]
-        for derivable in derivable_list:
-            target_id = derivable
-            # reset the list of visible names for parser
-            special_ids = [dict(zip(self.keys(),self.keys()))]
-            print("Target id: %s" % derivable)
-            drel_exprs = self[derivable]["_method.expression"]
-            drel_purposes = self[derivable]["_method.purpose"]
-            all_methods = []
-            if not isinstance(drel_exprs,list):
-                drel_exprs = [drel_exprs]
-                drel_purposes = [drel_purposes]
-            for drel_purpose,drel_expr in zip(drel_purposes,drel_exprs):
-                if drel_purpose != 'Evaluation':
-                    continue
-                drel_expr = "\n".join(drel_expr.splitlines())
-                # print("Transforming %s" % drel_expr)
-                # List categories are treated differently...
-                try:
-                    meth_ast = parser.parse(drel_expr+"\n",lexer=lexer)
-                except:
-                    print('Syntax error in method for %s; leaving as is' % derivable)
-                    a,b = sys.exc_info()[:2]
-                    print((repr(a),repr(b)))
-                    print(traceback.print_tb(sys.exc_info()[-1],None,sys.stdout))
-                    # reset the lexer
-                    lexer.begin('INITIAL')
-                    continue
-                # Construct the python method
-                cat_meth = False
-                if self[derivable].get('_definition.scope','Item') == 'Category':
-                    cat_meth = True
-                pyth_meth = py_from_ast.make_python_function(meth_ast,"pyfunc",target_id,
-                                                                           loopable=loop_info,
-                                                             cif_dic = self,cat_meth=cat_meth)
-                all_methods.append(pyth_meth)
-            if len(all_methods)>0:
-                save_overwrite = self[derivable].overwrite
-                self[derivable].overwrite = True
-                self[derivable]["_method.py_expression"] = all_methods
-                self[derivable].overwrite = save_overwrite
-            #print("Final result:\n " + repr(self[derivable]["_method.py_expression"]))
-
-    def add_drel_funcs(self):
-        from .drel import drel_ast_yacc
-        from .drel import py_from_ast
-        funclist = [a for a in self.keys() if self[a].get("_name.category_id","")=='function']
-        funcnames = [(self[a]["_name.object_id"],
-                      getattr(self[a].GetKeyedPacket("_method.purpose","Evaluation"),"_method.expression")) for a in funclist]
-        # create executable python code...
-        parser = drel_ast_yacc.parser
-        # we provide a table of loopable categories {cat_name:(key,[item_name,...]),...})
-        loopable_cats = self.get_loopable_cats()
-        loop_keys = [listify(self[a]["_category_key.name"]) for a in loopable_cats]
-        loop_keys = [[self[a]['_name.object_id'] for a in b] for b in loop_keys]
-        cat_names = [self.names_in_cat(a,names_only=True) for a in loopable_cats]
-        loop_info = dict(zip(loopable_cats,zip(loop_keys,cat_names)))
-        for funcname,funcbody in funcnames:
-            newline_body = "\n".join(funcbody.splitlines())
-            parser.target_id = funcname
-            res_ast = parser.parse(newline_body)
-            py_function = py_from_ast.make_python_function(res_ast,None,targetname=funcname,func_def=True,loopable=loop_info,cif_dic = self)
-            #print('dREL library function ->\n' + py_function)
-            global_table = globals()
-            exec(py_function, global_table)    #add to namespace
-        #print('Globals after dREL functions added:' + repr(globals()))
-        self.ddlm_functions = globals()  #for outside access
-
-    @track_recursion
-    def derive_item(self,start_key,cifdata,store_value = False,allow_defaults=True):
-        key = start_key   #starting value
-        result = None     #success is a non-None value
-        default_result = False #we have not used a default value
-        # check for aliases
-        # check for an older form of a new value
-        found_it = [k for k in self.alias_table.get(key,[]) if k in cifdata]
-        if len(found_it)>0:
-            corrected_type = self.change_type(key,cifdata[found_it[0]])
-            return corrected_type
-        # now do the reverse check - any alternative form
-        alias_name = [a for a in self.alias_table.items() if key in a[1]]
-        print('Aliases for %s: %s' % (key,repr(alias_name)))
-        if len(alias_name)==1:
-            key = alias_name[0][0]   #actual definition name
-            if key in cifdata: return self.change_type(key,cifdata[key])
-            found_it = [k for k in alias_name[0][1] if k in cifdata]
-            if len(found_it)>0:
-                return self.change_type(key,cifdata[found_it[0]])
-        elif len(alias_name)>1:
-            raise CifError('Dictionary error: dataname alias appears in different definitions: ' + repr(alias_name))
-
-        the_category = self[key]["_name.category_id"]
-        cat_names = [a for a in self.keys() if self[a].get("_name.category_id",None)==the_category]
-        has_cat_names = [a for a in cat_names if cifdata.has_key_or_alias(a)]
-        # store any default value in case we have a problem
-        def_val = self[key].get("_enumeration.default","")
-        def_index_val = self[key].get("_enumeration.def_index_id","")
-        if len(has_cat_names)==0: # try category method
-            cat_result = {}
-            pulled_from_cats = [k for k in self.keys() if '_category_construct_local.components' in self[k]]
-            pulled_from_cats = [(k,[
-                                  self[n]['_name.category_id'] for n in self[k]['_category_construct_local.components']]
-                               ) for k in pulled_from_cats]
-            pulled_to_cats = [k[0] for k in pulled_from_cats if the_category in k[1]]
-            if '_category_construct_local.type' in self[the_category]:
-                print("**Now constructing category %s using DDLm attributes**" % the_category)
-                try:
-                    cat_result = self.construct_category(the_category,cifdata,store_value=True)
-                except (CifRecursionError,StarFile.StarDerivationError):
-                    print('** Failed to construct category %s (error)' % the_category)
-            # Trying a pull-back when the category is partially populated
-            # will not work, hence we test that cat_result has no keys
-            if len(pulled_to_cats)>0 and len(cat_result)==0:
-                print("**Now populating category %s from pulled-back category %s" % (the_category,repr(pulled_to_cats)))
-                try:
-                    cat_result = self.push_from_pullback(the_category,pulled_to_cats,cifdata,store_value=True)
-                except (CifRecursionError,StarFile.StarDerivationError):
-                    print('** Failed to construct category %s from pullback information (error)' % the_category)
-            if '_method.py_expression' in self[the_category] and key not in cat_result:
-                print("**Now applying category method for %s in search of %s**" % (the_category,key))
-                cat_result = self.derive_item(the_category,cifdata,store_value=True)
-            print("**Tried pullbacks, obtained for %s " % the_category + repr(cat_result))
-            # do we now have our value?
-            if key in cat_result:
-                return cat_result[key]
-
-        # Recalculate in case it actually worked
-        has_cat_names = [a for a in cat_names if cifdata.has_key_or_alias(a)]
-        the_funcs = self[key].get('_method.py_expression',"")
-        if the_funcs:   #attempt to calculate it
-            #global_table = globals()
-            #global_table.update(self.ddlm_functions)
-            for one_func in the_funcs:
-                print('Executing function for %s:' % key)
-                #print(one_func)
-                exec(one_func, globals())  #will access dREL functions, puts "pyfunc" in scope
-                # print('in following global environment: ' + repr(global_table))
-                stored_setting = cifdata.provide_value
-                cifdata.provide_value = True
-                try:
-                    result = pyfunc(cifdata)
-                except CifRecursionError as s:
-                    print(s)
-                    result = None
-                except StarFile.StarDerivationError as s:
-                    print(s)
-                    result = None
-                finally:
-                    cifdata.provide_value = stored_setting
-                if result is not None:
-                    break
-                #print("Function returned {!r}".format(result))
-
-        if result is None and allow_defaults:   # try defaults
-            if def_val:
-                result = self.change_type(key,def_val)
-                default_result = True
-            elif def_index_val:            #derive a default value
-                index_vals = self[key]["_enumeration_default.index"]
-                val_to_index = cifdata[def_index_val]     #what we are keying on
-                if self[def_index_val]['_type.contents'] in ['Code','Name','Tag']:
-                    lcase_comp = True
-                    index_vals = [a.lower() for a in index_vals]
-                # Handle loops
-                if isinstance(val_to_index,list):
-                    if lcase_comp:
-                        val_to_index = [a.lower() for a in val_to_index]
-                    keypos = [index_vals.index(a) for a in val_to_index]
-                    result = [self[key]["_enumeration_default.value"][a]  for a in keypos]
-                else:
-                    if lcase_comp:
-                        val_to_index = val_to_index.lower()
-                    keypos = index_vals.index(val_to_index)   #value error if no such value available
-                    result = self[key]["_enumeration_default.value"][keypos]
-                    default_result = True   #flag that it must be extended
-                result = self.change_type(key,result)
-                print("Indexed on %s to get %s for %s" % (def_index_val,repr(result),repr(val_to_index)))
-
-        # read it in
-        if result is None:   #can't do anything else
-            print('Warning: no way of deriving item %s, allow_defaults is %s' % (key,repr(allow_defaults)))
-            raise StarFile.StarDerivationError(start_key)
-        is_looped = False
-        if self[the_category].get('_definition.class','Set')=='Loop':
-            is_looped = True
-            if len(has_cat_names)>0:   #this category already exists
-                if result is None or default_result: #need to create a list of values
-                    loop_len = len(cifdata[has_cat_names[0]])
-                    out_result = [result]*loop_len
-                    result = out_result
-            else:   #nothing exists in this category, we can't store this at all
-                print('Resetting result %s for %s to null list as category is empty' % (key,result))
-                result = []
-
-        # now try to insert the new information into the right place
-        # find if items of this category already appear...
-        # Never cache empty values
-        if not (isinstance(result,list) and len(result)==0) and\
-          store_value:
-            if self[key].get("_definition.scope","Item")=='Item':
-                if is_looped:
-                    result = self.store_new_looped_value(key,cifdata,result,default_result)
-                else:
-                    result = self.store_new_unlooped_value(key,cifdata,result)
-            else:
-                self.store_new_cat_values(cifdata,result,the_category)
-        return result
-
-    def store_new_looped_value(self,key,cifdata,result,default_result):
-          """Store a looped value from the dREL system into a CifFile"""
-          # try to change any matrices etc. to lists
-          the_category = self[key]["_name.category_id"]
-          out_result = result
-          if result is not None and not default_result:
-                  # find any numpy arrays
-                  def conv_from_numpy(one_elem):
-                      if not hasattr(one_elem,'dtype'):
-                         if isinstance(one_elem,(list,tuple)):
-                            return StarFile.StarList([conv_from_numpy(a) for a in one_elem])
-                         return one_elem
-                      if one_elem.size > 1:   #so is not a float
-                         return StarFile.StarList([conv_from_numpy(a) for a in one_elem.tolist()])
-                      else:
-                          try:
-                            return one_elem.item(0)
-                          except:
-                            return one_elem
-                  out_result = [conv_from_numpy(a) for a in result]
-          # so out_result now contains a value suitable for storage
-          cat_names = [a for a in self.keys() if self[a].get("_name.category_id",None)==the_category]
-          has_cat_names = [a for a in cat_names if a in cifdata]
-          print('Adding {}, found pre-existing names: '.format(key) + repr(has_cat_names))
-          if len(has_cat_names)>0:   #this category already exists
-              cifdata[key] = out_result      #lengths must match or else!!
-              cifdata.AddLoopName(has_cat_names[0],key)
-          else:
-              cifdata[key] = out_result
-              cifdata.CreateLoop([key])
-          print('Loop info:' + repr(cifdata.loops))
-          return out_result
-
-    def store_new_unlooped_value(self,key,cifdata,result):
-          """Store a single value from the dREL system"""
-          if result is not None and hasattr(result,'dtype'):
-              if result.size > 1:
-                  out_result = StarFile.StarList(result.tolist())
-                  cifdata[key] = out_result
-              else:
-                  cifdata[key] = result.item(0)
-          else:
-              cifdata[key] = result
-          return result
-
-    def construct_category(self,category,cifdata,store_value=True):
-        """Construct a category using DDLm attributes"""
-        con_type = self[category].get('_category_construct_local.type',None)
-        if con_type == None:
-            return {}
-        if con_type == 'Pullback' or con_type == 'Filter':
-            morphisms  = self[category]['_category_construct_local.components']
-            morph_values = [cifdata[a] for a in morphisms] # the mapped values for each cat
-            cats = [self[a]['_name.category_id'] for a in morphisms]
-            cat_keys = [self[a]['_category.key_id'] for a in cats]
-            cat_values = [list(cifdata[a]) for a in cat_keys] #the category key values for each cat
-            if con_type == 'Filter':
-                int_filter = self[category].get('_category_construct_local.integer_filter',None)
-                text_filter = self[category].get('_category_construct_local.text_filter',None)
-                if int_filter is not None:
-                    morph_values.append([int(a) for a in int_filter])
-                if text_filter is not None:
-                    morph_values.append(text_filter)
-                cat_values.append(range(len(morph_values[-1])))
-            # create the mathematical product filtered by equality of dataname values
-            pullback_ids = [(x,y) for x in cat_values[0] for y in cat_values[1] \
-                            if morph_values[0][cat_values[0].index(x)]==morph_values[1][cat_values[1].index(y)]]
-            # now prepare for return
-            if len(pullback_ids)==0:
-                return {}
-            newids = self[category]['_category_construct_local.new_ids']
-            fullnewids = [self.cat_obj_lookup_table[(category,n)][0] for n in newids]
-            if con_type == 'Pullback':
-                final_results = {fullnewids[0]:[x[0] for x in pullback_ids],fullnewids[1]:[x[1] for x in pullback_ids]}
-                final_results.update(self.duplicate_datanames(cifdata,cats[0],category,key_vals = final_results[fullnewids[0]],skip_names=newids))
-                final_results.update(self.duplicate_datanames(cifdata,cats[1],category,key_vals = final_results[fullnewids[1]],skip_names=newids))
-            elif con_type == 'Filter':   #simple filter
-                final_results = {fullnewids[0]:[x[0] for x in pullback_ids]}
-                final_results.update(self.duplicate_datanames(cifdata,cats[0],category,key_vals = final_results[fullnewids[0]],skip_names=newids))
-            if store_value:
-                self.store_new_cat_values(cifdata,final_results,category)
-            return final_results
-
-    def push_from_pullback(self,target_category,source_categories,cifdata,store_value=True):
-        """Each of the categories in source_categories are pullbacks that include
-        the target_category"""
-        target_key = self[target_category]['_category.key_id']
-        result = {target_key:[]}
-        first_time = True
-        # for each source category, determine which element goes to the target
-        for sc in source_categories:
-            components = self[sc]['_category_construct_local.components']
-            comp_cats = [self[c]['_name.category_id'] for c in components]
-            new_ids = self[sc]['_category_construct_local.new_ids']
-            source_ids = [self.cat_obj_lookup_table[(sc,n)][0] for n in new_ids]
-            if len(components) == 2:  # not a filter
-                element_pos = comp_cats.index(target_category)
-                old_id = source_ids[element_pos]
-                print('Using %s to populate %s' % (old_id,target_key))
-                result[target_key].extend(cifdata[old_id])
-                # project through all identical names
-                extra_result = self.duplicate_datanames(cifdata,sc,target_category,skip_names=new_ids+[target_key])
-                # we only include keys that are common to all categories
-                if first_time:
-                    result.update(extra_result)
-                else:
-                    for k in extra_result.keys():
-                        if k in result:
-                            print('Updating %s: was %s' % (k,repr(result[k])))
-                            result[k].extend(extra_result[k])
-            else:
-                extra_result = self.duplicate_datanames(cifdata,sc,target_category,skip_names=new_ids)
-                if len(extra_result)>0 or source_ids[0] in cifdata:  #something is present
-                    result[target_key].extend(cifdata[source_ids[0]])
-                    for k in extra_result.keys():
-                        if k in result:
-                            print('Reverse filter: Updating %s: was %s' % (k,repr(result[k])))
-                            result[k].extend(extra_result[k])
-                        else:
-                            result[k]=extra_result[k]
-    # Bonus derivation if there is a singleton filter
-                    if self[sc]['_category_construct_local.type'] == 'Filter':
-                        int_filter = self[sc].get('_category_construct_local.integer_filter',None)
-                        text_filter = self[sc].get('_category_construct_local.text_filter',None)
-                        if int_filter is not None:
-                            filter_values = int_filter
-                        else:
-                            filter_values = text_filter
-                        if len(filter_values)==1:    #a singleton
-                            extra_dataname = self[sc]['_category_construct_local.components'][0]
-                            if int_filter is not None:
-                                new_value = [int(filter_values[0])] * len(cifdata[source_ids[0]])
-                            else:
-                                new_value = filter_values * len(cifdata[source_ids[0]])
-                            if extra_dataname not in result:
-                                result[extra_dataname] = new_value
-                            else:
-                                result[extra_dataname].extend(new_value)
-                    else:
-                        raise ValueError('Unexpected category construct type' + self[sc]['_category_construct_local.type'])
-            first_time = False
-        # check for sanity - all dataname lengths must be identical
-        datalen = len(set([len(a) for a in result.values()]))
-        if datalen != 1:
-            raise AssertionError('Failed to construct equal-length category items,'+ repr(result))
-        if store_value:
-            print('Now storing ' + repr(result))
-            self.store_new_cat_values(cifdata,result,target_category)
-        return result
-
-    def duplicate_datanames(self,cifdata,from_category,to_category,key_vals=None,skip_names=[]):
-        """Copy across datanames for which the from_category key equals [[key_vals]]"""
-        result = {}
-        s_names_in_cat = set(self.names_in_cat(from_category,names_only=True))
-        t_names_in_cat = set(self.names_in_cat(to_category,names_only=True))
-        can_project = s_names_in_cat & t_names_in_cat
-        can_project -= set(skip_names)  #already dealt with
-        source_key = self[from_category]['_category.key_id']
-        print('Source dataname set: ' + repr(s_names_in_cat))
-        print('Target dataname set: ' + repr(t_names_in_cat))
-        print('Projecting through following datanames from %s to %s' % (from_category,to_category) + repr(can_project))
-        for project_name in can_project:
-            full_from_name = self.cat_obj_lookup_table[(from_category.lower(),project_name.lower())][0]
-            full_to_name = self.cat_obj_lookup_table[(to_category.lower(),project_name.lower())][0]
-            if key_vals is None:
-                try:
-                    result[full_to_name] = cifdata[full_from_name]
-                except StarFile.StarDerivationError:
-                    pass
-            else:
-                all_key_vals = cifdata[source_key]
-                filter_pos = [all_key_vals.index(a) for a in key_vals]
-                try:
-                    all_data_vals = cifdata[full_from_name]
-                except StarFile.StarDerivationError:
-                    pass
-                result[full_to_name] = [all_data_vals[i] for i in filter_pos]
-        return result
-
-    def store_new_cat_values(self,cifdata,result,the_category):
-        """Store the values in [[result]] into [[cifdata]]"""
-        the_key = [a for a in result.keys() if self[a].get('_type.purpose','')=='Key']
-        double_names = [a for a in result.keys() if a in cifdata]
-        if len(double_names)>0:
-            already_present = [a for a in self.names_in_cat(the_category) if a in cifdata]
-            if set(already_present) != set(result.keys()):
-                print("Category %s not updated, mismatched datanames: %s" % (the_category, repr(set(already_present)^set(result.keys()))))
-                return
-            #check key values
-            old_keys = set(cifdata[the_key])
-            common_keys = old_keys & set(result[the_key])
-            if len(common_keys)>0:
-                print("Category %s not updated, key values in common:" % (common_keys))
-                return
-            #extend result values with old values
-            for one_name,one_value in result.items():
-                result[one_name].extend(cifdata[one_name])
-        for one_name, one_value in result.items():
-            try:
-                self.store_new_looped_value(one_name,cifdata,one_value,False)
-            except StarFile.StarError:
-                print('%s: Not replacing %s with calculated %s' % (one_name,repr(cifdata[one_name]),repr(one_value)))
-        #put the key as the first item
-        print('Fixing item order for {}'.format(repr(the_key)))
-        for one_key in the_key:  #should only be one
-            cifdata.ChangeItemOrder(one_key,0)
-
-
-    def generate_default_packet(self,catname,catkey,keyvalue):
-        """Return a StarPacket with items from ``catname`` and a key value
-        of ``keyvalue``"""
-        newpack = StarPacket()
-        for na in self.names_in_cat(catname):
-            def_val = self[na].get("_enumeration.default","")
-            if def_val:
-                final_val = self.change_type(na,def_val)
-                newpack.extend(final_val)
-                setattr(newpack,na,final_val)
-        if len(newpack)>0:
-            newpack.extend(keyvalue)
-            setattr(newpack,catkey,keyvalue)
-        return newpack
-
-
-    def switch_numpy(self,to_val):
-        pass
-
-    def change_type(self,itemname,inval):
-        if inval == "?": return inval
-        change_function = convert_type(self[itemname])
-        if isinstance(inval,list) and not isinstance(inval,StarFile.StarList):   #from a loop
-            newval = list([change_function(a) for a in inval])
-        else:
-            newval = change_function(inval)
-        return newval
-
-    def install_validation_functions(self):
-        """Install the DDL-appropriate validation checks"""
-        if self.diclang != 'DDLm':
-            # functions which check conformance
-            self.item_validation_funs = [
-                self.validate_item_type,
-                self.validate_item_esd,
-                self.validate_item_enum,
-                self.validate_enum_range,
-                self.validate_looping
-            ]
-            # functions checking loop values
-            self.loop_validation_funs = [
-                self.validate_loop_membership,
-                self.validate_loop_key,
-                self.validate_loop_references
-            ]
-            # where we need to look at other values
-            self.global_validation_funs = [
-                self.validate_exclusion,
-                self.validate_parent,
-                self.validate_child,
-                self.validate_dependents,
-                self.validate_uniqueness
-            ]
-            # where only a full block will do
-            self.block_validation_funs = [
-                self.validate_mandatory_category
-            ]
-            # removal is quicker with special checks
-            self.global_remove_validation_funs = [
-                self.validate_remove_parent_child
-            ]
-        elif self.diclang == 'DDLm':
-            self.item_validation_funs = [
-                self.validate_item_enum,
-                self.validate_item_esd_ddlm,
-                ]
-            self.loop_validation_funs = [
-                self.validate_looping_ddlm,
-                self.validate_loop_key_ddlm,
-                self.validate_loop_membership
-                ]
-            self.global_validation_funs = []
-            self.block_validation_funs = [
-                self.check_mandatory_items,
-                self.check_prohibited_items
-                ]
-            self.global_remove_validation_funs = []
-        self.optimize = False        # default value
-        self.done_parents = []
-        self.done_children = []
-        self.done_keys = []
-
-    def validate_item_type(self,item_name,item_value):
-        def mymatch(m,a):
-            res = m.match(a)
-            if res != None: return res.group()
-            else: return ""
-        target_type = self[item_name].get(self.type_spec)
-        if target_type == None:          # e.g. a category definition
-            return {"result":True}                  # not restricted in any way
-        matchexpr = self.typedic[target_type]
-        item_values = listify(item_value)
-        #for item in item_values:
-            #print("Type match " + item_name + " " + item + ":",)
-        #skip dots and question marks
-        check_all = [a for a in item_values if a !="." and a != "?"]
-        check_all = [a for a in check_all if mymatch(matchexpr,a) != a]
-        if len(check_all)>0: return {"result":False,"bad_values":check_all}
-        else: return {"result":True}
-
-    def decide(self,result_list):
-        """Construct the return list"""
-        if len(result_list)==0:
-               return {"result":True}
-        else:
-               return {"result":False,"bad_values":result_list}
-
-    def validate_item_container(self, item_name,item_value):
-        container_type = self[item_name]['_type.container']
-        item_values = listify(item_value)
-        if container_type == 'Single':
-           okcheck = [a for a in item_values if not isinstance(a,(int,float,long,unicode))]
-           return decide(okcheck)
-        if container_type in ('Multiple','List'):
-           okcheck = [a for a in item_values if not isinstance(a,StarList)]
-           return decide(okcheck)
-        if container_type == 'Array':    #A list with numerical values
-           okcheck = [a for a in item_values if not isinstance(a,StarList)]
-           first_check = decide(okcheck)
-           if not first_check['result']: return first_check
-           #num_check = [a for a in item_values if len([b for b in a if not isinstance
-
-    def validate_item_esd(self,item_name,item_value):
-        if self[item_name].get(self.primitive_type) != 'numb':
-            return {"result":None}
-        can_esd = self[item_name].get(self.esd_spec,"none") == "esd"
-        if can_esd: return {"result":True}         #must be OK!
-        item_values = listify(item_value)
-        check_all = list([a for a in item_values if get_number_with_esd(a)[1] != None])
-        if len(check_all)>0: return {"result":False,"bad_values":check_all}
-        return {"result":True}
-
-    def validate_item_esd_ddlm(self,item_name,item_value):
-        if self[item_name].get('self.primitive_type') not in \
-        ['Count','Index','Integer','Real','Imag','Complex','Binary','Hexadecimal','Octal']:
-            return {"result":None}
-        can_esd = True
-        if self[item_name].get('_type.purpose') != 'Measurand':
-            can_esd = False
-        item_values = listify(item_value)
-        check_all = [get_number_with_esd(a)[1] for a in item_values]
-        check_all = [v for v in check_all if (can_esd and v == None) or \
-                 (not can_esd and v != None)]
-        if len(check_all)>0: return {"result":False,"bad_values":check_all}
-        return {"result":True}
-
-    def validate_enum_range(self,item_name,item_value):
-        if "_item_range.minimum" not in self[item_name] and \
-           "_item_range.maximum" not in self[item_name]:
-            return {"result":None}
-        minvals = self[item_name].get("_item_range.minimum",default = ["."])
-        maxvals = self[item_name].get("_item_range.maximum",default = ["."])
-        def makefloat(a):
-            if a == ".": return a
-            else: return float(a)
-        maxvals = map(makefloat, maxvals)
-        minvals = map(makefloat, minvals)
-        rangelist = list(zip(minvals,maxvals))
-        item_values = listify(item_value)
-        def map_check(rangelist,item_value):
-            if item_value == "?" or item_value == ".": return True
-            iv,esd = get_number_with_esd(item_value)
-            if iv==None: return None  #shouldn't happen as is numb type
-            for lower,upper in rangelist:
-                #check the minima
-                if lower == ".": lower = iv - 1
-                if upper == ".": upper = iv + 1
-                if iv > lower and iv < upper: return True
-                if upper == lower and iv == upper: return True
-            # debug
-            # print("Value %s fails range check %d < x < %d" % (item_value,lower,upper))
-            return False
-        check_all = [a for a in item_values if map_check(rangelist,a) != True]
-        if len(check_all)>0: return {"result":False,"bad_values":check_all}
-        else: return {"result":True}
-
-    def validate_item_enum(self,item_name,item_value):
-        try:
-            enum_list = self[item_name][self.enum_spec][:]
-        except KeyError:
-            return {"result":None}
-        enum_list.append(".")   #default value
-        enum_list.append("?")   #unknown
-        item_values = listify(item_value)
-        #print("Enum check: {!r} in {!r}".format(item_values, enum_list))
-        check_all = [a for a in item_values if a not in enum_list]
-        if len(check_all)>0: return {"result":False,"bad_values":check_all}
-        else: return {"result":True}
-
-    def validate_looping(self,item_name,item_value):
-        try:
-            must_loop = self[item_name][self.must_loop_spec]
-        except KeyError:
-            return {"result":None}
-        if must_loop == 'yes' and isinstance(item_value,(unicode,str)): # not looped
-            return {"result":False}      #this could be triggered
-        if must_loop == 'no' and not isinstance(item_value,(unicode,str)):
-            return {"result":False}
-        return {"result":True}
-
-    def validate_looping_ddlm(self,loop_names):
-        """Check that all names are loopable"""
-        truly_loopy = self.get_final_cats(loop_names)
-        if len(truly_loopy)<len(loop_names):  #some are bad
-            categories = [(a,self[a][self.cat_spec].lower()) for a in loop_names]
-            not_looped = [a[0] for a in categories if a[1] not in self.parent_lookup.keys()]
-            return {"result":False,"bad_items":not_looped}
-        return {"result":True}
-
-
-    def validate_loop_membership(self,loop_names):
-        final_cat = self.get_final_cats(loop_names)
-        bad_items =  [a for a in final_cat if a != final_cat[0]]
-        if len(bad_items)>0:
-            return {"result":False,"bad_items":bad_items}
-        else: return {"result":True}
-
-    def get_final_cats(self,loop_names):
-        """Return a list of the uppermost parent categories for the loop_names. Names
-        that are not from loopable categories are ignored."""
-        try:
-            categories = [self[a][self.cat_spec].lower() for a in loop_names]
-        except KeyError:       #category_id is mandatory
-            raise ValidCifError( "%s missing from dictionary %s for item in loop containing %s" % (self.cat_spec,self.dicname,loop_names[0]))
-        truly_looped = [a for a in categories if a in self.parent_lookup.keys()]
-        return [self.parent_lookup[a] for a in truly_looped]
-
-    def validate_loop_key(self,loop_names):
-        category = self[loop_names[0]][self.cat_spec]
-        # find any unique values which must be present
-        key_spec = self[category].get(self.key_spec,[])
-        for names_to_check in key_spec:
-            if isinstance(names_to_check,unicode):   #only one
-                names_to_check = [names_to_check]
-            for loop_key in names_to_check:
-                if loop_key not in loop_names:
-                    #is this one of those dang implicit items?
-                    if self[loop_key].get(self.must_exist_spec,None) == "implicit":
-                        continue          #it is virtually there...
-                    alternates = self.get_alternates(loop_key)
-                    if alternates == []:
-                        return {"result":False,"bad_items":loop_key}
-                    for alt_names in alternates:
-                        alt = [a for a in alt_names if a in loop_names]
-                        if len(alt) == 0:
-                            return {"result":False,"bad_items":loop_key}  # no alternates
-        return {"result":True}
-
-    def validate_loop_key_ddlm(self,loop_names):
-        """Make sure at least one of the necessary keys are available"""
-        final_cats = self.get_final_cats(loop_names)
-        if len(final_cats)>0:
-            poss_keys = self.cat_key_table[final_cats[0]][0] # 
-            found_keys = [a for a in poss_keys if a in loop_names]
-            if len(found_keys)>0:
-                return {"result":True}
-            else:
-                return {"result":False,"bad_items":poss_keys}
-        else:
-            return {"result":True}
-
-    def validate_loop_references(self,loop_names):
-        must_haves = [self[a].get(self.list_ref_spec,None) for a in loop_names]
-        must_haves = [a for a in must_haves if a != None]
-        # build a flat list.  For efficiency we don't remove duplicates,as
-        # we expect no more than the order of 10 or 20 looped names.
-        def flat_func(a,b):
-            if isinstance(b,unicode):
-               a.append(b)       #single name
-            else:
-               a.extend(b)       #list of names
-            return a
-        flat_mh = []
-        [flat_func(flat_mh,a) for a in must_haves]
-        group_mh = filter(lambda a:a[-1]=="_",flat_mh)
-        single_mh = filter(lambda a:a[-1]!="_",flat_mh)
-        res = [a for a in single_mh if a not in loop_names]
-        def check_gr(s_item, name_list):
-            nl = map(lambda a:a[:len(s_item)],name_list)
-            if s_item in nl: return True
-            return False
-        res_g = [a for a in group_mh if check_gr(a,loop_names)]
-        if len(res) == 0 and len(res_g) == 0: return {"result":True}
-        # construct alternate list
-        alternates = map(lambda a: (a,self.get_alternates(a)),res)
-        alternates = [a for a in alternates if a[1] != []]
-        # next line purely for error reporting
-        missing_alts = [a[0] for a in alternates if a[1] == []]
-        if len(alternates) != len(res):
-           return {"result":False,"bad_items":missing_alts}   #short cut; at least one
-                                                       #doesn't have an altern
-        #loop over alternates
-        for orig_name,alt_names in alternates:
-             alt = [a for a in alt_names if a in loop_names]
-             if len(alt) == 0: return {"result":False,"bad_items":orig_name}# no alternates
-        return {"result":True}        #found alternates
-
-    def get_alternates(self,main_name,exclusive_only=False):
-        alternates = self[main_name].get(self.related_func,None)
-        alt_names = []
-        if alternates != None:
-            alt_names =  self[main_name].get(self.related_item,None)
-            if isinstance(alt_names,unicode):
-                alt_names = [alt_names]
-                alternates = [alternates]
-            together = zip(alt_names,alternates)
-            if exclusive_only:
-                alt_names = [a for a in together if a[1]=="alternate_exclusive" \
-                                             or a[1]=="replace"]
-            else:
-                alt_names = [a for a in together if a[1]=="alternate" or a[1]=="replace"]
-            alt_names = list([a[0] for a in alt_names])
-        # now do the alias thing
-        alias_names = listify(self[main_name].get("_item_aliases.alias_name",[]))
-        alt_names.extend(alias_names)
-        # print("Alternates for {}: {!r}".format(main_name, alt_names))
-        return alt_names
-
-
-    def validate_exclusion(self,item_name,item_value,whole_block,provisional_items={},globals={}):
-       alternates = [a.lower() for a in self.get_alternates(item_name,exclusive_only=True)]
-       item_name_list = [a.lower() for a in whole_block.keys()]
-       item_name_list.extend([a.lower() for a in provisional_items.keys()])
-       bad = [a for a in alternates if a in item_name_list]
-       if len(bad)>0:
-           print("Bad: %s, alternates %s" % (repr(bad),repr(alternates)))
-           return {"result":False,"bad_items":bad}
-       else: return {"result":True}
-
-    # validate that parent exists and contains matching values
-    def validate_parent(self,item_name,item_value,whole_block,provisional_items={},globals={}):
-        parent_item = self[item_name].get(self.parent_spec)
-        if not parent_item: return {"result":None}   #no parent specified
-        if isinstance(parent_item,list):
-            parent_item = parent_item[0]
-        if self.optimize:
-            if parent_item in self.done_parents:
-                return {"result":None}
-            else:
-                self.done_parents.append(parent_item)
-                print("Done parents %s" % repr(self.done_parents))
-        # initialise parent/child values
-        if isinstance(item_value,unicode):
-            child_values = [item_value]
-        else: child_values = item_value[:]    #copy for safety
-        # track down the parent
-        # print("Looking for {} parent item {} in {!r}".format(item_name, parent_item, whole_block))
-        # if globals contains the parent values, we are doing a DDL2 dictionary, and so
-        # we have collected all parent values into the global block - so no need to search
-        # for them elsewhere.
-        # print("Looking for {!r}".format(parent_item))
-        parent_values = globals.get(parent_item)
-        if not parent_values:
-            parent_values = provisional_items.get(parent_item,whole_block.get(parent_item))
-        if not parent_values:
-            # go for alternates
-            namespace = whole_block.keys()
-            namespace.extend(provisional_items.keys())
-            namespace.extend(globals.keys())
-            alt_names = filter_present(self.get_alternates(parent_item),namespace)
-            if len(alt_names) == 0:
-                if len([a for a in child_values if a != "." and a != "?"])>0:
-                    return {"result":False,"parent":parent_item}#no parent available -> error
-                else:
-                    return {"result":None}       #maybe True is more appropriate??
-            parent_item = alt_names[0]           #should never be more than one??
-            parent_values = provisional_items.get(parent_item,whole_block.get(parent_item))
-            if not parent_values:   # check global block
-                parent_values = globals.get(parent_item)
-        if isinstance(parent_values,unicode):
-            parent_values = [parent_values]
-        #print("Checking parent %s against %s, values %r/%r" % (parent_item,
-        #                                          item_name, parent_values, child_values))
-        missing = self.check_parent_child(parent_values,child_values)
-        if len(missing) > 0:
-            return {"result":False,"bad_values":missing,"parent":parent_item}
-        return {"result":True}
-
-    def validate_child(self,item_name,item_value,whole_block,provisional_items={},globals={}):
-        try:
-            child_items = self[item_name][self.child_spec][:]  #copy
-        except KeyError:
-            return {"result":None}    #not relevant
-        # special case for dictionaries  -> we check parents of children only
-        if item_name in globals:  #dictionary so skip
-            return {"result":None}
-        if isinstance(child_items,unicode): # only one child
-            child_items = [child_items]
-        if isinstance(item_value,unicode): # single value
-            parent_values = [item_value]
-        else: parent_values = item_value[:]
-        # expand child list with list of alternates
-        for child_item in child_items[:]:
-            child_items.extend(self.get_alternates(child_item))
-        # now loop over the children
-        for child_item in child_items:
-            if self.optimize:
-                if child_item in self.done_children:
-                    return {"result":None}
-                else:
-                    self.done_children.append(child_item)
-                    print("Done children %s" % repr(self.done_children))
-            if child_item in provisional_items:
-                child_values = provisional_items[child_item][:]
-            elif child_item in whole_block:
-                child_values = whole_block[child_item][:]
-            else:  continue
-            if isinstance(child_values,unicode):
-                child_values = [child_values]
-                # print("Checking child %s against %s, values %r/%r" % (child_item,
-                #       item_name, child_values, parent_values))
-            missing = self.check_parent_child(parent_values,child_values)
-            if len(missing)>0:
-                return {"result":False,"bad_values":missing,"child":child_item}
-        return {"result":True}       #could mean that no child items present
-
-    #a generic checker: all child vals should appear in parent_vals
-    def check_parent_child(self,parent_vals,child_vals):
-        # shield ourselves from dots and question marks
-        pv = parent_vals[:]
-        pv.extend([".","?"])
-        res =  [a for a in child_vals if a not in pv]
-        #print("Missing: %s" % res)
-        return res
-
-    def validate_remove_parent_child(self,item_name,whole_block):
-        try:
-            child_items = self[item_name][self.child_spec]
-        except KeyError:
-            return {"result":None}
-        if isinstance(child_items,unicode): # only one child
-            child_items = [child_items]
-        for child_item in child_items:
-            if child_item in whole_block:
-                return {"result":False,"child":child_item}
-        return {"result":True}
-
-    def validate_dependents(self,item_name,item_value,whole_block,prov={},globals={}):
-        try:
-            dep_items = self[item_name][self.dep_spec][:]
-        except KeyError:
-            return {"result":None}    #not relevant
-        if isinstance(dep_items,unicode):
-            dep_items = [dep_items]
-        actual_names = whole_block.keys()
-        actual_names.extend(prov.keys())
-        actual_names.extend(globals.keys())
-        missing = [a for a in dep_items if a not in actual_names]
-        if len(missing) > 0:
-            alternates = map(lambda a:[self.get_alternates(a),a],missing)
-            # compact way to get a list of alternative items which are
-            # present
-            have_check = [(filter_present(b[0],actual_names),
-                                       b[1]) for b in alternates]
-            have_check = list([a for a in have_check if len(a[0])==0])
-            if len(have_check) > 0:
-                have_check = [a[1] for a in have_check]
-                return {"result":False,"bad_items":have_check}
-        return {"result":True}
-
-    def validate_uniqueness(self,item_name,item_value,whole_block,provisional_items={},
-                                                                  globals={}):
-        category = self[item_name].get(self.cat_spec)
-        if category == None:
-            print("No category found for %s" % item_name)
-            return {"result":None}
-        # print("Category {!r} for item {}".format(category, item_name))
-        # we make a copy in the following as we will be removing stuff later!
-        unique_i = self[category].get("_category_key.name",[])[:]
-        if isinstance(unique_i,unicode):
-            unique_i = [unique_i]
-        if item_name not in unique_i:       #no need to verify
-            return {"result":None}
-        if isinstance(item_value,unicode):  #not looped
-            return {"result":None}
-        # print("Checking %s -> %s -> %s ->Unique: %r" % (item_name,category,catentry, unique_i))
-        # check that we can't optimize by not doing this check
-        if self.optimize:
-            if unique_i in self.done_keys:
-                return {"result":None}
-            else:
-                self.done_keys.append(unique_i)
-        val_list = []
-        # get the matching data from any other data items
-        unique_i.remove(item_name)
-        other_data = []
-        if len(unique_i) > 0:            # i.e. do have others to think about
-           for other_name in unique_i:
-           # we look for the value first in the provisional dict, then the main block
-           # the logic being that anything in the provisional dict overrides the
-           # main block
-               if other_name in provisional_items:
-                   other_data.append(provisional_items[other_name])
-               elif other_name in whole_block:
-                   other_data.append(whole_block[other_name])
-               elif self[other_name].get(self.must_exist_spec)=="implicit":
-                   other_data.append([item_name]*len(item_value))  #placeholder
-               else:
-                   return {"result":False,"bad_items":other_name}#missing data name
-        # ok, so we go through all of our values
-        # this works by comparing lists of strings to one other, and
-        # so could be fooled if you think that '1.' and '1' are
-        # identical
-        for i in range(len(item_value)):
-            #print("Value no. %d" % i, end=" ")
-            this_entry = item_value[i]
-            for j in range(len(other_data)):
-                this_entry = " ".join([this_entry,other_data[j][i]])
-            #print("Looking for {!r} in {!r}: ".format(this_entry, val_list))
-            if this_entry in val_list:
-                return {"result":False,"bad_values":this_entry}
-            val_list.append(this_entry)
-        return {"result":True}
-
-
-    def validate_mandatory_category(self,whole_block):
-        mand_cats = [self[a]['_category.id'] for a in self.keys() if self[a].get("_category.mandatory_code","no")=="yes"]
-        if len(mand_cats) == 0:
-            return {"result":True}
-        # print("Mandatory categories - {!r}".format(mand_cats)
-        # find which categories each of our datanames belongs to
-        all_cats = [self[a].get(self.cat_spec) for a in whole_block.keys()]
-        missing = set(mand_cats) - set(all_cats)
-        if len(missing) > 0:
-            return {"result":False,"bad_items":repr(missing)}
-        return {"result":True}
-
-    def check_mandatory_items(self,whole_block,default_scope='Item'):
-        """Return an error if any mandatory items are missing"""
-        if len(self.scopes_mandatory)== 0: return {"result":True}
-        if default_scope == 'Datablock':
-            return {"result":True}     #is a data file
-        scope = whole_block.get('_definition.scope',default_scope)
-        if '_dictionary.title' in whole_block:
-           scope = 'Dictionary'
-        missing = list([a for a in self.scopes_mandatory[scope] if a not in whole_block])
-        if len(missing)==0:
-            return {"result":True}
-        else:
-            return {"result":False,"bad_items":missing}
-
-    def check_prohibited_items(self,whole_block,default_scope='Item'):
-        """Return an error if any prohibited items are present"""
-        if len(self.scopes_naughty)== 0: return {"result":True}
-        if default_scope == 'Datablock':
-            return {"result":True}     #is a data file
-        scope = whole_block.get('_definition.scope',default_scope)
-        if '_dictionary.title' in whole_block:
-           scope = 'Dictionary'
-        present = list([a for a in self.scopes_naughty[scope] if a in whole_block])
-        if len(present)==0:
-            return {"result":True}
-        else:
-            return {"result":False,"bad_items":present}
-
-
-    def run_item_validation(self,item_name,item_value):
-        return {item_name:list([(f.__name__,f(item_name,item_value)) for f in self.item_validation_funs])}
-
-    def run_loop_validation(self,loop_names):
-        return {loop_names[0]:list([(f.__name__,f(loop_names)) for f in self.loop_validation_funs])}
-
-    def run_global_validation(self,item_name,item_value,data_block,provisional_items={},globals={}):
-        results = list([(f.__name__,f(item_name,item_value,data_block,provisional_items,globals)) for f in self.global_validation_funs])
-        return {item_name:results}
-
-    def run_block_validation(self,whole_block,block_scope='Item'):
-        results = list([(f.__name__,f(whole_block)) for f in self.block_validation_funs])
-        # fix up the return values
-        return {"whole_block":results}
-
-    def optimize_on(self):
-        self.optimize = True
-        self.done_keys = []
-        self.done_children = []
-        self.done_parents = []
-
-    def optimize_off(self):
-        self.optimize = False
-        self.done_keys = []
-        self.done_children = []
-        self.done_parents = []
-
-
-
-class ValidCifBlock(CifBlock):
-    """A `CifBlock` that is valid with respect to a given CIF dictionary.  Methods
-    of `CifBlock` are overridden where necessary to disallow addition of invalid items to the
-    `CifBlock`.
-
-    ## Initialisation
-
-    * `dic` is a `CifDic` object to be used for validation.
-
-    """
-    def __init__(self,dic = None, diclist=[], mergemode = "replace",*args,**kwords):
-        CifBlock.__init__(self,*args,**kwords)
-        if dic and diclist:
-            print("Warning: diclist argument ignored when initialising ValidCifBlock")
-        if isinstance(dic,CifDic):
-            self.fulldic = dic
-        else:
-            raise TypeError( "ValidCifBlock passed non-CifDic type in dic argument")
-        if len(diclist)==0 and not dic:
-            raise ValidCifError( "At least one dictionary must be specified")
-        if diclist and not dic:
-            self.fulldic = merge_dic(diclist,mergemode)
-        if not self.run_data_checks()[0]:
-            raise ValidCifError( self.report())
-
-    def run_data_checks(self,verbose=False):
-        self.v_result = {}
-        self.fulldic.optimize_on()
-        for dataname in self.keys():
-            update_value(self.v_result,self.fulldic.run_item_validation(dataname,self[dataname]))
-            update_value(self.v_result,self.fulldic.run_global_validation(dataname,self[dataname],self))
-        for loop_names in self.loops.values():
-            update_value(self.v_result,self.fulldic.run_loop_validation(loop_names))
-        # now run block-level checks
-        update_value(self.v_result,self.fulldic.run_block_validation(self))
-        # return false and list of baddies if anything didn't match
-        self.fulldic.optimize_off()
-        all_keys = list(self.v_result.keys()) #dictionary will change
-        for test_key in all_keys:
-            #print("%s: %r" % (test_key, self.v_result[test_key]))
-            self.v_result[test_key] = [a for a in self.v_result[test_key] if a[1]["result"]==False]
-            if len(self.v_result[test_key]) == 0:
-                del self.v_result[test_key]
-        isvalid = len(self.v_result)==0
-        #if not isvalid:
-        #    print("Baddies: {!r}".format(self.v_result))
-        return isvalid,self.v_result
-
-    def single_item_check(self,item_name,item_value):
-        #self.match_single_item(item_name)
-        if item_name not in self.fulldic:
-            result = {item_name:[]}
-        else:
-            result = self.fulldic.run_item_validation(item_name,item_value)
-        baddies = list([a for a in result[item_name] if a[1]["result"]==False])
-        # if even one false one is found, this should trigger
-        isvalid = (len(baddies) == 0)
-        # if not isvalid: print("Failures for {}: {!r}".format(item_name, baddies))
-        return isvalid,baddies
-
-    def loop_item_check(self,loop_names):
-        in_dic_names = list([a for a in loop_names if a in self.fulldic])
-        if len(in_dic_names)==0:
-            result = {loop_names[0]:[]}
-        else:
-            result = self.fulldic.run_loop_validation(in_dic_names)
-        baddies = list([a for a in result[in_dic_names[0]] if a[1]["result"]==False])
-        # if even one false one is found, this should trigger
-        isvalid = (len(baddies) == 0)
-        # if not isvalid: print("Failures for {}: {!r}".format(loop_names, baddies))
-        return isvalid,baddies
-
-    def global_item_check(self,item_name,item_value,provisional_items={}):
-        if item_name not in self.fulldic:
-            result = {item_name:[]}
-        else:
-            result = self.fulldic.run_global_validation(item_name,
-               item_value,self,provisional_items = provisional_items)
-        baddies = list([a for a in result[item_name] if a[1]["result"] is False])
-        # if even one false one is found, this should trigger
-        isvalid = (len(baddies) == 0)
-        # if not isvalid: print("Failures for {}: {!r}".format(item_name, baddies))
-        return isvalid,baddies
-
-    def remove_global_item_check(self,item_name):
-        if item_name not in self.fulldic:
-            result = {item_name:[]}
-        else:
-            result = self.fulldic.run_remove_global_validation(item_name,self,False)
-        baddies = list([a for a in result[item_name] if a[1]["result"]==False])
-        # if even one false one is found, this should trigger
-        isvalid = (len(baddies) == 0)
-        # if not isvalid: print("Failures for {}: {!r}".format(item_name, baddies))
-        return isvalid,baddies
-
-    def AddToLoop(self,dataname,loopdata):
-        # single item checks
-        paired_data = loopdata.items()
-        for name,value in paired_data:
-            valid,problems = self.single_item_check(name,value)
-            self.report_if_invalid(valid,problems)
-        # loop item checks; merge with current loop
-        found = 0
-        for aloop in self.block["loops"]:
-            if dataname in aloop:
-                loopnames = aloop.keys()
-                for new_name in loopdata.keys():
-                    if new_name not in loopnames: loopnames.append(new_name)
-                valid,problems = self.looped_item_check(loopnames)
-                self.report_if_invalid(valid,problems)
-        prov_dict = loopdata.copy()
-        for name,value in paired_data:
-            del prov_dict[name]   # remove temporarily
-            valid,problems = self.global_item_check(name,value,prov_dict)
-            prov_dict[name] = value  # add back in
-            self.report_if_invalid(valid,problems)
-        CifBlock.AddToLoop(self,dataname,loopdata)
-
-    def AddCifItem(self,data):
-        if isinstance(data[0],(unicode,str)):   # single item
-            valid,problems = self.single_item_check(data[0],data[1])
-            self.report_if_invalid(valid,problems,data[0])
-            valid,problems = self.global_item_check(data[0],data[1])
-            self.report_if_invalid(valid,problems,data[0])
-        elif isinstance(data[0],tuple) or isinstance(data[0],list):
-            paired_data = list(zip(data[0],data[1]))
-            for name,value in paired_data:
-                valid,problems = self.single_item_check(name,value)
-                self.report_if_invalid(valid,problems,name)
-            valid,problems = self.loop_item_check(data[0])
-            self.report_if_invalid(valid,problems,data[0])
-            prov_dict = {}            # for storing temporary items
-            for name,value in paired_data: prov_dict[name]=value
-            for name,value in paired_data:
-                del prov_dict[name]   # remove temporarily
-                valid,problems = self.global_item_check(name,value,prov_dict)
-                prov_dict[name] = value  # add back in
-                self.report_if_invalid(valid,problems,name)
-        else:
-            raise ValueError("Programming error: AddCifItem passed non-tuple,non-string item")
-        super(ValidCifBlock,self).AddCifItem(data)
-
-    def AddItem(self,key,value,**kwargs):
-        """Set value of dataname `key` to `value` after checking for conformance with CIF dictionary"""
-        valid,problems = self.single_item_check(key,value)
-        self.report_if_invalid(valid,problems,key)
-        valid,problems = self.global_item_check(key,value)
-        self.report_if_invalid(valid,problems,key)
-        super(ValidCifBlock,self).AddItem(key,value,**kwargs)
-
-    # utility function
-    def report_if_invalid(self,valid,bad_list,data_name):
-        if not valid:
-            bad_tests = [a[0] for a in bad_list]
-            error_string = ",".join(bad_tests)
-            error_string = repr(data_name) + " fails following validity checks: "  + error_string
-            raise ValidCifError( error_string)
-
-    def __delitem__(self,key):
-        # we don't need to run single item checks; we do need to run loop and
-        # global checks.
-        if key in self:
-            try:
-                loop_items = self.GetLoop(key)
-            except TypeError:
-                loop_items = []
-            if loop_items:             #need to check loop conformance
-                loop_names = [a[0] for a in loop_items if a[0] != key]
-                valid,problems = self.loop_item_check(loop_names)
-                self.report_if_invalid(valid,problems)
-            valid,problems = self.remove_global_item_check(key)
-            self.report_if_invalid(valid,problems)
-        self.RemoveCifItem(key)
-
-
-    def report(self):
-       outstr = StringIO()
-       outstr.write( "Validation results\n")
-       outstr.write( "------------------\n")
-       print("%d invalid items found\n" % len(self.v_result))
-       for item_name,val_func_list in self.v_result.items():
-           outstr.write("%s fails following tests:\n" % item_name)
-           for val_func in val_func_list:
-               outstr.write("\t%s\n")
-       return outstr.getvalue()
-
-
-class ValidCifFile(CifFile):
-    """A CIF file for which all datablocks are valid.  Argument `dic` to
-    initialisation specifies a `CifDic` object to use for validation."""
-    def __init__(self,dic=None,diclist=[],mergemode="replace",*args,**kwargs):
-        print("WARNING: ValidCifFile will be removed in the next release.")
-        if not diclist and not dic and not hasattr(self,'bigdic'):
-            raise ValidCifError( "At least one dictionary is required to create a ValidCifFile object")
-        if not dic and diclist:     #merge here for speed
-            self.bigdic = merge_dic(diclist,mergemode)
-        elif dic and not diclist:
-            self.bigdic = dic
-        emapsCifFile.__init__(self,*args,**kwargs)
-        for blockname in self.keys():
-            self.dictionary[blockname]=ValidCifBlock(data=self.dictionary[blockname],dic=self.bigdic)
-
-    def NewBlock(self,blockname,blockcontents,**kwargs):
-        emapsCifFile.NewBlock(self,blockname,blockcontents,**kwargs)
-        # dictionary[blockname] is now a CifBlock object.  We
-        # turn it into a ValidCifBlock object
-        self.dictionary[blockname] = ValidCifBlock(dic=self.bigdic,
-                                         data=self.dictionary[blockname])
-
-
-class ValidationResult:
-    """Represents validation result. It is initialised with """
-    def __init__(self,results):
-        """results is return value of validate function"""
-        self.valid_result, self.no_matches = results
-
-    def report(self,use_html):
-        """Return string with human-readable description of validation result"""
-        return validate_report((self.valid_result, self.no_matches),use_html)
-
-    def is_valid(self,block_name=None):
-        """Return True for valid CIF file, otherwise False"""
-        if block_name is not None:
-            block_names = [block_name]
-        else:
-            block_names = self.valid_result.iterkeys()
-        for block_name in block_names:
-            if not self.valid_result[block_name] == (True,{}):
-                valid = False
-                break
-            else:
-                valid = True
-        return valid
-
-    def has_no_match_items(self,block_name=None):
-        """Return true if some items are not found in dictionary"""
-        if block_name is not None:
-            block_names = [block_name]
-        else:
-            block_names = self.no_matches.iter_keys()
-        for block_name in block_names:
-            if self.no_matches[block_name]:
-                has_no_match_items = True
-                break
-            else:
-                has_no_match_items = False
-        return has_no_match_items
-
-
-
-def Validate(ciffile,dic = "", diclist=[],mergemode="replace",isdic=False):
-    """Validate the `ciffile` conforms to the definitions in `CifDic` object `dic`, or if `dic` is missing,
-    to the results of merging the `CifDic` objects in `diclist` according to `mergemode`.  Flag
-    `isdic` indicates that `ciffile` is a CIF dictionary meaning that save frames should be
-    accessed for validation and that mandatory_category should be interpreted differently for DDL2."""
-    if not isinstance(ciffile,CifFile):
-        check_file = CifFile(ciffile)
-    else:
-        check_file = ciffile
-    if not dic:
-        fulldic = merge_dic(diclist,mergemode)
-    else:
-        fulldic = dic
-    no_matches = {}
-    valid_result = {}
-    if isdic:          #assume one block only
-        check_file.scoping = 'instance' #only data blocks visible
-        top_level = check_file.keys()[0]
-        check_file.scoping = 'dictionary'   #all blocks visible
-        # collect a list of parents for speed
-        if fulldic.diclang == 'DDL2':
-            poss_parents = fulldic.get_all("_item_linked.parent_name")
-            for parent in poss_parents:
-                curr_parent = listify(check_file.get(parent,[]))
-                new_vals = check_file.get_all(parent)
-                new_vals.extend(curr_parent)
-                if len(new_vals)>0:
-                    check_file[parent] = new_vals
-                print("Added %s (len %d)" % (parent,len(check_file[parent])))
-    # now run the validations
-    for block in check_file.keys():
-        if isdic and block == top_level:
-           block_scope = 'Dictionary'
-        elif isdic:
-           block_scope = 'Item'
-        else:
-           block_scope = 'Datablock'
-        no_matches[block] = [a for a in check_file[block].keys() if a not in fulldic]
-        # remove non-matching items
-        print("Not matched: " + repr(no_matches[block]))
-        for nogood in no_matches[block]:
-             del check_file[block][nogood]
-        print("Validating block %s, scope %s" % (block,block_scope))
-        valid_result[block] = run_data_checks(check_file[block],fulldic,block_scope=block_scope)
-    return valid_result,no_matches
-
-def validate_report(val_result,use_html=False):
-    valid_result,no_matches = val_result
-    outstr = StringIO()
-    if use_html:
-        outstr.write("<h2>Validation results</h2>")
-    else:
-        outstr.write( "Validation results\n")
-        outstr.write( "------------------\n")
-    if len(valid_result) > 10:
-        suppress_valid = True         #don't clutter with valid messages
-        if use_html:
-           outstr.write("<p>For brevity, valid blocks are not reported in the output.</p>")
-    else:
-        suppress_valid = False
-    for block in valid_result.keys():
-        block_result = valid_result[block]
-        if block_result[0]:
-            out_line = "Block '%s' is VALID" % block
-        else:
-            out_line = "Block '%s' is INVALID" % block
-        if use_html:
-            if (block_result[0] and (not suppress_valid or len(no_matches[block])>0)) or not block_result[0]:
-                outstr.write( "<h3>%s</h3><p>" % out_line)
-        else:
-                outstr.write( "\n %s\n" % out_line)
-        if len(no_matches[block])!= 0:
-            if use_html:
-                outstr.write( "<p>The following items were not found in the dictionary")
-                outstr.write(" (note that this does not invalidate the data block):</p>")
-                outstr.write("<p><table>\n")
-                [outstr.write("<tr><td>%s</td></tr>" % it) for it in no_matches[block]]
-                outstr.write("</table>\n")
-            else:
-                outstr.write( "\n The following items were not found in the dictionary:\n")
-                outstr.write("Note that this does not invalidate the data block\n")
-                [outstr.write("%s\n" % it) for it in no_matches[block]]
-        # now organise our results by type of error, not data item...
-        error_type_dic = {}
-        for error_item, error_list in block_result[1].items():
-            for func_name,bad_result in error_list:
-                bad_result.update({"item_name":error_item})
-                try:
-                    error_type_dic[func_name].append(bad_result)
-                except KeyError:
-                    error_type_dic[func_name] = [bad_result]
-        # make a table of test name, test message
-        info_table = {\
-        'validate_item_type':\
-            "The following data items had badly formed values",
-        'validate_item_esd':\
-            "The following data items should not have esds appended",
-        'validate_enum_range':\
-            "The following data items have values outside permitted range",
-        'validate_item_enum':\
-            "The following data items have values outside permitted set",
-        'validate_looping':\
-            "The following data items violate looping constraints",
-        'validate_loop_membership':\
-            "The following looped data names are of different categories to the first looped data name",
-        'validate_loop_key':\
-            "A required dataname for this category is missing from the loop\n containing the dataname",
-        'validate_loop_key_ddlm':\
-            "A loop key is missing for the category containing the dataname",
-        'validate_loop_references':\
-            "A dataname required by the item is missing from the loop",
-        'validate_parent':\
-            "A parent dataname is missing or contains different values",
-        'validate_child':\
-            "A child dataname contains different values to the parent",
-        'validate_uniqueness':\
-            "One or more data items do not take unique values",
-        'validate_dependents':\
-            "A dataname required by the item is missing from the data block",
-        'validate_exclusion': \
-            "Both dataname and exclusive alternates or aliases are present in data block",
-        'validate_mandatory_category':\
-            "A required category is missing from this block",
-        'check_mandatory_items':\
-            "A required data attribute is missing from this block",
-        'check_prohibited_items':\
-            "A prohibited data attribute is present in this block"}
-
-        for test_name,test_results in error_type_dic.items():
-           if use_html:
-               outstr.write(html_error_report(test_name,info_table[test_name],test_results))
-           else:
-               outstr.write(error_report(test_name,info_table[test_name],test_results))
-               outstr.write("\n\n")
-    return outstr.getvalue()
-
-# A function to lay out a single error report.  We are passed
-# the name of the error (one of our validation functions), the
-# explanation to print out, and a dictionary with the error
-# information.  We print no more than 50 characters of the item
-
-def error_report(error_name,error_explanation,error_dics):
-   retstring = "\n\n " + error_explanation + ":\n\n"
-   headstring = "%-32s" % "Item name"
-   bodystring = ""
-   if "bad_values" in error_dics[0]:
-      headstring += "%-20s" % "Bad value(s)"
-   if "bad_items" in error_dics[0]:
-      headstring += "%-20s" % "Bad dataname(s)"
-   if "child" in error_dics[0]:
-      headstring += "%-20s" % "Child"
-   if "parent" in error_dics[0]:
-      headstring += "%-20s" % "Parent"
-   headstring +="\n"
-   for error in error_dics:
-      bodystring += "\n%-32s" % error["item_name"]
-      if "bad_values" in error:
-          out_vals = [repr(a)[:50] for a in error["bad_values"]]
-          bodystring += "%-20s" % out_vals
-      if "bad_items" in error:
-          bodystring += "%-20s" % repr(error["bad_items"])
-      if "child" in error:
-          bodystring += "%-20s" % repr(error["child"])
-      if "parent" in error:
-          bodystring += "%-20s" % repr(error["parent"])
-   return retstring + headstring + bodystring
-
-#  This lays out an HTML error report
-
-def html_error_report(error_name,error_explanation,error_dics,annotate=[]):
-   retstring = "<h4>" + error_explanation + ":</h4>"
-   retstring = retstring + "<table cellpadding=5><tr>"
-   headstring = "<th>Item name</th>"
-   bodystring = ""
-   if "bad_values" in error_dics[0]:
-      headstring += "<th>Bad value(s)</th>"
-   if "bad_items" in error_dics[0]:
-      headstring += "<th>Bad dataname(s)</th>"
-   if "child" in error_dics[0]:
-      headstring += "<th>Child</th>"
-   if "parent" in error_dics[0]:
-      headstring += "<th>Parent</th>"
-   headstring +="</tr>\n"
-   for error in error_dics:
-      bodystring += "<tr><td><tt>%s</tt></td>" % error["item_name"]
-      if "bad_values" in error:
-          bodystring += "<td>%s</td>" % error["bad_values"]
-      if "bad_items" in error:
-          bodystring += "<td><tt>%s</tt></td>" % error["bad_items"]
-      if "child" in error:
-          bodystring += "<td><tt>%s</tt></td>" % error["child"]
-      if "parent" in error:
-          bodystring += "<td><tt>%s</tt></td>" % error["parent"]
-      bodystring += "</tr>\n"
-   return retstring + headstring + bodystring + "</table>\n"
-
-def run_data_checks(check_block,fulldic,block_scope='Item'):
-    v_result = {}
-    for key in check_block.keys():
-        update_value(v_result, fulldic.run_item_validation(key,check_block[key]))
-        update_value(v_result, fulldic.run_global_validation(key,check_block[key],check_block))
-    for loopnames in check_block.loops.values():
-        update_value(v_result, fulldic.run_loop_validation(loopnames))
-    update_value(v_result,fulldic.run_block_validation(check_block,block_scope=block_scope))
-    # return false and list of baddies if anything didn't match
-    all_keys = list(v_result.keys())
-    for test_key in all_keys:
-        v_result[test_key] = [a for a in v_result[test_key] if a[1]["result"]==False]
-        if len(v_result[test_key]) == 0:
-            del v_result[test_key]
-    # if even one false one is found, this should trigger
-    # print("Baddies: {!r}".format(v_result))
-    isvalid = len(v_result)==0
-    return isvalid,v_result
-
-
-def get_number_with_esd(numstring):
-    numb_re = '((-?(([0-9]*[.]([0-9]+))|([0-9]+)[.]?))([(][0-9]+[)])?([eEdD][+-]?[0-9]+)?)|(\\?)|(\\.)'
-    our_match = re.match(numb_re,numstring)
-    if our_match:
-        a,base_num,b,c,dad,dbd,esd,exp,q,dot = our_match.groups()
-        # print("Debug: {} -> {!r}".format(numstring, our_match.groups()))
-    else:
-        return None,None
-    if dot or q: return None,None     #a dot or question mark
-    if exp:          #has exponent
-       exp = exp.replace("d","e")     # mop up old fashioned numbers
-       exp = exp.replace("D","e")
-       base_num = base_num + exp
-    # print("Debug: have %s for base_num from %s" % (base_num,numstring))
-    base_num = float(base_num)
-    # work out esd, if present.
-    if esd:
-        esd = float(esd[1:-1])    # no brackets
-        if dad:                   # decimal point + digits
-            esd = esd * (10 ** (-1* len(dad)))
-        if exp:
-            esd = esd * (10 ** (float(exp[1:])))
-    return base_num,esd
-
-def float_with_esd(inval):
-    if isinstance(inval,unicode):
-        j = inval.find("(")
-        if j>=0:  return float(inval[:j])
-    return float(inval)
-
-
-
-def convert_type(definition):
-    """Convert value to have the type given by definition"""
-    #extract the actual required type information
-    container = definition['_type.container']
-    dimension = definition.get('_type.dimension',StarFile.StarList([]))
-    structure = interpret_structure(definition['_type.contents'])
-    if container == 'Single':   #a single value to convert
-        return convert_single_value(structure)
-    elif container == 'List':   #lots of the same value
-        return convert_list_values(structure,dimension)
-    elif container == 'Multiple': #no idea
-        return None
-    elif container in ('Array','Matrix'): #numpy array
-        return convert_matrix_values(structure)
-    return lambda a:a    #unable to convert
-
-def convert_single_value(type_spec):
-    """Convert a single item according to type_spec"""
-    if type_spec == 'Real':
-        return float_with_esd
-    if type_spec in ('Count','Integer','Index','Binary','Hexadecimal','Octal'):
-        return int
-    if type_spec == 'Complex':
-        return complex
-    if type_spec == 'Imag':
-        return lambda a:complex(0,a)
-    if type_spec in ('Code','Name','Tag'):  #case-insensitive -> lowercase
-        return lambda a:a.lower()
-    return lambda a:a   #can't do anything numeric
-
-class convert_simple_list(object):
-
-    """\
-    Callable object that converts values in a simple list according
-    to the specified element structure.
-    """
-
-    def __init__(self, structure):
-        self.converters = [convert_single_value(tp) for tp in structure]
-        return
-
-    def __call__(self, element):
-        if len(element) != len(self.converters):
-            emsg = "Expected iterable of %i values, got %i." % (
-                (len(self.converters), len(element)))
-            raise ValueError(emsg)
-        rv = [f(e) for f, e in zip(self.converters, element)]
-        return rv
-
-# End of class convert_single_value
-
-def convert_list_values(structure, dimension):
-    """Convert the values according to the element
-       structure given in [[structure]]"""
-    # simple repetition
-    if isinstance(structure, (unicode, str)):
-        fcnv = convert_single_value(structure)
-    # assume structure is a list of types
-    else:
-        fcnv = convert_simple_list(structure)
-    rv = fcnv
-    # setup nested conversion function when dimension differs from 1.
-    if len(dimension) > 0 and int(dimension[0]) != 1:
-        rv = lambda args : [fcnv(a) for a in args]
-    return rv
-
-def convert_matrix_values(valtype):
-    """Convert a dREL String or Float valued List structure to a numpy matrix structure"""
-    # first convert to numpy array, then let numpy do the work
-    try:
-        import numpy
-    except ImportError:
-        return lambda a:a   #cannot do it
-    if valtype == 'Real':
-        dtype = float
-    elif valtype == 'Integer':
-        dtype = int
-    elif valtype == 'Complex':
-        dtype = complex
-    else:
-        raise ValueError('Unknown matrix value type')
-    fcnv = lambda a : numpy.asarray(a, dtype=dtype)
-    return fcnv
-
-def interpret_structure(struc_spec):
-    """Interpret a DDLm structure specification"""
-    from . import TypeContentsParser as t
-    p = t.TypeParser(t.TypeParserScanner(struc_spec))
-    return getattr(p,"input")()
-
-
-# A utility function to append to item values rather than replace them
-def update_value(base_dict,new_items):
-    for new_key in new_items.keys():
-        if new_key in base_dict:
-            base_dict[new_key].extend(new_items[new_key])
-        else:
-            base_dict[new_key] = new_items[new_key]
-
-#Transpose the list of lists passed to us
-def transpose(base_list):
-    new_lofl = []
-    full_length = len(base_list)
-    opt_range = range(full_length)
-    for i in range(len(base_list[0])):
-       new_packet = []
-       for j in opt_range:
-          new_packet.append(base_list[j][i])
-       new_lofl.append(new_packet)
-    return new_lofl
-
-# listify strings - used surprisingly often
-def listify(item):
-    if isinstance(item,(unicode,str)): return [item]
-    else: return item
-
-# given a list of search items, return a list of items
-# actually contained in the given data block
-def filter_present(namelist,datablocknames):
-    return [a for a in namelist if a in datablocknames]
-
-# Make an item immutable, used if we want a list to be a key
-def make_immutable(values):
-    """Turn list of StarList values into a list of immutable items"""
-    if not isinstance(values[0],StarList):
-        return values
-    else:
-        return [tuple(a) for a in values]
-
-# merge ddl dictionaries.  We should be passed filenames or CifFile
-# objects
-def merge_dic(diclist,mergemode="replace",ddlspec=None):
-    dic_as_cif_list = []
-    for dic in diclist:
-        if not isinstance(dic,CifFile) and \
-           not isinstance(dic,(unicode,str)):
-               raise TypeError("Require list of CifFile names/objects for dictionary merging")
-        if not isinstance(dic,CifFile): dic_as_cif_list.append(CifFile(dic))
-        else: dic_as_cif_list.append(dic)
-    # we now merge left to right
-    basedic = dic_as_cif_list[0]
-    if "on_this_dictionary" in basedic:   #DDL1 style only
-        for dic in dic_as_cif_list[1:]:
-           basedic.merge(dic,mode=mergemode,match_att=["_name"])
-    elif len(basedic.keys()) == 1:                     #One block: DDL2/m style
-        old_block = basedic[basedic.keys()[0]]
-        for dic in dic_as_cif_list[1:]:
-           new_block = dic[dic.keys()[0]]
-           basedic.merge(dic,mode=mergemode,
-                         single_block=[basedic.keys()[0],dic.keys()[0]],
-                         match_att=["_item.name"],match_function=find_parent)
-    return CifDic(basedic)
-
-def find_parent(ddl2_def):
-    if "_item.name" not in ddl2_def:
-       return None
-    if isinstance(ddl2_def["_item.name"],unicode):
-        return ddl2_def["_item.name"]
-    if "_item_linked.child_name" not in ddl2_def:
-        raise CifError("Asked to find parent in block with no child_names")
-    if "_item_linked.parent_name" not in ddl2_def:
-        raise CifError("Asked to find parent in block with no parent_names")
-    result = list([a for a in ddl2_def["_item.name"] if a not in ddl2_def["_item_linked.child_name"]])
-    if len(result)>1 or len(result)==0:
-        raise CifError("Unable to find single unique parent data item")
-    return result[0]
-
-
-def ReadCif(filename,grammar='auto',scantype='standard',scoping='instance',standard='CIF',
-            permissive=False):
-    """ Read in a CIF file, returning a `CifFile` object.
-
-    * `filename` may be a URL, a file
-    path on the local system, or any object with a `read` method.
-
-    * `grammar` chooses the CIF grammar variant. `1.0` is the original 1992 grammar and `1.1`
-    is identical except for the exclusion of square brackets as the first characters in
-    undelimited datanames. `2.0` will read files in the CIF2.0 standard, and `STAR2` will
-    read files according to the STAR2 publication.  If grammar is `None`, autodetection
-    will be attempted in the order `2.0`, `1.1` and `1.0`. This will always succeed for
-    properly-formed CIF2.0 files.  Note that only Unicode characters in the basic multilingual
-    plane are recognised (this will be fixed when PyCIFRW is ported to Python 3).
-
-    * `scantype` can be `standard` or `flex`.  `standard` provides pure Python parsing at the
-    cost of a factor of 10 or so in speed.  `flex` will tokenise the input CIF file using
-    fast C routines, but is not available for CIF2/STAR2 files.  Note that running PyCIFRW in
-    Jython uses native Java regular expressions
-    to provide a speedup regardless of this argument (and does not yet support CIF2).
-
-    * `scoping` is only relevant where nested save frames are expected (STAR2 only).
-    `instance` scoping makes nested save frames
-    invisible outside their hierarchy, allowing duplicate save frame names in separate
-    hierarchies. `dictionary` scoping makes all save frames within a data block visible to each
-    other, thereby restricting all save frames to have unique names.
-    Currently the only recognised value for `standard` is `CIF`, which when set enforces a
-    maximum length of 75 characters for datanames and has no other effect. """
-
-    finalcif = CifFile(scoping=scoping,standard=standard)
-    return StarFile.ReadStar(filename,prepared=finalcif,grammar=grammar,scantype=scantype,
-                             permissive=permissive)
-    #return StarFile.StarFile(filename,maxlength,scantype=scantype,grammar=grammar,**kwargs)
-
-class CifLoopBlock(StarFile.LoopBlock):
-    def __init__(self,data=(),**kwargs):
-        super(CifLoopBlock,self).__init__(data,**kwargs)
-
-#No documentation flags
-
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+try:
+    from cStringIO import StringIO
+except ImportError:
+    from io import StringIO
+
+# Python 2,3 compatibility
+try:
+    from urllib import urlopen         # for arbitrary opening
+    from urlparse import urlparse, urljoin
+except:
+    from urllib.request import urlopen
+    from urllib.parse import urlparse, urljoin
+
+# The unicode type does not exist in Python3 as the str type
+# encompasses unicode.  PyCIFRW tests for 'unicode' would fail
+# Suggestions for a better approach welcome.
+#
+# long type no longer exists in Python3, so we alias to int
+#
+if isinstance(u"abc",str):   #Python3
+    unicode = str
+    long = int
+
+__copyright = """
+PYCIFRW License Agreement (Python License, Version 2)
+-----------------------------------------------------
+
+1. This LICENSE AGREEMENT is between the Australian Nuclear Science
+and Technology Organisation ("ANSTO"), and the Individual or
+Organization ("Licensee") accessing and otherwise using this software
+("PyCIFRW") in source or binary form and its associated documentation.
+
+2. Subject to the terms and conditions of this License Agreement,
+ANSTO hereby grants Licensee a nonexclusive, royalty-free, world-wide
+license to reproduce, analyze, test, perform and/or display publicly,
+prepare derivative works, distribute, and otherwise use PyCIFRW alone
+or in any derivative version, provided, however, that this License
+Agreement and ANSTO's notice of copyright, i.e., "Copyright (c)
+2001-2014 ANSTO; All Rights Reserved" are retained in PyCIFRW alone or
+in any derivative version prepared by Licensee.
+
+3. In the event Licensee prepares a derivative work that is based on
+or incorporates PyCIFRW or any part thereof, and wants to make the
+derivative work available to others as provided herein, then Licensee
+hereby agrees to include in any such work a brief summary of the
+changes made to PyCIFRW.
+
+4. ANSTO is making PyCIFRW available to Licensee on an "AS IS"
+basis. ANSTO MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
+IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, ANSTO MAKES NO AND
+DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
+FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYCIFRW WILL NOT
+INFRINGE ANY THIRD PARTY RIGHTS.
+
+5. ANSTO SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYCIFRW
+FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A
+RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYCIFRW, OR ANY
+DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
+
+6. This License Agreement will automatically terminate upon a material
+breach of its terms and conditions.
+
+7. Nothing in this License Agreement shall be deemed to create any
+relationship of agency, partnership, or joint venture between ANSTO
+and Licensee. This License Agreement does not grant permission to use
+ANSTO trademarks or trade name in a trademark sense to endorse or
+promote products or services of Licensee, or any third party.
+
+8. By copying, installing or otherwise using PyCIFRW, Licensee agrees
+to be bound by the terms and conditions of this License Agreement.
+
+"""
+
+
+import re,sys
+from . import StarFile
+from .StarFile import StarList  #put in global scope for exec statement
+try:
+    import numpy                   #put in global scope for exec statement
+    from .drel import drel_runtime  #put in global scope for exec statement
+except ImportError:
+    pass                       #will fail when using dictionaries for calcs
+from copy import copy          #must be in global scope for exec statement
+
+def track_recursion(in_this_func):
+    """Keep an eye on a function call to make sure that the key argument hasn't been
+    seen before"""
+    def wrapper(*args,**kwargs):
+        key_arg = args[1]
+        if key_arg in wrapper.called_list:
+            print('Recursion watch: %s already called %d times' % (key_arg,wrapper.called_list.count(key_arg)))
+            raise CifRecursionError( key_arg,wrapper.called_list[:])    #failure
+        if len(wrapper.called_list) == 0:   #first time
+            wrapper.stored_use_defaults = kwargs.get("allow_defaults",False)
+            print('All recursive calls will set allow_defaults to ' + repr(wrapper.stored_use_defaults))
+        else:
+            kwargs["allow_defaults"] = wrapper.stored_use_defaults
+        wrapper.called_list.append(key_arg)
+        print('Recursion watch: call stack: ' + repr(wrapper.called_list))
+        try:
+            result = in_this_func(*args,**kwargs)
+        except StarFile.StarDerivationError as s:
+            if len(wrapper.called_list) == 1: #no more
+                raise StarFile.StarDerivationFailure(wrapper.called_list[0])
+            else:
+                raise
+        finally:
+            wrapper.called_list.pop()
+            if len(wrapper.called_list) == 0:
+                wrapper.stored_used_defaults = 'error'
+        return result
+    wrapper.called_list = []
+    return wrapper
+
+class CifBlock(StarFile.StarBlock):
+    """
+    A class to hold a single block of a CIF file.  A `CifBlock` object can be treated as
+    a Python dictionary, in particular, individual items can be accessed using square
+    brackets e.g. `b['_a_dataname']`.  All other Python dictionary methods are also
+    available (e.g. `keys()`, `values()`).  Looped datanames will return a list of values.
+
+    ## Initialisation
+
+    When provided, `data` should be another `CifBlock` whose contents will be copied to
+    this block.
+
+    * if `strict` is set, maximum name lengths will be enforced
+
+    * `maxoutlength` is the maximum length for output lines
+
+    * `wraplength` is the ideal length to make output lines
+
+    * When set, `overwrite` allows the values of datanames to be changed (otherwise an error
+    is raised).
+
+    * `compat_mode` will allow deprecated behaviour of creating single-dataname loops using
+    the syntax `a[_dataname] = [1,2,3,4]`.  This should now be done by calling `CreateLoop`
+    after setting the dataitem value.
+    """
+    def __init__(self,data = (), strict = 1, compat_mode=False, **kwargs):
+        """When provided, `data` should be another CifBlock whose contents will be copied to
+        this block.
+
+        * if `strict` is set, maximum name lengths will be enforced
+
+        * `maxoutlength` is the maximum length for output lines
+
+        * `wraplength` is the ideal length to make output lines
+
+        * When set, `overwrite` allows the values of datanames to be changed (otherwise an error
+        is raised).
+
+        * `compat_mode` will allow deprecated behaviour of creating single-dataname loops using
+        the syntax `a[_dataname] = [1,2,3,4]`.  This should now be done by calling `CreateLoop`
+        after setting the dataitem value.
+        """
+        if strict: maxnamelength=75
+        else:
+           maxnamelength=-1
+        super(CifBlock,self).__init__(data=data,maxnamelength=maxnamelength,**kwargs)
+        self.dictionary = None   #DDL dictionary referring to this block
+        self.compat_mode = compat_mode   #old-style behaviour of setitem
+
+    def RemoveCifItem(self,itemname):
+        """Remove `itemname` from the CifBlock"""
+        self.RemoveItem(itemname)
+
+    def __setitem__(self,key,value):
+        self.AddItem(key,value)
+        # for backwards compatibility make a single-element loop
+        if self.compat_mode:
+            if isinstance(value,(tuple,list)) and not isinstance(value,StarFile.StarList):
+                 # single element loop
+                 self.CreateLoop([key])
+
+    def copy(self):
+        newblock = super(CifBlock,self).copy()
+        return self.copy.im_class(newblock)   #catch inheritance
+
+    def AddCifItem(self,data):
+        """ *DEPRECATED*. Use `AddItem` instead."""
+        # we accept only tuples, strings and lists!!
+        if not (isinstance(data[0],(unicode,tuple,list,str))):
+                  raise TypeError('Cif datanames are either a string, tuple or list')
+        # we catch single item loops as well...
+        if isinstance(data[0],(unicode,str)):
+            self.AddSingleCifItem(data[0],list(data[1]))
+            if isinstance(data[1],(tuple,list)) and not isinstance(data[1],StarFile.StarList):  # a single element loop
+                self.CreateLoop([data[0]])
+            return
+        # otherwise, we loop over the datanames
+        keyvals = zip(data[0][0],[list(a) for a in data[1][0]])
+        [self.AddSingleCifItem(a,b) for a,b in keyvals]
+        # and create the loop
+        self.CreateLoop(data[0][0])
+
+    def AddSingleCifItem(self,key,value):
+        """*Deprecated*. Use `AddItem` instead"""
+        """Add a single data item. If it is part of a loop, a separate call should be made"""
+        self.AddItem(key,value)
+
+    def loopnames(self):
+        return [self.loops[a] for a in self.loops]
+
+
+class CifFile(StarFile.StarFile):
+    def __init__(self,datasource=None,strict=1,standard='CIF',**kwargs):
+        super(CifFile,self).__init__(datasource=datasource,standard=standard, **kwargs)
+        self.strict = strict
+        self.header_comment = \
+"""
+##########################################################################
+#               Crystallographic Information Format file
+#               Produced by PyCifRW module
+#
+#  This is a CIF file.  CIF has been adopted by the International
+#  Union of Crystallography as the standard for data archiving and
+#  transmission.
+#
+#  For information on this file format, follow the CIF links at
+#  http://www.iucr.org
+##########################################################################
+"""
+
+
+class CifError(Exception):
+    def __init__(self,value):
+        self.value = value
+    def __str__(self):
+        return '\nCif Format error: '+ self.value
+
+class ValidCifError(Exception):
+    def __init__(self,value):
+        self.value = value
+    def __str__(self):
+        return '\nCif Validity error: ' + self.value
+
+class CifRecursionError(Exception):
+    def __init__(self,key_value,call_stack):
+        self.key_value = key_value
+        self.call_stack = call_stack
+    def __str__(self):
+        return "Derivation has recursed, %s seen twice (call stack %s)" % (self.key_value,repr(self.call_stack))
+
+
+class DicBlock(StarFile.StarBlock):
+    """A definition block within a dictionary, which allows imports
+    to be transparently followed"""
+
+    def __init__(self,*args,**kwargs):
+        super(DicBlock,self).__init__(*args,**kwargs)
+        self._import_cache = {}
+        
+    def __getitem__(self,dataname):
+        value = None
+        if super(DicBlock,self).has_key("_import.get") and self._import_cache:
+            value = self.follow_import(super(DicBlock,self).__getitem__("_import.get"),dataname) 
+        try:
+            final_value = super(DicBlock,self).__getitem__(dataname)
+        except KeyError:    #not there
+            final_value = value
+        if final_value is None:
+            raise KeyError("%s not found" % dataname)
+        return final_value
+
+    def has_key(self,key):
+        try:
+            self[key]
+        except KeyError:
+            return False
+        return True
+    
+    def add_dict_cache(self,name,cached):
+        """Add a loaded dictionary to this block's cache"""
+        self._import_cache[name]=cached
+        
+    def follow_import(self,import_info,dataname):
+        """Find the dataname values from the imported dictionary. `import_info`
+        is a list of import locations"""
+        latest_value = None
+        for import_ref in import_info:
+            file_loc = import_ref["file"]
+            if file_loc not in self._import_cache:
+                raise ValueError("Dictionary for import %s not found" % file_loc)
+            import_from = self._import_cache[file_loc]
+            miss = import_ref.get('miss','Exit')
+            target_key = import_ref["save"]
+            try:
+                import_target = import_from[target_key]
+            except KeyError:
+                if miss == 'Exit':
+                    raise CifError('Import frame %s not found in %s' % (target_key,file_loc))
+                else: continue
+            # now import appropriately
+            mode = import_ref.get("mode",'Contents').lower()
+            if mode == "contents":   #only this is used at this level
+                latest_value = import_target.get(dataname,latest_value)
+        return latest_value
+    
+class CifDic(StarFile.StarFile):
+    """Create a Cif Dictionary object from the provided source, which can
+    be a filename/URL or a emapsCifFile.  Optional arguments (relevant to DDLm
+    only):
+
+    * do_minimum (Boolean):
+         Do not set up the dREL system for auto-calculation or perform
+         imports.  This implies do_imports=False and do_dREL=False
+
+    * do_imports = No/Full/Contents/All:
+         If not 'No', intepret _import.get statements for
+         Full mode/Contents mode/Both respectively. See also option 'heavy'
+
+    * do_dREL = True/False:
+         Parse and convert all dREL methods to Python. Implies do_imports=All
+
+    * heavy = True/False:
+         (Experimental). If True, importation overwrites definitions. If False,
+         attributes are resolved dynamically.
+    """
+    def __init__(self,dic,do_minimum=False,do_imports='All', do_dREL=True,
+                 grammar='auto',heavy=True,**kwargs):
+        self.do_minimum = do_minimum
+        if do_minimum:
+            do_imports = 'No'
+            do_dREL = False
+        if do_dREL: do_imports = 'All'
+        if heavy == 'Light' and do_imports not in ('contents','No'):
+            raise(ValueError,"Light imports only available for mode 'contents'")
+        self.template_cache = {}    #for DDLm imports
+        self.ddlm_functions = {}    #for DDLm functions
+        self.switch_numpy(False)    #no Numpy arrays returned
+        super(CifDic,self).__init__(datasource=dic,grammar=grammar,blocktype=DicBlock,**kwargs)
+        self.standard = 'Dic'    #for correct output order
+        self.scoping = 'dictionary'
+        (self.dicname,self.diclang) = self.dic_determine()
+        print('%s is a %s dictionary' % (self.dicname,self.diclang))
+        self.scopes_mandatory = {}
+        self.scopes_naughty = {}
+        self._import_dics = []   #Non-empty for DDLm only
+        # rename and expand out definitions using "_name" in DDL dictionaries
+        if self.diclang == "DDL1":
+            self.DDL1_normalise()   #this removes any non-definition entries
+        self.create_def_block_table() #From now on, [] uses definition_id
+        if self.diclang == "DDL1":
+            self.ddl1_cat_load()
+        elif self.diclang == "DDL2":
+            self.DDL2_normalise()   #iron out some DDL2 tricky bits
+        elif self.diclang == "DDLm":
+            self.scoping = 'dictionary'   #expose all save frames
+            if do_imports is not 'No':
+                self.obtain_imports(import_mode=do_imports,heavy=heavy)#recursively calls this routine
+            self.create_alias_table()
+            self.create_cat_obj_table()
+            self.create_cat_key_table()
+            if do_dREL:
+                print('Doing full dictionary initialisation')
+                self.initialise_drel()
+        self.add_category_info(full=do_dREL)
+        # initialise type information
+        self.typedic={}
+        self.primdic = {}   #typecode<->primitive type translation
+        self.add_type_info()
+        self.install_validation_functions()
+
+    def dic_determine(self):
+        if "on_this_dictionary" in self:
+            self.master_block = super(CifDic,self).__getitem__("on_this_dictionary")
+            self.def_id_spec = "_name"
+            self.cat_id_spec = "_category.id"   #we add this ourselves
+            self.type_spec = "_type"
+            self.enum_spec = "_enumeration"
+            self.cat_spec = "_category"
+            self.esd_spec = "_type_conditions"
+            self.must_loop_spec = "_list"
+            self.must_exist_spec = "_list_mandatory"
+            self.list_ref_spec = "_list_reference"
+            self.key_spec = "_list_mandatory"
+            self.unique_spec = "_list_uniqueness"
+            self.child_spec = "_list_link_child"
+            self.parent_spec = "_list_link_parent"
+            self.related_func = "_related_function"
+            self.related_item = "_related_item"
+            self.primitive_type = "_type"
+            self.dep_spec = "xxx"
+            self.cat_list = []   #to save searching all the time
+            name = super(CifDic,self).__getitem__("on_this_dictionary")["_dictionary_name"]
+            version = super(CifDic,self).__getitem__("on_this_dictionary")["_dictionary_version"]
+            return (name+version,"DDL1")
+        elif len(self.get_roots()) == 1:              # DDL2/DDLm
+            self.master_block = super(CifDic,self).__getitem__(self.get_roots()[0][0])
+            # now change to dictionary scoping
+            self.scoping = 'dictionary'
+            name = self.master_block["_dictionary.title"]
+            version = self.master_block["_dictionary.version"]
+            if self.master_block.has_key("_dictionary.class"):   #DDLm
+                self.enum_spec = '_enumeration_set.state'
+                self.key_spec = '_category.key_id'
+                self.must_exist_spec = None
+                self.cat_spec = '_name.category_id'
+                self.primitive_type = '_type.contents'
+                self.cat_id_spec = "_definition.id"
+                self.def_id_spec = "_definition.id"
+                return(name+version,"DDLm")
+            else:   #DDL2
+                self.cat_id_spec = "_category.id"
+                self.def_id_spec = "_item.name"
+                self.key_spec = "_category_mandatory.name"
+                self.type_spec = "_item_type.code"
+                self.enum_spec = "_item_enumeration.value"
+                self.esd_spec = "_item_type_conditions.code"
+                self.cat_spec = "_item.category_id"
+                self.loop_spec = "there_is_no_loop_spec!"
+                self.must_loop_spec = "xxx"
+                self.must_exist_spec = "_item.mandatory_code"
+                self.child_spec = "_item_linked.child_name"
+                self.parent_spec = "_item_linked.parent_name"
+                self.related_func = "_item_related.function_code"
+                self.related_item = "_item_related.related_name"
+                self.unique_spec = "_category_key.name"
+                self.list_ref_spec = "xxx"
+                self.primitive_type = "_type"
+                self.dep_spec = "_item_dependent.dependent_name"
+                return (name+version,"DDL2")
+        else:
+            raise CifError("Unable to determine dictionary DDL version")
+
+    def DDL1_normalise(self):
+        # switch off block name collision checks
+        self.standard = None
+        # add default type information in DDL2 style
+        # initial types and constructs
+        base_types = ["char","numb","null"]
+        prim_types = base_types[:]
+        base_constructs = [".*",
+            '(-?(([0-9]*[.][0-9]+)|([0-9]+)[.]?)([(][0-9]+[)])?([eEdD][+-]?[0-9]+)?)|\\?|\\.',
+            "\"\" "]
+        for key,value in self.items():
+           newnames = [key]  #keep by default
+           if "_name" in value:
+               real_name = value["_name"]
+               if isinstance(real_name,list):        #looped values
+                   for looped_name in real_name:
+                      new_value = value.copy()
+                      new_value["_name"] = looped_name  #only looped name
+                      self[looped_name] = new_value
+                   newnames = real_name
+               else:
+                      self[real_name] = value
+                      newnames = [real_name]
+           # delete the old one
+           if key not in newnames:
+              del self[key]
+        # loop again to normalise the contents of each definition
+        for key,value in self.items():
+           #unlock the block
+           save_overwrite = value.overwrite
+           value.overwrite = True
+           # deal with a missing _list, _type_conditions
+           if "_list" not in value: value["_list"] = 'no'
+           if "_type_conditions" not in value: value["_type_conditions"] = 'none'
+           # deal with enumeration ranges
+           if "_enumeration_range" in value:
+               max,min = self.getmaxmin(value["_enumeration_range"])
+               if min == ".":
+                   self[key].AddLoopItem((("_item_range.maximum","_item_range.minimum"),((max,max),(max,min))))
+               elif max == ".":
+                   self[key].AddLoopItem((("_item_range.maximum","_item_range.minimum"),((max,min),(min,min))))
+               else:
+                   self[key].AddLoopItem((("_item_range.maximum","_item_range.minimum"),((max,max,min),(max,min,min))))
+           #add any type construct information
+           if "_type_construct" in value:
+               base_types.append(value["_name"]+"_type")   #ie dataname_type
+               base_constructs.append(value["_type_construct"]+"$")
+               prim_types.append(value["_type"])     #keep a record
+               value["_type"] = base_types[-1]   #the new type name
+
+        #make categories conform with ddl2
+        #note that we must remove everything from the last underscore
+           if value.get("_category",None) == "category_overview":
+                last_under = value["_name"].rindex("_")
+                catid = value["_name"][1:last_under]
+                value["_category.id"] = catid  #remove square bracks
+                if catid not in self.cat_list: self.cat_list.append(catid)
+           value.overwrite = save_overwrite
+        # we now add any missing categories before filling in the rest of the
+        # information
+        for key,value in self.items():
+            #print('processing ddl1 definition %s' % key)
+            if "_category" in self[key]:
+                if self[key]["_category"] not in self.cat_list:
+                    # rogue category, add it in
+                    newcat = self[key]["_category"]
+                    fake_name = "_" + newcat + "_[]"
+                    newcatdata = CifBlock()
+                    newcatdata["_category"] = "category_overview"
+                    newcatdata["_category.id"] = newcat
+                    newcatdata["_type"] = "null"
+                    self[fake_name] = newcatdata
+                    self.cat_list.append(newcat)
+        # write out the type information in DDL2 style
+        self.master_block.AddLoopItem((
+            ("_item_type_list.code","_item_type_list.construct",
+              "_item_type_list.primitive_code"),
+            (base_types,base_constructs,prim_types)
+            ))
+
+    def ddl1_cat_load(self):
+        deflist = self.keys()       #slight optimization
+        cat_mand_dic = {}
+        cat_unique_dic = {}
+        # a function to extract any necessary information from each definition
+        def get_cat_info(single_def):
+            if self[single_def].get(self.must_exist_spec)=='yes':
+                thiscat = self[single_def]["_category"]
+                curval = cat_mand_dic.get(thiscat,[])
+                curval.append(single_def)
+                cat_mand_dic[thiscat] = curval
+            # now the unique items...
+            # cif_core.dic throws us a curly one: the value of list_uniqueness is
+            # not the same as the defined item for publ_body_label, so we have
+            # to collect both together.  We assume a non-listed entry, which
+            # is true for all current (May 2005) ddl1 dictionaries.
+            if self[single_def].get(self.unique_spec,None)!=None:
+                thiscat = self[single_def]["_category"]
+                new_unique = self[single_def][self.unique_spec]
+                uis = cat_unique_dic.get(thiscat,[])
+                if single_def not in uis: uis.append(single_def)
+                if new_unique not in uis: uis.append(new_unique)
+                cat_unique_dic[thiscat] = uis
+
+        [get_cat_info(a) for a in deflist] # apply the above function
+        for cat in cat_mand_dic.keys():
+            self[cat]["_category_mandatory.name"] = cat_mand_dic[cat]
+        for cat in cat_unique_dic.keys():
+            self[cat]["_category_key.name"] = cat_unique_dic[cat]
+
+    def create_pcloop(self,definition):
+        old_children = self[definition].get('_item_linked.child_name',[])
+        old_parents = self[definition].get('_item_linked.parent_name',[])
+        if isinstance(old_children,unicode):
+             old_children = [old_children]
+        if isinstance(old_parents,unicode):
+             old_parents = [old_parents]
+        if (len(old_children)==0 and len(old_parents)==0) or \
+           (len(old_children) > 1 and len(old_parents)>1):
+             return
+        if len(old_children)==0:
+             old_children = [definition]*len(old_parents)
+        if len(old_parents)==0:
+             old_parents = [definition]*len(old_children)
+        newloop = CifLoopBlock(dimension=1)
+        newloop.AddLoopItem(('_item_linked.parent_name',old_parents))
+        newloop.AddLoopItem(('_item_linked.child_name',old_children))
+        try:
+            del self[definition]['_item_linked.parent_name']
+            del self[definition]['_item_linked.child_name']
+        except KeyError:
+            pass
+        self[definition].insert_loop(newloop)
+
+
+
+    def DDL2_normalise(self):
+       listed_defs = filter(lambda a:isinstance(self[a].get('_item.name'),list),self.keys())
+       # now filter out all the single element lists!
+       dodgy_defs = filter(lambda a:len(self[a]['_item.name']) > 1, listed_defs)
+       for item_def in dodgy_defs:
+                # print("DDL2 norm: processing %s" % item_def)
+                thisdef = self[item_def]
+                packet_no = thisdef['_item.name'].index(item_def)
+                realcat = thisdef['_item.category_id'][packet_no]
+                realmand = thisdef['_item.mandatory_code'][packet_no]
+                # first add in all the missing categories
+                # we don't replace the entry in the list corresponding to the
+                # current item, as that would wipe out the information we want
+                for child_no in range(len(thisdef['_item.name'])):
+                    if child_no == packet_no: continue
+                    child_name = thisdef['_item.name'][child_no]
+                    child_cat = thisdef['_item.category_id'][child_no]
+                    child_mand = thisdef['_item.mandatory_code'][child_no]
+                    if child_name not in self:
+                        self[child_name] = CifBlock()
+                        self[child_name]['_item.name'] = child_name
+                    self[child_name]['_item.category_id'] = child_cat
+                    self[child_name]['_item.mandatory_code'] = child_mand
+                self[item_def]['_item.name'] = item_def
+                self[item_def]['_item.category_id'] = realcat
+                self[item_def]['_item.mandatory_code'] = realmand
+
+       target_defs = [a for a in self.keys() if '_item_linked.child_name' in self[a] or \
+                                     '_item_linked.parent_name' in self[a]]
+       # now dodgy_defs contains all definition blocks with more than one child/parent link
+       for item_def in dodgy_defs: self.create_pcloop(item_def)           #regularise appearance
+       for item_def in dodgy_defs:
+             print('Processing %s' % item_def)
+             thisdef = self[item_def]
+             child_list = thisdef['_item_linked.child_name']
+             parents = thisdef['_item_linked.parent_name']
+             # for each parent, find the list of children.
+             family = list(zip(parents,child_list))
+             notmychildren = family         #We aim to remove non-children
+             # Loop over the parents, relocating as necessary
+             while len(notmychildren):
+                # get all children of first entry
+                mychildren = [a for a in family if a[0]==notmychildren[0][0]]
+                print("Parent %s: %d children" % (notmychildren[0][0],len(mychildren)))
+                for parent,child in mychildren:   #parent is the same for all
+                         # Make sure that we simply add in the new entry for the child, not replace it,
+                         # otherwise we might spoil the child entry loop structure
+                         try:
+                             childloop = self[child].GetLoop('_item_linked.parent_name')
+                         except KeyError:
+                             print('Creating new parent entry %s for definition %s' % (parent,child))
+                             self[child]['_item_linked.parent_name'] = [parent]
+                             childloop = self[child].GetLoop('_item_linked.parent_name')
+                             childloop.AddLoopItem(('_item_linked.child_name',[child]))
+                             continue
+                         else:
+                             # A parent loop already exists and so will a child loop due to the
+                             # call to create_pcloop above
+                             pars = [a for a in childloop if getattr(a,'_item_linked.child_name','')==child]
+                             goodpars = [a for a in pars if getattr(a,'_item_linked.parent_name','')==parent]
+                             if len(goodpars)>0:   #no need to add it
+                                 print('Skipping duplicated parent - child entry in %s: %s - %s' % (child,parent,child))
+                                 continue
+                             print('Adding %s to %s entry' % (parent,child))
+                             newpacket = childloop.GetPacket(0)   #essentially a copy, I hope
+                             setattr(newpacket,'_item_linked.child_name',child)
+                             setattr(newpacket,'_item_linked.parent_name',parent)
+                             childloop.AddPacket(newpacket)
+                #
+                # Make sure the parent also points to the children.  We get
+                # the current entry, then add our
+                # new values if they are not there already
+                #
+                parent_name = mychildren[0][0]
+                old_children = self[parent_name].get('_item_linked.child_name',[])
+                old_parents = self[parent_name].get('_item_linked.parent_name',[])
+                oldfamily = zip(old_parents,old_children)
+                newfamily = []
+                print('Old parents -> %s' % repr(old_parents))
+                for jj, childname in mychildren:
+                    alreadythere = [a for a in oldfamily if a[0]==parent_name and a[1] ==childname]
+                    if len(alreadythere)>0: continue
+                    'Adding new child %s to parent definition at %s' % (childname,parent_name)
+                    old_children.append(childname)
+                    old_parents.append(parent_name)
+                # Now output the loop, blowing away previous definitions.  If there is something
+                # else in this category, we are destroying it.
+                newloop = CifLoopBlock(dimension=1)
+                newloop.AddLoopItem(('_item_linked.parent_name',old_parents))
+                newloop.AddLoopItem(('_item_linked.child_name',old_children))
+                del self[parent_name]['_item_linked.parent_name']
+                del self[parent_name]['_item_linked.child_name']
+                self[parent_name].insert_loop(newloop)
+                print('New parents -> %s' % repr(self[parent_name]['_item_linked.parent_name']))
+                # now make a new,smaller list
+                notmychildren = [a for a in notmychildren if a[0]!=mychildren[0][0]]
+
+       # now flatten any single element lists
+       single_defs = filter(lambda a:len(self[a]['_item.name'])==1,listed_defs)
+       for flat_def in single_defs:
+           flat_keys = self[flat_def].GetLoop('_item.name').keys()
+           for flat_key in flat_keys: self[flat_def][flat_key] = self[flat_def][flat_key][0]
+       # now deal with the multiple lists
+       # next we do aliases
+       all_aliases = [a for a in self.keys() if self[a].has_key('_item_aliases.alias_name')]
+       for aliased in all_aliases:
+          my_aliases = listify(self[aliased]['_item_aliases.alias_name'])
+          for alias in my_aliases:
+              self[alias] = self[aliased].copy()   #we are going to delete stuff...
+              del self[alias]["_item_aliases.alias_name"]
+
+    def ddlm_parse_valid(self):
+        if "_dictionary_valid.application" not in self.master_block:
+            return
+        for scope_pack in self.master_block.GetLoop("_dictionary_valid.application"):
+            scope = getattr(scope_pack,"_dictionary_valid.application")
+            valid_info = getattr(scope_pack,"_dictionary_valid.attributes")
+            if scope[1] == "Mandatory":
+                self.scopes_mandatory[scope[0]] = self.expand_category_opt(valid_info)
+            elif scope[1] == "Prohibited":
+                self.scopes_naughty[scope[0]] = self.expand_category_opt(valid_info)
+
+    def obtain_imports(self,import_mode,heavy=False):
+        """Collate import information"""
+        self._import_dics = []
+        import_frames = list([(a,self[a]['_import.get']) for a in self.keys() if '_import.get' in self[a]])
+        print('Import mode %s applied to following frames' % import_mode)
+        print(str([a[0] for a in import_frames]))
+        if import_mode != 'All':
+           for i in range(len(import_frames)):
+                import_frames[i] = (import_frames[i][0],[a for a in import_frames[i][1] if a.get('mode','Contents').lower() == import_mode.lower()])
+           print('Importing following frames in mode %s' % import_mode)
+           print(str(import_frames))
+        #resolve all references
+        for parent_block,import_list in import_frames:
+          for import_ref in import_list:
+            file_loc = import_ref["file"]
+            full_uri = self.resolve_path(file_loc)
+            if full_uri not in self.template_cache:
+                dic_as_cif = CifFile(full_uri,grammar=self.grammar)
+                self.template_cache[full_uri] = CifDic(dic_as_cif,do_imports=import_mode,heavy=heavy,do_dREL=False)  #this will recurse internal imports
+                print('Added %s to cached dictionaries' % full_uri)
+            import_from = self.template_cache[full_uri]
+            dupl = import_ref.get('dupl','Exit')
+            miss = import_ref.get('miss','Exit')
+            target_key = import_ref["save"]
+            try:
+                import_target = import_from[target_key]
+            except KeyError:
+                if miss == 'Exit':
+                   raise CifError('Import frame %s not found in %s' % (target_key,full_uri))
+                else: continue
+            # now import appropriately
+            mode = import_ref.get("mode",'Contents').lower()
+            if target_key in self and mode=='full':  #so blockname will be duplicated
+                if dupl == 'Exit':
+                    raise CifError('Import frame %s already in dictionary' % target_key)
+                elif dupl == 'Ignore':
+                    continue
+            if heavy:
+                self.ddlm_import(parent_block,import_from,import_target,target_key,mode)
+            else:
+                self.ddlm_import_light(parent_block,import_from,import_target,target_key,file_loc,mode)
+                
+    def ddlm_import(self,parent_block,import_from,import_target,target_key,mode='All'):
+            """Import other dictionaries in place"""
+            if mode == 'contents':   #merge attributes only
+                self[parent_block].merge(import_target)
+            elif mode =="full":
+                # Do the syntactic merge
+                syntactic_head = self[self.get_parent(parent_block)] #root frame if no nesting
+                from_cat_head = import_target['_name.object_id']
+                child_frames = import_from.ddlm_all_children(from_cat_head)
+                 # Check for Head merging Head
+                if self[parent_block].get('_definition.class','Datum')=='Head' and \
+                   import_target.get('_definition.class','Datum')=='Head':
+                      head_to_head = True
+                else:
+                      head_to_head = False
+                      child_frames.remove(from_cat_head)
+                # As we are in syntax land, we call the CifFile methods
+                child_blocks = list([import_from.block_id_table[a.lower()] for a in child_frames])
+                child_blocks = super(CifDic,import_from).makebc(child_blocks)
+                # Prune out any datablocks that have identical definitions
+                from_defs = dict([(a,child_blocks[a].get('_definition.id','').lower()) for a in child_blocks.keys()])
+                double_defs = list([b for b in from_defs.items() if self.has_key(b[1])])
+                print('Definitions for %s superseded' % repr(double_defs))
+                for b in double_defs:
+                    del child_blocks[b[0]]
+                super(CifDic,self).merge_fast(child_blocks,parent=syntactic_head)      #
+                print('Syntactic merge of %s (%d defs) in %s mode, now have %d defs' % (target_key,len(child_frames),
+                   mode,len(self)))
+                # Now the semantic merge
+                # First expand our definition <-> blockname tree
+                self.create_def_block_table()
+                merging_cat = self[parent_block]['_name.object_id']      #new parent
+                if head_to_head:
+                    child_frames = self.ddlm_immediate_children(from_cat_head)    #old children
+                    #the new parent is the importing category for all old children
+                    for f in child_frames:
+                        self[f].overwrite = True
+                        self[f]['_name.category_id'] = merging_cat
+                        self[f].overwrite = False
+                    # remove the old head
+                    del self[from_cat_head]
+                    print('Semantic merge: %d defs reparented from %s to %s' % (len(child_frames),from_cat_head,merging_cat))
+                else:  #imported category is only child
+                    from_frame = import_from[target_key]['_definition.id'] #so we can find it
+                    child_frame = [d for d in self.keys() if self[d]['_definition.id']==from_frame][0]
+                    self[child_frame]['_name.category_id'] = merging_cat
+                    print('Semantic merge: category for %s : now %s' % (from_frame,merging_cat))
+            # it will never happen again...
+            del self[parent_block]["_import.get"]
+
+    def resolve_path(self,file_loc):
+        url_comps = urlparse(file_loc)
+        if url_comps[0]: return file_loc    #already full URI
+        new_url = urljoin(self.my_uri,file_loc)
+        #print("Transformed %s to %s for import " % (file_loc,new_url))
+        return new_url
+
+    def ddlm_import_light(self,parent_block,import_from,import_target,target_key,file_loc,mode='All'):
+        """Register the imported dictionaries but do not alter any definitions. `parent_block`
+        contains the id of the block that is importing. `import_target` is the block that
+        should be imported. `import_from` is the CifFile that contains the definitions."""
+        if mode == 'contents':   #merge attributes only
+            self[parent_block].add_dict_cache(file_loc,import_from)
+        elif mode =="full":
+             # Check for Head merging Head
+            if self[parent_block].get('_definition.class','Datum')=='Head' and \
+               import_target.get('_definition.class','Datum')=='Head':
+                   head_to_head = True
+            else:
+                   head_to_head = False
+            # Figure out the actual definition ID
+            head_id = import_target["_definition.id"]
+            # Adjust parent information
+            merging_cat = self[parent_block]['_name.object_id']
+            from_cat_head = import_target['_name.object_id']
+            if not head_to_head:   # imported category is only child
+                import_target["_name.category_id"]=merging_cat
+            self._import_dics = [(import_from,head_id)]+self._import_dics #prepend
+
+    def lookup_imports(self,key):
+        """Check the list of imported dictionaries for this definition"""
+        for one_dic,head_def in self._import_dics:
+            from_cat_head = one_dic[head_def]['_name.object_id']
+            possible_keys = one_dic.ddlm_all_children(from_cat_head)
+            if key in possible_keys:
+                return one_dic[key]
+        raise KeyError("%s not found in import dictionaries" % key)
+        
+
+
+    def create_def_block_table(self):
+        """ Create an internal table matching definition to block id """
+        proto_table = [(super(CifDic,self).__getitem__(a),a) for a in super(CifDic,self).keys()]
+        # now get the actual ids instead of blocks
+        proto_table = list([(a[0].get(self.cat_id_spec,a[0].get(self.def_id_spec,a[1])),a[1]) for a in proto_table])
+        # remove non-definitions
+        if self.diclang != "DDL1":
+            top_blocks = list([a[0].lower() for a in self.get_roots()])
+        else:
+            top_blocks = ["on_this_dictionary"]
+        # catch dodgy duplicates
+        uniques = set([a[0] for a in proto_table])
+        if len(uniques)<len(proto_table):
+            def_names = list([a[0] for a in proto_table])
+            dodgy = [a for a in def_names if def_names.count(a)>1]
+            raise CifError('Duplicate definitions in dictionary:' + repr(dodgy))
+        self.block_id_table = dict([(a[0].lower(),a[1].lower()) for a in proto_table if a[1].lower() not in top_blocks])
+
+    def __getitem__(self,key):
+        """Access a datablock by definition id, after the lookup has been created"""
+        try:
+            return super(CifDic,self).__getitem__(self.block_id_table[key.lower()])
+        except AttributeError:   #block_id_table not present yet
+            return super(CifDic,self).__getitem__(key)
+        except KeyError: # key is missing
+            try: # print(Definition for %s not found, reverting to CifFile' % key)
+                return super(CifDic,self).__getitem__(key)
+            except KeyError: # try imports
+                return self.lookup_imports(key)
+
+    def __setitem__(self,key,value):
+        """Add a new definition block"""
+        super(CifDic,self).__setitem__(key,value)
+        try:
+            self.block_id_table[value['_definition.id']]=key
+        except AttributeError:   #does not exist yet
+            pass
+
+    def NewBlock(self,*args,**kwargs):
+        newname = super(CifDic,self).NewBlock(*args,**kwargs)
+        try:
+            self.block_id_table[self[newname]['_definition.id']]=newname
+        except AttributeError: #no block_id table
+            pass
+                
+    def __delitem__(self,key):
+        """Remove a definition"""
+        try:
+            super(CifDic,self).__delitem__(self.block_id_table[key.lower()])
+            del self.block_id_table[key.lower()]
+        except (AttributeError,KeyError):   #block_id_table not present yet
+            super(CifDic,self).__delitem__(key)
+            return
+        # fix other datastructures
+        # cat_obj table
+
+    def keys(self):
+        """Return all definitions"""
+        try:
+            return self.block_id_table.keys()
+        except AttributeError:
+            return super(CifDic,self).keys()
+
+    def has_key(self,key):
+        return key in self
+
+    def __contains__(self,key):
+        try:
+            return key.lower() in self.block_id_table
+        except AttributeError:
+            return super(CifDic,self).__contains__(key)
+
+    def items(self):
+        """Return (key,value) pairs"""
+        return list([(a,self[a]) for a in self.keys()])
+
+    def unlock(self):
+        """Allow overwriting of all definitions in this collection"""
+        for a in self.keys():
+            self[a].overwrite=True
+
+    def lock(self):
+        """Disallow changes in definitions"""
+        for a in self.keys():
+            self[a].overwrite=False
+
+    def rename(self,oldname,newname,blockname_as_well=True):
+        """Change a _definition.id from oldname to newname, and if `blockname_as_well` is True,
+        change the underlying blockname too."""
+        if blockname_as_well:
+            super(CifDic,self).rename(self.block_id_table[oldname.lower()],newname)
+            self.block_id_table[newname.lower()]=newname
+            if oldname.lower() in self.block_id_table: #not removed
+               del self.block_id_table[oldname.lower()]
+        else:
+            self.block_id_table[newname.lower()]=self.block_id_table[oldname.lower()]
+            del self.block_id_table[oldname.lower()]
+            return
+
+    def get_root_category(self):
+        """Get the single 'Head' category of this dictionary"""
+        root_cats = [r for r in self.keys() if self[r].get('_definition.class','Datum')=='Head']
+        if len(root_cats)>1 or len(root_cats)==0:
+            raise CifError("Cannot determine a unique Head category, got" % repr(root_cats))
+        return root_cats[0]
+
+    def ddlm_immediate_children(self,catname):
+        """Return a list of datanames for the immediate children of catname.  These are
+        semantic children (i.e. based on _name.category_id), not structural children as
+        in the case of StarFile.get_immediate_children"""
+
+        straight_children = [a for a in self.keys() if self[a].get('_name.category_id','').lower() == catname.lower()]
+        return list(straight_children)
+
+    def ddlm_all_children(self,catname):
+        """Return a list of all children, including the `catname`"""
+        all_children = self.ddlm_immediate_children(catname)
+        cat_children = [a for a in all_children if self[a].get('_definition.scope','Item') == 'Category']
+        for c in cat_children:
+            all_children.remove(c)
+            all_children += self.ddlm_all_children(c)
+        return all_children + [catname]
+
+    def is_semantic_child(self,parent,maybe_child):
+        """Return true if `maybe_child` is a child of `parent`"""
+        all_children = self.ddlm_all_children(parent)
+        return maybe_child in all_children
+
+    def ddlm_danglers(self):
+        """Return a list of definitions that do not have a category defined
+        for them, or are children of an unattached category"""
+        top_block = self.get_root_category()
+        connected = set(self.ddlm_all_children(top_block))
+        all_keys = set(self.keys())
+        unconnected = all_keys - connected
+        return list(unconnected)
+
+    def get_ddlm_parent(self,itemname):
+        """Get the parent category of itemname"""
+        parent = self[itemname].get('_name.category_id','')
+        if parent == '':  # use the top block by default
+            raise CifError("%s has no parent" % itemname)
+        return parent
+
+    def expand_category_opt(self,name_list):
+        """Return a list of all non-category items in a category or return the name
+           if the name is not a category"""
+        new_list = []
+        for name in name_list:
+          if self.get(name,{}).get('_definition.scope','Item') == 'Category':
+            new_list += self.expand_category_opt([a for a in self.keys() if \
+                     self[a].get('_name.category_id','').lower() == name.lower()])
+          else:
+            new_list.append(name)
+        return new_list
+
+    def get_categories(self):
+        """Return a list of category names"""
+        return list([c for c in self.keys() if self[c].get("_definition.scope")=='Category'])
+
+    def names_in_cat(self,cat,names_only=False):
+        names = [a for a in self.keys() if self[a].get('_name.category_id','').lower()==cat.lower()]
+        if not names_only:
+            return list([a for a in names if self[a].get('_definition.scope','Item')=='Item'])
+        else:
+            return list([self[a]["_name.object_id"] for a in names])
+
+
+
+    def create_alias_table(self):
+        """Populate an alias table that we can look up when searching for a dataname"""
+        all_aliases = [a for a in self.keys() if '_alias.definition_id' in self[a]]
+        self.alias_table = dict([[a,self[a]['_alias.definition_id']] for a in all_aliases])
+
+    def create_cat_obj_table(self):
+        """Populate a table indexed by (cat,obj) and returning the correct dataname"""
+        base_table = dict([((self[a].get('_name.category_id','').lower(),self[a].get('_name.object_id','').lower()),[self[a].get('_definition.id','')]) \
+                           for a in self.keys() if self[a].get('_definition.scope','Item')=='Item'])
+        loopable = self.get_loopable_cats()
+        loopers = [self.ddlm_immediate_children(a) for a in loopable]
+        print('Loopable cats:' + repr(loopable))
+        loop_children = [[b for b in a if b.lower() in loopable ] for a in loopers]
+        expand_list = dict([(a,b) for a,b in zip(loopable,loop_children) if len(b)>0])
+        print("Expansion list:" + repr(expand_list))
+        extra_table = {}   #for debugging we keep it separate from base_table until the end
+        def expand_base_table(parent_cat,child_cats):
+            extra_names = []
+            # first deal with all the child categories
+            for child_cat in child_cats:
+              nn = []
+              if child_cat in expand_list:  # a nested category: grab its names
+                nn = expand_base_table(child_cat,expand_list[child_cat])
+                # store child names
+                extra_names += nn
+              # add all child names to the table
+              child_names = [(self[n]['_name.object_id'].lower(),self[n]['_definition.id']) \
+                             for n in self.names_in_cat(child_cat) if self[n].get('_type.purpose','') != 'Key']
+              child_names += extra_names
+              extra_table.update(dict([((parent_cat,obj),[name]) for obj,name in child_names if (parent_cat,name) not in extra_table]))
+            # and the repeated ones get appended instead
+            repeats = [a for a in child_names if a in extra_table]
+            for obj,name in repeats:
+                extra_table[(parent_cat,obj)] += [name]
+            # and finally, add our own names to the return list
+            child_names += [(self[n]['_name.object_id'].lower(),self[n]['_definition.id']) \
+                            for n in self.names_in_cat(parent_cat) if self[n].get('_type.purpose','')!='Key']
+            return child_names
+        [expand_base_table(parent,child) for parent,child in expand_list.items()]
+        print('Expansion cat/obj values: ' + repr(extra_table))
+        # append repeated ones
+        non_repeats = dict([a for a in extra_table.items() if a[0] not in base_table])
+        repeats = [a for a in extra_table.keys() if a in base_table]
+        base_table.update(non_repeats)
+        for k in repeats:
+            base_table[k] += extra_table[k]
+        self.cat_obj_lookup_table = base_table
+        self.loop_expand_list = expand_list
+
+    def get_loopable_cats(self):
+        """A short utility function which returns a list of looped categories. This
+        is preferred to a fixed attribute as that fixed attribute would need to be
+        updated after any edits"""
+        return [a.lower() for a in self.keys() if self[a].get('_definition.class','')=='Loop']
+
+    def create_cat_key_table(self):
+        """Create a utility table with a list of keys applicable to each category. A key is
+        a compound key, that is, it is a list"""
+        self.cat_key_table = dict([(c,[listify(self[c].get("_category_key.name",
+            [self[c].get("_category.key_id")]))]) for c in self.get_loopable_cats()])
+        def collect_keys(parent_cat,child_cats):
+                kk = []
+                for child_cat in child_cats:
+                    if child_cat in self.loop_expand_list:
+                        kk += collect_keys(child_cat)
+                    # add these keys to our list
+                    kk += [listify(self[child_cat].get('_category_key.name',[self[child_cat].get('_category.key_id')]))]
+                self.cat_key_table[parent_cat] = self.cat_key_table[parent_cat] + kk
+                return kk
+        for k,v in self.loop_expand_list.items():
+            collect_keys(k,v)
+        print('Keys for categories' + repr(self.cat_key_table))
+
+    def add_type_info(self):
+        if "_item_type_list.construct" in self.master_block:
+            types = self.master_block["_item_type_list.code"]
+            prim_types = self.master_block["_item_type_list.primitive_code"]
+            constructs = list([a + "$" for a in self.master_block["_item_type_list.construct"]])
+            # add in \r wherever we see \n, and change \{ to \\{
+            def regex_fiddle(mm_regex):
+                brack_match = r"((.*\[.+)(\\{)(.*\].*))"
+                ret_match = r"((.*\[.+)(\\n)(.*\].*))"
+                fixed_regexp = mm_regex[:]  #copy
+                # fix the brackets
+                bm = re.match(brack_match,mm_regex)
+                if bm != None:
+                    fixed_regexp = bm.expand(r"\2\\\\{\4")
+                # fix missing \r
+                rm = re.match(ret_match,fixed_regexp)
+                if rm != None:
+                    fixed_regexp = rm.expand(r"\2\3\\r\4")
+                #print("Regexp %s becomes %s" % (mm_regex,fixed_regexp))
+                return fixed_regexp
+            constructs = map(regex_fiddle,constructs)
+            for typecode,construct in zip(types,constructs):
+                self.typedic[typecode] = re.compile(construct,re.MULTILINE|re.DOTALL)
+            # now make a primitive <-> type construct mapping
+            for typecode,primtype in zip(types,prim_types):
+                self.primdic[typecode] = primtype
+
+    def add_category_info(self,full=True):
+        if self.diclang == "DDLm":
+            catblocks = [c for c in self.keys() if self[c].get('_definition.scope')=='Category']
+            looped_cats = [a for a in catblocks if self[a].get('_definition.class','Set') == 'Loop']
+            self.parent_lookup = {}
+            for one_cat in looped_cats:
+                parent_cat = one_cat
+                parent_def = self[parent_cat]
+                next_up = parent_def['_name.category_id'].lower()
+                while next_up in self and self[next_up].get('_definition.class','Set') == 'Loop':
+                    parent_def = self[next_up]
+                    parent_cat = next_up
+                    next_up = parent_def['_name.category_id'].lower()
+                self.parent_lookup[one_cat] = parent_cat
+
+            if full:
+                self.key_equivs = {}
+                for one_cat in looped_cats:   #follow them up
+                    lower_keys = listify(self[one_cat]['_category_key.name'])
+                    start_keys = lower_keys[:]
+                    while len(lower_keys)>0:
+                        this_cat = self[lower_keys[0]]['_name.category_id']
+                        parent = [a for a in looped_cats if self[this_cat]['_name.category_id'].lower()==a]
+                        #print(Processing %s, keys %s, parent %s" % (this_cat,repr(lower_keys),repr(parent)))
+                        if len(parent)>1:
+                            raise CifError("Category %s has more than one parent: %s" % (one_cat,repr(parent)))
+                        if len(parent)==0: break
+                        parent = parent[0]
+                        parent_keys = listify(self[parent]['_category_key.name'])
+                        linked_keys = [self[l]["_name.linked_item_id"] for l in lower_keys]
+                        # sanity check
+                        if set(parent_keys) != set(linked_keys):
+                            raise CifError("Parent keys and linked keys are different! %s/%s" % (parent_keys,linked_keys))
+                            # now add in our information
+                        for parent,child in zip(linked_keys,start_keys):
+                            self.key_equivs[child] = self.key_equivs.get(child,[])+[parent]
+                        lower_keys = linked_keys  #preserves order of start keys
+
+        else:
+            self.parent_lookup = {}
+            self.key_equivs = {}
+
+    def change_category_name(self,oldname,newname):
+        self.unlock()
+        """Change the category name from [[oldname]] to [[newname]]"""
+        if oldname not in self:
+            raise KeyError('Cannot rename non-existent category %s to %s' % (oldname,newname))
+        if newname in self:
+            raise KeyError('Cannot rename %s to %s as %s already exists' % (oldname,newname,oldname))
+        child_defs = self.ddlm_immediate_children(oldname)
+        self.rename(oldname,newname)   #NB no name integrity checks
+        self[newname]['_name.object_id']=newname
+        self[newname]['_definition.id']=newname
+        for child_def in child_defs:
+            self[child_def]['_name.category_id'] = newname
+            if self[child_def].get('_definition.scope','Item')=='Item':
+                newid = self.create_catobj_name(newname,self[child_def]['_name.object_id'])
+                self[child_def]['_definition.id']=newid
+                self.rename(child_def,newid[1:])  #no underscore at the beginning
+        self.lock()
+
+    def create_catobj_name(self,cat,obj):
+        """Combine category and object in approved fashion to create id"""
+        return ('_'+cat+'.'+obj)
+
+    def change_category(self,itemname,catname):
+        """Move itemname into catname, return new handle"""
+        defid = self[itemname]
+        if defid['_name.category_id'].lower()==catname.lower():
+            print('Already in category, no change')
+            return itemname
+        if catname not in self:    #don't have it
+            print('No such category %s' % catname)
+            return itemname
+        self.unlock()
+        objid = defid['_name.object_id']
+        defid['_name.category_id'] = catname
+        newid = itemname # stays the same for categories
+        if defid.get('_definition.scope','Item') == 'Item':
+            newid = self.create_catobj_name(catname,objid)
+            defid['_definition.id']= newid
+            self.rename(itemname,newid)
+        self.set_parent(catname,newid)
+        self.lock()
+        return newid
+
+    def change_name(self,one_def,newobj):
+        """Change the object_id of one_def to newobj. This is not used for
+        categories, but can be used for dictionaries"""
+        if '_dictionary.title' not in self[one_def]:  #a dictionary block
+            newid = self.create_catobj_name(self[one_def]['_name.category_id'],newobj)
+            self.unlock()
+            self.rename(one_def,newid)
+            self[newid]['_definition.id']=newid
+            self[newid]['_name.object_id']=newobj
+        else:
+            self.unlock()
+            newid = newobj
+            self.rename(one_def,newobj)
+            self[newid]['_dictionary.title'] = newid
+        self.lock()
+        return newid
+
+    # Note that our semantic parent is given by catparent, but our syntactic parent is
+    # always just the root block
+    def add_category(self,catname,catparent=None,is_loop=True,allow_dangler=False):
+        """Add a new category to the dictionary with name [[catname]].
+           If [[catparent]] is None, the category will be a child of
+           the topmost 'Head' category or else the top data block. If
+           [[is_loop]] is false, a Set category is created. If [[allow_dangler]]
+           is true, the parent category does not have to exist."""
+        if catname in self:
+            raise CifError('Attempt to add existing category %s' % catname)
+        self.unlock()
+        syntactic_root = self.get_roots()[0][0]
+        if catparent is None:
+            semantic_root = [a for a in self.keys() if self[a].get('_definition.class',None)=='Head']
+            if len(semantic_root)>0:
+                semantic_root = semantic_root[0]
+            else:
+                semantic_root = syntactic_root
+        else:
+            semantic_root = catparent
+        realname = super(CifDic,self).NewBlock(catname,parent=syntactic_root)
+        self.block_id_table[catname.lower()]=realname
+        self[catname]['_name.object_id'] = catname
+        if not allow_dangler or catparent is None:
+            self[catname]['_name.category_id'] = self[semantic_root]['_name.object_id']
+        else:
+            self[catname]['_name.category_id'] = catparent
+        self[catname]['_definition.id'] = catname
+        self[catname]['_definition.scope'] = 'Category'
+        if is_loop:
+            self[catname]['_definition.class'] = 'Loop'
+        else:
+            self[catname]['_definition.class'] = 'Set'
+        self[catname]['_description.text'] = 'No definition provided'
+        self.lock()
+        return catname
+
+    def add_definition(self,itemname,catparent,def_text='PLEASE DEFINE ME',allow_dangler=False):
+        """Add itemname to category [[catparent]]. If itemname contains periods,
+        all text before the final period is ignored. If [[allow_dangler]] is True,
+        no check for a parent category is made."""
+        self.unlock()
+        if '.' in itemname:
+            objname = itemname.split('.')[-1]
+        else:
+            objname = itemname
+        objname = objname.strip('_')
+        if not allow_dangler and (catparent not in self or self[catparent]['_definition.scope']!='Category'):
+            raise CifError('No category %s in dictionary' % catparent)
+        fullname = '_'+catparent.lower()+'.'+objname
+        print('New name: %s' % fullname)
+        syntactic_root = self.get_roots()[0][0]
+        realname = super(CifDic,self).NewBlock(fullname, fix=False, parent=syntactic_root) #low-level change
+        # update our dictionary structures
+        self.block_id_table[fullname]=realname
+        self[fullname]['_definition.id']=fullname
+        self[fullname]['_name.object_id']=objname
+        self[fullname]['_name.category_id']=catparent
+        self[fullname]['_definition.class']='Datum'
+        self[fullname]['_description.text']=def_text
+        return realname
+
+    def remove_definition(self,defname):
+        """Remove a definition from the dictionary."""
+        if defname not in self:
+            return
+        if self[defname].get('_definition.scope')=='Category':
+            children = self.ddlm_immediate_children(defname)
+            [self.remove_definition(a) for a in children]
+            cat_id = self[defname]['_definition.id'].lower()
+        del self[defname]
+
+    def get_cat_obj(self,name):
+        """Return (cat,obj) tuple. [[name]] must contain only a single period"""
+        cat,obj = name.split('.')
+        return (cat.strip('_'),obj)
+
+    def get_name_by_cat_obj(self,category,object,give_default=False):
+        """Return the dataname corresponding to the given category and object"""
+        if category[0] == '_':    #accidentally left in
+           true_cat = category[1:].lower()
+        else:
+           true_cat = category.lower()
+        try:
+            return self.cat_obj_lookup_table[(true_cat,object.lower())][0]
+        except KeyError:
+            if give_default:
+               return '_'+true_cat+'.'+object
+        raise KeyError('No such category,object in the dictionary: %s %s' % (true_cat,object))
+
+
+    def WriteOut(self,**kwargs):
+        myblockorder = self.get_full_child_list()
+        self.set_grammar(self.grammar)
+        self.standard = 'Dic'
+        return super(CifDic,self).WriteOut(blockorder = myblockorder,**kwargs)
+
+    def get_full_child_list(self):
+        """Return a list of definition blocks in order parent-child-child-child-parent-child..."""
+        top_block = self.get_roots()[0][0]
+        root_cat = [a for a in self.keys() if self[a].get('_definition.class','Datum')=='Head']
+        if len(root_cat) == 1:
+            all_names = [top_block] + self.recurse_child_list(root_cat[0])
+            unrooted = self.ddlm_danglers()
+            double_names =  set(unrooted).intersection(set(all_names))
+            if len(double_names)>0:
+                raise CifError('Names are children of internal and external categories:%s' % repr(double_names))
+            remaining = unrooted[:]
+            for no_root in unrooted:
+                if self[no_root].get('_definition.scope','Item')=='Category':
+                    all_names += [no_root]
+                    remaining.remove(no_root)
+                    these_children = [n for n in unrooted if self[n]['_name.category_id'].lower()==no_root.lower()]
+                    all_names += these_children
+                    [remaining.remove(n) for n in these_children]
+            # now sort by category
+            ext_cats = set([self[r].get('_name.category_id',self.cat_from_name(r)).lower() for r in remaining])
+            for e in ext_cats:
+                cat_items = [r for r in remaining if self[r].get('_name.category_id',self.cat_from_name(r)).lower() == e]
+                [remaining.remove(n) for n in cat_items]
+                all_names += cat_items
+            if len(remaining)>0:
+                print('WARNING: following items do not seem to belong to a category??')
+                print(repr(remaining))
+                all_names += remaining
+            print('Final block order: ' + repr(all_names))
+            return all_names
+        raise ValueError('Dictionary contains no/multiple Head categories, please print as plain CIF instead')
+
+    def cat_from_name(self,one_name):
+        """Guess the category from the name. This should be used only when this is not important semantic information,
+        for example, when printing out"""
+        (cat,obj) = one_name.split(".")
+        if cat[0] == "_": cat = cat[1:]
+        return cat
+
+    def recurse_child_list(self,parentname):
+        """Recursively expand the logical child list of [[parentname]]"""
+        final_list = [parentname]
+        child_blocks = [a for a in self.child_table.keys() if self[a].get('_name.category_id','').lower() == parentname.lower()]
+        child_blocks.sort()    #we love alphabetical order
+        child_items = [a for a in child_blocks if self[a].get('_definition.scope','Item') == 'Item']
+        final_list += child_items
+        child_cats = [a for a in child_blocks if self[a].get('_definition.scope','Item') == 'Category']
+        for child_cat in child_cats:
+            final_list += self.recurse_child_list(child_cat)
+        return final_list
+
+
+
+    def get_key_pack(self,category,value,data):
+        keyname = self[category][self.unique_spec]
+        onepack = data.GetPackKey(keyname,value)
+        return onepack
+
+    def get_number_with_esd(numstring):
+        numb_re = '((-?(([0-9]*[.]([0-9]+))|([0-9]+)[.]?))([(][0-9]+[)])?([eEdD][+-]?[0-9]+)?)|(\\?)|(\\.)'
+        our_match = re.match(numb_re,numstring)
+        if our_match:
+            a,base_num,b,c,dad,dbd,esd,exp,q,dot = our_match.groups()
+            # print("Debug: {} -> {!r}".format(numstring, our_match.groups()))
+        else:
+            return None,None
+        if dot or q: return None,None     #a dot or question mark
+        if exp:          #has exponent
+           exp = exp.replace("d","e")     # mop up old fashioned numbers
+           exp = exp.replace("D","e")
+           base_num = base_num + exp
+        # print("Debug: have %s for base_num from %s" % (base_num,numstring))
+        base_num = float(base_num)
+        # work out esd, if present.
+        if esd:
+            esd = float(esd[1:-1])    # no brackets
+            if dad:                   # decimal point + digits
+                esd = esd * (10 ** (-1* len(dad)))
+            if exp:
+                esd = esd * (10 ** (float(exp[1:])))
+        return base_num,esd
+
+    def getmaxmin(self,rangeexp):
+        regexp = '(-?(([0-9]*[.]([0-9]+))|([0-9]+)[.]?)([eEdD][+-]?[0-9]+)?)*'
+        regexp = regexp + ":" + regexp
+        regexp = re.match(regexp,rangeexp)
+        try:
+            minimum = regexp.group(1)
+            maximum = regexp.group(7)
+        except AttributeError:
+            print("Can't match %s" % rangeexp)
+        if minimum == None: minimum = "."
+        else: minimum = float(minimum)
+        if maximum == None: maximum = "."
+        else: maximum = float(maximum)
+        return maximum,minimum
+
+    def initialise_drel(self):
+        """Parse drel functions and prepare data structures in dictionary"""
+        self.ddlm_parse_valid() #extract validity information from data block
+        self.transform_drel()   #parse the drel functions
+        self.add_drel_funcs()   #put the drel functions into the namespace
+
+    def transform_drel(self):
+        from .drel import drel_ast_yacc
+        from .drel import py_from_ast
+        import traceback
+        parser = drel_ast_yacc.parser
+        lexer = drel_ast_yacc.lexer
+        my_namespace = self.keys()
+        my_namespace = dict(zip(my_namespace,my_namespace))
+        # we provide a table of loopable categories {cat_name:((key1,key2..),[item_name,...]),...})
+        loopable_cats = self.get_loopable_cats()
+        loop_keys = [listify(self[a]["_category_key.name"]) for a in loopable_cats]
+        loop_keys = [[self[a]['_name.object_id'] for a in b] for b in loop_keys]
+        cat_names = [self.names_in_cat(a,names_only=True) for a in loopable_cats]
+        loop_info = dict(zip(loopable_cats,zip(loop_keys,cat_names)))
+        # parser.listable_items = [a for a in self.keys() if "*" in self[a].get("_type.dimension","")]
+        derivable_list = [a for a in self.keys() if "_method.expression" in self[a] \
+                              and self[a].get("_name.category_id","")!= "function"]
+        for derivable in derivable_list:
+            target_id = derivable
+            # reset the list of visible names for parser
+            special_ids = [dict(zip(self.keys(),self.keys()))]
+            print("Target id: %s" % derivable)
+            drel_exprs = self[derivable]["_method.expression"]
+            drel_purposes = self[derivable]["_method.purpose"]
+            all_methods = []
+            if not isinstance(drel_exprs,list):
+                drel_exprs = [drel_exprs]
+                drel_purposes = [drel_purposes]
+            for drel_purpose,drel_expr in zip(drel_purposes,drel_exprs):
+                if drel_purpose != 'Evaluation':
+                    continue
+                drel_expr = "\n".join(drel_expr.splitlines())
+                # print("Transforming %s" % drel_expr)
+                # List categories are treated differently...
+                try:
+                    meth_ast = parser.parse(drel_expr+"\n",lexer=lexer)
+                except:
+                    print('Syntax error in method for %s; leaving as is' % derivable)
+                    a,b = sys.exc_info()[:2]
+                    print((repr(a),repr(b)))
+                    print(traceback.print_tb(sys.exc_info()[-1],None,sys.stdout))
+                    # reset the lexer
+                    lexer.begin('INITIAL')
+                    continue
+                # Construct the python method
+                cat_meth = False
+                if self[derivable].get('_definition.scope','Item') == 'Category':
+                    cat_meth = True
+                pyth_meth = py_from_ast.make_python_function(meth_ast,"pyfunc",target_id,
+                                                                           loopable=loop_info,
+                                                             cif_dic = self,cat_meth=cat_meth)
+                all_methods.append(pyth_meth)
+            if len(all_methods)>0:
+                save_overwrite = self[derivable].overwrite
+                self[derivable].overwrite = True
+                self[derivable]["_method.py_expression"] = all_methods
+                self[derivable].overwrite = save_overwrite
+            #print("Final result:\n " + repr(self[derivable]["_method.py_expression"]))
+
+    def add_drel_funcs(self):
+        from .drel import drel_ast_yacc
+        from .drel import py_from_ast
+        funclist = [a for a in self.keys() if self[a].get("_name.category_id","")=='function']
+        funcnames = [(self[a]["_name.object_id"],
+                      getattr(self[a].GetKeyedPacket("_method.purpose","Evaluation"),"_method.expression")) for a in funclist]
+        # create executable python code...
+        parser = drel_ast_yacc.parser
+        # we provide a table of loopable categories {cat_name:(key,[item_name,...]),...})
+        loopable_cats = self.get_loopable_cats()
+        loop_keys = [listify(self[a]["_category_key.name"]) for a in loopable_cats]
+        loop_keys = [[self[a]['_name.object_id'] for a in b] for b in loop_keys]
+        cat_names = [self.names_in_cat(a,names_only=True) for a in loopable_cats]
+        loop_info = dict(zip(loopable_cats,zip(loop_keys,cat_names)))
+        for funcname,funcbody in funcnames:
+            newline_body = "\n".join(funcbody.splitlines())
+            parser.target_id = funcname
+            res_ast = parser.parse(newline_body)
+            py_function = py_from_ast.make_python_function(res_ast,None,targetname=funcname,func_def=True,loopable=loop_info,cif_dic = self)
+            #print('dREL library function ->\n' + py_function)
+            global_table = globals()
+            exec(py_function, global_table)    #add to namespace
+        #print('Globals after dREL functions added:' + repr(globals()))
+        self.ddlm_functions = globals()  #for outside access
+
+    @track_recursion
+    def derive_item(self,start_key,cifdata,store_value = False,allow_defaults=True):
+        key = start_key   #starting value
+        result = None     #success is a non-None value
+        default_result = False #we have not used a default value
+        # check for aliases
+        # check for an older form of a new value
+        found_it = [k for k in self.alias_table.get(key,[]) if k in cifdata]
+        if len(found_it)>0:
+            corrected_type = self.change_type(key,cifdata[found_it[0]])
+            return corrected_type
+        # now do the reverse check - any alternative form
+        alias_name = [a for a in self.alias_table.items() if key in a[1]]
+        print('Aliases for %s: %s' % (key,repr(alias_name)))
+        if len(alias_name)==1:
+            key = alias_name[0][0]   #actual definition name
+            if key in cifdata: return self.change_type(key,cifdata[key])
+            found_it = [k for k in alias_name[0][1] if k in cifdata]
+            if len(found_it)>0:
+                return self.change_type(key,cifdata[found_it[0]])
+        elif len(alias_name)>1:
+            raise CifError('Dictionary error: dataname alias appears in different definitions: ' + repr(alias_name))
+
+        the_category = self[key]["_name.category_id"]
+        cat_names = [a for a in self.keys() if self[a].get("_name.category_id",None)==the_category]
+        has_cat_names = [a for a in cat_names if cifdata.has_key_or_alias(a)]
+        # store any default value in case we have a problem
+        def_val = self[key].get("_enumeration.default","")
+        def_index_val = self[key].get("_enumeration.def_index_id","")
+        if len(has_cat_names)==0: # try category method
+            cat_result = {}
+            pulled_from_cats = [k for k in self.keys() if '_category_construct_local.components' in self[k]]
+            pulled_from_cats = [(k,[
+                                  self[n]['_name.category_id'] for n in self[k]['_category_construct_local.components']]
+                               ) for k in pulled_from_cats]
+            pulled_to_cats = [k[0] for k in pulled_from_cats if the_category in k[1]]
+            if '_category_construct_local.type' in self[the_category]:
+                print("**Now constructing category %s using DDLm attributes**" % the_category)
+                try:
+                    cat_result = self.construct_category(the_category,cifdata,store_value=True)
+                except (CifRecursionError,StarFile.StarDerivationError):
+                    print('** Failed to construct category %s (error)' % the_category)
+            # Trying a pull-back when the category is partially populated
+            # will not work, hence we test that cat_result has no keys
+            if len(pulled_to_cats)>0 and len(cat_result)==0:
+                print("**Now populating category %s from pulled-back category %s" % (the_category,repr(pulled_to_cats)))
+                try:
+                    cat_result = self.push_from_pullback(the_category,pulled_to_cats,cifdata,store_value=True)
+                except (CifRecursionError,StarFile.StarDerivationError):
+                    print('** Failed to construct category %s from pullback information (error)' % the_category)
+            if '_method.py_expression' in self[the_category] and key not in cat_result:
+                print("**Now applying category method for %s in search of %s**" % (the_category,key))
+                cat_result = self.derive_item(the_category,cifdata,store_value=True)
+            print("**Tried pullbacks, obtained for %s " % the_category + repr(cat_result))
+            # do we now have our value?
+            if key in cat_result:
+                return cat_result[key]
+
+        # Recalculate in case it actually worked
+        has_cat_names = [a for a in cat_names if cifdata.has_key_or_alias(a)]
+        the_funcs = self[key].get('_method.py_expression',"")
+        if the_funcs:   #attempt to calculate it
+            #global_table = globals()
+            #global_table.update(self.ddlm_functions)
+            for one_func in the_funcs:
+                print('Executing function for %s:' % key)
+                #print(one_func)
+                exec(one_func, globals())  #will access dREL functions, puts "pyfunc" in scope
+                # print('in following global environment: ' + repr(global_table))
+                stored_setting = cifdata.provide_value
+                cifdata.provide_value = True
+                try:
+                    result = pyfunc(cifdata)
+                except CifRecursionError as s:
+                    print(s)
+                    result = None
+                except StarFile.StarDerivationError as s:
+                    print(s)
+                    result = None
+                finally:
+                    cifdata.provide_value = stored_setting
+                if result is not None:
+                    break
+                #print("Function returned {!r}".format(result))
+
+        if result is None and allow_defaults:   # try defaults
+            if def_val:
+                result = self.change_type(key,def_val)
+                default_result = True
+            elif def_index_val:            #derive a default value
+                index_vals = self[key]["_enumeration_default.index"]
+                val_to_index = cifdata[def_index_val]     #what we are keying on
+                if self[def_index_val]['_type.contents'] in ['Code','Name','Tag']:
+                    lcase_comp = True
+                    index_vals = [a.lower() for a in index_vals]
+                # Handle loops
+                if isinstance(val_to_index,list):
+                    if lcase_comp:
+                        val_to_index = [a.lower() for a in val_to_index]
+                    keypos = [index_vals.index(a) for a in val_to_index]
+                    result = [self[key]["_enumeration_default.value"][a]  for a in keypos]
+                else:
+                    if lcase_comp:
+                        val_to_index = val_to_index.lower()
+                    keypos = index_vals.index(val_to_index)   #value error if no such value available
+                    result = self[key]["_enumeration_default.value"][keypos]
+                    default_result = True   #flag that it must be extended
+                result = self.change_type(key,result)
+                print("Indexed on %s to get %s for %s" % (def_index_val,repr(result),repr(val_to_index)))
+
+        # read it in
+        if result is None:   #can't do anything else
+            print('Warning: no way of deriving item %s, allow_defaults is %s' % (key,repr(allow_defaults)))
+            raise StarFile.StarDerivationError(start_key)
+        is_looped = False
+        if self[the_category].get('_definition.class','Set')=='Loop':
+            is_looped = True
+            if len(has_cat_names)>0:   #this category already exists
+                if result is None or default_result: #need to create a list of values
+                    loop_len = len(cifdata[has_cat_names[0]])
+                    out_result = [result]*loop_len
+                    result = out_result
+            else:   #nothing exists in this category, we can't store this at all
+                print('Resetting result %s for %s to null list as category is empty' % (key,result))
+                result = []
+
+        # now try to insert the new information into the right place
+        # find if items of this category already appear...
+        # Never cache empty values
+        if not (isinstance(result,list) and len(result)==0) and\
+          store_value:
+            if self[key].get("_definition.scope","Item")=='Item':
+                if is_looped:
+                    result = self.store_new_looped_value(key,cifdata,result,default_result)
+                else:
+                    result = self.store_new_unlooped_value(key,cifdata,result)
+            else:
+                self.store_new_cat_values(cifdata,result,the_category)
+        return result
+
+    def store_new_looped_value(self,key,cifdata,result,default_result):
+          """Store a looped value from the dREL system into a CifFile"""
+          # try to change any matrices etc. to lists
+          the_category = self[key]["_name.category_id"]
+          out_result = result
+          if result is not None and not default_result:
+                  # find any numpy arrays
+                  def conv_from_numpy(one_elem):
+                      if not hasattr(one_elem,'dtype'):
+                         if isinstance(one_elem,(list,tuple)):
+                            return StarFile.StarList([conv_from_numpy(a) for a in one_elem])
+                         return one_elem
+                      if one_elem.size > 1:   #so is not a float
+                         return StarFile.StarList([conv_from_numpy(a) for a in one_elem.tolist()])
+                      else:
+                          try:
+                            return one_elem.item(0)
+                          except:
+                            return one_elem
+                  out_result = [conv_from_numpy(a) for a in result]
+          # so out_result now contains a value suitable for storage
+          cat_names = [a for a in self.keys() if self[a].get("_name.category_id",None)==the_category]
+          has_cat_names = [a for a in cat_names if a in cifdata]
+          print('Adding {}, found pre-existing names: '.format(key) + repr(has_cat_names))
+          if len(has_cat_names)>0:   #this category already exists
+              cifdata[key] = out_result      #lengths must match or else!!
+              cifdata.AddLoopName(has_cat_names[0],key)
+          else:
+              cifdata[key] = out_result
+              cifdata.CreateLoop([key])
+          print('Loop info:' + repr(cifdata.loops))
+          return out_result
+
+    def store_new_unlooped_value(self,key,cifdata,result):
+          """Store a single value from the dREL system"""
+          if result is not None and hasattr(result,'dtype'):
+              if result.size > 1:
+                  out_result = StarFile.StarList(result.tolist())
+                  cifdata[key] = out_result
+              else:
+                  cifdata[key] = result.item(0)
+          else:
+              cifdata[key] = result
+          return result
+
+    def construct_category(self,category,cifdata,store_value=True):
+        """Construct a category using DDLm attributes"""
+        con_type = self[category].get('_category_construct_local.type',None)
+        if con_type == None:
+            return {}
+        if con_type == 'Pullback' or con_type == 'Filter':
+            morphisms  = self[category]['_category_construct_local.components']
+            morph_values = [cifdata[a] for a in morphisms] # the mapped values for each cat
+            cats = [self[a]['_name.category_id'] for a in morphisms]
+            cat_keys = [self[a]['_category.key_id'] for a in cats]
+            cat_values = [list(cifdata[a]) for a in cat_keys] #the category key values for each cat
+            if con_type == 'Filter':
+                int_filter = self[category].get('_category_construct_local.integer_filter',None)
+                text_filter = self[category].get('_category_construct_local.text_filter',None)
+                if int_filter is not None:
+                    morph_values.append([int(a) for a in int_filter])
+                if text_filter is not None:
+                    morph_values.append(text_filter)
+                cat_values.append(range(len(morph_values[-1])))
+            # create the mathematical product filtered by equality of dataname values
+            pullback_ids = [(x,y) for x in cat_values[0] for y in cat_values[1] \
+                            if morph_values[0][cat_values[0].index(x)]==morph_values[1][cat_values[1].index(y)]]
+            # now prepare for return
+            if len(pullback_ids)==0:
+                return {}
+            newids = self[category]['_category_construct_local.new_ids']
+            fullnewids = [self.cat_obj_lookup_table[(category,n)][0] for n in newids]
+            if con_type == 'Pullback':
+                final_results = {fullnewids[0]:[x[0] for x in pullback_ids],fullnewids[1]:[x[1] for x in pullback_ids]}
+                final_results.update(self.duplicate_datanames(cifdata,cats[0],category,key_vals = final_results[fullnewids[0]],skip_names=newids))
+                final_results.update(self.duplicate_datanames(cifdata,cats[1],category,key_vals = final_results[fullnewids[1]],skip_names=newids))
+            elif con_type == 'Filter':   #simple filter
+                final_results = {fullnewids[0]:[x[0] for x in pullback_ids]}
+                final_results.update(self.duplicate_datanames(cifdata,cats[0],category,key_vals = final_results[fullnewids[0]],skip_names=newids))
+            if store_value:
+                self.store_new_cat_values(cifdata,final_results,category)
+            return final_results
+
+    def push_from_pullback(self,target_category,source_categories,cifdata,store_value=True):
+        """Each of the categories in source_categories are pullbacks that include
+        the target_category"""
+        target_key = self[target_category]['_category.key_id']
+        result = {target_key:[]}
+        first_time = True
+        # for each source category, determine which element goes to the target
+        for sc in source_categories:
+            components = self[sc]['_category_construct_local.components']
+            comp_cats = [self[c]['_name.category_id'] for c in components]
+            new_ids = self[sc]['_category_construct_local.new_ids']
+            source_ids = [self.cat_obj_lookup_table[(sc,n)][0] for n in new_ids]
+            if len(components) == 2:  # not a filter
+                element_pos = comp_cats.index(target_category)
+                old_id = source_ids[element_pos]
+                print('Using %s to populate %s' % (old_id,target_key))
+                result[target_key].extend(cifdata[old_id])
+                # project through all identical names
+                extra_result = self.duplicate_datanames(cifdata,sc,target_category,skip_names=new_ids+[target_key])
+                # we only include keys that are common to all categories
+                if first_time:
+                    result.update(extra_result)
+                else:
+                    for k in extra_result.keys():
+                        if k in result:
+                            print('Updating %s: was %s' % (k,repr(result[k])))
+                            result[k].extend(extra_result[k])
+            else:
+                extra_result = self.duplicate_datanames(cifdata,sc,target_category,skip_names=new_ids)
+                if len(extra_result)>0 or source_ids[0] in cifdata:  #something is present
+                    result[target_key].extend(cifdata[source_ids[0]])
+                    for k in extra_result.keys():
+                        if k in result:
+                            print('Reverse filter: Updating %s: was %s' % (k,repr(result[k])))
+                            result[k].extend(extra_result[k])
+                        else:
+                            result[k]=extra_result[k]
+    # Bonus derivation if there is a singleton filter
+                    if self[sc]['_category_construct_local.type'] == 'Filter':
+                        int_filter = self[sc].get('_category_construct_local.integer_filter',None)
+                        text_filter = self[sc].get('_category_construct_local.text_filter',None)
+                        if int_filter is not None:
+                            filter_values = int_filter
+                        else:
+                            filter_values = text_filter
+                        if len(filter_values)==1:    #a singleton
+                            extra_dataname = self[sc]['_category_construct_local.components'][0]
+                            if int_filter is not None:
+                                new_value = [int(filter_values[0])] * len(cifdata[source_ids[0]])
+                            else:
+                                new_value = filter_values * len(cifdata[source_ids[0]])
+                            if extra_dataname not in result:
+                                result[extra_dataname] = new_value
+                            else:
+                                result[extra_dataname].extend(new_value)
+                    else:
+                        raise ValueError('Unexpected category construct type' + self[sc]['_category_construct_local.type'])
+            first_time = False
+        # check for sanity - all dataname lengths must be identical
+        datalen = len(set([len(a) for a in result.values()]))
+        if datalen != 1:
+            raise AssertionError('Failed to construct equal-length category items,'+ repr(result))
+        if store_value:
+            print('Now storing ' + repr(result))
+            self.store_new_cat_values(cifdata,result,target_category)
+        return result
+
+    def duplicate_datanames(self,cifdata,from_category,to_category,key_vals=None,skip_names=[]):
+        """Copy across datanames for which the from_category key equals [[key_vals]]"""
+        result = {}
+        s_names_in_cat = set(self.names_in_cat(from_category,names_only=True))
+        t_names_in_cat = set(self.names_in_cat(to_category,names_only=True))
+        can_project = s_names_in_cat & t_names_in_cat
+        can_project -= set(skip_names)  #already dealt with
+        source_key = self[from_category]['_category.key_id']
+        print('Source dataname set: ' + repr(s_names_in_cat))
+        print('Target dataname set: ' + repr(t_names_in_cat))
+        print('Projecting through following datanames from %s to %s' % (from_category,to_category) + repr(can_project))
+        for project_name in can_project:
+            full_from_name = self.cat_obj_lookup_table[(from_category.lower(),project_name.lower())][0]
+            full_to_name = self.cat_obj_lookup_table[(to_category.lower(),project_name.lower())][0]
+            if key_vals is None:
+                try:
+                    result[full_to_name] = cifdata[full_from_name]
+                except StarFile.StarDerivationError:
+                    pass
+            else:
+                all_key_vals = cifdata[source_key]
+                filter_pos = [all_key_vals.index(a) for a in key_vals]
+                try:
+                    all_data_vals = cifdata[full_from_name]
+                except StarFile.StarDerivationError:
+                    pass
+                result[full_to_name] = [all_data_vals[i] for i in filter_pos]
+        return result
+
+    def store_new_cat_values(self,cifdata,result,the_category):
+        """Store the values in [[result]] into [[cifdata]]"""
+        the_key = [a for a in result.keys() if self[a].get('_type.purpose','')=='Key']
+        double_names = [a for a in result.keys() if a in cifdata]
+        if len(double_names)>0:
+            already_present = [a for a in self.names_in_cat(the_category) if a in cifdata]
+            if set(already_present) != set(result.keys()):
+                print("Category %s not updated, mismatched datanames: %s" % (the_category, repr(set(already_present)^set(result.keys()))))
+                return
+            #check key values
+            old_keys = set(cifdata[the_key])
+            common_keys = old_keys & set(result[the_key])
+            if len(common_keys)>0:
+                print("Category %s not updated, key values in common:" % (common_keys))
+                return
+            #extend result values with old values
+            for one_name,one_value in result.items():
+                result[one_name].extend(cifdata[one_name])
+        for one_name, one_value in result.items():
+            try:
+                self.store_new_looped_value(one_name,cifdata,one_value,False)
+            except StarFile.StarError:
+                print('%s: Not replacing %s with calculated %s' % (one_name,repr(cifdata[one_name]),repr(one_value)))
+        #put the key as the first item
+        print('Fixing item order for {}'.format(repr(the_key)))
+        for one_key in the_key:  #should only be one
+            cifdata.ChangeItemOrder(one_key,0)
+
+
+    def generate_default_packet(self,catname,catkey,keyvalue):
+        """Return a StarPacket with items from ``catname`` and a key value
+        of ``keyvalue``"""
+        newpack = StarPacket()
+        for na in self.names_in_cat(catname):
+            def_val = self[na].get("_enumeration.default","")
+            if def_val:
+                final_val = self.change_type(na,def_val)
+                newpack.extend(final_val)
+                setattr(newpack,na,final_val)
+        if len(newpack)>0:
+            newpack.extend(keyvalue)
+            setattr(newpack,catkey,keyvalue)
+        return newpack
+
+
+    def switch_numpy(self,to_val):
+        pass
+
+    def change_type(self,itemname,inval):
+        if inval == "?": return inval
+        change_function = convert_type(self[itemname])
+        if isinstance(inval,list) and not isinstance(inval,StarFile.StarList):   #from a loop
+            newval = list([change_function(a) for a in inval])
+        else:
+            newval = change_function(inval)
+        return newval
+
+    def install_validation_functions(self):
+        """Install the DDL-appropriate validation checks"""
+        if self.diclang != 'DDLm':
+            # functions which check conformance
+            self.item_validation_funs = [
+                self.validate_item_type,
+                self.validate_item_esd,
+                self.validate_item_enum,
+                self.validate_enum_range,
+                self.validate_looping
+            ]
+            # functions checking loop values
+            self.loop_validation_funs = [
+                self.validate_loop_membership,
+                self.validate_loop_key,
+                self.validate_loop_references
+            ]
+            # where we need to look at other values
+            self.global_validation_funs = [
+                self.validate_exclusion,
+                self.validate_parent,
+                self.validate_child,
+                self.validate_dependents,
+                self.validate_uniqueness
+            ]
+            # where only a full block will do
+            self.block_validation_funs = [
+                self.validate_mandatory_category
+            ]
+            # removal is quicker with special checks
+            self.global_remove_validation_funs = [
+                self.validate_remove_parent_child
+            ]
+        elif self.diclang == 'DDLm':
+            self.item_validation_funs = [
+                self.validate_item_enum,
+                self.validate_item_esd_ddlm,
+                ]
+            self.loop_validation_funs = [
+                self.validate_looping_ddlm,
+                self.validate_loop_key_ddlm,
+                self.validate_loop_membership
+                ]
+            self.global_validation_funs = []
+            self.block_validation_funs = [
+                self.check_mandatory_items,
+                self.check_prohibited_items
+                ]
+            self.global_remove_validation_funs = []
+        self.optimize = False        # default value
+        self.done_parents = []
+        self.done_children = []
+        self.done_keys = []
+
+    def validate_item_type(self,item_name,item_value):
+        def mymatch(m,a):
+            res = m.match(a)
+            if res != None: return res.group()
+            else: return ""
+        target_type = self[item_name].get(self.type_spec)
+        if target_type == None:          # e.g. a category definition
+            return {"result":True}                  # not restricted in any way
+        matchexpr = self.typedic[target_type]
+        item_values = listify(item_value)
+        #for item in item_values:
+            #print("Type match " + item_name + " " + item + ":",)
+        #skip dots and question marks
+        check_all = [a for a in item_values if a !="." and a != "?"]
+        check_all = [a for a in check_all if mymatch(matchexpr,a) != a]
+        if len(check_all)>0: return {"result":False,"bad_values":check_all}
+        else: return {"result":True}
+
+    def decide(self,result_list):
+        """Construct the return list"""
+        if len(result_list)==0:
+               return {"result":True}
+        else:
+               return {"result":False,"bad_values":result_list}
+
+    def validate_item_container(self, item_name,item_value):
+        container_type = self[item_name]['_type.container']
+        item_values = listify(item_value)
+        if container_type == 'Single':
+           okcheck = [a for a in item_values if not isinstance(a,(int,float,long,unicode))]
+           return decide(okcheck)
+        if container_type in ('Multiple','List'):
+           okcheck = [a for a in item_values if not isinstance(a,StarList)]
+           return decide(okcheck)
+        if container_type == 'Array':    #A list with numerical values
+           okcheck = [a for a in item_values if not isinstance(a,StarList)]
+           first_check = decide(okcheck)
+           if not first_check['result']: return first_check
+           #num_check = [a for a in item_values if len([b for b in a if not isinstance
+
+    def validate_item_esd(self,item_name,item_value):
+        if self[item_name].get(self.primitive_type) != 'numb':
+            return {"result":None}
+        can_esd = self[item_name].get(self.esd_spec,"none") == "esd"
+        if can_esd: return {"result":True}         #must be OK!
+        item_values = listify(item_value)
+        check_all = list([a for a in item_values if get_number_with_esd(a)[1] != None])
+        if len(check_all)>0: return {"result":False,"bad_values":check_all}
+        return {"result":True}
+
+    def validate_item_esd_ddlm(self,item_name,item_value):
+        if self[item_name].get('self.primitive_type') not in \
+        ['Count','Index','Integer','Real','Imag','Complex','Binary','Hexadecimal','Octal']:
+            return {"result":None}
+        can_esd = True
+        if self[item_name].get('_type.purpose') != 'Measurand':
+            can_esd = False
+        item_values = listify(item_value)
+        check_all = [get_number_with_esd(a)[1] for a in item_values]
+        check_all = [v for v in check_all if (can_esd and v == None) or \
+                 (not can_esd and v != None)]
+        if len(check_all)>0: return {"result":False,"bad_values":check_all}
+        return {"result":True}
+
+    def validate_enum_range(self,item_name,item_value):
+        if "_item_range.minimum" not in self[item_name] and \
+           "_item_range.maximum" not in self[item_name]:
+            return {"result":None}
+        minvals = self[item_name].get("_item_range.minimum",default = ["."])
+        maxvals = self[item_name].get("_item_range.maximum",default = ["."])
+        def makefloat(a):
+            if a == ".": return a
+            else: return float(a)
+        maxvals = map(makefloat, maxvals)
+        minvals = map(makefloat, minvals)
+        rangelist = list(zip(minvals,maxvals))
+        item_values = listify(item_value)
+        def map_check(rangelist,item_value):
+            if item_value == "?" or item_value == ".": return True
+            iv,esd = get_number_with_esd(item_value)
+            if iv==None: return None  #shouldn't happen as is numb type
+            for lower,upper in rangelist:
+                #check the minima
+                if lower == ".": lower = iv - 1
+                if upper == ".": upper = iv + 1
+                if iv > lower and iv < upper: return True
+                if upper == lower and iv == upper: return True
+            # debug
+            # print("Value %s fails range check %d < x < %d" % (item_value,lower,upper))
+            return False
+        check_all = [a for a in item_values if map_check(rangelist,a) != True]
+        if len(check_all)>0: return {"result":False,"bad_values":check_all}
+        else: return {"result":True}
+
+    def validate_item_enum(self,item_name,item_value):
+        try:
+            enum_list = self[item_name][self.enum_spec][:]
+        except KeyError:
+            return {"result":None}
+        enum_list.append(".")   #default value
+        enum_list.append("?")   #unknown
+        item_values = listify(item_value)
+        #print("Enum check: {!r} in {!r}".format(item_values, enum_list))
+        check_all = [a for a in item_values if a not in enum_list]
+        if len(check_all)>0: return {"result":False,"bad_values":check_all}
+        else: return {"result":True}
+
+    def validate_looping(self,item_name,item_value):
+        try:
+            must_loop = self[item_name][self.must_loop_spec]
+        except KeyError:
+            return {"result":None}
+        if must_loop == 'yes' and isinstance(item_value,(unicode,str)): # not looped
+            return {"result":False}      #this could be triggered
+        if must_loop == 'no' and not isinstance(item_value,(unicode,str)):
+            return {"result":False}
+        return {"result":True}
+
+    def validate_looping_ddlm(self,loop_names):
+        """Check that all names are loopable"""
+        truly_loopy = self.get_final_cats(loop_names)
+        if len(truly_loopy)<len(loop_names):  #some are bad
+            categories = [(a,self[a][self.cat_spec].lower()) for a in loop_names]
+            not_looped = [a[0] for a in categories if a[1] not in self.parent_lookup.keys()]
+            return {"result":False,"bad_items":not_looped}
+        return {"result":True}
+
+
+    def validate_loop_membership(self,loop_names):
+        final_cat = self.get_final_cats(loop_names)
+        bad_items =  [a for a in final_cat if a != final_cat[0]]
+        if len(bad_items)>0:
+            return {"result":False,"bad_items":bad_items}
+        else: return {"result":True}
+
+    def get_final_cats(self,loop_names):
+        """Return a list of the uppermost parent categories for the loop_names. Names
+        that are not from loopable categories are ignored."""
+        try:
+            categories = [self[a][self.cat_spec].lower() for a in loop_names]
+        except KeyError:       #category_id is mandatory
+            raise ValidCifError( "%s missing from dictionary %s for item in loop containing %s" % (self.cat_spec,self.dicname,loop_names[0]))
+        truly_looped = [a for a in categories if a in self.parent_lookup.keys()]
+        return [self.parent_lookup[a] for a in truly_looped]
+
+    def validate_loop_key(self,loop_names):
+        category = self[loop_names[0]][self.cat_spec]
+        # find any unique values which must be present
+        key_spec = self[category].get(self.key_spec,[])
+        for names_to_check in key_spec:
+            if isinstance(names_to_check,unicode):   #only one
+                names_to_check = [names_to_check]
+            for loop_key in names_to_check:
+                if loop_key not in loop_names:
+                    #is this one of those dang implicit items?
+                    if self[loop_key].get(self.must_exist_spec,None) == "implicit":
+                        continue          #it is virtually there...
+                    alternates = self.get_alternates(loop_key)
+                    if alternates == []:
+                        return {"result":False,"bad_items":loop_key}
+                    for alt_names in alternates:
+                        alt = [a for a in alt_names if a in loop_names]
+                        if len(alt) == 0:
+                            return {"result":False,"bad_items":loop_key}  # no alternates
+        return {"result":True}
+
+    def validate_loop_key_ddlm(self,loop_names):
+        """Make sure at least one of the necessary keys are available"""
+        final_cats = self.get_final_cats(loop_names)
+        if len(final_cats)>0:
+            poss_keys = self.cat_key_table[final_cats[0]][0] # 
+            found_keys = [a for a in poss_keys if a in loop_names]
+            if len(found_keys)>0:
+                return {"result":True}
+            else:
+                return {"result":False,"bad_items":poss_keys}
+        else:
+            return {"result":True}
+
+    def validate_loop_references(self,loop_names):
+        must_haves = [self[a].get(self.list_ref_spec,None) for a in loop_names]
+        must_haves = [a for a in must_haves if a != None]
+        # build a flat list.  For efficiency we don't remove duplicates,as
+        # we expect no more than the order of 10 or 20 looped names.
+        def flat_func(a,b):
+            if isinstance(b,unicode):
+               a.append(b)       #single name
+            else:
+               a.extend(b)       #list of names
+            return a
+        flat_mh = []
+        [flat_func(flat_mh,a) for a in must_haves]
+        group_mh = filter(lambda a:a[-1]=="_",flat_mh)
+        single_mh = filter(lambda a:a[-1]!="_",flat_mh)
+        res = [a for a in single_mh if a not in loop_names]
+        def check_gr(s_item, name_list):
+            nl = map(lambda a:a[:len(s_item)],name_list)
+            if s_item in nl: return True
+            return False
+        res_g = [a for a in group_mh if check_gr(a,loop_names)]
+        if len(res) == 0 and len(res_g) == 0: return {"result":True}
+        # construct alternate list
+        alternates = map(lambda a: (a,self.get_alternates(a)),res)
+        alternates = [a for a in alternates if a[1] != []]
+        # next line purely for error reporting
+        missing_alts = [a[0] for a in alternates if a[1] == []]
+        if len(alternates) != len(res):
+           return {"result":False,"bad_items":missing_alts}   #short cut; at least one
+                                                       #doesn't have an altern
+        #loop over alternates
+        for orig_name,alt_names in alternates:
+             alt = [a for a in alt_names if a in loop_names]
+             if len(alt) == 0: return {"result":False,"bad_items":orig_name}# no alternates
+        return {"result":True}        #found alternates
+
+    def get_alternates(self,main_name,exclusive_only=False):
+        alternates = self[main_name].get(self.related_func,None)
+        alt_names = []
+        if alternates != None:
+            alt_names =  self[main_name].get(self.related_item,None)
+            if isinstance(alt_names,unicode):
+                alt_names = [alt_names]
+                alternates = [alternates]
+            together = zip(alt_names,alternates)
+            if exclusive_only:
+                alt_names = [a for a in together if a[1]=="alternate_exclusive" \
+                                             or a[1]=="replace"]
+            else:
+                alt_names = [a for a in together if a[1]=="alternate" or a[1]=="replace"]
+            alt_names = list([a[0] for a in alt_names])
+        # now do the alias thing
+        alias_names = listify(self[main_name].get("_item_aliases.alias_name",[]))
+        alt_names.extend(alias_names)
+        # print("Alternates for {}: {!r}".format(main_name, alt_names))
+        return alt_names
+
+
+    def validate_exclusion(self,item_name,item_value,whole_block,provisional_items={},globals={}):
+       alternates = [a.lower() for a in self.get_alternates(item_name,exclusive_only=True)]
+       item_name_list = [a.lower() for a in whole_block.keys()]
+       item_name_list.extend([a.lower() for a in provisional_items.keys()])
+       bad = [a for a in alternates if a in item_name_list]
+       if len(bad)>0:
+           print("Bad: %s, alternates %s" % (repr(bad),repr(alternates)))
+           return {"result":False,"bad_items":bad}
+       else: return {"result":True}
+
+    # validate that parent exists and contains matching values
+    def validate_parent(self,item_name,item_value,whole_block,provisional_items={},globals={}):
+        parent_item = self[item_name].get(self.parent_spec)
+        if not parent_item: return {"result":None}   #no parent specified
+        if isinstance(parent_item,list):
+            parent_item = parent_item[0]
+        if self.optimize:
+            if parent_item in self.done_parents:
+                return {"result":None}
+            else:
+                self.done_parents.append(parent_item)
+                print("Done parents %s" % repr(self.done_parents))
+        # initialise parent/child values
+        if isinstance(item_value,unicode):
+            child_values = [item_value]
+        else: child_values = item_value[:]    #copy for safety
+        # track down the parent
+        # print("Looking for {} parent item {} in {!r}".format(item_name, parent_item, whole_block))
+        # if globals contains the parent values, we are doing a DDL2 dictionary, and so
+        # we have collected all parent values into the global block - so no need to search
+        # for them elsewhere.
+        # print("Looking for {!r}".format(parent_item))
+        parent_values = globals.get(parent_item)
+        if not parent_values:
+            parent_values = provisional_items.get(parent_item,whole_block.get(parent_item))
+        if not parent_values:
+            # go for alternates
+            namespace = whole_block.keys()
+            namespace.extend(provisional_items.keys())
+            namespace.extend(globals.keys())
+            alt_names = filter_present(self.get_alternates(parent_item),namespace)
+            if len(alt_names) == 0:
+                if len([a for a in child_values if a != "." and a != "?"])>0:
+                    return {"result":False,"parent":parent_item}#no parent available -> error
+                else:
+                    return {"result":None}       #maybe True is more appropriate??
+            parent_item = alt_names[0]           #should never be more than one??
+            parent_values = provisional_items.get(parent_item,whole_block.get(parent_item))
+            if not parent_values:   # check global block
+                parent_values = globals.get(parent_item)
+        if isinstance(parent_values,unicode):
+            parent_values = [parent_values]
+        #print("Checking parent %s against %s, values %r/%r" % (parent_item,
+        #                                          item_name, parent_values, child_values))
+        missing = self.check_parent_child(parent_values,child_values)
+        if len(missing) > 0:
+            return {"result":False,"bad_values":missing,"parent":parent_item}
+        return {"result":True}
+
+    def validate_child(self,item_name,item_value,whole_block,provisional_items={},globals={}):
+        try:
+            child_items = self[item_name][self.child_spec][:]  #copy
+        except KeyError:
+            return {"result":None}    #not relevant
+        # special case for dictionaries  -> we check parents of children only
+        if item_name in globals:  #dictionary so skip
+            return {"result":None}
+        if isinstance(child_items,unicode): # only one child
+            child_items = [child_items]
+        if isinstance(item_value,unicode): # single value
+            parent_values = [item_value]
+        else: parent_values = item_value[:]
+        # expand child list with list of alternates
+        for child_item in child_items[:]:
+            child_items.extend(self.get_alternates(child_item))
+        # now loop over the children
+        for child_item in child_items:
+            if self.optimize:
+                if child_item in self.done_children:
+                    return {"result":None}
+                else:
+                    self.done_children.append(child_item)
+                    print("Done children %s" % repr(self.done_children))
+            if child_item in provisional_items:
+                child_values = provisional_items[child_item][:]
+            elif child_item in whole_block:
+                child_values = whole_block[child_item][:]
+            else:  continue
+            if isinstance(child_values,unicode):
+                child_values = [child_values]
+                # print("Checking child %s against %s, values %r/%r" % (child_item,
+                #       item_name, child_values, parent_values))
+            missing = self.check_parent_child(parent_values,child_values)
+            if len(missing)>0:
+                return {"result":False,"bad_values":missing,"child":child_item}
+        return {"result":True}       #could mean that no child items present
+
+    #a generic checker: all child vals should appear in parent_vals
+    def check_parent_child(self,parent_vals,child_vals):
+        # shield ourselves from dots and question marks
+        pv = parent_vals[:]
+        pv.extend([".","?"])
+        res =  [a for a in child_vals if a not in pv]
+        #print("Missing: %s" % res)
+        return res
+
+    def validate_remove_parent_child(self,item_name,whole_block):
+        try:
+            child_items = self[item_name][self.child_spec]
+        except KeyError:
+            return {"result":None}
+        if isinstance(child_items,unicode): # only one child
+            child_items = [child_items]
+        for child_item in child_items:
+            if child_item in whole_block:
+                return {"result":False,"child":child_item}
+        return {"result":True}
+
+    def validate_dependents(self,item_name,item_value,whole_block,prov={},globals={}):
+        try:
+            dep_items = self[item_name][self.dep_spec][:]
+        except KeyError:
+            return {"result":None}    #not relevant
+        if isinstance(dep_items,unicode):
+            dep_items = [dep_items]
+        actual_names = whole_block.keys()
+        actual_names.extend(prov.keys())
+        actual_names.extend(globals.keys())
+        missing = [a for a in dep_items if a not in actual_names]
+        if len(missing) > 0:
+            alternates = map(lambda a:[self.get_alternates(a),a],missing)
+            # compact way to get a list of alternative items which are
+            # present
+            have_check = [(filter_present(b[0],actual_names),
+                                       b[1]) for b in alternates]
+            have_check = list([a for a in have_check if len(a[0])==0])
+            if len(have_check) > 0:
+                have_check = [a[1] for a in have_check]
+                return {"result":False,"bad_items":have_check}
+        return {"result":True}
+
+    def validate_uniqueness(self,item_name,item_value,whole_block,provisional_items={},
+                                                                  globals={}):
+        category = self[item_name].get(self.cat_spec)
+        if category == None:
+            print("No category found for %s" % item_name)
+            return {"result":None}
+        # print("Category {!r} for item {}".format(category, item_name))
+        # we make a copy in the following as we will be removing stuff later!
+        unique_i = self[category].get("_category_key.name",[])[:]
+        if isinstance(unique_i,unicode):
+            unique_i = [unique_i]
+        if item_name not in unique_i:       #no need to verify
+            return {"result":None}
+        if isinstance(item_value,unicode):  #not looped
+            return {"result":None}
+        # print("Checking %s -> %s -> %s ->Unique: %r" % (item_name,category,catentry, unique_i))
+        # check that we can't optimize by not doing this check
+        if self.optimize:
+            if unique_i in self.done_keys:
+                return {"result":None}
+            else:
+                self.done_keys.append(unique_i)
+        val_list = []
+        # get the matching data from any other data items
+        unique_i.remove(item_name)
+        other_data = []
+        if len(unique_i) > 0:            # i.e. do have others to think about
+           for other_name in unique_i:
+           # we look for the value first in the provisional dict, then the main block
+           # the logic being that anything in the provisional dict overrides the
+           # main block
+               if other_name in provisional_items:
+                   other_data.append(provisional_items[other_name])
+               elif other_name in whole_block:
+                   other_data.append(whole_block[other_name])
+               elif self[other_name].get(self.must_exist_spec)=="implicit":
+                   other_data.append([item_name]*len(item_value))  #placeholder
+               else:
+                   return {"result":False,"bad_items":other_name}#missing data name
+        # ok, so we go through all of our values
+        # this works by comparing lists of strings to one other, and
+        # so could be fooled if you think that '1.' and '1' are
+        # identical
+        for i in range(len(item_value)):
+            #print("Value no. %d" % i, end=" ")
+            this_entry = item_value[i]
+            for j in range(len(other_data)):
+                this_entry = " ".join([this_entry,other_data[j][i]])
+            #print("Looking for {!r} in {!r}: ".format(this_entry, val_list))
+            if this_entry in val_list:
+                return {"result":False,"bad_values":this_entry}
+            val_list.append(this_entry)
+        return {"result":True}
+
+
+    def validate_mandatory_category(self,whole_block):
+        mand_cats = [self[a]['_category.id'] for a in self.keys() if self[a].get("_category.mandatory_code","no")=="yes"]
+        if len(mand_cats) == 0:
+            return {"result":True}
+        # print("Mandatory categories - {!r}".format(mand_cats)
+        # find which categories each of our datanames belongs to
+        all_cats = [self[a].get(self.cat_spec) for a in whole_block.keys()]
+        missing = set(mand_cats) - set(all_cats)
+        if len(missing) > 0:
+            return {"result":False,"bad_items":repr(missing)}
+        return {"result":True}
+
+    def check_mandatory_items(self,whole_block,default_scope='Item'):
+        """Return an error if any mandatory items are missing"""
+        if len(self.scopes_mandatory)== 0: return {"result":True}
+        if default_scope == 'Datablock':
+            return {"result":True}     #is a data file
+        scope = whole_block.get('_definition.scope',default_scope)
+        if '_dictionary.title' in whole_block:
+           scope = 'Dictionary'
+        missing = list([a for a in self.scopes_mandatory[scope] if a not in whole_block])
+        if len(missing)==0:
+            return {"result":True}
+        else:
+            return {"result":False,"bad_items":missing}
+
+    def check_prohibited_items(self,whole_block,default_scope='Item'):
+        """Return an error if any prohibited items are present"""
+        if len(self.scopes_naughty)== 0: return {"result":True}
+        if default_scope == 'Datablock':
+            return {"result":True}     #is a data file
+        scope = whole_block.get('_definition.scope',default_scope)
+        if '_dictionary.title' in whole_block:
+           scope = 'Dictionary'
+        present = list([a for a in self.scopes_naughty[scope] if a in whole_block])
+        if len(present)==0:
+            return {"result":True}
+        else:
+            return {"result":False,"bad_items":present}
+
+
+    def run_item_validation(self,item_name,item_value):
+        return {item_name:list([(f.__name__,f(item_name,item_value)) for f in self.item_validation_funs])}
+
+    def run_loop_validation(self,loop_names):
+        return {loop_names[0]:list([(f.__name__,f(loop_names)) for f in self.loop_validation_funs])}
+
+    def run_global_validation(self,item_name,item_value,data_block,provisional_items={},globals={}):
+        results = list([(f.__name__,f(item_name,item_value,data_block,provisional_items,globals)) for f in self.global_validation_funs])
+        return {item_name:results}
+
+    def run_block_validation(self,whole_block,block_scope='Item'):
+        results = list([(f.__name__,f(whole_block)) for f in self.block_validation_funs])
+        # fix up the return values
+        return {"whole_block":results}
+
+    def optimize_on(self):
+        self.optimize = True
+        self.done_keys = []
+        self.done_children = []
+        self.done_parents = []
+
+    def optimize_off(self):
+        self.optimize = False
+        self.done_keys = []
+        self.done_children = []
+        self.done_parents = []
+
+
+
+class ValidCifBlock(CifBlock):
+    """A `CifBlock` that is valid with respect to a given CIF dictionary.  Methods
+    of `CifBlock` are overridden where necessary to disallow addition of invalid items to the
+    `CifBlock`.
+
+    ## Initialisation
+
+    * `dic` is a `CifDic` object to be used for validation.
+
+    """
+    def __init__(self,dic = None, diclist=[], mergemode = "replace",*args,**kwords):
+        CifBlock.__init__(self,*args,**kwords)
+        if dic and diclist:
+            print("Warning: diclist argument ignored when initialising ValidCifBlock")
+        if isinstance(dic,CifDic):
+            self.fulldic = dic
+        else:
+            raise TypeError( "ValidCifBlock passed non-CifDic type in dic argument")
+        if len(diclist)==0 and not dic:
+            raise ValidCifError( "At least one dictionary must be specified")
+        if diclist and not dic:
+            self.fulldic = merge_dic(diclist,mergemode)
+        if not self.run_data_checks()[0]:
+            raise ValidCifError( self.report())
+
+    def run_data_checks(self,verbose=False):
+        self.v_result = {}
+        self.fulldic.optimize_on()
+        for dataname in self.keys():
+            update_value(self.v_result,self.fulldic.run_item_validation(dataname,self[dataname]))
+            update_value(self.v_result,self.fulldic.run_global_validation(dataname,self[dataname],self))
+        for loop_names in self.loops.values():
+            update_value(self.v_result,self.fulldic.run_loop_validation(loop_names))
+        # now run block-level checks
+        update_value(self.v_result,self.fulldic.run_block_validation(self))
+        # return false and list of baddies if anything didn't match
+        self.fulldic.optimize_off()
+        all_keys = list(self.v_result.keys()) #dictionary will change
+        for test_key in all_keys:
+            #print("%s: %r" % (test_key, self.v_result[test_key]))
+            self.v_result[test_key] = [a for a in self.v_result[test_key] if a[1]["result"]==False]
+            if len(self.v_result[test_key]) == 0:
+                del self.v_result[test_key]
+        isvalid = len(self.v_result)==0
+        #if not isvalid:
+        #    print("Baddies: {!r}".format(self.v_result))
+        return isvalid,self.v_result
+
+    def single_item_check(self,item_name,item_value):
+        #self.match_single_item(item_name)
+        if item_name not in self.fulldic:
+            result = {item_name:[]}
+        else:
+            result = self.fulldic.run_item_validation(item_name,item_value)
+        baddies = list([a for a in result[item_name] if a[1]["result"]==False])
+        # if even one false one is found, this should trigger
+        isvalid = (len(baddies) == 0)
+        # if not isvalid: print("Failures for {}: {!r}".format(item_name, baddies))
+        return isvalid,baddies
+
+    def loop_item_check(self,loop_names):
+        in_dic_names = list([a for a in loop_names if a in self.fulldic])
+        if len(in_dic_names)==0:
+            result = {loop_names[0]:[]}
+        else:
+            result = self.fulldic.run_loop_validation(in_dic_names)
+        baddies = list([a for a in result[in_dic_names[0]] if a[1]["result"]==False])
+        # if even one false one is found, this should trigger
+        isvalid = (len(baddies) == 0)
+        # if not isvalid: print("Failures for {}: {!r}".format(loop_names, baddies))
+        return isvalid,baddies
+
+    def global_item_check(self,item_name,item_value,provisional_items={}):
+        if item_name not in self.fulldic:
+            result = {item_name:[]}
+        else:
+            result = self.fulldic.run_global_validation(item_name,
+               item_value,self,provisional_items = provisional_items)
+        baddies = list([a for a in result[item_name] if a[1]["result"] is False])
+        # if even one false one is found, this should trigger
+        isvalid = (len(baddies) == 0)
+        # if not isvalid: print("Failures for {}: {!r}".format(item_name, baddies))
+        return isvalid,baddies
+
+    def remove_global_item_check(self,item_name):
+        if item_name not in self.fulldic:
+            result = {item_name:[]}
+        else:
+            result = self.fulldic.run_remove_global_validation(item_name,self,False)
+        baddies = list([a for a in result[item_name] if a[1]["result"]==False])
+        # if even one false one is found, this should trigger
+        isvalid = (len(baddies) == 0)
+        # if not isvalid: print("Failures for {}: {!r}".format(item_name, baddies))
+        return isvalid,baddies
+
+    def AddToLoop(self,dataname,loopdata):
+        # single item checks
+        paired_data = loopdata.items()
+        for name,value in paired_data:
+            valid,problems = self.single_item_check(name,value)
+            self.report_if_invalid(valid,problems)
+        # loop item checks; merge with current loop
+        found = 0
+        for aloop in self.block["loops"]:
+            if dataname in aloop:
+                loopnames = aloop.keys()
+                for new_name in loopdata.keys():
+                    if new_name not in loopnames: loopnames.append(new_name)
+                valid,problems = self.looped_item_check(loopnames)
+                self.report_if_invalid(valid,problems)
+        prov_dict = loopdata.copy()
+        for name,value in paired_data:
+            del prov_dict[name]   # remove temporarily
+            valid,problems = self.global_item_check(name,value,prov_dict)
+            prov_dict[name] = value  # add back in
+            self.report_if_invalid(valid,problems)
+        CifBlock.AddToLoop(self,dataname,loopdata)
+
+    def AddCifItem(self,data):
+        if isinstance(data[0],(unicode,str)):   # single item
+            valid,problems = self.single_item_check(data[0],data[1])
+            self.report_if_invalid(valid,problems,data[0])
+            valid,problems = self.global_item_check(data[0],data[1])
+            self.report_if_invalid(valid,problems,data[0])
+        elif isinstance(data[0],tuple) or isinstance(data[0],list):
+            paired_data = list(zip(data[0],data[1]))
+            for name,value in paired_data:
+                valid,problems = self.single_item_check(name,value)
+                self.report_if_invalid(valid,problems,name)
+            valid,problems = self.loop_item_check(data[0])
+            self.report_if_invalid(valid,problems,data[0])
+            prov_dict = {}            # for storing temporary items
+            for name,value in paired_data: prov_dict[name]=value
+            for name,value in paired_data:
+                del prov_dict[name]   # remove temporarily
+                valid,problems = self.global_item_check(name,value,prov_dict)
+                prov_dict[name] = value  # add back in
+                self.report_if_invalid(valid,problems,name)
+        else:
+            raise ValueError("Programming error: AddCifItem passed non-tuple,non-string item")
+        super(ValidCifBlock,self).AddCifItem(data)
+
+    def AddItem(self,key,value,**kwargs):
+        """Set value of dataname `key` to `value` after checking for conformance with CIF dictionary"""
+        valid,problems = self.single_item_check(key,value)
+        self.report_if_invalid(valid,problems,key)
+        valid,problems = self.global_item_check(key,value)
+        self.report_if_invalid(valid,problems,key)
+        super(ValidCifBlock,self).AddItem(key,value,**kwargs)
+
+    # utility function
+    def report_if_invalid(self,valid,bad_list,data_name):
+        if not valid:
+            bad_tests = [a[0] for a in bad_list]
+            error_string = ",".join(bad_tests)
+            error_string = repr(data_name) + " fails following validity checks: "  + error_string
+            raise ValidCifError( error_string)
+
+    def __delitem__(self,key):
+        # we don't need to run single item checks; we do need to run loop and
+        # global checks.
+        if key in self:
+            try:
+                loop_items = self.GetLoop(key)
+            except TypeError:
+                loop_items = []
+            if loop_items:             #need to check loop conformance
+                loop_names = [a[0] for a in loop_items if a[0] != key]
+                valid,problems = self.loop_item_check(loop_names)
+                self.report_if_invalid(valid,problems)
+            valid,problems = self.remove_global_item_check(key)
+            self.report_if_invalid(valid,problems)
+        self.RemoveCifItem(key)
+
+
+    def report(self):
+       outstr = StringIO()
+       outstr.write( "Validation results\n")
+       outstr.write( "------------------\n")
+       print("%d invalid items found\n" % len(self.v_result))
+       for item_name,val_func_list in self.v_result.items():
+           outstr.write("%s fails following tests:\n" % item_name)
+           for val_func in val_func_list:
+               outstr.write("\t%s\n")
+       return outstr.getvalue()
+
+
+class ValidCifFile(CifFile):
+    """A CIF file for which all datablocks are valid.  Argument `dic` to
+    initialisation specifies a `CifDic` object to use for validation."""
+    def __init__(self,dic=None,diclist=[],mergemode="replace",*args,**kwargs):
+        print("WARNING: ValidCifFile will be removed in the next release.")
+        if not diclist and not dic and not hasattr(self,'bigdic'):
+            raise ValidCifError( "At least one dictionary is required to create a ValidCifFile object")
+        if not dic and diclist:     #merge here for speed
+            self.bigdic = merge_dic(diclist,mergemode)
+        elif dic and not diclist:
+            self.bigdic = dic
+        emapsCifFile.__init__(self,*args,**kwargs)
+        for blockname in self.keys():
+            self.dictionary[blockname]=ValidCifBlock(data=self.dictionary[blockname],dic=self.bigdic)
+
+    def NewBlock(self,blockname,blockcontents,**kwargs):
+        emapsCifFile.NewBlock(self,blockname,blockcontents,**kwargs)
+        # dictionary[blockname] is now a CifBlock object.  We
+        # turn it into a ValidCifBlock object
+        self.dictionary[blockname] = ValidCifBlock(dic=self.bigdic,
+                                         data=self.dictionary[blockname])
+
+
+class ValidationResult:
+    """Represents validation result. It is initialised with """
+    def __init__(self,results):
+        """results is return value of validate function"""
+        self.valid_result, self.no_matches = results
+
+    def report(self,use_html):
+        """Return string with human-readable description of validation result"""
+        return validate_report((self.valid_result, self.no_matches),use_html)
+
+    def is_valid(self,block_name=None):
+        """Return True for valid CIF file, otherwise False"""
+        if block_name is not None:
+            block_names = [block_name]
+        else:
+            block_names = self.valid_result.iterkeys()
+        for block_name in block_names:
+            if not self.valid_result[block_name] == (True,{}):
+                valid = False
+                break
+            else:
+                valid = True
+        return valid
+
+    def has_no_match_items(self,block_name=None):
+        """Return true if some items are not found in dictionary"""
+        if block_name is not None:
+            block_names = [block_name]
+        else:
+            block_names = self.no_matches.iter_keys()
+        for block_name in block_names:
+            if self.no_matches[block_name]:
+                has_no_match_items = True
+                break
+            else:
+                has_no_match_items = False
+        return has_no_match_items
+
+
+
+def Validate(ciffile,dic = "", diclist=[],mergemode="replace",isdic=False):
+    """Validate the `ciffile` conforms to the definitions in `CifDic` object `dic`, or if `dic` is missing,
+    to the results of merging the `CifDic` objects in `diclist` according to `mergemode`.  Flag
+    `isdic` indicates that `ciffile` is a CIF dictionary meaning that save frames should be
+    accessed for validation and that mandatory_category should be interpreted differently for DDL2."""
+    if not isinstance(ciffile,CifFile):
+        check_file = CifFile(ciffile)
+    else:
+        check_file = ciffile
+    if not dic:
+        fulldic = merge_dic(diclist,mergemode)
+    else:
+        fulldic = dic
+    no_matches = {}
+    valid_result = {}
+    if isdic:          #assume one block only
+        check_file.scoping = 'instance' #only data blocks visible
+        top_level = check_file.keys()[0]
+        check_file.scoping = 'dictionary'   #all blocks visible
+        # collect a list of parents for speed
+        if fulldic.diclang == 'DDL2':
+            poss_parents = fulldic.get_all("_item_linked.parent_name")
+            for parent in poss_parents:
+                curr_parent = listify(check_file.get(parent,[]))
+                new_vals = check_file.get_all(parent)
+                new_vals.extend(curr_parent)
+                if len(new_vals)>0:
+                    check_file[parent] = new_vals
+                print("Added %s (len %d)" % (parent,len(check_file[parent])))
+    # now run the validations
+    for block in check_file.keys():
+        if isdic and block == top_level:
+           block_scope = 'Dictionary'
+        elif isdic:
+           block_scope = 'Item'
+        else:
+           block_scope = 'Datablock'
+        no_matches[block] = [a for a in check_file[block].keys() if a not in fulldic]
+        # remove non-matching items
+        print("Not matched: " + repr(no_matches[block]))
+        for nogood in no_matches[block]:
+             del check_file[block][nogood]
+        print("Validating block %s, scope %s" % (block,block_scope))
+        valid_result[block] = run_data_checks(check_file[block],fulldic,block_scope=block_scope)
+    return valid_result,no_matches
+
+def validate_report(val_result,use_html=False):
+    valid_result,no_matches = val_result
+    outstr = StringIO()
+    if use_html:
+        outstr.write("<h2>Validation results</h2>")
+    else:
+        outstr.write( "Validation results\n")
+        outstr.write( "------------------\n")
+    if len(valid_result) > 10:
+        suppress_valid = True         #don't clutter with valid messages
+        if use_html:
+           outstr.write("<p>For brevity, valid blocks are not reported in the output.</p>")
+    else:
+        suppress_valid = False
+    for block in valid_result.keys():
+        block_result = valid_result[block]
+        if block_result[0]:
+            out_line = "Block '%s' is VALID" % block
+        else:
+            out_line = "Block '%s' is INVALID" % block
+        if use_html:
+            if (block_result[0] and (not suppress_valid or len(no_matches[block])>0)) or not block_result[0]:
+                outstr.write( "<h3>%s</h3><p>" % out_line)
+        else:
+                outstr.write( "\n %s\n" % out_line)
+        if len(no_matches[block])!= 0:
+            if use_html:
+                outstr.write( "<p>The following items were not found in the dictionary")
+                outstr.write(" (note that this does not invalidate the data block):</p>")
+                outstr.write("<p><table>\n")
+                [outstr.write("<tr><td>%s</td></tr>" % it) for it in no_matches[block]]
+                outstr.write("</table>\n")
+            else:
+                outstr.write( "\n The following items were not found in the dictionary:\n")
+                outstr.write("Note that this does not invalidate the data block\n")
+                [outstr.write("%s\n" % it) for it in no_matches[block]]
+        # now organise our results by type of error, not data item...
+        error_type_dic = {}
+        for error_item, error_list in block_result[1].items():
+            for func_name,bad_result in error_list:
+                bad_result.update({"item_name":error_item})
+                try:
+                    error_type_dic[func_name].append(bad_result)
+                except KeyError:
+                    error_type_dic[func_name] = [bad_result]
+        # make a table of test name, test message
+        info_table = {\
+        'validate_item_type':\
+            "The following data items had badly formed values",
+        'validate_item_esd':\
+            "The following data items should not have esds appended",
+        'validate_enum_range':\
+            "The following data items have values outside permitted range",
+        'validate_item_enum':\
+            "The following data items have values outside permitted set",
+        'validate_looping':\
+            "The following data items violate looping constraints",
+        'validate_loop_membership':\
+            "The following looped data names are of different categories to the first looped data name",
+        'validate_loop_key':\
+            "A required dataname for this category is missing from the loop\n containing the dataname",
+        'validate_loop_key_ddlm':\
+            "A loop key is missing for the category containing the dataname",
+        'validate_loop_references':\
+            "A dataname required by the item is missing from the loop",
+        'validate_parent':\
+            "A parent dataname is missing or contains different values",
+        'validate_child':\
+            "A child dataname contains different values to the parent",
+        'validate_uniqueness':\
+            "One or more data items do not take unique values",
+        'validate_dependents':\
+            "A dataname required by the item is missing from the data block",
+        'validate_exclusion': \
+            "Both dataname and exclusive alternates or aliases are present in data block",
+        'validate_mandatory_category':\
+            "A required category is missing from this block",
+        'check_mandatory_items':\
+            "A required data attribute is missing from this block",
+        'check_prohibited_items':\
+            "A prohibited data attribute is present in this block"}
+
+        for test_name,test_results in error_type_dic.items():
+           if use_html:
+               outstr.write(html_error_report(test_name,info_table[test_name],test_results))
+           else:
+               outstr.write(error_report(test_name,info_table[test_name],test_results))
+               outstr.write("\n\n")
+    return outstr.getvalue()
+
+# A function to lay out a single error report.  We are passed
+# the name of the error (one of our validation functions), the
+# explanation to print out, and a dictionary with the error
+# information.  We print no more than 50 characters of the item
+
+def error_report(error_name,error_explanation,error_dics):
+   retstring = "\n\n " + error_explanation + ":\n\n"
+   headstring = "%-32s" % "Item name"
+   bodystring = ""
+   if "bad_values" in error_dics[0]:
+      headstring += "%-20s" % "Bad value(s)"
+   if "bad_items" in error_dics[0]:
+      headstring += "%-20s" % "Bad dataname(s)"
+   if "child" in error_dics[0]:
+      headstring += "%-20s" % "Child"
+   if "parent" in error_dics[0]:
+      headstring += "%-20s" % "Parent"
+   headstring +="\n"
+   for error in error_dics:
+      bodystring += "\n%-32s" % error["item_name"]
+      if "bad_values" in error:
+          out_vals = [repr(a)[:50] for a in error["bad_values"]]
+          bodystring += "%-20s" % out_vals
+      if "bad_items" in error:
+          bodystring += "%-20s" % repr(error["bad_items"])
+      if "child" in error:
+          bodystring += "%-20s" % repr(error["child"])
+      if "parent" in error:
+          bodystring += "%-20s" % repr(error["parent"])
+   return retstring + headstring + bodystring
+
+#  This lays out an HTML error report
+
+def html_error_report(error_name,error_explanation,error_dics,annotate=[]):
+   retstring = "<h4>" + error_explanation + ":</h4>"
+   retstring = retstring + "<table cellpadding=5><tr>"
+   headstring = "<th>Item name</th>"
+   bodystring = ""
+   if "bad_values" in error_dics[0]:
+      headstring += "<th>Bad value(s)</th>"
+   if "bad_items" in error_dics[0]:
+      headstring += "<th>Bad dataname(s)</th>"
+   if "child" in error_dics[0]:
+      headstring += "<th>Child</th>"
+   if "parent" in error_dics[0]:
+      headstring += "<th>Parent</th>"
+   headstring +="</tr>\n"
+   for error in error_dics:
+      bodystring += "<tr><td><tt>%s</tt></td>" % error["item_name"]
+      if "bad_values" in error:
+          bodystring += "<td>%s</td>" % error["bad_values"]
+      if "bad_items" in error:
+          bodystring += "<td><tt>%s</tt></td>" % error["bad_items"]
+      if "child" in error:
+          bodystring += "<td><tt>%s</tt></td>" % error["child"]
+      if "parent" in error:
+          bodystring += "<td><tt>%s</tt></td>" % error["parent"]
+      bodystring += "</tr>\n"
+   return retstring + headstring + bodystring + "</table>\n"
+
+def run_data_checks(check_block,fulldic,block_scope='Item'):
+    v_result = {}
+    for key in check_block.keys():
+        update_value(v_result, fulldic.run_item_validation(key,check_block[key]))
+        update_value(v_result, fulldic.run_global_validation(key,check_block[key],check_block))
+    for loopnames in check_block.loops.values():
+        update_value(v_result, fulldic.run_loop_validation(loopnames))
+    update_value(v_result,fulldic.run_block_validation(check_block,block_scope=block_scope))
+    # return false and list of baddies if anything didn't match
+    all_keys = list(v_result.keys())
+    for test_key in all_keys:
+        v_result[test_key] = [a for a in v_result[test_key] if a[1]["result"]==False]
+        if len(v_result[test_key]) == 0:
+            del v_result[test_key]
+    # if even one false one is found, this should trigger
+    # print("Baddies: {!r}".format(v_result))
+    isvalid = len(v_result)==0
+    return isvalid,v_result
+
+
+def get_number_with_esd(numstring):
+    numb_re = '((-?(([0-9]*[.]([0-9]+))|([0-9]+)[.]?))([(][0-9]+[)])?([eEdD][+-]?[0-9]+)?)|(\\?)|(\\.)'
+    our_match = re.match(numb_re,numstring)
+    if our_match:
+        a,base_num,b,c,dad,dbd,esd,exp,q,dot = our_match.groups()
+        # print("Debug: {} -> {!r}".format(numstring, our_match.groups()))
+    else:
+        return None,None
+    if dot or q: return None,None     #a dot or question mark
+    if exp:          #has exponent
+       exp = exp.replace("d","e")     # mop up old fashioned numbers
+       exp = exp.replace("D","e")
+       base_num = base_num + exp
+    # print("Debug: have %s for base_num from %s" % (base_num,numstring))
+    base_num = float(base_num)
+    # work out esd, if present.
+    if esd:
+        esd = float(esd[1:-1])    # no brackets
+        if dad:                   # decimal point + digits
+            esd = esd * (10 ** (-1* len(dad)))
+        if exp:
+            esd = esd * (10 ** (float(exp[1:])))
+    return base_num,esd
+
+def float_with_esd(inval):
+    if isinstance(inval,unicode):
+        j = inval.find("(")
+        if j>=0:  return float(inval[:j])
+    return float(inval)
+
+
+
+def convert_type(definition):
+    """Convert value to have the type given by definition"""
+    #extract the actual required type information
+    container = definition['_type.container']
+    dimension = definition.get('_type.dimension',StarFile.StarList([]))
+    structure = interpret_structure(definition['_type.contents'])
+    if container == 'Single':   #a single value to convert
+        return convert_single_value(structure)
+    elif container == 'List':   #lots of the same value
+        return convert_list_values(structure,dimension)
+    elif container == 'Multiple': #no idea
+        return None
+    elif container in ('Array','Matrix'): #numpy array
+        return convert_matrix_values(structure)
+    return lambda a:a    #unable to convert
+
+def convert_single_value(type_spec):
+    """Convert a single item according to type_spec"""
+    if type_spec == 'Real':
+        return float_with_esd
+    if type_spec in ('Count','Integer','Index','Binary','Hexadecimal','Octal'):
+        return int
+    if type_spec == 'Complex':
+        return complex
+    if type_spec == 'Imag':
+        return lambda a:complex(0,a)
+    if type_spec in ('Code','Name','Tag'):  #case-insensitive -> lowercase
+        return lambda a:a.lower()
+    return lambda a:a   #can't do anything numeric
+
+class convert_simple_list(object):
+
+    """\
+    Callable object that converts values in a simple list according
+    to the specified element structure.
+    """
+
+    def __init__(self, structure):
+        self.converters = [convert_single_value(tp) for tp in structure]
+        return
+
+    def __call__(self, element):
+        if len(element) != len(self.converters):
+            emsg = "Expected iterable of %i values, got %i." % (
+                (len(self.converters), len(element)))
+            raise ValueError(emsg)
+        rv = [f(e) for f, e in zip(self.converters, element)]
+        return rv
+
+# End of class convert_single_value
+
+def convert_list_values(structure, dimension):
+    """Convert the values according to the element
+       structure given in [[structure]]"""
+    # simple repetition
+    if isinstance(structure, (unicode, str)):
+        fcnv = convert_single_value(structure)
+    # assume structure is a list of types
+    else:
+        fcnv = convert_simple_list(structure)
+    rv = fcnv
+    # setup nested conversion function when dimension differs from 1.
+    if len(dimension) > 0 and int(dimension[0]) != 1:
+        rv = lambda args : [fcnv(a) for a in args]
+    return rv
+
+def convert_matrix_values(valtype):
+    """Convert a dREL String or Float valued List structure to a numpy matrix structure"""
+    # first convert to numpy array, then let numpy do the work
+    try:
+        import numpy
+    except ImportError:
+        return lambda a:a   #cannot do it
+    if valtype == 'Real':
+        dtype = float
+    elif valtype == 'Integer':
+        dtype = int
+    elif valtype == 'Complex':
+        dtype = complex
+    else:
+        raise ValueError('Unknown matrix value type')
+    fcnv = lambda a : numpy.asarray(a, dtype=dtype)
+    return fcnv
+
+def interpret_structure(struc_spec):
+    """Interpret a DDLm structure specification"""
+    from . import TypeContentsParser as t
+    p = t.TypeParser(t.TypeParserScanner(struc_spec))
+    return getattr(p,"input")()
+
+
+# A utility function to append to item values rather than replace them
+def update_value(base_dict,new_items):
+    for new_key in new_items.keys():
+        if new_key in base_dict:
+            base_dict[new_key].extend(new_items[new_key])
+        else:
+            base_dict[new_key] = new_items[new_key]
+
+#Transpose the list of lists passed to us
+def transpose(base_list):
+    new_lofl = []
+    full_length = len(base_list)
+    opt_range = range(full_length)
+    for i in range(len(base_list[0])):
+       new_packet = []
+       for j in opt_range:
+          new_packet.append(base_list[j][i])
+       new_lofl.append(new_packet)
+    return new_lofl
+
+# listify strings - used surprisingly often
+def listify(item):
+    if isinstance(item,(unicode,str)): return [item]
+    else: return item
+
+# given a list of search items, return a list of items
+# actually contained in the given data block
+def filter_present(namelist,datablocknames):
+    return [a for a in namelist if a in datablocknames]
+
+# Make an item immutable, used if we want a list to be a key
+def make_immutable(values):
+    """Turn list of StarList values into a list of immutable items"""
+    if not isinstance(values[0],StarList):
+        return values
+    else:
+        return [tuple(a) for a in values]
+
+# merge ddl dictionaries.  We should be passed filenames or CifFile
+# objects
+def merge_dic(diclist,mergemode="replace",ddlspec=None):
+    dic_as_cif_list = []
+    for dic in diclist:
+        if not isinstance(dic,CifFile) and \
+           not isinstance(dic,(unicode,str)):
+               raise TypeError("Require list of CifFile names/objects for dictionary merging")
+        if not isinstance(dic,CifFile): dic_as_cif_list.append(CifFile(dic))
+        else: dic_as_cif_list.append(dic)
+    # we now merge left to right
+    basedic = dic_as_cif_list[0]
+    if "on_this_dictionary" in basedic:   #DDL1 style only
+        for dic in dic_as_cif_list[1:]:
+           basedic.merge(dic,mode=mergemode,match_att=["_name"])
+    elif len(basedic.keys()) == 1:                     #One block: DDL2/m style
+        old_block = basedic[basedic.keys()[0]]
+        for dic in dic_as_cif_list[1:]:
+           new_block = dic[dic.keys()[0]]
+           basedic.merge(dic,mode=mergemode,
+                         single_block=[basedic.keys()[0],dic.keys()[0]],
+                         match_att=["_item.name"],match_function=find_parent)
+    return CifDic(basedic)
+
+def find_parent(ddl2_def):
+    if "_item.name" not in ddl2_def:
+       return None
+    if isinstance(ddl2_def["_item.name"],unicode):
+        return ddl2_def["_item.name"]
+    if "_item_linked.child_name" not in ddl2_def:
+        raise CifError("Asked to find parent in block with no child_names")
+    if "_item_linked.parent_name" not in ddl2_def:
+        raise CifError("Asked to find parent in block with no parent_names")
+    result = list([a for a in ddl2_def["_item.name"] if a not in ddl2_def["_item_linked.child_name"]])
+    if len(result)>1 or len(result)==0:
+        raise CifError("Unable to find single unique parent data item")
+    return result[0]
+
+
+def ReadCif(filename,grammar='auto',scantype='standard',scoping='instance',standard='CIF',
+            permissive=False):
+    """ Read in a CIF file, returning a `CifFile` object.
+
+    * `filename` may be a URL, a file
+    path on the local system, or any object with a `read` method.
+
+    * `grammar` chooses the CIF grammar variant. `1.0` is the original 1992 grammar and `1.1`
+    is identical except for the exclusion of square brackets as the first characters in
+    undelimited datanames. `2.0` will read files in the CIF2.0 standard, and `STAR2` will
+    read files according to the STAR2 publication.  If grammar is `None`, autodetection
+    will be attempted in the order `2.0`, `1.1` and `1.0`. This will always succeed for
+    properly-formed CIF2.0 files.  Note that only Unicode characters in the basic multilingual
+    plane are recognised (this will be fixed when PyCIFRW is ported to Python 3).
+
+    * `scantype` can be `standard` or `flex`.  `standard` provides pure Python parsing at the
+    cost of a factor of 10 or so in speed.  `flex` will tokenise the input CIF file using
+    fast C routines, but is not available for CIF2/STAR2 files.  Note that running PyCIFRW in
+    Jython uses native Java regular expressions
+    to provide a speedup regardless of this argument (and does not yet support CIF2).
+
+    * `scoping` is only relevant where nested save frames are expected (STAR2 only).
+    `instance` scoping makes nested save frames
+    invisible outside their hierarchy, allowing duplicate save frame names in separate
+    hierarchies. `dictionary` scoping makes all save frames within a data block visible to each
+    other, thereby restricting all save frames to have unique names.
+    Currently the only recognised value for `standard` is `CIF`, which when set enforces a
+    maximum length of 75 characters for datanames and has no other effect. """
+
+    finalcif = CifFile(scoping=scoping,standard=standard)
+    return StarFile.ReadStar(filename,prepared=finalcif,grammar=grammar,scantype=scantype,
+                             permissive=permissive)
+    #return StarFile.StarFile(filename,maxlength,scantype=scantype,grammar=grammar,**kwargs)
+
+class CifLoopBlock(StarFile.LoopBlock):
+    def __init__(self,data=(),**kwargs):
+        super(CifLoopBlock,self).__init__(data,**kwargs)
+
+#No documentation flags
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/StarFile.py` & `pyemaps-1.0.9/CifFile/src/StarFile.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,2496 +1,2496 @@
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-__copyright = """
-PYCIFRW License Agreement (Python License, Version 2)
------------------------------------------------------
-
-1. This LICENSE AGREEMENT is between the Australian Nuclear Science
-and Technology Organisation ("ANSTO"), and the Individual or
-Organization ("Licensee") accessing and otherwise using this software
-("PyCIFRW") in source or binary form and its associated documentation.
-
-2. Subject to the terms and conditions of this License Agreement,
-ANSTO hereby grants Licensee a nonexclusive, royalty-free, world-wide
-license to reproduce, analyze, test, perform and/or display publicly,
-prepare derivative works, distribute, and otherwise use PyCIFRW alone
-or in any derivative version, provided, however, that this License
-Agreement and ANSTO's notice of copyright, i.e., "Copyright (c)
-2001-2014 ANSTO; All Rights Reserved" are retained in PyCIFRW alone or
-in any derivative version prepared by Licensee.
-
-3. In the event Licensee prepares a derivative work that is based on
-or incorporates PyCIFRW or any part thereof, and wants to make the
-derivative work available to others as provided herein, then Licensee
-hereby agrees to include in any such work a brief summary of the
-changes made to PyCIFRW.
-
-4. ANSTO is making PyCIFRW available to Licensee on an "AS IS"
-basis. ANSTO MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
-IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, ANSTO MAKES NO AND
-DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
-FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYCIFRW WILL NOT
-INFRINGE ANY THIRD PARTY RIGHTS.
-
-5. ANSTO SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYCIFRW
-FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A
-RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYCIFRW, OR ANY
-DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
-
-6. This License Agreement will automatically terminate upon a material
-breach of its terms and conditions.
-
-7. Nothing in this License Agreement shall be deemed to create any
-relationship of agency, partnership, or joint venture between ANSTO
-and Licensee. This License Agreement does not grant permission to use
-ANSTO trademarks or trade name in a trademark sense to endorse or
-promote products or services of Licensee, or any third party.
-
-8. By copying, installing or otherwise using PyCIFRW, Licensee agrees
-to be bound by the terms and conditions of this License Agreement.
-
-"""
-
-
-import sys
-
-# Python 2,3 compatibility
-try:
-    from urllib import urlopen         # for arbitrary opening
-    from urlparse import urlparse, urlunparse
-except:
-    from urllib.request import urlopen
-    from urllib.parse import urlparse,urlunparse
-import re,os
-import textwrap
-
-try:
-    from StringIO import StringIO #not cStringIO as we cannot subclass
-except ImportError:
-    from io import StringIO
-
-if isinstance(u"abc",str):   #Python 3
-    unicode = str
-    long = int
-
-try:
-    import numpy
-    have_numpy = True
-except ImportError:
-    have_numpy = False
-
-# Windows paths require special handling. pathlib is available from
-# Python 3.4. For earlier Python versions dictionary import will not work
-# on Windows
-try:
-    from pathlib import Path
-    have_pathlib = True
-except:
-    have_pathlib = False
-
-class StarList(list):
-    def __getitem__(self,args):
-        if isinstance(args,(int,slice)):
-            return super(StarList,self).__getitem__(args)
-        elif isinstance(args,tuple) and len(args)>1:   #extended comma notation
-            return super(StarList,self).__getitem__(args[0]).__getitem__(args[1:])
-        else:
-            return super(StarList,self).__getitem__(args[0])
-
-    def __str__(self):
-        return "SL("+super(StarList,self).__str__() + ")"
-
-class StarDict(dict):
-    pass
-
-
-class LoopBlock(object):
-    def __init__(self,parent_block,dataname):
-        self.loop_no = parent_block.FindLoop(dataname)
-        if self.loop_no < 0:
-            raise KeyError('%s is not in a loop structure' % dataname)
-        self.parent_block = parent_block
-
-    def keys(self):
-        return self.parent_block.loops[self.loop_no]
-
-    def values(self):
-        return [self.parent_block[a] for a in self.keys()]
-
-    #Avoid iterator even though that is Python3-esque
-    def items(self):
-        return list(zip(self.keys(),self.values()))
-
-    def __getitem__(self,dataname):
-        if isinstance(dataname,int):   #a packet request
-            return self.GetPacket(dataname)
-        if dataname in self.keys():
-            return self.parent_block[dataname]
-        else:
-            raise KeyError('%s not in loop block' % dataname)
-
-    def __setitem__(self,dataname,value):
-        self.parent_block[dataname] = value
-        self.parent_block.AddLoopName(self.keys()[0],dataname)
-
-    def __contains__(self,key):
-        return key in self.parent_block.loops[self.loop_no]
-
-    def has_key(self,key):
-        return key in self
-
-    def __iter__(self):
-        packet_list = zip(*self.values())
-        names = self.keys()
-        for p in packet_list:
-            r = StarPacket(p)
-            for n in range(len(names)):
-                setattr(r,names[n].lower(),r[n])
-            yield r
-
-    # for compatibility
-    def __getattr__(self,attname):
-        return getattr(self.parent_block,attname)
-
-    def load_iter(self,coords=[]):
-        count = 0        #to create packet index
-        while not self.popout:
-            # ok, we have a new packet:  append a list to our subloops
-            for aloop in self.loops:
-                aloop.new_enclosing_packet()
-            for iname in self.item_order:
-                if isinstance(iname,LoopBlock):       #into a nested loop
-                    for subitems in iname.load_iter(coords=coords+[count]):
-                        # print 'Yielding %s' % `subitems`
-                        yield subitems
-                    # print 'End of internal loop'
-                else:
-                    if self.dimension == 0:
-                        # print 'Yielding %s' % `self[iname]`
-                        yield self,self[iname]
-                    else:
-                        backval = self.block[iname]
-                        for i in range(len(coords)):
-                           # print 'backval, coords: %s, %s' % (`backval`,`coords`)
-                           backval = backval[coords[i]]
-                        yield self,backval
-            count = count + 1      # count packets
-        self.popout = False        # reinitialise
-        # print 'Finished iterating'
-        yield self,'###Blank###'     #this value should never be used
-
-    # an experimental fast iterator for level-1 loops (ie CIF)
-    def fast_load_iter(self):
-        targets = map(lambda a:self.block[a],self.item_order)
-        while targets:
-            for target in targets:
-                yield self,target
-
-    # Add another list of the required shape to take into account a new outer packet
-    def new_enclosing_packet(self):
-        if self.dimension > 1:      #otherwise have a top-level list
-            for iname in self.keys():  #includes lower levels
-                target_list = self[iname]
-                for i in range(3,self.dimension): #dim 2 upwards are lists of lists of...
-                    target_list = target_list[-1]
-                target_list.append([])
-                # print '%s now %s' % (iname,`self[iname]`)
-
-    def recursive_iter(self,dict_so_far={},coord=[]):
-        # print "Recursive iter: coord %s, keys %s, dim %d" % (`coord`,`self.block.keys()`,self.dimension)
-        my_length = 0
-        top_items = self.block.items()
-        top_values = self.block.values()       #same order as items
-        drill_values = self.block.values()
-        for dimup in range(0,self.dimension):  #look higher in the tree
-            if len(drill_values)>0:            #this block has values
-                drill_values=drill_values[0]   #drill in
-            else:
-                raise StarError("Malformed loop packet %s" % repr( top_items[0] ))
-        my_length = len(drill_values[0])       #length of 'string' entry
-        if self.dimension == 0:                #top level
-            for aloop in self.loops:
-                for apacket in aloop.recursive_iter():
-                    # print "Recursive yielding %s" % repr( dict(top_items + apacket.items()) )
-                    prep_yield = StarPacket(top_values+apacket.values())  #straight list
-                    for name,value in top_items + apacket.items():
-                        setattr(prep_yield,name,value)
-                    yield prep_yield
-        else:                                  #in some loop
-            for i in range(my_length):
-                kvpairs = map(lambda a:(a,self.coord_to_group(a,coord)[i]),self.block.keys())
-                kvvals = map(lambda a:a[1],kvpairs)   #just values
-                # print "Recursive kvpairs at %d: %s" % (i,repr( kvpairs ))
-                if self.loops:
-                  for aloop in self.loops:
-                    for apacket in aloop.recursive_iter(coord=coord+[i]):
-                        # print "Recursive yielding %s" % repr( dict(kvpairs + apacket.items()) )
-                        prep_yield = StarPacket(kvvals+apacket.values())
-                        for name,value in kvpairs + apacket.items():
-                            setattr(prep_yield,name,value)
-                        yield prep_yield
-                else:           # we're at the bottom of the tree
-                    # print "Recursive yielding %s" % repr( dict(kvpairs) )
-                    prep_yield = StarPacket(kvvals)
-                    for name,value in kvpairs:
-                        setattr(prep_yield,name,value)
-                    yield prep_yield
-
-    # small function to use the coordinates.
-    def coord_to_group(self,dataname,coords):
-          if not isinstance(dataname,unicode):
-             return dataname     # flag inner loop processing
-          newm = self[dataname]          # newm must be a list or tuple
-          for c in coords:
-              # print "Coord_to_group: %s ->" % (repr( newm )),
-              newm = newm[c]
-              # print repr( newm )
-          return newm
-
-    def flat_iterator(self):
-            my_length = 0
-            top_keys = self.block.keys()
-            if len(top_keys)>0:
-                my_length = len(self.block[top_keys[0]])
-            for pack_no in range(my_length):
-                yield(self.collapse(pack_no))
-
-
-    def RemoveItem(self,itemname):
-        """Remove `itemname` from the block."""
-        # first check any loops
-        loop_no = self.FindLoop(itemname)
-        testkey = itemname.lower()
-        if testkey in self:
-            del self.block[testkey]
-            del self.true_case[testkey]
-            # now remove from loop
-            if loop_no >= 0:
-                self.loops[loop_no].remove(testkey)
-                if len(self.loops[loop_no])==0:
-                    del self.loops[loop_no]
-                    self.item_order.remove(loop_no)
-            else:  #will appear in order list
-                self.item_order.remove(testkey)
-
-    def RemoveLoopItem(self,itemname):
-        """*Deprecated*. Use `RemoveItem` instead"""
-        self.RemoveItem(itemname)
-
-    def GetLoop(self,keyname):
-        """Return a `StarFile.LoopBlock` object constructed from the loop containing `keyname`.
-        `keyname` is only significant as a way to specify the loop."""
-        return LoopBlock(self,keyname)
-
-    def GetPacket(self,index):
-        thispack = StarPacket([])
-        for myitem in self.parent_block.loops[self.loop_no]:
-            thispack.append(self[myitem][index])
-            setattr(thispack,myitem,thispack[-1])
-        return thispack
-
-    def AddPacket(self,packet):
-        for myitem in self.parent_block.loops[self.loop_no]:
-            old_values = self.parent_block[myitem]
-            old_values.append(packet.__getattribute__(myitem))
-            self.parent_block[myitem] = old_values
-
-    def GetItemOrder(self):
-        """Return a list of datanames in this `LoopBlock` in the order that they will be
-        printed"""
-        return self.parent_block.loops[self.loop_no][:]
-
-
-    def ChangeItemOrder(self,itemname,newpos):
-        """Change the position at which `itemname` appears when printing out to `newpos`."""
-        self.parent_block.loops[self.loop_no].remove(itemname.lower())
-        self.parent_block.loops[self.loop_no].insert(newpos,itemname.lower())
-
-    def GetItemPosition(self,itemname):
-        """A utility function to get the numerical order in the printout
-        of `itemname`.  An item has coordinate `(loop_no,pos)` with
-        the top level having a `loop_no` of -1.  If an integer is passed to
-        the routine then it will return the position of the loop
-        referenced by that number."""
-        if isinstance(itemname,int):
-            # return loop position
-            return (-1, self.item_order.index(itemname))
-        if not itemname in self:
-            raise ValueError('No such dataname %s' % itemname)
-        testname = itemname.lower()
-        if testname in self.item_order:
-            return (-1,self.item_order.index(testname))
-        loop_no = self.FindLoop(testname)
-        loop_pos = self.loops[loop_no].index(testname)
-        return loop_no,loop_pos
-
-    def GetLoopNames(self,keyname):
-        if keyname in self:
-            return self.keys()
-        for aloop in self.loops:
-            try:
-                return aloop.GetLoopNames(keyname)
-            except KeyError:
-                pass
-        raise KeyError('Item does not exist')
-
-    def GetLoopNames(self,keyname):
-        """Return all datanames appearing together with `keyname`"""
-        loop_no = self.FindLoop(keyname)
-        if loop_no >= 0:
-            return self.loops[loop_no]
-        else:
-            raise KeyError('%s is not in any loop' % keyname)
-
-    def AddToLoop(self,dataname,loopdata):
-        thisloop = self.GetLoop(dataname)
-        for itemname,itemvalue in loopdata.items():
-            thisloop[itemname] = itemvalue
-
-    def AddToLoop(self,dataname,loopdata):
-        """*Deprecated*. Use `AddItem` followed by calls to `AddLoopName`.
-
-        Add multiple columns to the loop containing `dataname`. `loopdata` is a
-        collection of (key,value) pairs, where `key` is the new dataname and `value`
-        is a list of values for that dataname"""
-        self.update(loopdata)
-        for one_name in loopdata:
-            self.AddLoopName(dataname,one_name)
-
-
-class StarBlock(object):
-    def __init__(self,data = (), maxoutlength=2048, wraplength=80, overwrite=True,
-                 characterset='ascii',maxnamelength=-1):
-        self.block = {}    #the actual data storage (lower case keys)
-        self.loops = {}    #each loop is indexed by a number and contains a list of datanames
-        self.item_order = []  #lower case, loops referenced by integer
-        self.formatting_hints = {}
-        self.true_case = {} #transform lower case to supplied case
-        self.provide_value = False  #prefer string version always
-        self.dictionary = None      #DDLm dictionary
-        self.popout = False         #used during load iteration
-        self.curitem = -1           #used during iteration
-        self.cache_vals = True      #store all calculated values
-        self.maxoutlength = maxoutlength
-        self.setmaxnamelength(maxnamelength)  #to enforce CIF limit of 75 characters
-        self.set_characterset(characterset)   #to check input names
-        self.wraplength = wraplength
-        self.overwrite = overwrite
-        self.string_delimiters = ["'",'"',"\n;"]   #universal CIF set
-        self.list_delimiter = "  "                 #CIF2 default
-        self.wrapper = textwrap.TextWrapper()
-        if isinstance(data,(tuple,list)):
-            for item in data:
-                self.AddLoopItem(item)
-        elif isinstance(data,StarBlock):
-            self.block = data.block.copy()
-            self.item_order = data.item_order[:]
-            self.true_case = data.true_case.copy()
-            # loops as well
-            self.loops = data.loops.copy()
-
-    def setmaxnamelength(self,maxlength):
-        """Set the maximum allowable dataname length (-1 for no check)"""
-        self.maxnamelength = maxlength
-        if maxlength > 0:
-            bad_names = [a for a in self.keys() if len(a)>self.maxnamelength]
-            if len(bad_names)>0:
-                raise StarError('Datanames too long: ' + repr( bad_names ))
-
-    def set_characterset(self,characterset):
-        """Set the characterset for checking datanames: may be `ascii` or `unicode`"""
-        self.characterset = characterset
-        if characterset == 'ascii':
-            self.char_check = re.compile("[][ \n\r\t!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~\"#$';_-]+",re.M)
-        elif characterset == 'unicode':
-            if sys.maxunicode < 1114111:
-               self.char_check = re.compile(u"[][ \n\r\t!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~\"#$';_\u00A0-\uD7FF\uE000-\uFDCF\uFDF0-\uFFFD-]+",re.M)
-            else:
-               self.char_check = re.compile(u"[][ \n\r\t!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~\"#$';_\u00A0-\uD7FF\uE000-\uFDCF\uFDF0-\uFFFD\U00010000-\U0010FFFD-]+",re.M)
-
-    def __str__(self):
-        return self.printsection()
-
-    def __setitem__(self,key,value):
-        if key == "saves":
-            raise StarError("""Setting the saves key is deprecated. Add the save block to
-    an enclosing block collection (e.g. CIF or STAR file) with this block as child""")
-        self.AddItem(key,value)
-
-    def __getitem__(self,key):
-        if key == "saves":
-            raise StarError("""The saves key is deprecated. Access the save block from
-    the enclosing block collection (e.g. CIF or STAR file object)""")
-        try:
-           rawitem,is_value = self.GetFullItemValue(key)
-        except KeyError:
-           if self.dictionary:
-               # send the dictionary the required key and a pointer to us
-               try:
-                   new_value = self.dictionary.derive_item(key,self,store_value=self.cache_vals,allow_defaults=False)
-               except StarDerivationFailure:   #try now with defaults included
-                   try:
-                       new_value = self.dictionary.derive_item(key,self,store_value=self.cache_vals,allow_defaults=True)
-                   except StarDerivationFailure as s:
-                       print("In StarBlock.__getitem__, " + repr(s))
-                       raise KeyError('No such item: %s' % key)
-               print('Set %s to derived value %s' % (key, repr(new_value)))
-               return new_value
-           else:
-               raise KeyError('No such item: %s' % key)
-        # we now have an item, we can try to convert it to a number if that is appropriate
-        # note numpy values are never stored but are converted to lists
-        if not self.dictionary or not key in self.dictionary: return rawitem
-        print('%s: is_value %s provide_value %s value %s' % (key,repr( is_value ),repr( self.provide_value ),repr( rawitem )))
-        if is_value:
-            if self.provide_value: return rawitem
-            else:
-               print('Turning %s into string' % repr( rawitem ))
-               return self.convert_to_string(key)
-        else:    # a string
-            if self.provide_value and ((not isinstance(rawitem,list) and rawitem != '?' and rawitem != ".") or \
-                                      (isinstance(rawitem,list) and '?' not in rawitem and '.' not in rawitem)):
-                return self.dictionary.change_type(key,rawitem)
-            elif self.provide_value: # catch the question marks
-                do_calculate = False
-                if isinstance(rawitem,(list,tuple)):
-                    known = [a for a in rawitem if a != '?']
-                    if len(known) == 0:   #all questions
-                        do_calculate = True
-                elif rawitem == '?':
-                        do_calculate = True
-                if do_calculate:
-                   # remove old value
-                   del self[key]
-                   try:
-                       new_value = self.dictionary.derive_item(key,self,store_value=True,allow_defaults=False)
-                   except StarDerivationFailure as s:
-                       try:
-                           new_value = self.dictionary.derive_item(key,self,store_value=True,allow_defaults=True)
-                       except StarDerivationFailure as s:
-
-                           print("Could not turn %s into a value:" + repr(s))
-                           return rawitem
-                   else:
-                       print('Set %s to derived value %s' % (key, repr( new_value )))
-                       return new_value
-            return rawitem   #can't do anything
-
-    def __delitem__(self,key):
-        self.RemoveItem(key)
-
-    def __len__(self):
-        blen = len(self.block)
-        return blen
-
-    def __nonzero__(self):
-        if self.__len__() > 0: return 1
-        return 0
-
-    # keys returns all internal keys
-    def keys(self):
-        return list(self.block.keys())    #always lower case
-
-    def values(self):
-        return [self[a] for a in self.keys()]
-
-    def items(self):
-        return list(zip(self.keys(),self.values()))
-
-    def __contains__(self,key):
-        if isinstance(key,(unicode,str)) and key.lower() in self.keys():
-            return True
-        return False
-
-    def has_key(self,key):
-        return key in self
-
-    def has_key_or_alias(self,key):
-        """Check if a dataname or alias is available in the block"""
-        initial_test = key in self
-        if initial_test: return True
-        elif self.dictionary:
-            aliases = [k for k in self.dictionary.alias_table.get(key,[]) if self.has_key(k)]
-            if len(aliases)>0:
-               return True
-        return False
-
-    def get(self,key,default=None):
-        if key in self:
-            retval = self.__getitem__(key)
-        else:
-            retval = default
-        return retval
-
-    def clear(self):
-        self.block = {}
-        self.loops = {}
-        self.item_order = []
-        self.true_case = {}
-
-    # doesn't appear to work
-    def copy(self):
-        newcopy = StarBlock()
-        newcopy.block = self.block.copy()
-        newcopy.loops = []
-        newcopy.item_order = self.item_order[:]
-        newcopy.true_case = self.true_case.copy()
-        newcopy.loops = self.loops.copy()
-    #    return self.copy.im_class(newcopy)   #catch inheritance
-        return newcopy
-
-    def update(self,adict):
-        for key in adict.keys():
-            self.AddItem(key,adict[key])
-
-    def GetItemPosition(self,itemname):
-        """A utility function to get the numerical order in the printout
-        of `itemname`.  An item has coordinate `(loop_no,pos)` with
-        the top level having a `loop_no` of -1.  If an integer is passed to
-        the routine then it will return the position of the loop
-        referenced by that number."""
-        if isinstance(itemname,int):
-            # return loop position
-            return (-1, self.item_order.index(itemname))
-        if not itemname in self:
-            raise ValueError('No such dataname %s' % itemname)
-        testname = itemname.lower()
-        if testname in self.item_order:
-            return (-1,self.item_order.index(testname))
-        loop_no = self.FindLoop(testname)
-        loop_pos = self.loops[loop_no].index(testname)
-        return loop_no,loop_pos
-
-    def ChangeItemOrder(self,itemname,newpos):
-        """Move the printout order of `itemname` to `newpos`. If `itemname` is
-        in a loop, `newpos` refers to the order within the loop."""
-        if isinstance(itemname,(unicode,str)):
-            true_name = itemname.lower()
-        else:
-            true_name = itemname
-        loopno = self.FindLoop(true_name)
-        if loopno < 0:  #top level
-            self.item_order.remove(true_name)
-            self.item_order.insert(newpos,true_name)
-        else:
-            self.loops[loopno].remove(true_name)
-            self.loops[loopno].insert(newpos,true_name)
-
-    def GetItemOrder(self):
-        """Return a list of datanames in the order in which they will be printed.  Loops are
-        referred to by numerical index"""
-        return self.item_order[:]
-
-    def AddItem(self,key,value,precheck=False):
-        """Add dataname `key` to block with value `value`.  `value` may be
-        a single value, a list or a tuple. If `precheck` is False (the default),
-        all values will be checked and converted to unicode strings as necessary. If
-        `precheck` is True, this checking is bypassed.  No checking is necessary
-        when values are read from a CIF file as they are already in correct form."""
-        if not isinstance(key,(unicode,str)):
-             raise TypeError('Star datanames are strings only (got %s)' % repr( key ))
-        key = unicode(key)    #everything is unicode internally
-        if not precheck:
-             self.check_data_name(key,self.maxnamelength)    # make sure no nasty characters
-        # check for overwriting
-        if key in self:
-             if not self.overwrite:
-                 raise StarError( 'Attempt to insert duplicate item name %s' % key)
-        if not precheck:   #need to sanitise
-            regval,empty_val = self.regularise_data(value)
-            pure_string = check_stringiness(regval)
-            self.check_item_value(regval)
-        else:
-            regval,empty_val = value,None
-            pure_string = True
-        # update ancillary information first
-        lower_key = key.lower()
-        if not lower_key in self and self.FindLoop(lower_key)<0:      #need to add to order
-            self.item_order.append(lower_key)
-        # always remove from our case table in case the case is different
-        try:
-            del self.true_case[lower_key]
-        except KeyError:
-            pass
-        self.true_case[lower_key] = key
-        if pure_string:
-            self.block.update({lower_key:[regval,empty_val]})
-        else:
-            self.block.update({lower_key:[empty_val,regval]})
-
-    def AddLoopItem(self,incomingdata,precheck=False,maxlength=-1):
-        """*Deprecated*. Use `AddItem` followed by `CreateLoop` if
-        necessary."""
-        # print "Received data %s" % `incomingdata`
-        # we accept tuples, strings, lists and dicts!!
-        # Direct insertion: we have a string-valued key, with an array
-        # of values -> single-item into our loop
-        if isinstance(incomingdata[0],(tuple,list)):
-           # a whole loop
-           keyvallist = zip(incomingdata[0],incomingdata[1])
-           for key,value in keyvallist:
-               self.AddItem(key,value)
-           self.CreateLoop(incomingdata[0])
-        elif not isinstance(incomingdata[0],(unicode,str)):
-             raise TypeError('Star datanames are strings only (got %s)' % repr( incomingdata[0] ))
-        else:
-            self.AddItem(incomingdata[0],incomingdata[1])
-
-    def check_data_name(self,dataname,maxlength=-1):
-        if maxlength > 0:
-            self.check_name_length(dataname,maxlength)
-        if dataname[0]!='_':
-            raise StarError( 'Dataname ' + dataname + ' does not begin with _')
-        if self.characterset=='ascii':
-            if len ([a for a in dataname if ord(a) < 33 or ord(a) > 126]) > 0:
-                raise StarError( 'Dataname ' + dataname + ' contains forbidden characters')
-        else:
-            # print 'Checking %s for unicode characterset conformance' % dataname
-            if len ([a for a in dataname if ord(a) < 33]) > 0:
-                raise StarError( 'Dataname ' + dataname + ' contains forbidden characters (below code point 33)')
-            if len ([a for a in dataname if ord(a) > 126 and ord(a) < 160]) > 0:
-                raise StarError( 'Dataname ' + dataname + ' contains forbidden characters (between code point 127-159)')
-            if len ([a for a in dataname if ord(a) > 0xD7FF and ord(a) < 0xE000]) > 0:
-                raise StarError( 'Dataname ' + dataname + ' contains unsupported characters (between U+D800 and U+E000)')
-            if len ([a for a in dataname if ord(a) > 0xFDCF and ord(a) < 0xFDF0]) > 0:
-                raise StarError( 'Dataname ' + dataname + ' contains unsupported characters (between U+FDD0 and U+FDEF)')
-            if len ([a for a in dataname if ord(a) == 0xFFFE or ord(a) == 0xFFFF]) > 0:
-                raise StarError( 'Dataname ' + dataname + ' contains unsupported characters (U+FFFE and/or U+FFFF)')
-            if len ([a for a in dataname if ord(a) > 0x10000 and (ord(a) & 0xE == 0xE)]) > 0:
-                print('%s fails' % dataname)
-                for a in dataname: print('%x' % ord(a),end="")
-                print()
-                raise StarError( u'Dataname ' + dataname + u' contains unsupported characters (U+xFFFE and/or U+xFFFF)')
-
-    def check_name_length(self,dataname,maxlength):
-        if len(dataname)>maxlength:
-            raise StarError( 'Dataname %s exceeds maximum length %d' % (dataname,maxlength))
-        return
-
-    def check_item_value(self,item):
-        test_item = item
-        if not isinstance(item,(list,dict,tuple)):
-           test_item = [item]         #single item list
-        def check_one (it):
-            if isinstance(it,unicode):
-                if it=='': return
-                me = self.char_check.match(it)
-                if not me:
-                    print("Fail value check: %s" % it)
-                    raise StarError('Bad character in %s' % it)
-                else:
-                    if me.span() != (0,len(it)):
-                        print("Fail value check, match only %d-%d in string %s" % (me.span()[0],me.span()[1],repr( it )))
-                        raise StarError('Data item "' + repr( it ) +  u'"... contains forbidden characters')
-        [check_one(a) for a in test_item]
-
-    def regularise_data(self,dataitem):
-        """Place dataitem into a list if necessary"""
-        from numbers import Number
-        if isinstance(dataitem,str):
-            return unicode(dataitem),None
-        if isinstance(dataitem,(Number,unicode,StarList,StarDict)):
-            return dataitem,None  #assume StarList/StarDict contain unicode if necessary
-        if isinstance(dataitem,(tuple,list)):
-            v,s = zip(*list([self.regularise_data(a) for a in dataitem]))
-            return list(v),list(s)
-            #return dataitem,[None]*len(dataitem)
-        # so try to make into a list
-        try:
-            regval = list(dataitem)
-        except TypeError as value:
-            raise StarError( str(dataitem) + ' is wrong type for data value\n' )
-        v,s = zip(*list([self.regularise_data(a) for a in regval]))
-        return list(v),list(s)
-
-    def RemoveItem(self,itemname):
-        """Remove `itemname` from the block."""
-        # first check any loops
-        loop_no = self.FindLoop(itemname)
-        testkey = itemname.lower()
-        if testkey in self:
-            del self.block[testkey]
-            del self.true_case[testkey]
-            # now remove from loop
-            if loop_no >= 0:
-                self.loops[loop_no].remove(testkey)
-                if len(self.loops[loop_no])==0:
-                    del self.loops[loop_no]
-                    self.item_order.remove(loop_no)
-            else:  #will appear in order list
-                self.item_order.remove(testkey)
-
-    def RemoveLoopItem(self,itemname):
-        """*Deprecated*. Use `RemoveItem` instead"""
-        self.RemoveItem(itemname)
-
-    def GetItemValue(self,itemname):
-        """Return value of `itemname`.  If `itemname` is looped, a list
-        of all values will be returned."""
-        return self.GetFullItemValue(itemname)[0]
-
-    def GetFullItemValue(self,itemname):
-        """Return the value associated with `itemname`, and a boolean flagging whether
-        (True) or not (False) it is in a form suitable for calculation.  False is
-        always returned for strings and `StarList` objects."""
-        try:
-            s,v = self.block[itemname.lower()]
-        except KeyError:
-            raise KeyError('Itemname %s not in datablock' % itemname)
-        # prefer string value unless all are None
-        # are we a looped value?
-        if not isinstance(s,(tuple,list)) or isinstance(s,StarList):
-            if not_none(s):
-                return s,False    #a string value
-            else:
-                return v,not isinstance(v,StarList)  #a StarList is not calculation-ready
-        elif not_none(s):
-            return s,False         #a list of string values
-        else:
-            if len(v)>0:
-                return v,not isinstance(v[0],StarList)
-            return v,True
-
-    def CreateLoop(self,datanames,order=-1,length_check=True):
-           """Create a loop in the datablock. `datanames` is a list of datanames that
-           together form a loop.  If length_check is True, they should have been initialised in the block
-           to have the same number of elements (possibly 0). If `order` is given,
-           the loop will appear at this position in the block when printing
-           out. A single-row loop will be created if the provided datanames are all
-           non-lists. A loop counts as a single position."""
-
-           if length_check:
-               # check lengths: these datanames should exist
-               listed_values = [a for a in datanames if isinstance(self[a],list) and not isinstance(self[a],StarList)]
-               if len(listed_values) == len(datanames):
-                   len_set = set([len(self[a]) for a in datanames])
-                   if len(len_set)>1:
-                       raise ValueError('Request to loop datanames %s with different lengths: %s' % (repr( datanames ),repr( len_set )))
-               elif len(listed_values) != 0:
-                   raise ValueError('Request to loop datanames where some are single values and some are not')
-               else:    #all are unlisted, turn into lists
-                   for d in datanames:
-                       self[d] = [self[d]]
-           # store as lower case
-           lc_datanames = [d.lower() for d in datanames]
-           # remove these datanames from all other loops
-           [self.loops[a].remove(b) for a in self.loops for b in lc_datanames if b in self.loops[a]]
-           # remove empty loops
-           empty_loops = [a for a in self.loops.keys() if len(self.loops[a])==0]
-           for a in empty_loops:
-               self.item_order.remove(a)
-               del self.loops[a]
-           if len(self.loops)>0:
-               loopno = max(self.loops.keys()) + 1
-           else:
-               loopno = 1
-           self.loops[loopno] = list(lc_datanames)
-           if order >= 0:
-               self.item_order.insert(order,loopno)
-           else:
-               self.item_order.append(loopno)
-           # remove these datanames from item ordering
-           self.item_order = [a for a in self.item_order if a not in lc_datanames]
-
-    def AddLoopName(self,oldname, newname):
-        """Add `newname` to the loop containing `oldname`. If it is already in the new loop, no
-        error is raised.  If `newname` is in a different loop, it is removed from that loop.
-        The number of values associated with `newname` must match the number of values associated
-        with all other columns of the new loop or a `ValueError` will be raised."""
-        lower_newname = newname.lower()
-        loop_no = self.FindLoop(oldname)
-        if loop_no < 0:
-            raise KeyError('%s not in loop' % oldname)
-        if lower_newname in self.loops[loop_no]:
-            return
-        # check length
-        old_provides = self.provide_value
-        self.provide_value = False
-        loop_len = len(self[oldname])
-        self.provide_value = old_provides
-        if len(self[newname]) != loop_len:
-            raise StarLengthError('Mismatch of loop column lengths for %s: should be %d' % (newname,loop_len))
-        # remove from any other loops
-        [self.loops[a].remove(lower_newname) for a in self.loops if lower_newname in self.loops[a]]
-        # and add to this loop
-        self.loops[loop_no].append(lower_newname)
-        # remove from item_order if present
-        try:
-            self.item_order.remove(lower_newname)
-        except ValueError:
-            pass
-
-    def FindLoop(self,keyname):
-        """Find the loop that contains `keyname` and return its numerical index or
-        -1 if not present. The numerical index can be used to refer to the loop in
-        other routines."""
-        loop_no = [a for a in self.loops.keys() if keyname.lower() in self.loops[a]]
-        if len(loop_no)>0:
-            return loop_no[0]
-        else:
-            return -1
-
-    def GetLoop(self,keyname):
-        """Return a `StarFile.LoopBlock` object constructed from the loop containing `keyname`.
-        `keyname` is only significant as a way to specify the loop."""
-        return LoopBlock(self,keyname)
-
-    def GetLoopNames(self,keyname):
-        if keyname in self:
-            return self.keys()
-        for aloop in self.loops:
-            try:
-                return aloop.GetLoopNames(keyname)
-            except KeyError:
-                pass
-        raise KeyError('Item does not exist')
-
-    def GetLoopNames(self,keyname):
-        """Return all datanames appearing together with `keyname`"""
-        loop_no = self.FindLoop(keyname)
-        if loop_no >= 0:
-            return self.loops[loop_no]
-        else:
-            raise KeyError('%s is not in any loop' % keyname)
-
-    def AddLoopName(self,oldname, newname):
-        """Add `newname` to the loop containing `oldname`. If it is already in the new loop, no
-        error is raised.  If `newname` is in a different loop, it is removed from that loop.
-        The number of values associated with `newname` must match the number of values associated
-        with all other columns of the new loop or a `ValueError` will be raised."""
-        lower_newname = newname.lower()
-        loop_no = self.FindLoop(oldname)
-        if loop_no < 0:
-            raise KeyError('%s not in loop' % oldname)
-        if lower_newname in self.loops[loop_no]:
-            return
-        # check length
-        old_provides = self.provide_value
-        self.provide_value = False
-        loop_len = len(self[oldname])
-        self.provide_value = old_provides
-        if len(self[newname]) != loop_len:
-            raise StarLengthError('Mismatch of loop column lengths for %s: should be %d' % (newname,loop_len))
-        # remove from any other loops
-        [self.loops[a].remove(lower_newname) for a in self.loops if lower_newname in self.loops[a]]
-        # and add to this loop
-        self.loops[loop_no].append(lower_newname)
-        # remove from item_order if present
-        try:
-            self.item_order.remove(lower_newname)
-        except ValueError:
-            pass
-
-    def AddToLoop(self,dataname,loopdata):
-        thisloop = self.GetLoop(dataname)
-        for itemname,itemvalue in loopdata.items():
-            thisloop[itemname] = itemvalue
-
-    def AddToLoop(self,dataname,loopdata):
-        """*Deprecated*. Use `AddItem` followed by calls to `AddLoopName`.
-
-        Add multiple columns to the loop containing `dataname`. `loopdata` is a
-        collection of (key,value) pairs, where `key` is the new dataname and `value`
-        is a list of values for that dataname"""
-        self.update(loopdata)
-        for one_name in loopdata:
-            self.AddLoopName(dataname,one_name)
-
-    def RemoveKeyedPacket(self,keyname,keyvalue):
-        """Remove the packet for which dataname `keyname` takes
-        value `keyvalue`.  Only the first such occurrence is
-        removed."""
-        packet_coord = list(self[keyname]).index(keyvalue)
-        loopnames = self.GetLoopNames(keyname)
-        for dataname in loopnames:
-            self.block[dataname][0] = list(self.block[dataname][0])
-            del self.block[dataname][0][packet_coord]
-            self.block[dataname][1] = list(self.block[dataname][1])
-            del self.block[dataname][1][packet_coord]
-
-    def GetKeyedPacket(self,keyname,keyvalue,no_case=False):
-        """Return the loop packet (a `StarPacket` object) where `keyname` has value
-        `keyvalue`. Ignore case in `keyvalue` if `no_case` is True.  `ValueError`
-        is raised if no packet is found or more than one packet is found."""
-        my_loop = self.GetLoop(keyname)
-        #print("Looking for %s in %s" % (keyvalue, my_loop.parent_block))
-        #print('Packet check on:' + keyname)
-        #[print(repr(getattr(a,keyname))) for a in my_loop]
-        if no_case:
-           one_pack= [a for a in my_loop if getattr(a,keyname).lower()==keyvalue.lower()]
-        else:
-           one_pack= [a for a in my_loop if getattr(a,keyname)==keyvalue]
-        if len(one_pack)!=1:
-            raise ValueError("Bad packet key %s = %s: returned %d packets" % (keyname,keyvalue,len(one_pack)))
-        print("Keyed packet: %s" % one_pack[0])
-        return one_pack[0]
-
-    def GetCompoundKeyedPacket(self,keydict):
-        """Return the loop packet (a `StarPacket` object) where the `{key:(value,caseless)}` pairs
-        in `keydict` take the appropriate values. Ignore case for a given `key` if `caseless` is
-        True.  `ValueError` is raised if no packet is found or more than one packet is found."""
-        #print "Looking for %s in %s" % (keyvalue, self.parent_block[keyname])
-        keynames = list(keydict.keys())
-        my_loop = self.GetLoop(keynames[0])
-        for one_key in keynames:
-            keyval,no_case = keydict[one_key]
-            if no_case:
-               my_loop = list([a for a in my_loop if str(getattr(a,one_key)).lower()==str(keyval).lower()])
-            else:
-               my_loop = list([a for a in my_loop if getattr(a,one_key)==keyval])
-        if len(my_loop)!=1:
-            raise ValueError("Bad packet keys %s: returned %d packets" % (repr(keydict),len(my_loop)))
-        print("Compound keyed packet: %s" % my_loop[0])
-        return my_loop[0]
-
-    def GetKeyedSemanticPacket(self,keyvalue,cat_id):
-        """Return a complete packet for category `cat_id` where the
-        category key for the category equals `keyvalue`.  This routine
-        will understand any joined loops, so if separate loops in the
-        datafile belong to the
-        same category hierarchy (e.g. `_atom_site` and `_atom_site_aniso`),
-        the returned `StarPacket` object will contain datanames from
-        both categories."""
-        target_keys = self.dictionary.cat_key_table[cat_id]
-        target_keys = [k[0] for k in target_keys] #one only in each list
-        p = StarPacket()
-        # set case-sensitivity flag
-        lcase = False
-        if self.dictionary[target_keys[0]]['_type.contents'] in ['Code','Tag','Name']:
-            lcase = True
-        for cat_key in target_keys:
-            try:
-                extra_packet = self.GetKeyedPacket(cat_key,keyvalue,no_case=lcase)
-            except KeyError:        #missing key
-                try:
-                    test_key = self[cat_key]  #generate key if possible
-                    print('Test key is %s' % repr( test_key ))
-                    if test_key is not None and\
-                    not (isinstance(test_key,list) and (None in test_key or len(test_key)==0)):
-                        print('Getting packet for key %s' % repr( keyvalue ))
-                        extra_packet = self.GetKeyedPacket(cat_key,keyvalue,no_case=lcase)
-                except:             #cannot be generated
-                    continue
-            except ValueError:      #none/more than one, assume none
-                continue
-                #extra_packet = self.dictionary.generate_default_packet(cat_id,cat_key,keyvalue)
-            p.merge_packet(extra_packet)
-        # the following attributes used to calculate missing values
-        for keyname in target_keys:
-            if hasattr(p,keyname):
-                p.key = [keyname]
-                break
-        if not hasattr(p,"key"):
-            raise ValueError("No key found for %s, packet is %s" % (cat_id,str(p)))
-        p.cif_dictionary = self.dictionary
-        p.fulldata = self
-        return p
-
-    def GetMultiKeyedSemanticPacket(self,keydict,cat_id):
-        """Return a complete packet for category `cat_id` where the keyvalues are
-        provided as a dictionary of key:(value,caseless) pairs
-        This routine
-        will understand any joined loops, so if separate loops in the
-        datafile belong to the
-        same category hierarchy (e.g. `_atom_site` and `_atom_site_aniso`),
-        the returned `StarPacket` object will contain datanames from
-        the requested category and any children."""
-        #if len(keyvalues)==1:   #simplification
-        #    return self.GetKeyedSemanticPacket(keydict[1][0],cat_id)
-        target_keys = self.dictionary.cat_key_table[cat_id]
-        # update the dictionary passed to us with all equivalents, for
-        # simplicity.
-        parallel_keys = list(zip(*target_keys))  #transpose
-        print('Parallel keys:' + repr(parallel_keys))
-        print('Keydict:' + repr(keydict))
-        start_keys = list(keydict.keys())
-        for one_name in start_keys:
-            key_set = [a for a in parallel_keys if one_name in a]
-            for one_key in key_set:
-                keydict[one_key] = keydict[one_name]
-        # target_keys is a list of lists, each of which is a compound key
-        p = StarPacket()
-        # a little function to return the dataname for a key
-        def find_key(key):
-            for one_key in self.dictionary.key_equivs.get(key,[])+[key]:
-                if self.has_key(one_key):
-                    return one_key
-            return None
-        for one_set in target_keys: #loop down the categories
-            true_keys = [find_key(k) for k in one_set]
-            true_keys = [k for k in true_keys if k is not None]
-            if len(true_keys)==len(one_set):
-                truekeydict = dict([(t,keydict[k]) for t,k in zip(true_keys,one_set)])
-                try:
-                    extra_packet = self.GetCompoundKeyedPacket(truekeydict)
-                except KeyError:     #one or more are missing
-                    continue         #should try harder?
-                except ValueError:
-                    continue
-            else:
-                continue
-            print('Merging packet for keys ' + repr(one_set))
-            p.merge_packet(extra_packet)
-        # the following attributes used to calculate missing values
-        p.key = true_keys
-        p.cif_dictionary = self.dictionary
-        p.fulldata = self
-        return p
-
-
-    def set_grammar(self,new_grammar):
-        self.string_delimiters = ["'",'"',"\n;",None]
-        if new_grammar in ['STAR2','2.0']:
-            self.string_delimiters += ['"""',"'''"]
-        if new_grammar == '2.0':
-            self.list_delimiter = "  "
-        elif new_grammar == 'STAR2':
-            self.list_delimiter = ", "
-        elif new_grammar not in ['1.0','1.1']:
-            raise StarError('Request to set unknown grammar %s' % new_grammar)
-
-    def SetOutputLength(self,wraplength=80,maxoutlength=2048):
-        """Set the maximum output line length (`maxoutlength`) and the line length to
-        wrap at (`wraplength`).  The wrap length is a target only and may not always be
-        possible."""
-        if wraplength > maxoutlength:
-            raise StarError("Wrap length (requested %d) must be <= Maximum line length (requested %d)" % (wraplength,maxoutlength))
-        self.wraplength = wraplength
-        self.maxoutlength = maxoutlength
-
-    def printsection(self,instring='',blockstart="",blockend="",indent=0,finish_at='',start_from=''):
-        self.provide_value = False
-        # first make an ordering
-        self.create_ordering(finish_at,start_from)  #create self.output_order
-        # now do it...
-        if not instring:
-            outstring = CIFStringIO(target_width=80)       # the returned string
-        else:
-            outstring = instring
-        # print block delimiter
-        outstring.write(blockstart,canbreak=True)
-        while len(self.output_order)>0:
-           #print "Remaining to output " + `self.output_order`
-           itemname = self.output_order.pop(0)
-           if not isinstance(itemname,int):  #no loop
-                   item_spec = [i for i in self.formatting_hints if i['dataname'].lower()==itemname.lower()]
-                   if len(item_spec)>0:
-                       item_spec = item_spec[0]
-                       col_pos = item_spec.get('column',-1)
-                       name_pos = item_spec.get('name_pos',-1)
-                   else:
-                       col_pos = -1
-                       item_spec = {}
-                       name_pos = -1
-                   if col_pos < 0: col_pos = 40
-                   outstring.set_tab(col_pos)
-                   itemvalue = self[itemname]
-                   outstring.write(self.true_case[itemname],mustbreak=True,do_tab=False,startcol=name_pos)
-                   outstring.write(' ',canbreak=True,do_tab=False,delimiter=True)    #space after itemname
-                   self.format_value(itemvalue,outstring,hints=item_spec)
-           else:# we are asked to print a loop block
-                    outstring.set_tab(10)       #guess this is OK?
-                    loop_spec = [i['name_pos'] for i in self.formatting_hints if i["dataname"]=='loop']
-                    if loop_spec:
-                        loop_indent = max(loop_spec[0],0)
-                    else:
-                        loop_indent = indent
-                    outstring.write('loop_\n',mustbreak=True,do_tab=False,startcol=loop_indent)
-                    self.format_names(outstring,indent+2,loop_no=itemname)
-                    self.format_packets(outstring,indent+2,loop_no=itemname)
-        else:
-            returnstring = outstring.getvalue()
-        outstring.close()
-        return returnstring
-
-    def format_names(self,outstring,indent=0,loop_no=-1):
-        """Print datanames from `loop_no` one per line"""
-        temp_order = self.loops[loop_no][:]   #copy
-        format_hints = dict([(i['dataname'],i) for i in self.formatting_hints if i['dataname'] in temp_order])
-        while len(temp_order)>0:
-            itemname = temp_order.pop(0)
-            req_indent = format_hints.get(itemname,{}).get('name_pos',indent)
-            outstring.write(' ' * req_indent,do_tab=False)
-            outstring.write(self.true_case[itemname],do_tab=False)
-            outstring.write("\n",do_tab=False)
-
-    def format_packets(self,outstring,indent=0,loop_no=-1):
-       alldata = [self[a] for a in self.loops[loop_no]]
-       loopnames = self.loops[loop_no]
-       #print 'Alldata: %s' % `alldata`
-       packet_data = list(zip(*alldata))
-       #print 'Packet data: %s' % `packet_data`
-       #create a dictionary for quick lookup of formatting requirements
-       format_hints = dict([(i['dataname'],i) for i in self.formatting_hints if i['dataname'] in loopnames])
-       for position in range(len(packet_data)):
-           if position > 0:
-               outstring.write("\n")    #new line each packet except first
-           for point in range(len(packet_data[position])):
-               datapoint = packet_data[position][point]
-               format_hint = format_hints.get(loopnames[point],{})
-               packstring = self.format_packet_item(datapoint,indent,outstring,format_hint)
-               outstring.write(' ',canbreak=True,do_tab=False,delimiter=True)
-
-    def format_packet_item(self,pack_item,indent,outstring,format_hint):
-           # print 'Formatting %s' % `pack_item`
-           # temporary check for any non-unicode items
-           if isinstance(pack_item,str) and not isinstance(pack_item,unicode):
-               raise StarError("Item {0!r} is not unicode".format(pack_item))
-           if isinstance(pack_item,unicode):
-               delimiter = format_hint.get('delimiter',None)
-               startcol = format_hint.get('column',-1)
-               outstring.write(self._formatstring(pack_item,delimiter=delimiter),startcol=startcol)
-           else:
-               self.format_value(pack_item,outstring,hints = format_hint)
-
-    def _formatstring(self,instring,delimiter=None,standard='CIF1',indent=0,hints={}):
-        if hints.get("reformat",False) and "\n" in instring:
-            instring = "\n"+self.do_wrapping(instring,hints["reformat_indent"])
-        allowed_delimiters = set(self.string_delimiters)
-        if len(instring)==0: allowed_delimiters.difference_update([None])
-        if len(instring) > (self.maxoutlength-2) or '\n' in instring:
-                allowed_delimiters.intersection_update(["\n;","'''",'"""'])
-        [allowed_delimiters.difference_update([None]) for k in '[]{}\v\t ,' if k in instring]
-        if len(instring)>0 and instring[0] in '_$#;(':
-                allowed_delimiters.difference_update([None])
-        if len(instring)>3 and (instring[:4].lower()=='data' or instring[:4].lower()=='save'):
-                allowed_delimiters.difference_update([None])
-        if len(instring)>5 and instring[:6].lower()=='global':
-                allowed_delimiters.difference_update([None])
-        if '"' in instring: allowed_delimiters.difference_update(['"',None])
-        if "'" in instring: allowed_delimiters.difference_update(["'",None])
-        out_delimiter = "\n;"  #default (most conservative)
-        if delimiter in allowed_delimiters:
-            out_delimiter = delimiter
-        elif "'" in allowed_delimiters: out_delimiter = "'"
-        elif '"' in allowed_delimiters: out_delimiter = '"'
-        if out_delimiter in ['"',"'",'"""',"'''"]: return out_delimiter + instring + out_delimiter
-        elif out_delimiter is None: return instring
-        # we are left with semicolon strings
-        # use our protocols:
-        maxlinelength = max([len(a) for a in instring.split('\n')])
-        if maxlinelength > self.maxoutlength:
-            protocol_string = apply_line_folding(instring)
-        else:
-            protocol_string = instring
-        # now check for embedded delimiters
-        if "\n;" in protocol_string:
-            prefix = "CIF:"
-            while prefix in protocol_string: prefix = prefix + ":"
-            protocol_string = apply_line_prefix(protocol_string,prefix+"> ")
-        return "\n;" + protocol_string + "\n;"
-
-    def format_value(self,itemvalue,stringsink,compound=False,hints={}):
-        """Format a Star data value"""
-        global have_numpy
-        delimiter = hints.get('delimiter',None)
-        startcol = hints.get('column',-1)
-        if isinstance(itemvalue,str) and not isinstance(itemvalue,unicode): #not allowed
-            raise StarError("Non-unicode value {0} found in block".format(itemvalue))
-        if isinstance(itemvalue,unicode):  #need to sanitize
-            stringsink.write(self._formatstring(itemvalue,delimiter=delimiter,hints=hints),canbreak = True,startcol=startcol)
-        elif isinstance(itemvalue,(list)) or (hasattr(itemvalue,'dtype') and hasattr(itemvalue,'__iter__')): #numpy
-           stringsink.set_tab(0)
-           stringsink.write('[',canbreak=True,newindent=True,mustbreak=compound,startcol=startcol)
-           if len(itemvalue)>0:
-               self.format_value(itemvalue[0],stringsink)
-               for listval in itemvalue[1:]:
-                  # print 'Formatting %s' % `listval`
-                  stringsink.write(self.list_delimiter,do_tab=False)
-                  self.format_value(listval,stringsink,compound=True)
-           stringsink.write(']',unindent=True)
-        elif isinstance(itemvalue,dict):
-           stringsink.set_tab(0)
-           stringsink.write('{',newindent=True,mustbreak=compound,startcol=startcol)  #start a new line inside
-           items = list(itemvalue.items())
-           if len(items)>0:
-               stringsink.write("'"+items[0][0]+"'"+':',canbreak=True)
-               self.format_value(items[0][1],stringsink)
-               for key,value in items[1:]:
-                   stringsink.write(self.list_delimiter)
-                   stringsink.write("'"+key+"'"+":",canbreak=True)
-                   self.format_value(value,stringsink)   #never break between key and value
-           stringsink.write('}',unindent=True)
-        elif isinstance(itemvalue,(float,int,long)) or \
-             (have_numpy and isinstance(itemvalue,(numpy.number))):  #TODO - handle uncertainties
-           stringsink.write(str(itemvalue),canbreak=True,startcol=startcol)   #numbers
-        else:
-           raise ValueError('Value in unexpected format for output: %s' % repr( itemvalue ))
-
-    def create_ordering(self,finish_at,start_from):
-        """Create a canonical ordering that includes loops using our formatting hints dictionary"""
-        requested_order = list([i['dataname'] for i in self.formatting_hints if i['dataname']!='loop'])
-        new_order = []
-        for item in requested_order:
-           if isinstance(item,unicode) and item.lower() in self.item_order:
-               new_order.append(item.lower())
-           elif item in self:    #in a loop somewhere
-               target_loop = self.FindLoop(item)
-               if target_loop not in new_order:
-                   new_order.append(target_loop)
-                   # adjust loop name order
-                   loopnames = self.loops[target_loop]
-                   loop_order = [i for i in requested_order if i in loopnames]
-                   unordered = [i for i in loopnames if i not in loop_order]
-                   self.loops[target_loop] = loop_order + unordered
-        extras = list([i for i in self.item_order if i not in new_order])
-        self.output_order = new_order + extras
-        # now handle partial output
-        if start_from != '':
-            if start_from in requested_order:
-                sfi = requested_order.index(start_from)
-                loop_order = [self.FindLoop(k) for k in requested_order[sfi:] if self.FindLoop(k)>0]
-                candidates = list([k for k in self.output_order if k in requested_order[sfi:]])
-                cand_pos = len(new_order)
-                if len(candidates)>0:
-                    cand_pos = self.output_order.index(candidates[0])
-                if len(loop_order)>0:
-                    cand_pos = min(cand_pos,self.output_order.index(loop_order[0]))
-                if cand_pos < len(self.output_order):
-                    print('Output starts from %s, requested %s' % (self.output_order[cand_pos],start_from))
-                    self.output_order = self.output_order[cand_pos:]
-                else:
-                    print('Start is beyond end of output list')
-                    self.output_order = []
-            elif start_from in extras:
-               self.output_order = self.output_order[self.output_order.index(start_from):]
-            else:
-               self.output_order = []
-        if finish_at != '':
-            if finish_at in requested_order:
-                fai = requested_order.index(finish_at)
-                loop_order = list([self.FindLoop(k) for k in requested_order[fai:] if self.FindLoop(k)>0])
-                candidates = list([k for k in self.output_order if k in requested_order[fai:]])
-                cand_pos = len(new_order)
-                if len(candidates)>0:
-                    cand_pos = self.output_order.index(candidates[0])
-                if len(loop_order)>0:
-                    cand_pos = min(cand_pos,self.output_order.index(loop_order[0]))
-                if cand_pos < len(self.output_order):
-                    print('Output finishes before %s, requested before %s' % (self.output_order[cand_pos],finish_at))
-                    self.output_order = self.output_order[:cand_pos]
-                else:
-                    print('All of block output')
-            elif finish_at in extras:
-               self.output_order = self.output_order[:self.output_order.index(finish_at)]
-        #print('Final order: ' + repr(self.output_order))
-
-    def convert_to_string(self,dataname):
-        """Convert values held in dataname value fork to string version"""
-        v,is_value = self.GetFullItemValue(dataname)
-        if not is_value:
-            return v
-        if check_stringiness(v): return v   #already strings
-        # TODO...something else
-        return v
-
-    def do_wrapping(self,instring,indent=3):
-        """Wrap the provided string"""
-        if "   " in instring:   #already formatted
-            return instring
-        self.wrapper.initial_indent = ' '*indent
-        self.wrapper.subsequent_indent = ' '*indent
-        # remove leading and trailing space
-        instring = instring.strip()
-        # split into paragraphs
-        paras = instring.split("\n\n")
-        wrapped_paras = [self.wrapper.fill(p) for p in paras]
-        return "\n".join(wrapped_paras)
-
-
-    def merge(self,new_block,mode="strict",match_att=[],match_function=None,
-                   rel_keys = []):
-        if mode == 'strict':
-           for key in new_block.keys():
-               if key in self and key not in match_att:
-                  raise StarError( "Identical keys %s in strict merge mode" % key)
-               elif key not in match_att:           #a new dataname
-                   self[key] = new_block[key]
-           # we get here if there are no keys in common, so we can now copy
-           # the loops and not worry about overlaps
-           for one_loop in new_block.loops.values():
-               self.CreateLoop(one_loop)
-           # we have lost case information
-           self.true_case.update(new_block.true_case)
-        elif mode == 'replace':
-           newkeys = list(new_block.keys())
-           for ma in match_att:
-              try:
-                   newkeys.remove(ma)        #don't touch the special ones
-              except ValueError:
-                   pass
-           for key in new_block.keys():
-                  if isinstance(key,unicode):
-                      self[key] = new_block[key]
-           # creating the loop will remove items from other loops
-           for one_loop in new_block.loops.values():
-               self.CreateLoop(one_loop)
-           # we have lost case information
-           self.true_case.update(new_block.true_case)
-        elif mode == 'overlay':
-           print('Overlay mode, current overwrite is %s' % self.overwrite)
-           raise StarError('Overlay block merge mode not implemented')
-           save_overwrite = self.overwrite
-           self.overwrite = True
-           for attribute in new_block.keys():
-               if attribute in match_att: continue      #ignore this one
-               new_value = new_block[attribute]
-               #non-looped items
-               if new_block.FindLoop(attribute)<0:     #not looped
-                  self[attribute] = new_value
-           my_loops = self.loops.values()
-           perfect_overlaps = [a for a in new_block.loops if a in my_loops]
-           for po in perfect_overlaps:
-              loop_keys = [a for a in po if a in rel_keys]  #do we have a key?
-              try:
-                  newkeypos = map(lambda a:newkeys.index(a),loop_keys)
-                  newkeypos = newkeypos[0]      #one key per loop for now
-                  loop_keys = loop_keys[0]
-              except (ValueError,IndexError):
-                  newkeypos = []
-                  overlap_data = map(lambda a:listify(self[a]),overlaps) #old packet data
-                  new_data = map(lambda a:new_block[a],overlaps) #new packet data
-                  packet_data = transpose(overlap_data)
-                  new_p_data = transpose(new_data)
-                  # remove any packets for which the keys match between old and new; we
-                  # make the arbitrary choice that the old data stays
-                  if newkeypos:
-                      # get matching values in new list
-                      print("Old, new data:\n%s\n%s" % (repr(overlap_data[newkeypos]),repr(new_data[newkeypos])))
-                      key_matches = filter(lambda a:a in overlap_data[newkeypos],new_data[newkeypos])
-                      # filter out any new data with these key values
-                      new_p_data = filter(lambda a:a[newkeypos] not in key_matches,new_p_data)
-                      if new_p_data:
-                          new_data = transpose(new_p_data)
-                      else: new_data = []
-                  # wipe out the old data and enter the new stuff
-                  byebyeloop = self.GetLoop(overlaps[0])
-                  # print("Removing '%r' with overlaps '%r'" % (byebyeloop, overlaps))
-                  # Note that if, in the original dictionary, overlaps are not
-                  # looped, GetLoop will return the block itself.  So we check
-                  # for this case...
-                  if byebyeloop != self:
-                      self.remove_loop(byebyeloop)
-                  self.AddLoopItem((overlaps,overlap_data))  #adding old packets
-                  for pd in new_p_data:                             #adding new packets
-                     if pd not in packet_data:
-                        for i in range(len(overlaps)):
-                            #don't do this at home; we are appending
-                            #to something in place
-                            self[overlaps[i]].append(pd[i])
-           self.overwrite = save_overwrite
-
-    def assign_dictionary(self,dic):
-        if not dic.diclang=="DDLm":
-            print("Warning: ignoring dictionary %s" % dic.my_uri)
-            return
-        self.dictionary = dic
-
-    def unassign_dictionary(self):
-        """Remove dictionary-dependent behaviour"""
-        self.dictionary = None
-
-
-
-class StarPacket(list):
-    def merge_packet(self,incoming):
-        """Merge contents of incoming packet with this packet"""
-        new_attrs = [a for a in dir(incoming) if a[0] == '_' and a[1] != "_"]
-        self.extend(incoming)
-        for na in new_attrs:
-            setattr(self,na,getattr(incoming,na))
-
-    def __getattr__(self,att_name):
-        """Derive a missing attribute"""
-        if att_name.lower() in self.__dict__:
-            return getattr(self,att_name.lower())
-        if att_name in ('cif_dictionary','fulldata','key'):
-            raise AttributeError('Programming error: can only assign value of %s' % att_name)
-        d = self.cif_dictionary
-        c = self.fulldata
-        k = self.key
-        assert isinstance(k,list)
-        d.derive_item(att_name,c,store_value=True)
-        #
-        # now pick out the new value
-        # self.key is a list of the key values
-        keydict = dict([(v,(getattr(self,v),True)) for v in k])
-        full_pack = c.GetCompoundKeyedPacket(keydict)
-        return getattr(full_pack,att_name)
-
-class BlockCollection(object):
-    """A container for StarBlock objects. The constructor takes
-    one non-keyword argument `datasource` to set the initial data.  If
-    `datasource` is a Python dictionary, the values must be `StarBlock`
-    objects and the keys will be blocknames in the new object. Keyword
-    arguments:
-
-    standard:
-        `CIF` or `Dic`.  `CIF` enforces 75-character blocknames, and will
-        print block contents before that block's save frame.
-
-    blocktype:
-        The type of blocks held in this container. Normally `StarBlock`
-        or `CifBlock`.
-
-    characterset:
-        `ascii` or `unicode`.  Blocknames and datanames appearing within
-        blocks are restricted to the appropriate characterset. Note that
-        only characters in the basic multilingual plane are accepted. This
-        restriction will be lifted when PyCIFRW is ported to Python3.
-
-    scoping:
-        `instance` or `dictionary`: `instance` implies that save frames are
-        hidden from save frames lower in the hierarchy or in sibling
-        hierarchies. `dictionary` makes all save frames visible everywhere
-        within a data block.  This setting is only relevant for STAR2 dictionaries and
-        STAR2 data files, as save frames are currently not used in plain CIF data
-        files.
-
-"""
-    def __init__(self,datasource=None,standard='CIF',blocktype = StarBlock,
-                 characterset='ascii',scoping='instance',**kwargs):
-        import collections
-        self.dictionary = {}
-        self.standard = standard
-        self.lower_keys = set()           # short_cuts
-        self.renamed = {}
-        self.PC = collections.namedtuple('PC',['block_id','parent'])
-        self.child_table = {}
-        self.visible_keys = []            # for efficiency
-        self.block_input_order = []       # to output in same order
-        self.scoping = scoping  #will trigger setting of child table
-        self.blocktype = blocktype
-        self.master_template = {}   #for outputting
-        self.set_grammar('2.0')
-        self.set_characterset(characterset)
-        if isinstance(datasource,BlockCollection):
-            self.merge_fast(datasource)
-            self.scoping = scoping   #reset visibility
-        elif isinstance(datasource,dict):
-            for key,value in datasource.items():
-                 self[key]= value
-        self.header_comment = ''
-
-    def set_grammar(self,new_grammar):
-        """Set the syntax and grammar for output to `new_grammar`"""
-        if new_grammar not in ['1.1','1.0','2.0','STAR2']:
-            raise StarError('Unrecognised output grammar %s' % new_grammar)
-        self.grammar = new_grammar
-
-    def set_characterset(self,characterset):
-        """Set the allowed characters for datanames and datablocks: may be `ascii` or `unicode`. If datanames
-        have already been added to any datablocks, they are not checked."""
-        self.characterset = characterset
-        for one_block in self.lower_keys:
-            self[one_block].set_characterset(characterset)
-
-    def unlock(self):
-        """Allow overwriting of all blocks in this collection"""
-        for a in self.lower_keys:
-            self[a].overwrite=True
-
-    def lock(self):
-        """Disallow overwriting for all blocks in this collection"""
-        for a in self.lower_keys:
-            self[a].overwrite = False
-
-    def __str__(self):
-        return self.WriteOut()
-
-    def __setitem__(self,key,value):
-        self.NewBlock(key,value,parent=None)
-
-    def __getitem__(self,key):
-        if isinstance(key,(unicode,str)):
-           lowerkey = key.lower()
-           if lowerkey in self.lower_keys:
-               return self.dictionary[lowerkey]
-           #print 'Visible keys:' + `self.visible_keys`
-           #print 'All keys' + `self.lower_keys`
-           #print 'Child table' + `self.child_table`
-           raise KeyError('No such item %s' % key)
-
-    # we have to get an ordered list of the current keys,
-    # as we'll have to delete one of them anyway.
-    # Deletion will delete any key regardless of visibility
-
-    def __delitem__(self,key):
-        dummy = self[key]   #raise error if not present
-        lowerkey = key.lower()
-        # get rid of all children recursively as well
-        children = [a[0] for a in self.child_table.items() if a[1].parent == lowerkey]
-        for child in children:
-            del self[child]   #recursive call
-        del self.dictionary[lowerkey]
-        del self.child_table[lowerkey]
-        try:
-            self.visible_keys.remove(lowerkey)
-        except KeyError:
-            pass
-        self.lower_keys.remove(lowerkey)
-        self.block_input_order.remove(lowerkey)
-
-    def __len__(self):
-        return len(self.visible_keys)
-
-    def __contains__(self,item):
-        """Support the 'in' operator"""
-        if not isinstance(item,(unicode,str)): return False
-        if item.lower() in self.visible_keys:
-            return True
-        return False
-
-    # We iterate over all visible
-    def __iter__(self):
-        for one_block in self.keys():
-            yield self[one_block]
-
-    # TODO: handle different case
-    def keys(self):
-        return self.visible_keys
-
-    # Note that has_key does not exist in 3.5
-    def has_key(self,key):
-        return key in self
-
-    def get(self,key,default=None):
-        if key in self:     # take account of case
-            return self.__getitem__(key)
-        else:
-            return default
-
-    def clear(self):
-        self.dictionary.clear()
-        self.lower_keys = set()
-        self.child_table = {}
-        self.visible_keys = []
-        self.block_input_order = []
-
-    def copy(self):
-        newcopy = self.dictionary.copy()  #all blocks
-        for k,v in self.dictionary.items():
-            newcopy[k] = v.copy()
-        newcopy = BlockCollection(newcopy)
-        newcopy.child_table = self.child_table.copy()
-        newcopy.lower_keys = self.lower_keys.copy()
-        newcopy.block_input_order = self.block_input_order.copy()
-        newcopy.characterset = self.characterset
-        newcopy.SetTemplate(self.master_template.copy())
-        newcopy.scoping = self.scoping  #this sets visible keys
-        return newcopy
-
-    def update(self,adict):
-        for key in adict.keys():
-            self[key] = adict[key]
-
-    def items(self):
-        return [(a,self[a]) for a in self.keys()]
-
-    def first_block(self):
-        """Return the 'first' block.  This is not necessarily the first block in the file."""
-        if self.keys():
-            return self[self.keys()[0]]
-
-    def NewBlock(self,blockname,blockcontents=None,fix=True,parent=None):
-        """Add a new block named `blockname` with contents `blockcontents`. If `fix`
-        is True, `blockname` will have spaces and tabs replaced by underscores. `parent`
-        allows a parent block to be set so that block hierarchies can be created.  Depending on
-        the output standard, these blocks will be printed out as nested save frames or
-        ignored."""
-        if blockcontents is None:
-            blockcontents = self.blocktype()
-        if self.standard == "CIF":
-            blockcontents.setmaxnamelength(75)
-        if len(blockname)>75:
-                 raise StarError('Blockname %s is longer than 75 characters' % blockname)
-        if fix:
-            newblockname = re.sub('[  \t]','_',blockname)
-        else: newblockname = blockname
-        new_lowerbn = newblockname.lower()
-        if new_lowerbn in self.lower_keys:   #already there
-            if self.standard is not None:
-               toplevelnames = [a[0] for a in self.child_table.items() if a[1].parent==None]
-               if parent is None and new_lowerbn not in toplevelnames:  #can give a new key to this one
-                  while new_lowerbn in self.lower_keys: new_lowerbn = new_lowerbn + '+'
-               elif parent is not None and new_lowerbn in toplevelnames: #can fix a different one
-                  replace_name = new_lowerbn
-                  while replace_name in self.lower_keys: replace_name = replace_name + '+'
-                  self._rekey(new_lowerbn,replace_name)
-                  # now continue on to add in the new block
-                  if parent.lower() == new_lowerbn:        #the new block's requested parent just got renamed!!
-                      parent = replace_name
-               else:
-                  raise StarError( "Attempt to replace existing block " + blockname)
-            else:
-               del self[new_lowerbn]
-        self.dictionary.update({new_lowerbn:blockcontents})
-        self.lower_keys.add(new_lowerbn)
-        self.block_input_order.append(new_lowerbn)
-        if parent is None:
-           self.child_table[new_lowerbn]=self.PC(newblockname,None)
-           self.visible_keys.append(new_lowerbn)
-        else:
-           if parent.lower() in self.lower_keys:
-              if self.scoping == 'instance':
-                 self.child_table[new_lowerbn]=self.PC(newblockname,parent.lower())
-              else:
-                 self.child_table[new_lowerbn]=self.PC(newblockname,parent.lower())
-                 self.visible_keys.append(new_lowerbn)
-           else:
-               print('Warning:Parent block %s does not exist for child %s' % (parent,newblockname))
-        self[new_lowerbn].set_grammar(self.grammar)
-        self[new_lowerbn].set_characterset(self.characterset)
-        self[new_lowerbn].formatting_hints = self.master_template
-        return new_lowerbn  #in case calling routine wants to know
-
-    def _rekey(self,oldname,newname,block_id=''):
-        """The block with key [[oldname]] gets [[newname]] as a new key, but the printed name
-           does not change unless [[block_id]] is given.  Prefer [[rename]] for a safe version."""
-        move_block = self[oldname]    #old block
-        is_visible = oldname in self.visible_keys
-        move_block_info = self.child_table[oldname]    #old info
-        move_block_children = [a for a in self.child_table.items() if a[1].parent==oldname]
-        # now rewrite the necessary bits
-        self.child_table.update(dict([(a[0],self.PC(a[1].block_id,newname)) for a in move_block_children]))
-        oldpos = self.block_input_order.index(oldname)
-        del self[oldname]   #do this after updating child table so we don't delete children
-        self.dictionary.update({newname:move_block})
-        self.lower_keys.add(newname)
-        #print 'Block input order was: ' + `self.block_input_order`
-        self.block_input_order[oldpos:oldpos]=[newname]
-        if block_id == '':
-           self.child_table.update({newname:move_block_info})
-        else:
-           self.child_table.update({newname:self.PC(block_id,move_block_info.parent)})
-        if is_visible: self.visible_keys += [newname]
-
-    def rename(self,oldname,newname):
-        """Rename datablock from [[oldname]] to [[newname]]. Both key and printed name are changed.  No
-           conformance checks are conducted."""
-        realoldname = oldname.lower()
-        realnewname = newname.lower()
-        if realnewname in self.lower_keys:
-            raise StarError('Cannot change blockname %s to %s as %s already present' % (oldname,newname,newname))
-        if realoldname not in self.lower_keys:
-            raise KeyError('Cannot find old block %s' % realoldname)
-        self._rekey(realoldname,realnewname,block_id=newname)
-
-    def makebc(self,namelist,scoping='dictionary'):
-        """Make a block collection from a list of block names"""
-        newbc = BlockCollection()
-        block_lower = [n.lower() for n in namelist]
-        proto_child_table = [a for a in self.child_table.items() if a[0] in block_lower]
-        newbc.child_table = dict(proto_child_table)
-        new_top_level = [(a[0],self.PC(a[1].block_id,None)) for a in newbc.child_table.items() if a[1].parent not in block_lower]
-        newbc.child_table.update(dict(new_top_level))
-        newbc.lower_keys = set([a[0] for a in proto_child_table])
-        newbc.dictionary = dict((a[0],self.dictionary[a[0]]) for a in proto_child_table)
-        newbc.scoping = scoping
-        newbc.block_input_order = block_lower
-        return newbc
-
-
-    def merge_fast(self,new_bc,parent=None):
-        """Do a fast merge. WARNING: this may change one or more of its frame headers in order to
-        remove duplicate frames.  Please keep a handle to the block object instead of the text of
-        the header."""
-        if self.standard is None:
-            mode = 'replace'
-        else:
-            mode = 'strict'
-        overlap_flag = not self.lower_keys.isdisjoint(new_bc.lower_keys)
-        if parent is not None:
-            parent_name = [a[0] for a in self.dictionary.items() if a[1] == parent]
-            if len(parent_name)==0 or len(parent_name)>1:
-                raise StarError("Unable to find unique parent block name: have %s" % str(parent_name))
-            parent_name = parent_name[0]
-        else:
-            parent_name = None  #an error will be thrown if we treat as a string
-        if overlap_flag and mode != 'replace':
-            double_keys = self.lower_keys.intersection(new_bc.lower_keys)
-            for dup_key in double_keys:
-                  our_parent = self.child_table[dup_key].parent
-                  their_parent = new_bc.child_table[dup_key].parent
-                  if (our_parent is None and their_parent is not None and parent is None) or\
-                      parent is not None:  #rename our block
-                    start_key = dup_key
-                    while start_key in self.lower_keys: start_key = start_key+'+'
-                    self._rekey(dup_key,start_key)
-                    if parent_name.lower() == dup_key:  #we just renamed the prospective parent!
-                        parent_name = start_key
-                  elif our_parent is not None and their_parent is None and parent is None:
-                    start_key = dup_key
-                    while start_key in new_bc.lower_keys: start_key = start_key+'+'
-                    new_bc._rekey(dup_key,start_key)
-                  else:
-                    raise StarError("In strict merge mode:duplicate keys %s" % dup_key)
-        self.dictionary.update(new_bc.dictionary)
-        self.lower_keys.update(new_bc.lower_keys)
-        self.visible_keys += (list(new_bc.lower_keys))
-        self.block_input_order += new_bc.block_input_order
-        #print('Block input order now:' + repr(self.block_input_order))
-        self.child_table.update(new_bc.child_table)
-        if parent_name is not None:     #redo the child_table entries
-              reparent_list = [(a[0],a[1].block_id) for a in new_bc.child_table.items() if a[1].parent==None]
-              reparent_dict = [(a[0],self.PC(a[1],parent_name.lower())) for a in reparent_list]
-              self.child_table.update(dict(reparent_dict))
-
-    def merge(self,new_bc,mode=None,parent=None,single_block=[],
-                   idblock="",match_att=[],match_function=None):
-        if mode is None:
-            if self.standard is None:
-               mode = 'replace'
-            else:
-               mode = 'strict'
-        if single_block:
-            self[single_block[0]].merge(new_bc[single_block[1]],mode,
-                                                   match_att=match_att,
-                                                   match_function=match_function)
-            return None
-        base_keys = [a[1].block_id for a in self.child_table.items()]
-        block_to_item = base_keys   #default
-        new_keys = [a[1].block_id for a in new_bc.child_table.items()]    #get list of incoming blocks
-        if match_att:
-            #make a blockname -> item name map
-            if match_function:
-                block_to_item = [match_function(self[a]) for a in self.keys()]
-            else:
-                block_to_item = [self[a].get(match_att[0],None) for a in self.keys()]
-            #print `block_to_item`
-        for key in new_keys:        #run over incoming blocknames
-            if key == idblock: continue    #skip dictionary id
-            basekey = key           #default value
-            if len(match_att)>0:
-               attval = new_bc[key].get(match_att[0],0)  #0 if ignoring matching
-            else:
-               attval = 0
-            for ii in range(len(block_to_item)):  #do this way to get looped names
-                thisatt = block_to_item[ii]       #keyname in old block
-                #print "Looking for %s in %s" % (attval,thisatt)
-                if attval == thisatt or \
-                   (isinstance(thisatt,list) and attval in thisatt):
-                      basekey = base_keys.pop(ii)
-                      block_to_item.remove(thisatt)
-                      break
-            if not basekey in self or mode=="replace":
-                new_parent = new_bc.get_parent(key)
-                if parent is not None and new_parent is None:
-                   new_parent = parent
-                self.NewBlock(basekey,new_bc[key],parent=new_parent)   #add the block
-            else:
-                if mode=="strict":
-                    raise StarError( "In strict merge mode: block %s in old and block %s in new files" % (basekey,key))
-                elif mode=="overlay":
-                    # print "Merging block %s with %s" % (basekey,key)
-                    self[basekey].merge(new_bc[key],mode,match_att=match_att)
-                else:
-                    raise StarError( "Merge called with unknown mode %s" % mode)
-
-    def checknamelengths(self,target_block,maxlength=-1):
-        if maxlength < 0:
-            return
-        else:
-            toolong = [a for a in target_block.keys() if len(a)>maxlength]
-        outstring = ""
-        if toolong:
-           outstring = "\n".join(toolong)
-           raise StarError( 'Following data names too long:' + outstring)
-
-    def get_all(self,item_name):
-        raw_values = [self[a].get(item_name) for a in self.keys()]
-        raw_values = [a for a in raw_values if a != None]
-        ret_vals = []
-        for rv in raw_values:
-            if isinstance(rv,list):
-                for rvv in rv:
-                    if rvv not in ret_vals: ret_vals.append(rvv)
-            else:
-                if rv not in ret_vals: ret_vals.append(rv)
-        return ret_vals
-
-    def __setattr__(self,attr_name,newval):
-        if attr_name == 'scoping':
-            if newval not in ('dictionary','instance'):
-                raise StarError("Star file may only have 'dictionary' or 'instance' scoping, not %s" % newval)
-            if newval == 'dictionary':
-                self.visible_keys = [a for a in self.lower_keys]
-            else:
-                #only top-level datablocks visible
-                self.visible_keys = [a[0] for a in self.child_table.items() if a[1].parent==None]
-        object.__setattr__(self,attr_name,newval)
-
-    def get_parent(self,blockname):
-        """Return the name of the block enclosing [[blockname]] in canonical form (lower case)"""
-        possibles = (a for a in self.child_table.items() if a[0] == blockname.lower())
-        try:
-            first = next(possibles)   #get first one
-        except:
-            raise StarError('no parent for %s' % blockname)
-        try:
-           second = next(possibles)
-        except StopIteration:
-           return first[1].parent
-        raise StarError('More than one parent for %s' % blockname)
-
-    def get_roots(self):
-        """Get the top-level blocks"""
-        return [a for a in self.child_table.items() if a[1].parent==None]
-
-    def get_children(self,blockname,include_parent=False,scoping='dictionary'):
-        """Get all children of [[blockname]] as a block collection. If [[include_parent]] is
-        True, the parent block will also be included in the block collection as the root."""
-        newbc = BlockCollection()
-        block_lower = blockname.lower()
-        proto_child_table = [a for a in self.child_table.items() if self.is_child_of_parent(block_lower,a[1].block_id)]
-        newbc.child_table = dict(proto_child_table)
-        if not include_parent:
-           newbc.child_table.update(dict([(a[0],self.PC(a[1].block_id,None)) for a in proto_child_table if a[1].parent == block_lower]))
-        newbc.lower_keys = set([a[0] for a in proto_child_table])
-        newbc.dictionary = dict((a[0],self.dictionary[a[0]]) for a in proto_child_table)
-        if include_parent:
-            newbc.child_table.update({block_lower:self.PC(self.child_table[block_lower].block_id,None)})
-            newbc.lower_keys.add(block_lower)
-            newbc.dictionary.update({block_lower:self.dictionary[block_lower]})
-        newbc.scoping = scoping
-        return newbc
-
-    def get_immediate_children(self,parentname):
-        """Get the next level of children of the given block as a list, without nested levels"""
-        child_handles = [a for a in self.child_table.items() if a[1].parent == parentname.lower()]
-        return child_handles
-
-    # This takes time
-    def get_child_list(self,parentname):
-        """Get a list of all child categories in alphabetical order"""
-        child_handles = [a[0] for a in self.child_table.items() if self.is_child_of_parent(parentname.lower(),a[0])]
-        child_handles.sort()
-        return child_handles
-
-    def is_child_of_parent(self,parentname,blockname):
-        """Return `True` if `blockname` is a child of `parentname`"""
-        checkname = parentname.lower()
-        more_children = [a[0] for a in self.child_table.items() if a[1].parent == checkname]
-        if blockname.lower() in more_children:
-           return True
-        else:
-           for one_child in more_children:
-               if self.is_child_of_parent(one_child,blockname): return True
-        return False
-
-    def set_parent(self,parentname,childname):
-        """Set the parent block"""
-        # first check that both blocks exist
-        if parentname.lower() not in self.lower_keys:
-            raise KeyError('Parent block %s does not exist' % parentname)
-        if childname.lower() not in self.lower_keys:
-            raise KeyError('Child block %s does not exist' % childname)
-        old_entry = self.child_table[childname.lower()]
-        self.child_table[childname.lower()]=self.PC(old_entry.block_id,
-               parentname.lower())
-        self.scoping = self.scoping #reset visibility
-
-    def SetTemplate(self,template_file):
-            """Use `template_file` as a template for all block output"""
-            self.master_template = process_template(template_file)
-            for b in self.dictionary.values():
-                b.formatting_hints = self.master_template
-
-    def WriteOut(self,comment='',wraplength=80,maxoutlength=0,blockorder=None,saves_after=None):
-        """Return the contents of this file as a string, wrapping if possible at `wraplength`
-        characters and restricting maximum line length to `maxoutlength`.  Delimiters and
-        save frame nesting are controlled by `self.grammar`. If `blockorder` is
-        provided, blocks are output in this order unless nested save frames have been
-        requested (STAR2). The default block order is the order in which blocks were input.
-        `saves_after` inserts all save frames after the given dataname,
-        which allows less important items to appear later.  Useful in conjunction with a
-        template for dictionary files."""
-        if maxoutlength != 0:
-            self.SetOutputLength(maxoutlength)
-        if not comment:
-            comment = self.header_comment
-        outstring = StringIO()
-        if self.grammar == "2.0" and comment[0:10] != r"#\#CIF_2.0":
-            outstring.write(r"#\#CIF_2.0" + "\n")
-        outstring.write(comment)
-        # prepare all blocks
-        for b in self.dictionary.values():
-            b.set_grammar(self.grammar)
-            b.formatting_hints = self.master_template
-            b.SetOutputLength(wraplength,self.maxoutlength)
-        # loop over top-level
-        # monitor output
-        all_names = list(self.child_table.keys())   #i.e. lower case
-        if blockorder is None:
-            blockorder = self.block_input_order
-        top_block_names = [(a,self.child_table[a].block_id) for a in blockorder if self.child_table[a].parent is None]
-        for blockref,blockname in top_block_names:
-            print('Writing %s, ' % blockname + repr(self[blockref]))
-            outstring.write('\n' + 'data_' +blockname+'\n')
-            all_names.remove(blockref)
-            if self.standard == 'Dic':              #put contents before save frames
-                outstring.write(self[blockref].printsection(finish_at='_dictionary_valid.application'))
-            if self.grammar == 'STAR2':  #nested save frames
-                child_refs = self.get_immediate_children(blockref)
-                for child_ref,child_info in child_refs:
-                    child_name = child_info.block_id
-                    outstring.write('\n\n' + 'save_' + child_name + '\n')
-                    self.block_to_string_nested(child_ref,child_name,outstring,4)
-                    outstring.write('\n' + 'save_'+ '\n')
-            elif self.grammar in ('1.0','1.1','2.0'):                   #non-nested save frames
-                child_refs = [a for a in blockorder if self.is_child_of_parent(blockref,a)]
-                for child_ref in child_refs:
-                    child_name = self.child_table[child_ref].block_id
-                    outstring.write('\n\n' + 'save_' + child_name + '\n')
-                    outstring.write(str(self[child_ref]))
-                    outstring.write('\n\n' + 'save_' + '\n')
-                    all_names.remove(child_ref.lower())
-            else:
-                raise StarError('Grammar %s is not recognised for output' % self.grammar)
-            if self.standard != 'Dic':              #put contents after save frames
-                outstring.write(str(self[blockref]))
-            else:
-                outstring.write(self[blockref].printsection(start_from='_dictionary_valid.application'))
-        returnstring =  outstring.getvalue()
-        outstring.close()
-        if len(all_names)>0:
-            print('WARNING: following blocks not output: %s' % repr(all_names))
-        else:
-            print('All blocks output.')
-        return returnstring
-
-    def block_to_string_nested(self,block_ref,block_id,outstring,indentlevel=0):
-        """Output a complete datablock indexed by [[block_ref]] and named [[block_id]], including children,
-           and syntactically nesting save frames"""
-        child_refs = self.get_immediate_children(block_ref)
-        self[block_ref].set_grammar(self.grammar)
-        if self.standard == 'Dic':
-            outstring.write(str(self[block_ref]))
-        for child_ref,child_info in child_refs:
-            child_name = child_info.block_id
-            outstring.write('\n' + 'save_' + child_name + '\n')
-            self.block_to_string_nested(child_ref,child_name,outstring,indentlevel)
-            outstring.write('\n' + '  '*indentlevel + 'save_' + '\n')
-        if self.standard != 'Dic':
-            outstring.write(str(self[block_ref]))
-
-
-class StarFile(BlockCollection):
-    def __init__(self,datasource=None,maxinlength=-1,maxoutlength=0,
-                scoping='instance',grammar='1.1',scantype='standard',
-                 permissive=False,**kwargs):
-        super(StarFile,self).__init__(datasource=datasource,**kwargs)
-        self.my_uri = getattr(datasource,'my_uri','')
-        if maxoutlength == 0:
-            self.maxoutlength = 2048
-        else:
-            self.maxoutlength = maxoutlength
-        self.scoping = scoping
-        if isinstance(datasource,(unicode,str)) or hasattr(datasource,"read"):
-            ReadStar(datasource,prepared=self,grammar=grammar,scantype=scantype,
-                     maxlength = maxinlength,permissive=permissive)
-        self.header_comment = \
-"""#\\#STAR
-##########################################################################
-#               STAR Format file
-#               Produced by PySTARRW module
-#
-#  This is a STAR file.  STAR is a superset of the CIF file type.  For
-#  more information, please refer to International Tables for Crystallography,
-#  Volume G, Chapter 2.1
-#
-##########################################################################
-"""
-    def set_uri(self,my_uri): self.my_uri = my_uri
-
-
-class CIFStringIO(StringIO):
-    def __init__(self,target_width=80,**kwargs):
-        StringIO.__init__(self,**kwargs)
-        self.currentpos = 0
-        self.target_width = target_width
-        self.tabwidth = -1
-        self.indentlist = [0]
-        self.last_char = ""
-
-    def write(self,outstring,canbreak=False,mustbreak=False,do_tab=True,newindent=False,unindent=False,
-                             delimiter=False,startcol=-1):
-        """Write a string with correct linebreak, tabs and indents"""
-        # do we need to break?
-        if delimiter:
-            if len(outstring)>1:
-                raise ValueError('Delimiter %s is longer than one character' % repr( outstring ))
-            output_delimiter = True
-        if mustbreak:    #insert a new line and indent
-            temp_string = '\n' + ' ' * self.indentlist[-1]
-            StringIO.write(self,temp_string)
-            self.currentpos = self.indentlist[-1]
-            self.last_char = temp_string[-1]
-        if self.currentpos+len(outstring)>self.target_width: #try to break
-            if not delimiter and outstring[0]!='\n':          #ie <cr>;
-              if canbreak:
-                temp_string = '\n' + ' ' * self.indentlist[-1]
-                StringIO.write(self,temp_string)
-                self.currentpos = self.indentlist[-1]
-                self.last_char = temp_string[-1]
-            else:        #assume a break will be forced on next value
-                output_delimiter = False    #the line break becomes the delimiter
-        #try to match requested column
-        if startcol > 0:
-            if self.currentpos < startcol:
-                StringIO.write(self,(startcol - self.currentpos)* ' ')
-                self.currentpos = startcol
-                self.last_char = ' '
-            else:
-                print('Could not format %s at column %d as already at %d' % (outstring,startcol,self.currentpos))
-                startcol = -1   #so that tabbing works as a backup
-        #handle tabs
-        if self.tabwidth >0 and do_tab and startcol < 0:
-            next_stop = ((self.currentpos//self.tabwidth)+1)*self.tabwidth
-            #print 'Currentpos %d: Next tab stop at %d' % (self.currentpos,next_stop)
-            if self.currentpos < next_stop:
-                StringIO.write(self,(next_stop-self.currentpos)*' ')
-                self.currentpos = next_stop
-                self.last_char = ' '
-        #calculate indentation after tabs and col setting applied
-        if newindent:           #indent by current amount
-            if self.indentlist[-1] == 0:    #first time
-                self.indentlist.append(self.currentpos)
-                # print 'Indentlist: ' + `self.indentlist`
-            else:
-                self.indentlist.append(self.indentlist[-1]+2)
-        elif unindent:
-            if len(self.indentlist)>1:
-                self.indentlist.pop()
-            else:
-                print('Warning: cannot unindent any further')
-        #check that we still need a delimiter
-        if self.last_char in [' ','\n','\t']:
-            output_delimiter = False
-        #now output the string - every invocation comes through here
-        if (delimiter and output_delimiter) or not delimiter:
-            StringIO.write(self,outstring)
-        last_line_break = outstring.rfind('\n')
-        if last_line_break >=0:
-            self.currentpos = len(outstring)-last_line_break
-        else:
-            self.currentpos = self.currentpos + len(outstring)
-        #remember the last character
-        if len(outstring)>0:
-            self.last_char = outstring[-1]
-
-    def set_tab(self,tabwidth):
-        """Set the tab stop position"""
-        self.tabwidth = tabwidth
-
-class StarError(Exception):
-    def __init__(self,value):
-        self.value = value
-    def __str__(self):
-        return '\nStar Format error: '+ self.value
-
-class StarLengthError(Exception):
-    def __init__(self,value):
-        self.value = value
-    def __str__(self):
-        return '\nStar length error: ' + self.value
-
-class StarDerivationError(Exception):
-    def __init__(self,fail_name):
-        self.fail_name = fail_name
-    def __str__(self):
-        return "Derivation of %s failed, None returned" % self.fail_name
-
-#
-# This is subclassed from AttributeError in order to allow hasattr
-# to work.
-#
-class StarDerivationFailure(AttributeError):
-    def __init__(self,fail_name):
-        self.fail_name = fail_name
-    def __str__(self):
-        return "Derivation of %s failed" % self.fail_name
-
-def ReadStar(filename,prepared = None, maxlength=-1,
-             scantype='standard',grammar='STAR2',CBF=False, permissive=False):
-
-    """ Read in a STAR file, returning the contents in the `prepared` object.
-
-    * `filename` may be a URL, a file
-    path on the local system, or any object with a `read` method.
-
-    * `prepared` provides a `StarFile` or `CifFile` object that the contents of `filename`
-    will be added to.
-
-    * `maxlength` is the maximum allowable line length in the input file. This has been set at
-    2048 characters for CIF but is unlimited (-1) for STAR files.
-
-    * `grammar` chooses the STAR grammar variant. `1.0` is the original 1992 CIF/STAR grammar and `1.1`
-    is identical except for the exclusion of square brackets as the first characters in
-    undelimited datanames. `2.0` will read files in the CIF2.0 standard, and `STAR2` will
-    read files according to the STAR2 publication.  If grammar is `None` or `auto`, autodetection
-    will be attempted in the order `2.0`, `1.1` and `1.0`. This will always succeed for conformant CIF2.0 files.
-    Note that (nested) save frames are read in all grammar variations and then flagged afterwards if
-    they do not match the requested grammar.
-
-    * `scantype` can be `standard` or `flex`.  `standard` provides pure Python parsing at the
-    cost of a factor of 10 or so in speed.  `flex` will tokenise the input CIF file using
-    fast C routines.  Note that running PyCIFRW in Jython uses native Java regular expressions
-    to provide a speedup regardless of this argument.
-
-    * `CBF` flags that the input file is in Crystallographic Binary File format. The binary block is
-    excised from the input data stream before parsing and is not available in the returned object.
-
-    * `permissive` allows non UTF8 encodings (currently only latin1) in the input file. These are a 
-    violation of the standard.
-
-    """
-
-    # save desired scoping
-    save_scoping = prepared.scoping
-    from . import YappsStarParser_1_1 as Y11
-    from . import YappsStarParser_1_0 as Y10
-    from . import YappsStarParser_2_0 as Y20
-    from . import YappsStarParser_STAR2 as YST
-    if prepared is None:
-        prepared = StarFile()
-    if grammar == "auto" or grammar is None:
-        try_list = [('2.0',Y20),('1.1',Y11),('1.0',Y10)]
-    elif grammar == '1.0':
-        try_list = [('1.0',Y10)]
-    elif grammar == '1.1':
-        try_list = [('1.1',Y11)]
-    elif grammar == '2.0':
-        try_list = [('2.0',Y20)]
-    elif grammar == 'STAR2':
-        try_list = [('STAR2',YST)]
-    else:
-        raise AttributeError('Unknown STAR/CIF grammar requested, %s' % repr( grammar ))
-    if isinstance(filename,(unicode,str)):
-        # create an absolute URL
-        relpath = urlparse(filename)
-        if len(relpath.scheme) <= 1:
-            if not os.path.isabs(filename):
-                fullpath = os.path.join(os.getcwd(),filename)
-            else:
-                fullpath = filename
-            if have_pathlib:  # Python > 3.4
-                my_uri = Path(fullpath).as_uri()
-            else:     # works on Linux/Mac only
-                newrel = list(relpath)
-                newrel[0] = "file"
-                newrel[2] = fullpath
-                my_uri = urlunparse(newrel)
-        else:
-            my_uri = urlunparse(relpath)
-        # print("Full URL is: " + my_uri)
-        filestream = urlopen(my_uri)
-        try:
-            text = filestream.read().decode('utf-8-sig')
-        except UnicodeDecodeError:
-            if permissive:
-                text = filestream.read().decode('latin1')
-                print("WARNING: %s violates standard (latin1 encoding instead of UTF8)." % filename)
-            else:
-                raise StarError("%s: bad encoding (must be utf8 or ascii)" % filename)
-        filestream.close()
-    else:
-        filestream = filename   #already opened for us
-        text = filestream.read()
-        if not isinstance(text,unicode):
-            try:
-                text = text.decode('utf-8-sig')  #CIF is always ascii/utf8
-            except UnicodeDecodeError:
-                if permissive:
-                    text = filestream.read().decode('latin1')
-                    print("WARNING: text violates CIF standard (latin1 encoding instead of UTF8)")
-                else:
-                    raise StarError("Bad input encoding (must be utf8 or ascii)")
-        my_uri = ""
-    if not text:      # empty file, return empty block
-        return prepared.set_uri(my_uri)
-    # filter out non-ASCII characters in CBF files if required.  We assume
-    # that the binary is enclosed in a fixed string that occurs
-    # nowhere else.
-    if CBF:
-       text_bits  = text.split("-BINARY-FORMAT-SECTION-")
-       text = text_bits[0]
-       for section in range(2,len(text_bits),2):
-           text = text+" (binary omitted)"+text_bits[section]
-    # we recognise ctrl-Z as end of file
-    endoffile = text.find(chr(26))
-    if endoffile >= 0:
-        text = text[:endoffile]
-    split = text.split('\n')
-    if maxlength > 0:
-        toolong = [a for a in split if len(a)>maxlength]
-        if toolong:
-            pos = split.index(toolong[0])
-            raise StarError( 'Line %d contains more than %d characters' % (pos+1,maxlength))
-    # honour the header string
-    if text[:10] != r"#\#CIF_2.0" and ('2.0',Y20) in try_list:
-        try_list.remove(('2.0',Y20),)
-        if not try_list:
-            raise StarError('File %s missing CIF2.0 header' % (filename))
-    for grammar_name,Y in try_list:
-       if scantype == 'standard' or grammar_name in ['2.0','STAR2']:
-            parser = Y.StarParser(Y.StarParserScanner(text))
-       else:
-            parser = Y.StarParser(Y.yappsrt.Scanner(None,[],text,scantype='flex'))
-       # handle encoding switch
-       if grammar_name in ['2.0','STAR2']:
-           prepared.set_characterset('unicode')
-       else:
-           prepared.set_characterset('ascii')
-       proto_star = None
-       try:
-           proto_star = getattr(parser,"input")(prepared)
-       except Y.yappsrt.YappsSyntaxError as e:
-           input = parser._scanner.input
-           Y.yappsrt.print_error(input, e, parser._scanner)
-       except Y.yappsrt.NoMoreTokens:
-           print('Could not complete parsing; stopped around here:',file=sys.stderr)
-           print(parser._scanner,file=sys.stderr)
-       except ValueError:
-           print('Unexpected error:')
-           import traceback
-           traceback.print_exc()
-       if proto_star is not None:
-           proto_star.set_grammar(grammar_name)   #remember for output
-           break
-    if proto_star is None:
-        errorstring = 'Syntax error in input file: last value parsed was %s' % Y.lastval
-        errorstring = errorstring + '\nParser status: %s' % repr( parser._scanner )
-        raise StarError( errorstring)
-    # set visibility correctly
-    proto_star.scoping = 'dictionary'
-    proto_star.set_uri(my_uri)
-    proto_star.scoping = save_scoping
-    return proto_star
-
-def get_dim(dataitem,current=0,packlen=0):
-    zerotypes = [int, float, str]
-    if type(dataitem) in zerotypes:
-        return current, packlen
-    if not dataitem.__class__ == ().__class__ and \
-       not dataitem.__class__ == [].__class__:
-       return current, packlen
-    elif len(dataitem)>0:
-    #    print "Get_dim: %d: %s" % (current,`dataitem`)
-        return get_dim(dataitem[0],current+1,len(dataitem))
-    else: return current+1,0
-
-def apply_line_folding(instring,minwraplength=60,maxwraplength=80):
-    """Insert line folding characters into instring between min/max wraplength"""
-    # first check that we need to do this
-    lines = instring.split('\n')
-    line_len = [len(l) for l in lines]
-    if max(line_len) < maxwraplength and re.match("\\[ \v\t\f]*\n",instring) is None:
-        return instring
-    outstring = "\\\n"   #header
-    for l in lines:
-        if len(l) < maxwraplength:
-            outstring = outstring + l
-            if len(l) > 0 and l[-1]=='\\': #who'da thunk it?  A line ending with a backslash
-                    outstring = outstring + "\\\n"  #
-            outstring = outstring + "\n"  #  put back the split character
-        else:
-            current_bit = l
-            while len(current_bit) > maxwraplength:
-                space_pos = re.search('[ \v\f\t]+',current_bit[minwraplength:])
-                if space_pos is not None and space_pos.start()<maxwraplength-1:
-                    outstring = outstring + current_bit[:minwraplength+space_pos.start()] + "\\\n"
-                    current_bit = current_bit[minwraplength+space_pos.start():]
-                else:    #just blindly insert
-                    outstring = outstring + current_bit[:maxwraplength-1] + "\\\n"
-                    current_bit = current_bit[maxwraplength-1:]
-            outstring = outstring + current_bit
-            if current_bit[-1] == '\\':  #a backslash just happens to be here
-                outstring = outstring + "\\\n"
-            outstring = outstring + '\n'
-    outstring = outstring[:-1]  #remove final newline
-    return outstring
-
-def remove_line_folding(instring):
-    """Remove line folding from instring"""
-    if re.match(r"\\[ \v\t\f]*" +"\n",instring) is not None:
-        return re.sub(r"\\[ \v\t\f]*$" + "\n?","",instring,flags=re.M)
-    else:
-        return instring
-
-def apply_line_prefix(instring,prefix):
-    """Prefix every line in instring with prefix"""
-    if prefix[0] != ";" and "\\" not in prefix:
-        header = re.match(r"(\\[ \v\t\f]*" +"\n)",instring)
-        if header is not None:
-            print('Found line folded string for prefixing...')
-            not_header = instring[header.end():]
-            outstring = prefix + "\\\\\n" + prefix
-        else:
-            print('No folding in input string...')
-            not_header = instring
-            outstring = prefix + "\\\n" + prefix
-        outstring = outstring + not_header.replace("\n","\n"+prefix)
-        return outstring
-    raise StarError("Requested prefix starts with semicolon or contains a backslash: " + prefix)
-
-def remove_line_prefix(instring):
-    """Remove prefix from every line if present"""
-    prefix_match = re.match("(?P<prefix>[^;\\\n][^\n\\\\]+)(?P<folding>\\\\{1,2}[ \t\v\f]*\n)",instring)
-    if prefix_match is not None:
-        prefix_text = prefix_match.group('prefix')
-        print('Found prefix %s' % prefix_text)
-        prefix_end = prefix_match.end('folding')
-        # keep any line folding instructions
-        if prefix_match.group('folding')[:2]=='\\\\':  #two backslashes
-            outstring = instring[prefix_match.end('folding')-1:].replace("\n"+prefix_text,"\n")
-            return "\\" + outstring  #keep line folding first line
-        else:
-            outstring = instring[prefix_match.end('folding')-1:].replace("\n"+prefix_text,"\n")
-            return outstring[1:]   #drop first line ending, no longer necessary
-    else:
-        return instring
-
-
-def listify(item):
-    if isinstance(item,unicode): return [item]
-    else: return item
-
-#Transpose the list of lists passed to us
-def transpose(base_list):
-    new_lofl = []
-    full_length = len(base_list)
-    opt_range = range(full_length)
-    for i in range(len(base_list[0])):
-       new_packet = []
-       for j in opt_range:
-          new_packet.append(base_list[j][i])
-       new_lofl.append(new_packet)
-    return new_lofl
-
-# This routine optimised to return as quickly as possible
-# as it is called a lot.
-def not_none(itemlist):
-    """Return true only if no values of None are present"""
-    if itemlist is None:
-        return False
-    if not isinstance(itemlist,(tuple,list)):
-        return True
-    for x in itemlist:
-       if not not_none(x): return False
-    return True
-
-
-def check_stringiness(data):
-   """Check that the contents of data are all strings"""
-   if not hasattr(data,'dtype'):   #so not Numpy
-       from numbers import Number
-       if isinstance(data,Number): return False
-       elif isinstance(data,(unicode,str)): return True
-       elif data is None:return False  #should be data are None :)
-       else:
-           for one_item in data:
-               if not check_stringiness(one_item): return False
-           return True   #all must be strings
-   else:   #numerical python
-       import numpy
-       if data.ndim == 0:    #a bare value
-           if data.dtype.kind in ['S','U']: return True
-           else: return False
-       else:
-           for one_item in numpy.nditer(data):
-               print('numpy data: ' + repr( one_item ))
-               if not check_stringiness(one_item): return False
-           return True
-
-def process_template(template_file):
-    """Process a template datafile to formatting instructions"""
-    template_as_cif = StarFile(template_file,grammar="2.0").first_block()
-    if isinstance(template_file,(unicode,str)):
-        template_string = open(template_file).read()
-    else:   #a StringIO object
-        template_file.seek(0)   #reset
-        template_string = template_file.read()
-    #template_as_lines = template_string.split("\n")
-    #template_as_lines = [l for l in template_as_lines if len(l)>0 and l[0]!='#']
-    #template_as_lines = [l for l in template_as_lines if l.split()[0] != 'loop_']
-    #template_full_lines = dict([(l.split()[0],l) for l in template_as_lines if len(l.split())>0])
-    form_hints = []   #ordered array of hint dictionaries
-    find_indent = "^ +"
-    for item in template_as_cif.item_order:  #order of input
-        if not isinstance(item,int):    #not nested
-            hint_dict = {"dataname":item}
-            # find the line in the file
-            start_pos = re.search("(^[ \t]*(?P<name>" + item + ")[ \t\n]+)(?P<spec>([\\S]+)|(^;))",template_string,re.I|re.M)
-            if start_pos.group("spec") != None:
-                spec_pos = start_pos.start("spec")-start_pos.start(0)
-                spec_char = template_string[start_pos.start("spec"):start_pos.start("spec")+3]
-                if spec_char[0] in '\'";':
-                    hint_dict.update({"delimiter":spec_char[0]})
-                    if spec_char == '"""' or spec_char == "'''":
-                        hint_dict.update({"delimiter":spec_char})
-                if spec_char[0] != ";":   #so we need to work out the column number
-                    hint_dict.update({"column":spec_pos})
-                else:                  #need to put in the carriage return
-                    hint_dict.update({"delimiter":"\n;"})
-                    # can we format the text?
-                    text_val = template_as_cif[item]
-                    hint_dict["reformat"] = "\n\t" in text_val or "\n  " in text_val
-                    if hint_dict["reformat"]:   #find the indentation
-                        p = re.search(find_indent,text_val,re.M)
-                        if p.group() is not None:
-                            hint_dict["reformat_indent"]=p.end() - p.start()
-                if start_pos.group('name') != None:
-                    name_pos = start_pos.start('name') - start_pos.start(0)
-                    hint_dict.update({"name_pos":name_pos})
-            #print '%s: %s' % (item,`hint_dict`)
-            form_hints.append(hint_dict)
-        else:           #loop block
-            testnames = template_as_cif.loops[item]
-            total_items = len(template_as_cif.loops[item])
-            testname = testnames[0]
-            #find the loop spec line in the file
-            loop_regex = "(^[ \t]*(?P<loop>loop_)[ \t\n\r]+(?P<name>" + testname + ")([ \t\n\r]+_[\\S]+){%d}[ \t]*$(?P<packet>(.(?!_loop|_[\\S]+))*))" % (total_items - 1)
-            loop_line = re.search(loop_regex,template_string,re.I|re.M|re.S)
-            loop_so_far = loop_line.end()
-            packet_text = loop_line.group('packet')
-            loop_indent = loop_line.start('loop') - loop_line.start(0)
-            form_hints.append({"dataname":'loop','name_pos':loop_indent})
-            packet_regex = "[ \t]*(?P<all>(?P<sqqq>'''([^\n\r\f']*)''')|(?P<sq>'([^\n\r\f']*)'+)|(?P<dq>\"([^\n\r\"]*)\"+)|(?P<none>[^\\s]+))"
-            packet_pos = re.finditer(packet_regex,packet_text)
-            line_end_pos = re.finditer("^",packet_text,re.M)
-            next_end = next(line_end_pos).end()
-            last_end = next_end
-            for loopname in testnames:
-                #find the name in the file for name pos
-                name_regex = "(^[ \t]*(?P<name>" + loopname + "))"
-                name_match = re.search(name_regex,template_string,re.I|re.M|re.S)
-                loop_name_indent = name_match.start('name')-name_match.start(0)
-                hint_dict = {"dataname":loopname,"name_pos":loop_name_indent}
-                #find the value
-                thismatch = next(packet_pos)
-                while thismatch.start('all') > next_end:
-                    try:
-                        last_end = next_end
-                        next_end = next(line_end_pos).start()
-                        print('next end %d' % next_end)
-                    except StopIteration:
-                        break
-                print('Start %d, last_end %d' % (thismatch.start('all'),last_end))
-                col_pos = thismatch.start('all') - last_end + 1
-                if thismatch.group('none') is None:
-                    if thismatch.group('sqqq') is not None:
-                        hint_dict.update({'delimiter':"'''"})
-                    else:
-                        hint_dict.update({'delimiter':thismatch.groups()[0][0]})
-                hint_dict.update({'column':col_pos})
-                print('%s: %s' % (loopname,repr( hint_dict )))
-                form_hints.append(hint_dict)
-    return form_hints
-
-
-#No documentation flags
-
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+__copyright = """
+PYCIFRW License Agreement (Python License, Version 2)
+-----------------------------------------------------
+
+1. This LICENSE AGREEMENT is between the Australian Nuclear Science
+and Technology Organisation ("ANSTO"), and the Individual or
+Organization ("Licensee") accessing and otherwise using this software
+("PyCIFRW") in source or binary form and its associated documentation.
+
+2. Subject to the terms and conditions of this License Agreement,
+ANSTO hereby grants Licensee a nonexclusive, royalty-free, world-wide
+license to reproduce, analyze, test, perform and/or display publicly,
+prepare derivative works, distribute, and otherwise use PyCIFRW alone
+or in any derivative version, provided, however, that this License
+Agreement and ANSTO's notice of copyright, i.e., "Copyright (c)
+2001-2014 ANSTO; All Rights Reserved" are retained in PyCIFRW alone or
+in any derivative version prepared by Licensee.
+
+3. In the event Licensee prepares a derivative work that is based on
+or incorporates PyCIFRW or any part thereof, and wants to make the
+derivative work available to others as provided herein, then Licensee
+hereby agrees to include in any such work a brief summary of the
+changes made to PyCIFRW.
+
+4. ANSTO is making PyCIFRW available to Licensee on an "AS IS"
+basis. ANSTO MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
+IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, ANSTO MAKES NO AND
+DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
+FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYCIFRW WILL NOT
+INFRINGE ANY THIRD PARTY RIGHTS.
+
+5. ANSTO SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYCIFRW
+FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A
+RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYCIFRW, OR ANY
+DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
+
+6. This License Agreement will automatically terminate upon a material
+breach of its terms and conditions.
+
+7. Nothing in this License Agreement shall be deemed to create any
+relationship of agency, partnership, or joint venture between ANSTO
+and Licensee. This License Agreement does not grant permission to use
+ANSTO trademarks or trade name in a trademark sense to endorse or
+promote products or services of Licensee, or any third party.
+
+8. By copying, installing or otherwise using PyCIFRW, Licensee agrees
+to be bound by the terms and conditions of this License Agreement.
+
+"""
+
+
+import sys
+
+# Python 2,3 compatibility
+try:
+    from urllib import urlopen         # for arbitrary opening
+    from urlparse import urlparse, urlunparse
+except:
+    from urllib.request import urlopen
+    from urllib.parse import urlparse,urlunparse
+import re,os
+import textwrap
+
+try:
+    from StringIO import StringIO #not cStringIO as we cannot subclass
+except ImportError:
+    from io import StringIO
+
+if isinstance(u"abc",str):   #Python 3
+    unicode = str
+    long = int
+
+try:
+    import numpy
+    have_numpy = True
+except ImportError:
+    have_numpy = False
+
+# Windows paths require special handling. pathlib is available from
+# Python 3.4. For earlier Python versions dictionary import will not work
+# on Windows
+try:
+    from pathlib import Path
+    have_pathlib = True
+except:
+    have_pathlib = False
+
+class StarList(list):
+    def __getitem__(self,args):
+        if isinstance(args,(int,slice)):
+            return super(StarList,self).__getitem__(args)
+        elif isinstance(args,tuple) and len(args)>1:   #extended comma notation
+            return super(StarList,self).__getitem__(args[0]).__getitem__(args[1:])
+        else:
+            return super(StarList,self).__getitem__(args[0])
+
+    def __str__(self):
+        return "SL("+super(StarList,self).__str__() + ")"
+
+class StarDict(dict):
+    pass
+
+
+class LoopBlock(object):
+    def __init__(self,parent_block,dataname):
+        self.loop_no = parent_block.FindLoop(dataname)
+        if self.loop_no < 0:
+            raise KeyError('%s is not in a loop structure' % dataname)
+        self.parent_block = parent_block
+
+    def keys(self):
+        return self.parent_block.loops[self.loop_no]
+
+    def values(self):
+        return [self.parent_block[a] for a in self.keys()]
+
+    #Avoid iterator even though that is Python3-esque
+    def items(self):
+        return list(zip(self.keys(),self.values()))
+
+    def __getitem__(self,dataname):
+        if isinstance(dataname,int):   #a packet request
+            return self.GetPacket(dataname)
+        if dataname in self.keys():
+            return self.parent_block[dataname]
+        else:
+            raise KeyError('%s not in loop block' % dataname)
+
+    def __setitem__(self,dataname,value):
+        self.parent_block[dataname] = value
+        self.parent_block.AddLoopName(self.keys()[0],dataname)
+
+    def __contains__(self,key):
+        return key in self.parent_block.loops[self.loop_no]
+
+    def has_key(self,key):
+        return key in self
+
+    def __iter__(self):
+        packet_list = zip(*self.values())
+        names = self.keys()
+        for p in packet_list:
+            r = StarPacket(p)
+            for n in range(len(names)):
+                setattr(r,names[n].lower(),r[n])
+            yield r
+
+    # for compatibility
+    def __getattr__(self,attname):
+        return getattr(self.parent_block,attname)
+
+    def load_iter(self,coords=[]):
+        count = 0        #to create packet index
+        while not self.popout:
+            # ok, we have a new packet:  append a list to our subloops
+            for aloop in self.loops:
+                aloop.new_enclosing_packet()
+            for iname in self.item_order:
+                if isinstance(iname,LoopBlock):       #into a nested loop
+                    for subitems in iname.load_iter(coords=coords+[count]):
+                        # print 'Yielding %s' % `subitems`
+                        yield subitems
+                    # print 'End of internal loop'
+                else:
+                    if self.dimension == 0:
+                        # print 'Yielding %s' % `self[iname]`
+                        yield self,self[iname]
+                    else:
+                        backval = self.block[iname]
+                        for i in range(len(coords)):
+                           # print 'backval, coords: %s, %s' % (`backval`,`coords`)
+                           backval = backval[coords[i]]
+                        yield self,backval
+            count = count + 1      # count packets
+        self.popout = False        # reinitialise
+        # print 'Finished iterating'
+        yield self,'###Blank###'     #this value should never be used
+
+    # an experimental fast iterator for level-1 loops (ie CIF)
+    def fast_load_iter(self):
+        targets = map(lambda a:self.block[a],self.item_order)
+        while targets:
+            for target in targets:
+                yield self,target
+
+    # Add another list of the required shape to take into account a new outer packet
+    def new_enclosing_packet(self):
+        if self.dimension > 1:      #otherwise have a top-level list
+            for iname in self.keys():  #includes lower levels
+                target_list = self[iname]
+                for i in range(3,self.dimension): #dim 2 upwards are lists of lists of...
+                    target_list = target_list[-1]
+                target_list.append([])
+                # print '%s now %s' % (iname,`self[iname]`)
+
+    def recursive_iter(self,dict_so_far={},coord=[]):
+        # print "Recursive iter: coord %s, keys %s, dim %d" % (`coord`,`self.block.keys()`,self.dimension)
+        my_length = 0
+        top_items = self.block.items()
+        top_values = self.block.values()       #same order as items
+        drill_values = self.block.values()
+        for dimup in range(0,self.dimension):  #look higher in the tree
+            if len(drill_values)>0:            #this block has values
+                drill_values=drill_values[0]   #drill in
+            else:
+                raise StarError("Malformed loop packet %s" % repr( top_items[0] ))
+        my_length = len(drill_values[0])       #length of 'string' entry
+        if self.dimension == 0:                #top level
+            for aloop in self.loops:
+                for apacket in aloop.recursive_iter():
+                    # print "Recursive yielding %s" % repr( dict(top_items + apacket.items()) )
+                    prep_yield = StarPacket(top_values+apacket.values())  #straight list
+                    for name,value in top_items + apacket.items():
+                        setattr(prep_yield,name,value)
+                    yield prep_yield
+        else:                                  #in some loop
+            for i in range(my_length):
+                kvpairs = map(lambda a:(a,self.coord_to_group(a,coord)[i]),self.block.keys())
+                kvvals = map(lambda a:a[1],kvpairs)   #just values
+                # print "Recursive kvpairs at %d: %s" % (i,repr( kvpairs ))
+                if self.loops:
+                  for aloop in self.loops:
+                    for apacket in aloop.recursive_iter(coord=coord+[i]):
+                        # print "Recursive yielding %s" % repr( dict(kvpairs + apacket.items()) )
+                        prep_yield = StarPacket(kvvals+apacket.values())
+                        for name,value in kvpairs + apacket.items():
+                            setattr(prep_yield,name,value)
+                        yield prep_yield
+                else:           # we're at the bottom of the tree
+                    # print "Recursive yielding %s" % repr( dict(kvpairs) )
+                    prep_yield = StarPacket(kvvals)
+                    for name,value in kvpairs:
+                        setattr(prep_yield,name,value)
+                    yield prep_yield
+
+    # small function to use the coordinates.
+    def coord_to_group(self,dataname,coords):
+          if not isinstance(dataname,unicode):
+             return dataname     # flag inner loop processing
+          newm = self[dataname]          # newm must be a list or tuple
+          for c in coords:
+              # print "Coord_to_group: %s ->" % (repr( newm )),
+              newm = newm[c]
+              # print repr( newm )
+          return newm
+
+    def flat_iterator(self):
+            my_length = 0
+            top_keys = self.block.keys()
+            if len(top_keys)>0:
+                my_length = len(self.block[top_keys[0]])
+            for pack_no in range(my_length):
+                yield(self.collapse(pack_no))
+
+
+    def RemoveItem(self,itemname):
+        """Remove `itemname` from the block."""
+        # first check any loops
+        loop_no = self.FindLoop(itemname)
+        testkey = itemname.lower()
+        if testkey in self:
+            del self.block[testkey]
+            del self.true_case[testkey]
+            # now remove from loop
+            if loop_no >= 0:
+                self.loops[loop_no].remove(testkey)
+                if len(self.loops[loop_no])==0:
+                    del self.loops[loop_no]
+                    self.item_order.remove(loop_no)
+            else:  #will appear in order list
+                self.item_order.remove(testkey)
+
+    def RemoveLoopItem(self,itemname):
+        """*Deprecated*. Use `RemoveItem` instead"""
+        self.RemoveItem(itemname)
+
+    def GetLoop(self,keyname):
+        """Return a `StarFile.LoopBlock` object constructed from the loop containing `keyname`.
+        `keyname` is only significant as a way to specify the loop."""
+        return LoopBlock(self,keyname)
+
+    def GetPacket(self,index):
+        thispack = StarPacket([])
+        for myitem in self.parent_block.loops[self.loop_no]:
+            thispack.append(self[myitem][index])
+            setattr(thispack,myitem,thispack[-1])
+        return thispack
+
+    def AddPacket(self,packet):
+        for myitem in self.parent_block.loops[self.loop_no]:
+            old_values = self.parent_block[myitem]
+            old_values.append(packet.__getattribute__(myitem))
+            self.parent_block[myitem] = old_values
+
+    def GetItemOrder(self):
+        """Return a list of datanames in this `LoopBlock` in the order that they will be
+        printed"""
+        return self.parent_block.loops[self.loop_no][:]
+
+
+    def ChangeItemOrder(self,itemname,newpos):
+        """Change the position at which `itemname` appears when printing out to `newpos`."""
+        self.parent_block.loops[self.loop_no].remove(itemname.lower())
+        self.parent_block.loops[self.loop_no].insert(newpos,itemname.lower())
+
+    def GetItemPosition(self,itemname):
+        """A utility function to get the numerical order in the printout
+        of `itemname`.  An item has coordinate `(loop_no,pos)` with
+        the top level having a `loop_no` of -1.  If an integer is passed to
+        the routine then it will return the position of the loop
+        referenced by that number."""
+        if isinstance(itemname,int):
+            # return loop position
+            return (-1, self.item_order.index(itemname))
+        if not itemname in self:
+            raise ValueError('No such dataname %s' % itemname)
+        testname = itemname.lower()
+        if testname in self.item_order:
+            return (-1,self.item_order.index(testname))
+        loop_no = self.FindLoop(testname)
+        loop_pos = self.loops[loop_no].index(testname)
+        return loop_no,loop_pos
+
+    def GetLoopNames(self,keyname):
+        if keyname in self:
+            return self.keys()
+        for aloop in self.loops:
+            try:
+                return aloop.GetLoopNames(keyname)
+            except KeyError:
+                pass
+        raise KeyError('Item does not exist')
+
+    def GetLoopNames(self,keyname):
+        """Return all datanames appearing together with `keyname`"""
+        loop_no = self.FindLoop(keyname)
+        if loop_no >= 0:
+            return self.loops[loop_no]
+        else:
+            raise KeyError('%s is not in any loop' % keyname)
+
+    def AddToLoop(self,dataname,loopdata):
+        thisloop = self.GetLoop(dataname)
+        for itemname,itemvalue in loopdata.items():
+            thisloop[itemname] = itemvalue
+
+    def AddToLoop(self,dataname,loopdata):
+        """*Deprecated*. Use `AddItem` followed by calls to `AddLoopName`.
+
+        Add multiple columns to the loop containing `dataname`. `loopdata` is a
+        collection of (key,value) pairs, where `key` is the new dataname and `value`
+        is a list of values for that dataname"""
+        self.update(loopdata)
+        for one_name in loopdata:
+            self.AddLoopName(dataname,one_name)
+
+
+class StarBlock(object):
+    def __init__(self,data = (), maxoutlength=2048, wraplength=80, overwrite=True,
+                 characterset='ascii',maxnamelength=-1):
+        self.block = {}    #the actual data storage (lower case keys)
+        self.loops = {}    #each loop is indexed by a number and contains a list of datanames
+        self.item_order = []  #lower case, loops referenced by integer
+        self.formatting_hints = {}
+        self.true_case = {} #transform lower case to supplied case
+        self.provide_value = False  #prefer string version always
+        self.dictionary = None      #DDLm dictionary
+        self.popout = False         #used during load iteration
+        self.curitem = -1           #used during iteration
+        self.cache_vals = True      #store all calculated values
+        self.maxoutlength = maxoutlength
+        self.setmaxnamelength(maxnamelength)  #to enforce CIF limit of 75 characters
+        self.set_characterset(characterset)   #to check input names
+        self.wraplength = wraplength
+        self.overwrite = overwrite
+        self.string_delimiters = ["'",'"',"\n;"]   #universal CIF set
+        self.list_delimiter = "  "                 #CIF2 default
+        self.wrapper = textwrap.TextWrapper()
+        if isinstance(data,(tuple,list)):
+            for item in data:
+                self.AddLoopItem(item)
+        elif isinstance(data,StarBlock):
+            self.block = data.block.copy()
+            self.item_order = data.item_order[:]
+            self.true_case = data.true_case.copy()
+            # loops as well
+            self.loops = data.loops.copy()
+
+    def setmaxnamelength(self,maxlength):
+        """Set the maximum allowable dataname length (-1 for no check)"""
+        self.maxnamelength = maxlength
+        if maxlength > 0:
+            bad_names = [a for a in self.keys() if len(a)>self.maxnamelength]
+            if len(bad_names)>0:
+                raise StarError('Datanames too long: ' + repr( bad_names ))
+
+    def set_characterset(self,characterset):
+        """Set the characterset for checking datanames: may be `ascii` or `unicode`"""
+        self.characterset = characterset
+        if characterset == 'ascii':
+            self.char_check = re.compile("[][ \n\r\t!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~\"#$';_-]+",re.M)
+        elif characterset == 'unicode':
+            if sys.maxunicode < 1114111:
+               self.char_check = re.compile(u"[][ \n\r\t!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~\"#$';_\u00A0-\uD7FF\uE000-\uFDCF\uFDF0-\uFFFD-]+",re.M)
+            else:
+               self.char_check = re.compile(u"[][ \n\r\t!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~\"#$';_\u00A0-\uD7FF\uE000-\uFDCF\uFDF0-\uFFFD\U00010000-\U0010FFFD-]+",re.M)
+
+    def __str__(self):
+        return self.printsection()
+
+    def __setitem__(self,key,value):
+        if key == "saves":
+            raise StarError("""Setting the saves key is deprecated. Add the save block to
+    an enclosing block collection (e.g. CIF or STAR file) with this block as child""")
+        self.AddItem(key,value)
+
+    def __getitem__(self,key):
+        if key == "saves":
+            raise StarError("""The saves key is deprecated. Access the save block from
+    the enclosing block collection (e.g. CIF or STAR file object)""")
+        try:
+           rawitem,is_value = self.GetFullItemValue(key)
+        except KeyError:
+           if self.dictionary:
+               # send the dictionary the required key and a pointer to us
+               try:
+                   new_value = self.dictionary.derive_item(key,self,store_value=self.cache_vals,allow_defaults=False)
+               except StarDerivationFailure:   #try now with defaults included
+                   try:
+                       new_value = self.dictionary.derive_item(key,self,store_value=self.cache_vals,allow_defaults=True)
+                   except StarDerivationFailure as s:
+                       print("In StarBlock.__getitem__, " + repr(s))
+                       raise KeyError('No such item: %s' % key)
+               print('Set %s to derived value %s' % (key, repr(new_value)))
+               return new_value
+           else:
+               raise KeyError('No such item: %s' % key)
+        # we now have an item, we can try to convert it to a number if that is appropriate
+        # note numpy values are never stored but are converted to lists
+        if not self.dictionary or not key in self.dictionary: return rawitem
+        print('%s: is_value %s provide_value %s value %s' % (key,repr( is_value ),repr( self.provide_value ),repr( rawitem )))
+        if is_value:
+            if self.provide_value: return rawitem
+            else:
+               print('Turning %s into string' % repr( rawitem ))
+               return self.convert_to_string(key)
+        else:    # a string
+            if self.provide_value and ((not isinstance(rawitem,list) and rawitem != '?' and rawitem != ".") or \
+                                      (isinstance(rawitem,list) and '?' not in rawitem and '.' not in rawitem)):
+                return self.dictionary.change_type(key,rawitem)
+            elif self.provide_value: # catch the question marks
+                do_calculate = False
+                if isinstance(rawitem,(list,tuple)):
+                    known = [a for a in rawitem if a != '?']
+                    if len(known) == 0:   #all questions
+                        do_calculate = True
+                elif rawitem == '?':
+                        do_calculate = True
+                if do_calculate:
+                   # remove old value
+                   del self[key]
+                   try:
+                       new_value = self.dictionary.derive_item(key,self,store_value=True,allow_defaults=False)
+                   except StarDerivationFailure as s:
+                       try:
+                           new_value = self.dictionary.derive_item(key,self,store_value=True,allow_defaults=True)
+                       except StarDerivationFailure as s:
+
+                           print("Could not turn %s into a value:" + repr(s))
+                           return rawitem
+                   else:
+                       print('Set %s to derived value %s' % (key, repr( new_value )))
+                       return new_value
+            return rawitem   #can't do anything
+
+    def __delitem__(self,key):
+        self.RemoveItem(key)
+
+    def __len__(self):
+        blen = len(self.block)
+        return blen
+
+    def __nonzero__(self):
+        if self.__len__() > 0: return 1
+        return 0
+
+    # keys returns all internal keys
+    def keys(self):
+        return list(self.block.keys())    #always lower case
+
+    def values(self):
+        return [self[a] for a in self.keys()]
+
+    def items(self):
+        return list(zip(self.keys(),self.values()))
+
+    def __contains__(self,key):
+        if isinstance(key,(unicode,str)) and key.lower() in self.keys():
+            return True
+        return False
+
+    def has_key(self,key):
+        return key in self
+
+    def has_key_or_alias(self,key):
+        """Check if a dataname or alias is available in the block"""
+        initial_test = key in self
+        if initial_test: return True
+        elif self.dictionary:
+            aliases = [k for k in self.dictionary.alias_table.get(key,[]) if self.has_key(k)]
+            if len(aliases)>0:
+               return True
+        return False
+
+    def get(self,key,default=None):
+        if key in self:
+            retval = self.__getitem__(key)
+        else:
+            retval = default
+        return retval
+
+    def clear(self):
+        self.block = {}
+        self.loops = {}
+        self.item_order = []
+        self.true_case = {}
+
+    # doesn't appear to work
+    def copy(self):
+        newcopy = StarBlock()
+        newcopy.block = self.block.copy()
+        newcopy.loops = []
+        newcopy.item_order = self.item_order[:]
+        newcopy.true_case = self.true_case.copy()
+        newcopy.loops = self.loops.copy()
+    #    return self.copy.im_class(newcopy)   #catch inheritance
+        return newcopy
+
+    def update(self,adict):
+        for key in adict.keys():
+            self.AddItem(key,adict[key])
+
+    def GetItemPosition(self,itemname):
+        """A utility function to get the numerical order in the printout
+        of `itemname`.  An item has coordinate `(loop_no,pos)` with
+        the top level having a `loop_no` of -1.  If an integer is passed to
+        the routine then it will return the position of the loop
+        referenced by that number."""
+        if isinstance(itemname,int):
+            # return loop position
+            return (-1, self.item_order.index(itemname))
+        if not itemname in self:
+            raise ValueError('No such dataname %s' % itemname)
+        testname = itemname.lower()
+        if testname in self.item_order:
+            return (-1,self.item_order.index(testname))
+        loop_no = self.FindLoop(testname)
+        loop_pos = self.loops[loop_no].index(testname)
+        return loop_no,loop_pos
+
+    def ChangeItemOrder(self,itemname,newpos):
+        """Move the printout order of `itemname` to `newpos`. If `itemname` is
+        in a loop, `newpos` refers to the order within the loop."""
+        if isinstance(itemname,(unicode,str)):
+            true_name = itemname.lower()
+        else:
+            true_name = itemname
+        loopno = self.FindLoop(true_name)
+        if loopno < 0:  #top level
+            self.item_order.remove(true_name)
+            self.item_order.insert(newpos,true_name)
+        else:
+            self.loops[loopno].remove(true_name)
+            self.loops[loopno].insert(newpos,true_name)
+
+    def GetItemOrder(self):
+        """Return a list of datanames in the order in which they will be printed.  Loops are
+        referred to by numerical index"""
+        return self.item_order[:]
+
+    def AddItem(self,key,value,precheck=False):
+        """Add dataname `key` to block with value `value`.  `value` may be
+        a single value, a list or a tuple. If `precheck` is False (the default),
+        all values will be checked and converted to unicode strings as necessary. If
+        `precheck` is True, this checking is bypassed.  No checking is necessary
+        when values are read from a CIF file as they are already in correct form."""
+        if not isinstance(key,(unicode,str)):
+             raise TypeError('Star datanames are strings only (got %s)' % repr( key ))
+        key = unicode(key)    #everything is unicode internally
+        if not precheck:
+             self.check_data_name(key,self.maxnamelength)    # make sure no nasty characters
+        # check for overwriting
+        if key in self:
+             if not self.overwrite:
+                 raise StarError( 'Attempt to insert duplicate item name %s' % key)
+        if not precheck:   #need to sanitise
+            regval,empty_val = self.regularise_data(value)
+            pure_string = check_stringiness(regval)
+            self.check_item_value(regval)
+        else:
+            regval,empty_val = value,None
+            pure_string = True
+        # update ancillary information first
+        lower_key = key.lower()
+        if not lower_key in self and self.FindLoop(lower_key)<0:      #need to add to order
+            self.item_order.append(lower_key)
+        # always remove from our case table in case the case is different
+        try:
+            del self.true_case[lower_key]
+        except KeyError:
+            pass
+        self.true_case[lower_key] = key
+        if pure_string:
+            self.block.update({lower_key:[regval,empty_val]})
+        else:
+            self.block.update({lower_key:[empty_val,regval]})
+
+    def AddLoopItem(self,incomingdata,precheck=False,maxlength=-1):
+        """*Deprecated*. Use `AddItem` followed by `CreateLoop` if
+        necessary."""
+        # print "Received data %s" % `incomingdata`
+        # we accept tuples, strings, lists and dicts!!
+        # Direct insertion: we have a string-valued key, with an array
+        # of values -> single-item into our loop
+        if isinstance(incomingdata[0],(tuple,list)):
+           # a whole loop
+           keyvallist = zip(incomingdata[0],incomingdata[1])
+           for key,value in keyvallist:
+               self.AddItem(key,value)
+           self.CreateLoop(incomingdata[0])
+        elif not isinstance(incomingdata[0],(unicode,str)):
+             raise TypeError('Star datanames are strings only (got %s)' % repr( incomingdata[0] ))
+        else:
+            self.AddItem(incomingdata[0],incomingdata[1])
+
+    def check_data_name(self,dataname,maxlength=-1):
+        if maxlength > 0:
+            self.check_name_length(dataname,maxlength)
+        if dataname[0]!='_':
+            raise StarError( 'Dataname ' + dataname + ' does not begin with _')
+        if self.characterset=='ascii':
+            if len ([a for a in dataname if ord(a) < 33 or ord(a) > 126]) > 0:
+                raise StarError( 'Dataname ' + dataname + ' contains forbidden characters')
+        else:
+            # print 'Checking %s for unicode characterset conformance' % dataname
+            if len ([a for a in dataname if ord(a) < 33]) > 0:
+                raise StarError( 'Dataname ' + dataname + ' contains forbidden characters (below code point 33)')
+            if len ([a for a in dataname if ord(a) > 126 and ord(a) < 160]) > 0:
+                raise StarError( 'Dataname ' + dataname + ' contains forbidden characters (between code point 127-159)')
+            if len ([a for a in dataname if ord(a) > 0xD7FF and ord(a) < 0xE000]) > 0:
+                raise StarError( 'Dataname ' + dataname + ' contains unsupported characters (between U+D800 and U+E000)')
+            if len ([a for a in dataname if ord(a) > 0xFDCF and ord(a) < 0xFDF0]) > 0:
+                raise StarError( 'Dataname ' + dataname + ' contains unsupported characters (between U+FDD0 and U+FDEF)')
+            if len ([a for a in dataname if ord(a) == 0xFFFE or ord(a) == 0xFFFF]) > 0:
+                raise StarError( 'Dataname ' + dataname + ' contains unsupported characters (U+FFFE and/or U+FFFF)')
+            if len ([a for a in dataname if ord(a) > 0x10000 and (ord(a) & 0xE == 0xE)]) > 0:
+                print('%s fails' % dataname)
+                for a in dataname: print('%x' % ord(a),end="")
+                print()
+                raise StarError( u'Dataname ' + dataname + u' contains unsupported characters (U+xFFFE and/or U+xFFFF)')
+
+    def check_name_length(self,dataname,maxlength):
+        if len(dataname)>maxlength:
+            raise StarError( 'Dataname %s exceeds maximum length %d' % (dataname,maxlength))
+        return
+
+    def check_item_value(self,item):
+        test_item = item
+        if not isinstance(item,(list,dict,tuple)):
+           test_item = [item]         #single item list
+        def check_one (it):
+            if isinstance(it,unicode):
+                if it=='': return
+                me = self.char_check.match(it)
+                if not me:
+                    print("Fail value check: %s" % it)
+                    raise StarError('Bad character in %s' % it)
+                else:
+                    if me.span() != (0,len(it)):
+                        print("Fail value check, match only %d-%d in string %s" % (me.span()[0],me.span()[1],repr( it )))
+                        raise StarError('Data item "' + repr( it ) +  u'"... contains forbidden characters')
+        [check_one(a) for a in test_item]
+
+    def regularise_data(self,dataitem):
+        """Place dataitem into a list if necessary"""
+        from numbers import Number
+        if isinstance(dataitem,str):
+            return unicode(dataitem),None
+        if isinstance(dataitem,(Number,unicode,StarList,StarDict)):
+            return dataitem,None  #assume StarList/StarDict contain unicode if necessary
+        if isinstance(dataitem,(tuple,list)):
+            v,s = zip(*list([self.regularise_data(a) for a in dataitem]))
+            return list(v),list(s)
+            #return dataitem,[None]*len(dataitem)
+        # so try to make into a list
+        try:
+            regval = list(dataitem)
+        except TypeError as value:
+            raise StarError( str(dataitem) + ' is wrong type for data value\n' )
+        v,s = zip(*list([self.regularise_data(a) for a in regval]))
+        return list(v),list(s)
+
+    def RemoveItem(self,itemname):
+        """Remove `itemname` from the block."""
+        # first check any loops
+        loop_no = self.FindLoop(itemname)
+        testkey = itemname.lower()
+        if testkey in self:
+            del self.block[testkey]
+            del self.true_case[testkey]
+            # now remove from loop
+            if loop_no >= 0:
+                self.loops[loop_no].remove(testkey)
+                if len(self.loops[loop_no])==0:
+                    del self.loops[loop_no]
+                    self.item_order.remove(loop_no)
+            else:  #will appear in order list
+                self.item_order.remove(testkey)
+
+    def RemoveLoopItem(self,itemname):
+        """*Deprecated*. Use `RemoveItem` instead"""
+        self.RemoveItem(itemname)
+
+    def GetItemValue(self,itemname):
+        """Return value of `itemname`.  If `itemname` is looped, a list
+        of all values will be returned."""
+        return self.GetFullItemValue(itemname)[0]
+
+    def GetFullItemValue(self,itemname):
+        """Return the value associated with `itemname`, and a boolean flagging whether
+        (True) or not (False) it is in a form suitable for calculation.  False is
+        always returned for strings and `StarList` objects."""
+        try:
+            s,v = self.block[itemname.lower()]
+        except KeyError:
+            raise KeyError('Itemname %s not in datablock' % itemname)
+        # prefer string value unless all are None
+        # are we a looped value?
+        if not isinstance(s,(tuple,list)) or isinstance(s,StarList):
+            if not_none(s):
+                return s,False    #a string value
+            else:
+                return v,not isinstance(v,StarList)  #a StarList is not calculation-ready
+        elif not_none(s):
+            return s,False         #a list of string values
+        else:
+            if len(v)>0:
+                return v,not isinstance(v[0],StarList)
+            return v,True
+
+    def CreateLoop(self,datanames,order=-1,length_check=True):
+           """Create a loop in the datablock. `datanames` is a list of datanames that
+           together form a loop.  If length_check is True, they should have been initialised in the block
+           to have the same number of elements (possibly 0). If `order` is given,
+           the loop will appear at this position in the block when printing
+           out. A single-row loop will be created if the provided datanames are all
+           non-lists. A loop counts as a single position."""
+
+           if length_check:
+               # check lengths: these datanames should exist
+               listed_values = [a for a in datanames if isinstance(self[a],list) and not isinstance(self[a],StarList)]
+               if len(listed_values) == len(datanames):
+                   len_set = set([len(self[a]) for a in datanames])
+                   if len(len_set)>1:
+                       raise ValueError('Request to loop datanames %s with different lengths: %s' % (repr( datanames ),repr( len_set )))
+               elif len(listed_values) != 0:
+                   raise ValueError('Request to loop datanames where some are single values and some are not')
+               else:    #all are unlisted, turn into lists
+                   for d in datanames:
+                       self[d] = [self[d]]
+           # store as lower case
+           lc_datanames = [d.lower() for d in datanames]
+           # remove these datanames from all other loops
+           [self.loops[a].remove(b) for a in self.loops for b in lc_datanames if b in self.loops[a]]
+           # remove empty loops
+           empty_loops = [a for a in self.loops.keys() if len(self.loops[a])==0]
+           for a in empty_loops:
+               self.item_order.remove(a)
+               del self.loops[a]
+           if len(self.loops)>0:
+               loopno = max(self.loops.keys()) + 1
+           else:
+               loopno = 1
+           self.loops[loopno] = list(lc_datanames)
+           if order >= 0:
+               self.item_order.insert(order,loopno)
+           else:
+               self.item_order.append(loopno)
+           # remove these datanames from item ordering
+           self.item_order = [a for a in self.item_order if a not in lc_datanames]
+
+    def AddLoopName(self,oldname, newname):
+        """Add `newname` to the loop containing `oldname`. If it is already in the new loop, no
+        error is raised.  If `newname` is in a different loop, it is removed from that loop.
+        The number of values associated with `newname` must match the number of values associated
+        with all other columns of the new loop or a `ValueError` will be raised."""
+        lower_newname = newname.lower()
+        loop_no = self.FindLoop(oldname)
+        if loop_no < 0:
+            raise KeyError('%s not in loop' % oldname)
+        if lower_newname in self.loops[loop_no]:
+            return
+        # check length
+        old_provides = self.provide_value
+        self.provide_value = False
+        loop_len = len(self[oldname])
+        self.provide_value = old_provides
+        if len(self[newname]) != loop_len:
+            raise StarLengthError('Mismatch of loop column lengths for %s: should be %d' % (newname,loop_len))
+        # remove from any other loops
+        [self.loops[a].remove(lower_newname) for a in self.loops if lower_newname in self.loops[a]]
+        # and add to this loop
+        self.loops[loop_no].append(lower_newname)
+        # remove from item_order if present
+        try:
+            self.item_order.remove(lower_newname)
+        except ValueError:
+            pass
+
+    def FindLoop(self,keyname):
+        """Find the loop that contains `keyname` and return its numerical index or
+        -1 if not present. The numerical index can be used to refer to the loop in
+        other routines."""
+        loop_no = [a for a in self.loops.keys() if keyname.lower() in self.loops[a]]
+        if len(loop_no)>0:
+            return loop_no[0]
+        else:
+            return -1
+
+    def GetLoop(self,keyname):
+        """Return a `StarFile.LoopBlock` object constructed from the loop containing `keyname`.
+        `keyname` is only significant as a way to specify the loop."""
+        return LoopBlock(self,keyname)
+
+    def GetLoopNames(self,keyname):
+        if keyname in self:
+            return self.keys()
+        for aloop in self.loops:
+            try:
+                return aloop.GetLoopNames(keyname)
+            except KeyError:
+                pass
+        raise KeyError('Item does not exist')
+
+    def GetLoopNames(self,keyname):
+        """Return all datanames appearing together with `keyname`"""
+        loop_no = self.FindLoop(keyname)
+        if loop_no >= 0:
+            return self.loops[loop_no]
+        else:
+            raise KeyError('%s is not in any loop' % keyname)
+
+    def AddLoopName(self,oldname, newname):
+        """Add `newname` to the loop containing `oldname`. If it is already in the new loop, no
+        error is raised.  If `newname` is in a different loop, it is removed from that loop.
+        The number of values associated with `newname` must match the number of values associated
+        with all other columns of the new loop or a `ValueError` will be raised."""
+        lower_newname = newname.lower()
+        loop_no = self.FindLoop(oldname)
+        if loop_no < 0:
+            raise KeyError('%s not in loop' % oldname)
+        if lower_newname in self.loops[loop_no]:
+            return
+        # check length
+        old_provides = self.provide_value
+        self.provide_value = False
+        loop_len = len(self[oldname])
+        self.provide_value = old_provides
+        if len(self[newname]) != loop_len:
+            raise StarLengthError('Mismatch of loop column lengths for %s: should be %d' % (newname,loop_len))
+        # remove from any other loops
+        [self.loops[a].remove(lower_newname) for a in self.loops if lower_newname in self.loops[a]]
+        # and add to this loop
+        self.loops[loop_no].append(lower_newname)
+        # remove from item_order if present
+        try:
+            self.item_order.remove(lower_newname)
+        except ValueError:
+            pass
+
+    def AddToLoop(self,dataname,loopdata):
+        thisloop = self.GetLoop(dataname)
+        for itemname,itemvalue in loopdata.items():
+            thisloop[itemname] = itemvalue
+
+    def AddToLoop(self,dataname,loopdata):
+        """*Deprecated*. Use `AddItem` followed by calls to `AddLoopName`.
+
+        Add multiple columns to the loop containing `dataname`. `loopdata` is a
+        collection of (key,value) pairs, where `key` is the new dataname and `value`
+        is a list of values for that dataname"""
+        self.update(loopdata)
+        for one_name in loopdata:
+            self.AddLoopName(dataname,one_name)
+
+    def RemoveKeyedPacket(self,keyname,keyvalue):
+        """Remove the packet for which dataname `keyname` takes
+        value `keyvalue`.  Only the first such occurrence is
+        removed."""
+        packet_coord = list(self[keyname]).index(keyvalue)
+        loopnames = self.GetLoopNames(keyname)
+        for dataname in loopnames:
+            self.block[dataname][0] = list(self.block[dataname][0])
+            del self.block[dataname][0][packet_coord]
+            self.block[dataname][1] = list(self.block[dataname][1])
+            del self.block[dataname][1][packet_coord]
+
+    def GetKeyedPacket(self,keyname,keyvalue,no_case=False):
+        """Return the loop packet (a `StarPacket` object) where `keyname` has value
+        `keyvalue`. Ignore case in `keyvalue` if `no_case` is True.  `ValueError`
+        is raised if no packet is found or more than one packet is found."""
+        my_loop = self.GetLoop(keyname)
+        #print("Looking for %s in %s" % (keyvalue, my_loop.parent_block))
+        #print('Packet check on:' + keyname)
+        #[print(repr(getattr(a,keyname))) for a in my_loop]
+        if no_case:
+           one_pack= [a for a in my_loop if getattr(a,keyname).lower()==keyvalue.lower()]
+        else:
+           one_pack= [a for a in my_loop if getattr(a,keyname)==keyvalue]
+        if len(one_pack)!=1:
+            raise ValueError("Bad packet key %s = %s: returned %d packets" % (keyname,keyvalue,len(one_pack)))
+        print("Keyed packet: %s" % one_pack[0])
+        return one_pack[0]
+
+    def GetCompoundKeyedPacket(self,keydict):
+        """Return the loop packet (a `StarPacket` object) where the `{key:(value,caseless)}` pairs
+        in `keydict` take the appropriate values. Ignore case for a given `key` if `caseless` is
+        True.  `ValueError` is raised if no packet is found or more than one packet is found."""
+        #print "Looking for %s in %s" % (keyvalue, self.parent_block[keyname])
+        keynames = list(keydict.keys())
+        my_loop = self.GetLoop(keynames[0])
+        for one_key in keynames:
+            keyval,no_case = keydict[one_key]
+            if no_case:
+               my_loop = list([a for a in my_loop if str(getattr(a,one_key)).lower()==str(keyval).lower()])
+            else:
+               my_loop = list([a for a in my_loop if getattr(a,one_key)==keyval])
+        if len(my_loop)!=1:
+            raise ValueError("Bad packet keys %s: returned %d packets" % (repr(keydict),len(my_loop)))
+        print("Compound keyed packet: %s" % my_loop[0])
+        return my_loop[0]
+
+    def GetKeyedSemanticPacket(self,keyvalue,cat_id):
+        """Return a complete packet for category `cat_id` where the
+        category key for the category equals `keyvalue`.  This routine
+        will understand any joined loops, so if separate loops in the
+        datafile belong to the
+        same category hierarchy (e.g. `_atom_site` and `_atom_site_aniso`),
+        the returned `StarPacket` object will contain datanames from
+        both categories."""
+        target_keys = self.dictionary.cat_key_table[cat_id]
+        target_keys = [k[0] for k in target_keys] #one only in each list
+        p = StarPacket()
+        # set case-sensitivity flag
+        lcase = False
+        if self.dictionary[target_keys[0]]['_type.contents'] in ['Code','Tag','Name']:
+            lcase = True
+        for cat_key in target_keys:
+            try:
+                extra_packet = self.GetKeyedPacket(cat_key,keyvalue,no_case=lcase)
+            except KeyError:        #missing key
+                try:
+                    test_key = self[cat_key]  #generate key if possible
+                    print('Test key is %s' % repr( test_key ))
+                    if test_key is not None and\
+                    not (isinstance(test_key,list) and (None in test_key or len(test_key)==0)):
+                        print('Getting packet for key %s' % repr( keyvalue ))
+                        extra_packet = self.GetKeyedPacket(cat_key,keyvalue,no_case=lcase)
+                except:             #cannot be generated
+                    continue
+            except ValueError:      #none/more than one, assume none
+                continue
+                #extra_packet = self.dictionary.generate_default_packet(cat_id,cat_key,keyvalue)
+            p.merge_packet(extra_packet)
+        # the following attributes used to calculate missing values
+        for keyname in target_keys:
+            if hasattr(p,keyname):
+                p.key = [keyname]
+                break
+        if not hasattr(p,"key"):
+            raise ValueError("No key found for %s, packet is %s" % (cat_id,str(p)))
+        p.cif_dictionary = self.dictionary
+        p.fulldata = self
+        return p
+
+    def GetMultiKeyedSemanticPacket(self,keydict,cat_id):
+        """Return a complete packet for category `cat_id` where the keyvalues are
+        provided as a dictionary of key:(value,caseless) pairs
+        This routine
+        will understand any joined loops, so if separate loops in the
+        datafile belong to the
+        same category hierarchy (e.g. `_atom_site` and `_atom_site_aniso`),
+        the returned `StarPacket` object will contain datanames from
+        the requested category and any children."""
+        #if len(keyvalues)==1:   #simplification
+        #    return self.GetKeyedSemanticPacket(keydict[1][0],cat_id)
+        target_keys = self.dictionary.cat_key_table[cat_id]
+        # update the dictionary passed to us with all equivalents, for
+        # simplicity.
+        parallel_keys = list(zip(*target_keys))  #transpose
+        print('Parallel keys:' + repr(parallel_keys))
+        print('Keydict:' + repr(keydict))
+        start_keys = list(keydict.keys())
+        for one_name in start_keys:
+            key_set = [a for a in parallel_keys if one_name in a]
+            for one_key in key_set:
+                keydict[one_key] = keydict[one_name]
+        # target_keys is a list of lists, each of which is a compound key
+        p = StarPacket()
+        # a little function to return the dataname for a key
+        def find_key(key):
+            for one_key in self.dictionary.key_equivs.get(key,[])+[key]:
+                if self.has_key(one_key):
+                    return one_key
+            return None
+        for one_set in target_keys: #loop down the categories
+            true_keys = [find_key(k) for k in one_set]
+            true_keys = [k for k in true_keys if k is not None]
+            if len(true_keys)==len(one_set):
+                truekeydict = dict([(t,keydict[k]) for t,k in zip(true_keys,one_set)])
+                try:
+                    extra_packet = self.GetCompoundKeyedPacket(truekeydict)
+                except KeyError:     #one or more are missing
+                    continue         #should try harder?
+                except ValueError:
+                    continue
+            else:
+                continue
+            print('Merging packet for keys ' + repr(one_set))
+            p.merge_packet(extra_packet)
+        # the following attributes used to calculate missing values
+        p.key = true_keys
+        p.cif_dictionary = self.dictionary
+        p.fulldata = self
+        return p
+
+
+    def set_grammar(self,new_grammar):
+        self.string_delimiters = ["'",'"',"\n;",None]
+        if new_grammar in ['STAR2','2.0']:
+            self.string_delimiters += ['"""',"'''"]
+        if new_grammar == '2.0':
+            self.list_delimiter = "  "
+        elif new_grammar == 'STAR2':
+            self.list_delimiter = ", "
+        elif new_grammar not in ['1.0','1.1']:
+            raise StarError('Request to set unknown grammar %s' % new_grammar)
+
+    def SetOutputLength(self,wraplength=80,maxoutlength=2048):
+        """Set the maximum output line length (`maxoutlength`) and the line length to
+        wrap at (`wraplength`).  The wrap length is a target only and may not always be
+        possible."""
+        if wraplength > maxoutlength:
+            raise StarError("Wrap length (requested %d) must be <= Maximum line length (requested %d)" % (wraplength,maxoutlength))
+        self.wraplength = wraplength
+        self.maxoutlength = maxoutlength
+
+    def printsection(self,instring='',blockstart="",blockend="",indent=0,finish_at='',start_from=''):
+        self.provide_value = False
+        # first make an ordering
+        self.create_ordering(finish_at,start_from)  #create self.output_order
+        # now do it...
+        if not instring:
+            outstring = CIFStringIO(target_width=80)       # the returned string
+        else:
+            outstring = instring
+        # print block delimiter
+        outstring.write(blockstart,canbreak=True)
+        while len(self.output_order)>0:
+           #print "Remaining to output " + `self.output_order`
+           itemname = self.output_order.pop(0)
+           if not isinstance(itemname,int):  #no loop
+                   item_spec = [i for i in self.formatting_hints if i['dataname'].lower()==itemname.lower()]
+                   if len(item_spec)>0:
+                       item_spec = item_spec[0]
+                       col_pos = item_spec.get('column',-1)
+                       name_pos = item_spec.get('name_pos',-1)
+                   else:
+                       col_pos = -1
+                       item_spec = {}
+                       name_pos = -1
+                   if col_pos < 0: col_pos = 40
+                   outstring.set_tab(col_pos)
+                   itemvalue = self[itemname]
+                   outstring.write(self.true_case[itemname],mustbreak=True,do_tab=False,startcol=name_pos)
+                   outstring.write(' ',canbreak=True,do_tab=False,delimiter=True)    #space after itemname
+                   self.format_value(itemvalue,outstring,hints=item_spec)
+           else:# we are asked to print a loop block
+                    outstring.set_tab(10)       #guess this is OK?
+                    loop_spec = [i['name_pos'] for i in self.formatting_hints if i["dataname"]=='loop']
+                    if loop_spec:
+                        loop_indent = max(loop_spec[0],0)
+                    else:
+                        loop_indent = indent
+                    outstring.write('loop_\n',mustbreak=True,do_tab=False,startcol=loop_indent)
+                    self.format_names(outstring,indent+2,loop_no=itemname)
+                    self.format_packets(outstring,indent+2,loop_no=itemname)
+        else:
+            returnstring = outstring.getvalue()
+        outstring.close()
+        return returnstring
+
+    def format_names(self,outstring,indent=0,loop_no=-1):
+        """Print datanames from `loop_no` one per line"""
+        temp_order = self.loops[loop_no][:]   #copy
+        format_hints = dict([(i['dataname'],i) for i in self.formatting_hints if i['dataname'] in temp_order])
+        while len(temp_order)>0:
+            itemname = temp_order.pop(0)
+            req_indent = format_hints.get(itemname,{}).get('name_pos',indent)
+            outstring.write(' ' * req_indent,do_tab=False)
+            outstring.write(self.true_case[itemname],do_tab=False)
+            outstring.write("\n",do_tab=False)
+
+    def format_packets(self,outstring,indent=0,loop_no=-1):
+       alldata = [self[a] for a in self.loops[loop_no]]
+       loopnames = self.loops[loop_no]
+       #print 'Alldata: %s' % `alldata`
+       packet_data = list(zip(*alldata))
+       #print 'Packet data: %s' % `packet_data`
+       #create a dictionary for quick lookup of formatting requirements
+       format_hints = dict([(i['dataname'],i) for i in self.formatting_hints if i['dataname'] in loopnames])
+       for position in range(len(packet_data)):
+           if position > 0:
+               outstring.write("\n")    #new line each packet except first
+           for point in range(len(packet_data[position])):
+               datapoint = packet_data[position][point]
+               format_hint = format_hints.get(loopnames[point],{})
+               packstring = self.format_packet_item(datapoint,indent,outstring,format_hint)
+               outstring.write(' ',canbreak=True,do_tab=False,delimiter=True)
+
+    def format_packet_item(self,pack_item,indent,outstring,format_hint):
+           # print 'Formatting %s' % `pack_item`
+           # temporary check for any non-unicode items
+           if isinstance(pack_item,str) and not isinstance(pack_item,unicode):
+               raise StarError("Item {0!r} is not unicode".format(pack_item))
+           if isinstance(pack_item,unicode):
+               delimiter = format_hint.get('delimiter',None)
+               startcol = format_hint.get('column',-1)
+               outstring.write(self._formatstring(pack_item,delimiter=delimiter),startcol=startcol)
+           else:
+               self.format_value(pack_item,outstring,hints = format_hint)
+
+    def _formatstring(self,instring,delimiter=None,standard='CIF1',indent=0,hints={}):
+        if hints.get("reformat",False) and "\n" in instring:
+            instring = "\n"+self.do_wrapping(instring,hints["reformat_indent"])
+        allowed_delimiters = set(self.string_delimiters)
+        if len(instring)==0: allowed_delimiters.difference_update([None])
+        if len(instring) > (self.maxoutlength-2) or '\n' in instring:
+                allowed_delimiters.intersection_update(["\n;","'''",'"""'])
+        [allowed_delimiters.difference_update([None]) for k in '[]{}\v\t ,' if k in instring]
+        if len(instring)>0 and instring[0] in '_$#;(':
+                allowed_delimiters.difference_update([None])
+        if len(instring)>3 and (instring[:4].lower()=='data' or instring[:4].lower()=='save'):
+                allowed_delimiters.difference_update([None])
+        if len(instring)>5 and instring[:6].lower()=='global':
+                allowed_delimiters.difference_update([None])
+        if '"' in instring: allowed_delimiters.difference_update(['"',None])
+        if "'" in instring: allowed_delimiters.difference_update(["'",None])
+        out_delimiter = "\n;"  #default (most conservative)
+        if delimiter in allowed_delimiters:
+            out_delimiter = delimiter
+        elif "'" in allowed_delimiters: out_delimiter = "'"
+        elif '"' in allowed_delimiters: out_delimiter = '"'
+        if out_delimiter in ['"',"'",'"""',"'''"]: return out_delimiter + instring + out_delimiter
+        elif out_delimiter is None: return instring
+        # we are left with semicolon strings
+        # use our protocols:
+        maxlinelength = max([len(a) for a in instring.split('\n')])
+        if maxlinelength > self.maxoutlength:
+            protocol_string = apply_line_folding(instring)
+        else:
+            protocol_string = instring
+        # now check for embedded delimiters
+        if "\n;" in protocol_string:
+            prefix = "CIF:"
+            while prefix in protocol_string: prefix = prefix + ":"
+            protocol_string = apply_line_prefix(protocol_string,prefix+"> ")
+        return "\n;" + protocol_string + "\n;"
+
+    def format_value(self,itemvalue,stringsink,compound=False,hints={}):
+        """Format a Star data value"""
+        global have_numpy
+        delimiter = hints.get('delimiter',None)
+        startcol = hints.get('column',-1)
+        if isinstance(itemvalue,str) and not isinstance(itemvalue,unicode): #not allowed
+            raise StarError("Non-unicode value {0} found in block".format(itemvalue))
+        if isinstance(itemvalue,unicode):  #need to sanitize
+            stringsink.write(self._formatstring(itemvalue,delimiter=delimiter,hints=hints),canbreak = True,startcol=startcol)
+        elif isinstance(itemvalue,(list)) or (hasattr(itemvalue,'dtype') and hasattr(itemvalue,'__iter__')): #numpy
+           stringsink.set_tab(0)
+           stringsink.write('[',canbreak=True,newindent=True,mustbreak=compound,startcol=startcol)
+           if len(itemvalue)>0:
+               self.format_value(itemvalue[0],stringsink)
+               for listval in itemvalue[1:]:
+                  # print 'Formatting %s' % `listval`
+                  stringsink.write(self.list_delimiter,do_tab=False)
+                  self.format_value(listval,stringsink,compound=True)
+           stringsink.write(']',unindent=True)
+        elif isinstance(itemvalue,dict):
+           stringsink.set_tab(0)
+           stringsink.write('{',newindent=True,mustbreak=compound,startcol=startcol)  #start a new line inside
+           items = list(itemvalue.items())
+           if len(items)>0:
+               stringsink.write("'"+items[0][0]+"'"+':',canbreak=True)
+               self.format_value(items[0][1],stringsink)
+               for key,value in items[1:]:
+                   stringsink.write(self.list_delimiter)
+                   stringsink.write("'"+key+"'"+":",canbreak=True)
+                   self.format_value(value,stringsink)   #never break between key and value
+           stringsink.write('}',unindent=True)
+        elif isinstance(itemvalue,(float,int,long)) or \
+             (have_numpy and isinstance(itemvalue,(numpy.number))):  #TODO - handle uncertainties
+           stringsink.write(str(itemvalue),canbreak=True,startcol=startcol)   #numbers
+        else:
+           raise ValueError('Value in unexpected format for output: %s' % repr( itemvalue ))
+
+    def create_ordering(self,finish_at,start_from):
+        """Create a canonical ordering that includes loops using our formatting hints dictionary"""
+        requested_order = list([i['dataname'] for i in self.formatting_hints if i['dataname']!='loop'])
+        new_order = []
+        for item in requested_order:
+           if isinstance(item,unicode) and item.lower() in self.item_order:
+               new_order.append(item.lower())
+           elif item in self:    #in a loop somewhere
+               target_loop = self.FindLoop(item)
+               if target_loop not in new_order:
+                   new_order.append(target_loop)
+                   # adjust loop name order
+                   loopnames = self.loops[target_loop]
+                   loop_order = [i for i in requested_order if i in loopnames]
+                   unordered = [i for i in loopnames if i not in loop_order]
+                   self.loops[target_loop] = loop_order + unordered
+        extras = list([i for i in self.item_order if i not in new_order])
+        self.output_order = new_order + extras
+        # now handle partial output
+        if start_from != '':
+            if start_from in requested_order:
+                sfi = requested_order.index(start_from)
+                loop_order = [self.FindLoop(k) for k in requested_order[sfi:] if self.FindLoop(k)>0]
+                candidates = list([k for k in self.output_order if k in requested_order[sfi:]])
+                cand_pos = len(new_order)
+                if len(candidates)>0:
+                    cand_pos = self.output_order.index(candidates[0])
+                if len(loop_order)>0:
+                    cand_pos = min(cand_pos,self.output_order.index(loop_order[0]))
+                if cand_pos < len(self.output_order):
+                    print('Output starts from %s, requested %s' % (self.output_order[cand_pos],start_from))
+                    self.output_order = self.output_order[cand_pos:]
+                else:
+                    print('Start is beyond end of output list')
+                    self.output_order = []
+            elif start_from in extras:
+               self.output_order = self.output_order[self.output_order.index(start_from):]
+            else:
+               self.output_order = []
+        if finish_at != '':
+            if finish_at in requested_order:
+                fai = requested_order.index(finish_at)
+                loop_order = list([self.FindLoop(k) for k in requested_order[fai:] if self.FindLoop(k)>0])
+                candidates = list([k for k in self.output_order if k in requested_order[fai:]])
+                cand_pos = len(new_order)
+                if len(candidates)>0:
+                    cand_pos = self.output_order.index(candidates[0])
+                if len(loop_order)>0:
+                    cand_pos = min(cand_pos,self.output_order.index(loop_order[0]))
+                if cand_pos < len(self.output_order):
+                    print('Output finishes before %s, requested before %s' % (self.output_order[cand_pos],finish_at))
+                    self.output_order = self.output_order[:cand_pos]
+                else:
+                    print('All of block output')
+            elif finish_at in extras:
+               self.output_order = self.output_order[:self.output_order.index(finish_at)]
+        #print('Final order: ' + repr(self.output_order))
+
+    def convert_to_string(self,dataname):
+        """Convert values held in dataname value fork to string version"""
+        v,is_value = self.GetFullItemValue(dataname)
+        if not is_value:
+            return v
+        if check_stringiness(v): return v   #already strings
+        # TODO...something else
+        return v
+
+    def do_wrapping(self,instring,indent=3):
+        """Wrap the provided string"""
+        if "   " in instring:   #already formatted
+            return instring
+        self.wrapper.initial_indent = ' '*indent
+        self.wrapper.subsequent_indent = ' '*indent
+        # remove leading and trailing space
+        instring = instring.strip()
+        # split into paragraphs
+        paras = instring.split("\n\n")
+        wrapped_paras = [self.wrapper.fill(p) for p in paras]
+        return "\n".join(wrapped_paras)
+
+
+    def merge(self,new_block,mode="strict",match_att=[],match_function=None,
+                   rel_keys = []):
+        if mode == 'strict':
+           for key in new_block.keys():
+               if key in self and key not in match_att:
+                  raise StarError( "Identical keys %s in strict merge mode" % key)
+               elif key not in match_att:           #a new dataname
+                   self[key] = new_block[key]
+           # we get here if there are no keys in common, so we can now copy
+           # the loops and not worry about overlaps
+           for one_loop in new_block.loops.values():
+               self.CreateLoop(one_loop)
+           # we have lost case information
+           self.true_case.update(new_block.true_case)
+        elif mode == 'replace':
+           newkeys = list(new_block.keys())
+           for ma in match_att:
+              try:
+                   newkeys.remove(ma)        #don't touch the special ones
+              except ValueError:
+                   pass
+           for key in new_block.keys():
+                  if isinstance(key,unicode):
+                      self[key] = new_block[key]
+           # creating the loop will remove items from other loops
+           for one_loop in new_block.loops.values():
+               self.CreateLoop(one_loop)
+           # we have lost case information
+           self.true_case.update(new_block.true_case)
+        elif mode == 'overlay':
+           print('Overlay mode, current overwrite is %s' % self.overwrite)
+           raise StarError('Overlay block merge mode not implemented')
+           save_overwrite = self.overwrite
+           self.overwrite = True
+           for attribute in new_block.keys():
+               if attribute in match_att: continue      #ignore this one
+               new_value = new_block[attribute]
+               #non-looped items
+               if new_block.FindLoop(attribute)<0:     #not looped
+                  self[attribute] = new_value
+           my_loops = self.loops.values()
+           perfect_overlaps = [a for a in new_block.loops if a in my_loops]
+           for po in perfect_overlaps:
+              loop_keys = [a for a in po if a in rel_keys]  #do we have a key?
+              try:
+                  newkeypos = map(lambda a:newkeys.index(a),loop_keys)
+                  newkeypos = newkeypos[0]      #one key per loop for now
+                  loop_keys = loop_keys[0]
+              except (ValueError,IndexError):
+                  newkeypos = []
+                  overlap_data = map(lambda a:listify(self[a]),overlaps) #old packet data
+                  new_data = map(lambda a:new_block[a],overlaps) #new packet data
+                  packet_data = transpose(overlap_data)
+                  new_p_data = transpose(new_data)
+                  # remove any packets for which the keys match between old and new; we
+                  # make the arbitrary choice that the old data stays
+                  if newkeypos:
+                      # get matching values in new list
+                      print("Old, new data:\n%s\n%s" % (repr(overlap_data[newkeypos]),repr(new_data[newkeypos])))
+                      key_matches = filter(lambda a:a in overlap_data[newkeypos],new_data[newkeypos])
+                      # filter out any new data with these key values
+                      new_p_data = filter(lambda a:a[newkeypos] not in key_matches,new_p_data)
+                      if new_p_data:
+                          new_data = transpose(new_p_data)
+                      else: new_data = []
+                  # wipe out the old data and enter the new stuff
+                  byebyeloop = self.GetLoop(overlaps[0])
+                  # print("Removing '%r' with overlaps '%r'" % (byebyeloop, overlaps))
+                  # Note that if, in the original dictionary, overlaps are not
+                  # looped, GetLoop will return the block itself.  So we check
+                  # for this case...
+                  if byebyeloop != self:
+                      self.remove_loop(byebyeloop)
+                  self.AddLoopItem((overlaps,overlap_data))  #adding old packets
+                  for pd in new_p_data:                             #adding new packets
+                     if pd not in packet_data:
+                        for i in range(len(overlaps)):
+                            #don't do this at home; we are appending
+                            #to something in place
+                            self[overlaps[i]].append(pd[i])
+           self.overwrite = save_overwrite
+
+    def assign_dictionary(self,dic):
+        if not dic.diclang=="DDLm":
+            print("Warning: ignoring dictionary %s" % dic.my_uri)
+            return
+        self.dictionary = dic
+
+    def unassign_dictionary(self):
+        """Remove dictionary-dependent behaviour"""
+        self.dictionary = None
+
+
+
+class StarPacket(list):
+    def merge_packet(self,incoming):
+        """Merge contents of incoming packet with this packet"""
+        new_attrs = [a for a in dir(incoming) if a[0] == '_' and a[1] != "_"]
+        self.extend(incoming)
+        for na in new_attrs:
+            setattr(self,na,getattr(incoming,na))
+
+    def __getattr__(self,att_name):
+        """Derive a missing attribute"""
+        if att_name.lower() in self.__dict__:
+            return getattr(self,att_name.lower())
+        if att_name in ('cif_dictionary','fulldata','key'):
+            raise AttributeError('Programming error: can only assign value of %s' % att_name)
+        d = self.cif_dictionary
+        c = self.fulldata
+        k = self.key
+        assert isinstance(k,list)
+        d.derive_item(att_name,c,store_value=True)
+        #
+        # now pick out the new value
+        # self.key is a list of the key values
+        keydict = dict([(v,(getattr(self,v),True)) for v in k])
+        full_pack = c.GetCompoundKeyedPacket(keydict)
+        return getattr(full_pack,att_name)
+
+class BlockCollection(object):
+    """A container for StarBlock objects. The constructor takes
+    one non-keyword argument `datasource` to set the initial data.  If
+    `datasource` is a Python dictionary, the values must be `StarBlock`
+    objects and the keys will be blocknames in the new object. Keyword
+    arguments:
+
+    standard:
+        `CIF` or `Dic`.  `CIF` enforces 75-character blocknames, and will
+        print block contents before that block's save frame.
+
+    blocktype:
+        The type of blocks held in this container. Normally `StarBlock`
+        or `CifBlock`.
+
+    characterset:
+        `ascii` or `unicode`.  Blocknames and datanames appearing within
+        blocks are restricted to the appropriate characterset. Note that
+        only characters in the basic multilingual plane are accepted. This
+        restriction will be lifted when PyCIFRW is ported to Python3.
+
+    scoping:
+        `instance` or `dictionary`: `instance` implies that save frames are
+        hidden from save frames lower in the hierarchy or in sibling
+        hierarchies. `dictionary` makes all save frames visible everywhere
+        within a data block.  This setting is only relevant for STAR2 dictionaries and
+        STAR2 data files, as save frames are currently not used in plain CIF data
+        files.
+
+"""
+    def __init__(self,datasource=None,standard='CIF',blocktype = StarBlock,
+                 characterset='ascii',scoping='instance',**kwargs):
+        import collections
+        self.dictionary = {}
+        self.standard = standard
+        self.lower_keys = set()           # short_cuts
+        self.renamed = {}
+        self.PC = collections.namedtuple('PC',['block_id','parent'])
+        self.child_table = {}
+        self.visible_keys = []            # for efficiency
+        self.block_input_order = []       # to output in same order
+        self.scoping = scoping  #will trigger setting of child table
+        self.blocktype = blocktype
+        self.master_template = {}   #for outputting
+        self.set_grammar('2.0')
+        self.set_characterset(characterset)
+        if isinstance(datasource,BlockCollection):
+            self.merge_fast(datasource)
+            self.scoping = scoping   #reset visibility
+        elif isinstance(datasource,dict):
+            for key,value in datasource.items():
+                 self[key]= value
+        self.header_comment = ''
+
+    def set_grammar(self,new_grammar):
+        """Set the syntax and grammar for output to `new_grammar`"""
+        if new_grammar not in ['1.1','1.0','2.0','STAR2']:
+            raise StarError('Unrecognised output grammar %s' % new_grammar)
+        self.grammar = new_grammar
+
+    def set_characterset(self,characterset):
+        """Set the allowed characters for datanames and datablocks: may be `ascii` or `unicode`. If datanames
+        have already been added to any datablocks, they are not checked."""
+        self.characterset = characterset
+        for one_block in self.lower_keys:
+            self[one_block].set_characterset(characterset)
+
+    def unlock(self):
+        """Allow overwriting of all blocks in this collection"""
+        for a in self.lower_keys:
+            self[a].overwrite=True
+
+    def lock(self):
+        """Disallow overwriting for all blocks in this collection"""
+        for a in self.lower_keys:
+            self[a].overwrite = False
+
+    def __str__(self):
+        return self.WriteOut()
+
+    def __setitem__(self,key,value):
+        self.NewBlock(key,value,parent=None)
+
+    def __getitem__(self,key):
+        if isinstance(key,(unicode,str)):
+           lowerkey = key.lower()
+           if lowerkey in self.lower_keys:
+               return self.dictionary[lowerkey]
+           #print 'Visible keys:' + `self.visible_keys`
+           #print 'All keys' + `self.lower_keys`
+           #print 'Child table' + `self.child_table`
+           raise KeyError('No such item %s' % key)
+
+    # we have to get an ordered list of the current keys,
+    # as we'll have to delete one of them anyway.
+    # Deletion will delete any key regardless of visibility
+
+    def __delitem__(self,key):
+        dummy = self[key]   #raise error if not present
+        lowerkey = key.lower()
+        # get rid of all children recursively as well
+        children = [a[0] for a in self.child_table.items() if a[1].parent == lowerkey]
+        for child in children:
+            del self[child]   #recursive call
+        del self.dictionary[lowerkey]
+        del self.child_table[lowerkey]
+        try:
+            self.visible_keys.remove(lowerkey)
+        except KeyError:
+            pass
+        self.lower_keys.remove(lowerkey)
+        self.block_input_order.remove(lowerkey)
+
+    def __len__(self):
+        return len(self.visible_keys)
+
+    def __contains__(self,item):
+        """Support the 'in' operator"""
+        if not isinstance(item,(unicode,str)): return False
+        if item.lower() in self.visible_keys:
+            return True
+        return False
+
+    # We iterate over all visible
+    def __iter__(self):
+        for one_block in self.keys():
+            yield self[one_block]
+
+    # TODO: handle different case
+    def keys(self):
+        return self.visible_keys
+
+    # Note that has_key does not exist in 3.5
+    def has_key(self,key):
+        return key in self
+
+    def get(self,key,default=None):
+        if key in self:     # take account of case
+            return self.__getitem__(key)
+        else:
+            return default
+
+    def clear(self):
+        self.dictionary.clear()
+        self.lower_keys = set()
+        self.child_table = {}
+        self.visible_keys = []
+        self.block_input_order = []
+
+    def copy(self):
+        newcopy = self.dictionary.copy()  #all blocks
+        for k,v in self.dictionary.items():
+            newcopy[k] = v.copy()
+        newcopy = BlockCollection(newcopy)
+        newcopy.child_table = self.child_table.copy()
+        newcopy.lower_keys = self.lower_keys.copy()
+        newcopy.block_input_order = self.block_input_order.copy()
+        newcopy.characterset = self.characterset
+        newcopy.SetTemplate(self.master_template.copy())
+        newcopy.scoping = self.scoping  #this sets visible keys
+        return newcopy
+
+    def update(self,adict):
+        for key in adict.keys():
+            self[key] = adict[key]
+
+    def items(self):
+        return [(a,self[a]) for a in self.keys()]
+
+    def first_block(self):
+        """Return the 'first' block.  This is not necessarily the first block in the file."""
+        if self.keys():
+            return self[self.keys()[0]]
+
+    def NewBlock(self,blockname,blockcontents=None,fix=True,parent=None):
+        """Add a new block named `blockname` with contents `blockcontents`. If `fix`
+        is True, `blockname` will have spaces and tabs replaced by underscores. `parent`
+        allows a parent block to be set so that block hierarchies can be created.  Depending on
+        the output standard, these blocks will be printed out as nested save frames or
+        ignored."""
+        if blockcontents is None:
+            blockcontents = self.blocktype()
+        if self.standard == "CIF":
+            blockcontents.setmaxnamelength(75)
+        if len(blockname)>75:
+                 raise StarError('Blockname %s is longer than 75 characters' % blockname)
+        if fix:
+            newblockname = re.sub('[  \t]','_',blockname)
+        else: newblockname = blockname
+        new_lowerbn = newblockname.lower()
+        if new_lowerbn in self.lower_keys:   #already there
+            if self.standard is not None:
+               toplevelnames = [a[0] for a in self.child_table.items() if a[1].parent==None]
+               if parent is None and new_lowerbn not in toplevelnames:  #can give a new key to this one
+                  while new_lowerbn in self.lower_keys: new_lowerbn = new_lowerbn + '+'
+               elif parent is not None and new_lowerbn in toplevelnames: #can fix a different one
+                  replace_name = new_lowerbn
+                  while replace_name in self.lower_keys: replace_name = replace_name + '+'
+                  self._rekey(new_lowerbn,replace_name)
+                  # now continue on to add in the new block
+                  if parent.lower() == new_lowerbn:        #the new block's requested parent just got renamed!!
+                      parent = replace_name
+               else:
+                  raise StarError( "Attempt to replace existing block " + blockname)
+            else:
+               del self[new_lowerbn]
+        self.dictionary.update({new_lowerbn:blockcontents})
+        self.lower_keys.add(new_lowerbn)
+        self.block_input_order.append(new_lowerbn)
+        if parent is None:
+           self.child_table[new_lowerbn]=self.PC(newblockname,None)
+           self.visible_keys.append(new_lowerbn)
+        else:
+           if parent.lower() in self.lower_keys:
+              if self.scoping == 'instance':
+                 self.child_table[new_lowerbn]=self.PC(newblockname,parent.lower())
+              else:
+                 self.child_table[new_lowerbn]=self.PC(newblockname,parent.lower())
+                 self.visible_keys.append(new_lowerbn)
+           else:
+               print('Warning:Parent block %s does not exist for child %s' % (parent,newblockname))
+        self[new_lowerbn].set_grammar(self.grammar)
+        self[new_lowerbn].set_characterset(self.characterset)
+        self[new_lowerbn].formatting_hints = self.master_template
+        return new_lowerbn  #in case calling routine wants to know
+
+    def _rekey(self,oldname,newname,block_id=''):
+        """The block with key [[oldname]] gets [[newname]] as a new key, but the printed name
+           does not change unless [[block_id]] is given.  Prefer [[rename]] for a safe version."""
+        move_block = self[oldname]    #old block
+        is_visible = oldname in self.visible_keys
+        move_block_info = self.child_table[oldname]    #old info
+        move_block_children = [a for a in self.child_table.items() if a[1].parent==oldname]
+        # now rewrite the necessary bits
+        self.child_table.update(dict([(a[0],self.PC(a[1].block_id,newname)) for a in move_block_children]))
+        oldpos = self.block_input_order.index(oldname)
+        del self[oldname]   #do this after updating child table so we don't delete children
+        self.dictionary.update({newname:move_block})
+        self.lower_keys.add(newname)
+        #print 'Block input order was: ' + `self.block_input_order`
+        self.block_input_order[oldpos:oldpos]=[newname]
+        if block_id == '':
+           self.child_table.update({newname:move_block_info})
+        else:
+           self.child_table.update({newname:self.PC(block_id,move_block_info.parent)})
+        if is_visible: self.visible_keys += [newname]
+
+    def rename(self,oldname,newname):
+        """Rename datablock from [[oldname]] to [[newname]]. Both key and printed name are changed.  No
+           conformance checks are conducted."""
+        realoldname = oldname.lower()
+        realnewname = newname.lower()
+        if realnewname in self.lower_keys:
+            raise StarError('Cannot change blockname %s to %s as %s already present' % (oldname,newname,newname))
+        if realoldname not in self.lower_keys:
+            raise KeyError('Cannot find old block %s' % realoldname)
+        self._rekey(realoldname,realnewname,block_id=newname)
+
+    def makebc(self,namelist,scoping='dictionary'):
+        """Make a block collection from a list of block names"""
+        newbc = BlockCollection()
+        block_lower = [n.lower() for n in namelist]
+        proto_child_table = [a for a in self.child_table.items() if a[0] in block_lower]
+        newbc.child_table = dict(proto_child_table)
+        new_top_level = [(a[0],self.PC(a[1].block_id,None)) for a in newbc.child_table.items() if a[1].parent not in block_lower]
+        newbc.child_table.update(dict(new_top_level))
+        newbc.lower_keys = set([a[0] for a in proto_child_table])
+        newbc.dictionary = dict((a[0],self.dictionary[a[0]]) for a in proto_child_table)
+        newbc.scoping = scoping
+        newbc.block_input_order = block_lower
+        return newbc
+
+
+    def merge_fast(self,new_bc,parent=None):
+        """Do a fast merge. WARNING: this may change one or more of its frame headers in order to
+        remove duplicate frames.  Please keep a handle to the block object instead of the text of
+        the header."""
+        if self.standard is None:
+            mode = 'replace'
+        else:
+            mode = 'strict'
+        overlap_flag = not self.lower_keys.isdisjoint(new_bc.lower_keys)
+        if parent is not None:
+            parent_name = [a[0] for a in self.dictionary.items() if a[1] == parent]
+            if len(parent_name)==0 or len(parent_name)>1:
+                raise StarError("Unable to find unique parent block name: have %s" % str(parent_name))
+            parent_name = parent_name[0]
+        else:
+            parent_name = None  #an error will be thrown if we treat as a string
+        if overlap_flag and mode != 'replace':
+            double_keys = self.lower_keys.intersection(new_bc.lower_keys)
+            for dup_key in double_keys:
+                  our_parent = self.child_table[dup_key].parent
+                  their_parent = new_bc.child_table[dup_key].parent
+                  if (our_parent is None and their_parent is not None and parent is None) or\
+                      parent is not None:  #rename our block
+                    start_key = dup_key
+                    while start_key in self.lower_keys: start_key = start_key+'+'
+                    self._rekey(dup_key,start_key)
+                    if parent_name.lower() == dup_key:  #we just renamed the prospective parent!
+                        parent_name = start_key
+                  elif our_parent is not None and their_parent is None and parent is None:
+                    start_key = dup_key
+                    while start_key in new_bc.lower_keys: start_key = start_key+'+'
+                    new_bc._rekey(dup_key,start_key)
+                  else:
+                    raise StarError("In strict merge mode:duplicate keys %s" % dup_key)
+        self.dictionary.update(new_bc.dictionary)
+        self.lower_keys.update(new_bc.lower_keys)
+        self.visible_keys += (list(new_bc.lower_keys))
+        self.block_input_order += new_bc.block_input_order
+        #print('Block input order now:' + repr(self.block_input_order))
+        self.child_table.update(new_bc.child_table)
+        if parent_name is not None:     #redo the child_table entries
+              reparent_list = [(a[0],a[1].block_id) for a in new_bc.child_table.items() if a[1].parent==None]
+              reparent_dict = [(a[0],self.PC(a[1],parent_name.lower())) for a in reparent_list]
+              self.child_table.update(dict(reparent_dict))
+
+    def merge(self,new_bc,mode=None,parent=None,single_block=[],
+                   idblock="",match_att=[],match_function=None):
+        if mode is None:
+            if self.standard is None:
+               mode = 'replace'
+            else:
+               mode = 'strict'
+        if single_block:
+            self[single_block[0]].merge(new_bc[single_block[1]],mode,
+                                                   match_att=match_att,
+                                                   match_function=match_function)
+            return None
+        base_keys = [a[1].block_id for a in self.child_table.items()]
+        block_to_item = base_keys   #default
+        new_keys = [a[1].block_id for a in new_bc.child_table.items()]    #get list of incoming blocks
+        if match_att:
+            #make a blockname -> item name map
+            if match_function:
+                block_to_item = [match_function(self[a]) for a in self.keys()]
+            else:
+                block_to_item = [self[a].get(match_att[0],None) for a in self.keys()]
+            #print `block_to_item`
+        for key in new_keys:        #run over incoming blocknames
+            if key == idblock: continue    #skip dictionary id
+            basekey = key           #default value
+            if len(match_att)>0:
+               attval = new_bc[key].get(match_att[0],0)  #0 if ignoring matching
+            else:
+               attval = 0
+            for ii in range(len(block_to_item)):  #do this way to get looped names
+                thisatt = block_to_item[ii]       #keyname in old block
+                #print "Looking for %s in %s" % (attval,thisatt)
+                if attval == thisatt or \
+                   (isinstance(thisatt,list) and attval in thisatt):
+                      basekey = base_keys.pop(ii)
+                      block_to_item.remove(thisatt)
+                      break
+            if not basekey in self or mode=="replace":
+                new_parent = new_bc.get_parent(key)
+                if parent is not None and new_parent is None:
+                   new_parent = parent
+                self.NewBlock(basekey,new_bc[key],parent=new_parent)   #add the block
+            else:
+                if mode=="strict":
+                    raise StarError( "In strict merge mode: block %s in old and block %s in new files" % (basekey,key))
+                elif mode=="overlay":
+                    # print "Merging block %s with %s" % (basekey,key)
+                    self[basekey].merge(new_bc[key],mode,match_att=match_att)
+                else:
+                    raise StarError( "Merge called with unknown mode %s" % mode)
+
+    def checknamelengths(self,target_block,maxlength=-1):
+        if maxlength < 0:
+            return
+        else:
+            toolong = [a for a in target_block.keys() if len(a)>maxlength]
+        outstring = ""
+        if toolong:
+           outstring = "\n".join(toolong)
+           raise StarError( 'Following data names too long:' + outstring)
+
+    def get_all(self,item_name):
+        raw_values = [self[a].get(item_name) for a in self.keys()]
+        raw_values = [a for a in raw_values if a != None]
+        ret_vals = []
+        for rv in raw_values:
+            if isinstance(rv,list):
+                for rvv in rv:
+                    if rvv not in ret_vals: ret_vals.append(rvv)
+            else:
+                if rv not in ret_vals: ret_vals.append(rv)
+        return ret_vals
+
+    def __setattr__(self,attr_name,newval):
+        if attr_name == 'scoping':
+            if newval not in ('dictionary','instance'):
+                raise StarError("Star file may only have 'dictionary' or 'instance' scoping, not %s" % newval)
+            if newval == 'dictionary':
+                self.visible_keys = [a for a in self.lower_keys]
+            else:
+                #only top-level datablocks visible
+                self.visible_keys = [a[0] for a in self.child_table.items() if a[1].parent==None]
+        object.__setattr__(self,attr_name,newval)
+
+    def get_parent(self,blockname):
+        """Return the name of the block enclosing [[blockname]] in canonical form (lower case)"""
+        possibles = (a for a in self.child_table.items() if a[0] == blockname.lower())
+        try:
+            first = next(possibles)   #get first one
+        except:
+            raise StarError('no parent for %s' % blockname)
+        try:
+           second = next(possibles)
+        except StopIteration:
+           return first[1].parent
+        raise StarError('More than one parent for %s' % blockname)
+
+    def get_roots(self):
+        """Get the top-level blocks"""
+        return [a for a in self.child_table.items() if a[1].parent==None]
+
+    def get_children(self,blockname,include_parent=False,scoping='dictionary'):
+        """Get all children of [[blockname]] as a block collection. If [[include_parent]] is
+        True, the parent block will also be included in the block collection as the root."""
+        newbc = BlockCollection()
+        block_lower = blockname.lower()
+        proto_child_table = [a for a in self.child_table.items() if self.is_child_of_parent(block_lower,a[1].block_id)]
+        newbc.child_table = dict(proto_child_table)
+        if not include_parent:
+           newbc.child_table.update(dict([(a[0],self.PC(a[1].block_id,None)) for a in proto_child_table if a[1].parent == block_lower]))
+        newbc.lower_keys = set([a[0] for a in proto_child_table])
+        newbc.dictionary = dict((a[0],self.dictionary[a[0]]) for a in proto_child_table)
+        if include_parent:
+            newbc.child_table.update({block_lower:self.PC(self.child_table[block_lower].block_id,None)})
+            newbc.lower_keys.add(block_lower)
+            newbc.dictionary.update({block_lower:self.dictionary[block_lower]})
+        newbc.scoping = scoping
+        return newbc
+
+    def get_immediate_children(self,parentname):
+        """Get the next level of children of the given block as a list, without nested levels"""
+        child_handles = [a for a in self.child_table.items() if a[1].parent == parentname.lower()]
+        return child_handles
+
+    # This takes time
+    def get_child_list(self,parentname):
+        """Get a list of all child categories in alphabetical order"""
+        child_handles = [a[0] for a in self.child_table.items() if self.is_child_of_parent(parentname.lower(),a[0])]
+        child_handles.sort()
+        return child_handles
+
+    def is_child_of_parent(self,parentname,blockname):
+        """Return `True` if `blockname` is a child of `parentname`"""
+        checkname = parentname.lower()
+        more_children = [a[0] for a in self.child_table.items() if a[1].parent == checkname]
+        if blockname.lower() in more_children:
+           return True
+        else:
+           for one_child in more_children:
+               if self.is_child_of_parent(one_child,blockname): return True
+        return False
+
+    def set_parent(self,parentname,childname):
+        """Set the parent block"""
+        # first check that both blocks exist
+        if parentname.lower() not in self.lower_keys:
+            raise KeyError('Parent block %s does not exist' % parentname)
+        if childname.lower() not in self.lower_keys:
+            raise KeyError('Child block %s does not exist' % childname)
+        old_entry = self.child_table[childname.lower()]
+        self.child_table[childname.lower()]=self.PC(old_entry.block_id,
+               parentname.lower())
+        self.scoping = self.scoping #reset visibility
+
+    def SetTemplate(self,template_file):
+            """Use `template_file` as a template for all block output"""
+            self.master_template = process_template(template_file)
+            for b in self.dictionary.values():
+                b.formatting_hints = self.master_template
+
+    def WriteOut(self,comment='',wraplength=80,maxoutlength=0,blockorder=None,saves_after=None):
+        """Return the contents of this file as a string, wrapping if possible at `wraplength`
+        characters and restricting maximum line length to `maxoutlength`.  Delimiters and
+        save frame nesting are controlled by `self.grammar`. If `blockorder` is
+        provided, blocks are output in this order unless nested save frames have been
+        requested (STAR2). The default block order is the order in which blocks were input.
+        `saves_after` inserts all save frames after the given dataname,
+        which allows less important items to appear later.  Useful in conjunction with a
+        template for dictionary files."""
+        if maxoutlength != 0:
+            self.SetOutputLength(maxoutlength)
+        if not comment:
+            comment = self.header_comment
+        outstring = StringIO()
+        if self.grammar == "2.0" and comment[0:10] != r"#\#CIF_2.0":
+            outstring.write(r"#\#CIF_2.0" + "\n")
+        outstring.write(comment)
+        # prepare all blocks
+        for b in self.dictionary.values():
+            b.set_grammar(self.grammar)
+            b.formatting_hints = self.master_template
+            b.SetOutputLength(wraplength,self.maxoutlength)
+        # loop over top-level
+        # monitor output
+        all_names = list(self.child_table.keys())   #i.e. lower case
+        if blockorder is None:
+            blockorder = self.block_input_order
+        top_block_names = [(a,self.child_table[a].block_id) for a in blockorder if self.child_table[a].parent is None]
+        for blockref,blockname in top_block_names:
+            print('Writing %s, ' % blockname + repr(self[blockref]))
+            outstring.write('\n' + 'data_' +blockname+'\n')
+            all_names.remove(blockref)
+            if self.standard == 'Dic':              #put contents before save frames
+                outstring.write(self[blockref].printsection(finish_at='_dictionary_valid.application'))
+            if self.grammar == 'STAR2':  #nested save frames
+                child_refs = self.get_immediate_children(blockref)
+                for child_ref,child_info in child_refs:
+                    child_name = child_info.block_id
+                    outstring.write('\n\n' + 'save_' + child_name + '\n')
+                    self.block_to_string_nested(child_ref,child_name,outstring,4)
+                    outstring.write('\n' + 'save_'+ '\n')
+            elif self.grammar in ('1.0','1.1','2.0'):                   #non-nested save frames
+                child_refs = [a for a in blockorder if self.is_child_of_parent(blockref,a)]
+                for child_ref in child_refs:
+                    child_name = self.child_table[child_ref].block_id
+                    outstring.write('\n\n' + 'save_' + child_name + '\n')
+                    outstring.write(str(self[child_ref]))
+                    outstring.write('\n\n' + 'save_' + '\n')
+                    all_names.remove(child_ref.lower())
+            else:
+                raise StarError('Grammar %s is not recognised for output' % self.grammar)
+            if self.standard != 'Dic':              #put contents after save frames
+                outstring.write(str(self[blockref]))
+            else:
+                outstring.write(self[blockref].printsection(start_from='_dictionary_valid.application'))
+        returnstring =  outstring.getvalue()
+        outstring.close()
+        if len(all_names)>0:
+            print('WARNING: following blocks not output: %s' % repr(all_names))
+        else:
+            print('All blocks output.')
+        return returnstring
+
+    def block_to_string_nested(self,block_ref,block_id,outstring,indentlevel=0):
+        """Output a complete datablock indexed by [[block_ref]] and named [[block_id]], including children,
+           and syntactically nesting save frames"""
+        child_refs = self.get_immediate_children(block_ref)
+        self[block_ref].set_grammar(self.grammar)
+        if self.standard == 'Dic':
+            outstring.write(str(self[block_ref]))
+        for child_ref,child_info in child_refs:
+            child_name = child_info.block_id
+            outstring.write('\n' + 'save_' + child_name + '\n')
+            self.block_to_string_nested(child_ref,child_name,outstring,indentlevel)
+            outstring.write('\n' + '  '*indentlevel + 'save_' + '\n')
+        if self.standard != 'Dic':
+            outstring.write(str(self[block_ref]))
+
+
+class StarFile(BlockCollection):
+    def __init__(self,datasource=None,maxinlength=-1,maxoutlength=0,
+                scoping='instance',grammar='1.1',scantype='standard',
+                 permissive=False,**kwargs):
+        super(StarFile,self).__init__(datasource=datasource,**kwargs)
+        self.my_uri = getattr(datasource,'my_uri','')
+        if maxoutlength == 0:
+            self.maxoutlength = 2048
+        else:
+            self.maxoutlength = maxoutlength
+        self.scoping = scoping
+        if isinstance(datasource,(unicode,str)) or hasattr(datasource,"read"):
+            ReadStar(datasource,prepared=self,grammar=grammar,scantype=scantype,
+                     maxlength = maxinlength,permissive=permissive)
+        self.header_comment = \
+"""#\\#STAR
+##########################################################################
+#               STAR Format file
+#               Produced by PySTARRW module
+#
+#  This is a STAR file.  STAR is a superset of the CIF file type.  For
+#  more information, please refer to International Tables for Crystallography,
+#  Volume G, Chapter 2.1
+#
+##########################################################################
+"""
+    def set_uri(self,my_uri): self.my_uri = my_uri
+
+
+class CIFStringIO(StringIO):
+    def __init__(self,target_width=80,**kwargs):
+        StringIO.__init__(self,**kwargs)
+        self.currentpos = 0
+        self.target_width = target_width
+        self.tabwidth = -1
+        self.indentlist = [0]
+        self.last_char = ""
+
+    def write(self,outstring,canbreak=False,mustbreak=False,do_tab=True,newindent=False,unindent=False,
+                             delimiter=False,startcol=-1):
+        """Write a string with correct linebreak, tabs and indents"""
+        # do we need to break?
+        if delimiter:
+            if len(outstring)>1:
+                raise ValueError('Delimiter %s is longer than one character' % repr( outstring ))
+            output_delimiter = True
+        if mustbreak:    #insert a new line and indent
+            temp_string = '\n' + ' ' * self.indentlist[-1]
+            StringIO.write(self,temp_string)
+            self.currentpos = self.indentlist[-1]
+            self.last_char = temp_string[-1]
+        if self.currentpos+len(outstring)>self.target_width: #try to break
+            if not delimiter and outstring[0]!='\n':          #ie <cr>;
+              if canbreak:
+                temp_string = '\n' + ' ' * self.indentlist[-1]
+                StringIO.write(self,temp_string)
+                self.currentpos = self.indentlist[-1]
+                self.last_char = temp_string[-1]
+            else:        #assume a break will be forced on next value
+                output_delimiter = False    #the line break becomes the delimiter
+        #try to match requested column
+        if startcol > 0:
+            if self.currentpos < startcol:
+                StringIO.write(self,(startcol - self.currentpos)* ' ')
+                self.currentpos = startcol
+                self.last_char = ' '
+            else:
+                print('Could not format %s at column %d as already at %d' % (outstring,startcol,self.currentpos))
+                startcol = -1   #so that tabbing works as a backup
+        #handle tabs
+        if self.tabwidth >0 and do_tab and startcol < 0:
+            next_stop = ((self.currentpos//self.tabwidth)+1)*self.tabwidth
+            #print 'Currentpos %d: Next tab stop at %d' % (self.currentpos,next_stop)
+            if self.currentpos < next_stop:
+                StringIO.write(self,(next_stop-self.currentpos)*' ')
+                self.currentpos = next_stop
+                self.last_char = ' '
+        #calculate indentation after tabs and col setting applied
+        if newindent:           #indent by current amount
+            if self.indentlist[-1] == 0:    #first time
+                self.indentlist.append(self.currentpos)
+                # print 'Indentlist: ' + `self.indentlist`
+            else:
+                self.indentlist.append(self.indentlist[-1]+2)
+        elif unindent:
+            if len(self.indentlist)>1:
+                self.indentlist.pop()
+            else:
+                print('Warning: cannot unindent any further')
+        #check that we still need a delimiter
+        if self.last_char in [' ','\n','\t']:
+            output_delimiter = False
+        #now output the string - every invocation comes through here
+        if (delimiter and output_delimiter) or not delimiter:
+            StringIO.write(self,outstring)
+        last_line_break = outstring.rfind('\n')
+        if last_line_break >=0:
+            self.currentpos = len(outstring)-last_line_break
+        else:
+            self.currentpos = self.currentpos + len(outstring)
+        #remember the last character
+        if len(outstring)>0:
+            self.last_char = outstring[-1]
+
+    def set_tab(self,tabwidth):
+        """Set the tab stop position"""
+        self.tabwidth = tabwidth
+
+class StarError(Exception):
+    def __init__(self,value):
+        self.value = value
+    def __str__(self):
+        return '\nStar Format error: '+ self.value
+
+class StarLengthError(Exception):
+    def __init__(self,value):
+        self.value = value
+    def __str__(self):
+        return '\nStar length error: ' + self.value
+
+class StarDerivationError(Exception):
+    def __init__(self,fail_name):
+        self.fail_name = fail_name
+    def __str__(self):
+        return "Derivation of %s failed, None returned" % self.fail_name
+
+#
+# This is subclassed from AttributeError in order to allow hasattr
+# to work.
+#
+class StarDerivationFailure(AttributeError):
+    def __init__(self,fail_name):
+        self.fail_name = fail_name
+    def __str__(self):
+        return "Derivation of %s failed" % self.fail_name
+
+def ReadStar(filename,prepared = None, maxlength=-1,
+             scantype='standard',grammar='STAR2',CBF=False, permissive=False):
+
+    """ Read in a STAR file, returning the contents in the `prepared` object.
+
+    * `filename` may be a URL, a file
+    path on the local system, or any object with a `read` method.
+
+    * `prepared` provides a `StarFile` or `CifFile` object that the contents of `filename`
+    will be added to.
+
+    * `maxlength` is the maximum allowable line length in the input file. This has been set at
+    2048 characters for CIF but is unlimited (-1) for STAR files.
+
+    * `grammar` chooses the STAR grammar variant. `1.0` is the original 1992 CIF/STAR grammar and `1.1`
+    is identical except for the exclusion of square brackets as the first characters in
+    undelimited datanames. `2.0` will read files in the CIF2.0 standard, and `STAR2` will
+    read files according to the STAR2 publication.  If grammar is `None` or `auto`, autodetection
+    will be attempted in the order `2.0`, `1.1` and `1.0`. This will always succeed for conformant CIF2.0 files.
+    Note that (nested) save frames are read in all grammar variations and then flagged afterwards if
+    they do not match the requested grammar.
+
+    * `scantype` can be `standard` or `flex`.  `standard` provides pure Python parsing at the
+    cost of a factor of 10 or so in speed.  `flex` will tokenise the input CIF file using
+    fast C routines.  Note that running PyCIFRW in Jython uses native Java regular expressions
+    to provide a speedup regardless of this argument.
+
+    * `CBF` flags that the input file is in Crystallographic Binary File format. The binary block is
+    excised from the input data stream before parsing and is not available in the returned object.
+
+    * `permissive` allows non UTF8 encodings (currently only latin1) in the input file. These are a 
+    violation of the standard.
+
+    """
+
+    # save desired scoping
+    save_scoping = prepared.scoping
+    from . import YappsStarParser_1_1 as Y11
+    from . import YappsStarParser_1_0 as Y10
+    from . import YappsStarParser_2_0 as Y20
+    from . import YappsStarParser_STAR2 as YST
+    if prepared is None:
+        prepared = StarFile()
+    if grammar == "auto" or grammar is None:
+        try_list = [('2.0',Y20),('1.1',Y11),('1.0',Y10)]
+    elif grammar == '1.0':
+        try_list = [('1.0',Y10)]
+    elif grammar == '1.1':
+        try_list = [('1.1',Y11)]
+    elif grammar == '2.0':
+        try_list = [('2.0',Y20)]
+    elif grammar == 'STAR2':
+        try_list = [('STAR2',YST)]
+    else:
+        raise AttributeError('Unknown STAR/CIF grammar requested, %s' % repr( grammar ))
+    if isinstance(filename,(unicode,str)):
+        # create an absolute URL
+        relpath = urlparse(filename)
+        if len(relpath.scheme) <= 1:
+            if not os.path.isabs(filename):
+                fullpath = os.path.join(os.getcwd(),filename)
+            else:
+                fullpath = filename
+            if have_pathlib:  # Python > 3.4
+                my_uri = Path(fullpath).as_uri()
+            else:     # works on Linux/Mac only
+                newrel = list(relpath)
+                newrel[0] = "file"
+                newrel[2] = fullpath
+                my_uri = urlunparse(newrel)
+        else:
+            my_uri = urlunparse(relpath)
+        # print("Full URL is: " + my_uri)
+        filestream = urlopen(my_uri)
+        try:
+            text = filestream.read().decode('utf-8-sig')
+        except UnicodeDecodeError:
+            if permissive:
+                text = filestream.read().decode('latin1')
+                print("WARNING: %s violates standard (latin1 encoding instead of UTF8)." % filename)
+            else:
+                raise StarError("%s: bad encoding (must be utf8 or ascii)" % filename)
+        filestream.close()
+    else:
+        filestream = filename   #already opened for us
+        text = filestream.read()
+        if not isinstance(text,unicode):
+            try:
+                text = text.decode('utf-8-sig')  #CIF is always ascii/utf8
+            except UnicodeDecodeError:
+                if permissive:
+                    text = filestream.read().decode('latin1')
+                    print("WARNING: text violates CIF standard (latin1 encoding instead of UTF8)")
+                else:
+                    raise StarError("Bad input encoding (must be utf8 or ascii)")
+        my_uri = ""
+    if not text:      # empty file, return empty block
+        return prepared.set_uri(my_uri)
+    # filter out non-ASCII characters in CBF files if required.  We assume
+    # that the binary is enclosed in a fixed string that occurs
+    # nowhere else.
+    if CBF:
+       text_bits  = text.split("-BINARY-FORMAT-SECTION-")
+       text = text_bits[0]
+       for section in range(2,len(text_bits),2):
+           text = text+" (binary omitted)"+text_bits[section]
+    # we recognise ctrl-Z as end of file
+    endoffile = text.find(chr(26))
+    if endoffile >= 0:
+        text = text[:endoffile]
+    split = text.split('\n')
+    if maxlength > 0:
+        toolong = [a for a in split if len(a)>maxlength]
+        if toolong:
+            pos = split.index(toolong[0])
+            raise StarError( 'Line %d contains more than %d characters' % (pos+1,maxlength))
+    # honour the header string
+    if text[:10] != r"#\#CIF_2.0" and ('2.0',Y20) in try_list:
+        try_list.remove(('2.0',Y20),)
+        if not try_list:
+            raise StarError('File %s missing CIF2.0 header' % (filename))
+    for grammar_name,Y in try_list:
+       if scantype == 'standard' or grammar_name in ['2.0','STAR2']:
+            parser = Y.StarParser(Y.StarParserScanner(text))
+       else:
+            parser = Y.StarParser(Y.yappsrt.Scanner(None,[],text,scantype='flex'))
+       # handle encoding switch
+       if grammar_name in ['2.0','STAR2']:
+           prepared.set_characterset('unicode')
+       else:
+           prepared.set_characterset('ascii')
+       proto_star = None
+       try:
+           proto_star = getattr(parser,"input")(prepared)
+       except Y.yappsrt.YappsSyntaxError as e:
+           input = parser._scanner.input
+           Y.yappsrt.print_error(input, e, parser._scanner)
+       except Y.yappsrt.NoMoreTokens:
+           print('Could not complete parsing; stopped around here:',file=sys.stderr)
+           print(parser._scanner,file=sys.stderr)
+       except ValueError:
+           print('Unexpected error:')
+           import traceback
+           traceback.print_exc()
+       if proto_star is not None:
+           proto_star.set_grammar(grammar_name)   #remember for output
+           break
+    if proto_star is None:
+        errorstring = 'Syntax error in input file: last value parsed was %s' % Y.lastval
+        errorstring = errorstring + '\nParser status: %s' % repr( parser._scanner )
+        raise StarError( errorstring)
+    # set visibility correctly
+    proto_star.scoping = 'dictionary'
+    proto_star.set_uri(my_uri)
+    proto_star.scoping = save_scoping
+    return proto_star
+
+def get_dim(dataitem,current=0,packlen=0):
+    zerotypes = [int, float, str]
+    if type(dataitem) in zerotypes:
+        return current, packlen
+    if not dataitem.__class__ == ().__class__ and \
+       not dataitem.__class__ == [].__class__:
+       return current, packlen
+    elif len(dataitem)>0:
+    #    print "Get_dim: %d: %s" % (current,`dataitem`)
+        return get_dim(dataitem[0],current+1,len(dataitem))
+    else: return current+1,0
+
+def apply_line_folding(instring,minwraplength=60,maxwraplength=80):
+    """Insert line folding characters into instring between min/max wraplength"""
+    # first check that we need to do this
+    lines = instring.split('\n')
+    line_len = [len(l) for l in lines]
+    if max(line_len) < maxwraplength and re.match("\\[ \v\t\f]*\n",instring) is None:
+        return instring
+    outstring = "\\\n"   #header
+    for l in lines:
+        if len(l) < maxwraplength:
+            outstring = outstring + l
+            if len(l) > 0 and l[-1]=='\\': #who'da thunk it?  A line ending with a backslash
+                    outstring = outstring + "\\\n"  #
+            outstring = outstring + "\n"  #  put back the split character
+        else:
+            current_bit = l
+            while len(current_bit) > maxwraplength:
+                space_pos = re.search('[ \v\f\t]+',current_bit[minwraplength:])
+                if space_pos is not None and space_pos.start()<maxwraplength-1:
+                    outstring = outstring + current_bit[:minwraplength+space_pos.start()] + "\\\n"
+                    current_bit = current_bit[minwraplength+space_pos.start():]
+                else:    #just blindly insert
+                    outstring = outstring + current_bit[:maxwraplength-1] + "\\\n"
+                    current_bit = current_bit[maxwraplength-1:]
+            outstring = outstring + current_bit
+            if current_bit[-1] == '\\':  #a backslash just happens to be here
+                outstring = outstring + "\\\n"
+            outstring = outstring + '\n'
+    outstring = outstring[:-1]  #remove final newline
+    return outstring
+
+def remove_line_folding(instring):
+    """Remove line folding from instring"""
+    if re.match(r"\\[ \v\t\f]*" +"\n",instring) is not None:
+        return re.sub(r"\\[ \v\t\f]*$" + "\n?","",instring,flags=re.M)
+    else:
+        return instring
+
+def apply_line_prefix(instring,prefix):
+    """Prefix every line in instring with prefix"""
+    if prefix[0] != ";" and "\\" not in prefix:
+        header = re.match(r"(\\[ \v\t\f]*" +"\n)",instring)
+        if header is not None:
+            print('Found line folded string for prefixing...')
+            not_header = instring[header.end():]
+            outstring = prefix + "\\\\\n" + prefix
+        else:
+            print('No folding in input string...')
+            not_header = instring
+            outstring = prefix + "\\\n" + prefix
+        outstring = outstring + not_header.replace("\n","\n"+prefix)
+        return outstring
+    raise StarError("Requested prefix starts with semicolon or contains a backslash: " + prefix)
+
+def remove_line_prefix(instring):
+    """Remove prefix from every line if present"""
+    prefix_match = re.match("(?P<prefix>[^;\\\n][^\n\\\\]+)(?P<folding>\\\\{1,2}[ \t\v\f]*\n)",instring)
+    if prefix_match is not None:
+        prefix_text = prefix_match.group('prefix')
+        print('Found prefix %s' % prefix_text)
+        prefix_end = prefix_match.end('folding')
+        # keep any line folding instructions
+        if prefix_match.group('folding')[:2]=='\\\\':  #two backslashes
+            outstring = instring[prefix_match.end('folding')-1:].replace("\n"+prefix_text,"\n")
+            return "\\" + outstring  #keep line folding first line
+        else:
+            outstring = instring[prefix_match.end('folding')-1:].replace("\n"+prefix_text,"\n")
+            return outstring[1:]   #drop first line ending, no longer necessary
+    else:
+        return instring
+
+
+def listify(item):
+    if isinstance(item,unicode): return [item]
+    else: return item
+
+#Transpose the list of lists passed to us
+def transpose(base_list):
+    new_lofl = []
+    full_length = len(base_list)
+    opt_range = range(full_length)
+    for i in range(len(base_list[0])):
+       new_packet = []
+       for j in opt_range:
+          new_packet.append(base_list[j][i])
+       new_lofl.append(new_packet)
+    return new_lofl
+
+# This routine optimised to return as quickly as possible
+# as it is called a lot.
+def not_none(itemlist):
+    """Return true only if no values of None are present"""
+    if itemlist is None:
+        return False
+    if not isinstance(itemlist,(tuple,list)):
+        return True
+    for x in itemlist:
+       if not not_none(x): return False
+    return True
+
+
+def check_stringiness(data):
+   """Check that the contents of data are all strings"""
+   if not hasattr(data,'dtype'):   #so not Numpy
+       from numbers import Number
+       if isinstance(data,Number): return False
+       elif isinstance(data,(unicode,str)): return True
+       elif data is None:return False  #should be data are None :)
+       else:
+           for one_item in data:
+               if not check_stringiness(one_item): return False
+           return True   #all must be strings
+   else:   #numerical python
+       import numpy
+       if data.ndim == 0:    #a bare value
+           if data.dtype.kind in ['S','U']: return True
+           else: return False
+       else:
+           for one_item in numpy.nditer(data):
+               print('numpy data: ' + repr( one_item ))
+               if not check_stringiness(one_item): return False
+           return True
+
+def process_template(template_file):
+    """Process a template datafile to formatting instructions"""
+    template_as_cif = StarFile(template_file,grammar="2.0").first_block()
+    if isinstance(template_file,(unicode,str)):
+        template_string = open(template_file).read()
+    else:   #a StringIO object
+        template_file.seek(0)   #reset
+        template_string = template_file.read()
+    #template_as_lines = template_string.split("\n")
+    #template_as_lines = [l for l in template_as_lines if len(l)>0 and l[0]!='#']
+    #template_as_lines = [l for l in template_as_lines if l.split()[0] != 'loop_']
+    #template_full_lines = dict([(l.split()[0],l) for l in template_as_lines if len(l.split())>0])
+    form_hints = []   #ordered array of hint dictionaries
+    find_indent = "^ +"
+    for item in template_as_cif.item_order:  #order of input
+        if not isinstance(item,int):    #not nested
+            hint_dict = {"dataname":item}
+            # find the line in the file
+            start_pos = re.search("(^[ \t]*(?P<name>" + item + ")[ \t\n]+)(?P<spec>([\\S]+)|(^;))",template_string,re.I|re.M)
+            if start_pos.group("spec") != None:
+                spec_pos = start_pos.start("spec")-start_pos.start(0)
+                spec_char = template_string[start_pos.start("spec"):start_pos.start("spec")+3]
+                if spec_char[0] in '\'";':
+                    hint_dict.update({"delimiter":spec_char[0]})
+                    if spec_char == '"""' or spec_char == "'''":
+                        hint_dict.update({"delimiter":spec_char})
+                if spec_char[0] != ";":   #so we need to work out the column number
+                    hint_dict.update({"column":spec_pos})
+                else:                  #need to put in the carriage return
+                    hint_dict.update({"delimiter":"\n;"})
+                    # can we format the text?
+                    text_val = template_as_cif[item]
+                    hint_dict["reformat"] = "\n\t" in text_val or "\n  " in text_val
+                    if hint_dict["reformat"]:   #find the indentation
+                        p = re.search(find_indent,text_val,re.M)
+                        if p.group() is not None:
+                            hint_dict["reformat_indent"]=p.end() - p.start()
+                if start_pos.group('name') != None:
+                    name_pos = start_pos.start('name') - start_pos.start(0)
+                    hint_dict.update({"name_pos":name_pos})
+            #print '%s: %s' % (item,`hint_dict`)
+            form_hints.append(hint_dict)
+        else:           #loop block
+            testnames = template_as_cif.loops[item]
+            total_items = len(template_as_cif.loops[item])
+            testname = testnames[0]
+            #find the loop spec line in the file
+            loop_regex = "(^[ \t]*(?P<loop>loop_)[ \t\n\r]+(?P<name>" + testname + ")([ \t\n\r]+_[\\S]+){%d}[ \t]*$(?P<packet>(.(?!_loop|_[\\S]+))*))" % (total_items - 1)
+            loop_line = re.search(loop_regex,template_string,re.I|re.M|re.S)
+            loop_so_far = loop_line.end()
+            packet_text = loop_line.group('packet')
+            loop_indent = loop_line.start('loop') - loop_line.start(0)
+            form_hints.append({"dataname":'loop','name_pos':loop_indent})
+            packet_regex = "[ \t]*(?P<all>(?P<sqqq>'''([^\n\r\f']*)''')|(?P<sq>'([^\n\r\f']*)'+)|(?P<dq>\"([^\n\r\"]*)\"+)|(?P<none>[^\\s]+))"
+            packet_pos = re.finditer(packet_regex,packet_text)
+            line_end_pos = re.finditer("^",packet_text,re.M)
+            next_end = next(line_end_pos).end()
+            last_end = next_end
+            for loopname in testnames:
+                #find the name in the file for name pos
+                name_regex = "(^[ \t]*(?P<name>" + loopname + "))"
+                name_match = re.search(name_regex,template_string,re.I|re.M|re.S)
+                loop_name_indent = name_match.start('name')-name_match.start(0)
+                hint_dict = {"dataname":loopname,"name_pos":loop_name_indent}
+                #find the value
+                thismatch = next(packet_pos)
+                while thismatch.start('all') > next_end:
+                    try:
+                        last_end = next_end
+                        next_end = next(line_end_pos).start()
+                        print('next end %d' % next_end)
+                    except StopIteration:
+                        break
+                print('Start %d, last_end %d' % (thismatch.start('all'),last_end))
+                col_pos = thismatch.start('all') - last_end + 1
+                if thismatch.group('none') is None:
+                    if thismatch.group('sqqq') is not None:
+                        hint_dict.update({'delimiter':"'''"})
+                    else:
+                        hint_dict.update({'delimiter':thismatch.groups()[0][0]})
+                hint_dict.update({'column':col_pos})
+                print('%s: %s' % (loopname,repr( hint_dict )))
+                form_hints.append(hint_dict)
+    return form_hints
+
+
+#No documentation flags
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/TypeContentsParser.py` & `pyemaps-1.0.9/CifFile/src/TypeContentsParser.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,82 +1,82 @@
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-#
-# helper code: we define our match tokens
-lastval = ''
-def monitor(location,value):
-    global lastval
-    #print 'At %s: %s' % (location,repr(value))
-    lastval = repr(value)
-    return value
-
-
-# Begin -- grammar generated by Yapps
-import sys, re
-from . import yapps3_compiled_rt as yappsrt
-
-class TypeParserScanner(yappsrt.Scanner):
-    def __init__(self, *args,**kwargs):
-        patterns = [
-         ('([ \t\n\r])', '([ \t\n\r])'),
-         ('container', '[A-Za-z]+\\('),
-         ('identifier', '[A-Za-z]+'),
-         ('c_c_b', '\\)'),
-         ('o_c_b', '\\('),
-         ('comma', '\\,'),
-         ('END', '$'),
-        ]
-        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r])'],*args,**kwargs)
-
-class TypeParser(yappsrt.Parser):
-    Context = yappsrt.Context
-    def input(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'input', [])
-        base_element = self.base_element(_context)
-        p = [base_element]
-        while self._peek('END', 'comma') == 'comma':
-            comma = self._scan('comma')
-            base_element = self.base_element(_context)
-            p.append(base_element)
-        if self._peek() not in ['END', 'comma']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['comma', 'END']))
-        END = self._scan('END')
-        if len(p)==1: p = p[0]
-        return p
-
-    def base_element(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'base_element', [])
-        _token = self._peek('container', 'identifier')
-        if _token == 'container':
-            container = self._scan('container')
-            element_list = self.element_list(_context)
-            c_c_b = self._scan('c_c_b')
-            return element_list
-        else: # == 'identifier'
-            identifier = self._scan('identifier')
-        return identifier
-
-    def element_list(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'element_list', [])
-        base_element = self.base_element(_context)
-        p = [base_element]
-        while self._peek('comma', 'c_c_b') == 'comma':
-            comma = self._scan('comma')
-            base_element = self.base_element(_context)
-            p.append(base_element)
-        if self._peek() not in ['comma', 'c_c_b']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['comma', 'c_c_b']))
-        return p
-
-
-def parse(rule, text):
-    P = TypeParser(TypeParserScanner(text))
-    return yappsrt.wrap_error_reporter(P, rule)
-
-# End -- grammar generated by Yapps
-
-
-
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+#
+# helper code: we define our match tokens
+lastval = ''
+def monitor(location,value):
+    global lastval
+    #print 'At %s: %s' % (location,repr(value))
+    lastval = repr(value)
+    return value
+
+
+# Begin -- grammar generated by Yapps
+import sys, re
+from . import yapps3_compiled_rt as yappsrt
+
+class TypeParserScanner(yappsrt.Scanner):
+    def __init__(self, *args,**kwargs):
+        patterns = [
+         ('([ \t\n\r])', '([ \t\n\r])'),
+         ('container', '[A-Za-z]+\\('),
+         ('identifier', '[A-Za-z]+'),
+         ('c_c_b', '\\)'),
+         ('o_c_b', '\\('),
+         ('comma', '\\,'),
+         ('END', '$'),
+        ]
+        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r])'],*args,**kwargs)
+
+class TypeParser(yappsrt.Parser):
+    Context = yappsrt.Context
+    def input(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'input', [])
+        base_element = self.base_element(_context)
+        p = [base_element]
+        while self._peek('END', 'comma') == 'comma':
+            comma = self._scan('comma')
+            base_element = self.base_element(_context)
+            p.append(base_element)
+        if self._peek() not in ['END', 'comma']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['comma', 'END']))
+        END = self._scan('END')
+        if len(p)==1: p = p[0]
+        return p
+
+    def base_element(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'base_element', [])
+        _token = self._peek('container', 'identifier')
+        if _token == 'container':
+            container = self._scan('container')
+            element_list = self.element_list(_context)
+            c_c_b = self._scan('c_c_b')
+            return element_list
+        else: # == 'identifier'
+            identifier = self._scan('identifier')
+        return identifier
+
+    def element_list(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'element_list', [])
+        base_element = self.base_element(_context)
+        p = [base_element]
+        while self._peek('comma', 'c_c_b') == 'comma':
+            comma = self._scan('comma')
+            base_element = self.base_element(_context)
+            p.append(base_element)
+        if self._peek() not in ['comma', 'c_c_b']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['comma', 'c_c_b']))
+        return p
+
+
+def parse(rule, text):
+    P = TypeParser(TypeParserScanner(text))
+    return yappsrt.wrap_error_reporter(P, rule)
+
+# End -- grammar generated by Yapps
+
+
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/YappsStarParser_1_0.py` & `pyemaps-1.0.9/CifFile/src/YappsStarParser_1_0.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,289 +1,289 @@
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-from .StarFile import StarBlock,StarFile,StarList,StarDict
-from io import StringIO
-# An alternative specification for the Cif Parser, based on Yapps2
-# by Amit Patel (http://theory.stanford.edu/~amitp/Yapps)
-#
-# helper code: we define our match tokens
-lastval = ''
-def monitor(location,value):
-    global lastval
-    #print 'At %s: %s' % (location,repr(value))
-    lastval = repr(value)
-    return value
-
-# Strip extras gets rid of leading and trailing whitespace, and
-# semicolons.
-def stripextras(value):
-     from .StarFile import remove_line_folding, remove_line_prefix
-     # we get rid of semicolons and leading/trailing terminators etc.
-     import re
-     jj = re.compile("[\n\r\f \t\v]*")
-     semis = re.compile("[\n\r\f \t\v]*[\n\r\f]\n*;")
-     cut = semis.match(value)
-     if cut:        #we have a semicolon-delimited string
-          nv = value[cut.end():len(value)-2]
-          try:
-             if nv[-1]=='\r': nv = nv[:-1]
-          except IndexError:    #empty data value
-             pass
-          # apply protocols
-          nv = remove_line_prefix(nv)
-          nv = remove_line_folding(nv)
-          return nv
-     else:
-          cut = jj.match(value)
-          if cut:
-               return stripstring(value[cut.end():])
-          return value
-
-# helper function to get rid of inverted commas etc.
-
-def stripstring(value):
-     if value:
-         if value[0]== '\'' and value[-1]=='\'':
-           return value[1:-1]
-         if value[0]=='"' and value[-1]=='"':
-           return value[1:-1]
-     return value
-
-# helper function to get rid of triple quotes
-def striptriple(value):
-    if value:
-        if value[:3] == '"""' and value[-3:] == '"""':
-            return value[3:-3]
-        if value[:3] == "'''" and value[-3:] == "'''":
-            return value[3:-3]
-    return value
-
-# helper function to populate a StarBlock given a list of names
-# and values .
-#
-# Note that there may be an empty list at the very end of our itemlists,
-# so we remove that if necessary.
-#
-
-def makeloop(target_block,loopdata):
-    loop_seq,itemlists = loopdata
-    if itemlists[-1] == []: itemlists.pop(-1)
-    # print('Making loop with %s' % repr(itemlists))
-    step_size = len(loop_seq)
-    for col_no in range(step_size):
-       target_block.AddItem(loop_seq[col_no], itemlists[col_no::step_size],precheck=True)
-    # now construct the loop
-    try:
-        target_block.CreateLoop(loop_seq)  #will raise ValueError on problem
-    except ValueError:
-        error_string =  'Incorrect number of loop values for loop containing %s' % repr(loop_seq)
-        print(error_string, file=sys.stderr)
-        raise ValueError(error_string)
-
-# return an object with the appropriate amount of nesting
-def make_empty(nestlevel):
-    gd = []
-    for i in range(1,nestlevel):
-        gd = [gd]
-    return gd
-
-# this function updates a dictionary first checking for name collisions,
-# which imply that the CIF is invalid.  We need case insensitivity for
-# names.
-
-# Unfortunately we cannot check loop item contents against non-loop contents
-# in a non-messy way during parsing, as we may not have easy access to previous
-# key value pairs in the context of our call (unlike our built-in access to all
-# previous loops).
-# For this reason, we don't waste time checking looped items against non-looped
-# names during parsing of a data block.  This would only match a subset of the
-# final items.   We do check against ordinary items, however.
-#
-# Note the following situations:
-# (1) new_dict is empty -> we have just added a loop; do no checking
-# (2) new_dict is not empty -> we have some new key-value pairs
-#
-def cif_update(old_dict,new_dict,loops):
-    old_keys = map(lambda a:a.lower(),old_dict.keys())
-    if new_dict != {}:    # otherwise we have a new loop
-        #print 'Comparing %s to %s' % (repr(old_keys),repr(new_dict.keys()))
-        for new_key in new_dict.keys():
-            if new_key.lower() in old_keys:
-                raise CifError("Duplicate dataname or blockname %s in input file" % new_key)
-            old_dict[new_key] = new_dict[new_key]
-#
-# this takes two lines, so we couldn't fit it into a one line execution statement...
-def order_update(order_array,new_name):
-    order_array.append(new_name)
-    return new_name
-
-# and finally...turn a sequence into a python dict (thanks to Stackoverflow)
-def pairwise(iterable):
-    try:
-        it = iter(iterable)
-        while 1:
-            yield next(it), next(it)
-    except StopIteration:
-        return
-
-# Begin -- grammar generated by Yapps
-import sys, re
-from . import yapps3_compiled_rt as yappsrt
-
-class StarParserScanner(yappsrt.Scanner):
-    def __init__(self, *args,**kwargs):
-        patterns = [
-         ('([ \t\n\r](?!;))|[ \t]', '([ \t\n\r](?!;))|[ \t]'),
-         ('(#.*[\n\r](?!;))|(#.*)', '(#.*[\n\r](?!;))|(#.*)'),
-         ('LBLOCK', '(L|l)(O|o)(O|o)(P|p)_'),
-         ('GLOBAL', '(G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_'),
-         ('STOP', '(S|s)(T|t)(O|o)(P|p)_'),
-         ('save_heading', '(S|s)(A|a)(V|v)(E|e)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_-]+'),
-         ('save_end', '(S|s)(A|a)(V|v)(E|e)_'),
-         ('data_name', '_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_-]+'),
-         ('data_heading', '(D|d)(A|a)(T|t)(A|a)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_-]+'),
-         ('start_sc_line', '(\n|\r\n);([^\n\r])*(\r\n|\r|\n)+'),
-         ('sc_line_of_text', '[^;\r\n]([^\r\n])*(\r\n|\r|\n)+'),
-         ('end_sc_line', ';'),
-         ('data_value_1', '((?!(((S|s)(A|a)(V|v)(E|e)_[^\\s]*)|((G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_[^\\s]*)|((S|s)(T|t)(O|o)(P|p)_[^\\s]*)|((D|d)(A|a)(T|t)(A|a)_[^\\s]*)))[^\\s"#$\'_][^\\s]*)|\'((\'(?=\\S))|([^\n\r\x0c\']))*\'+|"(("(?=\\S))|([^\n\r"]))*"+'),
-         ('END', '$'),
-        ]
-        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r](?!;))|[ \t]', '(#.*[\n\r](?!;))|(#.*)'],*args,**kwargs)
-
-class StarParser(yappsrt.Parser):
-    Context = yappsrt.Context
-    def input(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'input', [prepared])
-        _token = self._peek('END', 'data_heading')
-        if _token == 'data_heading':
-            dblock = self.dblock(prepared, _context)
-            allblocks = prepared;allblocks.merge_fast(dblock)
-            while self._peek('END', 'data_heading') == 'data_heading':
-                dblock = self.dblock(prepared, _context)
-                allblocks.merge_fast(dblock)
-            if self._peek() not in ['END', 'data_heading']:
-                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['END', 'data_heading']))
-            END = self._scan('END')
-        else: # == 'END'
-            END = self._scan('END')
-            allblocks = prepared
-        allblocks.unlock();return allblocks
-
-    def dblock(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'dblock', [prepared])
-        data_heading = self._scan('data_heading')
-        heading = data_heading[5:];thisbc=StarFile(characterset='unicode',standard=prepared.standard);newname = thisbc.NewBlock(heading,prepared.blocktype(overwrite=False));act_block=thisbc[newname]
-        while self._peek('save_heading', 'LBLOCK', 'data_name', 'save_end', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
-            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
-            if _token != 'save_heading':
-                dataseq = self.dataseq(thisbc[heading], _context)
-            else: # == 'save_heading'
-                save_frame = self.save_frame(prepared, _context)
-                thisbc.merge_fast(save_frame,parent=act_block)
-        if self._peek() not in ['save_heading', 'LBLOCK', 'data_name', 'save_end', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_heading', 'LBLOCK', 'data_name', 'save_end', 'END', 'data_heading']))
-        thisbc[heading].setmaxnamelength(thisbc[heading].maxnamelength);return (monitor('dblock',thisbc))
-
-    def dataseq(self, starblock, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'dataseq', [starblock])
-        data = self.data(starblock, _context)
-        while self._peek('LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
-            data = self.data(starblock, _context)
-        if self._peek() not in ['LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']))
-
-    def data(self, currentblock, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'data', [currentblock])
-        _token = self._peek('LBLOCK', 'data_name')
-        if _token == 'LBLOCK':
-            top_loop = self.top_loop(_context)
-            makeloop(currentblock,top_loop)
-        else: # == 'data_name'
-            datakvpair = self.datakvpair(_context)
-            currentblock.AddItem(datakvpair[0],datakvpair[1],precheck=True)
-
-    def datakvpair(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'datakvpair', [])
-        data_name = self._scan('data_name')
-        data_value = self.data_value(_context)
-        return [data_name,data_value]
-
-    def data_value(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'data_value', [])
-        _token = self._peek('data_value_1', 'start_sc_line')
-        if _token == 'data_value_1':
-            data_value_1 = self._scan('data_value_1')
-            thisval = stripstring(data_value_1)
-        else: # == 'start_sc_line'
-            sc_lines_of_text = self.sc_lines_of_text(_context)
-            thisval = stripextras(sc_lines_of_text)
-        return monitor('data_value',thisval)
-
-    def sc_lines_of_text(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'sc_lines_of_text', [])
-        start_sc_line = self._scan('start_sc_line')
-        lines = StringIO();lines.write(start_sc_line)
-        while self._peek('end_sc_line', 'sc_line_of_text') == 'sc_line_of_text':
-            sc_line_of_text = self._scan('sc_line_of_text')
-            lines.write(sc_line_of_text)
-        if self._peek() not in ['end_sc_line', 'sc_line_of_text']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['sc_line_of_text', 'end_sc_line']))
-        end_sc_line = self._scan('end_sc_line')
-        lines.write(end_sc_line);return monitor('sc_line_of_text',lines.getvalue())
-
-    def top_loop(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'top_loop', [])
-        LBLOCK = self._scan('LBLOCK')
-        loopfield = self.loopfield(_context)
-        loopvalues = self.loopvalues(_context)
-        return loopfield,loopvalues
-
-    def loopfield(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'loopfield', [])
-        toploop=[]
-        while self._peek('data_name', 'data_value_1', 'start_sc_line') == 'data_name':
-            data_name = self._scan('data_name')
-            toploop.append(data_name)
-        if self._peek() not in ['data_name', 'data_value_1', 'start_sc_line']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_name', 'data_value_1', 'start_sc_line']))
-        return toploop
-
-    def loopvalues(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'loopvalues', [])
-        data_value = self.data_value(_context)
-        dataloop=[data_value]
-        while self._peek('data_value_1', 'start_sc_line', 'LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading') in ['data_value_1', 'start_sc_line']:
-            data_value = self.data_value(_context)
-            dataloop.append(monitor('loopval',data_value))
-        if self._peek() not in ['data_value_1', 'start_sc_line', 'LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'start_sc_line', 'LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']))
-        return dataloop
-
-    def save_frame(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
-        save_heading = self._scan('save_heading')
-        savehead = save_heading[5:];savebc = StarFile();newname=savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));act_block=savebc[newname]
-        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
-            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
-            if _token != 'save_heading':
-                dataseq = self.dataseq(savebc[savehead], _context)
-            else: # == 'save_heading'
-                save_frame = self.save_frame(prepared, _context)
-                savebc.merge_fast(save_frame,parent=act_block)
-        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']))
-        save_end = self._scan('save_end')
-        return monitor('save_frame',savebc)
-
-
-def parse(rule, text):
-    P = StarParser(StarParserScanner(text))
-    return yappsrt.wrap_error_reporter(P, rule)
-
-# End -- grammar generated by Yapps
-
-
-
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+from .StarFile import StarBlock,StarFile,StarList,StarDict
+from io import StringIO
+# An alternative specification for the Cif Parser, based on Yapps2
+# by Amit Patel (http://theory.stanford.edu/~amitp/Yapps)
+#
+# helper code: we define our match tokens
+lastval = ''
+def monitor(location,value):
+    global lastval
+    #print 'At %s: %s' % (location,repr(value))
+    lastval = repr(value)
+    return value
+
+# Strip extras gets rid of leading and trailing whitespace, and
+# semicolons.
+def stripextras(value):
+     from .StarFile import remove_line_folding, remove_line_prefix
+     # we get rid of semicolons and leading/trailing terminators etc.
+     import re
+     jj = re.compile("[\n\r\f \t\v]*")
+     semis = re.compile("[\n\r\f \t\v]*[\n\r\f]\n*;")
+     cut = semis.match(value)
+     if cut:        #we have a semicolon-delimited string
+          nv = value[cut.end():len(value)-2]
+          try:
+             if nv[-1]=='\r': nv = nv[:-1]
+          except IndexError:    #empty data value
+             pass
+          # apply protocols
+          nv = remove_line_prefix(nv)
+          nv = remove_line_folding(nv)
+          return nv
+     else:
+          cut = jj.match(value)
+          if cut:
+               return stripstring(value[cut.end():])
+          return value
+
+# helper function to get rid of inverted commas etc.
+
+def stripstring(value):
+     if value:
+         if value[0]== '\'' and value[-1]=='\'':
+           return value[1:-1]
+         if value[0]=='"' and value[-1]=='"':
+           return value[1:-1]
+     return value
+
+# helper function to get rid of triple quotes
+def striptriple(value):
+    if value:
+        if value[:3] == '"""' and value[-3:] == '"""':
+            return value[3:-3]
+        if value[:3] == "'''" and value[-3:] == "'''":
+            return value[3:-3]
+    return value
+
+# helper function to populate a StarBlock given a list of names
+# and values .
+#
+# Note that there may be an empty list at the very end of our itemlists,
+# so we remove that if necessary.
+#
+
+def makeloop(target_block,loopdata):
+    loop_seq,itemlists = loopdata
+    if itemlists[-1] == []: itemlists.pop(-1)
+    # print('Making loop with %s' % repr(itemlists))
+    step_size = len(loop_seq)
+    for col_no in range(step_size):
+       target_block.AddItem(loop_seq[col_no], itemlists[col_no::step_size],precheck=True)
+    # now construct the loop
+    try:
+        target_block.CreateLoop(loop_seq)  #will raise ValueError on problem
+    except ValueError:
+        error_string =  'Incorrect number of loop values for loop containing %s' % repr(loop_seq)
+        print(error_string, file=sys.stderr)
+        raise ValueError(error_string)
+
+# return an object with the appropriate amount of nesting
+def make_empty(nestlevel):
+    gd = []
+    for i in range(1,nestlevel):
+        gd = [gd]
+    return gd
+
+# this function updates a dictionary first checking for name collisions,
+# which imply that the CIF is invalid.  We need case insensitivity for
+# names.
+
+# Unfortunately we cannot check loop item contents against non-loop contents
+# in a non-messy way during parsing, as we may not have easy access to previous
+# key value pairs in the context of our call (unlike our built-in access to all
+# previous loops).
+# For this reason, we don't waste time checking looped items against non-looped
+# names during parsing of a data block.  This would only match a subset of the
+# final items.   We do check against ordinary items, however.
+#
+# Note the following situations:
+# (1) new_dict is empty -> we have just added a loop; do no checking
+# (2) new_dict is not empty -> we have some new key-value pairs
+#
+def cif_update(old_dict,new_dict,loops):
+    old_keys = map(lambda a:a.lower(),old_dict.keys())
+    if new_dict != {}:    # otherwise we have a new loop
+        #print 'Comparing %s to %s' % (repr(old_keys),repr(new_dict.keys()))
+        for new_key in new_dict.keys():
+            if new_key.lower() in old_keys:
+                raise CifError("Duplicate dataname or blockname %s in input file" % new_key)
+            old_dict[new_key] = new_dict[new_key]
+#
+# this takes two lines, so we couldn't fit it into a one line execution statement...
+def order_update(order_array,new_name):
+    order_array.append(new_name)
+    return new_name
+
+# and finally...turn a sequence into a python dict (thanks to Stackoverflow)
+def pairwise(iterable):
+    try:
+        it = iter(iterable)
+        while 1:
+            yield next(it), next(it)
+    except StopIteration:
+        return
+
+# Begin -- grammar generated by Yapps
+import sys, re
+from . import yapps3_compiled_rt as yappsrt
+
+class StarParserScanner(yappsrt.Scanner):
+    def __init__(self, *args,**kwargs):
+        patterns = [
+         ('([ \t\n\r](?!;))|[ \t]', '([ \t\n\r](?!;))|[ \t]'),
+         ('(#.*[\n\r](?!;))|(#.*)', '(#.*[\n\r](?!;))|(#.*)'),
+         ('LBLOCK', '(L|l)(O|o)(O|o)(P|p)_'),
+         ('GLOBAL', '(G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_'),
+         ('STOP', '(S|s)(T|t)(O|o)(P|p)_'),
+         ('save_heading', '(S|s)(A|a)(V|v)(E|e)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_-]+'),
+         ('save_end', '(S|s)(A|a)(V|v)(E|e)_'),
+         ('data_name', '_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_-]+'),
+         ('data_heading', '(D|d)(A|a)(T|t)(A|a)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_-]+'),
+         ('start_sc_line', '(\n|\r\n);([^\n\r])*(\r\n|\r|\n)+'),
+         ('sc_line_of_text', '[^;\r\n]([^\r\n])*(\r\n|\r|\n)+'),
+         ('end_sc_line', ';'),
+         ('data_value_1', '((?!(((S|s)(A|a)(V|v)(E|e)_[^\\s]*)|((G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_[^\\s]*)|((S|s)(T|t)(O|o)(P|p)_[^\\s]*)|((D|d)(A|a)(T|t)(A|a)_[^\\s]*)))[^\\s"#$\'_][^\\s]*)|\'((\'(?=\\S))|([^\n\r\x0c\']))*\'+|"(("(?=\\S))|([^\n\r"]))*"+'),
+         ('END', '$'),
+        ]
+        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r](?!;))|[ \t]', '(#.*[\n\r](?!;))|(#.*)'],*args,**kwargs)
+
+class StarParser(yappsrt.Parser):
+    Context = yappsrt.Context
+    def input(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'input', [prepared])
+        _token = self._peek('END', 'data_heading')
+        if _token == 'data_heading':
+            dblock = self.dblock(prepared, _context)
+            allblocks = prepared;allblocks.merge_fast(dblock)
+            while self._peek('END', 'data_heading') == 'data_heading':
+                dblock = self.dblock(prepared, _context)
+                allblocks.merge_fast(dblock)
+            if self._peek() not in ['END', 'data_heading']:
+                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['END', 'data_heading']))
+            END = self._scan('END')
+        else: # == 'END'
+            END = self._scan('END')
+            allblocks = prepared
+        allblocks.unlock();return allblocks
+
+    def dblock(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'dblock', [prepared])
+        data_heading = self._scan('data_heading')
+        heading = data_heading[5:];thisbc=StarFile(characterset='unicode',standard=prepared.standard);newname = thisbc.NewBlock(heading,prepared.blocktype(overwrite=False));act_block=thisbc[newname]
+        while self._peek('save_heading', 'LBLOCK', 'data_name', 'save_end', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
+            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
+            if _token != 'save_heading':
+                dataseq = self.dataseq(thisbc[heading], _context)
+            else: # == 'save_heading'
+                save_frame = self.save_frame(prepared, _context)
+                thisbc.merge_fast(save_frame,parent=act_block)
+        if self._peek() not in ['save_heading', 'LBLOCK', 'data_name', 'save_end', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_heading', 'LBLOCK', 'data_name', 'save_end', 'END', 'data_heading']))
+        thisbc[heading].setmaxnamelength(thisbc[heading].maxnamelength);return (monitor('dblock',thisbc))
+
+    def dataseq(self, starblock, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'dataseq', [starblock])
+        data = self.data(starblock, _context)
+        while self._peek('LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
+            data = self.data(starblock, _context)
+        if self._peek() not in ['LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']))
+
+    def data(self, currentblock, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'data', [currentblock])
+        _token = self._peek('LBLOCK', 'data_name')
+        if _token == 'LBLOCK':
+            top_loop = self.top_loop(_context)
+            makeloop(currentblock,top_loop)
+        else: # == 'data_name'
+            datakvpair = self.datakvpair(_context)
+            currentblock.AddItem(datakvpair[0],datakvpair[1],precheck=True)
+
+    def datakvpair(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'datakvpair', [])
+        data_name = self._scan('data_name')
+        data_value = self.data_value(_context)
+        return [data_name,data_value]
+
+    def data_value(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'data_value', [])
+        _token = self._peek('data_value_1', 'start_sc_line')
+        if _token == 'data_value_1':
+            data_value_1 = self._scan('data_value_1')
+            thisval = stripstring(data_value_1)
+        else: # == 'start_sc_line'
+            sc_lines_of_text = self.sc_lines_of_text(_context)
+            thisval = stripextras(sc_lines_of_text)
+        return monitor('data_value',thisval)
+
+    def sc_lines_of_text(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'sc_lines_of_text', [])
+        start_sc_line = self._scan('start_sc_line')
+        lines = StringIO();lines.write(start_sc_line)
+        while self._peek('end_sc_line', 'sc_line_of_text') == 'sc_line_of_text':
+            sc_line_of_text = self._scan('sc_line_of_text')
+            lines.write(sc_line_of_text)
+        if self._peek() not in ['end_sc_line', 'sc_line_of_text']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['sc_line_of_text', 'end_sc_line']))
+        end_sc_line = self._scan('end_sc_line')
+        lines.write(end_sc_line);return monitor('sc_line_of_text',lines.getvalue())
+
+    def top_loop(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'top_loop', [])
+        LBLOCK = self._scan('LBLOCK')
+        loopfield = self.loopfield(_context)
+        loopvalues = self.loopvalues(_context)
+        return loopfield,loopvalues
+
+    def loopfield(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'loopfield', [])
+        toploop=[]
+        while self._peek('data_name', 'data_value_1', 'start_sc_line') == 'data_name':
+            data_name = self._scan('data_name')
+            toploop.append(data_name)
+        if self._peek() not in ['data_name', 'data_value_1', 'start_sc_line']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_name', 'data_value_1', 'start_sc_line']))
+        return toploop
+
+    def loopvalues(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'loopvalues', [])
+        data_value = self.data_value(_context)
+        dataloop=[data_value]
+        while self._peek('data_value_1', 'start_sc_line', 'LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading') in ['data_value_1', 'start_sc_line']:
+            data_value = self.data_value(_context)
+            dataloop.append(monitor('loopval',data_value))
+        if self._peek() not in ['data_value_1', 'start_sc_line', 'LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'start_sc_line', 'LBLOCK', 'data_name', 'save_heading', 'save_end', 'END', 'data_heading']))
+        return dataloop
+
+    def save_frame(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
+        save_heading = self._scan('save_heading')
+        savehead = save_heading[5:];savebc = StarFile();newname=savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));act_block=savebc[newname]
+        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
+            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
+            if _token != 'save_heading':
+                dataseq = self.dataseq(savebc[savehead], _context)
+            else: # == 'save_heading'
+                save_frame = self.save_frame(prepared, _context)
+                savebc.merge_fast(save_frame,parent=act_block)
+        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']))
+        save_end = self._scan('save_end')
+        return monitor('save_frame',savebc)
+
+
+def parse(rule, text):
+    P = StarParser(StarParserScanner(text))
+    return yappsrt.wrap_error_reporter(P, rule)
+
+# End -- grammar generated by Yapps
+
+
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/YappsStarParser_2_0.py` & `pyemaps-1.0.9/CifFile/src/YappsStarParser_STAR2.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,369 +1,382 @@
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-from .StarFile import StarBlock,StarFile,StarList,StarDict
-from io import StringIO
-# An alternative specification for the Cif Parser, based on Yapps2
-# by Amit Patel (http://theory.stanford.edu/~amitp/Yapps)
-#
-# helper code: we define our match tokens
-lastval = ''
-def monitor(location,value):
-    global lastval
-    #print 'At %s: %s' % (location,repr(value))
-    lastval = repr(value)
-    return value
-
-# Strip extras gets rid of leading and trailing whitespace, and
-# semicolons.
-def stripextras(value):
-     from .StarFile import remove_line_folding, remove_line_prefix
-     # we get rid of semicolons and leading/trailing terminators etc.
-     import re
-     jj = re.compile("[\n\r\f \t\v]*")
-     semis = re.compile("[\n\r\f \t\v]*[\n\r\f]\n*;")
-     cut = semis.match(value)
-     if cut:        #we have a semicolon-delimited string
-          nv = value[cut.end():len(value)-2]
-          try:
-             if nv[-1]=='\r': nv = nv[:-1]
-          except IndexError:    #empty data value
-             pass
-          # apply protocols
-          nv = remove_line_prefix(nv)
-          nv = remove_line_folding(nv)
-          return nv
-     else:
-          cut = jj.match(value)
-          if cut:
-               return stripstring(value[cut.end():])
-          return value
-
-# helper function to get rid of inverted commas etc.
-
-def stripstring(value):
-     if value:
-         if value[0]== '\'' and value[-1]=='\'':
-           return value[1:-1]
-         if value[0]=='"' and value[-1]=='"':
-           return value[1:-1]
-     return value
-
-# helper function to get rid of triple quotes
-def striptriple(value):
-    if value:
-        if value[:3] == '"""' and value[-3:] == '"""':
-            return value[3:-3]
-        if value[:3] == "'''" and value[-3:] == "'''":
-            return value[3:-3]
-    return value
-
-# helper function to populate a StarBlock given a list of names
-# and values .
-#
-# Note that there may be an empty list at the very end of our itemlists,
-# so we remove that if necessary.
-#
-
-def makeloop(target_block,loopdata):
-    loop_seq,itemlists = loopdata
-    if itemlists[-1] == []: itemlists.pop(-1)
-    # print('Making loop with %s' % repr(itemlists))
-    step_size = len(loop_seq)
-    for col_no in range(step_size):
-       target_block.AddItem(loop_seq[col_no], itemlists[col_no::step_size],precheck=True)
-    # now construct the loop
-    try:
-        target_block.CreateLoop(loop_seq)  #will raise ValueError on problem
-    except ValueError:
-        error_string =  'Incorrect number of loop values for loop containing %s' % repr(loop_seq)
-        print(error_string, file=sys.stderr)
-        raise ValueError(error_string)
-
-# return an object with the appropriate amount of nesting
-def make_empty(nestlevel):
-    gd = []
-    for i in range(1,nestlevel):
-        gd = [gd]
-    return gd
-
-# this function updates a dictionary first checking for name collisions,
-# which imply that the CIF is invalid.  We need case insensitivity for
-# names.
-
-# Unfortunately we cannot check loop item contents against non-loop contents
-# in a non-messy way during parsing, as we may not have easy access to previous
-# key value pairs in the context of our call (unlike our built-in access to all
-# previous loops).
-# For this reason, we don't waste time checking looped items against non-looped
-# names during parsing of a data block.  This would only match a subset of the
-# final items.   We do check against ordinary items, however.
-#
-# Note the following situations:
-# (1) new_dict is empty -> we have just added a loop; do no checking
-# (2) new_dict is not empty -> we have some new key-value pairs
-#
-def cif_update(old_dict,new_dict,loops):
-    old_keys = map(lambda a:a.lower(),old_dict.keys())
-    if new_dict != {}:    # otherwise we have a new loop
-        #print 'Comparing %s to %s' % (repr(old_keys),repr(new_dict.keys()))
-        for new_key in new_dict.keys():
-            if new_key.lower() in old_keys:
-                raise CifError("Duplicate dataname or blockname %s in input file" % new_key)
-            old_dict[new_key] = new_dict[new_key]
-#
-# this takes two lines, so we couldn't fit it into a one line execution statement...
-def order_update(order_array,new_name):
-    order_array.append(new_name)
-    return new_name
-
-# and finally...turn a sequence into a python dict (thanks to Stackoverflow)
-def pairwise(iterable):
-    try:
-        it = iter(iterable)
-        while 1:
-            yield next(it), next(it)
-    except StopIteration:
-        return
-
-# Begin -- grammar generated by Yapps
-import sys, re
-from . import yapps3_compiled_rt as yappsrt
-
-class StarParserScanner(yappsrt.Scanner):
-    def __init__(self, *args,**kwargs):
-        patterns = [
-         ('":"', ':'),
-         ('([ \t\n\r](?!;))|[ \t]', '([ \t\n\r](?!;))|[ \t]'),
-         ('(#.*[\n\r](?!;))|(#.*)', '(#.*[\n\r](?!;))|(#.*)'),
-         ('LBLOCK', '(L|l)(O|o)(O|o)(P|p)_'),
-         ('GLOBAL', '(G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_'),
-         ('STOP', '(S|s)(T|t)(O|o)(P|p)_'),
-         ('save_heading', u'(S|s)(A|a)(V|v)(E|e)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
-         ('save_end', '(S|s)(A|a)(V|v)(E|e)_'),
-         ('data_name', u'_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
-         ('data_heading', u'(D|d)(A|a)(T|t)(A|a)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
-         ('start_sc_line', '(\n|\r\n);([^\n\r])*(\r\n|\r|\n)+'),
-         ('sc_line_of_text', '[^;\r\n]([^\r\n])*(\r\n|\r|\n)+'),
-         ('end_sc_line', ';'),
-         ('c_c_b', '\\}'),
-         ('o_c_b', '\\{'),
-         ('c_s_b', '\\]'),
-         ('o_s_b', '\\['),
-         ('dat_val_internal_sq', '\\[([^\\s\\[\\]]*)\\]'),
-         ('triple_quote_data_value', '(?s)\'\'\'.*?\'\'\'|""".*?"""'),
-         ('single_quote_data_value', '\'([^\n\r\x0c\'])*\'+|"([^\n\r"])*"+'),
-         ('data_value_1', '((?!(((S|s)(A|a)(V|v)(E|e)_[^\\s]*)|((G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_[^\\s]*)|((S|s)(T|t)(O|o)(P|p)_[^\\s]*)|((D|d)(A|a)(T|t)(A|a)_[^\\s]*)))[^\\s"#$\'_\\{\\}\\[\\]][^\\s\\{\\}\\[\\]]*)'),
-         ('END', '$'),
-        ]
-        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r](?!;))|[ \t]', '(#.*[\n\r](?!;))|(#.*)'],*args,**kwargs)
-
-class StarParser(yappsrt.Parser):
-    Context = yappsrt.Context
-    def input(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'input', [prepared])
-        _token = self._peek('END', 'data_heading')
-        if _token == 'data_heading':
-            dblock = self.dblock(prepared, _context)
-            allblocks = prepared; allblocks.merge_fast(dblock)
-            while self._peek('END', 'data_heading') == 'data_heading':
-                dblock = self.dblock(prepared, _context)
-                allblocks.merge_fast(dblock)
-            if self._peek() not in ['END', 'data_heading']:
-                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['END', 'data_heading']))
-            END = self._scan('END')
-        else: # == 'END'
-            END = self._scan('END')
-            allblocks = prepared
-        allblocks.unlock(); return allblocks
-
-    def dblock(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'dblock', [prepared])
-        data_heading = self._scan('data_heading')
-        heading = data_heading[5:];thisbc=StarFile(characterset='unicode',standard=prepared.standard);act_heading = thisbc.NewBlock(heading,prepared.blocktype(overwrite=False));stored_block = thisbc[act_heading]
-        while self._peek('save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
-            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
-            if _token != 'save_heading':
-                dataseq = self.dataseq(stored_block, _context)
-            else: # == 'save_heading'
-                save_frame = self.save_frame(prepared, _context)
-                thisbc.merge_fast(save_frame,parent=stored_block)
-        if self._peek() not in ['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']))
-        stored_block.setmaxnamelength(stored_block.maxnamelength);return (monitor('dblock',thisbc))
-
-    def dataseq(self, starblock, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'dataseq', [starblock])
-        data = self.data(starblock, _context)
-        while self._peek('save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
-            data = self.data(starblock, _context)
-        if self._peek() not in ['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
-
-    def data(self, currentblock, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'data', [currentblock])
-        _token = self._peek('LBLOCK', 'data_name')
-        if _token == 'LBLOCK':
-            top_loop = self.top_loop(_context)
-            makeloop(currentblock,top_loop)
-        else: # == 'data_name'
-            datakvpair = self.datakvpair(_context)
-            currentblock.AddItem(datakvpair[0],datakvpair[1],precheck=False)
-
-    def datakvpair(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'datakvpair', [])
-        data_name = self._scan('data_name')
-        data_value = self.data_value(_context)
-        return [data_name,data_value]
-
-    def data_value(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'data_value', [])
-        _token = self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b')
-        if _token == 'data_value_1':
-            data_value_1 = self._scan('data_value_1')
-            thisval = data_value_1
-        elif _token not in ['start_sc_line', 'o_s_b', 'o_c_b']:
-            delimited_data_value = self.delimited_data_value(_context)
-            thisval = delimited_data_value
-        elif _token == 'start_sc_line':
-            sc_lines_of_text = self.sc_lines_of_text(_context)
-            thisval = stripextras(sc_lines_of_text)
-        else: # in ['o_s_b', 'o_c_b']
-            bracket_expression = self.bracket_expression(_context)
-            thisval = bracket_expression
-        return monitor('data_value',thisval)
-
-    def delimited_data_value(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'delimited_data_value', [])
-        _token = self._peek('triple_quote_data_value', 'single_quote_data_value')
-        if _token == 'triple_quote_data_value':
-            triple_quote_data_value = self._scan('triple_quote_data_value')
-            thisval = striptriple(triple_quote_data_value)
-        else: # == 'single_quote_data_value'
-            single_quote_data_value = self._scan('single_quote_data_value')
-            thisval = stripstring(single_quote_data_value)
-        return thisval
-
-    def sc_lines_of_text(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'sc_lines_of_text', [])
-        start_sc_line = self._scan('start_sc_line')
-        lines = StringIO();lines.write(start_sc_line)
-        while self._peek('end_sc_line', 'sc_line_of_text') == 'sc_line_of_text':
-            sc_line_of_text = self._scan('sc_line_of_text')
-            lines.write(sc_line_of_text)
-        if self._peek() not in ['end_sc_line', 'sc_line_of_text']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['sc_line_of_text', 'end_sc_line']))
-        end_sc_line = self._scan('end_sc_line')
-        lines.write(end_sc_line);return monitor('sc_line_of_text',lines.getvalue())
-
-    def bracket_expression(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'bracket_expression', [])
-        _token = self._peek('o_s_b', 'o_c_b')
-        if _token == 'o_s_b':
-            square_bracket_expr = self.square_bracket_expr(_context)
-            return square_bracket_expr
-        else: # == 'o_c_b'
-            curly_bracket_expr = self.curly_bracket_expr(_context)
-            return curly_bracket_expr
-
-    def top_loop(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'top_loop', [])
-        LBLOCK = self._scan('LBLOCK')
-        loopfield = self.loopfield(_context)
-        loopvalues = self.loopvalues(_context)
-        return loopfield,loopvalues
-
-    def loopfield(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'loopfield', [])
-        loop_seq=[]
-        while self._peek('data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') == 'data_name':
-            data_name = self._scan('data_name')
-            loop_seq.append(data_name)
-        if self._peek() not in ['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
-        return loop_seq
-
-    def loopvalues(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'loopvalues', [])
-        data_value = self.data_value(_context)
-        dataloop=[data_value]
-        while self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading') in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
-            data_value = self.data_value(_context)
-            dataloop.append(monitor('loopval',data_value))
-        if self._peek() not in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
-        return dataloop
-
-    def save_frame(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
-        save_heading = self._scan('save_heading')
-        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
-        while self._peek('save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
-            dataseq = self.dataseq(savebc[savehead], _context)
-        if self._peek() not in ['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']))
-        save_end = self._scan('save_end')
-        return monitor('save_frame',savebc)
-
-    def save_frame(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
-        save_heading = self._scan('save_heading')
-        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
-        while self._peek('save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
-            dataseq = self.dataseq(savebc[savehead], _context)
-        if self._peek() not in ['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']))
-        save_end = self._scan('save_end')
-        return monitor('save_frame',savebc)
-
-    def square_bracket_expr(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'square_bracket_expr', [])
-        o_s_b = self._scan('o_s_b')
-        this_list = []
-        while self._peek('c_s_b', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') != 'c_s_b':
-            data_value = self.data_value(_context)
-            this_list.append(data_value)
-            while self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'c_s_b', 'o_s_b', 'o_c_b') != 'c_s_b':
-                data_value = self.data_value(_context)
-                this_list.append(data_value)
-            if self._peek() not in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'c_s_b', 'o_s_b', 'o_c_b']:
-                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'c_s_b']))
-        if self._peek() not in ['c_s_b', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
-        c_s_b = self._scan('c_s_b')
-        return StarList(this_list)
-
-    def curly_bracket_expr(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'curly_bracket_expr', [])
-        o_c_b = self._scan('o_c_b')
-        table_as_list = []
-        while self._peek('c_c_b', 'triple_quote_data_value', 'single_quote_data_value') != 'c_c_b':
-            delimited_data_value = self.delimited_data_value(_context)
-            table_as_list = [delimited_data_value]
-            self._scan('":"')
-            data_value = self.data_value(_context)
-            table_as_list.append(data_value)
-            while self._peek('triple_quote_data_value', 'single_quote_data_value', 'c_c_b') != 'c_c_b':
-                delimited_data_value = self.delimited_data_value(_context)
-                table_as_list.append(delimited_data_value)
-                self._scan('":"')
-                data_value = self.data_value(_context)
-                table_as_list.append(data_value)
-            if self._peek() not in ['triple_quote_data_value', 'single_quote_data_value', 'c_c_b']:
-                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['triple_quote_data_value', 'single_quote_data_value', 'c_c_b']))
-        if self._peek() not in ['c_c_b', 'triple_quote_data_value', 'single_quote_data_value']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['triple_quote_data_value', 'single_quote_data_value', 'c_c_b']))
-        c_c_b = self._scan('c_c_b')
-        return StarDict(pairwise(table_as_list))
-
-
-def parse(rule, text):
-    P = StarParser(StarParserScanner(text))
-    return yappsrt.wrap_error_reporter(P, rule)
-
-# End -- grammar generated by Yapps
-
-
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+from .StarFile import StarBlock,StarFile,StarList,StarDict
+from io import StringIO
+# An alternative specification for the Cif Parser, based on Yapps2
+# by Amit Patel (http://theory.stanford.edu/~amitp/Yapps)
+#
+# helper code: we define our match tokens
+lastval = ''
+def monitor(location,value):
+    global lastval
+    #print 'At %s: %s' % (location,repr(value))
+    lastval = repr(value)
+    return value
+
+# Strip extras gets rid of leading and trailing whitespace, and
+# semicolons.
+def stripextras(value):
+     from .StarFile import remove_line_folding, remove_line_prefix
+     # we get rid of semicolons and leading/trailing terminators etc.
+     import re
+     jj = re.compile("[\n\r\f \t\v]*")
+     semis = re.compile("[\n\r\f \t\v]*[\n\r\f]\n*;")
+     cut = semis.match(value)
+     if cut:        #we have a semicolon-delimited string
+          nv = value[cut.end():len(value)-2]
+          try:
+             if nv[-1]=='\r': nv = nv[:-1]
+          except IndexError:    #empty data value
+             pass
+          # apply protocols
+          nv = remove_line_prefix(nv)
+          nv = remove_line_folding(nv)
+          return nv
+     else:
+          cut = jj.match(value)
+          if cut:
+               return stripstring(value[cut.end():])
+          return value
+
+# helper function to get rid of inverted commas etc.
+
+def stripstring(value):
+     if value:
+         if value[0]== '\'' and value[-1]=='\'':
+           return value[1:-1]
+         if value[0]=='"' and value[-1]=='"':
+           return value[1:-1]
+     return value
+
+# helper function to get rid of triple quotes
+def striptriple(value):
+    if value:
+        if value[:3] == '"""' and value[-3:] == '"""':
+            return value[3:-3]
+        if value[:3] == "'''" and value[-3:] == "'''":
+            return value[3:-3]
+    return value
+
+# helper function to populate a StarBlock given a list of names
+# and values .
+#
+# Note that there may be an empty list at the very end of our itemlists,
+# so we remove that if necessary.
+#
+
+def makeloop(target_block,loopdata):
+    loop_seq,itemlists = loopdata
+    if itemlists[-1] == []: itemlists.pop(-1)
+    # print('Making loop with %s' % repr(itemlists))
+    step_size = len(loop_seq)
+    for col_no in range(step_size):
+       target_block.AddItem(loop_seq[col_no], itemlists[col_no::step_size],precheck=True)
+    # now construct the loop
+    try:
+        target_block.CreateLoop(loop_seq)  #will raise ValueError on problem
+    except ValueError:
+        error_string =  'Incorrect number of loop values for loop containing %s' % repr(loop_seq)
+        print(error_string, file=sys.stderr)
+        raise ValueError(error_string)
+
+# return an object with the appropriate amount of nesting
+def make_empty(nestlevel):
+    gd = []
+    for i in range(1,nestlevel):
+        gd = [gd]
+    return gd
+
+# this function updates a dictionary first checking for name collisions,
+# which imply that the CIF is invalid.  We need case insensitivity for
+# names.
+
+# Unfortunately we cannot check loop item contents against non-loop contents
+# in a non-messy way during parsing, as we may not have easy access to previous
+# key value pairs in the context of our call (unlike our built-in access to all
+# previous loops).
+# For this reason, we don't waste time checking looped items against non-looped
+# names during parsing of a data block.  This would only match a subset of the
+# final items.   We do check against ordinary items, however.
+#
+# Note the following situations:
+# (1) new_dict is empty -> we have just added a loop; do no checking
+# (2) new_dict is not empty -> we have some new key-value pairs
+#
+def cif_update(old_dict,new_dict,loops):
+    old_keys = map(lambda a:a.lower(),old_dict.keys())
+    if new_dict != {}:    # otherwise we have a new loop
+        #print 'Comparing %s to %s' % (repr(old_keys),repr(new_dict.keys()))
+        for new_key in new_dict.keys():
+            if new_key.lower() in old_keys:
+                raise CifError("Duplicate dataname or blockname %s in input file" % new_key)
+            old_dict[new_key] = new_dict[new_key]
+#
+# this takes two lines, so we couldn't fit it into a one line execution statement...
+def order_update(order_array,new_name):
+    order_array.append(new_name)
+    return new_name
+
+# and finally...turn a sequence into a python dict (thanks to Stackoverflow)
+def pairwise(iterable):
+    try:
+        it = iter(iterable)
+        while 1:
+            yield next(it), next(it)
+    except StopIteration:
+        return
+
+# Begin -- grammar generated by Yapps
+import sys, re
+from . import yapps3_compiled_rt as yappsrt
+
+class StarParserScanner(yappsrt.Scanner):
+    def __init__(self, *args,**kwargs):
+        patterns = [
+         ('":"', ':'),
+         ('","', ','),
+         ('([ \t\n\r](?!;))|[ \t]', '([ \t\n\r](?!;))|[ \t]'),
+         ('(#.*[\n\r](?!;))|(#.*)', '(#.*[\n\r](?!;))|(#.*)'),
+         ('LBLOCK', '(L|l)(O|o)(O|o)(P|p)_'),
+         ('GLOBAL', '(G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_'),
+         ('STOP', '(S|s)(T|t)(O|o)(P|p)_'),
+         ('save_heading', u'(S|s)(A|a)(V|v)(E|e)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
+         ('save_end', '(S|s)(A|a)(V|v)(E|e)_'),
+         ('data_name', u'_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
+         ('data_heading', u'(D|d)(A|a)(T|t)(A|a)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
+         ('start_sc_line', '(\n|\r\n);([^\n\r])*(\r\n|\r|\n)+'),
+         ('sc_line_of_text', '[^;\r\n]([^\r\n])*(\r\n|\r|\n)+'),
+         ('end_sc_line', ';'),
+         ('c_c_b', '\\}'),
+         ('o_c_b', '\\{'),
+         ('c_s_b', '\\]'),
+         ('o_s_b', '\\['),
+         ('dat_val_internal_sq', '\\[([^\\s\\[\\]]*)\\]'),
+         ('triple_quote_data_value', '(?s)\'\'\'.*?\'\'\'|""".*?"""'),
+         ('single_quote_data_value', '\'([^\n\r\x0c\'])*\'+|"([^\n\r"])*"+'),
+         ('END', '$'),
+         ('data_value_1', '((?!(((S|s)(A|a)(V|v)(E|e)_[^\\s]*)|((G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_[^\\s]*)|((S|s)(T|t)(O|o)(P|p)_[^\\s]*)|((D|d)(A|a)(T|t)(A|a)_[^\\s]*)))[^\\s"#$\',_\\{\\}\\[\\]][^\\s,\\{\\}\\[\\]]*)'),
+        ]
+        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r](?!;))|[ \t]', '(#.*[\n\r](?!;))|(#.*)'],*args,**kwargs)
+
+class StarParser(yappsrt.Parser):
+    Context = yappsrt.Context
+    def input(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'input', [prepared])
+        _token = self._peek('END', 'data_heading')
+        if _token == 'data_heading':
+            dblock = self.dblock(prepared, _context)
+            allblocks = prepared; allblocks.merge_fast(dblock)
+            while self._peek('END', 'data_heading') == 'data_heading':
+                dblock = self.dblock(prepared, _context)
+                allblocks.merge_fast(dblock)
+            if self._peek() not in ['END', 'data_heading']:
+                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['END', 'data_heading']))
+            END = self._scan('END')
+        else: # == 'END'
+            END = self._scan('END')
+            allblocks = prepared
+        allblocks.unlock(); return allblocks
+
+    def dblock(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'dblock', [prepared])
+        data_heading = self._scan('data_heading')
+        heading = data_heading[5:];thisbc=StarFile(characterset='unicode',standard=prepared.standard);act_heading = thisbc.NewBlock(heading,prepared.blocktype(overwrite=False));stored_block = thisbc[act_heading]
+        while self._peek('save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
+            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
+            if _token != 'save_heading':
+                dataseq = self.dataseq(stored_block, _context)
+            else: # == 'save_heading'
+                save_frame = self.save_frame(prepared, _context)
+                thisbc.merge_fast(save_frame,parent=stored_block)
+        if self._peek() not in ['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']))
+        stored_block.setmaxnamelength(stored_block.maxnamelength);return (monitor('dblock',thisbc))
+
+    def dataseq(self, starblock, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'dataseq', [starblock])
+        data = self.data(starblock, _context)
+        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
+            data = self.data(starblock, _context)
+        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
+
+    def data(self, currentblock, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'data', [currentblock])
+        _token = self._peek('LBLOCK', 'data_name')
+        if _token == 'LBLOCK':
+            top_loop = self.top_loop(_context)
+            makeloop(currentblock,top_loop)
+        else: # == 'data_name'
+            datakvpair = self.datakvpair(_context)
+            currentblock.AddItem(datakvpair[0],datakvpair[1],precheck=False)
+
+    def datakvpair(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'datakvpair', [])
+        data_name = self._scan('data_name')
+        data_value = self.data_value(_context)
+        return [data_name,data_value]
+
+    def data_value(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'data_value', [])
+        _token = self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b')
+        if _token == 'data_value_1':
+            data_value_1 = self._scan('data_value_1')
+            thisval = data_value_1
+        elif _token not in ['start_sc_line', 'o_s_b', 'o_c_b']:
+            delimited_data_value = self.delimited_data_value(_context)
+            thisval = delimited_data_value
+        elif _token == 'start_sc_line':
+            sc_lines_of_text = self.sc_lines_of_text(_context)
+            thisval = stripextras(sc_lines_of_text)
+        else: # in ['o_s_b', 'o_c_b']
+            bracket_expression = self.bracket_expression(_context)
+            thisval = bracket_expression
+        return monitor('data_value',thisval)
+
+    def delimited_data_value(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'delimited_data_value', [])
+        _token = self._peek('triple_quote_data_value', 'single_quote_data_value')
+        if _token == 'triple_quote_data_value':
+            triple_quote_data_value = self._scan('triple_quote_data_value')
+            thisval = striptriple(triple_quote_data_value)
+        else: # == 'single_quote_data_value'
+            single_quote_data_value = self._scan('single_quote_data_value')
+            thisval = stripstring(single_quote_data_value)
+        return thisval
+
+    def sc_lines_of_text(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'sc_lines_of_text', [])
+        start_sc_line = self._scan('start_sc_line')
+        lines = StringIO();lines.write(start_sc_line)
+        while self._peek('end_sc_line', 'sc_line_of_text') == 'sc_line_of_text':
+            sc_line_of_text = self._scan('sc_line_of_text')
+            lines.write(sc_line_of_text)
+        if self._peek() not in ['end_sc_line', 'sc_line_of_text']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['sc_line_of_text', 'end_sc_line']))
+        end_sc_line = self._scan('end_sc_line')
+        lines.write(end_sc_line);return monitor('sc_line_of_text',lines.getvalue())
+
+    def bracket_expression(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'bracket_expression', [])
+        _token = self._peek('o_s_b', 'o_c_b')
+        if _token == 'o_s_b':
+            square_bracket_expr = self.square_bracket_expr(_context)
+            return square_bracket_expr
+        else: # == 'o_c_b'
+            curly_bracket_expr = self.curly_bracket_expr(_context)
+            return curly_bracket_expr
+
+    def top_loop(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'top_loop', [])
+        LBLOCK = self._scan('LBLOCK')
+        loopfield = self.loopfield(_context)
+        loopvalues = self.loopvalues(_context)
+        return loopfield,loopvalues
+
+    def loopfield(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'loopfield', [])
+        loop_seq=[]
+        while self._peek('data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') == 'data_name':
+            data_name = self._scan('data_name')
+            loop_seq.append(data_name)
+        if self._peek() not in ['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
+        return loop_seq
+
+    def loopvalues(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'loopvalues', [])
+        data_value = self.data_value(_context)
+        dataloop=[data_value]
+        while self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading') in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
+            data_value = self.data_value(_context)
+            dataloop.append(monitor('loopval',data_value))
+        if self._peek() not in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
+        return dataloop
+
+    def save_frame(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
+        save_heading = self._scan('save_heading')
+        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
+        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
+            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
+            if _token != 'save_heading':
+                dataseq = self.dataseq(savebc[savehead], _context)
+            else: # == 'save_heading'
+                save_frame = self.save_frame(prepared, _context)
+                savebc.merge_fast(save_frame,parent=stored_block)
+        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']))
+        save_end = self._scan('save_end')
+        return monitor('save_frame',savebc)
+
+    def save_frame(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
+        save_heading = self._scan('save_heading')
+        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
+        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
+            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
+            if _token != 'save_heading':
+                dataseq = self.dataseq(savebc[savehead], _context)
+            else: # == 'save_heading'
+                save_frame = self.save_frame(prepared, _context)
+                savebc.merge_fast(save_frame,parent=stored_block)
+        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']))
+        save_end = self._scan('save_end')
+        return monitor('save_frame',savebc)
+
+    def square_bracket_expr(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'square_bracket_expr', [])
+        o_s_b = self._scan('o_s_b')
+        this_list = []
+        while self._peek('c_s_b', 'data_value_1', '","', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') not in ['c_s_b', '","']:
+            data_value = self.data_value(_context)
+            this_list.append(data_value)
+            while self._peek('","', 'data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') == '","':
+                self._scan('","')
+                data_value = self.data_value(_context)
+                this_list.append(data_value)
+            if self._peek() not in ['","', 'data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
+                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['","', 'data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
+        if self._peek() not in ['c_s_b', 'data_value_1', '","', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', '","', 'o_s_b', 'o_c_b']))
+        c_s_b = self._scan('c_s_b')
+        return StarList(this_list)
+
+    def curly_bracket_expr(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'curly_bracket_expr', [])
+        o_c_b = self._scan('o_c_b')
+        table_as_list = []
+        while self._peek('c_c_b', 'triple_quote_data_value', 'single_quote_data_value', '","') in ['triple_quote_data_value', 'single_quote_data_value']:
+            delimited_data_value = self.delimited_data_value(_context)
+            table_as_list = [delimited_data_value]
+            self._scan('":"')
+            data_value = self.data_value(_context)
+            table_as_list.append(data_value)
+            while self._peek('","', 'triple_quote_data_value', 'single_quote_data_value', 'c_c_b') == '","':
+                self._scan('","')
+                delimited_data_value = self.delimited_data_value(_context)
+                table_as_list.append(delimited_data_value)
+                self._scan('":"')
+                data_value = self.data_value(_context)
+                table_as_list.append(data_value)
+            if self._peek() not in ['","', 'triple_quote_data_value', 'single_quote_data_value', 'c_c_b']:
+                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['","', 'triple_quote_data_value', 'single_quote_data_value', 'c_c_b']))
+        if self._peek() not in ['c_c_b', 'triple_quote_data_value', 'single_quote_data_value', '","']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['triple_quote_data_value', 'single_quote_data_value', 'c_c_b', '","']))
+        c_c_b = self._scan('c_c_b')
+        return StarDict(pairwise(table_as_list))
+
+
+def parse(rule, text):
+    P = StarParser(StarParserScanner(text))
+    return yappsrt.wrap_error_reporter(P, rule)
+
+# End -- grammar generated by Yapps
+
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/YappsStarParser_STAR2.py` & `pyemaps-1.0.9/CifFile/src/YappsStarParser_2_0.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,382 +1,369 @@
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-from .StarFile import StarBlock,StarFile,StarList,StarDict
-from io import StringIO
-# An alternative specification for the Cif Parser, based on Yapps2
-# by Amit Patel (http://theory.stanford.edu/~amitp/Yapps)
-#
-# helper code: we define our match tokens
-lastval = ''
-def monitor(location,value):
-    global lastval
-    #print 'At %s: %s' % (location,repr(value))
-    lastval = repr(value)
-    return value
-
-# Strip extras gets rid of leading and trailing whitespace, and
-# semicolons.
-def stripextras(value):
-     from .StarFile import remove_line_folding, remove_line_prefix
-     # we get rid of semicolons and leading/trailing terminators etc.
-     import re
-     jj = re.compile("[\n\r\f \t\v]*")
-     semis = re.compile("[\n\r\f \t\v]*[\n\r\f]\n*;")
-     cut = semis.match(value)
-     if cut:        #we have a semicolon-delimited string
-          nv = value[cut.end():len(value)-2]
-          try:
-             if nv[-1]=='\r': nv = nv[:-1]
-          except IndexError:    #empty data value
-             pass
-          # apply protocols
-          nv = remove_line_prefix(nv)
-          nv = remove_line_folding(nv)
-          return nv
-     else:
-          cut = jj.match(value)
-          if cut:
-               return stripstring(value[cut.end():])
-          return value
-
-# helper function to get rid of inverted commas etc.
-
-def stripstring(value):
-     if value:
-         if value[0]== '\'' and value[-1]=='\'':
-           return value[1:-1]
-         if value[0]=='"' and value[-1]=='"':
-           return value[1:-1]
-     return value
-
-# helper function to get rid of triple quotes
-def striptriple(value):
-    if value:
-        if value[:3] == '"""' and value[-3:] == '"""':
-            return value[3:-3]
-        if value[:3] == "'''" and value[-3:] == "'''":
-            return value[3:-3]
-    return value
-
-# helper function to populate a StarBlock given a list of names
-# and values .
-#
-# Note that there may be an empty list at the very end of our itemlists,
-# so we remove that if necessary.
-#
-
-def makeloop(target_block,loopdata):
-    loop_seq,itemlists = loopdata
-    if itemlists[-1] == []: itemlists.pop(-1)
-    # print('Making loop with %s' % repr(itemlists))
-    step_size = len(loop_seq)
-    for col_no in range(step_size):
-       target_block.AddItem(loop_seq[col_no], itemlists[col_no::step_size],precheck=True)
-    # now construct the loop
-    try:
-        target_block.CreateLoop(loop_seq)  #will raise ValueError on problem
-    except ValueError:
-        error_string =  'Incorrect number of loop values for loop containing %s' % repr(loop_seq)
-        print(error_string, file=sys.stderr)
-        raise ValueError(error_string)
-
-# return an object with the appropriate amount of nesting
-def make_empty(nestlevel):
-    gd = []
-    for i in range(1,nestlevel):
-        gd = [gd]
-    return gd
-
-# this function updates a dictionary first checking for name collisions,
-# which imply that the CIF is invalid.  We need case insensitivity for
-# names.
-
-# Unfortunately we cannot check loop item contents against non-loop contents
-# in a non-messy way during parsing, as we may not have easy access to previous
-# key value pairs in the context of our call (unlike our built-in access to all
-# previous loops).
-# For this reason, we don't waste time checking looped items against non-looped
-# names during parsing of a data block.  This would only match a subset of the
-# final items.   We do check against ordinary items, however.
-#
-# Note the following situations:
-# (1) new_dict is empty -> we have just added a loop; do no checking
-# (2) new_dict is not empty -> we have some new key-value pairs
-#
-def cif_update(old_dict,new_dict,loops):
-    old_keys = map(lambda a:a.lower(),old_dict.keys())
-    if new_dict != {}:    # otherwise we have a new loop
-        #print 'Comparing %s to %s' % (repr(old_keys),repr(new_dict.keys()))
-        for new_key in new_dict.keys():
-            if new_key.lower() in old_keys:
-                raise CifError("Duplicate dataname or blockname %s in input file" % new_key)
-            old_dict[new_key] = new_dict[new_key]
-#
-# this takes two lines, so we couldn't fit it into a one line execution statement...
-def order_update(order_array,new_name):
-    order_array.append(new_name)
-    return new_name
-
-# and finally...turn a sequence into a python dict (thanks to Stackoverflow)
-def pairwise(iterable):
-    try:
-        it = iter(iterable)
-        while 1:
-            yield next(it), next(it)
-    except StopIteration:
-        return
-
-# Begin -- grammar generated by Yapps
-import sys, re
-from . import yapps3_compiled_rt as yappsrt
-
-class StarParserScanner(yappsrt.Scanner):
-    def __init__(self, *args,**kwargs):
-        patterns = [
-         ('":"', ':'),
-         ('","', ','),
-         ('([ \t\n\r](?!;))|[ \t]', '([ \t\n\r](?!;))|[ \t]'),
-         ('(#.*[\n\r](?!;))|(#.*)', '(#.*[\n\r](?!;))|(#.*)'),
-         ('LBLOCK', '(L|l)(O|o)(O|o)(P|p)_'),
-         ('GLOBAL', '(G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_'),
-         ('STOP', '(S|s)(T|t)(O|o)(P|p)_'),
-         ('save_heading', u'(S|s)(A|a)(V|v)(E|e)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
-         ('save_end', '(S|s)(A|a)(V|v)(E|e)_'),
-         ('data_name', u'_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
-         ('data_heading', u'(D|d)(A|a)(T|t)(A|a)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
-         ('start_sc_line', '(\n|\r\n);([^\n\r])*(\r\n|\r|\n)+'),
-         ('sc_line_of_text', '[^;\r\n]([^\r\n])*(\r\n|\r|\n)+'),
-         ('end_sc_line', ';'),
-         ('c_c_b', '\\}'),
-         ('o_c_b', '\\{'),
-         ('c_s_b', '\\]'),
-         ('o_s_b', '\\['),
-         ('dat_val_internal_sq', '\\[([^\\s\\[\\]]*)\\]'),
-         ('triple_quote_data_value', '(?s)\'\'\'.*?\'\'\'|""".*?"""'),
-         ('single_quote_data_value', '\'([^\n\r\x0c\'])*\'+|"([^\n\r"])*"+'),
-         ('END', '$'),
-         ('data_value_1', '((?!(((S|s)(A|a)(V|v)(E|e)_[^\\s]*)|((G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_[^\\s]*)|((S|s)(T|t)(O|o)(P|p)_[^\\s]*)|((D|d)(A|a)(T|t)(A|a)_[^\\s]*)))[^\\s"#$\',_\\{\\}\\[\\]][^\\s,\\{\\}\\[\\]]*)'),
-        ]
-        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r](?!;))|[ \t]', '(#.*[\n\r](?!;))|(#.*)'],*args,**kwargs)
-
-class StarParser(yappsrt.Parser):
-    Context = yappsrt.Context
-    def input(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'input', [prepared])
-        _token = self._peek('END', 'data_heading')
-        if _token == 'data_heading':
-            dblock = self.dblock(prepared, _context)
-            allblocks = prepared; allblocks.merge_fast(dblock)
-            while self._peek('END', 'data_heading') == 'data_heading':
-                dblock = self.dblock(prepared, _context)
-                allblocks.merge_fast(dblock)
-            if self._peek() not in ['END', 'data_heading']:
-                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['END', 'data_heading']))
-            END = self._scan('END')
-        else: # == 'END'
-            END = self._scan('END')
-            allblocks = prepared
-        allblocks.unlock(); return allblocks
-
-    def dblock(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'dblock', [prepared])
-        data_heading = self._scan('data_heading')
-        heading = data_heading[5:];thisbc=StarFile(characterset='unicode',standard=prepared.standard);act_heading = thisbc.NewBlock(heading,prepared.blocktype(overwrite=False));stored_block = thisbc[act_heading]
-        while self._peek('save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
-            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
-            if _token != 'save_heading':
-                dataseq = self.dataseq(stored_block, _context)
-            else: # == 'save_heading'
-                save_frame = self.save_frame(prepared, _context)
-                thisbc.merge_fast(save_frame,parent=stored_block)
-        if self._peek() not in ['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']))
-        stored_block.setmaxnamelength(stored_block.maxnamelength);return (monitor('dblock',thisbc))
-
-    def dataseq(self, starblock, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'dataseq', [starblock])
-        data = self.data(starblock, _context)
-        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
-            data = self.data(starblock, _context)
-        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
-
-    def data(self, currentblock, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'data', [currentblock])
-        _token = self._peek('LBLOCK', 'data_name')
-        if _token == 'LBLOCK':
-            top_loop = self.top_loop(_context)
-            makeloop(currentblock,top_loop)
-        else: # == 'data_name'
-            datakvpair = self.datakvpair(_context)
-            currentblock.AddItem(datakvpair[0],datakvpair[1],precheck=False)
-
-    def datakvpair(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'datakvpair', [])
-        data_name = self._scan('data_name')
-        data_value = self.data_value(_context)
-        return [data_name,data_value]
-
-    def data_value(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'data_value', [])
-        _token = self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b')
-        if _token == 'data_value_1':
-            data_value_1 = self._scan('data_value_1')
-            thisval = data_value_1
-        elif _token not in ['start_sc_line', 'o_s_b', 'o_c_b']:
-            delimited_data_value = self.delimited_data_value(_context)
-            thisval = delimited_data_value
-        elif _token == 'start_sc_line':
-            sc_lines_of_text = self.sc_lines_of_text(_context)
-            thisval = stripextras(sc_lines_of_text)
-        else: # in ['o_s_b', 'o_c_b']
-            bracket_expression = self.bracket_expression(_context)
-            thisval = bracket_expression
-        return monitor('data_value',thisval)
-
-    def delimited_data_value(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'delimited_data_value', [])
-        _token = self._peek('triple_quote_data_value', 'single_quote_data_value')
-        if _token == 'triple_quote_data_value':
-            triple_quote_data_value = self._scan('triple_quote_data_value')
-            thisval = striptriple(triple_quote_data_value)
-        else: # == 'single_quote_data_value'
-            single_quote_data_value = self._scan('single_quote_data_value')
-            thisval = stripstring(single_quote_data_value)
-        return thisval
-
-    def sc_lines_of_text(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'sc_lines_of_text', [])
-        start_sc_line = self._scan('start_sc_line')
-        lines = StringIO();lines.write(start_sc_line)
-        while self._peek('end_sc_line', 'sc_line_of_text') == 'sc_line_of_text':
-            sc_line_of_text = self._scan('sc_line_of_text')
-            lines.write(sc_line_of_text)
-        if self._peek() not in ['end_sc_line', 'sc_line_of_text']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['sc_line_of_text', 'end_sc_line']))
-        end_sc_line = self._scan('end_sc_line')
-        lines.write(end_sc_line);return monitor('sc_line_of_text',lines.getvalue())
-
-    def bracket_expression(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'bracket_expression', [])
-        _token = self._peek('o_s_b', 'o_c_b')
-        if _token == 'o_s_b':
-            square_bracket_expr = self.square_bracket_expr(_context)
-            return square_bracket_expr
-        else: # == 'o_c_b'
-            curly_bracket_expr = self.curly_bracket_expr(_context)
-            return curly_bracket_expr
-
-    def top_loop(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'top_loop', [])
-        LBLOCK = self._scan('LBLOCK')
-        loopfield = self.loopfield(_context)
-        loopvalues = self.loopvalues(_context)
-        return loopfield,loopvalues
-
-    def loopfield(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'loopfield', [])
-        loop_seq=[]
-        while self._peek('data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') == 'data_name':
-            data_name = self._scan('data_name')
-            loop_seq.append(data_name)
-        if self._peek() not in ['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
-        return loop_seq
-
-    def loopvalues(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'loopvalues', [])
-        data_value = self.data_value(_context)
-        dataloop=[data_value]
-        while self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading') in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
-            data_value = self.data_value(_context)
-            dataloop.append(monitor('loopval',data_value))
-        if self._peek() not in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
-        return dataloop
-
-    def save_frame(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
-        save_heading = self._scan('save_heading')
-        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
-        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
-            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
-            if _token != 'save_heading':
-                dataseq = self.dataseq(savebc[savehead], _context)
-            else: # == 'save_heading'
-                save_frame = self.save_frame(prepared, _context)
-                savebc.merge_fast(save_frame,parent=stored_block)
-        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']))
-        save_end = self._scan('save_end')
-        return monitor('save_frame',savebc)
-
-    def save_frame(self, prepared, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
-        save_heading = self._scan('save_heading')
-        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
-        while self._peek('save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
-            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
-            if _token != 'save_heading':
-                dataseq = self.dataseq(savebc[savehead], _context)
-            else: # == 'save_heading'
-                save_frame = self.save_frame(prepared, _context)
-                savebc.merge_fast(save_frame,parent=stored_block)
-        if self._peek() not in ['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'save_heading', 'LBLOCK', 'data_name', 'END', 'data_heading']))
-        save_end = self._scan('save_end')
-        return monitor('save_frame',savebc)
-
-    def square_bracket_expr(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'square_bracket_expr', [])
-        o_s_b = self._scan('o_s_b')
-        this_list = []
-        while self._peek('c_s_b', 'data_value_1', '","', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') not in ['c_s_b', '","']:
-            data_value = self.data_value(_context)
-            this_list.append(data_value)
-            while self._peek('","', 'data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') == '","':
-                self._scan('","')
-                data_value = self.data_value(_context)
-                this_list.append(data_value)
-            if self._peek() not in ['","', 'data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
-                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['","', 'data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
-        if self._peek() not in ['c_s_b', 'data_value_1', '","', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', '","', 'o_s_b', 'o_c_b']))
-        c_s_b = self._scan('c_s_b')
-        return StarList(this_list)
-
-    def curly_bracket_expr(self, _parent=None):
-        _context = self.Context(_parent, self._scanner, self._pos, 'curly_bracket_expr', [])
-        o_c_b = self._scan('o_c_b')
-        table_as_list = []
-        while self._peek('c_c_b', 'triple_quote_data_value', 'single_quote_data_value', '","') in ['triple_quote_data_value', 'single_quote_data_value']:
-            delimited_data_value = self.delimited_data_value(_context)
-            table_as_list = [delimited_data_value]
-            self._scan('":"')
-            data_value = self.data_value(_context)
-            table_as_list.append(data_value)
-            while self._peek('","', 'triple_quote_data_value', 'single_quote_data_value', 'c_c_b') == '","':
-                self._scan('","')
-                delimited_data_value = self.delimited_data_value(_context)
-                table_as_list.append(delimited_data_value)
-                self._scan('":"')
-                data_value = self.data_value(_context)
-                table_as_list.append(data_value)
-            if self._peek() not in ['","', 'triple_quote_data_value', 'single_quote_data_value', 'c_c_b']:
-                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['","', 'triple_quote_data_value', 'single_quote_data_value', 'c_c_b']))
-        if self._peek() not in ['c_c_b', 'triple_quote_data_value', 'single_quote_data_value', '","']:
-            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['triple_quote_data_value', 'single_quote_data_value', 'c_c_b', '","']))
-        c_c_b = self._scan('c_c_b')
-        return StarDict(pairwise(table_as_list))
-
-
-def parse(rule, text):
-    P = StarParser(StarParserScanner(text))
-    return yappsrt.wrap_error_reporter(P, rule)
-
-# End -- grammar generated by Yapps
-
-
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+from .StarFile import StarBlock,StarFile,StarList,StarDict
+from io import StringIO
+# An alternative specification for the Cif Parser, based on Yapps2
+# by Amit Patel (http://theory.stanford.edu/~amitp/Yapps)
+#
+# helper code: we define our match tokens
+lastval = ''
+def monitor(location,value):
+    global lastval
+    #print 'At %s: %s' % (location,repr(value))
+    lastval = repr(value)
+    return value
+
+# Strip extras gets rid of leading and trailing whitespace, and
+# semicolons.
+def stripextras(value):
+     from .StarFile import remove_line_folding, remove_line_prefix
+     # we get rid of semicolons and leading/trailing terminators etc.
+     import re
+     jj = re.compile("[\n\r\f \t\v]*")
+     semis = re.compile("[\n\r\f \t\v]*[\n\r\f]\n*;")
+     cut = semis.match(value)
+     if cut:        #we have a semicolon-delimited string
+          nv = value[cut.end():len(value)-2]
+          try:
+             if nv[-1]=='\r': nv = nv[:-1]
+          except IndexError:    #empty data value
+             pass
+          # apply protocols
+          nv = remove_line_prefix(nv)
+          nv = remove_line_folding(nv)
+          return nv
+     else:
+          cut = jj.match(value)
+          if cut:
+               return stripstring(value[cut.end():])
+          return value
+
+# helper function to get rid of inverted commas etc.
+
+def stripstring(value):
+     if value:
+         if value[0]== '\'' and value[-1]=='\'':
+           return value[1:-1]
+         if value[0]=='"' and value[-1]=='"':
+           return value[1:-1]
+     return value
+
+# helper function to get rid of triple quotes
+def striptriple(value):
+    if value:
+        if value[:3] == '"""' and value[-3:] == '"""':
+            return value[3:-3]
+        if value[:3] == "'''" and value[-3:] == "'''":
+            return value[3:-3]
+    return value
+
+# helper function to populate a StarBlock given a list of names
+# and values .
+#
+# Note that there may be an empty list at the very end of our itemlists,
+# so we remove that if necessary.
+#
+
+def makeloop(target_block,loopdata):
+    loop_seq,itemlists = loopdata
+    if itemlists[-1] == []: itemlists.pop(-1)
+    # print('Making loop with %s' % repr(itemlists))
+    step_size = len(loop_seq)
+    for col_no in range(step_size):
+       target_block.AddItem(loop_seq[col_no], itemlists[col_no::step_size],precheck=True)
+    # now construct the loop
+    try:
+        target_block.CreateLoop(loop_seq)  #will raise ValueError on problem
+    except ValueError:
+        error_string =  'Incorrect number of loop values for loop containing %s' % repr(loop_seq)
+        print(error_string, file=sys.stderr)
+        raise ValueError(error_string)
+
+# return an object with the appropriate amount of nesting
+def make_empty(nestlevel):
+    gd = []
+    for i in range(1,nestlevel):
+        gd = [gd]
+    return gd
+
+# this function updates a dictionary first checking for name collisions,
+# which imply that the CIF is invalid.  We need case insensitivity for
+# names.
+
+# Unfortunately we cannot check loop item contents against non-loop contents
+# in a non-messy way during parsing, as we may not have easy access to previous
+# key value pairs in the context of our call (unlike our built-in access to all
+# previous loops).
+# For this reason, we don't waste time checking looped items against non-looped
+# names during parsing of a data block.  This would only match a subset of the
+# final items.   We do check against ordinary items, however.
+#
+# Note the following situations:
+# (1) new_dict is empty -> we have just added a loop; do no checking
+# (2) new_dict is not empty -> we have some new key-value pairs
+#
+def cif_update(old_dict,new_dict,loops):
+    old_keys = map(lambda a:a.lower(),old_dict.keys())
+    if new_dict != {}:    # otherwise we have a new loop
+        #print 'Comparing %s to %s' % (repr(old_keys),repr(new_dict.keys()))
+        for new_key in new_dict.keys():
+            if new_key.lower() in old_keys:
+                raise CifError("Duplicate dataname or blockname %s in input file" % new_key)
+            old_dict[new_key] = new_dict[new_key]
+#
+# this takes two lines, so we couldn't fit it into a one line execution statement...
+def order_update(order_array,new_name):
+    order_array.append(new_name)
+    return new_name
+
+# and finally...turn a sequence into a python dict (thanks to Stackoverflow)
+def pairwise(iterable):
+    try:
+        it = iter(iterable)
+        while 1:
+            yield next(it), next(it)
+    except StopIteration:
+        return
+
+# Begin -- grammar generated by Yapps
+import sys, re
+from . import yapps3_compiled_rt as yappsrt
+
+class StarParserScanner(yappsrt.Scanner):
+    def __init__(self, *args,**kwargs):
+        patterns = [
+         ('":"', ':'),
+         ('([ \t\n\r](?!;))|[ \t]', '([ \t\n\r](?!;))|[ \t]'),
+         ('(#.*[\n\r](?!;))|(#.*)', '(#.*[\n\r](?!;))|(#.*)'),
+         ('LBLOCK', '(L|l)(O|o)(O|o)(P|p)_'),
+         ('GLOBAL', '(G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_'),
+         ('STOP', '(S|s)(T|t)(O|o)(P|p)_'),
+         ('save_heading', u'(S|s)(A|a)(V|v)(E|e)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
+         ('save_end', '(S|s)(A|a)(V|v)(E|e)_'),
+         ('data_name', u'_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
+         ('data_heading', u'(D|d)(A|a)(T|t)(A|a)_[][!%&\\(\\)*+,./:<=>?@0-9A-Za-z\\\\^`{}\\|~"#$\';_\xa0-\ud7ff\ue000-\ufdcf\ufdf0-\ufffd\U00010000-\U0001fffd\U00020000-\U0002fffd\U00030000-\U0003fffd\U00040000-\U0004fffd\U00050000-\U0005fffd\U00060000-\U0006fffd\U00070000-\U0007fffd\U00080000-\U0008fffd\U00090000-\U0009fffd\U000a0000-\U000afffd\U000b0000-\U000bfffd\U000c0000-\U000cfffd\U000d0000-\U000dfffd\U000e0000-\U000efffd\U000f0000-\U000ffffd\U00100000-\U0010fffd-]+'),
+         ('start_sc_line', '(\n|\r\n);([^\n\r])*(\r\n|\r|\n)+'),
+         ('sc_line_of_text', '[^;\r\n]([^\r\n])*(\r\n|\r|\n)+'),
+         ('end_sc_line', ';'),
+         ('c_c_b', '\\}'),
+         ('o_c_b', '\\{'),
+         ('c_s_b', '\\]'),
+         ('o_s_b', '\\['),
+         ('dat_val_internal_sq', '\\[([^\\s\\[\\]]*)\\]'),
+         ('triple_quote_data_value', '(?s)\'\'\'.*?\'\'\'|""".*?"""'),
+         ('single_quote_data_value', '\'([^\n\r\x0c\'])*\'+|"([^\n\r"])*"+'),
+         ('data_value_1', '((?!(((S|s)(A|a)(V|v)(E|e)_[^\\s]*)|((G|g)(L|l)(O|o)(B|b)(A|a)(L|l)_[^\\s]*)|((S|s)(T|t)(O|o)(P|p)_[^\\s]*)|((D|d)(A|a)(T|t)(A|a)_[^\\s]*)))[^\\s"#$\'_\\{\\}\\[\\]][^\\s\\{\\}\\[\\]]*)'),
+         ('END', '$'),
+        ]
+        yappsrt.Scanner.__init__(self,patterns,['([ \t\n\r](?!;))|[ \t]', '(#.*[\n\r](?!;))|(#.*)'],*args,**kwargs)
+
+class StarParser(yappsrt.Parser):
+    Context = yappsrt.Context
+    def input(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'input', [prepared])
+        _token = self._peek('END', 'data_heading')
+        if _token == 'data_heading':
+            dblock = self.dblock(prepared, _context)
+            allblocks = prepared; allblocks.merge_fast(dblock)
+            while self._peek('END', 'data_heading') == 'data_heading':
+                dblock = self.dblock(prepared, _context)
+                allblocks.merge_fast(dblock)
+            if self._peek() not in ['END', 'data_heading']:
+                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['END', 'data_heading']))
+            END = self._scan('END')
+        else: # == 'END'
+            END = self._scan('END')
+            allblocks = prepared
+        allblocks.unlock(); return allblocks
+
+    def dblock(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'dblock', [prepared])
+        data_heading = self._scan('data_heading')
+        heading = data_heading[5:];thisbc=StarFile(characterset='unicode',standard=prepared.standard);act_heading = thisbc.NewBlock(heading,prepared.blocktype(overwrite=False));stored_block = thisbc[act_heading]
+        while self._peek('save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading') in ['save_heading', 'LBLOCK', 'data_name']:
+            _token = self._peek('save_heading', 'LBLOCK', 'data_name')
+            if _token != 'save_heading':
+                dataseq = self.dataseq(stored_block, _context)
+            else: # == 'save_heading'
+                save_frame = self.save_frame(prepared, _context)
+                thisbc.merge_fast(save_frame,parent=stored_block)
+        if self._peek() not in ['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_heading', 'save_end', 'LBLOCK', 'data_name', 'END', 'data_heading']))
+        stored_block.setmaxnamelength(stored_block.maxnamelength);return (monitor('dblock',thisbc))
+
+    def dataseq(self, starblock, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'dataseq', [starblock])
+        data = self.data(starblock, _context)
+        while self._peek('save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
+            data = self.data(starblock, _context)
+        if self._peek() not in ['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
+
+    def data(self, currentblock, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'data', [currentblock])
+        _token = self._peek('LBLOCK', 'data_name')
+        if _token == 'LBLOCK':
+            top_loop = self.top_loop(_context)
+            makeloop(currentblock,top_loop)
+        else: # == 'data_name'
+            datakvpair = self.datakvpair(_context)
+            currentblock.AddItem(datakvpair[0],datakvpair[1],precheck=False)
+
+    def datakvpair(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'datakvpair', [])
+        data_name = self._scan('data_name')
+        data_value = self.data_value(_context)
+        return [data_name,data_value]
+
+    def data_value(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'data_value', [])
+        _token = self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b')
+        if _token == 'data_value_1':
+            data_value_1 = self._scan('data_value_1')
+            thisval = data_value_1
+        elif _token not in ['start_sc_line', 'o_s_b', 'o_c_b']:
+            delimited_data_value = self.delimited_data_value(_context)
+            thisval = delimited_data_value
+        elif _token == 'start_sc_line':
+            sc_lines_of_text = self.sc_lines_of_text(_context)
+            thisval = stripextras(sc_lines_of_text)
+        else: # in ['o_s_b', 'o_c_b']
+            bracket_expression = self.bracket_expression(_context)
+            thisval = bracket_expression
+        return monitor('data_value',thisval)
+
+    def delimited_data_value(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'delimited_data_value', [])
+        _token = self._peek('triple_quote_data_value', 'single_quote_data_value')
+        if _token == 'triple_quote_data_value':
+            triple_quote_data_value = self._scan('triple_quote_data_value')
+            thisval = striptriple(triple_quote_data_value)
+        else: # == 'single_quote_data_value'
+            single_quote_data_value = self._scan('single_quote_data_value')
+            thisval = stripstring(single_quote_data_value)
+        return thisval
+
+    def sc_lines_of_text(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'sc_lines_of_text', [])
+        start_sc_line = self._scan('start_sc_line')
+        lines = StringIO();lines.write(start_sc_line)
+        while self._peek('end_sc_line', 'sc_line_of_text') == 'sc_line_of_text':
+            sc_line_of_text = self._scan('sc_line_of_text')
+            lines.write(sc_line_of_text)
+        if self._peek() not in ['end_sc_line', 'sc_line_of_text']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['sc_line_of_text', 'end_sc_line']))
+        end_sc_line = self._scan('end_sc_line')
+        lines.write(end_sc_line);return monitor('sc_line_of_text',lines.getvalue())
+
+    def bracket_expression(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'bracket_expression', [])
+        _token = self._peek('o_s_b', 'o_c_b')
+        if _token == 'o_s_b':
+            square_bracket_expr = self.square_bracket_expr(_context)
+            return square_bracket_expr
+        else: # == 'o_c_b'
+            curly_bracket_expr = self.curly_bracket_expr(_context)
+            return curly_bracket_expr
+
+    def top_loop(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'top_loop', [])
+        LBLOCK = self._scan('LBLOCK')
+        loopfield = self.loopfield(_context)
+        loopvalues = self.loopvalues(_context)
+        return loopfield,loopvalues
+
+    def loopfield(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'loopfield', [])
+        loop_seq=[]
+        while self._peek('data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') == 'data_name':
+            data_name = self._scan('data_name')
+            loop_seq.append(data_name)
+        if self._peek() not in ['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_name', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
+        return loop_seq
+
+    def loopvalues(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'loopvalues', [])
+        data_value = self.data_value(_context)
+        dataloop=[data_value]
+        while self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading') in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
+            data_value = self.data_value(_context)
+            dataloop.append(monitor('loopval',data_value))
+        if self._peek() not in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'LBLOCK', 'data_name', 'save_end', 'save_heading', 'END', 'data_heading']))
+        return dataloop
+
+    def save_frame(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
+        save_heading = self._scan('save_heading')
+        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
+        while self._peek('save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
+            dataseq = self.dataseq(savebc[savehead], _context)
+        if self._peek() not in ['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']))
+        save_end = self._scan('save_end')
+        return monitor('save_frame',savebc)
+
+    def save_frame(self, prepared, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'save_frame', [prepared])
+        save_heading = self._scan('save_heading')
+        savehead = save_heading[5:];savebc = StarFile();newname = savebc.NewBlock(savehead,prepared.blocktype(overwrite=False));stored_block = savebc[newname]
+        while self._peek('save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading') in ['LBLOCK', 'data_name']:
+            dataseq = self.dataseq(savebc[savehead], _context)
+        if self._peek() not in ['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['save_end', 'LBLOCK', 'data_name', 'save_heading', 'END', 'data_heading']))
+        save_end = self._scan('save_end')
+        return monitor('save_frame',savebc)
+
+    def square_bracket_expr(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'square_bracket_expr', [])
+        o_s_b = self._scan('o_s_b')
+        this_list = []
+        while self._peek('c_s_b', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b') != 'c_s_b':
+            data_value = self.data_value(_context)
+            this_list.append(data_value)
+            while self._peek('data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'c_s_b', 'o_s_b', 'o_c_b') != 'c_s_b':
+                data_value = self.data_value(_context)
+                this_list.append(data_value)
+            if self._peek() not in ['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'c_s_b', 'o_s_b', 'o_c_b']:
+                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b', 'c_s_b']))
+        if self._peek() not in ['c_s_b', 'data_value_1', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['data_value_1', 'c_s_b', 'triple_quote_data_value', 'single_quote_data_value', 'start_sc_line', 'o_s_b', 'o_c_b']))
+        c_s_b = self._scan('c_s_b')
+        return StarList(this_list)
+
+    def curly_bracket_expr(self, _parent=None):
+        _context = self.Context(_parent, self._scanner, self._pos, 'curly_bracket_expr', [])
+        o_c_b = self._scan('o_c_b')
+        table_as_list = []
+        while self._peek('c_c_b', 'triple_quote_data_value', 'single_quote_data_value') != 'c_c_b':
+            delimited_data_value = self.delimited_data_value(_context)
+            table_as_list = [delimited_data_value]
+            self._scan('":"')
+            data_value = self.data_value(_context)
+            table_as_list.append(data_value)
+            while self._peek('triple_quote_data_value', 'single_quote_data_value', 'c_c_b') != 'c_c_b':
+                delimited_data_value = self.delimited_data_value(_context)
+                table_as_list.append(delimited_data_value)
+                self._scan('":"')
+                data_value = self.data_value(_context)
+                table_as_list.append(data_value)
+            if self._peek() not in ['triple_quote_data_value', 'single_quote_data_value', 'c_c_b']:
+                raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['triple_quote_data_value', 'single_quote_data_value', 'c_c_b']))
+        if self._peek() not in ['c_c_b', 'triple_quote_data_value', 'single_quote_data_value']:
+            raise yappsrt.YappsSyntaxError(charpos=self._scanner.get_prev_char_pos(), context=_context, msg='Need one of ' + ', '.join(['triple_quote_data_value', 'single_quote_data_value', 'c_c_b']))
+        c_c_b = self._scan('c_c_b')
+        return StarDict(pairwise(table_as_list))
+
+
+def parse(rule, text):
+    P = StarParser(StarParserScanner(text))
+    return yappsrt.wrap_error_reporter(P, rule)
+
+# End -- grammar generated by Yapps
+
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/drel/drel_ast_yacc.py` & `pyemaps-1.0.9/CifFile/src/drel/drel_ast_yacc.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,582 +1,582 @@
-# A dREL grammar written for python-ply
-#
-# The output is an Abstract Syntax Tree that represents a
-# function fragment that needs to be wrapped with information
-# appropriate to the target language.
-
-# The grammar is based on the Python 2.7 grammar, in
-# consultation with Doug du Boulay's JsCifBrowser
-# grammar (also derived from a Python grammar).
-
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import absolute_import
-
-from .drel_lex import lexer,tokens
-import ply.yacc as yacc
-
-# Overall translation unit
-
-# Our input is a sequence of statements
-def p_input(p):
-    '''input : maybe_nline statement
-             | input statement '''
-    if p[1] is None:
-        p[0] = p[2]
-    else:
-         so_far = p[1][1]
-         new_statements = p[2][1]
-         p[0] = ["STATEMENTS",p[1][1] + p[2][1]]
-         #print('input now {!r}'.format(p[0]))
-
-# We distinguish between compound statements and
-# small statements. Small statements may be
-# chained together on a single line with semicolon
-# separators. Compound statements are not separated
-# in this way, and will always be terminated by
-# a newline.
-def p_statement(p):
-    '''statement : simple_stmt newlines
-                 | simple_stmt ";" newlines
-                 | compound_stmt '''
-    p[0] = p[1]
-
-# A simple statement is a sequence of small statements terminated by
-# a NEWLINE or EOF
-def p_simple_stmt(p):
-    ''' simple_stmt : small_stmt
-                    | simple_stmt ";" small_stmt '''
-    if len(p) == 2:
-        p[0] = ["STATEMENTS",[p[1]]]
-    else:
-        p[0] = ["STATEMENTS",p[1][1] + [p[3]]]
-
-# This production appears inside a set of braces. Any statement
-# will be automatically terminated by a newline so we do not
-# need to include that here
-def p_statements(p):
-    '''statements : statement
-                 | statements statement '''
-    if len(p) == 2: p[0] = p[1]
-    else: p[0] = ["STATEMENTS", p[1][1] + [p[2]]]
-
-def p_small_stmt(p):
-    '''small_stmt :   expr_stmt
-                    | print_stmt
-                    | break_stmt
-                    | next_stmt'''
-    p[0] = p[1]
-
-def p_break_stmt(p):
-    '''break_stmt : BREAK'''
-    p[0] = ["BREAK"]
-
-def p_next_stmt(p):
-    '''next_stmt : NEXT'''
-    p[0] = ["NEXT"]
-
-def p_print_stmt(p):
-    '''print_stmt : PRINT expression '''
-    p[0] = ['PRINT', p[2]]
-
-# Note here that a simple testlist_star_expr is useless as in our
-# side-effect-free world it will be evaluated and discarded. We
-# could just drop it right now but we let it go through to the
-# AST processor for language-dependent processing
-def p_expr_stmt(p):
-    ''' expr_stmt : testlist_star_expr
-                  | testlist_star_expr AUGOP testlist_star_expr
-                  | testlist_star_expr "=" testlist_star_expr
-                  | fancy_drel_assignment_stmt '''
-    if len(p) == 2 and p[1][0] != 'FANCY_ASSIGN':  # we have a list of expressions which we
-        p[0] = ["EXPRLIST",p[1]]
-    elif len(p) == 2 and p[1][0] == 'FANCY_ASSIGN':
-        p[0] = p[1]
-    else:
-        p[0] = ["ASSIGN",p[1],p[2],p[3]]
-
-def p_testlist_star_expr(p):  # list of expressions in fact
-    ''' testlist_star_expr : expression
-                           | testlist_star_expr "," maybe_nline expression '''
-    if len(p) == 2:
-       p[0] = [p[1]]
-    else:
-       p[0] = p[1] + [p[4]]
-
-# Simplified from the python 2.5 version due to apparent conflict with
-# the other type of IF expression...
-#
-def p_expression(p):
-    '''expression : or_test '''
-    p[0] = ["EXPR",p[1]]
-
-# This is too generous, as it allows a function call on the
-# LHS to be assigned to.  This will cause a syntax error on
-# execution.
-
-def p_or_test(p):
-    ''' or_test : and_test
-                 | or_test OR and_test
-                 | or_test BADOR and_test'''
-    if len(p) == 2: p[0] = p[1]
-    else: p[0] = ["MATHOP","or",p[1],p[3]]
-
-def p_and_test(p):
-    '''and_test : not_test
-                 | and_test AND not_test
-                 | and_test BADAND not_test'''
-    if len(p) == 2: p[0] = p[1]
-    else: p[0] = ["MATHOP","and", p[1],p[3]]
-
-def p_not_test(p):
-    '''not_test : comparison
-                 | NOT not_test'''
-    if len(p) == 2: p[0] = p[1]
-    else: p[0] = ["UNARY","not",p[2]]
-
-def p_comparison(p):
-    '''comparison : a_expr
-                   | a_expr comp_operator a_expr'''
-    if len(p) == 2: p[0] = p[1]
-    else:
-       p[0] = ["MATHOP",p[2],p[1],p[3]]
-
-def p_comp_operator(p):
-    '''comp_operator : restricted_comp_operator
-                     | IN
-                     | NOT IN '''
-    if len(p)==3:
-        p[0] = "not in"
-    else: p[0] = p[1]
-
-def p_restricted_comp_operator(p):   #for loop tests
-    '''restricted_comp_operator :  "<"
-                     | ">"
-                     | GTE
-                     | LTE
-                     | NEQ
-                     | ISEQUAL '''
-    p[0] = p[1]
-
-def p_a_expr(p):
-    '''a_expr : m_expr
-               | a_expr "+" m_expr
-               | a_expr "-" m_expr'''
-    if len(p) == 2:
-        p[0] = p[1]
-    else:
-        p[0] = ["MATHOP",p[2], p[1], p[3]]
-
-def p_m_expr(p):   #note bitwise and and or are pycifrw extensions
-    '''m_expr : u_expr
-               | m_expr "*" u_expr
-               | m_expr "/" u_expr
-               | m_expr "^" u_expr
-               | m_expr "&" u_expr
-               | m_expr "|" u_expr '''
-    if len(p) == 2:
-        p[0] = p[1]
-    else:
-        p[0] = ["MATHOP",p[2],p[1],p[3]]
-
-def p_u_expr(p):
-    '''u_expr : power
-               | "-" u_expr
-               | "+" u_expr'''
-    if len(p) == 2:
-        p[0] = p[1]
-    else:
-        p[0] = ["SIGN",p[1],p[2]]
-
-def p_power(p):
-    '''power : primary
-              | primary POWER u_expr'''
-    if len(p) == 2:
-        p[0] = p[1]
-    else:
-        p[0] = ["MATHOP","**",p[1] , p[3]]
-    # print('At power: p[0] is {!r}'.format(p[0]))
-
-def p_primary(p):
-    '''primary : atom
-                | attributeref
-                | subscription
-                | slicing
-                | call'''
-    # print 'Primary -> %s' % repr(p[1])
-    p[0] = p[1]
-
-def p_atom(p):
-    '''atom : ID
-             | item_tag
-             | literal
-             | enclosure'''
-    # print 'Atom -> %s' % repr(p[1])
-    p[0] = ["ATOM",p[1]]
-
-def p_item_tag(p):
-    '''item_tag : ITEM_TAG'''
-    p[0] = ["ITEM_TAG",p[1]]
-
-def p_literal(p):
-    '''literal : stringliteral
-                  | INTEGER
-                  | HEXINT
-                  | OCTINT
-                  | BININT
-                  | REAL
-                  | IMAGINARY'''
-    # print 'literal-> %s' % repr(p[1])
-    p[0] = ["LITERAL",p[1]]
-
-def p_stringliteral(p):
-    '''stringliteral : STRPREFIX SHORTSTRING
-                     | STRPREFIX LONGSTRING
-                     | SHORTSTRING
-                     | LONGSTRING'''
-    if len(p)==3: p[0] = p[1]+p[2]
-    else: p[0] = p[1]
-
-def p_enclosure(p):
-    '''enclosure : parenth_form
-                  | string_conversion
-                  | list_display
-                  | table_display '''
-    p[0]=p[1]
-
-def p_parenth_form(p):
-    '''parenth_form : OPEN_PAREN testlist_star_expr CLOSE_PAREN
-                     | OPEN_PAREN CLOSE_PAREN '''
-    if len(p) == 3: p[0] = ["GROUP"]
-    else:
-        p[0] = ["GROUP",p[2]]
-    # print('Parens: {!r}'.format(p[0]))
-
-def p_string_conversion(p):
-    '''string_conversion : "`" testlist_star_expr "`" '''
-    # WARNING: NOT IN PUBLISHED dREL papaer
-    p[0] = ["FUNC_CALL","str",p[2]]
-
-def p_list_display(p):
-    ''' list_display : "[" maybe_nline listmaker maybe_nline "]"
-                     | "[" maybe_nline "]" '''
-    if len(p) == 4: p[0] = ["LIST"]
-    else:
-        p[0] = ["LIST"] + p[3]
-
-
-# scrap the trailing comma
-def p_listmaker(p):
-    '''listmaker : expression listmaker2  '''
-    p[0] = [p[1]] + p[2]
-    # print('listmaker: {!r}'.format(p[0]))
-
-def p_listmaker2(p):
-    '''listmaker2 : "," maybe_nline expression
-                  | listmaker2 "," maybe_nline expression
-                  |             '''
-    if len(p) == 4:
-        p[0] = [p[3]]
-    elif len(p) < 2:
-        p[0] = []
-    else:
-        p[0] = p[1] + [p[4]]
-
-# define tables
-def p_table_display(p):
-    ''' table_display : "{" maybe_nline tablemaker maybe_nline "}"
-                      | "{" maybe_nline "}" '''
-    if len(p) == 4:
-        p[0] = ["TABLE"]
-    else:
-        p[0] = ["TABLE"] + p[3]
-
-def p_tablemaker(p):
-    '''tablemaker :  stringliteral ":" expression tablemaker2 '''
-    p[0] = [(p[1],p[3])] + p[4]
-
-def p_tablemaker2(p):
-    '''tablemaker2 : "," maybe_nline stringliteral ":" expression
-                   | tablemaker2 "," maybe_nline stringliteral ":" expression
-                   |  '''
-    if len(p) == 6:
-          p[0] = [(p[3],p[5])]
-    elif len(p) < 2:
-          p[0] = []
-    else:
-          p[0] = p[1] + [(p[4],p[6])]
-
-# Note that we need to catch tags of the form 't.12', which
-# our lexer will interpret as ID REAL.  We therefore also
-# accept t.12(3), which is not allowed, but we don't bother
-# trying to catch this error here.
-
-def p_attributeref(p):
-    '''attributeref : primary attribute_tag '''
-    p[0] = ["ATTRIBUTE",p[1],p[2]]
-
-def p_attribute_tag(p):
-    '''attribute_tag : "." ID
-                     | REAL '''
-    if len(p) == 3:
-        p[0] = p[2]
-    else:
-        p[0] = p[1][1:]
-
-def p_subscription(p):
-    '''subscription : primary "[" expression "]" '''
-    p[0] = ["SUBSCRIPTION",p[1],p[3]]
-
-def p_slicing(p):
-    '''slicing :  primary "[" proper_slice "]"
-               |  primary "[" slice_list "]" '''
-    p[0] = ["SLICE", p[1], p[3] ]
-
-def p_proper_slice(p):
-    '''proper_slice : short_slice
-                    | long_slice '''
-    p[0] = [p[1]]
-
-# Our AST slice convention is that, if anything is mentioned,
-# the first element is always
-# explicitly mentioned. A single element will be a starting
-# element. Two elements are start and finish. An empty list
-# is all elements. Three elements are start, finish, step.
-# We combine these into a list of slices.
-
-def p_short_slice(p):
-    '''short_slice : ":"
-                   | expression ":" expression
-                   | ":" expression
-                   | expression ":" '''
-    if len(p) == 2: p[0] = []
-    if len(p) == 4: p[0] = [p[1],p[3]]
-    if len(p) == 3 and p[1] == ":":
-        p[0] = [0,p[2]]
-    if len(p) == 3 and p[2] == ":":
-        p[0] = [p[1]]
-
-def p_long_slice(p):
-    '''long_slice : short_slice ":" expression '''
-    if len(p) == 4:
-        p[0] = p[1] + [p[3]]
-    else:
-        p[0] = p[1]
-
-def p_slice_list(p):
-    ''' slice_list : slice_item
-                   | slice_list "," slice_item '''
-    if len(p) == 2:
-        p[0] = [p[1]]
-    else:
-        p[0] = p[1] + [p[3]]
-
-def p_slice_item(p):
-    ''' slice_item : expression
-                   | proper_slice '''
-    p[0] = p[1]
-
-def p_call(p):
-    '''call : ID OPEN_PAREN CLOSE_PAREN
-            | ID OPEN_PAREN argument_list CLOSE_PAREN '''
-    if len(p) == 4:
-        p[0] = ["FUNC_CALL",p[1],[]]
-    else:
-        p[0] = ["FUNC_CALL",p[1],p[3]]
-    #print("Function call: {!r}".format(p[0]))
-
-# These are the arguments to a call, not a definition
-
-def p_argument_list(p):
-    '''argument_list : func_arg
-                     | argument_list "," func_arg '''
-    if len(p) == 2:
-        p[0] = [p[1]]
-    else:
-        p[0] = p[1] + [p[3]]
-
-def p_func_arg(p):
-    '''func_arg : expression '''
-    p[0] = p[1]
-
-def p_fancy_drel_assignment_stmt(p):
-    '''fancy_drel_assignment_stmt : ID OPEN_PAREN dotlist CLOSE_PAREN '''
-    p[0] = ["FANCY_ASSIGN",p[1],p[3]]
-#    print("Fancy assignment -> {!r}".format(p[0]))
-
-# Something made up specially for drel.  A newline is OK between assignments
-
-def p_dotlist(p):
-    '''dotlist : "." ID "=" expression
-               | dotlist "," "." ID "=" expression '''
-    if len(p) <= 5:   #first element of dotlist
-        p[0] = [[p[2],p[4]]]
-    else:              #append to previous elements
-         p[0] = p[1] + [[p[4],p[6]]]
-
-def p_exprlist(p):
-    ''' exprlist : a_expr
-                 | exprlist "," a_expr '''
-    if len(p) == 2:
-        p[0] = [p[1]]
-    else: p[0] = p[1] + [p[3]]
-
-# a (potentially enclosed) list of ids
-def p_id_list(p):
-    ''' id_list : ID
-                | id_list "," ID '''
-
-    if len(p) == 2:
-        p[0] = [p[1]]
-    else:
-        p[0] = p[1] + [p[3]]
-
-# now for the compound statements. We prepare them as a "STATEMENT"
-# list for smooth processing in the simple_stmt production
-
-def p_compound_stmt(p):
-    '''compound_stmt : if_stmt
-                     | if_else_stmt
-                     | for_stmt
-                     | do_stmt
-                     | loop_stmt
-                     | with_stmt
-                     | repeat_stmt
-                     | funcdef '''
-    p[0] = ["STATEMENTS",[p[1]]]
-    #print "Compound statement: \n" + p[0]
-
-# There must only be one else statement at the end of the else if statements,
-# so we show this by creating a separate production
-def p_if_else_stmt(p):
-    '''if_else_stmt : if_stmt ELSE suite'''
-    p[0] = p[1]
-    p[0].append(p[3])
-
-# The AST node is [IF_EXPR,cond, suite,[[elseif cond1,suite],[elseifcond2,suite]...]]
-def p_if_stmt(p):
-    '''if_stmt : IF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite
-               | if_stmt ELSEIF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite '''
-    if len(p) == 7:
-       p[0] = ["IF_EXPR"]
-       p[0].append(p[3])
-       p[0].append(p[6])
-       p[0].append([])
-    else:
-       p[0] = p[1]
-       p[0][3].append([p[4],p[7]])
-
-# Note the dREL divergence from Python here: we allow compound
-# statements to follow without a separate block (like C etc.)  Where
-# we have a single statement immediately following we have to make the
-# statement block.  A small_stmt will be a single production, so must
-# be put into a list in order to match the 'statements' structure
-# (i.e. 2nd element is a list of statements).  A compound_stmt is thus
-# forced to be also a non-listed object.
-
-def p_suite(p):
-    '''suite : statement
-               | "{" maybe_nline statements "}" maybe_nline '''
-    if len(p) == 2:
-        p[0] = p[1]
-    else:
-        p[0] = p[3]  #already have a statement block
-
-def p_for_stmt(p):
-    '''for_stmt : FOR id_list IN testlist_star_expr suite
-                | FOR "[" id_list "]" IN testlist_star_expr suite '''
-    if len(p)==6:
-        p[0] = ["FOR", p[2], p[4], p[5]]
-    else:
-        p[0] = ["FOR", p[3], p[6], p[7]]
-
-def p_loop_stmt(p):
-    '''loop_stmt : loop_head suite '''
-    p[0] = ["LOOP"] + p[1] + [p[2]]
-
-# We capture a list of all the actually present items in the current
-# datafile
-def p_loop_head(p):
-    '''loop_head : LOOP ID AS ID
-                 | LOOP ID AS ID ":" ID
-                 | LOOP ID AS ID ":" ID restricted_comp_operator ID '''
-
-    p[0] = [p[2],p[4]]
-    if len(p)>= 7:
-        p[0] = p[0] + [p[6]]
-    else: p[0] = p[0] + [""]
-    if len(p) >= 9:
-        p[0] = p[0] + [p[7],p[8]]
-    else: p[0] = p[0] + ["",""]
-
-def p_do_stmt(p):
-    '''do_stmt : do_stmt_head suite '''
-    p[0] = p[1] + [p[2]]
-
-# To translate the dREL do to a for statement, we need to make the
-# end of the range included in the range
-
-def p_do_stmt_head(p):
-    '''do_stmt_head : DO ID "=" expression "," expression
-                    | DO ID "=" expression "," expression "," expression'''
-
-    p[0] = ["DO",p[2],p[4],p[6]]
-    if len(p)==9:
-        p[0] = p[0] + [p[8]]
-    else:
-        p[0] = p[0] + [["EXPR",["LITERAL","1"]]]
-
-def p_repeat_stmt(p):
-    '''repeat_stmt : REPEAT suite'''
-    p[0] = ["REPEAT",p[2]]
-
-def p_with_stmt(p):
-    '''with_stmt : with_head maybe_nline suite'''
-    p[0] = p[1]+[p[3]]
-
-def p_with_head(p):
-    '''with_head : WITH ID AS ID'''
-    p[0] = ["WITH",p[2],p[4]]
-
-def p_funcdef(p):
-    ''' funcdef : FUNCTION ID OPEN_PAREN arglist CLOSE_PAREN suite '''
-    p[0] = ["FUNCTION",p[2],p[4],p[6]]
-
-def p_arglist(p):
-    ''' arglist : ID ":" list_display
-                | arglist "," ID ":" list_display '''
-    if len(p) == 4: p[0] = [(p[1],p[2])]
-    else: p[0] = p[1] + [(p[3],p[5])]
-
-# This production allows us to insert optional newlines
-
-def p_maybe_nline(p):
-    ''' maybe_nline : newlines
-                    | empty '''
-    pass
-
-# We need to allow multiple newlines here and not just in the lexer as
-# an intervening comment can cause multiple newline tokens to appear
-
-def p_newlines(p):
-    ''' newlines : NEWLINE
-                 | newlines NEWLINE '''
-    pass
-
-def p_empty(p):
-    ''' empty       : '''
-    pass
-
-def p_error(p):
-    try:
-        print('Syntax error at position %d, line %d token %s, value %s' % (p.lexpos,p.lineno,p.type,p.value))
-        print('Surrounding text: ' + p.lexer.lexdata[max(p.lexpos - 100,0): p.lexpos] + "*" + \
-           p.lexer.lexdata[p.lexpos:min(p.lexpos + 100,len(p.lexer.lexdata))])
-    except:
-        pass
-    parser.restart()
-    raise SyntaxError
-
-#lexer = drel_lex.lexer
-parser = yacc.yacc()
+# A dREL grammar written for python-ply
+#
+# The output is an Abstract Syntax Tree that represents a
+# function fragment that needs to be wrapped with information
+# appropriate to the target language.
+
+# The grammar is based on the Python 2.7 grammar, in
+# consultation with Doug du Boulay's JsCifBrowser
+# grammar (also derived from a Python grammar).
+
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import absolute_import
+
+from .drel_lex import lexer,tokens
+import ply.yacc as yacc
+
+# Overall translation unit
+
+# Our input is a sequence of statements
+def p_input(p):
+    '''input : maybe_nline statement
+             | input statement '''
+    if p[1] is None:
+        p[0] = p[2]
+    else:
+         so_far = p[1][1]
+         new_statements = p[2][1]
+         p[0] = ["STATEMENTS",p[1][1] + p[2][1]]
+         #print('input now {!r}'.format(p[0]))
+
+# We distinguish between compound statements and
+# small statements. Small statements may be
+# chained together on a single line with semicolon
+# separators. Compound statements are not separated
+# in this way, and will always be terminated by
+# a newline.
+def p_statement(p):
+    '''statement : simple_stmt newlines
+                 | simple_stmt ";" newlines
+                 | compound_stmt '''
+    p[0] = p[1]
+
+# A simple statement is a sequence of small statements terminated by
+# a NEWLINE or EOF
+def p_simple_stmt(p):
+    ''' simple_stmt : small_stmt
+                    | simple_stmt ";" small_stmt '''
+    if len(p) == 2:
+        p[0] = ["STATEMENTS",[p[1]]]
+    else:
+        p[0] = ["STATEMENTS",p[1][1] + [p[3]]]
+
+# This production appears inside a set of braces. Any statement
+# will be automatically terminated by a newline so we do not
+# need to include that here
+def p_statements(p):
+    '''statements : statement
+                 | statements statement '''
+    if len(p) == 2: p[0] = p[1]
+    else: p[0] = ["STATEMENTS", p[1][1] + [p[2]]]
+
+def p_small_stmt(p):
+    '''small_stmt :   expr_stmt
+                    | print_stmt
+                    | break_stmt
+                    | next_stmt'''
+    p[0] = p[1]
+
+def p_break_stmt(p):
+    '''break_stmt : BREAK'''
+    p[0] = ["BREAK"]
+
+def p_next_stmt(p):
+    '''next_stmt : NEXT'''
+    p[0] = ["NEXT"]
+
+def p_print_stmt(p):
+    '''print_stmt : PRINT expression '''
+    p[0] = ['PRINT', p[2]]
+
+# Note here that a simple testlist_star_expr is useless as in our
+# side-effect-free world it will be evaluated and discarded. We
+# could just drop it right now but we let it go through to the
+# AST processor for language-dependent processing
+def p_expr_stmt(p):
+    ''' expr_stmt : testlist_star_expr
+                  | testlist_star_expr AUGOP testlist_star_expr
+                  | testlist_star_expr "=" testlist_star_expr
+                  | fancy_drel_assignment_stmt '''
+    if len(p) == 2 and p[1][0] != 'FANCY_ASSIGN':  # we have a list of expressions which we
+        p[0] = ["EXPRLIST",p[1]]
+    elif len(p) == 2 and p[1][0] == 'FANCY_ASSIGN':
+        p[0] = p[1]
+    else:
+        p[0] = ["ASSIGN",p[1],p[2],p[3]]
+
+def p_testlist_star_expr(p):  # list of expressions in fact
+    ''' testlist_star_expr : expression
+                           | testlist_star_expr "," maybe_nline expression '''
+    if len(p) == 2:
+       p[0] = [p[1]]
+    else:
+       p[0] = p[1] + [p[4]]
+
+# Simplified from the python 2.5 version due to apparent conflict with
+# the other type of IF expression...
+#
+def p_expression(p):
+    '''expression : or_test '''
+    p[0] = ["EXPR",p[1]]
+
+# This is too generous, as it allows a function call on the
+# LHS to be assigned to.  This will cause a syntax error on
+# execution.
+
+def p_or_test(p):
+    ''' or_test : and_test
+                 | or_test OR and_test
+                 | or_test BADOR and_test'''
+    if len(p) == 2: p[0] = p[1]
+    else: p[0] = ["MATHOP","or",p[1],p[3]]
+
+def p_and_test(p):
+    '''and_test : not_test
+                 | and_test AND not_test
+                 | and_test BADAND not_test'''
+    if len(p) == 2: p[0] = p[1]
+    else: p[0] = ["MATHOP","and", p[1],p[3]]
+
+def p_not_test(p):
+    '''not_test : comparison
+                 | NOT not_test'''
+    if len(p) == 2: p[0] = p[1]
+    else: p[0] = ["UNARY","not",p[2]]
+
+def p_comparison(p):
+    '''comparison : a_expr
+                   | a_expr comp_operator a_expr'''
+    if len(p) == 2: p[0] = p[1]
+    else:
+       p[0] = ["MATHOP",p[2],p[1],p[3]]
+
+def p_comp_operator(p):
+    '''comp_operator : restricted_comp_operator
+                     | IN
+                     | NOT IN '''
+    if len(p)==3:
+        p[0] = "not in"
+    else: p[0] = p[1]
+
+def p_restricted_comp_operator(p):   #for loop tests
+    '''restricted_comp_operator :  "<"
+                     | ">"
+                     | GTE
+                     | LTE
+                     | NEQ
+                     | ISEQUAL '''
+    p[0] = p[1]
+
+def p_a_expr(p):
+    '''a_expr : m_expr
+               | a_expr "+" m_expr
+               | a_expr "-" m_expr'''
+    if len(p) == 2:
+        p[0] = p[1]
+    else:
+        p[0] = ["MATHOP",p[2], p[1], p[3]]
+
+def p_m_expr(p):   #note bitwise and and or are pycifrw extensions
+    '''m_expr : u_expr
+               | m_expr "*" u_expr
+               | m_expr "/" u_expr
+               | m_expr "^" u_expr
+               | m_expr "&" u_expr
+               | m_expr "|" u_expr '''
+    if len(p) == 2:
+        p[0] = p[1]
+    else:
+        p[0] = ["MATHOP",p[2],p[1],p[3]]
+
+def p_u_expr(p):
+    '''u_expr : power
+               | "-" u_expr
+               | "+" u_expr'''
+    if len(p) == 2:
+        p[0] = p[1]
+    else:
+        p[0] = ["SIGN",p[1],p[2]]
+
+def p_power(p):
+    '''power : primary
+              | primary POWER u_expr'''
+    if len(p) == 2:
+        p[0] = p[1]
+    else:
+        p[0] = ["MATHOP","**",p[1] , p[3]]
+    # print('At power: p[0] is {!r}'.format(p[0]))
+
+def p_primary(p):
+    '''primary : atom
+                | attributeref
+                | subscription
+                | slicing
+                | call'''
+    # print 'Primary -> %s' % repr(p[1])
+    p[0] = p[1]
+
+def p_atom(p):
+    '''atom : ID
+             | item_tag
+             | literal
+             | enclosure'''
+    # print 'Atom -> %s' % repr(p[1])
+    p[0] = ["ATOM",p[1]]
+
+def p_item_tag(p):
+    '''item_tag : ITEM_TAG'''
+    p[0] = ["ITEM_TAG",p[1]]
+
+def p_literal(p):
+    '''literal : stringliteral
+                  | INTEGER
+                  | HEXINT
+                  | OCTINT
+                  | BININT
+                  | REAL
+                  | IMAGINARY'''
+    # print 'literal-> %s' % repr(p[1])
+    p[0] = ["LITERAL",p[1]]
+
+def p_stringliteral(p):
+    '''stringliteral : STRPREFIX SHORTSTRING
+                     | STRPREFIX LONGSTRING
+                     | SHORTSTRING
+                     | LONGSTRING'''
+    if len(p)==3: p[0] = p[1]+p[2]
+    else: p[0] = p[1]
+
+def p_enclosure(p):
+    '''enclosure : parenth_form
+                  | string_conversion
+                  | list_display
+                  | table_display '''
+    p[0]=p[1]
+
+def p_parenth_form(p):
+    '''parenth_form : OPEN_PAREN testlist_star_expr CLOSE_PAREN
+                     | OPEN_PAREN CLOSE_PAREN '''
+    if len(p) == 3: p[0] = ["GROUP"]
+    else:
+        p[0] = ["GROUP",p[2]]
+    # print('Parens: {!r}'.format(p[0]))
+
+def p_string_conversion(p):
+    '''string_conversion : "`" testlist_star_expr "`" '''
+    # WARNING: NOT IN PUBLISHED dREL papaer
+    p[0] = ["FUNC_CALL","str",p[2]]
+
+def p_list_display(p):
+    ''' list_display : "[" maybe_nline listmaker maybe_nline "]"
+                     | "[" maybe_nline "]" '''
+    if len(p) == 4: p[0] = ["LIST"]
+    else:
+        p[0] = ["LIST"] + p[3]
+
+
+# scrap the trailing comma
+def p_listmaker(p):
+    '''listmaker : expression listmaker2  '''
+    p[0] = [p[1]] + p[2]
+    # print('listmaker: {!r}'.format(p[0]))
+
+def p_listmaker2(p):
+    '''listmaker2 : "," maybe_nline expression
+                  | listmaker2 "," maybe_nline expression
+                  |             '''
+    if len(p) == 4:
+        p[0] = [p[3]]
+    elif len(p) < 2:
+        p[0] = []
+    else:
+        p[0] = p[1] + [p[4]]
+
+# define tables
+def p_table_display(p):
+    ''' table_display : "{" maybe_nline tablemaker maybe_nline "}"
+                      | "{" maybe_nline "}" '''
+    if len(p) == 4:
+        p[0] = ["TABLE"]
+    else:
+        p[0] = ["TABLE"] + p[3]
+
+def p_tablemaker(p):
+    '''tablemaker :  stringliteral ":" expression tablemaker2 '''
+    p[0] = [(p[1],p[3])] + p[4]
+
+def p_tablemaker2(p):
+    '''tablemaker2 : "," maybe_nline stringliteral ":" expression
+                   | tablemaker2 "," maybe_nline stringliteral ":" expression
+                   |  '''
+    if len(p) == 6:
+          p[0] = [(p[3],p[5])]
+    elif len(p) < 2:
+          p[0] = []
+    else:
+          p[0] = p[1] + [(p[4],p[6])]
+
+# Note that we need to catch tags of the form 't.12', which
+# our lexer will interpret as ID REAL.  We therefore also
+# accept t.12(3), which is not allowed, but we don't bother
+# trying to catch this error here.
+
+def p_attributeref(p):
+    '''attributeref : primary attribute_tag '''
+    p[0] = ["ATTRIBUTE",p[1],p[2]]
+
+def p_attribute_tag(p):
+    '''attribute_tag : "." ID
+                     | REAL '''
+    if len(p) == 3:
+        p[0] = p[2]
+    else:
+        p[0] = p[1][1:]
+
+def p_subscription(p):
+    '''subscription : primary "[" expression "]" '''
+    p[0] = ["SUBSCRIPTION",p[1],p[3]]
+
+def p_slicing(p):
+    '''slicing :  primary "[" proper_slice "]"
+               |  primary "[" slice_list "]" '''
+    p[0] = ["SLICE", p[1], p[3] ]
+
+def p_proper_slice(p):
+    '''proper_slice : short_slice
+                    | long_slice '''
+    p[0] = [p[1]]
+
+# Our AST slice convention is that, if anything is mentioned,
+# the first element is always
+# explicitly mentioned. A single element will be a starting
+# element. Two elements are start and finish. An empty list
+# is all elements. Three elements are start, finish, step.
+# We combine these into a list of slices.
+
+def p_short_slice(p):
+    '''short_slice : ":"
+                   | expression ":" expression
+                   | ":" expression
+                   | expression ":" '''
+    if len(p) == 2: p[0] = []
+    if len(p) == 4: p[0] = [p[1],p[3]]
+    if len(p) == 3 and p[1] == ":":
+        p[0] = [0,p[2]]
+    if len(p) == 3 and p[2] == ":":
+        p[0] = [p[1]]
+
+def p_long_slice(p):
+    '''long_slice : short_slice ":" expression '''
+    if len(p) == 4:
+        p[0] = p[1] + [p[3]]
+    else:
+        p[0] = p[1]
+
+def p_slice_list(p):
+    ''' slice_list : slice_item
+                   | slice_list "," slice_item '''
+    if len(p) == 2:
+        p[0] = [p[1]]
+    else:
+        p[0] = p[1] + [p[3]]
+
+def p_slice_item(p):
+    ''' slice_item : expression
+                   | proper_slice '''
+    p[0] = p[1]
+
+def p_call(p):
+    '''call : ID OPEN_PAREN CLOSE_PAREN
+            | ID OPEN_PAREN argument_list CLOSE_PAREN '''
+    if len(p) == 4:
+        p[0] = ["FUNC_CALL",p[1],[]]
+    else:
+        p[0] = ["FUNC_CALL",p[1],p[3]]
+    #print("Function call: {!r}".format(p[0]))
+
+# These are the arguments to a call, not a definition
+
+def p_argument_list(p):
+    '''argument_list : func_arg
+                     | argument_list "," func_arg '''
+    if len(p) == 2:
+        p[0] = [p[1]]
+    else:
+        p[0] = p[1] + [p[3]]
+
+def p_func_arg(p):
+    '''func_arg : expression '''
+    p[0] = p[1]
+
+def p_fancy_drel_assignment_stmt(p):
+    '''fancy_drel_assignment_stmt : ID OPEN_PAREN dotlist CLOSE_PAREN '''
+    p[0] = ["FANCY_ASSIGN",p[1],p[3]]
+#    print("Fancy assignment -> {!r}".format(p[0]))
+
+# Something made up specially for drel.  A newline is OK between assignments
+
+def p_dotlist(p):
+    '''dotlist : "." ID "=" expression
+               | dotlist "," "." ID "=" expression '''
+    if len(p) <= 5:   #first element of dotlist
+        p[0] = [[p[2],p[4]]]
+    else:              #append to previous elements
+         p[0] = p[1] + [[p[4],p[6]]]
+
+def p_exprlist(p):
+    ''' exprlist : a_expr
+                 | exprlist "," a_expr '''
+    if len(p) == 2:
+        p[0] = [p[1]]
+    else: p[0] = p[1] + [p[3]]
+
+# a (potentially enclosed) list of ids
+def p_id_list(p):
+    ''' id_list : ID
+                | id_list "," ID '''
+
+    if len(p) == 2:
+        p[0] = [p[1]]
+    else:
+        p[0] = p[1] + [p[3]]
+
+# now for the compound statements. We prepare them as a "STATEMENT"
+# list for smooth processing in the simple_stmt production
+
+def p_compound_stmt(p):
+    '''compound_stmt : if_stmt
+                     | if_else_stmt
+                     | for_stmt
+                     | do_stmt
+                     | loop_stmt
+                     | with_stmt
+                     | repeat_stmt
+                     | funcdef '''
+    p[0] = ["STATEMENTS",[p[1]]]
+    #print "Compound statement: \n" + p[0]
+
+# There must only be one else statement at the end of the else if statements,
+# so we show this by creating a separate production
+def p_if_else_stmt(p):
+    '''if_else_stmt : if_stmt ELSE suite'''
+    p[0] = p[1]
+    p[0].append(p[3])
+
+# The AST node is [IF_EXPR,cond, suite,[[elseif cond1,suite],[elseifcond2,suite]...]]
+def p_if_stmt(p):
+    '''if_stmt : IF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite
+               | if_stmt ELSEIF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite '''
+    if len(p) == 7:
+       p[0] = ["IF_EXPR"]
+       p[0].append(p[3])
+       p[0].append(p[6])
+       p[0].append([])
+    else:
+       p[0] = p[1]
+       p[0][3].append([p[4],p[7]])
+
+# Note the dREL divergence from Python here: we allow compound
+# statements to follow without a separate block (like C etc.)  Where
+# we have a single statement immediately following we have to make the
+# statement block.  A small_stmt will be a single production, so must
+# be put into a list in order to match the 'statements' structure
+# (i.e. 2nd element is a list of statements).  A compound_stmt is thus
+# forced to be also a non-listed object.
+
+def p_suite(p):
+    '''suite : statement
+               | "{" maybe_nline statements "}" maybe_nline '''
+    if len(p) == 2:
+        p[0] = p[1]
+    else:
+        p[0] = p[3]  #already have a statement block
+
+def p_for_stmt(p):
+    '''for_stmt : FOR id_list IN testlist_star_expr suite
+                | FOR "[" id_list "]" IN testlist_star_expr suite '''
+    if len(p)==6:
+        p[0] = ["FOR", p[2], p[4], p[5]]
+    else:
+        p[0] = ["FOR", p[3], p[6], p[7]]
+
+def p_loop_stmt(p):
+    '''loop_stmt : loop_head suite '''
+    p[0] = ["LOOP"] + p[1] + [p[2]]
+
+# We capture a list of all the actually present items in the current
+# datafile
+def p_loop_head(p):
+    '''loop_head : LOOP ID AS ID
+                 | LOOP ID AS ID ":" ID
+                 | LOOP ID AS ID ":" ID restricted_comp_operator ID '''
+
+    p[0] = [p[2],p[4]]
+    if len(p)>= 7:
+        p[0] = p[0] + [p[6]]
+    else: p[0] = p[0] + [""]
+    if len(p) >= 9:
+        p[0] = p[0] + [p[7],p[8]]
+    else: p[0] = p[0] + ["",""]
+
+def p_do_stmt(p):
+    '''do_stmt : do_stmt_head suite '''
+    p[0] = p[1] + [p[2]]
+
+# To translate the dREL do to a for statement, we need to make the
+# end of the range included in the range
+
+def p_do_stmt_head(p):
+    '''do_stmt_head : DO ID "=" expression "," expression
+                    | DO ID "=" expression "," expression "," expression'''
+
+    p[0] = ["DO",p[2],p[4],p[6]]
+    if len(p)==9:
+        p[0] = p[0] + [p[8]]
+    else:
+        p[0] = p[0] + [["EXPR",["LITERAL","1"]]]
+
+def p_repeat_stmt(p):
+    '''repeat_stmt : REPEAT suite'''
+    p[0] = ["REPEAT",p[2]]
+
+def p_with_stmt(p):
+    '''with_stmt : with_head maybe_nline suite'''
+    p[0] = p[1]+[p[3]]
+
+def p_with_head(p):
+    '''with_head : WITH ID AS ID'''
+    p[0] = ["WITH",p[2],p[4]]
+
+def p_funcdef(p):
+    ''' funcdef : FUNCTION ID OPEN_PAREN arglist CLOSE_PAREN suite '''
+    p[0] = ["FUNCTION",p[2],p[4],p[6]]
+
+def p_arglist(p):
+    ''' arglist : ID ":" list_display
+                | arglist "," ID ":" list_display '''
+    if len(p) == 4: p[0] = [(p[1],p[2])]
+    else: p[0] = p[1] + [(p[3],p[5])]
+
+# This production allows us to insert optional newlines
+
+def p_maybe_nline(p):
+    ''' maybe_nline : newlines
+                    | empty '''
+    pass
+
+# We need to allow multiple newlines here and not just in the lexer as
+# an intervening comment can cause multiple newline tokens to appear
+
+def p_newlines(p):
+    ''' newlines : NEWLINE
+                 | newlines NEWLINE '''
+    pass
+
+def p_empty(p):
+    ''' empty       : '''
+    pass
+
+def p_error(p):
+    try:
+        print('Syntax error at position %d, line %d token %s, value %s' % (p.lexpos,p.lineno,p.type,p.value))
+        print('Surrounding text: ' + p.lexer.lexdata[max(p.lexpos - 100,0): p.lexpos] + "*" + \
+           p.lexer.lexdata[p.lexpos:min(p.lexpos + 100,len(p.lexer.lexdata))])
+    except:
+        pass
+    parser.restart()
+    raise SyntaxError
+
+#lexer = drel_lex.lexer
+parser = yacc.yacc()
```

### Comparing `pyemaps-1.0.8/CifFile/src/drel/drel_lex.py` & `pyemaps-1.0.9/CifFile/src/drel/drel_lex.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,228 +1,228 @@
-#Attempt to implement dREL using PLY (Python Lex Yacc)
-from __future__ import print_function
-import ply.lex as lex
-import re    #for multiline flag
-
-states = (
-    ('paren','inclusive'),
-    )
-
-tokens = (
-    'SHORTSTRING',
-    'LONGSTRING',
-    'INTEGER',
-    'BININT',
-    'HEXINT',
-    'OCTINT',
-    'REAL',
-    'POWER',
-    'ISEQUAL',
-    'NEQ',
-    'GTE',
-    'LTE',
-    'IMAGINARY',
-    'ID',            #variable name
-    'ITEM_TAG',      #cif item as variable
-    'COMMENT',
-    'STRPREFIX',
-    'ELLIPSIS',
-    'AND',
-    'BADAND',
-    'OR',
-    'BADOR',
-    'IN',
-    'NOT',
-    'DO',
-    'FOR',
-    'LOOP',
-    'REPEAT',
-    'AS',
-    'WITH',
-    'WHERE',
-    'ELSEIF',
-    'ELSE',
-    'BREAK',
-    'NEXT',
-    'IF',
-    'SWITCH',
-    'CASE',
-    'DEFAULT',
-    'AUGOP',
-    'PRINT',
-    'FUNCTION',
-    'NEWLINE',
-    'ESCAPE_NEWLINE',
-    'OPEN_PAREN',
-    'CLOSE_PAREN'
-     )
-
-literals = '+*-/;[],:^<>{}=.`&|'  #'&' and '|' are pycifrw extensions
-t_INITIAL_ignore = ' \t'
-t_paren_ignore = ' \t\n'
-
-def t_error(t):
-    print('Illegal character %s' % repr(t.value[0]))
-
-t_POWER = r'\*\*'
-t_ISEQUAL = r'=='
-t_NEQ = r'!='
-t_GTE = r'>='
-t_LTE = r'<='
-t_ELLIPSIS = r'\.\.\.'
-t_BADOR = r'\|\|'
-t_BADAND = r'&&'
-
-def t_AUGOP(t):
-    r'(\+\+=)|(\+=)|(-=)|(--=)|(\*=)|(/=)'
-    return t
-
-# We do not have this as a literal so that we can switch to ignoring newlines
-def t_INITIAL_OPEN_PAREN(t):
-    r'\('
-    t.lexer.paren_level = 1
-    t.lexer.begin('paren')
-    return t
-
-def t_paren_OPEN_PAREN(t):
-    r'\('
-    t.lexer.paren_level +=1
-    return t
-
-def t_paren_CLOSE_PAREN(t):
-    r'\)'
-    t.lexer.paren_level -=1
-    if t.lexer.paren_level == 0:
-        t.lexer.begin('INITIAL')
-    return t
-
-# Do the reals before the integers, otherwise the integer will
-# match the first part of the real
-#
-def t_IMAGINARY(t):
-    r'(((([0-9]+[.][0-9]*)|([.][0-9]+))([Ee][+-]?[0-9]+)?)|([0-9]+))[jJ]'
-    return t
-
-def t_REAL(t):
-    r'(([0-9]+[.][0-9]*)|([.][0-9]+))([Ee][+-]?[0-9]+)?'
-    try:
-        value = float(t.value)
-    except ValueError:
-        print('Error converting %s to real' % t.value)
-    return t
-
-# Do the binary,octal etc before decimal integer otherwise the 0 at
-# the front will match the decimal integer 0
-#
-def t_BININT(t):
-    r'0[bB][0-1]+'
-    try:
-        t.value = repr(int(t.value[2:],base=2))
-    except ValueError:
-        print('Unable to convert binary value %s' % t.value)
-    return t
-
-def t_OCTINT(t):
-    r'0[oO][0-7]+'
-    try:
-        t.value = repr(int(t.value[2:],base=8))
-    except ValueError:
-        print('Unable to convert octal value %s' % t.value)
-    return t
-
-def t_HEXINT(t):
-    r'0[xX][0-9a-fA-F]+'
-    try:
-        t.value = repr(int(t.value,base=16))
-    except ValueError:
-        print('Unable to convert hex value %s' % t.value)
-    return t
-
-def t_INTEGER(t):
-    r'[0-9]+'
-    try:
-        value = int(t.value)
-    except ValueError:
-        print('Incorrect integer value %s' % t.value)
-    return t
-
-def t_STRPREFIX(t):
-    r'r(?=["\'])|u(?=["\'])|R(?=["\'])|U(?=["\'])|ur(?=["\'])|UR(?=["\'])|Ur(?=["\'])|uR(?=["\'])'
-    return t
-
-# try longstring first as otherwise the '' will match a shortstring
-def t_LONGSTRING(t):
-    r"('''([^\\]|(\\.))*''')|(\"\"\"([^\\]|(\\.))*\"\"\")"
-    return t
-
-
-def t_SHORTSTRING(t):
-    r"('([^'\n]|(\\.))*')|(\"([^\"\n]|(\\.))*\")"
-    return t
-
-# special to avoid any ambiguity
-def t_ELSEIF(t):
-    r"(?i)ELSE\s+IF"
-    return t
-
-reserved = {
-    'and': 'AND',
-    'or': 'OR',
-    'in': 'IN',
-    'not': 'NOT',
-    'do': 'DO',
-    'Do': 'DO',
-    'for': 'FOR',
-    'For': 'FOR',
-    'loop': 'LOOP',
-    'Loop': 'LOOP',
-    'as': 'AS',
-    'with': 'WITH',
-    'With': 'WITH',
-    'where': 'WHERE',
-    'Where': 'WHERE',
-    'else': 'ELSE',
-    'Else': 'ELSE',
-    'Next': 'NEXT',
-    'next' : 'NEXT',
-    'break': 'BREAK',
-    'Break': 'BREAK',
-    'if': 'IF',
-    'If': 'IF',
-    'switch': 'SWITCH',
-    'case' : 'CASE',
-    'Function' : 'FUNCTION',
-    'function' : 'FUNCTION',
-    'Print' : 'PRINT',
-    'print' : 'PRINT',
-    'Repeat': 'REPEAT',
-    'repeat': 'REPEAT',
-    'default' : 'DEFAULT'
-    }
-
-def t_ID(t):
-    r'[a-zA-Z][a-zA-Z0-9_$]*'
-    t.type = reserved.get(t.value,'ID')
-    return t
-
-# Item tags can have underscores and digits inside, and must have
-# at least one underscore at the front
-def t_ITEM_TAG(t):
-    r'_[a-zA-Z_0-9]+'
-    return t
-
-def t_ESCAPE_NEWLINE(t):
-    r'\\\n'
-    t.lexer.lineno += 1
-
-def t_INITIAL_NEWLINE(t):
-    r'\n[\n \t]*'
-    t.lexer.lineno+=len(t.value)
-    return t
-
-def t_COMMENT(t):
-    r'\#.*'
-    pass
-
-lexer = lex.lex(reflags=re.MULTILINE)
-if __name__ == "__main__":
-    lex.runmain(lexer)
+#Attempt to implement dREL using PLY (Python Lex Yacc)
+from __future__ import print_function
+import ply.lex as lex
+import re    #for multiline flag
+
+states = (
+    ('paren','inclusive'),
+    )
+
+tokens = (
+    'SHORTSTRING',
+    'LONGSTRING',
+    'INTEGER',
+    'BININT',
+    'HEXINT',
+    'OCTINT',
+    'REAL',
+    'POWER',
+    'ISEQUAL',
+    'NEQ',
+    'GTE',
+    'LTE',
+    'IMAGINARY',
+    'ID',            #variable name
+    'ITEM_TAG',      #cif item as variable
+    'COMMENT',
+    'STRPREFIX',
+    'ELLIPSIS',
+    'AND',
+    'BADAND',
+    'OR',
+    'BADOR',
+    'IN',
+    'NOT',
+    'DO',
+    'FOR',
+    'LOOP',
+    'REPEAT',
+    'AS',
+    'WITH',
+    'WHERE',
+    'ELSEIF',
+    'ELSE',
+    'BREAK',
+    'NEXT',
+    'IF',
+    'SWITCH',
+    'CASE',
+    'DEFAULT',
+    'AUGOP',
+    'PRINT',
+    'FUNCTION',
+    'NEWLINE',
+    'ESCAPE_NEWLINE',
+    'OPEN_PAREN',
+    'CLOSE_PAREN'
+     )
+
+literals = '+*-/;[],:^<>{}=.`&|'  #'&' and '|' are pycifrw extensions
+t_INITIAL_ignore = ' \t'
+t_paren_ignore = ' \t\n'
+
+def t_error(t):
+    print('Illegal character %s' % repr(t.value[0]))
+
+t_POWER = r'\*\*'
+t_ISEQUAL = r'=='
+t_NEQ = r'!='
+t_GTE = r'>='
+t_LTE = r'<='
+t_ELLIPSIS = r'\.\.\.'
+t_BADOR = r'\|\|'
+t_BADAND = r'&&'
+
+def t_AUGOP(t):
+    r'(\+\+=)|(\+=)|(-=)|(--=)|(\*=)|(/=)'
+    return t
+
+# We do not have this as a literal so that we can switch to ignoring newlines
+def t_INITIAL_OPEN_PAREN(t):
+    r'\('
+    t.lexer.paren_level = 1
+    t.lexer.begin('paren')
+    return t
+
+def t_paren_OPEN_PAREN(t):
+    r'\('
+    t.lexer.paren_level +=1
+    return t
+
+def t_paren_CLOSE_PAREN(t):
+    r'\)'
+    t.lexer.paren_level -=1
+    if t.lexer.paren_level == 0:
+        t.lexer.begin('INITIAL')
+    return t
+
+# Do the reals before the integers, otherwise the integer will
+# match the first part of the real
+#
+def t_IMAGINARY(t):
+    r'(((([0-9]+[.][0-9]*)|([.][0-9]+))([Ee][+-]?[0-9]+)?)|([0-9]+))[jJ]'
+    return t
+
+def t_REAL(t):
+    r'(([0-9]+[.][0-9]*)|([.][0-9]+))([Ee][+-]?[0-9]+)?'
+    try:
+        value = float(t.value)
+    except ValueError:
+        print('Error converting %s to real' % t.value)
+    return t
+
+# Do the binary,octal etc before decimal integer otherwise the 0 at
+# the front will match the decimal integer 0
+#
+def t_BININT(t):
+    r'0[bB][0-1]+'
+    try:
+        t.value = repr(int(t.value[2:],base=2))
+    except ValueError:
+        print('Unable to convert binary value %s' % t.value)
+    return t
+
+def t_OCTINT(t):
+    r'0[oO][0-7]+'
+    try:
+        t.value = repr(int(t.value[2:],base=8))
+    except ValueError:
+        print('Unable to convert octal value %s' % t.value)
+    return t
+
+def t_HEXINT(t):
+    r'0[xX][0-9a-fA-F]+'
+    try:
+        t.value = repr(int(t.value,base=16))
+    except ValueError:
+        print('Unable to convert hex value %s' % t.value)
+    return t
+
+def t_INTEGER(t):
+    r'[0-9]+'
+    try:
+        value = int(t.value)
+    except ValueError:
+        print('Incorrect integer value %s' % t.value)
+    return t
+
+def t_STRPREFIX(t):
+    r'r(?=["\'])|u(?=["\'])|R(?=["\'])|U(?=["\'])|ur(?=["\'])|UR(?=["\'])|Ur(?=["\'])|uR(?=["\'])'
+    return t
+
+# try longstring first as otherwise the '' will match a shortstring
+def t_LONGSTRING(t):
+    r"('''([^\\]|(\\.))*''')|(\"\"\"([^\\]|(\\.))*\"\"\")"
+    return t
+
+
+def t_SHORTSTRING(t):
+    r"('([^'\n]|(\\.))*')|(\"([^\"\n]|(\\.))*\")"
+    return t
+
+# special to avoid any ambiguity
+def t_ELSEIF(t):
+    r"(?i)ELSE\s+IF"
+    return t
+
+reserved = {
+    'and': 'AND',
+    'or': 'OR',
+    'in': 'IN',
+    'not': 'NOT',
+    'do': 'DO',
+    'Do': 'DO',
+    'for': 'FOR',
+    'For': 'FOR',
+    'loop': 'LOOP',
+    'Loop': 'LOOP',
+    'as': 'AS',
+    'with': 'WITH',
+    'With': 'WITH',
+    'where': 'WHERE',
+    'Where': 'WHERE',
+    'else': 'ELSE',
+    'Else': 'ELSE',
+    'Next': 'NEXT',
+    'next' : 'NEXT',
+    'break': 'BREAK',
+    'Break': 'BREAK',
+    'if': 'IF',
+    'If': 'IF',
+    'switch': 'SWITCH',
+    'case' : 'CASE',
+    'Function' : 'FUNCTION',
+    'function' : 'FUNCTION',
+    'Print' : 'PRINT',
+    'print' : 'PRINT',
+    'Repeat': 'REPEAT',
+    'repeat': 'REPEAT',
+    'default' : 'DEFAULT'
+    }
+
+def t_ID(t):
+    r'[a-zA-Z][a-zA-Z0-9_$]*'
+    t.type = reserved.get(t.value,'ID')
+    return t
+
+# Item tags can have underscores and digits inside, and must have
+# at least one underscore at the front
+def t_ITEM_TAG(t):
+    r'_[a-zA-Z_0-9]+'
+    return t
+
+def t_ESCAPE_NEWLINE(t):
+    r'\\\n'
+    t.lexer.lineno += 1
+
+def t_INITIAL_NEWLINE(t):
+    r'\n[\n \t]*'
+    t.lexer.lineno+=len(t.value)
+    return t
+
+def t_COMMENT(t):
+    r'\#.*'
+    pass
+
+lexer = lex.lex(reflags=re.MULTILINE)
+if __name__ == "__main__":
+    lex.runmain(lexer)
```

### Comparing `pyemaps-1.0.8/CifFile/src/drel/drel_runtime.py` & `pyemaps-1.0.9/CifFile/src/drel/drel_runtime.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,126 +1,126 @@
-import numpy
-from numpy.linalg import eig
-
-# Python3 compatibility
-if isinstance(u"abc",str):   #Python 3
-    unicode = str
-
-def aug_append(current,extra):
-    """Add the contents of extra to current"""
-    have_list = isinstance(current,list)
-    if have_list:
-        if not isinstance(extra, list):
-            #append a single element
-            return current + [extra]
-        else:
-            newlist = current[:]
-            newlist.append(extra)
-            return newlist
-    elif isinstance(current,numpy.ndarray):
-        if current.ndim == extra.ndim + 1:
-            extra = numpy.expand_dims(extra,axis=0)
-        elif current.ndim == extra.ndim:
-            extra = numpy.expand_dims(extra,axis=0)
-            current = numpy.expand_dims(current,axis=0)
-        else:
-            raise ValueError('Arrays have mismatching sizes for concatenating: %d and %d' % (current.ndim,extra.ndim))
-        return numpy.concatenate((current,extra))
-    raise ValueError("Cannot append %s to %s" % (repr(extra),repr(current)))
-
-def aug_add(current,extra):
-    """Sum the contents of extra to current"""
-    have_list = isinstance(current,list)
-    if have_list:
-        if isinstance(extra, (float,int)):
-           # requires numpy
-           return numpy.array(current) + extra
-        elif isinstance(extra, list):
-           return numpy.array(current) + numpy.array(extra)
-    else:
-        return current + extra
-
-def aug_sub(current,extra):
-   have_list = isinstance(current,(list,numpy.ndarray))
-   if have_list:
-        if isinstance(extra, (float,int)):
-           # requires numpy
-           return numpy.array(current) - extra
-        elif isinstance(extra, (list,numpy.ndarray)):
-           return numpy.array(current) - numpy.array(extra)
-   else:
-        return current - extra
-
-def aug_remove(current,extra):
-    """Remove extra from current. Not in formal
-       specifications. Allowed to fail silently."""
-    have_list = isinstance(current,list)
-    if have_list:
-        if extra in current:
-            # not efficient as we modify in place here
-            current.remove(extra)
-            return current
-        else:
-            print('Removal Warning: %s not in %s' % (repr(extra),repr(current)))
-            return current
-    else:
-        raise ValueError("Cannot remove %s from %s" % (repr(extra),repr(current)))
-
-def drel_dot(first_arg,second_arg):
-    """Perform a multiplication on two unknown types"""
-    print("Multiply %s and %s" % (repr(first_arg),repr(second_arg)))
-    def make_numpy(input_arg):
-        if hasattr(input_arg,'__iter__'):
-            try:
-                return numpy.matrix(input_arg),True
-            except ValueError:
-                raise ValueError('Attempt to multiply non-matrix object %s' % (repr(input_arg)))
-        return input_arg,False
-    fa,first_matrix = make_numpy(first_arg)
-    sa,second_matrix = make_numpy(second_arg)
-    if first_matrix and second_matrix:  #mult of 2 non-scalars
-        if sa.shape[0] == 1:  #is a row vector
-           as_column = sa.T
-           result = (fa * as_column).T
-        else:
-           result = fa * sa
-       # detect scalars
-        if result.size == 1:
-            return result.item(0)
-       # remove extra dimension
-        elif result.ndim == 2 and 1 in result.shape:  #vector
-            return numpy.array(result).squeeze()
-        else:
-            return result
-    return fa * sa
-
-def drel_add(first_arg,second_arg):
-    """Separate string addition from the rest"""
-    if isinstance(first_arg,(unicode,str)) and isinstance(second_arg,(unicode,str)):
-        return first_arg+second_arg
-    else:
-        result = numpy.add(first_arg,second_arg)
-        return result
-
-
-def drel_eigen(in_matrix):
-    """Return 3 lists of form [a,v1,v2,v3], corresponding to the 3 eigenvalues 
-       and eigenvector components of a 3x3 matrix"""
-    vals,vects = eig(in_matrix)
-    move = list(numpy.argsort(vals))
-    move.reverse()
-    vals = vals[move]
-    vects = vects[move]
-    vects = list([[a]+list(numpy.asarray(v).ravel()) for a,v in zip(vals,vects)]) #Eigen returns 4-list
-    return vects
-
-def drel_int(in_val):
-    """Return in_val as an integer"""
-    try:
-        return in_val.astype('int')
-    except:
-        return int(in_val)
-
-def drel_strip(in_list,element):
-    """Return the nth element from the list"""
-    return [a[element] for a in in_list]
-
+import numpy
+from numpy.linalg import eig
+
+# Python3 compatibility
+if isinstance(u"abc",str):   #Python 3
+    unicode = str
+
+def aug_append(current,extra):
+    """Add the contents of extra to current"""
+    have_list = isinstance(current,list)
+    if have_list:
+        if not isinstance(extra, list):
+            #append a single element
+            return current + [extra]
+        else:
+            newlist = current[:]
+            newlist.append(extra)
+            return newlist
+    elif isinstance(current,numpy.ndarray):
+        if current.ndim == extra.ndim + 1:
+            extra = numpy.expand_dims(extra,axis=0)
+        elif current.ndim == extra.ndim:
+            extra = numpy.expand_dims(extra,axis=0)
+            current = numpy.expand_dims(current,axis=0)
+        else:
+            raise ValueError('Arrays have mismatching sizes for concatenating: %d and %d' % (current.ndim,extra.ndim))
+        return numpy.concatenate((current,extra))
+    raise ValueError("Cannot append %s to %s" % (repr(extra),repr(current)))
+
+def aug_add(current,extra):
+    """Sum the contents of extra to current"""
+    have_list = isinstance(current,list)
+    if have_list:
+        if isinstance(extra, (float,int)):
+           # requires numpy
+           return numpy.array(current) + extra
+        elif isinstance(extra, list):
+           return numpy.array(current) + numpy.array(extra)
+    else:
+        return current + extra
+
+def aug_sub(current,extra):
+   have_list = isinstance(current,(list,numpy.ndarray))
+   if have_list:
+        if isinstance(extra, (float,int)):
+           # requires numpy
+           return numpy.array(current) - extra
+        elif isinstance(extra, (list,numpy.ndarray)):
+           return numpy.array(current) - numpy.array(extra)
+   else:
+        return current - extra
+
+def aug_remove(current,extra):
+    """Remove extra from current. Not in formal
+       specifications. Allowed to fail silently."""
+    have_list = isinstance(current,list)
+    if have_list:
+        if extra in current:
+            # not efficient as we modify in place here
+            current.remove(extra)
+            return current
+        else:
+            print('Removal Warning: %s not in %s' % (repr(extra),repr(current)))
+            return current
+    else:
+        raise ValueError("Cannot remove %s from %s" % (repr(extra),repr(current)))
+
+def drel_dot(first_arg,second_arg):
+    """Perform a multiplication on two unknown types"""
+    print("Multiply %s and %s" % (repr(first_arg),repr(second_arg)))
+    def make_numpy(input_arg):
+        if hasattr(input_arg,'__iter__'):
+            try:
+                return numpy.matrix(input_arg),True
+            except ValueError:
+                raise ValueError('Attempt to multiply non-matrix object %s' % (repr(input_arg)))
+        return input_arg,False
+    fa,first_matrix = make_numpy(first_arg)
+    sa,second_matrix = make_numpy(second_arg)
+    if first_matrix and second_matrix:  #mult of 2 non-scalars
+        if sa.shape[0] == 1:  #is a row vector
+           as_column = sa.T
+           result = (fa * as_column).T
+        else:
+           result = fa * sa
+       # detect scalars
+        if result.size == 1:
+            return result.item(0)
+       # remove extra dimension
+        elif result.ndim == 2 and 1 in result.shape:  #vector
+            return numpy.array(result).squeeze()
+        else:
+            return result
+    return fa * sa
+
+def drel_add(first_arg,second_arg):
+    """Separate string addition from the rest"""
+    if isinstance(first_arg,(unicode,str)) and isinstance(second_arg,(unicode,str)):
+        return first_arg+second_arg
+    else:
+        result = numpy.add(first_arg,second_arg)
+        return result
+
+
+def drel_eigen(in_matrix):
+    """Return 3 lists of form [a,v1,v2,v3], corresponding to the 3 eigenvalues 
+       and eigenvector components of a 3x3 matrix"""
+    vals,vects = eig(in_matrix)
+    move = list(numpy.argsort(vals))
+    move.reverse()
+    vals = vals[move]
+    vects = vects[move]
+    vects = list([[a]+list(numpy.asarray(v).ravel()) for a,v in zip(vals,vects)]) #Eigen returns 4-list
+    return vects
+
+def drel_int(in_val):
+    """Return in_val as an integer"""
+    try:
+        return in_val.astype('int')
+    except:
+        return int(in_val)
+
+def drel_strip(in_list,element):
+    """Return the nth element from the list"""
+    return [a[element] for a in in_list]
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/drel/parsetab.py` & `pyemaps-1.0.9/CifFile/src/drel/parsetab.py`

 * *Ordering differences only*

 * *Files 2% similar despite different names*

```diff
@@ -1,185 +1,185 @@
-
-# parsetab.py
-# This file is automatically generated. Do not edit.
-_tabversion = '3.2'
-
-_lr_method = 'LALR'
-
-_lr_signature = '\xcc\x83\xf4<b8\x10\xb6\xfb\xc5z\x19\xd2\x9e\xc0\xa0'
-    
-_lr_action_items = {'REAL':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,48,48,-153,-152,-61,48,-76,-56,-156,48,-127,-75,-58,-126,48,-124,-78,-23,-129,-65,48,-63,48,-125,-74,-68,-66,-5,48,-50,-32,-79,-156,-30,48,-21,-70,-46,117,-69,-62,48,-59,-1,-77,-55,-131,-67,-27,48,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,48,-139,48,-3,-60,48,48,48,-52,-146,-42,-40,48,48,-39,48,-34,-35,-41,-37,-38,48,-31,-97,-95,48,48,-81,-72,-73,-51,48,48,48,48,48,48,48,48,-156,48,48,-147,-4,48,-82,-132,48,-26,-25,48,-33,-44,-45,-36,-84,-90,-54,-96,48,-80,48,-28,-29,-47,-48,-49,-112,48,-65,48,-8,-148,-140,48,-156,48,48,-100,48,-99,-98,48,48,-113,-156,-22,-9,-156,-156,-137,48,48,-83,-156,48,-89,48,48,48,-136,48,-141,48,-149,48,-144,-133,-134,-138,48,48,-142,-145,48,48,]),'DO':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,64,64,-153,-152,-61,64,-76,-56,-156,64,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,64,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,64,-139,-3,-60,64,-52,-146,-31,-97,-95,-81,-72,-73,-51,64,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,64,-8,-148,-140,64,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,64,-83,-89,64,-136,64,-141,64,-149,-144,-133,-134,-138,-142,-145,]),'*':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,130,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,130,130,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'PRINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,29,29,-153,-152,-61,29,-76,-56,-156,29,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,29,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,29,-139,29,-3,-60,29,-52,-146,-31,-97,-95,-81,-72,-73,-51,29,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,29,-8,-148,-140,29,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,29,-83,-89,29,-136,29,-141,29,-149,-144,-133,-134,-138,-142,-145,]),'^':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,132,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,132,132,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'AUGOP':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,220,230,234,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,137,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-22,-83,-89,]),';':([6,7,10,11,12,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,88,95,99,115,117,118,122,124,125,127,142,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,187,189,190,207,210,211,215,218,220,230,234,],[-6,-61,-15,-76,-56,86,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,-7,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-100,-99,-98,-117,-113,-22,-83,-89,]),'BININT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,51,51,-153,-152,-61,51,-76,-56,-156,51,-127,-75,-58,-126,51,-124,-78,-23,-129,-65,51,-63,51,-125,-74,-68,-66,-5,51,-50,-32,-79,-156,-30,51,-21,-70,-46,-53,-69,-62,51,-59,-1,-77,-55,-131,-67,-27,51,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,51,-139,51,-3,-60,51,51,51,-52,-146,-42,-40,51,51,-39,51,-34,-35,-41,-37,-38,51,-31,-97,-95,51,51,-81,-72,-73,-51,51,51,51,51,51,51,51,51,-156,51,51,-147,-4,51,-82,-132,51,-26,-25,51,-33,-44,-45,-36,-84,-90,-54,-96,51,-80,51,-28,-29,-47,-48,-49,-112,51,51,-8,-148,-140,51,-156,51,51,-100,51,-99,-98,51,51,-113,-156,-22,-9,-156,-156,-137,51,51,-83,-156,51,-89,51,51,51,-136,51,-141,51,-149,51,-144,-133,-134,-138,51,51,-142,-145,51,51,]),'.':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,133,144,159,163,165,173,184,190,207,210,211,214,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,120,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,182,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,241,-113,-83,-89,]),'WITH':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,9,9,-153,-152,-61,9,-76,-56,-156,9,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,9,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,9,-139,-3,-60,9,-52,-146,-31,-97,-95,-81,-72,-73,-51,9,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,9,-8,-148,-140,9,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,9,-83,-89,9,-136,9,-141,9,-149,-144,-133,-134,-138,-142,-145,]),'NEQ':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,111,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,111,]),'POWER':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,144,159,163,165,173,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,119,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,-113,-83,-89,]),'+':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,32,32,-153,-152,-61,32,-76,-56,-156,32,-127,-75,-58,-126,32,-124,-78,-23,-129,-65,32,-63,32,-125,-74,-68,-66,-5,32,-50,105,-79,-156,-30,32,-21,-70,-46,-53,-69,-62,32,-59,-1,-77,-55,-131,-67,-27,32,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,32,-139,32,-3,-60,32,32,32,-52,-146,-42,-40,32,32,-39,32,-34,-35,-41,-37,-38,32,-31,-97,-95,32,32,-81,-72,-73,-51,32,32,32,32,32,32,32,32,-156,32,32,-147,-4,32,-82,-132,32,-26,-25,32,105,-44,-45,-36,-84,-90,-54,-96,32,-80,32,-28,-29,-47,-48,-49,-112,32,-65,32,-8,-148,-140,32,-156,32,32,-100,32,-99,-98,32,32,-113,-156,-22,-9,-156,-156,-137,32,32,-83,-156,32,-89,32,32,32,-136,32,-141,32,-149,32,-144,-133,-134,-138,32,32,-142,-145,32,32,]),'NEWLINE':([0,1,5,6,7,10,11,12,13,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,43,44,46,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,79,81,86,87,88,95,99,115,117,118,122,124,125,127,136,141,142,144,147,148,154,155,156,158,159,160,162,163,164,165,173,175,176,177,178,179,184,187,189,190,193,202,203,207,210,211,215,218,219,220,222,223,230,231,233,234,253,254,255,264,265,278,279,],[1,-154,79,-6,-61,-15,-76,-56,1,1,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,1,-30,1,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-155,1,1,79,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,1,79,-7,-82,-26,-25,-33,-44,-45,1,-84,-88,1,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-148,-85,1,-100,-99,-98,-117,-113,1,-22,1,1,-83,1,-94,-89,-86,-91,1,-87,1,-92,-93,]),'-':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,67,67,-153,-152,-61,67,-76,-56,-156,67,-127,-75,-58,-126,67,-124,-78,-23,-129,-65,67,-63,67,-125,-74,-68,-66,-5,67,-50,107,-79,-156,-30,67,-21,-70,-46,-53,-69,-62,67,-59,-1,-77,-55,-131,-67,-27,67,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,67,-139,67,-3,-60,67,67,67,-52,-146,-42,-40,67,67,-39,67,-34,-35,-41,-37,-38,67,-31,-97,-95,67,67,-81,-72,-73,-51,67,67,67,67,67,67,67,67,-156,67,67,-147,-4,67,-82,-132,67,-26,-25,67,107,-44,-45,-36,-84,-90,-54,-96,67,-80,67,-28,-29,-47,-48,-49,-112,67,-65,67,-8,-148,-140,67,-156,67,67,-100,67,-99,-98,67,67,-113,-156,-22,-9,-156,-156,-137,67,67,-83,-156,67,-89,67,67,67,-136,67,-141,67,-149,67,-144,-133,-134,-138,67,67,-142,-145,67,67,]),',':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,89,96,98,99,115,117,118,122,123,124,125,127,144,147,148,152,154,155,156,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,180,181,183,184,185,187,189,190,196,197,199,202,207,209,210,211,212,213,218,220,230,233,234,235,236,237,238,239,243,248,251,253,254,256,258,264,270,274,278,279,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,136,-60,136,151,-122,-52,-31,-97,-95,-81,136,-72,-73,-51,-82,-26,-25,151,-33,-44,-45,-84,203,-90,-54,-96,206,-101,-103,-102,-111,-108,-110,-80,-28,-29,-47,-48,-49,-114,214,217,-112,-116,136,136,-65,136,-123,227,231,-100,-105,-99,-98,-106,240,-113,-22,-83,255,-89,-111,-109,-110,-107,-104,-115,136,-150,-86,265,267,-118,-87,-151,-119,-92,-93,]),'/':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,131,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,131,131,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'NEXT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,10,10,-153,-152,-61,10,-76,-56,-156,10,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,10,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,10,-139,10,-3,-60,10,-52,-146,-31,-97,-95,-81,-72,-73,-51,10,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,10,-8,-148,-140,10,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,10,-83,-89,10,-136,10,-141,10,-149,-144,-133,-134,-138,-142,-145,]),'SHORTSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,34,34,-153,-152,-61,34,-76,-56,-156,34,-127,-75,-58,-126,34,-124,-78,-23,-129,-65,34,-63,34,-125,-74,-68,-66,-5,34,-50,-32,-79,-156,-30,34,-156,-21,-70,-46,-53,-69,-62,34,-59,-1,-77,124,-55,-131,-67,-27,34,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,34,-139,34,-3,-60,34,34,34,-52,-146,-42,-40,34,34,-39,34,-34,-35,-41,-37,-38,34,-31,34,-97,-95,34,34,-81,-72,-73,-51,34,34,34,34,34,34,34,34,-156,34,34,-147,-4,34,-82,-132,34,-26,-25,34,-33,-44,-45,-36,-84,-90,-54,-96,34,-80,34,-28,-29,-47,-48,-49,-112,34,34,-8,-148,-140,34,-156,34,34,-100,34,-99,-98,34,34,-113,-156,-22,-9,-156,-156,-137,34,34,-83,-156,34,-89,34,34,34,-136,34,-141,34,-149,34,-156,-144,-133,-134,-138,-156,34,34,34,-142,34,-145,34,34,]),'OPEN_PAREN':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,74,75,76,78,79,80,81,82,84,85,86,87,88,90,91,92,93,99,100,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,53,53,-153,-152,-61,53,-76,-56,-156,53,-127,-75,-58,-126,53,-124,-78,-23,-129,-65,53,-63,53,-125,-74,-68,-66,-5,53,-50,-32,-79,-156,-30,53,-21,-70,-46,-53,-69,-62,53,-59,-1,-77,-55,-131,-67,-27,53,-130,-71,-24,-43,-128,133,134,-57,-64,-2,-155,-143,-156,-135,53,-139,53,-3,143,53,146,53,53,-52,153,-146,-42,-40,53,53,-39,53,-34,-35,-41,-37,-38,53,-31,-97,-95,53,53,-81,-72,-73,-51,53,53,53,53,53,53,53,53,-156,53,53,-147,-4,53,-82,-132,53,-26,-25,53,-33,-44,-45,-36,-84,-90,-54,-96,53,-80,53,-28,-29,-47,-48,-49,-112,53,53,-8,-148,-140,53,-156,53,53,-100,53,-99,-98,53,53,-113,-156,-22,-9,-156,-156,-137,53,53,-83,-156,53,-89,53,53,53,-136,53,-141,53,-149,53,-144,-133,-134,-138,53,53,-142,-145,53,53,]),'OCTINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,35,35,-153,-152,-61,35,-76,-56,-156,35,-127,-75,-58,-126,35,-124,-78,-23,-129,-65,35,-63,35,-125,-74,-68,-66,-5,35,-50,-32,-79,-156,-30,35,-21,-70,-46,-53,-69,-62,35,-59,-1,-77,-55,-131,-67,-27,35,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,35,-139,35,-3,-60,35,35,35,-52,-146,-42,-40,35,35,-39,35,-34,-35,-41,-37,-38,35,-31,-97,-95,35,35,-81,-72,-73,-51,35,35,35,35,35,35,35,35,-156,35,35,-147,-4,35,-82,-132,35,-26,-25,35,-33,-44,-45,-36,-84,-90,-54,-96,35,-80,35,-28,-29,-47,-48,-49,-112,35,35,-8,-148,-140,35,-156,35,35,-100,35,-99,-98,35,35,-113,-156,-22,-9,-156,-156,-137,35,35,-83,-156,35,-89,35,35,35,-136,35,-141,35,-149,35,-144,-133,-134,-138,35,35,-142,-145,35,35,]),'STRPREFIX':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,59,59,-153,-152,-61,59,-76,-56,-156,59,-127,-75,-58,-126,59,-124,-78,-23,-129,-65,59,-63,59,-125,-74,-68,-66,-5,59,-50,-32,-79,-156,-30,59,-156,-21,-70,-46,-53,-69,-62,59,-59,-1,-77,-55,-131,-67,-27,59,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,59,-139,59,-3,-60,59,59,59,-52,-146,-42,-40,59,59,-39,59,-34,-35,-41,-37,-38,59,-31,59,-97,-95,59,59,-81,-72,-73,-51,59,59,59,59,59,59,59,59,-156,59,59,-147,-4,59,-82,-132,59,-26,-25,59,-33,-44,-45,-36,-84,-90,-54,-96,59,-80,59,-28,-29,-47,-48,-49,-112,59,59,-8,-148,-140,59,-156,59,59,-100,59,-99,-98,59,59,-113,-156,-22,-9,-156,-156,-137,59,59,-83,-156,59,-89,59,59,59,-136,59,-141,59,-149,59,-156,-144,-133,-134,-138,-156,59,59,59,-142,59,-145,59,59,]),'INTEGER':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,36,36,-153,-152,-61,36,-76,-56,-156,36,-127,-75,-58,-126,36,-124,-78,-23,-129,-65,36,-63,36,-125,-74,-68,-66,-5,36,-50,-32,-79,-156,-30,36,-21,-70,-46,-53,-69,-62,36,-59,-1,-77,-55,-131,-67,-27,36,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,36,-139,36,-3,-60,36,36,36,-52,-146,-42,-40,36,36,-39,36,-34,-35,-41,-37,-38,36,-31,-97,-95,36,36,-81,-72,-73,-51,36,36,36,36,36,36,36,36,-156,36,36,-147,-4,36,-82,-132,36,-26,-25,36,-33,-44,-45,-36,-84,-90,-54,-96,36,-80,36,-28,-29,-47,-48,-49,-112,36,36,-8,-148,-140,36,-156,36,36,-100,36,-99,-98,36,36,-113,-156,-22,-9,-156,-156,-137,36,36,-83,-156,36,-89,36,36,36,-136,36,-141,36,-149,36,-144,-133,-134,-138,36,36,-142,-145,36,36,]),'IMAGINARY':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,69,69,-153,-152,-61,69,-76,-56,-156,69,-127,-75,-58,-126,69,-124,-78,-23,-129,-65,69,-63,69,-125,-74,-68,-66,-5,69,-50,-32,-79,-156,-30,69,-21,-70,-46,-53,-69,-62,69,-59,-1,-77,-55,-131,-67,-27,69,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,69,-139,69,-3,-60,69,69,69,-52,-146,-42,-40,69,69,-39,69,-34,-35,-41,-37,-38,69,-31,-97,-95,69,69,-81,-72,-73,-51,69,69,69,69,69,69,69,69,-156,69,69,-147,-4,69,-82,-132,69,-26,-25,69,-33,-44,-45,-36,-84,-90,-54,-96,69,-80,69,-28,-29,-47,-48,-49,-112,69,69,-8,-148,-140,69,-156,69,69,-100,69,-99,-98,69,69,-113,-156,-22,-9,-156,-156,-137,69,69,-83,-156,69,-89,69,69,69,-136,69,-141,69,-149,69,-144,-133,-134,-138,69,69,-142,-145,69,69,]),':':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,121,122,124,125,127,144,147,148,154,155,156,159,161,163,164,165,167,168,172,173,175,176,177,178,179,184,190,195,200,206,207,209,210,211,212,218,230,234,237,239,249,272,275,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,168,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,204,-90,-54,-96,208,-103,212,-80,-28,-29,-47,-48,-49,-112,204,224,229,168,-100,-105,-99,-98,-106,-113,-83,-89,212,-104,263,276,277,]),'=':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,126,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,216,218,220,230,234,257,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,135,-60,-52,-31,-97,-95,-81,-72,-73,174,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,242,-113,-22,-83,-89,268,]),'<':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,112,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,112,]),'$end':([1,3,4,5,15,19,22,25,33,37,55,61,68,72,78,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,0,-153,-152,-127,-126,-124,-129,-125,-5,-1,-131,-130,-128,-2,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'FUNCTION':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,38,38,-153,-152,-61,38,-76,-56,-156,38,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,38,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,38,-139,-3,-60,38,-52,-146,-31,-97,-95,-81,-72,-73,-51,38,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,38,-8,-148,-140,38,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,38,-83,-89,38,-136,38,-141,38,-149,-144,-133,-134,-138,-142,-145,]),'REPEAT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,39,39,-153,-152,-61,39,-76,-56,-156,39,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,39,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,39,-139,-3,-60,39,-52,-146,-31,-97,-95,-81,-72,-73,-51,39,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,39,-8,-148,-140,39,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,39,-83,-89,39,-136,39,-141,39,-149,-144,-133,-134,-138,-142,-145,]),'GTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,106,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,106,]),'FOR':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,31,31,-153,-152,-61,31,-76,-56,-156,31,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,31,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,31,-139,-3,-60,31,-52,-146,-31,-97,-95,-81,-72,-73,-51,31,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,31,-8,-148,-140,31,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,31,-83,-89,31,-136,31,-141,31,-149,-144,-133,-134,-138,-142,-145,]),'BADAND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,129,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,129,129,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'ELSEIF':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,91,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'LONGSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,17,17,-153,-152,-61,17,-76,-56,-156,17,-127,-75,-58,-126,17,-124,-78,-23,-129,-65,17,-63,17,-125,-74,-68,-66,-5,17,-50,-32,-79,-156,-30,17,-156,-21,-70,-46,-53,-69,-62,17,-59,-1,-77,125,-55,-131,-67,-27,17,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,17,-139,17,-3,-60,17,17,17,-52,-146,-42,-40,17,17,-39,17,-34,-35,-41,-37,-38,17,-31,17,-97,-95,17,17,-81,-72,-73,-51,17,17,17,17,17,17,17,17,-156,17,17,-147,-4,17,-82,-132,17,-26,-25,17,-33,-44,-45,-36,-84,-90,-54,-96,17,-80,17,-28,-29,-47,-48,-49,-112,17,17,-8,-148,-140,17,-156,17,17,-100,17,-99,-98,17,17,-113,-156,-22,-9,-156,-156,-137,17,17,-83,-156,17,-89,17,17,17,-136,17,-141,17,-149,17,-156,-144,-133,-134,-138,-156,17,17,17,-142,17,-145,17,17,]),'NOT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,114,115,117,118,121,122,124,125,127,128,129,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,45,45,-153,-152,-61,45,-76,-56,-156,45,-127,-75,-58,-126,45,-124,-78,-23,-129,-65,45,-63,-125,-74,-68,-66,-5,45,-50,110,-79,-156,-30,45,-21,-70,-46,-53,-69,-62,45,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,45,-139,45,-3,-60,45,45,45,-52,-146,45,-31,-97,-95,45,-81,-72,-73,-51,45,45,45,45,45,-156,45,45,-147,-4,45,-82,-132,45,-26,-25,45,-33,-44,-45,-84,-90,-54,-96,45,-80,45,-28,-29,-47,-48,-49,-112,45,-65,45,-8,-148,-140,45,-156,45,45,-100,45,-99,-98,45,45,-113,-156,-22,-9,-156,-156,-137,45,45,-83,-156,45,-89,45,45,45,-136,45,-141,45,-149,45,-144,-133,-134,-138,45,45,-142,-145,45,45,]),'AS':([83,94,],[139,149,]),'LTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,103,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,103,]),'IN':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,96,98,99,110,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,197,198,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,109,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,150,-122,-52,157,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-123,226,-100,-99,-98,-113,-83,-89,]),'[':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,229,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,263,267,268,269,273,276,277,],[-156,-154,43,43,-153,-152,-61,43,-76,-56,-156,43,-127,-75,-58,-126,43,-124,-78,-23,-129,-65,43,-63,97,43,-125,-74,-68,-66,-5,43,-50,-32,-79,-156,-30,43,-21,-70,-46,121,-69,-62,43,-59,-1,-77,-55,-131,-67,-27,43,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,43,-139,43,-3,-60,43,43,43,-52,-146,-42,-40,43,43,-39,43,-34,-35,-41,-37,-38,43,-31,-97,-95,43,43,-81,-72,-73,-51,43,43,43,43,43,43,43,43,-156,43,43,-147,-4,43,-82,-132,43,-26,-25,43,-33,-44,-45,-36,-84,-90,-54,-96,43,-80,43,-28,-29,-47,-48,-49,-112,43,-65,43,-8,-148,-140,43,-156,43,43,-100,43,-99,-98,43,43,-113,-156,-22,-9,-156,-156,-137,43,43,43,-83,-156,43,-89,43,43,43,-136,43,-141,43,-149,43,-144,-133,-134,-138,43,43,43,-142,-145,43,43,]),'ELSE':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,90,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),']':([1,4,5,7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,43,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,79,88,98,99,114,115,117,118,122,124,125,127,144,147,148,152,154,155,156,158,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,184,197,201,202,207,209,210,211,212,218,230,234,235,236,237,238,239,253,264,],[-154,-153,-152,-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-156,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-155,-60,-122,-52,159,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,198,-33,-44,-45,-156,-84,-88,-90,-54,-96,207,-101,-103,-102,210,-108,211,-80,-28,-29,-47,-48,-49,-112,-123,230,-85,-100,-105,-99,-98,-106,-113,-83,-89,-111,-109,-110,-107,-104,-86,-87,]),'ID':([0,1,2,3,4,5,7,8,9,11,12,13,14,15,17,18,19,21,22,23,24,25,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,64,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,97,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,120,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,143,144,145,146,147,148,149,150,151,153,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,182,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,224,225,226,227,228,230,231,232,234,240,241,242,244,245,246,247,248,250,252,256,259,260,261,262,267,268,269,273,276,277,],[-156,-154,73,73,-153,-152,-61,73,83,-76,-56,-156,73,-127,-75,-58,-126,88,-124,-78,-23,-129,94,-65,88,-63,98,88,-125,-74,-68,-66,-5,100,73,-50,-32,-79,-156,-30,88,-21,-70,-46,-53,-69,-62,88,-59,-1,-77,-55,-131,-67,126,-27,88,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,73,-139,73,-3,-60,73,88,88,98,-52,-146,-42,-40,88,88,-39,88,-34,-35,-41,-37,-38,88,-31,-97,-95,88,165,88,-81,-72,-73,-51,88,88,88,88,88,88,88,88,-156,88,73,193,-147,-4,88,-82,-132,88,-26,-25,195,88,197,200,-33,-44,-45,-36,-84,-90,-54,-96,88,-80,88,-28,-29,-47,-48,-49,216,-112,88,73,-8,-148,-140,73,-156,88,88,-100,88,-99,-98,88,88,-113,-156,-22,-9,-156,-156,247,-137,88,249,73,-83,-156,88,-89,88,257,88,73,-136,73,-141,73,-149,88,-144,-133,-134,269,-138,88,88,-142,-145,88,88,]),'CLOSE_PAREN':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,53,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,122,123,124,125,127,133,143,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,180,181,183,184,185,186,194,199,207,210,211,218,220,230,234,243,251,258,270,274,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,122,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,-81,173,-72,-73,-51,184,184,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-114,215,218,-112,-116,219,223,228,-100,-99,-98,-113,-22,-83,-89,-115,-150,-118,-151,-119,]),'IF':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,74,74,-153,-152,-61,74,-76,-56,-156,74,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,74,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,74,-139,-3,-60,74,-52,-146,-31,-97,-95,-81,-72,-73,-51,74,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,74,-8,-148,-140,74,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,74,-83,-89,74,-136,74,-141,74,-149,-144,-133,-134,-138,-142,-145,]),'AND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,128,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,128,128,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'`':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,89,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,21,21,-153,-152,-61,21,-76,-56,-156,21,-127,-75,-58,-126,21,-124,-78,-23,-129,-65,21,-63,21,-125,-74,-68,-66,-5,21,-50,-32,-79,-156,-30,21,-21,-70,-46,-53,-69,-62,21,-59,-1,-77,-55,-131,-67,-27,21,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,21,-139,21,-3,-60,144,21,21,21,-52,-146,-42,-40,21,21,-39,21,-34,-35,-41,-37,-38,21,-31,-97,-95,21,21,-81,-72,-73,-51,21,21,21,21,21,21,21,21,-156,21,21,-147,-4,21,-82,-132,21,-26,-25,21,-33,-44,-45,-36,-84,-90,-54,-96,21,-80,21,-28,-29,-47,-48,-49,-112,21,21,-8,-148,-140,21,-156,21,21,-100,21,-99,-98,21,21,-113,-156,-22,-9,-156,-156,-137,21,21,-83,-156,21,-89,21,21,21,-136,21,-141,21,-149,21,-144,-133,-134,-138,21,21,-142,-145,21,21,]),'BADOR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,92,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'BREAK':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,62,62,-153,-152,-61,62,-76,-56,-156,62,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,62,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,62,-139,62,-3,-60,62,-52,-146,-31,-97,-95,-81,-72,-73,-51,62,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,62,-8,-148,-140,62,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,62,-83,-89,62,-136,62,-141,62,-149,-144,-133,-134,-138,-142,-145,]),'HEXINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,63,63,-153,-152,-61,63,-76,-56,-156,63,-127,-75,-58,-126,63,-124,-78,-23,-129,-65,63,-63,63,-125,-74,-68,-66,-5,63,-50,-32,-79,-156,-30,63,-21,-70,-46,-53,-69,-62,63,-59,-1,-77,-55,-131,-67,-27,63,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,63,-139,63,-3,-60,63,63,63,-52,-146,-42,-40,63,63,-39,63,-34,-35,-41,-37,-38,63,-31,-97,-95,63,63,-81,-72,-73,-51,63,63,63,63,63,63,63,63,-156,63,63,-147,-4,63,-82,-132,63,-26,-25,63,-33,-44,-45,-36,-84,-90,-54,-96,63,-80,63,-28,-29,-47,-48,-49,-112,63,63,-8,-148,-140,63,-156,63,63,-100,63,-99,-98,63,63,-113,-156,-22,-9,-156,-156,-137,63,63,-83,-156,63,-89,63,63,63,-136,63,-141,63,-149,63,-144,-133,-134,-138,63,63,-142,-145,63,63,]),'ISEQUAL':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,102,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,102,]),'ITEM_TAG':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,76,76,-153,-152,-61,76,-76,-56,-156,76,-127,-75,-58,-126,76,-124,-78,-23,-129,-65,76,-63,76,-125,-74,-68,-66,-5,76,-50,-32,-79,-156,-30,76,-21,-70,-46,-53,-69,-62,76,-59,-1,-77,-55,-131,-67,-27,76,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,76,-139,76,-3,-60,76,76,76,-52,-146,-42,-40,76,76,-39,76,-34,-35,-41,-37,-38,76,-31,-97,-95,76,76,-81,-72,-73,-51,76,76,76,76,76,76,76,76,-156,76,76,-147,-4,76,-82,-132,76,-26,-25,76,-33,-44,-45,-36,-84,-90,-54,-96,76,-80,76,-28,-29,-47,-48,-49,-112,76,76,-8,-148,-140,76,-156,76,76,-100,76,-99,-98,76,76,-113,-156,-22,-9,-156,-156,-137,76,76,-83,-156,76,-89,76,76,76,-136,76,-141,76,-149,76,-144,-133,-134,-138,76,76,-142,-145,76,76,]),'{':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,46,46,-153,-152,-61,81,-76,-56,-156,81,-127,-75,-58,-126,46,-124,-78,-23,-129,-65,46,-63,46,-125,-74,-68,-66,-5,81,-50,-32,-79,-156,-30,46,-21,-70,-46,-53,-69,-62,46,-59,-1,-77,-55,-131,-67,-27,46,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,81,-139,46,-3,-60,81,46,46,-52,-146,-42,-40,46,46,-39,46,-34,-35,-41,-37,-38,46,-31,-97,-95,46,46,-81,-72,-73,-51,46,46,46,46,46,46,46,46,-156,46,46,-147,-4,46,-82,-132,46,-26,-25,46,-33,-44,-45,-36,-84,-90,-54,-96,46,-80,46,-28,-29,-47,-48,-49,-112,46,46,-8,-148,-140,81,-156,46,46,-100,46,-99,-98,46,46,-113,-156,-22,-9,-156,-156,-137,46,81,-83,-156,46,-89,46,46,81,-136,81,-141,81,-149,46,-144,-133,-134,-138,46,46,-142,-145,46,46,]),'>':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,113,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,113,]),'}':([1,4,5,7,11,12,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,40,41,42,44,46,48,49,50,51,52,54,56,60,61,63,65,68,69,70,71,72,75,76,79,80,81,82,85,87,88,99,101,115,116,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,162,163,164,165,173,175,176,177,178,179,184,191,192,205,207,210,211,218,221,222,225,230,233,234,245,250,254,259,260,262,278,279,],[-154,-153,-152,-61,-76,-56,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,-50,-32,-79,-30,-156,-70,-46,-53,-69,-62,-59,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-155,-143,-156,-135,-139,-3,-60,-52,-146,-31,163,-97,-95,-81,-72,-73,-51,163,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-156,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,222,-8,234,-100,-99,-98,-113,-9,-156,-137,-83,-94,-89,-136,-149,-91,-133,-134,-138,-92,-93,]),'OR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,93,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'LOOP':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,26,26,-153,-152,-61,26,-76,-56,-156,26,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,26,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,26,-139,-3,-60,26,-52,-146,-31,-97,-95,-81,-72,-73,-51,26,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,26,-8,-148,-140,26,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,26,-83,-89,26,-136,26,-141,26,-149,-144,-133,-134,-138,-142,-145,]),}
-
-_lr_action = { }
-for _k, _v in _lr_action_items.items():
-   for _x,_y in zip(_v[0],_v[1]):
-      if not _x in _lr_action:  _lr_action[_x] = { }
-      _lr_action[_x][_k] = _y
-del _lr_action_items
-
-_lr_goto_items = {'statements':([138,],[191,]),'comp_operator':([41,],[104,]),'small_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[6,6,6,6,6,6,142,6,6,6,6,6,6,6,6,]),'fancy_drel_assignment_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,]),'primary':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,]),'stringliteral':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,116,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,266,267,268,271,276,277,],[28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,161,28,28,28,28,28,28,28,28,28,28,28,190,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,272,28,28,275,28,28,]),'item_tag':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,]),'not_test':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[65,65,65,65,65,65,65,115,65,65,65,65,65,65,65,65,175,176,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,]),'listmaker':([114,],[158,]),'do_stmt_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[8,8,8,8,8,8,8,8,8,8,8,8,8,8,]),'func_arg':([133,143,217,],[180,180,243,]),'enclosure':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,]),'newlines':([0,13,16,43,46,81,86,136,158,162,203,219,222,223,231,255,265,],[5,5,87,5,5,5,141,5,5,5,5,5,5,5,5,5,5,]),'break_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,]),'dotlist':([133,],[181,]),'arglist':([153,],[199,]),'long_slice':([121,206,],[169,169,]),'repeat_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[68,68,68,68,68,68,68,68,68,68,68,68,68,68,]),'u_expr':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[49,49,49,49,49,49,99,49,49,49,127,49,49,49,49,49,49,49,49,49,164,49,49,49,177,178,179,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,]),'if_else_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,]),'parenth_form':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,]),'literal':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,]),'attributeref':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,]),'call':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,]),'argument_list':([133,143,],[183,183,]),'statement':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[55,78,82,82,82,82,82,192,221,82,82,82,82,82,]),'string_conversion':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,]),'with_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[13,13,13,13,13,13,13,13,13,13,13,13,13,13,]),'input':([0,],[3,]),'loop_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[14,14,14,14,14,14,14,14,14,14,14,14,14,14,]),'do_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[15,15,15,15,15,15,15,15,15,15,15,15,15,15,]),'next_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,]),'empty':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,]),'listmaker2':([160,],[202,]),'short_slice':([121,206,],[167,167,]),'power':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,]),'a_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[41,41,41,41,41,41,41,41,41,41,41,41,41,41,154,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,]),'print_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,]),'maybe_nline':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[2,84,114,116,138,188,201,205,232,244,245,246,252,266,271,]),'tablemaker2':([233,],[254,]),'slicing':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,]),'for_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[19,19,19,19,19,19,19,19,19,19,19,19,19,19,]),'m_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,105,107,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,155,156,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,]),'and_test':([2,3,8,14,21,29,39,53,84,86,90,92,93,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[70,70,70,70,70,70,70,70,70,70,70,147,148,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,]),'restricted_comp_operator':([41,247,],[108,261,]),'atom':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,]),'funcdef':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[61,61,61,61,61,61,61,61,61,61,61,61,61,61,]),'expr_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,]),'slice_list':([121,],[166,]),'subscription':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,]),'comparison':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,]),'attribute_tag':([50,],[118,]),'if_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[22,22,22,22,22,22,22,22,22,22,22,22,22,22,]),'id_list':([31,97,],[96,152,]),'proper_slice':([121,206,],[170,235,]),'list_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,229,232,240,242,244,246,248,252,263,267,268,276,277,],[23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,251,23,23,23,23,23,23,23,270,23,23,23,23,]),'loop_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[72,72,72,72,72,72,72,72,72,72,72,72,72,72,]),'or_test':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,]),'compound_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[37,37,37,37,37,37,37,37,37,37,37,37,37,37,]),'with_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[25,25,25,25,25,25,25,25,25,25,25,25,25,25,]),'tablemaker':([116,138,],[162,162,]),'table_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,]),'suite':([8,14,39,84,90,196,228,244,246,248,],[80,85,101,140,145,225,250,259,260,262,]),'simple_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[16,16,16,16,16,16,16,16,16,16,16,16,16,16,]),'testlist_star_expr':([2,3,8,14,21,39,53,84,86,90,135,137,138,150,191,196,226,228,244,246,248,],[77,77,77,77,89,77,123,77,77,77,187,189,77,196,77,77,248,77,77,77,77,]),'slice_item':([121,206,],[171,236,]),'expression':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[47,47,47,47,47,95,47,47,47,47,47,160,172,185,186,47,47,47,185,194,47,209,213,220,47,47,233,237,238,239,185,47,47,253,256,258,47,47,47,264,273,274,278,279,]),}
-
-_lr_goto = { }
-for _k, _v in _lr_goto_items.items():
-   for _x,_y in zip(_v[0],_v[1]):
-       if not _x in _lr_goto: _lr_goto[_x] = { }
-       _lr_goto[_x][_k] = _y
-del _lr_goto_items
-_lr_productions = [
-  ("S' -> input","S'",1,None,None,None),
-  ('input -> maybe_nline statement','input',2,'p_input','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',19),
-  ('input -> input statement','input',2,'p_input','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',20),
-  ('statement -> simple_stmt newlines','statement',2,'p_statement','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',36),
-  ('statement -> simple_stmt ; newlines','statement',3,'p_statement','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',37),
-  ('statement -> compound_stmt','statement',1,'p_statement','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',38),
-  ('simple_stmt -> small_stmt','simple_stmt',1,'p_simple_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',44),
-  ('simple_stmt -> simple_stmt ; small_stmt','simple_stmt',3,'p_simple_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',45),
-  ('statements -> statement','statements',1,'p_statements','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',55),
-  ('statements -> statements statement','statements',2,'p_statements','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',56),
-  ('small_stmt -> expr_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',61),
-  ('small_stmt -> print_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',62),
-  ('small_stmt -> break_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',63),
-  ('small_stmt -> next_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',64),
-  ('break_stmt -> BREAK','break_stmt',1,'p_break_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',68),
-  ('next_stmt -> NEXT','next_stmt',1,'p_next_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',72),
-  ('print_stmt -> PRINT expression','print_stmt',2,'p_print_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',76),
-  ('expr_stmt -> testlist_star_expr','expr_stmt',1,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',84),
-  ('expr_stmt -> testlist_star_expr AUGOP testlist_star_expr','expr_stmt',3,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',85),
-  ('expr_stmt -> testlist_star_expr = testlist_star_expr','expr_stmt',3,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',86),
-  ('expr_stmt -> fancy_drel_assignment_stmt','expr_stmt',1,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',87),
-  ('testlist_star_expr -> expression','testlist_star_expr',1,'p_testlist_star_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',96),
-  ('testlist_star_expr -> testlist_star_expr , maybe_nline expression','testlist_star_expr',4,'p_testlist_star_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',97),
-  ('expression -> or_test','expression',1,'p_expression','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',107),
-  ('or_test -> and_test','or_test',1,'p_or_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',115),
-  ('or_test -> or_test OR and_test','or_test',3,'p_or_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',116),
-  ('or_test -> or_test BADOR and_test','or_test',3,'p_or_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',117),
-  ('and_test -> not_test','and_test',1,'p_and_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',122),
-  ('and_test -> and_test AND not_test','and_test',3,'p_and_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',123),
-  ('and_test -> and_test BADAND not_test','and_test',3,'p_and_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',124),
-  ('not_test -> comparison','not_test',1,'p_not_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',129),
-  ('not_test -> NOT not_test','not_test',2,'p_not_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',130),
-  ('comparison -> a_expr','comparison',1,'p_comparison','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',135),
-  ('comparison -> a_expr comp_operator a_expr','comparison',3,'p_comparison','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',136),
-  ('comp_operator -> restricted_comp_operator','comp_operator',1,'p_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',142),
-  ('comp_operator -> IN','comp_operator',1,'p_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',143),
-  ('comp_operator -> NOT IN','comp_operator',2,'p_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',144),
-  ('restricted_comp_operator -> <','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',150),
-  ('restricted_comp_operator -> >','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',151),
-  ('restricted_comp_operator -> GTE','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',152),
-  ('restricted_comp_operator -> LTE','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',153),
-  ('restricted_comp_operator -> NEQ','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',154),
-  ('restricted_comp_operator -> ISEQUAL','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',155),
-  ('a_expr -> m_expr','a_expr',1,'p_a_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',159),
-  ('a_expr -> a_expr + m_expr','a_expr',3,'p_a_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',160),
-  ('a_expr -> a_expr - m_expr','a_expr',3,'p_a_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',161),
-  ('m_expr -> u_expr','m_expr',1,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',168),
-  ('m_expr -> m_expr * u_expr','m_expr',3,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',169),
-  ('m_expr -> m_expr / u_expr','m_expr',3,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',170),
-  ('m_expr -> m_expr ^ u_expr','m_expr',3,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',171),
-  ('u_expr -> power','u_expr',1,'p_u_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',178),
-  ('u_expr -> - u_expr','u_expr',2,'p_u_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',179),
-  ('u_expr -> + u_expr','u_expr',2,'p_u_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',180),
-  ('power -> primary','power',1,'p_power','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',187),
-  ('power -> primary POWER u_expr','power',3,'p_power','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',188),
-  ('primary -> atom','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',196),
-  ('primary -> attributeref','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',197),
-  ('primary -> subscription','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',198),
-  ('primary -> slicing','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',199),
-  ('primary -> call','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',200),
-  ('atom -> ID','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',205),
-  ('atom -> item_tag','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',206),
-  ('atom -> literal','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',207),
-  ('atom -> enclosure','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',208),
-  ('item_tag -> ITEM_TAG','item_tag',1,'p_item_tag','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',213),
-  ('literal -> stringliteral','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',217),
-  ('literal -> INTEGER','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',218),
-  ('literal -> HEXINT','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',219),
-  ('literal -> OCTINT','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',220),
-  ('literal -> BININT','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',221),
-  ('literal -> REAL','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',222),
-  ('literal -> IMAGINARY','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',223),
-  ('stringliteral -> STRPREFIX SHORTSTRING','stringliteral',2,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',228),
-  ('stringliteral -> STRPREFIX LONGSTRING','stringliteral',2,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',229),
-  ('stringliteral -> SHORTSTRING','stringliteral',1,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',230),
-  ('stringliteral -> LONGSTRING','stringliteral',1,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',231),
-  ('enclosure -> parenth_form','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',236),
-  ('enclosure -> string_conversion','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',237),
-  ('enclosure -> list_display','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',238),
-  ('enclosure -> table_display','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',239),
-  ('parenth_form -> OPEN_PAREN testlist_star_expr CLOSE_PAREN','parenth_form',3,'p_parenth_form','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',243),
-  ('parenth_form -> OPEN_PAREN CLOSE_PAREN','parenth_form',2,'p_parenth_form','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',244),
-  ('string_conversion -> ` testlist_star_expr `','string_conversion',3,'p_string_conversion','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',251),
-  ('list_display -> [ maybe_nline listmaker maybe_nline ]','list_display',5,'p_list_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',256),
-  ('list_display -> [ maybe_nline ]','list_display',3,'p_list_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',257),
-  ('listmaker -> expression listmaker2','listmaker',2,'p_listmaker','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',265),
-  ('listmaker2 -> , maybe_nline expression','listmaker2',3,'p_listmaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',270),
-  ('listmaker2 -> listmaker2 , maybe_nline expression','listmaker2',4,'p_listmaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',271),
-  ('listmaker2 -> <empty>','listmaker2',0,'p_listmaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',272),
-  ('table_display -> { maybe_nline tablemaker maybe_nline }','table_display',5,'p_table_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',282),
-  ('table_display -> { maybe_nline }','table_display',3,'p_table_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',283),
-  ('tablemaker -> stringliteral : expression tablemaker2','tablemaker',4,'p_tablemaker','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',290),
-  ('tablemaker2 -> , maybe_nline stringliteral : expression','tablemaker2',5,'p_tablemaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',294),
-  ('tablemaker2 -> tablemaker2 , maybe_nline stringliteral : expression','tablemaker2',6,'p_tablemaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',295),
-  ('tablemaker2 -> <empty>','tablemaker2',0,'p_tablemaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',296),
-  ('attributeref -> primary attribute_tag','attributeref',2,'p_attributeref','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',310),
-  ('attribute_tag -> . ID','attribute_tag',2,'p_attribute_tag','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',314),
-  ('attribute_tag -> REAL','attribute_tag',1,'p_attribute_tag','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',315),
-  ('subscription -> primary [ expression ]','subscription',4,'p_subscription','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',322),
-  ('slicing -> primary [ proper_slice ]','slicing',4,'p_slicing','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',326),
-  ('slicing -> primary [ slice_list ]','slicing',4,'p_slicing','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',327),
-  ('proper_slice -> short_slice','proper_slice',1,'p_proper_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',331),
-  ('proper_slice -> long_slice','proper_slice',1,'p_proper_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',332),
-  ('short_slice -> :','short_slice',1,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',343),
-  ('short_slice -> expression : expression','short_slice',3,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',344),
-  ('short_slice -> : expression','short_slice',2,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',345),
-  ('short_slice -> expression :','short_slice',2,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',346),
-  ('long_slice -> short_slice : expression','long_slice',3,'p_long_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',355),
-  ('slice_list -> slice_item','slice_list',1,'p_slice_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',362),
-  ('slice_list -> slice_list , slice_item','slice_list',3,'p_slice_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',363),
-  ('slice_item -> expression','slice_item',1,'p_slice_item','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',370),
-  ('slice_item -> proper_slice','slice_item',1,'p_slice_item','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',371),
-  ('call -> ID OPEN_PAREN CLOSE_PAREN','call',3,'p_call','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',375),
-  ('call -> ID OPEN_PAREN argument_list CLOSE_PAREN','call',4,'p_call','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',376),
-  ('argument_list -> func_arg','argument_list',1,'p_argument_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',386),
-  ('argument_list -> argument_list , func_arg','argument_list',3,'p_argument_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',387),
-  ('func_arg -> expression','func_arg',1,'p_func_arg','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',394),
-  ('fancy_drel_assignment_stmt -> ID OPEN_PAREN dotlist CLOSE_PAREN','fancy_drel_assignment_stmt',4,'p_fancy_drel_assignment_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',398),
-  ('dotlist -> . ID = expression','dotlist',4,'p_dotlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',405),
-  ('dotlist -> dotlist , . ID = expression','dotlist',6,'p_dotlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',406),
-  ('exprlist -> a_expr','exprlist',1,'p_exprlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',413),
-  ('exprlist -> exprlist , a_expr','exprlist',3,'p_exprlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',414),
-  ('id_list -> ID','id_list',1,'p_id_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',421),
-  ('id_list -> id_list , ID','id_list',3,'p_id_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',422),
-  ('compound_stmt -> if_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',433),
-  ('compound_stmt -> if_else_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',434),
-  ('compound_stmt -> for_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',435),
-  ('compound_stmt -> do_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',436),
-  ('compound_stmt -> loop_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',437),
-  ('compound_stmt -> with_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',438),
-  ('compound_stmt -> repeat_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',439),
-  ('compound_stmt -> funcdef','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',440),
-  ('if_else_stmt -> if_stmt ELSE suite','if_else_stmt',3,'p_if_else_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',447),
-  ('if_stmt -> IF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',6,'p_if_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',453),
-  ('if_stmt -> if_stmt ELSEIF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',7,'p_if_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',454),
-  ('suite -> statement','suite',1,'p_suite','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',473),
-  ('suite -> { maybe_nline statements } maybe_nline','suite',5,'p_suite','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',474),
-  ('for_stmt -> FOR id_list IN testlist_star_expr suite','for_stmt',5,'p_for_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',481),
-  ('for_stmt -> FOR [ id_list ] IN testlist_star_expr suite','for_stmt',7,'p_for_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',482),
-  ('loop_stmt -> loop_head suite','loop_stmt',2,'p_loop_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',489),
-  ('loop_head -> LOOP ID AS ID','loop_head',4,'p_loop_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',495),
-  ('loop_head -> LOOP ID AS ID : ID','loop_head',6,'p_loop_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',496),
-  ('loop_head -> LOOP ID AS ID : ID restricted_comp_operator ID','loop_head',8,'p_loop_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',497),
-  ('do_stmt -> do_stmt_head suite','do_stmt',2,'p_do_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',508),
-  ('do_stmt_head -> DO ID = expression , expression','do_stmt_head',6,'p_do_stmt_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',515),
-  ('do_stmt_head -> DO ID = expression , expression , expression','do_stmt_head',8,'p_do_stmt_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',516),
-  ('repeat_stmt -> REPEAT suite','repeat_stmt',2,'p_repeat_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',525),
-  ('with_stmt -> with_head maybe_nline suite','with_stmt',3,'p_with_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',529),
-  ('with_head -> WITH ID AS ID','with_head',4,'p_with_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',533),
-  ('funcdef -> FUNCTION ID OPEN_PAREN arglist CLOSE_PAREN suite','funcdef',6,'p_funcdef','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',537),
-  ('arglist -> ID : list_display','arglist',3,'p_arglist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',541),
-  ('arglist -> arglist , ID : list_display','arglist',5,'p_arglist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',542),
-  ('maybe_nline -> newlines','maybe_nline',1,'p_maybe_nline','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',549),
-  ('maybe_nline -> empty','maybe_nline',1,'p_maybe_nline','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',550),
-  ('newlines -> NEWLINE','newlines',1,'p_newlines','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',557),
-  ('newlines -> newlines NEWLINE','newlines',2,'p_newlines','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',558),
-  ('empty -> <empty>','empty',0,'p_empty','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',562),
-]
+
+# parsetab.py
+# This file is automatically generated. Do not edit.
+_tabversion = '3.2'
+
+_lr_method = 'LALR'
+
+_lr_signature = '\xcc\x83\xf4<b8\x10\xb6\xfb\xc5z\x19\xd2\x9e\xc0\xa0'
+    
+_lr_action_items = {'REAL':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,48,48,-153,-152,-61,48,-76,-56,-156,48,-127,-75,-58,-126,48,-124,-78,-23,-129,-65,48,-63,48,-125,-74,-68,-66,-5,48,-50,-32,-79,-156,-30,48,-21,-70,-46,117,-69,-62,48,-59,-1,-77,-55,-131,-67,-27,48,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,48,-139,48,-3,-60,48,48,48,-52,-146,-42,-40,48,48,-39,48,-34,-35,-41,-37,-38,48,-31,-97,-95,48,48,-81,-72,-73,-51,48,48,48,48,48,48,48,48,-156,48,48,-147,-4,48,-82,-132,48,-26,-25,48,-33,-44,-45,-36,-84,-90,-54,-96,48,-80,48,-28,-29,-47,-48,-49,-112,48,-65,48,-8,-148,-140,48,-156,48,48,-100,48,-99,-98,48,48,-113,-156,-22,-9,-156,-156,-137,48,48,-83,-156,48,-89,48,48,48,-136,48,-141,48,-149,48,-144,-133,-134,-138,48,48,-142,-145,48,48,]),'DO':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,64,64,-153,-152,-61,64,-76,-56,-156,64,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,64,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,64,-139,-3,-60,64,-52,-146,-31,-97,-95,-81,-72,-73,-51,64,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,64,-8,-148,-140,64,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,64,-83,-89,64,-136,64,-141,64,-149,-144,-133,-134,-138,-142,-145,]),'*':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,130,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,130,130,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'PRINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,29,29,-153,-152,-61,29,-76,-56,-156,29,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,29,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,29,-139,29,-3,-60,29,-52,-146,-31,-97,-95,-81,-72,-73,-51,29,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,29,-8,-148,-140,29,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,29,-83,-89,29,-136,29,-141,29,-149,-144,-133,-134,-138,-142,-145,]),'^':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,132,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,132,132,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'AUGOP':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,220,230,234,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,137,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-22,-83,-89,]),';':([6,7,10,11,12,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,88,95,99,115,117,118,122,124,125,127,142,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,187,189,190,207,210,211,215,218,220,230,234,],[-6,-61,-15,-76,-56,86,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,-7,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-100,-99,-98,-117,-113,-22,-83,-89,]),'BININT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,51,51,-153,-152,-61,51,-76,-56,-156,51,-127,-75,-58,-126,51,-124,-78,-23,-129,-65,51,-63,51,-125,-74,-68,-66,-5,51,-50,-32,-79,-156,-30,51,-21,-70,-46,-53,-69,-62,51,-59,-1,-77,-55,-131,-67,-27,51,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,51,-139,51,-3,-60,51,51,51,-52,-146,-42,-40,51,51,-39,51,-34,-35,-41,-37,-38,51,-31,-97,-95,51,51,-81,-72,-73,-51,51,51,51,51,51,51,51,51,-156,51,51,-147,-4,51,-82,-132,51,-26,-25,51,-33,-44,-45,-36,-84,-90,-54,-96,51,-80,51,-28,-29,-47,-48,-49,-112,51,51,-8,-148,-140,51,-156,51,51,-100,51,-99,-98,51,51,-113,-156,-22,-9,-156,-156,-137,51,51,-83,-156,51,-89,51,51,51,-136,51,-141,51,-149,51,-144,-133,-134,-138,51,51,-142,-145,51,51,]),'.':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,133,144,159,163,165,173,184,190,207,210,211,214,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,120,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,182,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,241,-113,-83,-89,]),'WITH':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,9,9,-153,-152,-61,9,-76,-56,-156,9,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,9,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,9,-139,-3,-60,9,-52,-146,-31,-97,-95,-81,-72,-73,-51,9,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,9,-8,-148,-140,9,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,9,-83,-89,9,-136,9,-141,9,-149,-144,-133,-134,-138,-142,-145,]),'NEQ':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,111,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,111,]),'POWER':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,144,159,163,165,173,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,119,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,-113,-83,-89,]),'+':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,32,32,-153,-152,-61,32,-76,-56,-156,32,-127,-75,-58,-126,32,-124,-78,-23,-129,-65,32,-63,32,-125,-74,-68,-66,-5,32,-50,105,-79,-156,-30,32,-21,-70,-46,-53,-69,-62,32,-59,-1,-77,-55,-131,-67,-27,32,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,32,-139,32,-3,-60,32,32,32,-52,-146,-42,-40,32,32,-39,32,-34,-35,-41,-37,-38,32,-31,-97,-95,32,32,-81,-72,-73,-51,32,32,32,32,32,32,32,32,-156,32,32,-147,-4,32,-82,-132,32,-26,-25,32,105,-44,-45,-36,-84,-90,-54,-96,32,-80,32,-28,-29,-47,-48,-49,-112,32,-65,32,-8,-148,-140,32,-156,32,32,-100,32,-99,-98,32,32,-113,-156,-22,-9,-156,-156,-137,32,32,-83,-156,32,-89,32,32,32,-136,32,-141,32,-149,32,-144,-133,-134,-138,32,32,-142,-145,32,32,]),'NEWLINE':([0,1,5,6,7,10,11,12,13,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,43,44,46,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,79,81,86,87,88,95,99,115,117,118,122,124,125,127,136,141,142,144,147,148,154,155,156,158,159,160,162,163,164,165,173,175,176,177,178,179,184,187,189,190,193,202,203,207,210,211,215,218,219,220,222,223,230,231,233,234,253,254,255,264,265,278,279,],[1,-154,79,-6,-61,-15,-76,-56,1,1,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,1,-30,1,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-155,1,1,79,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,1,79,-7,-82,-26,-25,-33,-44,-45,1,-84,-88,1,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-148,-85,1,-100,-99,-98,-117,-113,1,-22,1,1,-83,1,-94,-89,-86,-91,1,-87,1,-92,-93,]),'-':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,67,67,-153,-152,-61,67,-76,-56,-156,67,-127,-75,-58,-126,67,-124,-78,-23,-129,-65,67,-63,67,-125,-74,-68,-66,-5,67,-50,107,-79,-156,-30,67,-21,-70,-46,-53,-69,-62,67,-59,-1,-77,-55,-131,-67,-27,67,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,67,-139,67,-3,-60,67,67,67,-52,-146,-42,-40,67,67,-39,67,-34,-35,-41,-37,-38,67,-31,-97,-95,67,67,-81,-72,-73,-51,67,67,67,67,67,67,67,67,-156,67,67,-147,-4,67,-82,-132,67,-26,-25,67,107,-44,-45,-36,-84,-90,-54,-96,67,-80,67,-28,-29,-47,-48,-49,-112,67,-65,67,-8,-148,-140,67,-156,67,67,-100,67,-99,-98,67,67,-113,-156,-22,-9,-156,-156,-137,67,67,-83,-156,67,-89,67,67,67,-136,67,-141,67,-149,67,-144,-133,-134,-138,67,67,-142,-145,67,67,]),',':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,89,96,98,99,115,117,118,122,123,124,125,127,144,147,148,152,154,155,156,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,180,181,183,184,185,187,189,190,196,197,199,202,207,209,210,211,212,213,218,220,230,233,234,235,236,237,238,239,243,248,251,253,254,256,258,264,270,274,278,279,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,136,-60,136,151,-122,-52,-31,-97,-95,-81,136,-72,-73,-51,-82,-26,-25,151,-33,-44,-45,-84,203,-90,-54,-96,206,-101,-103,-102,-111,-108,-110,-80,-28,-29,-47,-48,-49,-114,214,217,-112,-116,136,136,-65,136,-123,227,231,-100,-105,-99,-98,-106,240,-113,-22,-83,255,-89,-111,-109,-110,-107,-104,-115,136,-150,-86,265,267,-118,-87,-151,-119,-92,-93,]),'/':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,131,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,131,131,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'NEXT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,10,10,-153,-152,-61,10,-76,-56,-156,10,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,10,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,10,-139,10,-3,-60,10,-52,-146,-31,-97,-95,-81,-72,-73,-51,10,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,10,-8,-148,-140,10,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,10,-83,-89,10,-136,10,-141,10,-149,-144,-133,-134,-138,-142,-145,]),'SHORTSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,34,34,-153,-152,-61,34,-76,-56,-156,34,-127,-75,-58,-126,34,-124,-78,-23,-129,-65,34,-63,34,-125,-74,-68,-66,-5,34,-50,-32,-79,-156,-30,34,-156,-21,-70,-46,-53,-69,-62,34,-59,-1,-77,124,-55,-131,-67,-27,34,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,34,-139,34,-3,-60,34,34,34,-52,-146,-42,-40,34,34,-39,34,-34,-35,-41,-37,-38,34,-31,34,-97,-95,34,34,-81,-72,-73,-51,34,34,34,34,34,34,34,34,-156,34,34,-147,-4,34,-82,-132,34,-26,-25,34,-33,-44,-45,-36,-84,-90,-54,-96,34,-80,34,-28,-29,-47,-48,-49,-112,34,34,-8,-148,-140,34,-156,34,34,-100,34,-99,-98,34,34,-113,-156,-22,-9,-156,-156,-137,34,34,-83,-156,34,-89,34,34,34,-136,34,-141,34,-149,34,-156,-144,-133,-134,-138,-156,34,34,34,-142,34,-145,34,34,]),'OPEN_PAREN':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,74,75,76,78,79,80,81,82,84,85,86,87,88,90,91,92,93,99,100,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,53,53,-153,-152,-61,53,-76,-56,-156,53,-127,-75,-58,-126,53,-124,-78,-23,-129,-65,53,-63,53,-125,-74,-68,-66,-5,53,-50,-32,-79,-156,-30,53,-21,-70,-46,-53,-69,-62,53,-59,-1,-77,-55,-131,-67,-27,53,-130,-71,-24,-43,-128,133,134,-57,-64,-2,-155,-143,-156,-135,53,-139,53,-3,143,53,146,53,53,-52,153,-146,-42,-40,53,53,-39,53,-34,-35,-41,-37,-38,53,-31,-97,-95,53,53,-81,-72,-73,-51,53,53,53,53,53,53,53,53,-156,53,53,-147,-4,53,-82,-132,53,-26,-25,53,-33,-44,-45,-36,-84,-90,-54,-96,53,-80,53,-28,-29,-47,-48,-49,-112,53,53,-8,-148,-140,53,-156,53,53,-100,53,-99,-98,53,53,-113,-156,-22,-9,-156,-156,-137,53,53,-83,-156,53,-89,53,53,53,-136,53,-141,53,-149,53,-144,-133,-134,-138,53,53,-142,-145,53,53,]),'OCTINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,35,35,-153,-152,-61,35,-76,-56,-156,35,-127,-75,-58,-126,35,-124,-78,-23,-129,-65,35,-63,35,-125,-74,-68,-66,-5,35,-50,-32,-79,-156,-30,35,-21,-70,-46,-53,-69,-62,35,-59,-1,-77,-55,-131,-67,-27,35,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,35,-139,35,-3,-60,35,35,35,-52,-146,-42,-40,35,35,-39,35,-34,-35,-41,-37,-38,35,-31,-97,-95,35,35,-81,-72,-73,-51,35,35,35,35,35,35,35,35,-156,35,35,-147,-4,35,-82,-132,35,-26,-25,35,-33,-44,-45,-36,-84,-90,-54,-96,35,-80,35,-28,-29,-47,-48,-49,-112,35,35,-8,-148,-140,35,-156,35,35,-100,35,-99,-98,35,35,-113,-156,-22,-9,-156,-156,-137,35,35,-83,-156,35,-89,35,35,35,-136,35,-141,35,-149,35,-144,-133,-134,-138,35,35,-142,-145,35,35,]),'STRPREFIX':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,59,59,-153,-152,-61,59,-76,-56,-156,59,-127,-75,-58,-126,59,-124,-78,-23,-129,-65,59,-63,59,-125,-74,-68,-66,-5,59,-50,-32,-79,-156,-30,59,-156,-21,-70,-46,-53,-69,-62,59,-59,-1,-77,-55,-131,-67,-27,59,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,59,-139,59,-3,-60,59,59,59,-52,-146,-42,-40,59,59,-39,59,-34,-35,-41,-37,-38,59,-31,59,-97,-95,59,59,-81,-72,-73,-51,59,59,59,59,59,59,59,59,-156,59,59,-147,-4,59,-82,-132,59,-26,-25,59,-33,-44,-45,-36,-84,-90,-54,-96,59,-80,59,-28,-29,-47,-48,-49,-112,59,59,-8,-148,-140,59,-156,59,59,-100,59,-99,-98,59,59,-113,-156,-22,-9,-156,-156,-137,59,59,-83,-156,59,-89,59,59,59,-136,59,-141,59,-149,59,-156,-144,-133,-134,-138,-156,59,59,59,-142,59,-145,59,59,]),'INTEGER':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,36,36,-153,-152,-61,36,-76,-56,-156,36,-127,-75,-58,-126,36,-124,-78,-23,-129,-65,36,-63,36,-125,-74,-68,-66,-5,36,-50,-32,-79,-156,-30,36,-21,-70,-46,-53,-69,-62,36,-59,-1,-77,-55,-131,-67,-27,36,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,36,-139,36,-3,-60,36,36,36,-52,-146,-42,-40,36,36,-39,36,-34,-35,-41,-37,-38,36,-31,-97,-95,36,36,-81,-72,-73,-51,36,36,36,36,36,36,36,36,-156,36,36,-147,-4,36,-82,-132,36,-26,-25,36,-33,-44,-45,-36,-84,-90,-54,-96,36,-80,36,-28,-29,-47,-48,-49,-112,36,36,-8,-148,-140,36,-156,36,36,-100,36,-99,-98,36,36,-113,-156,-22,-9,-156,-156,-137,36,36,-83,-156,36,-89,36,36,36,-136,36,-141,36,-149,36,-144,-133,-134,-138,36,36,-142,-145,36,36,]),'IMAGINARY':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,69,69,-153,-152,-61,69,-76,-56,-156,69,-127,-75,-58,-126,69,-124,-78,-23,-129,-65,69,-63,69,-125,-74,-68,-66,-5,69,-50,-32,-79,-156,-30,69,-21,-70,-46,-53,-69,-62,69,-59,-1,-77,-55,-131,-67,-27,69,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,69,-139,69,-3,-60,69,69,69,-52,-146,-42,-40,69,69,-39,69,-34,-35,-41,-37,-38,69,-31,-97,-95,69,69,-81,-72,-73,-51,69,69,69,69,69,69,69,69,-156,69,69,-147,-4,69,-82,-132,69,-26,-25,69,-33,-44,-45,-36,-84,-90,-54,-96,69,-80,69,-28,-29,-47,-48,-49,-112,69,69,-8,-148,-140,69,-156,69,69,-100,69,-99,-98,69,69,-113,-156,-22,-9,-156,-156,-137,69,69,-83,-156,69,-89,69,69,69,-136,69,-141,69,-149,69,-144,-133,-134,-138,69,69,-142,-145,69,69,]),':':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,121,122,124,125,127,144,147,148,154,155,156,159,161,163,164,165,167,168,172,173,175,176,177,178,179,184,190,195,200,206,207,209,210,211,212,218,230,234,237,239,249,272,275,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,168,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,204,-90,-54,-96,208,-103,212,-80,-28,-29,-47,-48,-49,-112,204,224,229,168,-100,-105,-99,-98,-106,-113,-83,-89,212,-104,263,276,277,]),'=':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,126,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,216,218,220,230,234,257,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,135,-60,-52,-31,-97,-95,-81,-72,-73,174,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,242,-113,-22,-83,-89,268,]),'<':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,112,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,112,]),'$end':([1,3,4,5,15,19,22,25,33,37,55,61,68,72,78,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,0,-153,-152,-127,-126,-124,-129,-125,-5,-1,-131,-130,-128,-2,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'FUNCTION':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,38,38,-153,-152,-61,38,-76,-56,-156,38,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,38,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,38,-139,-3,-60,38,-52,-146,-31,-97,-95,-81,-72,-73,-51,38,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,38,-8,-148,-140,38,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,38,-83,-89,38,-136,38,-141,38,-149,-144,-133,-134,-138,-142,-145,]),'REPEAT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,39,39,-153,-152,-61,39,-76,-56,-156,39,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,39,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,39,-139,-3,-60,39,-52,-146,-31,-97,-95,-81,-72,-73,-51,39,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,39,-8,-148,-140,39,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,39,-83,-89,39,-136,39,-141,39,-149,-144,-133,-134,-138,-142,-145,]),'GTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,106,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,106,]),'FOR':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,31,31,-153,-152,-61,31,-76,-56,-156,31,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,31,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,31,-139,-3,-60,31,-52,-146,-31,-97,-95,-81,-72,-73,-51,31,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,31,-8,-148,-140,31,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,31,-83,-89,31,-136,31,-141,31,-149,-144,-133,-134,-138,-142,-145,]),'BADAND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,129,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,129,129,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'ELSEIF':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,91,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'LONGSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,17,17,-153,-152,-61,17,-76,-56,-156,17,-127,-75,-58,-126,17,-124,-78,-23,-129,-65,17,-63,17,-125,-74,-68,-66,-5,17,-50,-32,-79,-156,-30,17,-156,-21,-70,-46,-53,-69,-62,17,-59,-1,-77,125,-55,-131,-67,-27,17,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,17,-139,17,-3,-60,17,17,17,-52,-146,-42,-40,17,17,-39,17,-34,-35,-41,-37,-38,17,-31,17,-97,-95,17,17,-81,-72,-73,-51,17,17,17,17,17,17,17,17,-156,17,17,-147,-4,17,-82,-132,17,-26,-25,17,-33,-44,-45,-36,-84,-90,-54,-96,17,-80,17,-28,-29,-47,-48,-49,-112,17,17,-8,-148,-140,17,-156,17,17,-100,17,-99,-98,17,17,-113,-156,-22,-9,-156,-156,-137,17,17,-83,-156,17,-89,17,17,17,-136,17,-141,17,-149,17,-156,-144,-133,-134,-138,-156,17,17,17,-142,17,-145,17,17,]),'NOT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,114,115,117,118,121,122,124,125,127,128,129,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,45,45,-153,-152,-61,45,-76,-56,-156,45,-127,-75,-58,-126,45,-124,-78,-23,-129,-65,45,-63,-125,-74,-68,-66,-5,45,-50,110,-79,-156,-30,45,-21,-70,-46,-53,-69,-62,45,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,45,-139,45,-3,-60,45,45,45,-52,-146,45,-31,-97,-95,45,-81,-72,-73,-51,45,45,45,45,45,-156,45,45,-147,-4,45,-82,-132,45,-26,-25,45,-33,-44,-45,-84,-90,-54,-96,45,-80,45,-28,-29,-47,-48,-49,-112,45,-65,45,-8,-148,-140,45,-156,45,45,-100,45,-99,-98,45,45,-113,-156,-22,-9,-156,-156,-137,45,45,-83,-156,45,-89,45,45,45,-136,45,-141,45,-149,45,-144,-133,-134,-138,45,45,-142,-145,45,45,]),'AS':([83,94,],[139,149,]),'LTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,103,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,103,]),'IN':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,96,98,99,110,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,197,198,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,109,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,150,-122,-52,157,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-123,226,-100,-99,-98,-113,-83,-89,]),'[':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,229,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,263,267,268,269,273,276,277,],[-156,-154,43,43,-153,-152,-61,43,-76,-56,-156,43,-127,-75,-58,-126,43,-124,-78,-23,-129,-65,43,-63,97,43,-125,-74,-68,-66,-5,43,-50,-32,-79,-156,-30,43,-21,-70,-46,121,-69,-62,43,-59,-1,-77,-55,-131,-67,-27,43,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,43,-139,43,-3,-60,43,43,43,-52,-146,-42,-40,43,43,-39,43,-34,-35,-41,-37,-38,43,-31,-97,-95,43,43,-81,-72,-73,-51,43,43,43,43,43,43,43,43,-156,43,43,-147,-4,43,-82,-132,43,-26,-25,43,-33,-44,-45,-36,-84,-90,-54,-96,43,-80,43,-28,-29,-47,-48,-49,-112,43,-65,43,-8,-148,-140,43,-156,43,43,-100,43,-99,-98,43,43,-113,-156,-22,-9,-156,-156,-137,43,43,43,-83,-156,43,-89,43,43,43,-136,43,-141,43,-149,43,-144,-133,-134,-138,43,43,43,-142,-145,43,43,]),'ELSE':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,90,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),']':([1,4,5,7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,43,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,79,88,98,99,114,115,117,118,122,124,125,127,144,147,148,152,154,155,156,158,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,184,197,201,202,207,209,210,211,212,218,230,234,235,236,237,238,239,253,264,],[-154,-153,-152,-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-156,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-155,-60,-122,-52,159,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,198,-33,-44,-45,-156,-84,-88,-90,-54,-96,207,-101,-103,-102,210,-108,211,-80,-28,-29,-47,-48,-49,-112,-123,230,-85,-100,-105,-99,-98,-106,-113,-83,-89,-111,-109,-110,-107,-104,-86,-87,]),'ID':([0,1,2,3,4,5,7,8,9,11,12,13,14,15,17,18,19,21,22,23,24,25,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,64,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,97,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,120,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,143,144,145,146,147,148,149,150,151,153,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,182,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,224,225,226,227,228,230,231,232,234,240,241,242,244,245,246,247,248,250,252,256,259,260,261,262,267,268,269,273,276,277,],[-156,-154,73,73,-153,-152,-61,73,83,-76,-56,-156,73,-127,-75,-58,-126,88,-124,-78,-23,-129,94,-65,88,-63,98,88,-125,-74,-68,-66,-5,100,73,-50,-32,-79,-156,-30,88,-21,-70,-46,-53,-69,-62,88,-59,-1,-77,-55,-131,-67,126,-27,88,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,73,-139,73,-3,-60,73,88,88,98,-52,-146,-42,-40,88,88,-39,88,-34,-35,-41,-37,-38,88,-31,-97,-95,88,165,88,-81,-72,-73,-51,88,88,88,88,88,88,88,88,-156,88,73,193,-147,-4,88,-82,-132,88,-26,-25,195,88,197,200,-33,-44,-45,-36,-84,-90,-54,-96,88,-80,88,-28,-29,-47,-48,-49,216,-112,88,73,-8,-148,-140,73,-156,88,88,-100,88,-99,-98,88,88,-113,-156,-22,-9,-156,-156,247,-137,88,249,73,-83,-156,88,-89,88,257,88,73,-136,73,-141,73,-149,88,-144,-133,-134,269,-138,88,88,-142,-145,88,88,]),'CLOSE_PAREN':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,53,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,122,123,124,125,127,133,143,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,180,181,183,184,185,186,194,199,207,210,211,218,220,230,234,243,251,258,270,274,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,122,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,-81,173,-72,-73,-51,184,184,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-114,215,218,-112,-116,219,223,228,-100,-99,-98,-113,-22,-83,-89,-115,-150,-118,-151,-119,]),'IF':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,74,74,-153,-152,-61,74,-76,-56,-156,74,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,74,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,74,-139,-3,-60,74,-52,-146,-31,-97,-95,-81,-72,-73,-51,74,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,74,-8,-148,-140,74,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,74,-83,-89,74,-136,74,-141,74,-149,-144,-133,-134,-138,-142,-145,]),'AND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,128,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,128,128,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'`':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,89,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,21,21,-153,-152,-61,21,-76,-56,-156,21,-127,-75,-58,-126,21,-124,-78,-23,-129,-65,21,-63,21,-125,-74,-68,-66,-5,21,-50,-32,-79,-156,-30,21,-21,-70,-46,-53,-69,-62,21,-59,-1,-77,-55,-131,-67,-27,21,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,21,-139,21,-3,-60,144,21,21,21,-52,-146,-42,-40,21,21,-39,21,-34,-35,-41,-37,-38,21,-31,-97,-95,21,21,-81,-72,-73,-51,21,21,21,21,21,21,21,21,-156,21,21,-147,-4,21,-82,-132,21,-26,-25,21,-33,-44,-45,-36,-84,-90,-54,-96,21,-80,21,-28,-29,-47,-48,-49,-112,21,21,-8,-148,-140,21,-156,21,21,-100,21,-99,-98,21,21,-113,-156,-22,-9,-156,-156,-137,21,21,-83,-156,21,-89,21,21,21,-136,21,-141,21,-149,21,-144,-133,-134,-138,21,21,-142,-145,21,21,]),'BADOR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,92,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'BREAK':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,62,62,-153,-152,-61,62,-76,-56,-156,62,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,62,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,62,-139,62,-3,-60,62,-52,-146,-31,-97,-95,-81,-72,-73,-51,62,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,62,-8,-148,-140,62,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,62,-83,-89,62,-136,62,-141,62,-149,-144,-133,-134,-138,-142,-145,]),'HEXINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,63,63,-153,-152,-61,63,-76,-56,-156,63,-127,-75,-58,-126,63,-124,-78,-23,-129,-65,63,-63,63,-125,-74,-68,-66,-5,63,-50,-32,-79,-156,-30,63,-21,-70,-46,-53,-69,-62,63,-59,-1,-77,-55,-131,-67,-27,63,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,63,-139,63,-3,-60,63,63,63,-52,-146,-42,-40,63,63,-39,63,-34,-35,-41,-37,-38,63,-31,-97,-95,63,63,-81,-72,-73,-51,63,63,63,63,63,63,63,63,-156,63,63,-147,-4,63,-82,-132,63,-26,-25,63,-33,-44,-45,-36,-84,-90,-54,-96,63,-80,63,-28,-29,-47,-48,-49,-112,63,63,-8,-148,-140,63,-156,63,63,-100,63,-99,-98,63,63,-113,-156,-22,-9,-156,-156,-137,63,63,-83,-156,63,-89,63,63,63,-136,63,-141,63,-149,63,-144,-133,-134,-138,63,63,-142,-145,63,63,]),'ISEQUAL':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,102,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,102,]),'ITEM_TAG':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,76,76,-153,-152,-61,76,-76,-56,-156,76,-127,-75,-58,-126,76,-124,-78,-23,-129,-65,76,-63,76,-125,-74,-68,-66,-5,76,-50,-32,-79,-156,-30,76,-21,-70,-46,-53,-69,-62,76,-59,-1,-77,-55,-131,-67,-27,76,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,76,-139,76,-3,-60,76,76,76,-52,-146,-42,-40,76,76,-39,76,-34,-35,-41,-37,-38,76,-31,-97,-95,76,76,-81,-72,-73,-51,76,76,76,76,76,76,76,76,-156,76,76,-147,-4,76,-82,-132,76,-26,-25,76,-33,-44,-45,-36,-84,-90,-54,-96,76,-80,76,-28,-29,-47,-48,-49,-112,76,76,-8,-148,-140,76,-156,76,76,-100,76,-99,-98,76,76,-113,-156,-22,-9,-156,-156,-137,76,76,-83,-156,76,-89,76,76,76,-136,76,-141,76,-149,76,-144,-133,-134,-138,76,76,-142,-145,76,76,]),'{':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,46,46,-153,-152,-61,81,-76,-56,-156,81,-127,-75,-58,-126,46,-124,-78,-23,-129,-65,46,-63,46,-125,-74,-68,-66,-5,81,-50,-32,-79,-156,-30,46,-21,-70,-46,-53,-69,-62,46,-59,-1,-77,-55,-131,-67,-27,46,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,81,-139,46,-3,-60,81,46,46,-52,-146,-42,-40,46,46,-39,46,-34,-35,-41,-37,-38,46,-31,-97,-95,46,46,-81,-72,-73,-51,46,46,46,46,46,46,46,46,-156,46,46,-147,-4,46,-82,-132,46,-26,-25,46,-33,-44,-45,-36,-84,-90,-54,-96,46,-80,46,-28,-29,-47,-48,-49,-112,46,46,-8,-148,-140,81,-156,46,46,-100,46,-99,-98,46,46,-113,-156,-22,-9,-156,-156,-137,46,81,-83,-156,46,-89,46,46,81,-136,81,-141,81,-149,46,-144,-133,-134,-138,46,46,-142,-145,46,46,]),'>':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,113,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,113,]),'}':([1,4,5,7,11,12,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,40,41,42,44,46,48,49,50,51,52,54,56,60,61,63,65,68,69,70,71,72,75,76,79,80,81,82,85,87,88,99,101,115,116,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,162,163,164,165,173,175,176,177,178,179,184,191,192,205,207,210,211,218,221,222,225,230,233,234,245,250,254,259,260,262,278,279,],[-154,-153,-152,-61,-76,-56,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,-50,-32,-79,-30,-156,-70,-46,-53,-69,-62,-59,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-155,-143,-156,-135,-139,-3,-60,-52,-146,-31,163,-97,-95,-81,-72,-73,-51,163,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-156,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,222,-8,234,-100,-99,-98,-113,-9,-156,-137,-83,-94,-89,-136,-149,-91,-133,-134,-138,-92,-93,]),'OR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,93,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'LOOP':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,26,26,-153,-152,-61,26,-76,-56,-156,26,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,26,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,26,-139,-3,-60,26,-52,-146,-31,-97,-95,-81,-72,-73,-51,26,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,26,-8,-148,-140,26,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,26,-83,-89,26,-136,26,-141,26,-149,-144,-133,-134,-138,-142,-145,]),}
+
+_lr_action = { }
+for _k, _v in _lr_action_items.items():
+   for _x,_y in zip(_v[0],_v[1]):
+      if not _x in _lr_action:  _lr_action[_x] = { }
+      _lr_action[_x][_k] = _y
+del _lr_action_items
+
+_lr_goto_items = {'statements':([138,],[191,]),'comp_operator':([41,],[104,]),'small_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[6,6,6,6,6,6,142,6,6,6,6,6,6,6,6,]),'fancy_drel_assignment_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,]),'primary':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,]),'stringliteral':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,116,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,266,267,268,271,276,277,],[28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,161,28,28,28,28,28,28,28,28,28,28,28,190,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,272,28,28,275,28,28,]),'item_tag':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,]),'not_test':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[65,65,65,65,65,65,65,115,65,65,65,65,65,65,65,65,175,176,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,]),'listmaker':([114,],[158,]),'do_stmt_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[8,8,8,8,8,8,8,8,8,8,8,8,8,8,]),'func_arg':([133,143,217,],[180,180,243,]),'enclosure':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,]),'newlines':([0,13,16,43,46,81,86,136,158,162,203,219,222,223,231,255,265,],[5,5,87,5,5,5,141,5,5,5,5,5,5,5,5,5,5,]),'break_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,]),'dotlist':([133,],[181,]),'arglist':([153,],[199,]),'long_slice':([121,206,],[169,169,]),'repeat_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[68,68,68,68,68,68,68,68,68,68,68,68,68,68,]),'u_expr':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[49,49,49,49,49,49,99,49,49,49,127,49,49,49,49,49,49,49,49,49,164,49,49,49,177,178,179,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,]),'if_else_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,]),'parenth_form':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,]),'literal':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,]),'attributeref':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,]),'call':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,]),'argument_list':([133,143,],[183,183,]),'statement':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[55,78,82,82,82,82,82,192,221,82,82,82,82,82,]),'string_conversion':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,]),'with_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[13,13,13,13,13,13,13,13,13,13,13,13,13,13,]),'input':([0,],[3,]),'loop_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[14,14,14,14,14,14,14,14,14,14,14,14,14,14,]),'do_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[15,15,15,15,15,15,15,15,15,15,15,15,15,15,]),'next_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,]),'empty':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,]),'listmaker2':([160,],[202,]),'short_slice':([121,206,],[167,167,]),'power':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,]),'a_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[41,41,41,41,41,41,41,41,41,41,41,41,41,41,154,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,]),'print_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,]),'maybe_nline':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[2,84,114,116,138,188,201,205,232,244,245,246,252,266,271,]),'tablemaker2':([233,],[254,]),'slicing':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,]),'for_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[19,19,19,19,19,19,19,19,19,19,19,19,19,19,]),'m_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,105,107,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,155,156,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,]),'and_test':([2,3,8,14,21,29,39,53,84,86,90,92,93,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[70,70,70,70,70,70,70,70,70,70,70,147,148,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,]),'restricted_comp_operator':([41,247,],[108,261,]),'atom':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,]),'funcdef':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[61,61,61,61,61,61,61,61,61,61,61,61,61,61,]),'expr_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,]),'slice_list':([121,],[166,]),'subscription':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,]),'comparison':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,]),'attribute_tag':([50,],[118,]),'if_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[22,22,22,22,22,22,22,22,22,22,22,22,22,22,]),'id_list':([31,97,],[96,152,]),'proper_slice':([121,206,],[170,235,]),'list_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,229,232,240,242,244,246,248,252,263,267,268,276,277,],[23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,251,23,23,23,23,23,23,23,270,23,23,23,23,]),'loop_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[72,72,72,72,72,72,72,72,72,72,72,72,72,72,]),'or_test':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,]),'compound_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[37,37,37,37,37,37,37,37,37,37,37,37,37,37,]),'with_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[25,25,25,25,25,25,25,25,25,25,25,25,25,25,]),'tablemaker':([116,138,],[162,162,]),'table_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,]),'suite':([8,14,39,84,90,196,228,244,246,248,],[80,85,101,140,145,225,250,259,260,262,]),'simple_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[16,16,16,16,16,16,16,16,16,16,16,16,16,16,]),'testlist_star_expr':([2,3,8,14,21,39,53,84,86,90,135,137,138,150,191,196,226,228,244,246,248,],[77,77,77,77,89,77,123,77,77,77,187,189,77,196,77,77,248,77,77,77,77,]),'slice_item':([121,206,],[171,236,]),'expression':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[47,47,47,47,47,95,47,47,47,47,47,160,172,185,186,47,47,47,185,194,47,209,213,220,47,47,233,237,238,239,185,47,47,253,256,258,47,47,47,264,273,274,278,279,]),}
+
+_lr_goto = { }
+for _k, _v in _lr_goto_items.items():
+   for _x,_y in zip(_v[0],_v[1]):
+       if not _x in _lr_goto: _lr_goto[_x] = { }
+       _lr_goto[_x][_k] = _y
+del _lr_goto_items
+_lr_productions = [
+  ("S' -> input","S'",1,None,None,None),
+  ('input -> maybe_nline statement','input',2,'p_input','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',19),
+  ('input -> input statement','input',2,'p_input','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',20),
+  ('statement -> simple_stmt newlines','statement',2,'p_statement','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',36),
+  ('statement -> simple_stmt ; newlines','statement',3,'p_statement','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',37),
+  ('statement -> compound_stmt','statement',1,'p_statement','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',38),
+  ('simple_stmt -> small_stmt','simple_stmt',1,'p_simple_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',44),
+  ('simple_stmt -> simple_stmt ; small_stmt','simple_stmt',3,'p_simple_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',45),
+  ('statements -> statement','statements',1,'p_statements','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',55),
+  ('statements -> statements statement','statements',2,'p_statements','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',56),
+  ('small_stmt -> expr_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',61),
+  ('small_stmt -> print_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',62),
+  ('small_stmt -> break_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',63),
+  ('small_stmt -> next_stmt','small_stmt',1,'p_small_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',64),
+  ('break_stmt -> BREAK','break_stmt',1,'p_break_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',68),
+  ('next_stmt -> NEXT','next_stmt',1,'p_next_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',72),
+  ('print_stmt -> PRINT expression','print_stmt',2,'p_print_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',76),
+  ('expr_stmt -> testlist_star_expr','expr_stmt',1,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',84),
+  ('expr_stmt -> testlist_star_expr AUGOP testlist_star_expr','expr_stmt',3,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',85),
+  ('expr_stmt -> testlist_star_expr = testlist_star_expr','expr_stmt',3,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',86),
+  ('expr_stmt -> fancy_drel_assignment_stmt','expr_stmt',1,'p_expr_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',87),
+  ('testlist_star_expr -> expression','testlist_star_expr',1,'p_testlist_star_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',96),
+  ('testlist_star_expr -> testlist_star_expr , maybe_nline expression','testlist_star_expr',4,'p_testlist_star_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',97),
+  ('expression -> or_test','expression',1,'p_expression','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',107),
+  ('or_test -> and_test','or_test',1,'p_or_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',115),
+  ('or_test -> or_test OR and_test','or_test',3,'p_or_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',116),
+  ('or_test -> or_test BADOR and_test','or_test',3,'p_or_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',117),
+  ('and_test -> not_test','and_test',1,'p_and_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',122),
+  ('and_test -> and_test AND not_test','and_test',3,'p_and_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',123),
+  ('and_test -> and_test BADAND not_test','and_test',3,'p_and_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',124),
+  ('not_test -> comparison','not_test',1,'p_not_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',129),
+  ('not_test -> NOT not_test','not_test',2,'p_not_test','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',130),
+  ('comparison -> a_expr','comparison',1,'p_comparison','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',135),
+  ('comparison -> a_expr comp_operator a_expr','comparison',3,'p_comparison','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',136),
+  ('comp_operator -> restricted_comp_operator','comp_operator',1,'p_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',142),
+  ('comp_operator -> IN','comp_operator',1,'p_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',143),
+  ('comp_operator -> NOT IN','comp_operator',2,'p_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',144),
+  ('restricted_comp_operator -> <','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',150),
+  ('restricted_comp_operator -> >','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',151),
+  ('restricted_comp_operator -> GTE','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',152),
+  ('restricted_comp_operator -> LTE','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',153),
+  ('restricted_comp_operator -> NEQ','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',154),
+  ('restricted_comp_operator -> ISEQUAL','restricted_comp_operator',1,'p_restricted_comp_operator','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',155),
+  ('a_expr -> m_expr','a_expr',1,'p_a_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',159),
+  ('a_expr -> a_expr + m_expr','a_expr',3,'p_a_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',160),
+  ('a_expr -> a_expr - m_expr','a_expr',3,'p_a_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',161),
+  ('m_expr -> u_expr','m_expr',1,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',168),
+  ('m_expr -> m_expr * u_expr','m_expr',3,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',169),
+  ('m_expr -> m_expr / u_expr','m_expr',3,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',170),
+  ('m_expr -> m_expr ^ u_expr','m_expr',3,'p_m_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',171),
+  ('u_expr -> power','u_expr',1,'p_u_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',178),
+  ('u_expr -> - u_expr','u_expr',2,'p_u_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',179),
+  ('u_expr -> + u_expr','u_expr',2,'p_u_expr','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',180),
+  ('power -> primary','power',1,'p_power','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',187),
+  ('power -> primary POWER u_expr','power',3,'p_power','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',188),
+  ('primary -> atom','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',196),
+  ('primary -> attributeref','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',197),
+  ('primary -> subscription','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',198),
+  ('primary -> slicing','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',199),
+  ('primary -> call','primary',1,'p_primary','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',200),
+  ('atom -> ID','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',205),
+  ('atom -> item_tag','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',206),
+  ('atom -> literal','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',207),
+  ('atom -> enclosure','atom',1,'p_atom','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',208),
+  ('item_tag -> ITEM_TAG','item_tag',1,'p_item_tag','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',213),
+  ('literal -> stringliteral','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',217),
+  ('literal -> INTEGER','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',218),
+  ('literal -> HEXINT','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',219),
+  ('literal -> OCTINT','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',220),
+  ('literal -> BININT','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',221),
+  ('literal -> REAL','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',222),
+  ('literal -> IMAGINARY','literal',1,'p_literal','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',223),
+  ('stringliteral -> STRPREFIX SHORTSTRING','stringliteral',2,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',228),
+  ('stringliteral -> STRPREFIX LONGSTRING','stringliteral',2,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',229),
+  ('stringliteral -> SHORTSTRING','stringliteral',1,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',230),
+  ('stringliteral -> LONGSTRING','stringliteral',1,'p_stringliteral','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',231),
+  ('enclosure -> parenth_form','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',236),
+  ('enclosure -> string_conversion','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',237),
+  ('enclosure -> list_display','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',238),
+  ('enclosure -> table_display','enclosure',1,'p_enclosure','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',239),
+  ('parenth_form -> OPEN_PAREN testlist_star_expr CLOSE_PAREN','parenth_form',3,'p_parenth_form','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',243),
+  ('parenth_form -> OPEN_PAREN CLOSE_PAREN','parenth_form',2,'p_parenth_form','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',244),
+  ('string_conversion -> ` testlist_star_expr `','string_conversion',3,'p_string_conversion','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',251),
+  ('list_display -> [ maybe_nline listmaker maybe_nline ]','list_display',5,'p_list_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',256),
+  ('list_display -> [ maybe_nline ]','list_display',3,'p_list_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',257),
+  ('listmaker -> expression listmaker2','listmaker',2,'p_listmaker','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',265),
+  ('listmaker2 -> , maybe_nline expression','listmaker2',3,'p_listmaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',270),
+  ('listmaker2 -> listmaker2 , maybe_nline expression','listmaker2',4,'p_listmaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',271),
+  ('listmaker2 -> <empty>','listmaker2',0,'p_listmaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',272),
+  ('table_display -> { maybe_nline tablemaker maybe_nline }','table_display',5,'p_table_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',282),
+  ('table_display -> { maybe_nline }','table_display',3,'p_table_display','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',283),
+  ('tablemaker -> stringliteral : expression tablemaker2','tablemaker',4,'p_tablemaker','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',290),
+  ('tablemaker2 -> , maybe_nline stringliteral : expression','tablemaker2',5,'p_tablemaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',294),
+  ('tablemaker2 -> tablemaker2 , maybe_nline stringliteral : expression','tablemaker2',6,'p_tablemaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',295),
+  ('tablemaker2 -> <empty>','tablemaker2',0,'p_tablemaker2','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',296),
+  ('attributeref -> primary attribute_tag','attributeref',2,'p_attributeref','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',310),
+  ('attribute_tag -> . ID','attribute_tag',2,'p_attribute_tag','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',314),
+  ('attribute_tag -> REAL','attribute_tag',1,'p_attribute_tag','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',315),
+  ('subscription -> primary [ expression ]','subscription',4,'p_subscription','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',322),
+  ('slicing -> primary [ proper_slice ]','slicing',4,'p_slicing','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',326),
+  ('slicing -> primary [ slice_list ]','slicing',4,'p_slicing','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',327),
+  ('proper_slice -> short_slice','proper_slice',1,'p_proper_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',331),
+  ('proper_slice -> long_slice','proper_slice',1,'p_proper_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',332),
+  ('short_slice -> :','short_slice',1,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',343),
+  ('short_slice -> expression : expression','short_slice',3,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',344),
+  ('short_slice -> : expression','short_slice',2,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',345),
+  ('short_slice -> expression :','short_slice',2,'p_short_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',346),
+  ('long_slice -> short_slice : expression','long_slice',3,'p_long_slice','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',355),
+  ('slice_list -> slice_item','slice_list',1,'p_slice_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',362),
+  ('slice_list -> slice_list , slice_item','slice_list',3,'p_slice_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',363),
+  ('slice_item -> expression','slice_item',1,'p_slice_item','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',370),
+  ('slice_item -> proper_slice','slice_item',1,'p_slice_item','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',371),
+  ('call -> ID OPEN_PAREN CLOSE_PAREN','call',3,'p_call','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',375),
+  ('call -> ID OPEN_PAREN argument_list CLOSE_PAREN','call',4,'p_call','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',376),
+  ('argument_list -> func_arg','argument_list',1,'p_argument_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',386),
+  ('argument_list -> argument_list , func_arg','argument_list',3,'p_argument_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',387),
+  ('func_arg -> expression','func_arg',1,'p_func_arg','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',394),
+  ('fancy_drel_assignment_stmt -> ID OPEN_PAREN dotlist CLOSE_PAREN','fancy_drel_assignment_stmt',4,'p_fancy_drel_assignment_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',398),
+  ('dotlist -> . ID = expression','dotlist',4,'p_dotlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',405),
+  ('dotlist -> dotlist , . ID = expression','dotlist',6,'p_dotlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',406),
+  ('exprlist -> a_expr','exprlist',1,'p_exprlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',413),
+  ('exprlist -> exprlist , a_expr','exprlist',3,'p_exprlist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',414),
+  ('id_list -> ID','id_list',1,'p_id_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',421),
+  ('id_list -> id_list , ID','id_list',3,'p_id_list','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',422),
+  ('compound_stmt -> if_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',433),
+  ('compound_stmt -> if_else_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',434),
+  ('compound_stmt -> for_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',435),
+  ('compound_stmt -> do_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',436),
+  ('compound_stmt -> loop_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',437),
+  ('compound_stmt -> with_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',438),
+  ('compound_stmt -> repeat_stmt','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',439),
+  ('compound_stmt -> funcdef','compound_stmt',1,'p_compound_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',440),
+  ('if_else_stmt -> if_stmt ELSE suite','if_else_stmt',3,'p_if_else_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',447),
+  ('if_stmt -> IF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',6,'p_if_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',453),
+  ('if_stmt -> if_stmt ELSEIF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',7,'p_if_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',454),
+  ('suite -> statement','suite',1,'p_suite','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',473),
+  ('suite -> { maybe_nline statements } maybe_nline','suite',5,'p_suite','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',474),
+  ('for_stmt -> FOR id_list IN testlist_star_expr suite','for_stmt',5,'p_for_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',481),
+  ('for_stmt -> FOR [ id_list ] IN testlist_star_expr suite','for_stmt',7,'p_for_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',482),
+  ('loop_stmt -> loop_head suite','loop_stmt',2,'p_loop_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',489),
+  ('loop_head -> LOOP ID AS ID','loop_head',4,'p_loop_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',495),
+  ('loop_head -> LOOP ID AS ID : ID','loop_head',6,'p_loop_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',496),
+  ('loop_head -> LOOP ID AS ID : ID restricted_comp_operator ID','loop_head',8,'p_loop_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',497),
+  ('do_stmt -> do_stmt_head suite','do_stmt',2,'p_do_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',508),
+  ('do_stmt_head -> DO ID = expression , expression','do_stmt_head',6,'p_do_stmt_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',515),
+  ('do_stmt_head -> DO ID = expression , expression , expression','do_stmt_head',8,'p_do_stmt_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',516),
+  ('repeat_stmt -> REPEAT suite','repeat_stmt',2,'p_repeat_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',525),
+  ('with_stmt -> with_head maybe_nline suite','with_stmt',3,'p_with_stmt','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',529),
+  ('with_head -> WITH ID AS ID','with_head',4,'p_with_head','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',533),
+  ('funcdef -> FUNCTION ID OPEN_PAREN arglist CLOSE_PAREN suite','funcdef',6,'p_funcdef','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',537),
+  ('arglist -> ID : list_display','arglist',3,'p_arglist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',541),
+  ('arglist -> arglist , ID : list_display','arglist',5,'p_arglist','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',542),
+  ('maybe_nline -> newlines','maybe_nline',1,'p_maybe_nline','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',549),
+  ('maybe_nline -> empty','maybe_nline',1,'p_maybe_nline','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',550),
+  ('newlines -> NEWLINE','newlines',1,'p_newlines','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',557),
+  ('newlines -> newlines NEWLINE','newlines',2,'p_newlines','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',558),
+  ('empty -> <empty>','empty',0,'p_empty','build/bdist.linux-x86_64/egg/CifFile/drel/drel_ast_yacc.py',562),
+]
```

### Comparing `pyemaps-1.0.8/CifFile/src/drel/py_from_ast.py` & `pyemaps-1.0.9/CifFile/src/drel/py_from_ast.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,628 +1,628 @@
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-# The unicode type does not exist in Python3 as the str type
-# encompasses unicode.  PyCIFRW tests for 'unicode' would fail
-# Suggestions for a better approach welcome.
-
-if isinstance(u"abc",str):   #Python3
-    unicode = str
-
-import re
-from CifFile import CifError
-pycifrw_func_table = {   #how to use PyCIFRW CifFile objects
-         "data_access": "ciffile[%s]",   # argument is dataname to be accessed
-         "optional_data_access":"emapsCifFile.get(%s,None)",
-         "element_no": "%s[%s]", # accessing a particular element of the result of data_access
-         "count_data": "len(%s)", # number of elements for result of data_access
-         "cat_names":"emapsCifFile.dictionary.names_in_cat(%s)", #names in category %s
-         "has_name":"emapsCifFile.has_key_or_alias(%s)",
-         "semantic_packet":"emapsCifFile.GetKeyedSemanticPacket(%s,%s)" #get a packet for key, value
-                     }
-
-def make_python_function(in_ast,func_name,targetname, special_ids=[{}],
-                         func_table = pycifrw_func_table, cif_dic=None,cat_meth=False, 
-                         func_def = False, have_sn=True,loopable={},debug=None,depends=False):
-    """Convert in_ast to python code"""
-    if debug is not None:
-        print("incoming AST:")
-        print(repr(in_ast))
-    func_text,withtable,dependencies,cur_row = start_traverse(in_ast,func_table,target_id=targetname,cat_meth=cat_meth,loopable=loopable,debug=debug,func=func_def,cif_dic=cif_dic)
-    if debug is not None:
-        print('Start========')
-        print(func_text)
-        print('End==========')
-    if func_def and not depends:
-        return func_text
-    elif func_def:
-        return func_text, None
-    # now indent the string
-    noindent = func_text.splitlines()
-    # get the minimum indent and remove empty lines
-    no_spaces = [re.match(r' *',a).end() for a in noindent if a] #drop empty lines
-    min_spaces = min(no_spaces)+4   # because we add 4 ourselves to everything
-    if len(withtable) > 0 or cur_row:  # a loop method
-            d_vars = [a[1][0] for a in withtable.items()]
-            if cur_row:
-                d_vars = d_vars + ['__current_row']
-            dummy_vars = ",".join(d_vars)
-            actual_names = [k for k in withtable.keys()]
-            actual_names = [func_table["data_access"]% ("'"+a+"'") for a in actual_names]
-            # intercept optional values and replace with [] if None
-            optional_names = ["__option_w%d"%n for n,k in enumerate(withtable.keys()) if withtable[k][2]]
-            if cur_row:
-                actual_names+=['__row_id']
-            final_names = actual_names[:]
-            one_pack_names = [func_table["element_no"] % (a,"packet_no") for a in actual_names]
-            for n,k in enumerate(withtable.keys()):
-                if withtable[k][2]:
-                    final_names[n]="__option_w%d"%n  #pre-evaluated
-                    one_pack_names[n] = "__option_w%d"%n
-            map_names = ",".join(final_names)
-            one_packet_each = ",".join(one_pack_names)
-            preamble = "def %s(ciffile,packet_no=-1):\n" % (func_name)
-            preamble +="    try:\n"
-            preamble +="        from itertools import repeat,imap\n"   #note that imap might fail
-            preamble +="    except ImportError: #python3\n"
-            preamble +="        imap = map\n"
-            preamble +="    def drel_func(%s):\n" % dummy_vars
-            # for debugging
-            print_instruction = "'Function passed variables "+("{!r} "*len(d_vars))+"'.format("+dummy_vars+",)"
-            preamble +="        print(%s)\n" % print_instruction
-            # preamble +="        print('Globals inside looped drel_func:' + repr(globals())\n")
-            # the actual function gets inserted here
-            # Handle the optional names
-            end_body = "\n"
-            for n,one_opt in enumerate(withtable.keys()):
-                if withtable[one_opt][2]:
-                    end_body += "    try:\n"
-                    end_body += "            %s%d = %s\n" % ("__option_w",n,func_table["optional_data_access"]%("'"+one_opt+"'"))
-                    end_body += "    except KeyError:\n"
-                    end_body += "            %s%d = None\n" % ("__option_w",n)
-            end_body+=      "    if packet_no < 0:   #map\n"
-            for one_opt in optional_names:
-                end_body += "        if %s is None: %s = repeat(None)\n" % (one_opt,one_opt)
-
-            if cur_row and len(actual_names) > 1:    #i.e. have real names from category
-                end_body +="        __row_id = range(%s)\n" % (func_table['count_data'] % ("'"+actual_names[0]+"'"))
-            elif cur_row and len(actual_names)==1:   #so no actual names available
-
-                end_body += "        cat_names = %s\n" % (func_table["cat_names"] % ("'"+getcatname(targetname)[0]+"'"))
-                end_body += "        have_name = [a for a in cat_names if %s]\n" % (func_table["has_name"] % "a")
-                end_body += "        if len(have_name)>0:\n"
-                end_body += "           full_length = %s \n" % (func_table["count_data"] % (func_table["data_access"] % "have_name[0]"))
-                end_body += "           __row_id = range(full_length)\n"
-                end_body += "        else:\n"
-                end_body += "           return []\n"
-
-            end_body+=      "        return list(imap(drel_func,%s))\n" % (map_names+",")
-            end_body+=     "    else:\n"
-            end_body+=     "        return drel_func(%s)\n" % one_packet_each
-
-    else:
-            preamble = "def %s(ciffile):\n" % func_name
-            #preamble +="        global StarList#from emapsCifFile.drel import drel_runtime\n"
-            end_body = ""
-
-    if cat_meth:
-        preamble += " "*8 + "__dreltarget = {}\n" # initialise
-    num_header = """
-        import math,cmath
-        try:
-            import numpy
-        except:
-            print("Can't import numerical python, this method may not work")
-"""
-    preamble += num_header
-    indented = map(lambda a:" "*8 + a +"\n",noindent)  #indent dREL body
-    postamble = ""
-    postamble += " "*8 + "return __dreltarget"
-    final = preamble + "".join(indented) + postamble + end_body
-    if not depends:
-        return final
-    else: return final, dependencies
-
-def start_traverse(in_node,api_table,target_id=None,loopable={},cat_meth=False,debug=None, func=False,
-                  cif_dic=None):
-  special_info = {"special_id":[{}],"target_id":target_id,"withtable":{},"sub_subject":"",
-                  "depends":set(),"loopable_cats":loopable,"packet_vars":{},
-                  "need_current_row":False,"rhs":None,"inif":False}
-  # create a virtual enclosing 'with' statement
-  if target_id is not None and not cat_meth and not func:
-      cat,name = getcatname(target_id)
-      special_info["special_id"][-1].update({"_"+cat:[cat,"",False]})
-      if cat in special_info["loopable_cats"].keys():    #
-          special_info["special_id"][-1]["_"+cat][1] = "looped_cat"
-  mathop_table = {"+":None, "-":None, "<":"<", "*":None, "/":None,
-                  "&":"&", "|":"|",
-                  ">":">", "<=":"<=", ">=":">=", "!=":"!=",
-                  "or":" or ", "and":" and ",
-                  "==":"==", "in":" in ", "not in":" not in ",
-                  "^":None,"**":"**"}
-
-  aug_assign_table = {"++=":"drel_runtime.aug_append",
-                      "+=":"drel_runtime.aug_add",
-                      "-=":"drel_runtime.aug_sub",
-                      "--=":"drel_runtime.aug_remove"}
-
-  def traverse_ast(in_node,debug=debug):
-    if isinstance(in_node,(unicode,str)):
-        return in_node
-    if isinstance(in_node[0],list):
-        raise SyntaxError('First element of AST Node must be string: ' + repr(in_node))
-    node_type = in_node[0]
-    if debug == node_type:
-        print(node_type + ": " + repr(in_node))
-    if node_type == "ARGLIST":
-        pass
-    elif node_type == "BINARY":
-        return("%d" % int(in_node[1],base=2))
-    elif node_type == "FALSE":
-        return("False")
-    elif node_type == "REAL":
-        return(in_node[1])
-    elif node_type == "HEX":
-        return("%d" % int(in_node[1],base=16))
-    elif node_type == "INT":
-        return(in_node[1])
-    elif node_type == "IMAGINARY":
-        return(in_node[1])
-    elif node_type == "OCTAL":
-        return("%d" % int(in_node[1],base=8))
-
-    elif node_type == "ATOM":
-        if isinstance(in_node[1],(unicode,str)):
-            # pick up built-in literals
-            if in_node[1].lower() == 'twopi':
-                return "(2.0 * math.pi)"
-            if in_node[1].lower() == 'pi':
-                return "math.pi"
-            else:
-                return in_node[1]
-        else:
-            return traverse_ast(in_node[1])
-    elif node_type == "ITEM_TAG":
-        return in_node[1]
-    elif node_type == "LITERAL":
-        return in_node[1]
-    elif node_type == "LIST":
-        if len(in_node)==1:  #empty list
-           return "StarList([])"
-        if special_info["rhs"] == True:
-            outstring = "StarList(["
-        else:
-            outstring = ""
-        for list_elem in in_node[1:]:
-            outstring = outstring + traverse_ast(list_elem) + ","
-        if special_info["rhs"] == True:
-            return outstring[:-1] + "])"
-        else:
-            return outstring[:-1]
-    elif node_type == "TABLE":
-        if len(in_node)==1:
-            return "StarTable({})"
-        else:
-            outstring = "{"
-        for table_elem in in_node[1:]:
-            outstring = outstring + traverse_ast(table_elem[0])+":"+traverse_ast(table_elem[1]) +","
-        return outstring[:-1] + "}"
-    elif node_type == "SUBSCRIPTION":  # variable, single expression
-        newid = 0
-        if in_node[1][0] == "ATOM" and in_node[1][1][0] == "ITEM_TAG":  #keyed lookup
-            print("Found category used as item tag: subscribing")
-            newid = [in_node[1][1][1][1:],False,False]  #drop underscore and remember
-        else:
-            primary = traverse_ast(in_node[1])
-            # check to see if this is a special variable
-            for idtable in special_info["special_id"]:
-                newid = idtable.get(primary,0)
-                if newid: break
-                if primary in special_info["loopable_cats"].keys():   #loop category used
-                    newid = [primary,False,False]
-                    break
-        if newid:
-            #FIXME: the dataname may not be the <cat>.<obj> construction (eg pdCIF)
-            key_items = ["_"+newid[0]+"."+s for s in special_info["loopable_cats"][newid[0]][0]]  #key name
-            special_info["depends"].update([k.lower() for k in key_items])
-            get_loop = api_table["semantic_packet"] % (traverse_ast(in_node[2]),"'"+newid[0]+"'")
-            special_info["sub_subject"] = newid[0]  #in case of attribute reference following
-            print("Set sub_subject to %s" % special_info["sub_subject"])
-            return get_loop
-        else:
-            outstring = primary + "["
-            outstring = outstring + traverse_ast(in_node[2]) + "]"
-            return outstring
-
-    elif node_type == "ATTRIBUTE":  # id/tag , att
-        outstring = ""
-        newid = 0
-        # check for special ids
-        primary = traverse_ast(in_node[1])  # this will set sub_subject if necessary
-        for idtable in special_info["special_id"]:
-            newid = idtable.get(primary,0)
-            if newid: break
-        if newid:
-            #catch our output name
-            true_name = cif_dic.get_name_by_cat_obj(newid[0].lower(),in_node[2].lower()).lower()
-            if true_name == special_info.get("target_id","").lower():
-                    outstring = "__dreltarget"
-                    special_info["have_drel_target"] = True
-            # if we are looping, we add a loop prefix. If we are withing an
-            # unlooped category, we put the full name back.
-            elif newid[2] or (not newid[2] and not newid[1]):   # looping or simple with
-                outstring = api_table["data_access"] % ('"' +true_name +'"')
-                special_info["depends"].add(true_name)
-                if newid[1]:  # a loop statement requires an index
-                    outstring += "[" + newid[1]+ "]"
-            else:   # a with statement; capture the name and create a dummy variable
-                if true_name not in special_info["withtable"]:  #new
-                    position = len(special_info["withtable"])
-                    new_var = "__w%d" % position
-                    isoptional = special_info["inif"]
-                    special_info["withtable"][true_name] = (new_var,position,isoptional)
-                outstring += special_info["withtable"][true_name][0]
-                special_info["depends"].add(true_name)
-        elif in_node[1][0] == "ATOM" and primary[0] == "_":   # a cat/obj name
-            fullname = cif_dic.get_name_by_cat_obj(primary,in_node[2]).lower()
-            # a simple cat.obj dataname from the dictionary
-            if special_info.get("target_id","").lower() == fullname:
-                outstring = "__dreltarget"
-                special_info["have_drel_target"] = True
-            else:
-                special_info["depends"].add(fullname)
-                outstring = api_table["data_access"] % ("'" + fullname + "'")
-        else: # default to Python attribute access
-            # check for packet variables
-            if primary in special_info["packet_vars"]:
-                real_cat = special_info["packet_vars"][primary]
-                fullname = cif_dic.get_name_by_cat_obj(real_cat,in_node[2])
-                special_info['depends'].add(fullname)
-            elif special_info["sub_subject"]:
-                fullname = cif_dic.get_name_by_cat_obj(special_info["sub_subject"],in_node[2])
-                special_info['depends'].add(fullname)
-            else:  # not anything special
-                fullname = in_node[2]
-            outstring = "getattr(" + primary + ",'" + fullname + "')"
-            # sub_subject no longer relevant after attribute resolution
-            special_info['sub_subject'] = ""
-        return outstring
-
-    elif node_type == "FUNC_CALL":
-        if in_node[1] == "Current_Row":  #not a function but a keyword really
-            outstring = "__current_row"
-            special_info["need_current_row"]=True
-        else:
-            func_name,every_arg_prefix,postfix = get_function_name(in_node[1])
-            outstring = func_name + "( "
-            if func_name == "list" and len(in_node[2])>1:   #special case
-                outstring = outstring + "["
-            for argument in in_node[2]:
-                outstring = outstring + every_arg_prefix + traverse_ast(argument) + ","
-            if postfix == None:  # signal for dictionary defined
-                outstring = outstring + "ciffile)"
-            else:
-                outstring = outstring[:-1]
-                if func_name == "list" and len(in_node[2])>1:
-                    outstring = outstring + "]"
-                outstring = outstring + ")" + postfix
-        return outstring
-
-    elif node_type == "SLICE":  # primary [[start,finish,step],[...]
-        outstring = traverse_ast(in_node[1]) + "["
-        slice_list = in_node[2]
-        for one_slice in slice_list:
-            if one_slice[0] == "EXPR":   #not a slice as such
-                outstring += traverse_ast(one_slice)
-            elif len(one_slice) == 0:
-                outstring += ":"
-            elif len(one_slice) >0:    # at least start
-                outstring += traverse_ast(one_slice[0]) + ":"
-                if len(one_slice) >1:    #start,finish only
-                    outstring += traverse_ast(one_slice[1])
-                if len(one_slice) == 3:    #step as well
-                    outstring += ":" + traverse_ast(one_slice[2])
-            outstring += ","
-        outstring = outstring[:-1] + "]"
-        return outstring
-
-    elif node_type == "MATHOP":
-        op = mathop_table[in_node[1]]
-        first_arg = traverse_ast(in_node[2])
-        second_arg = traverse_ast(in_node[3])
-        if op is not None:    #simple operation
-            outstring = first_arg + op + second_arg
-        else:
-            outstring = fix_mathops(in_node[1],first_arg,second_arg)
-        return outstring
-    elif node_type == "SIGN":
-        outstring = "drel_runtime.drel_dot(" + in_node[1] + "1," + traverse_ast(in_node[2])+")"
-        return outstring
-    elif node_type == "UNARY":
-        outstring = in_node[1] + " " + traverse_ast(in_node[2])
-        return outstring
-
-    elif node_type == "IF_EXPR":   #IF_EXPR test true_suite [ELSE IF_EXPR] false_suite
-        outstring = "if "
-        outstring = outstring + traverse_ast(in_node[1])
-        outstring = outstring + ":"
-        old_inif = special_info["inif"]
-        special_info["inif"] = True
-        true_bit = traverse_ast(in_node[2])
-        outstring = outstring + add_indent("\n"+true_bit)  #indent
-        elseif = in_node[3]
-        if len(elseif)!=0:
-            for one_cond in elseif:  #each entry is condition, suite
-                outstring += "\nelif " + traverse_ast(one_cond[0]) + ":"
-                outstring += add_indent("\n" + traverse_ast(one_cond[1]))
-        if len(in_node)>4:
-            outstring = outstring + "\nelse:"
-            false_bit = traverse_ast(in_node[4])
-            outstring = outstring + add_indent("\n"+false_bit)  #indent
-        special_info["inif"] = old_inif
-        return outstring
-
-# dREL for statements include the final value, whereas a python range will include
-# everything up to the final number
-    elif node_type == "DO":    #DO ID = start, finish, incr, suite
-        outstring = "for " + in_node[1] + " in range(" + traverse_ast(in_node[2]) + ","
-        finish = traverse_ast(in_node[3])
-        increment = traverse_ast(in_node[4])
-        outstring = outstring + finish + "+1" + "," + increment
-        outstring = outstring + "):"
-        suite = add_indent("\n"+traverse_ast(in_node[5]))
-        return outstring + suite
-    elif node_type == "FOR": # FOR target_list expression_list suite
-        outstring = "for "
-        for express in in_node[1]:
-            outstring = outstring + traverse_ast(express) + ","
-        outstring = outstring[:-1] + " in "
-        special_info["rhs"] = True
-        for target in in_node[2]:
-            outstring += "copy("+traverse_ast(target) + "),"
-        special_info["rhs"] = None
-        outstring = outstring[:-1] + ":" + add_indent("\n" + traverse_ast(in_node[3]))
-        return outstring
-    elif node_type == "REPEAT": #REPEAT suite
-        outstring = "while True:" + add_indent("\n" + traverse_ast(in_node[1]))
-        return outstring
-    elif node_type == "WITH": #new_id old_id suite
-        # each entry in special_id is [alias:[cat_name,loop variable, is_loop]]
-        alias_id = in_node[1]
-        cat_id = in_node[2]
-        is_already_there = [a for a in special_info['special_id'][-1].keys() if \
-            special_info['special_id'][-1][a][0] == cat_id]
-        if len(is_already_there)>0:
-            del special_info['special_id'][-1][is_already_there[0]]
-            print("Found explicit loop category alias: %s for %s" % (alias_id,cat_id) )
-        special_info['special_id'][-1].update({alias_id:[cat_id,"",False]})
-        if in_node[2] in special_info['loopable_cats'].keys(): #flag this
-            special_info['special_id'][-1][alias_id][1] = "looped_cat"
-        outstring = traverse_ast(in_node[3])
-        return outstring
-
-    elif node_type == "LOOP": #ALIAS CAT LOOPVAR COMP COMPVAR SUITE 
-        alias_id = in_node[1]
-        cat_id = in_node[2]
-        var_info = [cat_id,"",False]
-        if cat_id not in special_info['loopable_cats'].keys():
-            message =  "%s is not a loopable category (must be one of:\n%s)" % (cat_id,special_info['loopable_cats'].keys())
-            print(message)
-            raise CifError(message)
-        #loop over some index
-        loop_num = len(special_info['special_id'][-1])+1
-        if in_node[3] == "":  # provide our own
-            loop_index = "__pi%d" % loop_num
-        else:
-            loop_index = in_node[3]
-        var_info[1] = loop_index
-        var_info[2] = True
-        special_info['special_id'][-1].update({alias_id:var_info})
-        # now emit some text: first to find the length of the category
-        # loopable cats contains a list of names defined for the category
-        # this might not be robust as we ignore alternative resolutions of the (cat,name) pair
-        catnames = set([a[1][0] for a in cif_dic.cat_obj_lookup_table.items() if a[0][0]==cat_id.lower()])
-        outstring = "__pyallitems = " + repr(catnames)
-        outstring += "\nprint('names in cat = %s' % repr(__pyallitems))"
-        outstring += "\n" + "__pycitems = [a for a in __pyallitems if %s]" % (api_table["has_name"] % "a")
-        outstring += "\nprint('names in cat -> %s' % repr(__pycitems))\n"
-        cat_key = cif_dic[cat_id]['_category_key.name'][0]   #take official key
-        # If there is nothing in the category, provoke category creation by evaluating the key
-        outstring += "if len(__pycitems)==0:\n"
-        outstring += "    __pydummy = %s\n" % (api_table["data_access"] % repr(cat_key))
-        outstring += "    __pycitems = [a for a in __pyallitems if %s]\n" % (api_table["has_name"] % "a")
-        outstring += "    print('After category creation, names in cat ->' + repr(__pycitems))\n"
-        special_info["depends"].add(cat_key)  #add key as a dependency
-        if var_info[2] == True:
-            access_string = api_table["count_data"] % (api_table["data_access"] % "__pycitems[0]")
-            outstring += "\n" + "__loop_range%d = range(%s)" % (loop_num,access_string)
-        else:
-            outstring += "\n" + "__loop_range%d = [0]" % loop_num
-            #outstring +="\n" + "for __noloop in [0]:"
-        # deal with this comparison test
-        if in_node[4] != "":
-            outstring += "\n" + "__loop_range%d = [a for a in __loop_range%d if a %s %s]" % (loop_num,loop_num,in_node[4],in_node[5])
-        # now output the looping command
-        outstring += "\n" + "for %s in __loop_range%d:" % (loop_index,loop_num)
-        # now the actual body of the loop
-        loop_body = traverse_ast(in_node[6])
-        outstring = outstring + add_indent("\n"+loop_body)
-        return outstring
-
-    elif node_type == "FUNCTION":   #FUNCTION ID ARGLIST SUITE
-        func_name = in_node[1]
-        outstring = "def %s (" % func_name
-        for one_arg in in_node[2]:
-            outstring += one_arg[0] + ","
-        outstring = outstring + "ciffile):"
-        # imports
-        #import_lines = "import numpy\nfrom emapsCifFile.drel import drel_runtime\n"
-        import_lines = ""
-        outstring = outstring + add_indent("\n" + import_lines + traverse_ast(in_node[3])+"\nreturn %s" % func_name)
-        return outstring
-
-
-    elif node_type == "STATEMENTS":
-        outstring = ""
-        for one_statement in in_node[1]:
-#            try:
-                next_bit = traverse_ast(one_statement)
-                if not isinstance(next_bit,(unicode,str)):
-                    print("Unable to traverse AST for %s" % one_statement[0])
-                else:
-                    outstring = outstring + next_bit + "\n"
-#            except SyntaxError as message:
-#                print("Failed, so far have \n " + outstring)
-#                outstring += "raise SyntaxError, %s" % message
-#            except:
-#                print("Failed, so far have \n " + outstring)
-#                outstring += "raise SyntaxError, %s" % `one_statement`
-        return outstring
-    elif node_type == "ASSIGN":  #Target_list ,assigner, expression list
-        outstring = ""
-        lhs_values = []
-        special_info["rhs"] = False
-        for target_value in in_node[1]:
-            one_value = traverse_ast(target_value)
-            outstring = outstring + one_value +","
-            lhs_values.append(one_value)
-        lhs = outstring[:-1]
-        rhs = ""
-        special_info["rhs"] = True
-        for order,expression in enumerate(in_node[3]):
-            rhs += traverse_ast(expression)+","
-            if special_info["sub_subject"] != "":   #a full packet
-                special_info["packet_vars"].update({lhs_values[order]:special_info["sub_subject"]})
-                special_info["sub_subject"] = ""
-        # we cannot expand a numpy array, hence the workaround here
-        #if in_node[2] == "++=":
-        #    outstring = "_temp1 = %s;%s = %s(_temp1,%s)" % (lhs,lhs,aug_assign_table["++="],rhs[:-1])
-        if in_node[2] != "=":
-            outstring = "%s = %s(%s,%s)" % (lhs, aug_assign_table[in_node[2]],lhs,rhs[:-1])
-        else:
-            outstring = "%s = %s" % (lhs,rhs[:-1])
-        special_info["rhs"] = None
-        return outstring
-    elif node_type == "FANCY_ASSIGN":  # [1] is cat name, [2] is list of objects
-        catname = in_node[1]
-        outstring = ""
-        special_info["rhs"] = True
-        for obj,value in in_node[2]:
-            real_id = cif_dic.get_name_by_cat_obj(catname, obj)
-            newvalue = traverse_ast(value)
-            outstring = outstring + "__dreltarget.update({'%s':__dreltarget.get('%s',[])+[%s]})\n" % (real_id,real_id,newvalue)
-        special_info["rhs"] = None
-        return outstring
-
-    elif node_type == "LIST":
-        outstring = "["
-        for one_element in in_node[1]:
-            outstring = outstring + traverse_ast(one_element)  + ","
-        return outstring + "]"
-    elif node_type == "EXPR":
-        return traverse_ast(in_node[1])
-    # Expr list occurs only when a non-assignment statement appears as expr_stmt
-    elif node_type == "EXPRLIST":
-        outstring = ""
-        for one_expr in in_node[1]:
-            outstring += traverse_ast(one_expr) + "\n"
-        return outstring
-    elif node_type == "GROUP":
-        outstring = "("
-        for expression in in_node[1]:
-             outstring = outstring + traverse_ast(expression) + ","
-        return outstring[:-1] + ")"
-    elif node_type == "PRINT":
-        return 'print( ' + traverse_ast(in_node[1]) + ")"
-    elif node_type == "BREAK":
-        return 'break '
-    elif node_type == "NEXT":
-        return 'continue '
-
-    else:
-       return "Not found: %s" % repr(in_node)
-  result = traverse_ast(in_node)
-  # remove target id from dependencies
-  if special_info["target_id"] is not None:
-      special_info["depends"].discard(special_info["target_id"].lower())
-  if not special_info.get("have_drel_target",False):
-      print('WARNING: no assignment to __dreltarget in %s (this is OK for category methods)' % repr(target_id))
-      print(result)
-  return result,special_info["withtable"],special_info["depends"],special_info["need_current_row"]
-
-def get_function_name(in_name):
-    """Return the Python name of the dREL function, an argument prefix,
-       and anything to be appended to the end"""
-    builtins = {"table":"dict",
-                "list":"list",
-                "array":"numpy.array",
-                "len":"len",
-                "abs":"abs",
-                "magn":"abs",
-                "atoi":"int",
-                "float":"float",
-                "str":"str",
-                "array":"numpy.array",
-                "norm":"numpy.linalg.norm",
-                "sqrt":"math.sqrt",
-                "exp":"math.exp",
-                "complex":"complex",
-                "max":"max",
-                "min":"min",
-                "strip":"drel_runtime.drel_strip",
-                "int":"drel_runtime.drel_int",
-                "eigen":"drel_runtime.drel_eigen",
-                "hash":"hash"  #dREL extension
-    }
-    test_name = in_name.lower()
-    target_name = builtins.get(test_name,None)
-    if target_name is not None:
-        return target_name,"",""
-    if test_name in ['sind','cosd','tand']:
-        return "math."+test_name[:-1],"math.radians(",")"
-    if test_name in ['acosd','asind','atand','atan2d']:
-        return "math.degrees(math."+test_name[:-1],"",")"
-    if test_name == "mod":
-        return "divmod","","[1]"
-    if test_name == "upper":
-        return "","",".upper()"
-    if test_name == "transpose":
-        return "","",".T"
-    if test_name == 'expimag':
-        return "cmath.exp","1j*(",")"
-    if test_name in ['real','imag']:
-        return "","","." + test_name
-    if test_name == 'matrix':
-        return "numpy.matrix","",".astype('float64')"
-    if test_name == 'sort':
-        return "","",".sort()"
-    return in_name,"",None   #dictionary defined
-
-def fix_mathops(op,first_arg,second_arg):
-    """Return a string that will carry out the requested operation"""
-    if op == "^":
-        return "numpy.cross(%s,%s)" % (first_arg,second_arg)
-    elif op == "*":  #could be matrix multiplication
-        return "drel_runtime.drel_dot(%s,%s)" % (first_arg,second_arg)
-    elif op == "+":
-        return "drel_runtime.drel_add(%s,%s)" % (first_arg, second_arg)
-    elif op == "-":
-        return "numpy.subtract(%s,%s)" % (first_arg, second_arg)
-    # beware integer division on this one...
-    elif op == "/":
-        return "numpy.true_divide(%s,%s)" % (first_arg, second_arg)
-
-def add_indent(text,n=4):
-    """Indent text by n spaces"""
-    return re.sub("\n","\n"+4*" ",text)
-
-def getcatname(dataname):
-    """Return cat,name pair from dataname"""
-    try:
-        cat,name = dataname.split(".")
-    except ValueError:        #no period in name
-        return cat,None
-    return cat[1:],name
-
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+# The unicode type does not exist in Python3 as the str type
+# encompasses unicode.  PyCIFRW tests for 'unicode' would fail
+# Suggestions for a better approach welcome.
+
+if isinstance(u"abc",str):   #Python3
+    unicode = str
+
+import re
+from CifFile import CifError
+pycifrw_func_table = {   #how to use PyCIFRW CifFile objects
+         "data_access": "ciffile[%s]",   # argument is dataname to be accessed
+         "optional_data_access":"emapsCifFile.get(%s,None)",
+         "element_no": "%s[%s]", # accessing a particular element of the result of data_access
+         "count_data": "len(%s)", # number of elements for result of data_access
+         "cat_names":"emapsCifFile.dictionary.names_in_cat(%s)", #names in category %s
+         "has_name":"emapsCifFile.has_key_or_alias(%s)",
+         "semantic_packet":"emapsCifFile.GetKeyedSemanticPacket(%s,%s)" #get a packet for key, value
+                     }
+
+def make_python_function(in_ast,func_name,targetname, special_ids=[{}],
+                         func_table = pycifrw_func_table, cif_dic=None,cat_meth=False, 
+                         func_def = False, have_sn=True,loopable={},debug=None,depends=False):
+    """Convert in_ast to python code"""
+    if debug is not None:
+        print("incoming AST:")
+        print(repr(in_ast))
+    func_text,withtable,dependencies,cur_row = start_traverse(in_ast,func_table,target_id=targetname,cat_meth=cat_meth,loopable=loopable,debug=debug,func=func_def,cif_dic=cif_dic)
+    if debug is not None:
+        print('Start========')
+        print(func_text)
+        print('End==========')
+    if func_def and not depends:
+        return func_text
+    elif func_def:
+        return func_text, None
+    # now indent the string
+    noindent = func_text.splitlines()
+    # get the minimum indent and remove empty lines
+    no_spaces = [re.match(r' *',a).end() for a in noindent if a] #drop empty lines
+    min_spaces = min(no_spaces)+4   # because we add 4 ourselves to everything
+    if len(withtable) > 0 or cur_row:  # a loop method
+            d_vars = [a[1][0] for a in withtable.items()]
+            if cur_row:
+                d_vars = d_vars + ['__current_row']
+            dummy_vars = ",".join(d_vars)
+            actual_names = [k for k in withtable.keys()]
+            actual_names = [func_table["data_access"]% ("'"+a+"'") for a in actual_names]
+            # intercept optional values and replace with [] if None
+            optional_names = ["__option_w%d"%n for n,k in enumerate(withtable.keys()) if withtable[k][2]]
+            if cur_row:
+                actual_names+=['__row_id']
+            final_names = actual_names[:]
+            one_pack_names = [func_table["element_no"] % (a,"packet_no") for a in actual_names]
+            for n,k in enumerate(withtable.keys()):
+                if withtable[k][2]:
+                    final_names[n]="__option_w%d"%n  #pre-evaluated
+                    one_pack_names[n] = "__option_w%d"%n
+            map_names = ",".join(final_names)
+            one_packet_each = ",".join(one_pack_names)
+            preamble = "def %s(ciffile,packet_no=-1):\n" % (func_name)
+            preamble +="    try:\n"
+            preamble +="        from itertools import repeat,imap\n"   #note that imap might fail
+            preamble +="    except ImportError: #python3\n"
+            preamble +="        imap = map\n"
+            preamble +="    def drel_func(%s):\n" % dummy_vars
+            # for debugging
+            print_instruction = "'Function passed variables "+("{!r} "*len(d_vars))+"'.format("+dummy_vars+",)"
+            preamble +="        print(%s)\n" % print_instruction
+            # preamble +="        print('Globals inside looped drel_func:' + repr(globals())\n")
+            # the actual function gets inserted here
+            # Handle the optional names
+            end_body = "\n"
+            for n,one_opt in enumerate(withtable.keys()):
+                if withtable[one_opt][2]:
+                    end_body += "    try:\n"
+                    end_body += "            %s%d = %s\n" % ("__option_w",n,func_table["optional_data_access"]%("'"+one_opt+"'"))
+                    end_body += "    except KeyError:\n"
+                    end_body += "            %s%d = None\n" % ("__option_w",n)
+            end_body+=      "    if packet_no < 0:   #map\n"
+            for one_opt in optional_names:
+                end_body += "        if %s is None: %s = repeat(None)\n" % (one_opt,one_opt)
+
+            if cur_row and len(actual_names) > 1:    #i.e. have real names from category
+                end_body +="        __row_id = range(%s)\n" % (func_table['count_data'] % ("'"+actual_names[0]+"'"))
+            elif cur_row and len(actual_names)==1:   #so no actual names available
+
+                end_body += "        cat_names = %s\n" % (func_table["cat_names"] % ("'"+getcatname(targetname)[0]+"'"))
+                end_body += "        have_name = [a for a in cat_names if %s]\n" % (func_table["has_name"] % "a")
+                end_body += "        if len(have_name)>0:\n"
+                end_body += "           full_length = %s \n" % (func_table["count_data"] % (func_table["data_access"] % "have_name[0]"))
+                end_body += "           __row_id = range(full_length)\n"
+                end_body += "        else:\n"
+                end_body += "           return []\n"
+
+            end_body+=      "        return list(imap(drel_func,%s))\n" % (map_names+",")
+            end_body+=     "    else:\n"
+            end_body+=     "        return drel_func(%s)\n" % one_packet_each
+
+    else:
+            preamble = "def %s(ciffile):\n" % func_name
+            #preamble +="        global StarList#from emapsCifFile.drel import drel_runtime\n"
+            end_body = ""
+
+    if cat_meth:
+        preamble += " "*8 + "__dreltarget = {}\n" # initialise
+    num_header = """
+        import math,cmath
+        try:
+            import numpy
+        except:
+            print("Can't import numerical python, this method may not work")
+"""
+    preamble += num_header
+    indented = map(lambda a:" "*8 + a +"\n",noindent)  #indent dREL body
+    postamble = ""
+    postamble += " "*8 + "return __dreltarget"
+    final = preamble + "".join(indented) + postamble + end_body
+    if not depends:
+        return final
+    else: return final, dependencies
+
+def start_traverse(in_node,api_table,target_id=None,loopable={},cat_meth=False,debug=None, func=False,
+                  cif_dic=None):
+  special_info = {"special_id":[{}],"target_id":target_id,"withtable":{},"sub_subject":"",
+                  "depends":set(),"loopable_cats":loopable,"packet_vars":{},
+                  "need_current_row":False,"rhs":None,"inif":False}
+  # create a virtual enclosing 'with' statement
+  if target_id is not None and not cat_meth and not func:
+      cat,name = getcatname(target_id)
+      special_info["special_id"][-1].update({"_"+cat:[cat,"",False]})
+      if cat in special_info["loopable_cats"].keys():    #
+          special_info["special_id"][-1]["_"+cat][1] = "looped_cat"
+  mathop_table = {"+":None, "-":None, "<":"<", "*":None, "/":None,
+                  "&":"&", "|":"|",
+                  ">":">", "<=":"<=", ">=":">=", "!=":"!=",
+                  "or":" or ", "and":" and ",
+                  "==":"==", "in":" in ", "not in":" not in ",
+                  "^":None,"**":"**"}
+
+  aug_assign_table = {"++=":"drel_runtime.aug_append",
+                      "+=":"drel_runtime.aug_add",
+                      "-=":"drel_runtime.aug_sub",
+                      "--=":"drel_runtime.aug_remove"}
+
+  def traverse_ast(in_node,debug=debug):
+    if isinstance(in_node,(unicode,str)):
+        return in_node
+    if isinstance(in_node[0],list):
+        raise SyntaxError('First element of AST Node must be string: ' + repr(in_node))
+    node_type = in_node[0]
+    if debug == node_type:
+        print(node_type + ": " + repr(in_node))
+    if node_type == "ARGLIST":
+        pass
+    elif node_type == "BINARY":
+        return("%d" % int(in_node[1],base=2))
+    elif node_type == "FALSE":
+        return("False")
+    elif node_type == "REAL":
+        return(in_node[1])
+    elif node_type == "HEX":
+        return("%d" % int(in_node[1],base=16))
+    elif node_type == "INT":
+        return(in_node[1])
+    elif node_type == "IMAGINARY":
+        return(in_node[1])
+    elif node_type == "OCTAL":
+        return("%d" % int(in_node[1],base=8))
+
+    elif node_type == "ATOM":
+        if isinstance(in_node[1],(unicode,str)):
+            # pick up built-in literals
+            if in_node[1].lower() == 'twopi':
+                return "(2.0 * math.pi)"
+            if in_node[1].lower() == 'pi':
+                return "math.pi"
+            else:
+                return in_node[1]
+        else:
+            return traverse_ast(in_node[1])
+    elif node_type == "ITEM_TAG":
+        return in_node[1]
+    elif node_type == "LITERAL":
+        return in_node[1]
+    elif node_type == "LIST":
+        if len(in_node)==1:  #empty list
+           return "StarList([])"
+        if special_info["rhs"] == True:
+            outstring = "StarList(["
+        else:
+            outstring = ""
+        for list_elem in in_node[1:]:
+            outstring = outstring + traverse_ast(list_elem) + ","
+        if special_info["rhs"] == True:
+            return outstring[:-1] + "])"
+        else:
+            return outstring[:-1]
+    elif node_type == "TABLE":
+        if len(in_node)==1:
+            return "StarTable({})"
+        else:
+            outstring = "{"
+        for table_elem in in_node[1:]:
+            outstring = outstring + traverse_ast(table_elem[0])+":"+traverse_ast(table_elem[1]) +","
+        return outstring[:-1] + "}"
+    elif node_type == "SUBSCRIPTION":  # variable, single expression
+        newid = 0
+        if in_node[1][0] == "ATOM" and in_node[1][1][0] == "ITEM_TAG":  #keyed lookup
+            print("Found category used as item tag: subscribing")
+            newid = [in_node[1][1][1][1:],False,False]  #drop underscore and remember
+        else:
+            primary = traverse_ast(in_node[1])
+            # check to see if this is a special variable
+            for idtable in special_info["special_id"]:
+                newid = idtable.get(primary,0)
+                if newid: break
+                if primary in special_info["loopable_cats"].keys():   #loop category used
+                    newid = [primary,False,False]
+                    break
+        if newid:
+            #FIXME: the dataname may not be the <cat>.<obj> construction (eg pdCIF)
+            key_items = ["_"+newid[0]+"."+s for s in special_info["loopable_cats"][newid[0]][0]]  #key name
+            special_info["depends"].update([k.lower() for k in key_items])
+            get_loop = api_table["semantic_packet"] % (traverse_ast(in_node[2]),"'"+newid[0]+"'")
+            special_info["sub_subject"] = newid[0]  #in case of attribute reference following
+            print("Set sub_subject to %s" % special_info["sub_subject"])
+            return get_loop
+        else:
+            outstring = primary + "["
+            outstring = outstring + traverse_ast(in_node[2]) + "]"
+            return outstring
+
+    elif node_type == "ATTRIBUTE":  # id/tag , att
+        outstring = ""
+        newid = 0
+        # check for special ids
+        primary = traverse_ast(in_node[1])  # this will set sub_subject if necessary
+        for idtable in special_info["special_id"]:
+            newid = idtable.get(primary,0)
+            if newid: break
+        if newid:
+            #catch our output name
+            true_name = cif_dic.get_name_by_cat_obj(newid[0].lower(),in_node[2].lower()).lower()
+            if true_name == special_info.get("target_id","").lower():
+                    outstring = "__dreltarget"
+                    special_info["have_drel_target"] = True
+            # if we are looping, we add a loop prefix. If we are withing an
+            # unlooped category, we put the full name back.
+            elif newid[2] or (not newid[2] and not newid[1]):   # looping or simple with
+                outstring = api_table["data_access"] % ('"' +true_name +'"')
+                special_info["depends"].add(true_name)
+                if newid[1]:  # a loop statement requires an index
+                    outstring += "[" + newid[1]+ "]"
+            else:   # a with statement; capture the name and create a dummy variable
+                if true_name not in special_info["withtable"]:  #new
+                    position = len(special_info["withtable"])
+                    new_var = "__w%d" % position
+                    isoptional = special_info["inif"]
+                    special_info["withtable"][true_name] = (new_var,position,isoptional)
+                outstring += special_info["withtable"][true_name][0]
+                special_info["depends"].add(true_name)
+        elif in_node[1][0] == "ATOM" and primary[0] == "_":   # a cat/obj name
+            fullname = cif_dic.get_name_by_cat_obj(primary,in_node[2]).lower()
+            # a simple cat.obj dataname from the dictionary
+            if special_info.get("target_id","").lower() == fullname:
+                outstring = "__dreltarget"
+                special_info["have_drel_target"] = True
+            else:
+                special_info["depends"].add(fullname)
+                outstring = api_table["data_access"] % ("'" + fullname + "'")
+        else: # default to Python attribute access
+            # check for packet variables
+            if primary in special_info["packet_vars"]:
+                real_cat = special_info["packet_vars"][primary]
+                fullname = cif_dic.get_name_by_cat_obj(real_cat,in_node[2])
+                special_info['depends'].add(fullname)
+            elif special_info["sub_subject"]:
+                fullname = cif_dic.get_name_by_cat_obj(special_info["sub_subject"],in_node[2])
+                special_info['depends'].add(fullname)
+            else:  # not anything special
+                fullname = in_node[2]
+            outstring = "getattr(" + primary + ",'" + fullname + "')"
+            # sub_subject no longer relevant after attribute resolution
+            special_info['sub_subject'] = ""
+        return outstring
+
+    elif node_type == "FUNC_CALL":
+        if in_node[1] == "Current_Row":  #not a function but a keyword really
+            outstring = "__current_row"
+            special_info["need_current_row"]=True
+        else:
+            func_name,every_arg_prefix,postfix = get_function_name(in_node[1])
+            outstring = func_name + "( "
+            if func_name == "list" and len(in_node[2])>1:   #special case
+                outstring = outstring + "["
+            for argument in in_node[2]:
+                outstring = outstring + every_arg_prefix + traverse_ast(argument) + ","
+            if postfix == None:  # signal for dictionary defined
+                outstring = outstring + "ciffile)"
+            else:
+                outstring = outstring[:-1]
+                if func_name == "list" and len(in_node[2])>1:
+                    outstring = outstring + "]"
+                outstring = outstring + ")" + postfix
+        return outstring
+
+    elif node_type == "SLICE":  # primary [[start,finish,step],[...]
+        outstring = traverse_ast(in_node[1]) + "["
+        slice_list = in_node[2]
+        for one_slice in slice_list:
+            if one_slice[0] == "EXPR":   #not a slice as such
+                outstring += traverse_ast(one_slice)
+            elif len(one_slice) == 0:
+                outstring += ":"
+            elif len(one_slice) >0:    # at least start
+                outstring += traverse_ast(one_slice[0]) + ":"
+                if len(one_slice) >1:    #start,finish only
+                    outstring += traverse_ast(one_slice[1])
+                if len(one_slice) == 3:    #step as well
+                    outstring += ":" + traverse_ast(one_slice[2])
+            outstring += ","
+        outstring = outstring[:-1] + "]"
+        return outstring
+
+    elif node_type == "MATHOP":
+        op = mathop_table[in_node[1]]
+        first_arg = traverse_ast(in_node[2])
+        second_arg = traverse_ast(in_node[3])
+        if op is not None:    #simple operation
+            outstring = first_arg + op + second_arg
+        else:
+            outstring = fix_mathops(in_node[1],first_arg,second_arg)
+        return outstring
+    elif node_type == "SIGN":
+        outstring = "drel_runtime.drel_dot(" + in_node[1] + "1," + traverse_ast(in_node[2])+")"
+        return outstring
+    elif node_type == "UNARY":
+        outstring = in_node[1] + " " + traverse_ast(in_node[2])
+        return outstring
+
+    elif node_type == "IF_EXPR":   #IF_EXPR test true_suite [ELSE IF_EXPR] false_suite
+        outstring = "if "
+        outstring = outstring + traverse_ast(in_node[1])
+        outstring = outstring + ":"
+        old_inif = special_info["inif"]
+        special_info["inif"] = True
+        true_bit = traverse_ast(in_node[2])
+        outstring = outstring + add_indent("\n"+true_bit)  #indent
+        elseif = in_node[3]
+        if len(elseif)!=0:
+            for one_cond in elseif:  #each entry is condition, suite
+                outstring += "\nelif " + traverse_ast(one_cond[0]) + ":"
+                outstring += add_indent("\n" + traverse_ast(one_cond[1]))
+        if len(in_node)>4:
+            outstring = outstring + "\nelse:"
+            false_bit = traverse_ast(in_node[4])
+            outstring = outstring + add_indent("\n"+false_bit)  #indent
+        special_info["inif"] = old_inif
+        return outstring
+
+# dREL for statements include the final value, whereas a python range will include
+# everything up to the final number
+    elif node_type == "DO":    #DO ID = start, finish, incr, suite
+        outstring = "for " + in_node[1] + " in range(" + traverse_ast(in_node[2]) + ","
+        finish = traverse_ast(in_node[3])
+        increment = traverse_ast(in_node[4])
+        outstring = outstring + finish + "+1" + "," + increment
+        outstring = outstring + "):"
+        suite = add_indent("\n"+traverse_ast(in_node[5]))
+        return outstring + suite
+    elif node_type == "FOR": # FOR target_list expression_list suite
+        outstring = "for "
+        for express in in_node[1]:
+            outstring = outstring + traverse_ast(express) + ","
+        outstring = outstring[:-1] + " in "
+        special_info["rhs"] = True
+        for target in in_node[2]:
+            outstring += "copy("+traverse_ast(target) + "),"
+        special_info["rhs"] = None
+        outstring = outstring[:-1] + ":" + add_indent("\n" + traverse_ast(in_node[3]))
+        return outstring
+    elif node_type == "REPEAT": #REPEAT suite
+        outstring = "while True:" + add_indent("\n" + traverse_ast(in_node[1]))
+        return outstring
+    elif node_type == "WITH": #new_id old_id suite
+        # each entry in special_id is [alias:[cat_name,loop variable, is_loop]]
+        alias_id = in_node[1]
+        cat_id = in_node[2]
+        is_already_there = [a for a in special_info['special_id'][-1].keys() if \
+            special_info['special_id'][-1][a][0] == cat_id]
+        if len(is_already_there)>0:
+            del special_info['special_id'][-1][is_already_there[0]]
+            print("Found explicit loop category alias: %s for %s" % (alias_id,cat_id) )
+        special_info['special_id'][-1].update({alias_id:[cat_id,"",False]})
+        if in_node[2] in special_info['loopable_cats'].keys(): #flag this
+            special_info['special_id'][-1][alias_id][1] = "looped_cat"
+        outstring = traverse_ast(in_node[3])
+        return outstring
+
+    elif node_type == "LOOP": #ALIAS CAT LOOPVAR COMP COMPVAR SUITE 
+        alias_id = in_node[1]
+        cat_id = in_node[2]
+        var_info = [cat_id,"",False]
+        if cat_id not in special_info['loopable_cats'].keys():
+            message =  "%s is not a loopable category (must be one of:\n%s)" % (cat_id,special_info['loopable_cats'].keys())
+            print(message)
+            raise CifError(message)
+        #loop over some index
+        loop_num = len(special_info['special_id'][-1])+1
+        if in_node[3] == "":  # provide our own
+            loop_index = "__pi%d" % loop_num
+        else:
+            loop_index = in_node[3]
+        var_info[1] = loop_index
+        var_info[2] = True
+        special_info['special_id'][-1].update({alias_id:var_info})
+        # now emit some text: first to find the length of the category
+        # loopable cats contains a list of names defined for the category
+        # this might not be robust as we ignore alternative resolutions of the (cat,name) pair
+        catnames = set([a[1][0] for a in cif_dic.cat_obj_lookup_table.items() if a[0][0]==cat_id.lower()])
+        outstring = "__pyallitems = " + repr(catnames)
+        outstring += "\nprint('names in cat = %s' % repr(__pyallitems))"
+        outstring += "\n" + "__pycitems = [a for a in __pyallitems if %s]" % (api_table["has_name"] % "a")
+        outstring += "\nprint('names in cat -> %s' % repr(__pycitems))\n"
+        cat_key = cif_dic[cat_id]['_category_key.name'][0]   #take official key
+        # If there is nothing in the category, provoke category creation by evaluating the key
+        outstring += "if len(__pycitems)==0:\n"
+        outstring += "    __pydummy = %s\n" % (api_table["data_access"] % repr(cat_key))
+        outstring += "    __pycitems = [a for a in __pyallitems if %s]\n" % (api_table["has_name"] % "a")
+        outstring += "    print('After category creation, names in cat ->' + repr(__pycitems))\n"
+        special_info["depends"].add(cat_key)  #add key as a dependency
+        if var_info[2] == True:
+            access_string = api_table["count_data"] % (api_table["data_access"] % "__pycitems[0]")
+            outstring += "\n" + "__loop_range%d = range(%s)" % (loop_num,access_string)
+        else:
+            outstring += "\n" + "__loop_range%d = [0]" % loop_num
+            #outstring +="\n" + "for __noloop in [0]:"
+        # deal with this comparison test
+        if in_node[4] != "":
+            outstring += "\n" + "__loop_range%d = [a for a in __loop_range%d if a %s %s]" % (loop_num,loop_num,in_node[4],in_node[5])
+        # now output the looping command
+        outstring += "\n" + "for %s in __loop_range%d:" % (loop_index,loop_num)
+        # now the actual body of the loop
+        loop_body = traverse_ast(in_node[6])
+        outstring = outstring + add_indent("\n"+loop_body)
+        return outstring
+
+    elif node_type == "FUNCTION":   #FUNCTION ID ARGLIST SUITE
+        func_name = in_node[1]
+        outstring = "def %s (" % func_name
+        for one_arg in in_node[2]:
+            outstring += one_arg[0] + ","
+        outstring = outstring + "ciffile):"
+        # imports
+        #import_lines = "import numpy\nfrom emapsCifFile.drel import drel_runtime\n"
+        import_lines = ""
+        outstring = outstring + add_indent("\n" + import_lines + traverse_ast(in_node[3])+"\nreturn %s" % func_name)
+        return outstring
+
+
+    elif node_type == "STATEMENTS":
+        outstring = ""
+        for one_statement in in_node[1]:
+#            try:
+                next_bit = traverse_ast(one_statement)
+                if not isinstance(next_bit,(unicode,str)):
+                    print("Unable to traverse AST for %s" % one_statement[0])
+                else:
+                    outstring = outstring + next_bit + "\n"
+#            except SyntaxError as message:
+#                print("Failed, so far have \n " + outstring)
+#                outstring += "raise SyntaxError, %s" % message
+#            except:
+#                print("Failed, so far have \n " + outstring)
+#                outstring += "raise SyntaxError, %s" % `one_statement`
+        return outstring
+    elif node_type == "ASSIGN":  #Target_list ,assigner, expression list
+        outstring = ""
+        lhs_values = []
+        special_info["rhs"] = False
+        for target_value in in_node[1]:
+            one_value = traverse_ast(target_value)
+            outstring = outstring + one_value +","
+            lhs_values.append(one_value)
+        lhs = outstring[:-1]
+        rhs = ""
+        special_info["rhs"] = True
+        for order,expression in enumerate(in_node[3]):
+            rhs += traverse_ast(expression)+","
+            if special_info["sub_subject"] != "":   #a full packet
+                special_info["packet_vars"].update({lhs_values[order]:special_info["sub_subject"]})
+                special_info["sub_subject"] = ""
+        # we cannot expand a numpy array, hence the workaround here
+        #if in_node[2] == "++=":
+        #    outstring = "_temp1 = %s;%s = %s(_temp1,%s)" % (lhs,lhs,aug_assign_table["++="],rhs[:-1])
+        if in_node[2] != "=":
+            outstring = "%s = %s(%s,%s)" % (lhs, aug_assign_table[in_node[2]],lhs,rhs[:-1])
+        else:
+            outstring = "%s = %s" % (lhs,rhs[:-1])
+        special_info["rhs"] = None
+        return outstring
+    elif node_type == "FANCY_ASSIGN":  # [1] is cat name, [2] is list of objects
+        catname = in_node[1]
+        outstring = ""
+        special_info["rhs"] = True
+        for obj,value in in_node[2]:
+            real_id = cif_dic.get_name_by_cat_obj(catname, obj)
+            newvalue = traverse_ast(value)
+            outstring = outstring + "__dreltarget.update({'%s':__dreltarget.get('%s',[])+[%s]})\n" % (real_id,real_id,newvalue)
+        special_info["rhs"] = None
+        return outstring
+
+    elif node_type == "LIST":
+        outstring = "["
+        for one_element in in_node[1]:
+            outstring = outstring + traverse_ast(one_element)  + ","
+        return outstring + "]"
+    elif node_type == "EXPR":
+        return traverse_ast(in_node[1])
+    # Expr list occurs only when a non-assignment statement appears as expr_stmt
+    elif node_type == "EXPRLIST":
+        outstring = ""
+        for one_expr in in_node[1]:
+            outstring += traverse_ast(one_expr) + "\n"
+        return outstring
+    elif node_type == "GROUP":
+        outstring = "("
+        for expression in in_node[1]:
+             outstring = outstring + traverse_ast(expression) + ","
+        return outstring[:-1] + ")"
+    elif node_type == "PRINT":
+        return 'print( ' + traverse_ast(in_node[1]) + ")"
+    elif node_type == "BREAK":
+        return 'break '
+    elif node_type == "NEXT":
+        return 'continue '
+
+    else:
+       return "Not found: %s" % repr(in_node)
+  result = traverse_ast(in_node)
+  # remove target id from dependencies
+  if special_info["target_id"] is not None:
+      special_info["depends"].discard(special_info["target_id"].lower())
+  if not special_info.get("have_drel_target",False):
+      print('WARNING: no assignment to __dreltarget in %s (this is OK for category methods)' % repr(target_id))
+      print(result)
+  return result,special_info["withtable"],special_info["depends"],special_info["need_current_row"]
+
+def get_function_name(in_name):
+    """Return the Python name of the dREL function, an argument prefix,
+       and anything to be appended to the end"""
+    builtins = {"table":"dict",
+                "list":"list",
+                "array":"numpy.array",
+                "len":"len",
+                "abs":"abs",
+                "magn":"abs",
+                "atoi":"int",
+                "float":"float",
+                "str":"str",
+                "array":"numpy.array",
+                "norm":"numpy.linalg.norm",
+                "sqrt":"math.sqrt",
+                "exp":"math.exp",
+                "complex":"complex",
+                "max":"max",
+                "min":"min",
+                "strip":"drel_runtime.drel_strip",
+                "int":"drel_runtime.drel_int",
+                "eigen":"drel_runtime.drel_eigen",
+                "hash":"hash"  #dREL extension
+    }
+    test_name = in_name.lower()
+    target_name = builtins.get(test_name,None)
+    if target_name is not None:
+        return target_name,"",""
+    if test_name in ['sind','cosd','tand']:
+        return "math."+test_name[:-1],"math.radians(",")"
+    if test_name in ['acosd','asind','atand','atan2d']:
+        return "math.degrees(math."+test_name[:-1],"",")"
+    if test_name == "mod":
+        return "divmod","","[1]"
+    if test_name == "upper":
+        return "","",".upper()"
+    if test_name == "transpose":
+        return "","",".T"
+    if test_name == 'expimag':
+        return "cmath.exp","1j*(",")"
+    if test_name in ['real','imag']:
+        return "","","." + test_name
+    if test_name == 'matrix':
+        return "numpy.matrix","",".astype('float64')"
+    if test_name == 'sort':
+        return "","",".sort()"
+    return in_name,"",None   #dictionary defined
+
+def fix_mathops(op,first_arg,second_arg):
+    """Return a string that will carry out the requested operation"""
+    if op == "^":
+        return "numpy.cross(%s,%s)" % (first_arg,second_arg)
+    elif op == "*":  #could be matrix multiplication
+        return "drel_runtime.drel_dot(%s,%s)" % (first_arg,second_arg)
+    elif op == "+":
+        return "drel_runtime.drel_add(%s,%s)" % (first_arg, second_arg)
+    elif op == "-":
+        return "numpy.subtract(%s,%s)" % (first_arg, second_arg)
+    # beware integer division on this one...
+    elif op == "/":
+        return "numpy.true_divide(%s,%s)" % (first_arg, second_arg)
+
+def add_indent(text,n=4):
+    """Indent text by n spaces"""
+    return re.sub("\n","\n"+4*" ",text)
+
+def getcatname(dataname):
+    """Return cat,name pair from dataname"""
+    try:
+        cat,name = dataname.split(".")
+    except ValueError:        #no period in name
+        return cat,None
+    return cat[1:],name
+
```

### Comparing `pyemaps-1.0.8/CifFile/src/parsetab.py` & `pyemaps-1.0.9/CifFile/src/parsetab.py`

 * *Ordering differences only*

 * *Files 1% similar despite different names*

```diff
@@ -1,185 +1,185 @@
-
-# parsetab.py
-# This file is automatically generated. Do not edit.
-_tabversion = '3.2'
-
-_lr_method = 'LALR'
-
-_lr_signature = '\xcc\x83\xf4<b8\x10\xb6\xfb\xc5z\x19\xd2\x9e\xc0\xa0'
-    
-_lr_action_items = {'REAL':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,48,48,-153,-152,-61,48,-76,-56,-156,48,-127,-75,-58,-126,48,-124,-78,-23,-129,-65,48,-63,48,-125,-74,-68,-66,-5,48,-50,-32,-79,-156,-30,48,-21,-70,-46,117,-69,-62,48,-59,-1,-77,-55,-131,-67,-27,48,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,48,-139,48,-3,-60,48,48,48,-52,-146,-42,-40,48,48,-39,48,-34,-35,-41,-37,-38,48,-31,-97,-95,48,48,-81,-72,-73,-51,48,48,48,48,48,48,48,48,-156,48,48,-147,-4,48,-82,-132,48,-26,-25,48,-33,-44,-45,-36,-84,-90,-54,-96,48,-80,48,-28,-29,-47,-48,-49,-112,48,-65,48,-8,-148,-140,48,-156,48,48,-100,48,-99,-98,48,48,-113,-156,-22,-9,-156,-156,-137,48,48,-83,-156,48,-89,48,48,48,-136,48,-141,48,-149,48,-144,-133,-134,-138,48,48,-142,-145,48,48,]),'DO':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,64,64,-153,-152,-61,64,-76,-56,-156,64,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,64,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,64,-139,-3,-60,64,-52,-146,-31,-97,-95,-81,-72,-73,-51,64,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,64,-8,-148,-140,64,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,64,-83,-89,64,-136,64,-141,64,-149,-144,-133,-134,-138,-142,-145,]),'*':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,130,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,130,130,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'PRINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,29,29,-153,-152,-61,29,-76,-56,-156,29,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,29,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,29,-139,29,-3,-60,29,-52,-146,-31,-97,-95,-81,-72,-73,-51,29,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,29,-8,-148,-140,29,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,29,-83,-89,29,-136,29,-141,29,-149,-144,-133,-134,-138,-142,-145,]),'^':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,132,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,132,132,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'AUGOP':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,220,230,234,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,137,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-22,-83,-89,]),';':([6,7,10,11,12,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,88,95,99,115,117,118,122,124,125,127,142,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,187,189,190,207,210,211,215,218,220,230,234,],[-6,-61,-15,-76,-56,86,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,-7,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-100,-99,-98,-117,-113,-22,-83,-89,]),'BININT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,51,51,-153,-152,-61,51,-76,-56,-156,51,-127,-75,-58,-126,51,-124,-78,-23,-129,-65,51,-63,51,-125,-74,-68,-66,-5,51,-50,-32,-79,-156,-30,51,-21,-70,-46,-53,-69,-62,51,-59,-1,-77,-55,-131,-67,-27,51,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,51,-139,51,-3,-60,51,51,51,-52,-146,-42,-40,51,51,-39,51,-34,-35,-41,-37,-38,51,-31,-97,-95,51,51,-81,-72,-73,-51,51,51,51,51,51,51,51,51,-156,51,51,-147,-4,51,-82,-132,51,-26,-25,51,-33,-44,-45,-36,-84,-90,-54,-96,51,-80,51,-28,-29,-47,-48,-49,-112,51,51,-8,-148,-140,51,-156,51,51,-100,51,-99,-98,51,51,-113,-156,-22,-9,-156,-156,-137,51,51,-83,-156,51,-89,51,51,51,-136,51,-141,51,-149,51,-144,-133,-134,-138,51,51,-142,-145,51,51,]),'.':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,133,144,159,163,165,173,184,190,207,210,211,214,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,120,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,182,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,241,-113,-83,-89,]),'WITH':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,9,9,-153,-152,-61,9,-76,-56,-156,9,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,9,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,9,-139,-3,-60,9,-52,-146,-31,-97,-95,-81,-72,-73,-51,9,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,9,-8,-148,-140,9,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,9,-83,-89,9,-136,9,-141,9,-149,-144,-133,-134,-138,-142,-145,]),'NEQ':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,111,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,111,]),'POWER':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,144,159,163,165,173,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,119,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,-113,-83,-89,]),'+':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,32,32,-153,-152,-61,32,-76,-56,-156,32,-127,-75,-58,-126,32,-124,-78,-23,-129,-65,32,-63,32,-125,-74,-68,-66,-5,32,-50,105,-79,-156,-30,32,-21,-70,-46,-53,-69,-62,32,-59,-1,-77,-55,-131,-67,-27,32,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,32,-139,32,-3,-60,32,32,32,-52,-146,-42,-40,32,32,-39,32,-34,-35,-41,-37,-38,32,-31,-97,-95,32,32,-81,-72,-73,-51,32,32,32,32,32,32,32,32,-156,32,32,-147,-4,32,-82,-132,32,-26,-25,32,105,-44,-45,-36,-84,-90,-54,-96,32,-80,32,-28,-29,-47,-48,-49,-112,32,-65,32,-8,-148,-140,32,-156,32,32,-100,32,-99,-98,32,32,-113,-156,-22,-9,-156,-156,-137,32,32,-83,-156,32,-89,32,32,32,-136,32,-141,32,-149,32,-144,-133,-134,-138,32,32,-142,-145,32,32,]),'NEWLINE':([0,1,5,6,7,10,11,12,13,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,43,44,46,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,79,81,86,87,88,95,99,115,117,118,122,124,125,127,136,141,142,144,147,148,154,155,156,158,159,160,162,163,164,165,173,175,176,177,178,179,184,187,189,190,193,202,203,207,210,211,215,218,219,220,222,223,230,231,233,234,253,254,255,264,265,278,279,],[1,-154,79,-6,-61,-15,-76,-56,1,1,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,1,-30,1,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-155,1,1,79,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,1,79,-7,-82,-26,-25,-33,-44,-45,1,-84,-88,1,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-148,-85,1,-100,-99,-98,-117,-113,1,-22,1,1,-83,1,-94,-89,-86,-91,1,-87,1,-92,-93,]),'-':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,67,67,-153,-152,-61,67,-76,-56,-156,67,-127,-75,-58,-126,67,-124,-78,-23,-129,-65,67,-63,67,-125,-74,-68,-66,-5,67,-50,107,-79,-156,-30,67,-21,-70,-46,-53,-69,-62,67,-59,-1,-77,-55,-131,-67,-27,67,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,67,-139,67,-3,-60,67,67,67,-52,-146,-42,-40,67,67,-39,67,-34,-35,-41,-37,-38,67,-31,-97,-95,67,67,-81,-72,-73,-51,67,67,67,67,67,67,67,67,-156,67,67,-147,-4,67,-82,-132,67,-26,-25,67,107,-44,-45,-36,-84,-90,-54,-96,67,-80,67,-28,-29,-47,-48,-49,-112,67,-65,67,-8,-148,-140,67,-156,67,67,-100,67,-99,-98,67,67,-113,-156,-22,-9,-156,-156,-137,67,67,-83,-156,67,-89,67,67,67,-136,67,-141,67,-149,67,-144,-133,-134,-138,67,67,-142,-145,67,67,]),',':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,89,96,98,99,115,117,118,122,123,124,125,127,144,147,148,152,154,155,156,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,180,181,183,184,185,187,189,190,196,197,199,202,207,209,210,211,212,213,218,220,230,233,234,235,236,237,238,239,243,248,251,253,254,256,258,264,270,274,278,279,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,136,-60,136,151,-122,-52,-31,-97,-95,-81,136,-72,-73,-51,-82,-26,-25,151,-33,-44,-45,-84,203,-90,-54,-96,206,-101,-103,-102,-111,-108,-110,-80,-28,-29,-47,-48,-49,-114,214,217,-112,-116,136,136,-65,136,-123,227,231,-100,-105,-99,-98,-106,240,-113,-22,-83,255,-89,-111,-109,-110,-107,-104,-115,136,-150,-86,265,267,-118,-87,-151,-119,-92,-93,]),'/':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,131,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,131,131,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'NEXT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,10,10,-153,-152,-61,10,-76,-56,-156,10,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,10,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,10,-139,10,-3,-60,10,-52,-146,-31,-97,-95,-81,-72,-73,-51,10,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,10,-8,-148,-140,10,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,10,-83,-89,10,-136,10,-141,10,-149,-144,-133,-134,-138,-142,-145,]),'SHORTSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,34,34,-153,-152,-61,34,-76,-56,-156,34,-127,-75,-58,-126,34,-124,-78,-23,-129,-65,34,-63,34,-125,-74,-68,-66,-5,34,-50,-32,-79,-156,-30,34,-156,-21,-70,-46,-53,-69,-62,34,-59,-1,-77,124,-55,-131,-67,-27,34,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,34,-139,34,-3,-60,34,34,34,-52,-146,-42,-40,34,34,-39,34,-34,-35,-41,-37,-38,34,-31,34,-97,-95,34,34,-81,-72,-73,-51,34,34,34,34,34,34,34,34,-156,34,34,-147,-4,34,-82,-132,34,-26,-25,34,-33,-44,-45,-36,-84,-90,-54,-96,34,-80,34,-28,-29,-47,-48,-49,-112,34,34,-8,-148,-140,34,-156,34,34,-100,34,-99,-98,34,34,-113,-156,-22,-9,-156,-156,-137,34,34,-83,-156,34,-89,34,34,34,-136,34,-141,34,-149,34,-156,-144,-133,-134,-138,-156,34,34,34,-142,34,-145,34,34,]),'OPEN_PAREN':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,74,75,76,78,79,80,81,82,84,85,86,87,88,90,91,92,93,99,100,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,53,53,-153,-152,-61,53,-76,-56,-156,53,-127,-75,-58,-126,53,-124,-78,-23,-129,-65,53,-63,53,-125,-74,-68,-66,-5,53,-50,-32,-79,-156,-30,53,-21,-70,-46,-53,-69,-62,53,-59,-1,-77,-55,-131,-67,-27,53,-130,-71,-24,-43,-128,133,134,-57,-64,-2,-155,-143,-156,-135,53,-139,53,-3,143,53,146,53,53,-52,153,-146,-42,-40,53,53,-39,53,-34,-35,-41,-37,-38,53,-31,-97,-95,53,53,-81,-72,-73,-51,53,53,53,53,53,53,53,53,-156,53,53,-147,-4,53,-82,-132,53,-26,-25,53,-33,-44,-45,-36,-84,-90,-54,-96,53,-80,53,-28,-29,-47,-48,-49,-112,53,53,-8,-148,-140,53,-156,53,53,-100,53,-99,-98,53,53,-113,-156,-22,-9,-156,-156,-137,53,53,-83,-156,53,-89,53,53,53,-136,53,-141,53,-149,53,-144,-133,-134,-138,53,53,-142,-145,53,53,]),'OCTINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,35,35,-153,-152,-61,35,-76,-56,-156,35,-127,-75,-58,-126,35,-124,-78,-23,-129,-65,35,-63,35,-125,-74,-68,-66,-5,35,-50,-32,-79,-156,-30,35,-21,-70,-46,-53,-69,-62,35,-59,-1,-77,-55,-131,-67,-27,35,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,35,-139,35,-3,-60,35,35,35,-52,-146,-42,-40,35,35,-39,35,-34,-35,-41,-37,-38,35,-31,-97,-95,35,35,-81,-72,-73,-51,35,35,35,35,35,35,35,35,-156,35,35,-147,-4,35,-82,-132,35,-26,-25,35,-33,-44,-45,-36,-84,-90,-54,-96,35,-80,35,-28,-29,-47,-48,-49,-112,35,35,-8,-148,-140,35,-156,35,35,-100,35,-99,-98,35,35,-113,-156,-22,-9,-156,-156,-137,35,35,-83,-156,35,-89,35,35,35,-136,35,-141,35,-149,35,-144,-133,-134,-138,35,35,-142,-145,35,35,]),'STRPREFIX':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,59,59,-153,-152,-61,59,-76,-56,-156,59,-127,-75,-58,-126,59,-124,-78,-23,-129,-65,59,-63,59,-125,-74,-68,-66,-5,59,-50,-32,-79,-156,-30,59,-156,-21,-70,-46,-53,-69,-62,59,-59,-1,-77,-55,-131,-67,-27,59,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,59,-139,59,-3,-60,59,59,59,-52,-146,-42,-40,59,59,-39,59,-34,-35,-41,-37,-38,59,-31,59,-97,-95,59,59,-81,-72,-73,-51,59,59,59,59,59,59,59,59,-156,59,59,-147,-4,59,-82,-132,59,-26,-25,59,-33,-44,-45,-36,-84,-90,-54,-96,59,-80,59,-28,-29,-47,-48,-49,-112,59,59,-8,-148,-140,59,-156,59,59,-100,59,-99,-98,59,59,-113,-156,-22,-9,-156,-156,-137,59,59,-83,-156,59,-89,59,59,59,-136,59,-141,59,-149,59,-156,-144,-133,-134,-138,-156,59,59,59,-142,59,-145,59,59,]),'INTEGER':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,36,36,-153,-152,-61,36,-76,-56,-156,36,-127,-75,-58,-126,36,-124,-78,-23,-129,-65,36,-63,36,-125,-74,-68,-66,-5,36,-50,-32,-79,-156,-30,36,-21,-70,-46,-53,-69,-62,36,-59,-1,-77,-55,-131,-67,-27,36,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,36,-139,36,-3,-60,36,36,36,-52,-146,-42,-40,36,36,-39,36,-34,-35,-41,-37,-38,36,-31,-97,-95,36,36,-81,-72,-73,-51,36,36,36,36,36,36,36,36,-156,36,36,-147,-4,36,-82,-132,36,-26,-25,36,-33,-44,-45,-36,-84,-90,-54,-96,36,-80,36,-28,-29,-47,-48,-49,-112,36,36,-8,-148,-140,36,-156,36,36,-100,36,-99,-98,36,36,-113,-156,-22,-9,-156,-156,-137,36,36,-83,-156,36,-89,36,36,36,-136,36,-141,36,-149,36,-144,-133,-134,-138,36,36,-142,-145,36,36,]),'IMAGINARY':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,69,69,-153,-152,-61,69,-76,-56,-156,69,-127,-75,-58,-126,69,-124,-78,-23,-129,-65,69,-63,69,-125,-74,-68,-66,-5,69,-50,-32,-79,-156,-30,69,-21,-70,-46,-53,-69,-62,69,-59,-1,-77,-55,-131,-67,-27,69,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,69,-139,69,-3,-60,69,69,69,-52,-146,-42,-40,69,69,-39,69,-34,-35,-41,-37,-38,69,-31,-97,-95,69,69,-81,-72,-73,-51,69,69,69,69,69,69,69,69,-156,69,69,-147,-4,69,-82,-132,69,-26,-25,69,-33,-44,-45,-36,-84,-90,-54,-96,69,-80,69,-28,-29,-47,-48,-49,-112,69,69,-8,-148,-140,69,-156,69,69,-100,69,-99,-98,69,69,-113,-156,-22,-9,-156,-156,-137,69,69,-83,-156,69,-89,69,69,69,-136,69,-141,69,-149,69,-144,-133,-134,-138,69,69,-142,-145,69,69,]),':':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,121,122,124,125,127,144,147,148,154,155,156,159,161,163,164,165,167,168,172,173,175,176,177,178,179,184,190,195,200,206,207,209,210,211,212,218,230,234,237,239,249,272,275,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,168,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,204,-90,-54,-96,208,-103,212,-80,-28,-29,-47,-48,-49,-112,204,224,229,168,-100,-105,-99,-98,-106,-113,-83,-89,212,-104,263,276,277,]),'=':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,126,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,216,218,220,230,234,257,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,135,-60,-52,-31,-97,-95,-81,-72,-73,174,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,242,-113,-22,-83,-89,268,]),'<':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,112,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,112,]),'$end':([1,3,4,5,15,19,22,25,33,37,55,61,68,72,78,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,0,-153,-152,-127,-126,-124,-129,-125,-5,-1,-131,-130,-128,-2,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'FUNCTION':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,38,38,-153,-152,-61,38,-76,-56,-156,38,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,38,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,38,-139,-3,-60,38,-52,-146,-31,-97,-95,-81,-72,-73,-51,38,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,38,-8,-148,-140,38,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,38,-83,-89,38,-136,38,-141,38,-149,-144,-133,-134,-138,-142,-145,]),'REPEAT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,39,39,-153,-152,-61,39,-76,-56,-156,39,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,39,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,39,-139,-3,-60,39,-52,-146,-31,-97,-95,-81,-72,-73,-51,39,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,39,-8,-148,-140,39,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,39,-83,-89,39,-136,39,-141,39,-149,-144,-133,-134,-138,-142,-145,]),'GTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,106,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,106,]),'FOR':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,31,31,-153,-152,-61,31,-76,-56,-156,31,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,31,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,31,-139,-3,-60,31,-52,-146,-31,-97,-95,-81,-72,-73,-51,31,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,31,-8,-148,-140,31,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,31,-83,-89,31,-136,31,-141,31,-149,-144,-133,-134,-138,-142,-145,]),'BADAND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,129,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,129,129,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'ELSEIF':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,91,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'LONGSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,17,17,-153,-152,-61,17,-76,-56,-156,17,-127,-75,-58,-126,17,-124,-78,-23,-129,-65,17,-63,17,-125,-74,-68,-66,-5,17,-50,-32,-79,-156,-30,17,-156,-21,-70,-46,-53,-69,-62,17,-59,-1,-77,125,-55,-131,-67,-27,17,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,17,-139,17,-3,-60,17,17,17,-52,-146,-42,-40,17,17,-39,17,-34,-35,-41,-37,-38,17,-31,17,-97,-95,17,17,-81,-72,-73,-51,17,17,17,17,17,17,17,17,-156,17,17,-147,-4,17,-82,-132,17,-26,-25,17,-33,-44,-45,-36,-84,-90,-54,-96,17,-80,17,-28,-29,-47,-48,-49,-112,17,17,-8,-148,-140,17,-156,17,17,-100,17,-99,-98,17,17,-113,-156,-22,-9,-156,-156,-137,17,17,-83,-156,17,-89,17,17,17,-136,17,-141,17,-149,17,-156,-144,-133,-134,-138,-156,17,17,17,-142,17,-145,17,17,]),'NOT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,114,115,117,118,121,122,124,125,127,128,129,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,45,45,-153,-152,-61,45,-76,-56,-156,45,-127,-75,-58,-126,45,-124,-78,-23,-129,-65,45,-63,-125,-74,-68,-66,-5,45,-50,110,-79,-156,-30,45,-21,-70,-46,-53,-69,-62,45,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,45,-139,45,-3,-60,45,45,45,-52,-146,45,-31,-97,-95,45,-81,-72,-73,-51,45,45,45,45,45,-156,45,45,-147,-4,45,-82,-132,45,-26,-25,45,-33,-44,-45,-84,-90,-54,-96,45,-80,45,-28,-29,-47,-48,-49,-112,45,-65,45,-8,-148,-140,45,-156,45,45,-100,45,-99,-98,45,45,-113,-156,-22,-9,-156,-156,-137,45,45,-83,-156,45,-89,45,45,45,-136,45,-141,45,-149,45,-144,-133,-134,-138,45,45,-142,-145,45,45,]),'AS':([83,94,],[139,149,]),'LTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,103,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,103,]),'IN':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,96,98,99,110,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,197,198,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,109,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,150,-122,-52,157,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-123,226,-100,-99,-98,-113,-83,-89,]),'[':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,229,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,263,267,268,269,273,276,277,],[-156,-154,43,43,-153,-152,-61,43,-76,-56,-156,43,-127,-75,-58,-126,43,-124,-78,-23,-129,-65,43,-63,97,43,-125,-74,-68,-66,-5,43,-50,-32,-79,-156,-30,43,-21,-70,-46,121,-69,-62,43,-59,-1,-77,-55,-131,-67,-27,43,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,43,-139,43,-3,-60,43,43,43,-52,-146,-42,-40,43,43,-39,43,-34,-35,-41,-37,-38,43,-31,-97,-95,43,43,-81,-72,-73,-51,43,43,43,43,43,43,43,43,-156,43,43,-147,-4,43,-82,-132,43,-26,-25,43,-33,-44,-45,-36,-84,-90,-54,-96,43,-80,43,-28,-29,-47,-48,-49,-112,43,-65,43,-8,-148,-140,43,-156,43,43,-100,43,-99,-98,43,43,-113,-156,-22,-9,-156,-156,-137,43,43,43,-83,-156,43,-89,43,43,43,-136,43,-141,43,-149,43,-144,-133,-134,-138,43,43,43,-142,-145,43,43,]),'ELSE':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,90,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),']':([1,4,5,7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,43,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,79,88,98,99,114,115,117,118,122,124,125,127,144,147,148,152,154,155,156,158,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,184,197,201,202,207,209,210,211,212,218,230,234,235,236,237,238,239,253,264,],[-154,-153,-152,-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-156,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-155,-60,-122,-52,159,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,198,-33,-44,-45,-156,-84,-88,-90,-54,-96,207,-101,-103,-102,210,-108,211,-80,-28,-29,-47,-48,-49,-112,-123,230,-85,-100,-105,-99,-98,-106,-113,-83,-89,-111,-109,-110,-107,-104,-86,-87,]),'ID':([0,1,2,3,4,5,7,8,9,11,12,13,14,15,17,18,19,21,22,23,24,25,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,64,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,97,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,120,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,143,144,145,146,147,148,149,150,151,153,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,182,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,224,225,226,227,228,230,231,232,234,240,241,242,244,245,246,247,248,250,252,256,259,260,261,262,267,268,269,273,276,277,],[-156,-154,73,73,-153,-152,-61,73,83,-76,-56,-156,73,-127,-75,-58,-126,88,-124,-78,-23,-129,94,-65,88,-63,98,88,-125,-74,-68,-66,-5,100,73,-50,-32,-79,-156,-30,88,-21,-70,-46,-53,-69,-62,88,-59,-1,-77,-55,-131,-67,126,-27,88,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,73,-139,73,-3,-60,73,88,88,98,-52,-146,-42,-40,88,88,-39,88,-34,-35,-41,-37,-38,88,-31,-97,-95,88,165,88,-81,-72,-73,-51,88,88,88,88,88,88,88,88,-156,88,73,193,-147,-4,88,-82,-132,88,-26,-25,195,88,197,200,-33,-44,-45,-36,-84,-90,-54,-96,88,-80,88,-28,-29,-47,-48,-49,216,-112,88,73,-8,-148,-140,73,-156,88,88,-100,88,-99,-98,88,88,-113,-156,-22,-9,-156,-156,247,-137,88,249,73,-83,-156,88,-89,88,257,88,73,-136,73,-141,73,-149,88,-144,-133,-134,269,-138,88,88,-142,-145,88,88,]),'CLOSE_PAREN':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,53,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,122,123,124,125,127,133,143,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,180,181,183,184,185,186,194,199,207,210,211,218,220,230,234,243,251,258,270,274,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,122,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,-81,173,-72,-73,-51,184,184,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-114,215,218,-112,-116,219,223,228,-100,-99,-98,-113,-22,-83,-89,-115,-150,-118,-151,-119,]),'IF':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,74,74,-153,-152,-61,74,-76,-56,-156,74,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,74,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,74,-139,-3,-60,74,-52,-146,-31,-97,-95,-81,-72,-73,-51,74,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,74,-8,-148,-140,74,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,74,-83,-89,74,-136,74,-141,74,-149,-144,-133,-134,-138,-142,-145,]),'AND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,128,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,128,128,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'`':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,89,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,21,21,-153,-152,-61,21,-76,-56,-156,21,-127,-75,-58,-126,21,-124,-78,-23,-129,-65,21,-63,21,-125,-74,-68,-66,-5,21,-50,-32,-79,-156,-30,21,-21,-70,-46,-53,-69,-62,21,-59,-1,-77,-55,-131,-67,-27,21,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,21,-139,21,-3,-60,144,21,21,21,-52,-146,-42,-40,21,21,-39,21,-34,-35,-41,-37,-38,21,-31,-97,-95,21,21,-81,-72,-73,-51,21,21,21,21,21,21,21,21,-156,21,21,-147,-4,21,-82,-132,21,-26,-25,21,-33,-44,-45,-36,-84,-90,-54,-96,21,-80,21,-28,-29,-47,-48,-49,-112,21,21,-8,-148,-140,21,-156,21,21,-100,21,-99,-98,21,21,-113,-156,-22,-9,-156,-156,-137,21,21,-83,-156,21,-89,21,21,21,-136,21,-141,21,-149,21,-144,-133,-134,-138,21,21,-142,-145,21,21,]),'BADOR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,92,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'BREAK':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,62,62,-153,-152,-61,62,-76,-56,-156,62,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,62,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,62,-139,62,-3,-60,62,-52,-146,-31,-97,-95,-81,-72,-73,-51,62,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,62,-8,-148,-140,62,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,62,-83,-89,62,-136,62,-141,62,-149,-144,-133,-134,-138,-142,-145,]),'HEXINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,63,63,-153,-152,-61,63,-76,-56,-156,63,-127,-75,-58,-126,63,-124,-78,-23,-129,-65,63,-63,63,-125,-74,-68,-66,-5,63,-50,-32,-79,-156,-30,63,-21,-70,-46,-53,-69,-62,63,-59,-1,-77,-55,-131,-67,-27,63,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,63,-139,63,-3,-60,63,63,63,-52,-146,-42,-40,63,63,-39,63,-34,-35,-41,-37,-38,63,-31,-97,-95,63,63,-81,-72,-73,-51,63,63,63,63,63,63,63,63,-156,63,63,-147,-4,63,-82,-132,63,-26,-25,63,-33,-44,-45,-36,-84,-90,-54,-96,63,-80,63,-28,-29,-47,-48,-49,-112,63,63,-8,-148,-140,63,-156,63,63,-100,63,-99,-98,63,63,-113,-156,-22,-9,-156,-156,-137,63,63,-83,-156,63,-89,63,63,63,-136,63,-141,63,-149,63,-144,-133,-134,-138,63,63,-142,-145,63,63,]),'ISEQUAL':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,102,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,102,]),'ITEM_TAG':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,76,76,-153,-152,-61,76,-76,-56,-156,76,-127,-75,-58,-126,76,-124,-78,-23,-129,-65,76,-63,76,-125,-74,-68,-66,-5,76,-50,-32,-79,-156,-30,76,-21,-70,-46,-53,-69,-62,76,-59,-1,-77,-55,-131,-67,-27,76,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,76,-139,76,-3,-60,76,76,76,-52,-146,-42,-40,76,76,-39,76,-34,-35,-41,-37,-38,76,-31,-97,-95,76,76,-81,-72,-73,-51,76,76,76,76,76,76,76,76,-156,76,76,-147,-4,76,-82,-132,76,-26,-25,76,-33,-44,-45,-36,-84,-90,-54,-96,76,-80,76,-28,-29,-47,-48,-49,-112,76,76,-8,-148,-140,76,-156,76,76,-100,76,-99,-98,76,76,-113,-156,-22,-9,-156,-156,-137,76,76,-83,-156,76,-89,76,76,76,-136,76,-141,76,-149,76,-144,-133,-134,-138,76,76,-142,-145,76,76,]),'{':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,46,46,-153,-152,-61,81,-76,-56,-156,81,-127,-75,-58,-126,46,-124,-78,-23,-129,-65,46,-63,46,-125,-74,-68,-66,-5,81,-50,-32,-79,-156,-30,46,-21,-70,-46,-53,-69,-62,46,-59,-1,-77,-55,-131,-67,-27,46,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,81,-139,46,-3,-60,81,46,46,-52,-146,-42,-40,46,46,-39,46,-34,-35,-41,-37,-38,46,-31,-97,-95,46,46,-81,-72,-73,-51,46,46,46,46,46,46,46,46,-156,46,46,-147,-4,46,-82,-132,46,-26,-25,46,-33,-44,-45,-36,-84,-90,-54,-96,46,-80,46,-28,-29,-47,-48,-49,-112,46,46,-8,-148,-140,81,-156,46,46,-100,46,-99,-98,46,46,-113,-156,-22,-9,-156,-156,-137,46,81,-83,-156,46,-89,46,46,81,-136,81,-141,81,-149,46,-144,-133,-134,-138,46,46,-142,-145,46,46,]),'>':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,113,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,113,]),'}':([1,4,5,7,11,12,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,40,41,42,44,46,48,49,50,51,52,54,56,60,61,63,65,68,69,70,71,72,75,76,79,80,81,82,85,87,88,99,101,115,116,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,162,163,164,165,173,175,176,177,178,179,184,191,192,205,207,210,211,218,221,222,225,230,233,234,245,250,254,259,260,262,278,279,],[-154,-153,-152,-61,-76,-56,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,-50,-32,-79,-30,-156,-70,-46,-53,-69,-62,-59,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-155,-143,-156,-135,-139,-3,-60,-52,-146,-31,163,-97,-95,-81,-72,-73,-51,163,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-156,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,222,-8,234,-100,-99,-98,-113,-9,-156,-137,-83,-94,-89,-136,-149,-91,-133,-134,-138,-92,-93,]),'OR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,93,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'LOOP':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,26,26,-153,-152,-61,26,-76,-56,-156,26,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,26,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,26,-139,-3,-60,26,-52,-146,-31,-97,-95,-81,-72,-73,-51,26,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,26,-8,-148,-140,26,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,26,-83,-89,26,-136,26,-141,26,-149,-144,-133,-134,-138,-142,-145,]),}
-
-_lr_action = { }
-for _k, _v in _lr_action_items.items():
-   for _x,_y in zip(_v[0],_v[1]):
-      if not _x in _lr_action:  _lr_action[_x] = { }
-      _lr_action[_x][_k] = _y
-del _lr_action_items
-
-_lr_goto_items = {'statements':([138,],[191,]),'comp_operator':([41,],[104,]),'small_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[6,6,6,6,6,6,142,6,6,6,6,6,6,6,6,]),'fancy_drel_assignment_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,]),'primary':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,]),'stringliteral':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,116,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,266,267,268,271,276,277,],[28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,161,28,28,28,28,28,28,28,28,28,28,28,190,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,272,28,28,275,28,28,]),'item_tag':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,]),'not_test':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[65,65,65,65,65,65,65,115,65,65,65,65,65,65,65,65,175,176,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,]),'listmaker':([114,],[158,]),'do_stmt_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[8,8,8,8,8,8,8,8,8,8,8,8,8,8,]),'func_arg':([133,143,217,],[180,180,243,]),'enclosure':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,]),'newlines':([0,13,16,43,46,81,86,136,158,162,203,219,222,223,231,255,265,],[5,5,87,5,5,5,141,5,5,5,5,5,5,5,5,5,5,]),'break_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,]),'dotlist':([133,],[181,]),'arglist':([153,],[199,]),'repeat_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[68,68,68,68,68,68,68,68,68,68,68,68,68,68,]),'u_expr':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[49,49,49,49,49,49,99,49,49,49,127,49,49,49,49,49,49,49,49,49,164,49,49,49,177,178,179,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,]),'if_else_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,]),'parenth_form':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,]),'literal':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,]),'attributeref':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,]),'call':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,]),'argument_list':([133,143,],[183,183,]),'statement':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[55,78,82,82,82,82,82,192,221,82,82,82,82,82,]),'string_conversion':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,]),'with_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[13,13,13,13,13,13,13,13,13,13,13,13,13,13,]),'input':([0,],[3,]),'loop_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[14,14,14,14,14,14,14,14,14,14,14,14,14,14,]),'do_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[15,15,15,15,15,15,15,15,15,15,15,15,15,15,]),'next_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,]),'empty':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,]),'listmaker2':([160,],[202,]),'short_slice':([121,206,],[167,167,]),'power':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,]),'a_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[41,41,41,41,41,41,41,41,41,41,41,41,41,41,154,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,]),'print_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,]),'and_test':([2,3,8,14,21,29,39,53,84,86,90,92,93,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[70,70,70,70,70,70,70,70,70,70,70,147,148,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,]),'maybe_nline':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[2,84,114,116,138,188,201,205,232,244,245,246,252,266,271,]),'tablemaker2':([233,],[254,]),'slicing':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,]),'for_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[19,19,19,19,19,19,19,19,19,19,19,19,19,19,]),'m_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,105,107,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,155,156,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,]),'table_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,]),'restricted_comp_operator':([41,247,],[108,261,]),'atom':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,]),'funcdef':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[61,61,61,61,61,61,61,61,61,61,61,61,61,61,]),'expr_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,]),'slice_list':([121,],[166,]),'subscription':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,]),'comparison':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,]),'attribute_tag':([50,],[118,]),'if_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[22,22,22,22,22,22,22,22,22,22,22,22,22,22,]),'id_list':([31,97,],[96,152,]),'proper_slice':([121,206,],[170,235,]),'list_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,229,232,240,242,244,246,248,252,263,267,268,276,277,],[23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,251,23,23,23,23,23,23,23,270,23,23,23,23,]),'loop_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[72,72,72,72,72,72,72,72,72,72,72,72,72,72,]),'or_test':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,]),'compound_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[37,37,37,37,37,37,37,37,37,37,37,37,37,37,]),'with_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[25,25,25,25,25,25,25,25,25,25,25,25,25,25,]),'tablemaker':([116,138,],[162,162,]),'long_slice':([121,206,],[169,169,]),'suite':([8,14,39,84,90,196,228,244,246,248,],[80,85,101,140,145,225,250,259,260,262,]),'simple_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[16,16,16,16,16,16,16,16,16,16,16,16,16,16,]),'testlist_star_expr':([2,3,8,14,21,39,53,84,86,90,135,137,138,150,191,196,226,228,244,246,248,],[77,77,77,77,89,77,123,77,77,77,187,189,77,196,77,77,248,77,77,77,77,]),'slice_item':([121,206,],[171,236,]),'expression':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[47,47,47,47,47,95,47,47,47,47,47,160,172,185,186,47,47,47,185,194,47,209,213,220,47,47,233,237,238,239,185,47,47,253,256,258,47,47,47,264,273,274,278,279,]),}
-
-_lr_goto = { }
-for _k, _v in _lr_goto_items.items():
-   for _x,_y in zip(_v[0],_v[1]):
-       if not _x in _lr_goto: _lr_goto[_x] = { }
-       _lr_goto[_x][_k] = _y
-del _lr_goto_items
-_lr_productions = [
-  ("S' -> input","S'",1,None,None,None),
-  ('input -> maybe_nline statement','input',2,'p_input','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',19),
-  ('input -> input statement','input',2,'p_input','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',20),
-  ('statement -> simple_stmt newlines','statement',2,'p_statement','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',36),
-  ('statement -> simple_stmt ; newlines','statement',3,'p_statement','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',37),
-  ('statement -> compound_stmt','statement',1,'p_statement','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',38),
-  ('simple_stmt -> small_stmt','simple_stmt',1,'p_simple_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',44),
-  ('simple_stmt -> simple_stmt ; small_stmt','simple_stmt',3,'p_simple_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',45),
-  ('statements -> statement','statements',1,'p_statements','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',55),
-  ('statements -> statements statement','statements',2,'p_statements','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',56),
-  ('small_stmt -> expr_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',61),
-  ('small_stmt -> print_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',62),
-  ('small_stmt -> break_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',63),
-  ('small_stmt -> next_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',64),
-  ('break_stmt -> BREAK','break_stmt',1,'p_break_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',68),
-  ('next_stmt -> NEXT','next_stmt',1,'p_next_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',72),
-  ('print_stmt -> PRINT expression','print_stmt',2,'p_print_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',76),
-  ('expr_stmt -> testlist_star_expr','expr_stmt',1,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',84),
-  ('expr_stmt -> testlist_star_expr AUGOP testlist_star_expr','expr_stmt',3,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',85),
-  ('expr_stmt -> testlist_star_expr = testlist_star_expr','expr_stmt',3,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',86),
-  ('expr_stmt -> fancy_drel_assignment_stmt','expr_stmt',1,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',87),
-  ('testlist_star_expr -> expression','testlist_star_expr',1,'p_testlist_star_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',96),
-  ('testlist_star_expr -> testlist_star_expr , maybe_nline expression','testlist_star_expr',4,'p_testlist_star_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',97),
-  ('expression -> or_test','expression',1,'p_expression','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',107),
-  ('or_test -> and_test','or_test',1,'p_or_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',115),
-  ('or_test -> or_test OR and_test','or_test',3,'p_or_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',116),
-  ('or_test -> or_test BADOR and_test','or_test',3,'p_or_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',117),
-  ('and_test -> not_test','and_test',1,'p_and_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',122),
-  ('and_test -> and_test AND not_test','and_test',3,'p_and_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',123),
-  ('and_test -> and_test BADAND not_test','and_test',3,'p_and_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',124),
-  ('not_test -> comparison','not_test',1,'p_not_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',129),
-  ('not_test -> NOT not_test','not_test',2,'p_not_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',130),
-  ('comparison -> a_expr','comparison',1,'p_comparison','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',135),
-  ('comparison -> a_expr comp_operator a_expr','comparison',3,'p_comparison','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',136),
-  ('comp_operator -> restricted_comp_operator','comp_operator',1,'p_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',142),
-  ('comp_operator -> IN','comp_operator',1,'p_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',143),
-  ('comp_operator -> NOT IN','comp_operator',2,'p_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',144),
-  ('restricted_comp_operator -> <','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',150),
-  ('restricted_comp_operator -> >','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',151),
-  ('restricted_comp_operator -> GTE','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',152),
-  ('restricted_comp_operator -> LTE','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',153),
-  ('restricted_comp_operator -> NEQ','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',154),
-  ('restricted_comp_operator -> ISEQUAL','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',155),
-  ('a_expr -> m_expr','a_expr',1,'p_a_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',159),
-  ('a_expr -> a_expr + m_expr','a_expr',3,'p_a_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',160),
-  ('a_expr -> a_expr - m_expr','a_expr',3,'p_a_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',161),
-  ('m_expr -> u_expr','m_expr',1,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',168),
-  ('m_expr -> m_expr * u_expr','m_expr',3,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',169),
-  ('m_expr -> m_expr / u_expr','m_expr',3,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',170),
-  ('m_expr -> m_expr ^ u_expr','m_expr',3,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',171),
-  ('u_expr -> power','u_expr',1,'p_u_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',178),
-  ('u_expr -> - u_expr','u_expr',2,'p_u_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',179),
-  ('u_expr -> + u_expr','u_expr',2,'p_u_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',180),
-  ('power -> primary','power',1,'p_power','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',187),
-  ('power -> primary POWER u_expr','power',3,'p_power','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',188),
-  ('primary -> atom','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',196),
-  ('primary -> attributeref','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',197),
-  ('primary -> subscription','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',198),
-  ('primary -> slicing','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',199),
-  ('primary -> call','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',200),
-  ('atom -> ID','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',205),
-  ('atom -> item_tag','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',206),
-  ('atom -> literal','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',207),
-  ('atom -> enclosure','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',208),
-  ('item_tag -> ITEM_TAG','item_tag',1,'p_item_tag','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',213),
-  ('literal -> stringliteral','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',217),
-  ('literal -> INTEGER','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',218),
-  ('literal -> HEXINT','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',219),
-  ('literal -> OCTINT','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',220),
-  ('literal -> BININT','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',221),
-  ('literal -> REAL','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',222),
-  ('literal -> IMAGINARY','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',223),
-  ('stringliteral -> STRPREFIX SHORTSTRING','stringliteral',2,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',228),
-  ('stringliteral -> STRPREFIX LONGSTRING','stringliteral',2,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',229),
-  ('stringliteral -> SHORTSTRING','stringliteral',1,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',230),
-  ('stringliteral -> LONGSTRING','stringliteral',1,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',231),
-  ('enclosure -> parenth_form','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',236),
-  ('enclosure -> string_conversion','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',237),
-  ('enclosure -> list_display','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',238),
-  ('enclosure -> table_display','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',239),
-  ('parenth_form -> OPEN_PAREN testlist_star_expr CLOSE_PAREN','parenth_form',3,'p_parenth_form','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',243),
-  ('parenth_form -> OPEN_PAREN CLOSE_PAREN','parenth_form',2,'p_parenth_form','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',244),
-  ('string_conversion -> ` testlist_star_expr `','string_conversion',3,'p_string_conversion','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',251),
-  ('list_display -> [ maybe_nline listmaker maybe_nline ]','list_display',5,'p_list_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',256),
-  ('list_display -> [ maybe_nline ]','list_display',3,'p_list_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',257),
-  ('listmaker -> expression listmaker2','listmaker',2,'p_listmaker','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',265),
-  ('listmaker2 -> , maybe_nline expression','listmaker2',3,'p_listmaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',270),
-  ('listmaker2 -> listmaker2 , maybe_nline expression','listmaker2',4,'p_listmaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',271),
-  ('listmaker2 -> <empty>','listmaker2',0,'p_listmaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',272),
-  ('table_display -> { maybe_nline tablemaker maybe_nline }','table_display',5,'p_table_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',282),
-  ('table_display -> { maybe_nline }','table_display',3,'p_table_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',283),
-  ('tablemaker -> stringliteral : expression tablemaker2','tablemaker',4,'p_tablemaker','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',290),
-  ('tablemaker2 -> , maybe_nline stringliteral : expression','tablemaker2',5,'p_tablemaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',294),
-  ('tablemaker2 -> tablemaker2 , maybe_nline stringliteral : expression','tablemaker2',6,'p_tablemaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',295),
-  ('tablemaker2 -> <empty>','tablemaker2',0,'p_tablemaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',296),
-  ('attributeref -> primary attribute_tag','attributeref',2,'p_attributeref','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',310),
-  ('attribute_tag -> . ID','attribute_tag',2,'p_attribute_tag','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',314),
-  ('attribute_tag -> REAL','attribute_tag',1,'p_attribute_tag','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',315),
-  ('subscription -> primary [ expression ]','subscription',4,'p_subscription','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',322),
-  ('slicing -> primary [ proper_slice ]','slicing',4,'p_slicing','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',326),
-  ('slicing -> primary [ slice_list ]','slicing',4,'p_slicing','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',327),
-  ('proper_slice -> short_slice','proper_slice',1,'p_proper_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',331),
-  ('proper_slice -> long_slice','proper_slice',1,'p_proper_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',332),
-  ('short_slice -> :','short_slice',1,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',343),
-  ('short_slice -> expression : expression','short_slice',3,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',344),
-  ('short_slice -> : expression','short_slice',2,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',345),
-  ('short_slice -> expression :','short_slice',2,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',346),
-  ('long_slice -> short_slice : expression','long_slice',3,'p_long_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',355),
-  ('slice_list -> slice_item','slice_list',1,'p_slice_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',362),
-  ('slice_list -> slice_list , slice_item','slice_list',3,'p_slice_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',363),
-  ('slice_item -> expression','slice_item',1,'p_slice_item','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',370),
-  ('slice_item -> proper_slice','slice_item',1,'p_slice_item','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',371),
-  ('call -> ID OPEN_PAREN CLOSE_PAREN','call',3,'p_call','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',375),
-  ('call -> ID OPEN_PAREN argument_list CLOSE_PAREN','call',4,'p_call','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',376),
-  ('argument_list -> func_arg','argument_list',1,'p_argument_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',386),
-  ('argument_list -> argument_list , func_arg','argument_list',3,'p_argument_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',387),
-  ('func_arg -> expression','func_arg',1,'p_func_arg','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',394),
-  ('fancy_drel_assignment_stmt -> ID OPEN_PAREN dotlist CLOSE_PAREN','fancy_drel_assignment_stmt',4,'p_fancy_drel_assignment_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',398),
-  ('dotlist -> . ID = expression','dotlist',4,'p_dotlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',405),
-  ('dotlist -> dotlist , . ID = expression','dotlist',6,'p_dotlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',406),
-  ('exprlist -> a_expr','exprlist',1,'p_exprlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',413),
-  ('exprlist -> exprlist , a_expr','exprlist',3,'p_exprlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',414),
-  ('id_list -> ID','id_list',1,'p_id_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',421),
-  ('id_list -> id_list , ID','id_list',3,'p_id_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',422),
-  ('compound_stmt -> if_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',433),
-  ('compound_stmt -> if_else_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',434),
-  ('compound_stmt -> for_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',435),
-  ('compound_stmt -> do_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',436),
-  ('compound_stmt -> loop_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',437),
-  ('compound_stmt -> with_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',438),
-  ('compound_stmt -> repeat_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',439),
-  ('compound_stmt -> funcdef','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',440),
-  ('if_else_stmt -> if_stmt ELSE suite','if_else_stmt',3,'p_if_else_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',447),
-  ('if_stmt -> IF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',6,'p_if_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',453),
-  ('if_stmt -> if_stmt ELSEIF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',7,'p_if_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',454),
-  ('suite -> statement','suite',1,'p_suite','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',473),
-  ('suite -> { maybe_nline statements } maybe_nline','suite',5,'p_suite','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',474),
-  ('for_stmt -> FOR id_list IN testlist_star_expr suite','for_stmt',5,'p_for_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',481),
-  ('for_stmt -> FOR [ id_list ] IN testlist_star_expr suite','for_stmt',7,'p_for_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',482),
-  ('loop_stmt -> loop_head suite','loop_stmt',2,'p_loop_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',489),
-  ('loop_head -> LOOP ID AS ID','loop_head',4,'p_loop_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',495),
-  ('loop_head -> LOOP ID AS ID : ID','loop_head',6,'p_loop_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',496),
-  ('loop_head -> LOOP ID AS ID : ID restricted_comp_operator ID','loop_head',8,'p_loop_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',497),
-  ('do_stmt -> do_stmt_head suite','do_stmt',2,'p_do_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',508),
-  ('do_stmt_head -> DO ID = expression , expression','do_stmt_head',6,'p_do_stmt_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',515),
-  ('do_stmt_head -> DO ID = expression , expression , expression','do_stmt_head',8,'p_do_stmt_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',516),
-  ('repeat_stmt -> REPEAT suite','repeat_stmt',2,'p_repeat_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',525),
-  ('with_stmt -> with_head maybe_nline suite','with_stmt',3,'p_with_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',529),
-  ('with_head -> WITH ID AS ID','with_head',4,'p_with_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',533),
-  ('funcdef -> FUNCTION ID OPEN_PAREN arglist CLOSE_PAREN suite','funcdef',6,'p_funcdef','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',537),
-  ('arglist -> ID : list_display','arglist',3,'p_arglist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',541),
-  ('arglist -> arglist , ID : list_display','arglist',5,'p_arglist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',542),
-  ('maybe_nline -> newlines','maybe_nline',1,'p_maybe_nline','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',549),
-  ('maybe_nline -> empty','maybe_nline',1,'p_maybe_nline','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',550),
-  ('newlines -> NEWLINE','newlines',1,'p_newlines','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',557),
-  ('newlines -> newlines NEWLINE','newlines',2,'p_newlines','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',558),
-  ('empty -> <empty>','empty',0,'p_empty','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',562),
-]
+
+# parsetab.py
+# This file is automatically generated. Do not edit.
+_tabversion = '3.2'
+
+_lr_method = 'LALR'
+
+_lr_signature = '\xcc\x83\xf4<b8\x10\xb6\xfb\xc5z\x19\xd2\x9e\xc0\xa0'
+    
+_lr_action_items = {'REAL':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,48,48,-153,-152,-61,48,-76,-56,-156,48,-127,-75,-58,-126,48,-124,-78,-23,-129,-65,48,-63,48,-125,-74,-68,-66,-5,48,-50,-32,-79,-156,-30,48,-21,-70,-46,117,-69,-62,48,-59,-1,-77,-55,-131,-67,-27,48,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,48,-139,48,-3,-60,48,48,48,-52,-146,-42,-40,48,48,-39,48,-34,-35,-41,-37,-38,48,-31,-97,-95,48,48,-81,-72,-73,-51,48,48,48,48,48,48,48,48,-156,48,48,-147,-4,48,-82,-132,48,-26,-25,48,-33,-44,-45,-36,-84,-90,-54,-96,48,-80,48,-28,-29,-47,-48,-49,-112,48,-65,48,-8,-148,-140,48,-156,48,48,-100,48,-99,-98,48,48,-113,-156,-22,-9,-156,-156,-137,48,48,-83,-156,48,-89,48,48,48,-136,48,-141,48,-149,48,-144,-133,-134,-138,48,48,-142,-145,48,48,]),'DO':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,64,64,-153,-152,-61,64,-76,-56,-156,64,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,64,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,64,-139,-3,-60,64,-52,-146,-31,-97,-95,-81,-72,-73,-51,64,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,64,-8,-148,-140,64,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,64,-83,-89,64,-136,64,-141,64,-149,-144,-133,-134,-138,-142,-145,]),'*':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,130,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,130,130,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'PRINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,29,29,-153,-152,-61,29,-76,-56,-156,29,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,29,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,29,-139,29,-3,-60,29,-52,-146,-31,-97,-95,-81,-72,-73,-51,29,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,29,-8,-148,-140,29,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,29,-83,-89,29,-136,29,-141,29,-149,-144,-133,-134,-138,-142,-145,]),'^':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,132,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,132,132,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'AUGOP':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,220,230,234,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,137,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-22,-83,-89,]),';':([6,7,10,11,12,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,88,95,99,115,117,118,122,124,125,127,142,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,187,189,190,207,210,211,215,218,220,230,234,],[-6,-61,-15,-76,-56,86,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,-7,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-100,-99,-98,-117,-113,-22,-83,-89,]),'BININT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,51,51,-153,-152,-61,51,-76,-56,-156,51,-127,-75,-58,-126,51,-124,-78,-23,-129,-65,51,-63,51,-125,-74,-68,-66,-5,51,-50,-32,-79,-156,-30,51,-21,-70,-46,-53,-69,-62,51,-59,-1,-77,-55,-131,-67,-27,51,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,51,-139,51,-3,-60,51,51,51,-52,-146,-42,-40,51,51,-39,51,-34,-35,-41,-37,-38,51,-31,-97,-95,51,51,-81,-72,-73,-51,51,51,51,51,51,51,51,51,-156,51,51,-147,-4,51,-82,-132,51,-26,-25,51,-33,-44,-45,-36,-84,-90,-54,-96,51,-80,51,-28,-29,-47,-48,-49,-112,51,51,-8,-148,-140,51,-156,51,51,-100,51,-99,-98,51,51,-113,-156,-22,-9,-156,-156,-137,51,51,-83,-156,51,-89,51,51,51,-136,51,-141,51,-149,51,-144,-133,-134,-138,51,51,-142,-145,51,51,]),'.':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,133,144,159,163,165,173,184,190,207,210,211,214,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,120,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,182,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,241,-113,-83,-89,]),'WITH':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,9,9,-153,-152,-61,9,-76,-56,-156,9,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,9,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,9,-139,-3,-60,9,-52,-146,-31,-97,-95,-81,-72,-73,-51,9,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,9,-8,-148,-140,9,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,9,-83,-89,9,-136,9,-141,9,-149,-144,-133,-134,-138,-142,-145,]),'NEQ':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,111,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,111,]),'POWER':([7,11,12,17,18,23,28,30,34,35,36,42,48,50,51,52,54,56,60,63,69,73,75,76,88,117,118,122,124,125,144,159,163,165,173,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-79,-70,119,-69,-62,-59,-77,-55,-67,-71,-60,-57,-64,-60,-97,-95,-81,-72,-73,-82,-84,-90,-96,-80,-112,-65,-100,-99,-98,-113,-83,-89,]),'+':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,32,32,-153,-152,-61,32,-76,-56,-156,32,-127,-75,-58,-126,32,-124,-78,-23,-129,-65,32,-63,32,-125,-74,-68,-66,-5,32,-50,105,-79,-156,-30,32,-21,-70,-46,-53,-69,-62,32,-59,-1,-77,-55,-131,-67,-27,32,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,32,-139,32,-3,-60,32,32,32,-52,-146,-42,-40,32,32,-39,32,-34,-35,-41,-37,-38,32,-31,-97,-95,32,32,-81,-72,-73,-51,32,32,32,32,32,32,32,32,-156,32,32,-147,-4,32,-82,-132,32,-26,-25,32,105,-44,-45,-36,-84,-90,-54,-96,32,-80,32,-28,-29,-47,-48,-49,-112,32,-65,32,-8,-148,-140,32,-156,32,32,-100,32,-99,-98,32,32,-113,-156,-22,-9,-156,-156,-137,32,32,-83,-156,32,-89,32,32,32,-136,32,-141,32,-149,32,-144,-133,-134,-138,32,32,-142,-145,32,32,]),'NEWLINE':([0,1,5,6,7,10,11,12,13,16,17,18,20,23,24,27,28,30,34,35,36,40,41,42,43,44,46,47,48,49,50,51,52,54,56,57,58,60,62,63,65,66,69,70,71,73,75,76,77,79,81,86,87,88,95,99,115,117,118,122,124,125,127,136,141,142,144,147,148,154,155,156,158,159,160,162,163,164,165,173,175,176,177,178,179,184,187,189,190,193,202,203,207,210,211,215,218,219,220,222,223,230,231,233,234,253,254,255,264,265,278,279,],[1,-154,79,-6,-61,-15,-76,-56,1,1,-75,-58,-10,-78,-23,-20,-65,-63,-74,-68,-66,-50,-32,-79,1,-30,1,-21,-70,-46,-53,-69,-62,-59,-77,-13,-11,-55,-14,-67,-27,-12,-71,-24,-43,-60,-57,-64,-17,-155,1,1,79,-60,-16,-52,-31,-97,-95,-81,-72,-73,-51,1,79,-7,-82,-26,-25,-33,-44,-45,1,-84,-88,1,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-19,-18,-65,-148,-85,1,-100,-99,-98,-117,-113,1,-22,1,1,-83,1,-94,-89,-86,-91,1,-87,1,-92,-93,]),'-':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,67,67,-153,-152,-61,67,-76,-56,-156,67,-127,-75,-58,-126,67,-124,-78,-23,-129,-65,67,-63,67,-125,-74,-68,-66,-5,67,-50,107,-79,-156,-30,67,-21,-70,-46,-53,-69,-62,67,-59,-1,-77,-55,-131,-67,-27,67,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,67,-139,67,-3,-60,67,67,67,-52,-146,-42,-40,67,67,-39,67,-34,-35,-41,-37,-38,67,-31,-97,-95,67,67,-81,-72,-73,-51,67,67,67,67,67,67,67,67,-156,67,67,-147,-4,67,-82,-132,67,-26,-25,67,107,-44,-45,-36,-84,-90,-54,-96,67,-80,67,-28,-29,-47,-48,-49,-112,67,-65,67,-8,-148,-140,67,-156,67,67,-100,67,-99,-98,67,67,-113,-156,-22,-9,-156,-156,-137,67,67,-83,-156,67,-89,67,67,67,-136,67,-141,67,-149,67,-144,-133,-134,-138,67,67,-142,-145,67,67,]),',':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,89,96,98,99,115,117,118,122,123,124,125,127,144,147,148,152,154,155,156,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,180,181,183,184,185,187,189,190,196,197,199,202,207,209,210,211,212,213,218,220,230,233,234,235,236,237,238,239,243,248,251,253,254,256,258,264,270,274,278,279,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,136,-60,136,151,-122,-52,-31,-97,-95,-81,136,-72,-73,-51,-82,-26,-25,151,-33,-44,-45,-84,203,-90,-54,-96,206,-101,-103,-102,-111,-108,-110,-80,-28,-29,-47,-48,-49,-114,214,217,-112,-116,136,136,-65,136,-123,227,231,-100,-105,-99,-98,-106,240,-113,-22,-83,255,-89,-111,-109,-110,-107,-104,-115,136,-150,-86,265,267,-118,-87,-151,-119,-92,-93,]),'/':([7,11,12,17,18,23,28,30,34,35,36,40,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,131,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,131,131,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'NEXT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,10,10,-153,-152,-61,10,-76,-56,-156,10,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,10,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,10,-139,10,-3,-60,10,-52,-146,-31,-97,-95,-81,-72,-73,-51,10,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,10,-8,-148,-140,10,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,10,-83,-89,10,-136,10,-141,10,-149,-144,-133,-134,-138,-142,-145,]),'SHORTSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,34,34,-153,-152,-61,34,-76,-56,-156,34,-127,-75,-58,-126,34,-124,-78,-23,-129,-65,34,-63,34,-125,-74,-68,-66,-5,34,-50,-32,-79,-156,-30,34,-156,-21,-70,-46,-53,-69,-62,34,-59,-1,-77,124,-55,-131,-67,-27,34,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,34,-139,34,-3,-60,34,34,34,-52,-146,-42,-40,34,34,-39,34,-34,-35,-41,-37,-38,34,-31,34,-97,-95,34,34,-81,-72,-73,-51,34,34,34,34,34,34,34,34,-156,34,34,-147,-4,34,-82,-132,34,-26,-25,34,-33,-44,-45,-36,-84,-90,-54,-96,34,-80,34,-28,-29,-47,-48,-49,-112,34,34,-8,-148,-140,34,-156,34,34,-100,34,-99,-98,34,34,-113,-156,-22,-9,-156,-156,-137,34,34,-83,-156,34,-89,34,34,34,-136,34,-141,34,-149,34,-156,-144,-133,-134,-138,-156,34,34,34,-142,34,-145,34,34,]),'OPEN_PAREN':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,74,75,76,78,79,80,81,82,84,85,86,87,88,90,91,92,93,99,100,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,53,53,-153,-152,-61,53,-76,-56,-156,53,-127,-75,-58,-126,53,-124,-78,-23,-129,-65,53,-63,53,-125,-74,-68,-66,-5,53,-50,-32,-79,-156,-30,53,-21,-70,-46,-53,-69,-62,53,-59,-1,-77,-55,-131,-67,-27,53,-130,-71,-24,-43,-128,133,134,-57,-64,-2,-155,-143,-156,-135,53,-139,53,-3,143,53,146,53,53,-52,153,-146,-42,-40,53,53,-39,53,-34,-35,-41,-37,-38,53,-31,-97,-95,53,53,-81,-72,-73,-51,53,53,53,53,53,53,53,53,-156,53,53,-147,-4,53,-82,-132,53,-26,-25,53,-33,-44,-45,-36,-84,-90,-54,-96,53,-80,53,-28,-29,-47,-48,-49,-112,53,53,-8,-148,-140,53,-156,53,53,-100,53,-99,-98,53,53,-113,-156,-22,-9,-156,-156,-137,53,53,-83,-156,53,-89,53,53,53,-136,53,-141,53,-149,53,-144,-133,-134,-138,53,53,-142,-145,53,53,]),'OCTINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,35,35,-153,-152,-61,35,-76,-56,-156,35,-127,-75,-58,-126,35,-124,-78,-23,-129,-65,35,-63,35,-125,-74,-68,-66,-5,35,-50,-32,-79,-156,-30,35,-21,-70,-46,-53,-69,-62,35,-59,-1,-77,-55,-131,-67,-27,35,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,35,-139,35,-3,-60,35,35,35,-52,-146,-42,-40,35,35,-39,35,-34,-35,-41,-37,-38,35,-31,-97,-95,35,35,-81,-72,-73,-51,35,35,35,35,35,35,35,35,-156,35,35,-147,-4,35,-82,-132,35,-26,-25,35,-33,-44,-45,-36,-84,-90,-54,-96,35,-80,35,-28,-29,-47,-48,-49,-112,35,35,-8,-148,-140,35,-156,35,35,-100,35,-99,-98,35,35,-113,-156,-22,-9,-156,-156,-137,35,35,-83,-156,35,-89,35,35,35,-136,35,-141,35,-149,35,-144,-133,-134,-138,35,35,-142,-145,35,35,]),'STRPREFIX':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,59,59,-153,-152,-61,59,-76,-56,-156,59,-127,-75,-58,-126,59,-124,-78,-23,-129,-65,59,-63,59,-125,-74,-68,-66,-5,59,-50,-32,-79,-156,-30,59,-156,-21,-70,-46,-53,-69,-62,59,-59,-1,-77,-55,-131,-67,-27,59,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,59,-139,59,-3,-60,59,59,59,-52,-146,-42,-40,59,59,-39,59,-34,-35,-41,-37,-38,59,-31,59,-97,-95,59,59,-81,-72,-73,-51,59,59,59,59,59,59,59,59,-156,59,59,-147,-4,59,-82,-132,59,-26,-25,59,-33,-44,-45,-36,-84,-90,-54,-96,59,-80,59,-28,-29,-47,-48,-49,-112,59,59,-8,-148,-140,59,-156,59,59,-100,59,-99,-98,59,59,-113,-156,-22,-9,-156,-156,-137,59,59,-83,-156,59,-89,59,59,59,-136,59,-141,59,-149,59,-156,-144,-133,-134,-138,-156,59,59,59,-142,59,-145,59,59,]),'INTEGER':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,36,36,-153,-152,-61,36,-76,-56,-156,36,-127,-75,-58,-126,36,-124,-78,-23,-129,-65,36,-63,36,-125,-74,-68,-66,-5,36,-50,-32,-79,-156,-30,36,-21,-70,-46,-53,-69,-62,36,-59,-1,-77,-55,-131,-67,-27,36,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,36,-139,36,-3,-60,36,36,36,-52,-146,-42,-40,36,36,-39,36,-34,-35,-41,-37,-38,36,-31,-97,-95,36,36,-81,-72,-73,-51,36,36,36,36,36,36,36,36,-156,36,36,-147,-4,36,-82,-132,36,-26,-25,36,-33,-44,-45,-36,-84,-90,-54,-96,36,-80,36,-28,-29,-47,-48,-49,-112,36,36,-8,-148,-140,36,-156,36,36,-100,36,-99,-98,36,36,-113,-156,-22,-9,-156,-156,-137,36,36,-83,-156,36,-89,36,36,36,-136,36,-141,36,-149,36,-144,-133,-134,-138,36,36,-142,-145,36,36,]),'IMAGINARY':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,69,69,-153,-152,-61,69,-76,-56,-156,69,-127,-75,-58,-126,69,-124,-78,-23,-129,-65,69,-63,69,-125,-74,-68,-66,-5,69,-50,-32,-79,-156,-30,69,-21,-70,-46,-53,-69,-62,69,-59,-1,-77,-55,-131,-67,-27,69,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,69,-139,69,-3,-60,69,69,69,-52,-146,-42,-40,69,69,-39,69,-34,-35,-41,-37,-38,69,-31,-97,-95,69,69,-81,-72,-73,-51,69,69,69,69,69,69,69,69,-156,69,69,-147,-4,69,-82,-132,69,-26,-25,69,-33,-44,-45,-36,-84,-90,-54,-96,69,-80,69,-28,-29,-47,-48,-49,-112,69,69,-8,-148,-140,69,-156,69,69,-100,69,-99,-98,69,69,-113,-156,-22,-9,-156,-156,-137,69,69,-83,-156,69,-89,69,69,69,-136,69,-141,69,-149,69,-144,-133,-134,-138,69,69,-142,-145,69,69,]),':':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,121,122,124,125,127,144,147,148,154,155,156,159,161,163,164,165,167,168,172,173,175,176,177,178,179,184,190,195,200,206,207,209,210,211,212,218,230,234,237,239,249,272,275,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,168,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,204,-90,-54,-96,208,-103,212,-80,-28,-29,-47,-48,-49,-112,204,224,229,168,-100,-105,-99,-98,-106,-113,-83,-89,212,-104,263,276,277,]),'=':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,77,88,99,115,117,118,122,124,125,126,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,216,218,220,230,234,257,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,135,-60,-52,-31,-97,-95,-81,-72,-73,174,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,242,-113,-22,-83,-89,268,]),'<':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,112,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,112,]),'$end':([1,3,4,5,15,19,22,25,33,37,55,61,68,72,78,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,0,-153,-152,-127,-126,-124,-129,-125,-5,-1,-131,-130,-128,-2,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'FUNCTION':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,38,38,-153,-152,-61,38,-76,-56,-156,38,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,38,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,38,-139,-3,-60,38,-52,-146,-31,-97,-95,-81,-72,-73,-51,38,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,38,-8,-148,-140,38,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,38,-83,-89,38,-136,38,-141,38,-149,-144,-133,-134,-138,-142,-145,]),'REPEAT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,39,39,-153,-152,-61,39,-76,-56,-156,39,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,39,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,39,-139,-3,-60,39,-52,-146,-31,-97,-95,-81,-72,-73,-51,39,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,39,-8,-148,-140,39,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,39,-83,-89,39,-136,39,-141,39,-149,-144,-133,-134,-138,-142,-145,]),'GTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,106,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,106,]),'FOR':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,31,31,-153,-152,-61,31,-76,-56,-156,31,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,31,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,31,-139,-3,-60,31,-52,-146,-31,-97,-95,-81,-72,-73,-51,31,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,31,-8,-148,-140,31,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,31,-83,-89,31,-136,31,-141,31,-149,-144,-133,-134,-138,-142,-145,]),'BADAND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,129,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,129,129,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'ELSEIF':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,91,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),'LONGSTRING':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,59,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,116,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,255,256,259,260,262,265,266,267,268,269,271,273,276,277,],[-156,-154,17,17,-153,-152,-61,17,-76,-56,-156,17,-127,-75,-58,-126,17,-124,-78,-23,-129,-65,17,-63,17,-125,-74,-68,-66,-5,17,-50,-32,-79,-156,-30,17,-156,-21,-70,-46,-53,-69,-62,17,-59,-1,-77,125,-55,-131,-67,-27,17,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,17,-139,17,-3,-60,17,17,17,-52,-146,-42,-40,17,17,-39,17,-34,-35,-41,-37,-38,17,-31,17,-97,-95,17,17,-81,-72,-73,-51,17,17,17,17,17,17,17,17,-156,17,17,-147,-4,17,-82,-132,17,-26,-25,17,-33,-44,-45,-36,-84,-90,-54,-96,17,-80,17,-28,-29,-47,-48,-49,-112,17,17,-8,-148,-140,17,-156,17,17,-100,17,-99,-98,17,17,-113,-156,-22,-9,-156,-156,-137,17,17,-83,-156,17,-89,17,17,17,-136,17,-141,17,-149,17,-156,-144,-133,-134,-138,-156,17,17,17,-142,17,-145,17,17,]),'NOT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,114,115,117,118,121,122,124,125,127,128,129,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,45,45,-153,-152,-61,45,-76,-56,-156,45,-127,-75,-58,-126,45,-124,-78,-23,-129,-65,45,-63,-125,-74,-68,-66,-5,45,-50,110,-79,-156,-30,45,-21,-70,-46,-53,-69,-62,45,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,45,-139,45,-3,-60,45,45,45,-52,-146,45,-31,-97,-95,45,-81,-72,-73,-51,45,45,45,45,45,-156,45,45,-147,-4,45,-82,-132,45,-26,-25,45,-33,-44,-45,-84,-90,-54,-96,45,-80,45,-28,-29,-47,-48,-49,-112,45,-65,45,-8,-148,-140,45,-156,45,45,-100,45,-99,-98,45,45,-113,-156,-22,-9,-156,-156,-137,45,45,-83,-156,45,-89,45,45,45,-136,45,-141,45,-149,45,-144,-133,-134,-138,45,45,-142,-145,45,45,]),'AS':([83,94,],[139,149,]),'LTE':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,103,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,103,]),'IN':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,96,98,99,110,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,197,198,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,109,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,150,-122,-52,157,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-123,226,-100,-99,-98,-113,-83,-89,]),'[':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,73,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,190,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,229,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,263,267,268,269,273,276,277,],[-156,-154,43,43,-153,-152,-61,43,-76,-56,-156,43,-127,-75,-58,-126,43,-124,-78,-23,-129,-65,43,-63,97,43,-125,-74,-68,-66,-5,43,-50,-32,-79,-156,-30,43,-21,-70,-46,121,-69,-62,43,-59,-1,-77,-55,-131,-67,-27,43,-130,-71,-24,-43,-128,-60,-57,-64,-2,-155,-143,-156,-135,43,-139,43,-3,-60,43,43,43,-52,-146,-42,-40,43,43,-39,43,-34,-35,-41,-37,-38,43,-31,-97,-95,43,43,-81,-72,-73,-51,43,43,43,43,43,43,43,43,-156,43,43,-147,-4,43,-82,-132,43,-26,-25,43,-33,-44,-45,-36,-84,-90,-54,-96,43,-80,43,-28,-29,-47,-48,-49,-112,43,-65,43,-8,-148,-140,43,-156,43,43,-100,43,-99,-98,43,43,-113,-156,-22,-9,-156,-156,-137,43,43,43,-83,-156,43,-89,43,43,43,-136,43,-141,43,-149,43,-144,-133,-134,-138,43,43,43,-142,-145,43,43,]),'ELSE':([1,4,5,15,19,22,25,33,37,61,68,72,79,80,82,85,87,101,140,141,145,222,225,245,250,259,260,262,],[-154,-153,-152,-127,-126,90,-129,-125,-5,-131,-130,-128,-155,-143,-135,-139,-3,-146,-147,-4,-132,-156,-137,-136,-149,-133,-134,-138,]),']':([1,4,5,7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,43,44,48,49,50,51,52,54,56,60,63,65,69,70,71,75,76,79,88,98,99,114,115,117,118,122,124,125,127,144,147,148,152,154,155,156,158,159,160,163,164,165,166,167,168,169,170,171,172,173,175,176,177,178,179,184,197,201,202,207,209,210,211,212,218,230,234,235,236,237,238,239,253,264,],[-154,-153,-152,-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-156,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-155,-60,-122,-52,159,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,198,-33,-44,-45,-156,-84,-88,-90,-54,-96,207,-101,-103,-102,210,-108,211,-80,-28,-29,-47,-48,-49,-112,-123,230,-85,-100,-105,-99,-98,-106,-113,-83,-89,-111,-109,-110,-107,-104,-86,-87,]),'ID':([0,1,2,3,4,5,7,8,9,11,12,13,14,15,17,18,19,21,22,23,24,25,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,64,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,97,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,120,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,143,144,145,146,147,148,149,150,151,153,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,182,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,224,225,226,227,228,230,231,232,234,240,241,242,244,245,246,247,248,250,252,256,259,260,261,262,267,268,269,273,276,277,],[-156,-154,73,73,-153,-152,-61,73,83,-76,-56,-156,73,-127,-75,-58,-126,88,-124,-78,-23,-129,94,-65,88,-63,98,88,-125,-74,-68,-66,-5,100,73,-50,-32,-79,-156,-30,88,-21,-70,-46,-53,-69,-62,88,-59,-1,-77,-55,-131,-67,126,-27,88,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,73,-139,73,-3,-60,73,88,88,98,-52,-146,-42,-40,88,88,-39,88,-34,-35,-41,-37,-38,88,-31,-97,-95,88,165,88,-81,-72,-73,-51,88,88,88,88,88,88,88,88,-156,88,73,193,-147,-4,88,-82,-132,88,-26,-25,195,88,197,200,-33,-44,-45,-36,-84,-90,-54,-96,88,-80,88,-28,-29,-47,-48,-49,216,-112,88,73,-8,-148,-140,73,-156,88,88,-100,88,-99,-98,88,88,-113,-156,-22,-9,-156,-156,247,-137,88,249,73,-83,-156,88,-89,88,257,88,73,-136,73,-141,73,-149,88,-144,-133,-134,269,-138,88,88,-142,-145,88,88,]),'CLOSE_PAREN':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,47,48,49,50,51,52,53,54,56,60,63,65,69,70,71,75,76,88,99,115,117,118,122,123,124,125,127,133,143,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,180,181,183,184,185,186,194,199,207,210,211,218,220,230,234,243,251,258,270,274,],[-61,-76,-56,-75,-58,-78,-23,-65,-63,-74,-68,-66,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,122,-59,-77,-55,-67,-27,-71,-24,-43,-57,-64,-60,-52,-31,-97,-95,-81,173,-72,-73,-51,184,184,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-114,215,218,-112,-116,219,223,228,-100,-99,-98,-113,-22,-83,-89,-115,-150,-118,-151,-119,]),'IF':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,74,74,-153,-152,-61,74,-76,-56,-156,74,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,74,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,74,-139,-3,-60,74,-52,-146,-31,-97,-95,-81,-72,-73,-51,74,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,74,-8,-148,-140,74,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,74,-83,-89,74,-136,74,-141,74,-149,-144,-133,-134,-138,-142,-145,]),'AND':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,128,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,128,128,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'`':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,89,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,21,21,-153,-152,-61,21,-76,-56,-156,21,-127,-75,-58,-126,21,-124,-78,-23,-129,-65,21,-63,21,-125,-74,-68,-66,-5,21,-50,-32,-79,-156,-30,21,-21,-70,-46,-53,-69,-62,21,-59,-1,-77,-55,-131,-67,-27,21,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,21,-139,21,-3,-60,144,21,21,21,-52,-146,-42,-40,21,21,-39,21,-34,-35,-41,-37,-38,21,-31,-97,-95,21,21,-81,-72,-73,-51,21,21,21,21,21,21,21,21,-156,21,21,-147,-4,21,-82,-132,21,-26,-25,21,-33,-44,-45,-36,-84,-90,-54,-96,21,-80,21,-28,-29,-47,-48,-49,-112,21,21,-8,-148,-140,21,-156,21,21,-100,21,-99,-98,21,21,-113,-156,-22,-9,-156,-156,-137,21,21,-83,-156,21,-89,21,21,21,-136,21,-141,21,-149,21,-144,-133,-134,-138,21,21,-142,-145,21,21,]),'BADOR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,92,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'BREAK':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,62,62,-153,-152,-61,62,-76,-56,-156,62,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,62,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,62,-139,62,-3,-60,62,-52,-146,-31,-97,-95,-81,-72,-73,-51,62,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,62,-8,-148,-140,62,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,62,-83,-89,62,-136,62,-141,62,-149,-144,-133,-134,-138,-142,-145,]),'HEXINT':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,63,63,-153,-152,-61,63,-76,-56,-156,63,-127,-75,-58,-126,63,-124,-78,-23,-129,-65,63,-63,63,-125,-74,-68,-66,-5,63,-50,-32,-79,-156,-30,63,-21,-70,-46,-53,-69,-62,63,-59,-1,-77,-55,-131,-67,-27,63,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,63,-139,63,-3,-60,63,63,63,-52,-146,-42,-40,63,63,-39,63,-34,-35,-41,-37,-38,63,-31,-97,-95,63,63,-81,-72,-73,-51,63,63,63,63,63,63,63,63,-156,63,63,-147,-4,63,-82,-132,63,-26,-25,63,-33,-44,-45,-36,-84,-90,-54,-96,63,-80,63,-28,-29,-47,-48,-49,-112,63,63,-8,-148,-140,63,-156,63,63,-100,63,-99,-98,63,63,-113,-156,-22,-9,-156,-156,-137,63,63,-83,-156,63,-89,63,63,63,-136,63,-141,63,-149,63,-144,-133,-134,-138,63,63,-142,-145,63,63,]),'ISEQUAL':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,102,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,102,]),'ITEM_TAG':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,76,76,-153,-152,-61,76,-76,-56,-156,76,-127,-75,-58,-126,76,-124,-78,-23,-129,-65,76,-63,76,-125,-74,-68,-66,-5,76,-50,-32,-79,-156,-30,76,-21,-70,-46,-53,-69,-62,76,-59,-1,-77,-55,-131,-67,-27,76,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,76,-139,76,-3,-60,76,76,76,-52,-146,-42,-40,76,76,-39,76,-34,-35,-41,-37,-38,76,-31,-97,-95,76,76,-81,-72,-73,-51,76,76,76,76,76,76,76,76,-156,76,76,-147,-4,76,-82,-132,76,-26,-25,76,-33,-44,-45,-36,-84,-90,-54,-96,76,-80,76,-28,-29,-47,-48,-49,-112,76,76,-8,-148,-140,76,-156,76,76,-100,76,-99,-98,76,76,-113,-156,-22,-9,-156,-156,-137,76,76,-83,-156,76,-89,76,76,76,-136,76,-141,76,-149,76,-144,-133,-134,-138,76,76,-142,-145,76,76,]),'{':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,21,22,23,24,25,28,29,30,32,33,34,35,36,37,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,60,61,63,65,67,68,69,70,71,72,75,76,78,79,80,81,82,84,85,86,87,88,90,92,93,99,101,102,103,104,105,106,107,108,109,111,112,113,114,115,117,118,119,121,122,124,125,127,128,129,130,131,132,133,134,135,136,137,138,140,141,143,144,145,146,147,148,150,154,155,156,157,159,163,164,165,168,173,174,175,176,177,178,179,184,188,191,192,193,195,196,203,204,206,207,208,210,211,212,217,218,219,220,221,222,223,225,226,228,230,231,232,234,240,242,244,245,246,247,248,250,252,256,259,260,262,267,268,269,273,276,277,],[-156,-154,46,46,-153,-152,-61,81,-76,-56,-156,81,-127,-75,-58,-126,46,-124,-78,-23,-129,-65,46,-63,46,-125,-74,-68,-66,-5,81,-50,-32,-79,-156,-30,46,-21,-70,-46,-53,-69,-62,46,-59,-1,-77,-55,-131,-67,-27,46,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,81,-139,46,-3,-60,81,46,46,-52,-146,-42,-40,46,46,-39,46,-34,-35,-41,-37,-38,46,-31,-97,-95,46,46,-81,-72,-73,-51,46,46,46,46,46,46,46,46,-156,46,46,-147,-4,46,-82,-132,46,-26,-25,46,-33,-44,-45,-36,-84,-90,-54,-96,46,-80,46,-28,-29,-47,-48,-49,-112,46,46,-8,-148,-140,81,-156,46,46,-100,46,-99,-98,46,46,-113,-156,-22,-9,-156,-156,-137,46,81,-83,-156,46,-89,46,46,81,-136,81,-141,81,-149,46,-144,-133,-134,-138,46,46,-142,-145,46,46,]),'>':([7,11,12,17,18,23,28,30,34,35,36,40,41,42,48,49,50,51,52,54,56,60,63,69,71,73,75,76,88,99,117,118,122,124,125,127,144,155,156,159,163,164,165,173,177,178,179,184,190,207,210,211,218,230,234,247,],[-61,-76,-56,-75,-58,-78,-65,-63,-74,-68,-66,-50,113,-79,-70,-46,-53,-69,-62,-59,-77,-55,-67,-71,-43,-60,-57,-64,-60,-52,-97,-95,-81,-72,-73,-51,-82,-44,-45,-84,-90,-54,-96,-80,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,113,]),'}':([1,4,5,7,11,12,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,40,41,42,44,46,48,49,50,51,52,54,56,60,61,63,65,68,69,70,71,72,75,76,79,80,81,82,85,87,88,99,101,115,116,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,162,163,164,165,173,175,176,177,178,179,184,191,192,205,207,210,211,218,221,222,225,230,233,234,245,250,254,259,260,262,278,279,],[-154,-153,-152,-61,-76,-56,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,-50,-32,-79,-30,-156,-70,-46,-53,-69,-62,-59,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-155,-143,-156,-135,-139,-3,-60,-52,-146,-31,163,-97,-95,-81,-72,-73,-51,163,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-156,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,222,-8,234,-100,-99,-98,-113,-9,-156,-137,-83,-94,-89,-136,-149,-91,-133,-134,-138,-92,-93,]),'OR':([7,11,12,17,18,23,24,28,30,34,35,36,40,41,42,44,48,49,50,51,52,54,56,60,63,65,69,70,71,73,75,76,88,99,115,117,118,122,124,125,127,144,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,190,207,210,211,218,230,234,],[-61,-76,-56,-75,-58,-78,93,-65,-63,-74,-68,-66,-50,-32,-79,-30,-70,-46,-53,-69,-62,-59,-77,-55,-67,-27,-71,-24,-43,-60,-57,-64,-60,-52,-31,-97,-95,-81,-72,-73,-51,-82,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,-65,-100,-99,-98,-113,-83,-89,]),'LOOP':([0,1,2,3,4,5,7,8,11,12,13,14,15,17,18,19,22,23,24,25,28,30,33,34,35,36,37,39,40,41,42,44,47,48,49,50,51,52,54,55,56,60,61,63,65,68,69,70,71,72,75,76,78,79,80,81,82,84,85,87,88,90,99,101,115,117,118,122,124,125,127,138,140,141,144,145,147,148,154,155,156,159,163,164,165,173,175,176,177,178,179,184,191,192,193,195,196,207,210,211,218,219,220,221,222,223,225,228,230,234,244,245,246,247,248,250,256,259,260,262,269,273,],[-156,-154,26,26,-153,-152,-61,26,-76,-56,-156,26,-127,-75,-58,-126,-124,-78,-23,-129,-65,-63,-125,-74,-68,-66,-5,26,-50,-32,-79,-30,-21,-70,-46,-53,-69,-62,-59,-1,-77,-55,-131,-67,-27,-130,-71,-24,-43,-128,-57,-64,-2,-155,-143,-156,-135,26,-139,-3,-60,26,-52,-146,-31,-97,-95,-81,-72,-73,-51,26,-147,-4,-82,-132,-26,-25,-33,-44,-45,-84,-90,-54,-96,-80,-28,-29,-47,-48,-49,-112,26,-8,-148,-140,26,-100,-99,-98,-113,-156,-22,-9,-156,-156,-137,26,-83,-89,26,-136,26,-141,26,-149,-144,-133,-134,-138,-142,-145,]),}
+
+_lr_action = { }
+for _k, _v in _lr_action_items.items():
+   for _x,_y in zip(_v[0],_v[1]):
+      if not _x in _lr_action:  _lr_action[_x] = { }
+      _lr_action[_x][_k] = _y
+del _lr_action_items
+
+_lr_goto_items = {'statements':([138,],[191,]),'comp_operator':([41,],[104,]),'small_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[6,6,6,6,6,6,142,6,6,6,6,6,6,6,6,]),'fancy_drel_assignment_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,]),'primary':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,]),'stringliteral':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,116,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,266,267,268,271,276,277,],[28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,161,28,28,28,28,28,28,28,28,28,28,28,190,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,272,28,28,275,28,28,]),'item_tag':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,]),'not_test':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[65,65,65,65,65,65,65,115,65,65,65,65,65,65,65,65,175,176,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,]),'listmaker':([114,],[158,]),'do_stmt_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[8,8,8,8,8,8,8,8,8,8,8,8,8,8,]),'func_arg':([133,143,217,],[180,180,243,]),'enclosure':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,]),'newlines':([0,13,16,43,46,81,86,136,158,162,203,219,222,223,231,255,265,],[5,5,87,5,5,5,141,5,5,5,5,5,5,5,5,5,5,]),'break_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,]),'dotlist':([133,],[181,]),'arglist':([153,],[199,]),'repeat_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[68,68,68,68,68,68,68,68,68,68,68,68,68,68,]),'u_expr':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[49,49,49,49,49,49,99,49,49,49,127,49,49,49,49,49,49,49,49,49,164,49,49,49,177,178,179,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,]),'if_else_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[33,33,33,33,33,33,33,33,33,33,33,33,33,33,]),'parenth_form':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,]),'literal':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,]),'attributeref':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,]),'call':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,]),'argument_list':([133,143,],[183,183,]),'statement':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[55,78,82,82,82,82,82,192,221,82,82,82,82,82,]),'string_conversion':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,]),'with_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[13,13,13,13,13,13,13,13,13,13,13,13,13,13,]),'input':([0,],[3,]),'loop_head':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[14,14,14,14,14,14,14,14,14,14,14,14,14,14,]),'do_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[15,15,15,15,15,15,15,15,15,15,15,15,15,15,]),'next_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,]),'empty':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,]),'listmaker2':([160,],[202,]),'short_slice':([121,206,],[167,167,]),'power':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,]),'a_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[41,41,41,41,41,41,41,41,41,41,41,41,41,41,154,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,]),'print_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,]),'and_test':([2,3,8,14,21,29,39,53,84,86,90,92,93,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[70,70,70,70,70,70,70,70,70,70,70,147,148,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,]),'maybe_nline':([0,13,43,46,81,136,158,162,203,219,222,223,231,255,265,],[2,84,114,116,138,188,201,205,232,244,245,246,252,266,271,]),'tablemaker2':([233,],[254,]),'slicing':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,]),'for_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[19,19,19,19,19,19,19,19,19,19,19,19,19,19,]),'m_expr':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,104,105,107,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,155,156,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,]),'table_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,]),'restricted_comp_operator':([41,247,],[108,261,]),'atom':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,]),'funcdef':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[61,61,61,61,61,61,61,61,61,61,61,61,61,61,]),'expr_stmt':([2,3,8,14,39,84,86,90,138,191,196,228,244,246,248,],[20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,]),'slice_list':([121,],[166,]),'subscription':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,]),'comparison':([2,3,8,14,21,29,39,45,53,84,86,90,92,93,114,121,128,129,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,]),'attribute_tag':([50,],[118,]),'if_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[22,22,22,22,22,22,22,22,22,22,22,22,22,22,]),'id_list':([31,97,],[96,152,]),'proper_slice':([121,206,],[170,235,]),'list_display':([2,3,8,14,21,29,32,39,45,53,67,84,86,90,92,93,104,105,107,114,119,121,128,129,130,131,132,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,229,232,240,242,244,246,248,252,263,267,268,276,277,],[23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,251,23,23,23,23,23,23,23,270,23,23,23,23,]),'loop_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[72,72,72,72,72,72,72,72,72,72,72,72,72,72,]),'or_test':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,]),'compound_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[37,37,37,37,37,37,37,37,37,37,37,37,37,37,]),'with_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[25,25,25,25,25,25,25,25,25,25,25,25,25,25,]),'tablemaker':([116,138,],[162,162,]),'long_slice':([121,206,],[169,169,]),'suite':([8,14,39,84,90,196,228,244,246,248,],[80,85,101,140,145,225,250,259,260,262,]),'simple_stmt':([2,3,8,14,39,84,90,138,191,196,228,244,246,248,],[16,16,16,16,16,16,16,16,16,16,16,16,16,16,]),'testlist_star_expr':([2,3,8,14,21,39,53,84,86,90,135,137,138,150,191,196,226,228,244,246,248,],[77,77,77,77,89,77,123,77,77,77,187,189,77,196,77,77,248,77,77,77,77,]),'slice_item':([121,206,],[171,236,]),'expression':([2,3,8,14,21,29,39,53,84,86,90,114,121,133,134,135,137,138,143,146,150,168,174,188,191,196,204,206,208,212,217,226,228,232,240,242,244,246,248,252,267,268,276,277,],[47,47,47,47,47,95,47,47,47,47,47,160,172,185,186,47,47,47,185,194,47,209,213,220,47,47,233,237,238,239,185,47,47,253,256,258,47,47,47,264,273,274,278,279,]),}
+
+_lr_goto = { }
+for _k, _v in _lr_goto_items.items():
+   for _x,_y in zip(_v[0],_v[1]):
+       if not _x in _lr_goto: _lr_goto[_x] = { }
+       _lr_goto[_x][_k] = _y
+del _lr_goto_items
+_lr_productions = [
+  ("S' -> input","S'",1,None,None,None),
+  ('input -> maybe_nline statement','input',2,'p_input','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',19),
+  ('input -> input statement','input',2,'p_input','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',20),
+  ('statement -> simple_stmt newlines','statement',2,'p_statement','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',36),
+  ('statement -> simple_stmt ; newlines','statement',3,'p_statement','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',37),
+  ('statement -> compound_stmt','statement',1,'p_statement','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',38),
+  ('simple_stmt -> small_stmt','simple_stmt',1,'p_simple_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',44),
+  ('simple_stmt -> simple_stmt ; small_stmt','simple_stmt',3,'p_simple_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',45),
+  ('statements -> statement','statements',1,'p_statements','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',55),
+  ('statements -> statements statement','statements',2,'p_statements','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',56),
+  ('small_stmt -> expr_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',61),
+  ('small_stmt -> print_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',62),
+  ('small_stmt -> break_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',63),
+  ('small_stmt -> next_stmt','small_stmt',1,'p_small_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',64),
+  ('break_stmt -> BREAK','break_stmt',1,'p_break_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',68),
+  ('next_stmt -> NEXT','next_stmt',1,'p_next_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',72),
+  ('print_stmt -> PRINT expression','print_stmt',2,'p_print_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',76),
+  ('expr_stmt -> testlist_star_expr','expr_stmt',1,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',84),
+  ('expr_stmt -> testlist_star_expr AUGOP testlist_star_expr','expr_stmt',3,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',85),
+  ('expr_stmt -> testlist_star_expr = testlist_star_expr','expr_stmt',3,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',86),
+  ('expr_stmt -> fancy_drel_assignment_stmt','expr_stmt',1,'p_expr_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',87),
+  ('testlist_star_expr -> expression','testlist_star_expr',1,'p_testlist_star_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',96),
+  ('testlist_star_expr -> testlist_star_expr , maybe_nline expression','testlist_star_expr',4,'p_testlist_star_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',97),
+  ('expression -> or_test','expression',1,'p_expression','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',107),
+  ('or_test -> and_test','or_test',1,'p_or_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',115),
+  ('or_test -> or_test OR and_test','or_test',3,'p_or_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',116),
+  ('or_test -> or_test BADOR and_test','or_test',3,'p_or_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',117),
+  ('and_test -> not_test','and_test',1,'p_and_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',122),
+  ('and_test -> and_test AND not_test','and_test',3,'p_and_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',123),
+  ('and_test -> and_test BADAND not_test','and_test',3,'p_and_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',124),
+  ('not_test -> comparison','not_test',1,'p_not_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',129),
+  ('not_test -> NOT not_test','not_test',2,'p_not_test','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',130),
+  ('comparison -> a_expr','comparison',1,'p_comparison','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',135),
+  ('comparison -> a_expr comp_operator a_expr','comparison',3,'p_comparison','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',136),
+  ('comp_operator -> restricted_comp_operator','comp_operator',1,'p_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',142),
+  ('comp_operator -> IN','comp_operator',1,'p_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',143),
+  ('comp_operator -> NOT IN','comp_operator',2,'p_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',144),
+  ('restricted_comp_operator -> <','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',150),
+  ('restricted_comp_operator -> >','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',151),
+  ('restricted_comp_operator -> GTE','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',152),
+  ('restricted_comp_operator -> LTE','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',153),
+  ('restricted_comp_operator -> NEQ','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',154),
+  ('restricted_comp_operator -> ISEQUAL','restricted_comp_operator',1,'p_restricted_comp_operator','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',155),
+  ('a_expr -> m_expr','a_expr',1,'p_a_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',159),
+  ('a_expr -> a_expr + m_expr','a_expr',3,'p_a_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',160),
+  ('a_expr -> a_expr - m_expr','a_expr',3,'p_a_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',161),
+  ('m_expr -> u_expr','m_expr',1,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',168),
+  ('m_expr -> m_expr * u_expr','m_expr',3,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',169),
+  ('m_expr -> m_expr / u_expr','m_expr',3,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',170),
+  ('m_expr -> m_expr ^ u_expr','m_expr',3,'p_m_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',171),
+  ('u_expr -> power','u_expr',1,'p_u_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',178),
+  ('u_expr -> - u_expr','u_expr',2,'p_u_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',179),
+  ('u_expr -> + u_expr','u_expr',2,'p_u_expr','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',180),
+  ('power -> primary','power',1,'p_power','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',187),
+  ('power -> primary POWER u_expr','power',3,'p_power','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',188),
+  ('primary -> atom','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',196),
+  ('primary -> attributeref','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',197),
+  ('primary -> subscription','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',198),
+  ('primary -> slicing','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',199),
+  ('primary -> call','primary',1,'p_primary','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',200),
+  ('atom -> ID','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',205),
+  ('atom -> item_tag','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',206),
+  ('atom -> literal','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',207),
+  ('atom -> enclosure','atom',1,'p_atom','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',208),
+  ('item_tag -> ITEM_TAG','item_tag',1,'p_item_tag','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',213),
+  ('literal -> stringliteral','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',217),
+  ('literal -> INTEGER','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',218),
+  ('literal -> HEXINT','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',219),
+  ('literal -> OCTINT','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',220),
+  ('literal -> BININT','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',221),
+  ('literal -> REAL','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',222),
+  ('literal -> IMAGINARY','literal',1,'p_literal','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',223),
+  ('stringliteral -> STRPREFIX SHORTSTRING','stringliteral',2,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',228),
+  ('stringliteral -> STRPREFIX LONGSTRING','stringliteral',2,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',229),
+  ('stringliteral -> SHORTSTRING','stringliteral',1,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',230),
+  ('stringliteral -> LONGSTRING','stringliteral',1,'p_stringliteral','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',231),
+  ('enclosure -> parenth_form','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',236),
+  ('enclosure -> string_conversion','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',237),
+  ('enclosure -> list_display','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',238),
+  ('enclosure -> table_display','enclosure',1,'p_enclosure','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',239),
+  ('parenth_form -> OPEN_PAREN testlist_star_expr CLOSE_PAREN','parenth_form',3,'p_parenth_form','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',243),
+  ('parenth_form -> OPEN_PAREN CLOSE_PAREN','parenth_form',2,'p_parenth_form','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',244),
+  ('string_conversion -> ` testlist_star_expr `','string_conversion',3,'p_string_conversion','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',251),
+  ('list_display -> [ maybe_nline listmaker maybe_nline ]','list_display',5,'p_list_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',256),
+  ('list_display -> [ maybe_nline ]','list_display',3,'p_list_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',257),
+  ('listmaker -> expression listmaker2','listmaker',2,'p_listmaker','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',265),
+  ('listmaker2 -> , maybe_nline expression','listmaker2',3,'p_listmaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',270),
+  ('listmaker2 -> listmaker2 , maybe_nline expression','listmaker2',4,'p_listmaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',271),
+  ('listmaker2 -> <empty>','listmaker2',0,'p_listmaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',272),
+  ('table_display -> { maybe_nline tablemaker maybe_nline }','table_display',5,'p_table_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',282),
+  ('table_display -> { maybe_nline }','table_display',3,'p_table_display','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',283),
+  ('tablemaker -> stringliteral : expression tablemaker2','tablemaker',4,'p_tablemaker','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',290),
+  ('tablemaker2 -> , maybe_nline stringliteral : expression','tablemaker2',5,'p_tablemaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',294),
+  ('tablemaker2 -> tablemaker2 , maybe_nline stringliteral : expression','tablemaker2',6,'p_tablemaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',295),
+  ('tablemaker2 -> <empty>','tablemaker2',0,'p_tablemaker2','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',296),
+  ('attributeref -> primary attribute_tag','attributeref',2,'p_attributeref','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',310),
+  ('attribute_tag -> . ID','attribute_tag',2,'p_attribute_tag','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',314),
+  ('attribute_tag -> REAL','attribute_tag',1,'p_attribute_tag','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',315),
+  ('subscription -> primary [ expression ]','subscription',4,'p_subscription','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',322),
+  ('slicing -> primary [ proper_slice ]','slicing',4,'p_slicing','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',326),
+  ('slicing -> primary [ slice_list ]','slicing',4,'p_slicing','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',327),
+  ('proper_slice -> short_slice','proper_slice',1,'p_proper_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',331),
+  ('proper_slice -> long_slice','proper_slice',1,'p_proper_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',332),
+  ('short_slice -> :','short_slice',1,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',343),
+  ('short_slice -> expression : expression','short_slice',3,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',344),
+  ('short_slice -> : expression','short_slice',2,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',345),
+  ('short_slice -> expression :','short_slice',2,'p_short_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',346),
+  ('long_slice -> short_slice : expression','long_slice',3,'p_long_slice','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',355),
+  ('slice_list -> slice_item','slice_list',1,'p_slice_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',362),
+  ('slice_list -> slice_list , slice_item','slice_list',3,'p_slice_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',363),
+  ('slice_item -> expression','slice_item',1,'p_slice_item','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',370),
+  ('slice_item -> proper_slice','slice_item',1,'p_slice_item','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',371),
+  ('call -> ID OPEN_PAREN CLOSE_PAREN','call',3,'p_call','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',375),
+  ('call -> ID OPEN_PAREN argument_list CLOSE_PAREN','call',4,'p_call','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',376),
+  ('argument_list -> func_arg','argument_list',1,'p_argument_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',386),
+  ('argument_list -> argument_list , func_arg','argument_list',3,'p_argument_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',387),
+  ('func_arg -> expression','func_arg',1,'p_func_arg','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',394),
+  ('fancy_drel_assignment_stmt -> ID OPEN_PAREN dotlist CLOSE_PAREN','fancy_drel_assignment_stmt',4,'p_fancy_drel_assignment_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',398),
+  ('dotlist -> . ID = expression','dotlist',4,'p_dotlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',405),
+  ('dotlist -> dotlist , . ID = expression','dotlist',6,'p_dotlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',406),
+  ('exprlist -> a_expr','exprlist',1,'p_exprlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',413),
+  ('exprlist -> exprlist , a_expr','exprlist',3,'p_exprlist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',414),
+  ('id_list -> ID','id_list',1,'p_id_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',421),
+  ('id_list -> id_list , ID','id_list',3,'p_id_list','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',422),
+  ('compound_stmt -> if_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',433),
+  ('compound_stmt -> if_else_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',434),
+  ('compound_stmt -> for_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',435),
+  ('compound_stmt -> do_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',436),
+  ('compound_stmt -> loop_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',437),
+  ('compound_stmt -> with_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',438),
+  ('compound_stmt -> repeat_stmt','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',439),
+  ('compound_stmt -> funcdef','compound_stmt',1,'p_compound_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',440),
+  ('if_else_stmt -> if_stmt ELSE suite','if_else_stmt',3,'p_if_else_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',447),
+  ('if_stmt -> IF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',6,'p_if_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',453),
+  ('if_stmt -> if_stmt ELSEIF OPEN_PAREN expression CLOSE_PAREN maybe_nline suite','if_stmt',7,'p_if_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',454),
+  ('suite -> statement','suite',1,'p_suite','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',473),
+  ('suite -> { maybe_nline statements } maybe_nline','suite',5,'p_suite','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',474),
+  ('for_stmt -> FOR id_list IN testlist_star_expr suite','for_stmt',5,'p_for_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',481),
+  ('for_stmt -> FOR [ id_list ] IN testlist_star_expr suite','for_stmt',7,'p_for_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',482),
+  ('loop_stmt -> loop_head suite','loop_stmt',2,'p_loop_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',489),
+  ('loop_head -> LOOP ID AS ID','loop_head',4,'p_loop_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',495),
+  ('loop_head -> LOOP ID AS ID : ID','loop_head',6,'p_loop_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',496),
+  ('loop_head -> LOOP ID AS ID : ID restricted_comp_operator ID','loop_head',8,'p_loop_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',497),
+  ('do_stmt -> do_stmt_head suite','do_stmt',2,'p_do_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',508),
+  ('do_stmt_head -> DO ID = expression , expression','do_stmt_head',6,'p_do_stmt_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',515),
+  ('do_stmt_head -> DO ID = expression , expression , expression','do_stmt_head',8,'p_do_stmt_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',516),
+  ('repeat_stmt -> REPEAT suite','repeat_stmt',2,'p_repeat_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',525),
+  ('with_stmt -> with_head maybe_nline suite','with_stmt',3,'p_with_stmt','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',529),
+  ('with_head -> WITH ID AS ID','with_head',4,'p_with_head','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',533),
+  ('funcdef -> FUNCTION ID OPEN_PAREN arglist CLOSE_PAREN suite','funcdef',6,'p_funcdef','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',537),
+  ('arglist -> ID : list_display','arglist',3,'p_arglist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',541),
+  ('arglist -> arglist , ID : list_display','arglist',5,'p_arglist','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',542),
+  ('maybe_nline -> newlines','maybe_nline',1,'p_maybe_nline','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',549),
+  ('maybe_nline -> empty','maybe_nline',1,'p_maybe_nline','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',550),
+  ('newlines -> NEWLINE','newlines',1,'p_newlines','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',557),
+  ('newlines -> newlines NEWLINE','newlines',2,'p_newlines','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',558),
+  ('empty -> <empty>','empty',0,'p_empty','/home/jrh/programs/CIF/pycifrw-git/pycifrw/drel/drel_ast_yacc.py',562),
+]
```

### Comparing `pyemaps-1.0.8/CifFile/src/yapps3_compiled_rt.py` & `pyemaps-1.0.9/CifFile/src/yapps3_compiled_rt.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,390 +1,390 @@
-#
-# Yapps 2 Runtime, part of Yapps 2 - yet another python parser system
-# Copyright 1999-2003 by Amit J. Patel <amitp@cs.stanford.edu>
-#
-# This version of the Yapps 2 Runtime can be distributed under the
-# terms of the MIT open source license, either found in the LICENSE file
-# included with the Yapps distribution
-# <http://theory.stanford.edu/~amitp/yapps/> or at
-# <http://www.opensource.org/licenses/mit-license.php>
-#
-# Modified for PyCIFRW by JRH to allow external scanner
-#
-# To maximize python3/python2 compatibility
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-
-""" Detail of JRH modifications.
-
-The compiled module handles all token administration by itself, but
-does not deal with restrictions.  It also effectively removes the
-context-sensitivity of Yapps, as it ignores restrictions, but
-these restrictions turn out to be  unnecessary for CIF.
-
-Interestingly, the module scan function is never called directly
-from python.
-
-"""
-
-"""Run time libraries needed to run parsers generated by Yapps.
-
-This module defines parse-time exception classes, a scanner class, a
-base class for parsers produced by Yapps, and a context class that
-keeps track of the parse stack.
-
-"""
-
-# TODO: it should be possible to embed yappsrt into the generated
-# grammar to make a standalone module.
-
-import sys, re
-
-
-# For normal installation this module is "emapsCifFile.yapps3_compiled_rt"
-# and StarScan is an extension module within the parent CifFile module.
-if __name__.startswith('pyemaps.CifFile.'):
-    try:
-        from . import StarScan
-        have_star_scan = True
-    except ImportError:
-        have_star_scan = False
-# Otherwise assume this is imported from the yapps3/yapps2.py script
-# that is executed from Makefile to generate YappsStarParser sources.
-else:
-    assert __name__ == 'yapps3_compiled_rt', "Unexpected module name."
-    assert sys.argv[0].endswith('yapps2.py'), (
-        "This should be reached only when running yapps2.py in Makefile.")
-    have_star_scan = False
-
-class YappsSyntaxError(Exception):
-    """When we run into an unexpected token, this is the exception to use"""
-    def __init__(self, charpos=-1, msg="Bad Token", context=None):
-        Exception.__init__(self)
-        self.charpos = charpos
-        self.msg = msg
-        self.context = context
-
-    def __str__(self):
-        if self.charpos < 0: return 'SyntaxError'
-        else: return 'SyntaxError@char%s(%s)' % (repr(self.charpos), self.msg)
-
-class NoMoreTokens(Exception):
-    """Another exception object, for when we run out of tokens"""
-    pass
-
-class Scanner:
-    """Yapps scanner.
-
-    The Yapps scanner can work in context sensitive or context
-    insensitive modes.  The token(i) method is used to retrieve the
-    i-th token.  It takes a restrict set that limits the set of tokens
-    it is allowed to return.  In context sensitive mode, this restrict
-    set guides the scanner.  In context insensitive mode, there is no
-    restriction (the set is always the full set of tokens).
-
-    """
-
-    def __init__(self, patterns, ignore, input, scantype="standard"):
-        """Initialize the scanner.
-
-        Parameters:
-          patterns : [(terminal, uncompiled regex), ...] or None
-          ignore : [terminal,...]
-          input : string
-
-        If patterns is None, we assume that the subclass has
-        defined self.patterns : [(terminal, compiled regex), ...].
-        Note that the patterns parameter expects uncompiled regexes,
-        whereas the self.patterns field expects compiled regexes.
-        """
-        self.tokens = [] # [(begin char pos, end char pos, token name, matched text), ...]
-        self.restrictions = []
-        self.input = input
-        self.pos = 0
-        self.ignore = ignore
-        self.scantype = scantype
-        self.first_line_number = 1
-        if self.scantype == "flex" and have_star_scan:
-            StarScan.prepare(input)
-            self.scan = self.compiled_scan
-            self.token = self.compiled_token
-            self.__del__ = StarScan.cleanup
-        elif self.scantype == "flex":
-            print("WARNING: using Python scanner although C scanner requested")
-            self.scantype = "standard"
-        if self.scantype != "flex":
-            self.scan = self.interp_scan
-            self.token = self.interp_token
-
-        if patterns is not None:
-            # Compile the regex strings into regex objects
-            self.patterns = []
-            for terminal, regex in patterns:
-                self.patterns.append( (terminal, re.compile(regex)) )
-
-    def get_token_pos(self):
-        """Get the current token position in the input text."""
-        return len(self.tokens)
-
-    def get_char_pos(self):
-        """Get the current char position in the input text."""
-        return self.pos
-
-    def get_prev_char_pos(self, i=None):
-        """Get the previous position (one token back) in the input text."""
-        if self.pos == 0: return 0
-        if i is None: i = -1
-        return self.tokens[i][0]
-
-    def get_line_number(self):
-        """Get the line number of the current position in the input text."""
-        # TODO: make this work at any token/char position
-        return self.first_line_number + self.get_input_scanned().count('\n')
-
-    def get_column_number(self):
-        """Get the column number of the current position in the input text."""
-        s = self.get_input_scanned()
-        i = s.rfind('\n') # may be -1, but that's okay in this case
-        return len(s) - (i+1)
-
-    def get_input_scanned(self):
-        """Get the portion of the input that has been tokenized."""
-        return self.input[:self.pos]
-
-    def get_input_unscanned(self):
-        """Get the portion of the input that has not yet been tokenized."""
-        return self.input[self.pos:]
-
-    def interp_token(self, i, restrict=None):
-        """Get the i'th token in the input.
-
-        If i is one past the end, then scan for another token.
-
-        Args:
-
-        restrict : [token, ...] or None; if restrict is None, then any
-        token is allowed.  You may call token(i) more than once.
-        However, the restrict set may never be larger than what was
-        passed in on the first call to token(i).
-
-        """
-        if i == len(self.tokens):
-            self.scan(restrict)
-        if i < len(self.tokens):
-            # Make sure the restriction is more restricted.  This
-            # invariant is needed to avoid ruining tokenization at
-            # position i+1 and higher.
-            if restrict and self.restrictions[i]:
-                for r in restrict:
-                    if r not in self.restrictions[i]:
-                        raise NotImplementedError("Unimplemented: restriction set changed")
-            return self.tokens[i]
-        raise NoMoreTokens()
-
-    def compiled_token(self,i,restrict=0):
-        try:
-            return StarScan.token(i)
-        except IndexError:
-            raise NoMoreTokens()
-
-    def __repr__(self):
-        """Print the last 10 tokens that have been scanned in"""
-        output = ''
-        if self.scantype != "flex":
-            for t in self.tokens[-10:]:
-                output = '%s\n  (@%s)  %s  =  %s' % (output,t[0],t[2],repr(t[3]))
-        else:
-            out_tokens = StarScan.last_ten()
-            for t in out_tokens:
-                output = '%s\n  (~line %s)  %s  =  %s' % (output,t[0],t[2],repr(t[3]))
-        return output
-
-    def interp_scan(self, restrict):
-        """Should scan another token and add it to the list, self.tokens,
-        and add the restriction to self.restrictions"""
-        # Prepare accepted pattern list
-        if restrict:
-           # only patterns in the 'restrict' parameter or in self.ignore
-           # are accepted
-           accepted_patterns=[]
-           for p_name, p_regexp in self.patterns:
-               if p_name not in restrict and p_name not in self.ignore:
-                   pass
-               else:
-                   accepted_patterns.append((p_name,p_regexp))
-        else:
-           # every pattern is good
-           accepted_patterns=self.patterns
-        # Keep looking for a token, ignoring any in self.ignore
-        while 1:
-            # Search the patterns for the longest match, with earlier
-            # tokens in the list having preference
-            best_match = -1
-            best_pat = '(error)'
-            for p,regexp in accepted_patterns:
-                m = regexp.match(self.input, self.pos)
-                if m and len(m.group(0)) > best_match:
-                    # We got a match that's better than the previous one
-                    best_pat = p
-                    best_match = len(m.group(0))
-
-            # If we didn't find anything, raise an error
-            if best_pat == '(error)' and best_match < 0:
-                msg = 'Bad Token'
-                if restrict:
-                    msg = 'Trying to find one of '+', '.join(restrict)
-                raise YappsSyntaxError(self.pos, msg)
-
-            # If we found something that isn't to be ignored, return it
-            if best_pat not in self.ignore:
-                # Create a token with this data
-                token = (self.pos, self.pos+best_match, best_pat,
-                         self.input[self.pos:self.pos+best_match])
-                self.pos = self.pos + best_match
-                # Only add this token if it's not in the list
-                # (to prevent looping)
-                if not self.tokens or token != self.tokens[-1]:
-                    self.tokens.append(token)
-                    self.restrictions.append(restrict)
-                return
-            else:
-                # This token should be ignored ..
-                self.pos = self.pos + best_match
-
-    def compiled_scan(self,restrict):
-        token = StarScan.scan()
-        print("Calling compiled scan, got %s" % repr(token))
-        if token[2] not in restrict:
-            msg = "Bad Token"
-            if restrict:
-               msg = "Trying to find one of " + ", ".join(restrict)
-            raise YappsSyntaxError(self.pos,msg)
-        self.tokens.append(token)
-        self.restrictions.append(restrict)
-        return
-
-class Parser:
-    """Base class for Yapps-generated parsers.
-
-    """
-
-    def __init__(self, scanner):
-        self._scanner = scanner
-        self._pos = 0
-
-    def _peek(self, *types):
-        """Returns the token type for lookahead; if there are any args
-        then the list of args is the set of token types to allow"""
-        tok = self._scanner.token(self._pos, types)
-        return tok[2]
-
-    def _scan(self, type):
-        """Returns the matched text, and moves to the next token"""
-        tok = self._scanner.token(self._pos, [type])
-        if tok[2] != type:
-            raise YappsSyntaxError(tok[0], 'Trying to find '+type+' :'+ ' ,')
-        self._pos = 1 + self._pos
-        return tok[3]
-
-class Context:
-    """Class to represent the parser's call stack.
-
-    Every rule creates a Context that links to its parent rule.  The
-    contexts can be used for debugging.
-
-    """
-
-    def __init__(self, parent, scanner, tokenpos, rule, args=()):
-        """Create a new context.
-
-        Args:
-        parent: Context object or None
-        scanner: Scanner object
-        pos: integer (scanner token position)
-        rule: string (name of the rule)
-        args: tuple listing parameters to the rule
-
-        """
-        self.parent = parent
-        self.scanner = scanner
-        self.tokenpos = tokenpos
-        self.rule = rule
-        self.args = args
-
-    def __str__(self):
-        output = ''
-        if self.parent: output = str(self.parent) + ' > '
-        output += self.rule
-        return output
-
-#
-#  Note that this sort of error printout is useless with the
-#  compiled scanner
-#
-
-def print_line_with_pointer(text, p):
-    """Print the line of 'text' that includes position 'p',
-    along with a second line with a single caret (^) at position p"""
-
-    # TODO: separate out the logic for determining the line/character
-    # location from the logic for determining how to display an
-    # 80-column line to stderr.
-
-    # Now try printing part of the line
-    text = text[max(p-80, 0):p+80]
-    p = p - max(p-80, 0)
-
-    # Strip to the left
-    i = text[:p].rfind('\n')
-    j = text[:p].rfind('\r')
-    if i < 0 or (0 <= j < i): i = j
-    if 0 <= i < p:
-        p = p - i - 1
-        text = text[i+1:]
-
-    # Strip to the right
-    i = text.find('\n', p)
-    j = text.find('\r', p)
-    if i < 0 or (0 <= j < i): i = j
-    if i >= 0:
-        text = text[:i]
-
-    # Now shorten the text
-    while len(text) > 70 and p > 60:
-        # Cut off 10 chars
-        text = "..." + text[10:]
-        p = p - 7
-
-    # Now print the string, along with an indicator
-    print('> ',text,file=sys.stderr)
-    print('> ',' '*p + '^',file=sys.stderr)
-
-def print_error(input, err, scanner):
-    """Print error messages, the parser stack, and the input text -- for human-readable error messages."""
-    # NOTE: this function assumes 80 columns :-(
-    # Figure out the line number
-    line_number = scanner.get_line_number()
-    column_number = scanner.get_column_number()
-    print('%d:%d: %s' % (line_number, column_number, err.msg),file=sys.stderr)
-
-    context = err.context
-    if not context:
-        print_line_with_pointer(input, err.charpos)
-
-    while context:
-        # TODO: add line number
-        print('while parsing %s%s:' % (context.rule, tuple(context.args)),file=sys.stderr)
-        print_line_with_pointer(input, context.scanner.get_prev_char_pos(context.tokenpos))
-        context = context.parent
-
-def wrap_error_reporter(parser, rule):
-    try:
-        return getattr(parser, rule)()
-    except YappsSyntaxError as e:
-        input = parser._scanner.input
-        print_error(input, e, parser._scanner)
-    except NoMoreTokens:
-        print('Could not complete parsing; stopped around here:',file=sys.stderr)
-        print(parser._scanner,file=sys.stderr)
+#
+# Yapps 2 Runtime, part of Yapps 2 - yet another python parser system
+# Copyright 1999-2003 by Amit J. Patel <amitp@cs.stanford.edu>
+#
+# This version of the Yapps 2 Runtime can be distributed under the
+# terms of the MIT open source license, either found in the LICENSE file
+# included with the Yapps distribution
+# <http://theory.stanford.edu/~amitp/yapps/> or at
+# <http://www.opensource.org/licenses/mit-license.php>
+#
+# Modified for PyCIFRW by JRH to allow external scanner
+#
+# To maximize python3/python2 compatibility
+from __future__ import print_function
+from __future__ import unicode_literals
+from __future__ import division
+from __future__ import absolute_import
+
+""" Detail of JRH modifications.
+
+The compiled module handles all token administration by itself, but
+does not deal with restrictions.  It also effectively removes the
+context-sensitivity of Yapps, as it ignores restrictions, but
+these restrictions turn out to be  unnecessary for CIF.
+
+Interestingly, the module scan function is never called directly
+from python.
+
+"""
+
+"""Run time libraries needed to run parsers generated by Yapps.
+
+This module defines parse-time exception classes, a scanner class, a
+base class for parsers produced by Yapps, and a context class that
+keeps track of the parse stack.
+
+"""
+
+# TODO: it should be possible to embed yappsrt into the generated
+# grammar to make a standalone module.
+
+import sys, re
+
+
+# For normal installation this module is "emapsCifFile.yapps3_compiled_rt"
+# and StarScan is an extension module within the parent CifFile module.
+if __name__.startswith('pyemaps.CifFile.'):
+    try:
+        from . import StarScan
+        have_star_scan = True
+    except ImportError:
+        have_star_scan = False
+# Otherwise assume this is imported from the yapps3/yapps2.py script
+# that is executed from Makefile to generate YappsStarParser sources.
+else:
+    assert __name__ == 'yapps3_compiled_rt', "Unexpected module name."
+    assert sys.argv[0].endswith('yapps2.py'), (
+        "This should be reached only when running yapps2.py in Makefile.")
+    have_star_scan = False
+
+class YappsSyntaxError(Exception):
+    """When we run into an unexpected token, this is the exception to use"""
+    def __init__(self, charpos=-1, msg="Bad Token", context=None):
+        Exception.__init__(self)
+        self.charpos = charpos
+        self.msg = msg
+        self.context = context
+
+    def __str__(self):
+        if self.charpos < 0: return 'SyntaxError'
+        else: return 'SyntaxError@char%s(%s)' % (repr(self.charpos), self.msg)
+
+class NoMoreTokens(Exception):
+    """Another exception object, for when we run out of tokens"""
+    pass
+
+class Scanner:
+    """Yapps scanner.
+
+    The Yapps scanner can work in context sensitive or context
+    insensitive modes.  The token(i) method is used to retrieve the
+    i-th token.  It takes a restrict set that limits the set of tokens
+    it is allowed to return.  In context sensitive mode, this restrict
+    set guides the scanner.  In context insensitive mode, there is no
+    restriction (the set is always the full set of tokens).
+
+    """
+
+    def __init__(self, patterns, ignore, input, scantype="standard"):
+        """Initialize the scanner.
+
+        Parameters:
+          patterns : [(terminal, uncompiled regex), ...] or None
+          ignore : [terminal,...]
+          input : string
+
+        If patterns is None, we assume that the subclass has
+        defined self.patterns : [(terminal, compiled regex), ...].
+        Note that the patterns parameter expects uncompiled regexes,
+        whereas the self.patterns field expects compiled regexes.
+        """
+        self.tokens = [] # [(begin char pos, end char pos, token name, matched text), ...]
+        self.restrictions = []
+        self.input = input
+        self.pos = 0
+        self.ignore = ignore
+        self.scantype = scantype
+        self.first_line_number = 1
+        if self.scantype == "flex" and have_star_scan:
+            StarScan.prepare(input)
+            self.scan = self.compiled_scan
+            self.token = self.compiled_token
+            self.__del__ = StarScan.cleanup
+        elif self.scantype == "flex":
+            print("WARNING: using Python scanner although C scanner requested")
+            self.scantype = "standard"
+        if self.scantype != "flex":
+            self.scan = self.interp_scan
+            self.token = self.interp_token
+
+        if patterns is not None:
+            # Compile the regex strings into regex objects
+            self.patterns = []
+            for terminal, regex in patterns:
+                self.patterns.append( (terminal, re.compile(regex)) )
+
+    def get_token_pos(self):
+        """Get the current token position in the input text."""
+        return len(self.tokens)
+
+    def get_char_pos(self):
+        """Get the current char position in the input text."""
+        return self.pos
+
+    def get_prev_char_pos(self, i=None):
+        """Get the previous position (one token back) in the input text."""
+        if self.pos == 0: return 0
+        if i is None: i = -1
+        return self.tokens[i][0]
+
+    def get_line_number(self):
+        """Get the line number of the current position in the input text."""
+        # TODO: make this work at any token/char position
+        return self.first_line_number + self.get_input_scanned().count('\n')
+
+    def get_column_number(self):
+        """Get the column number of the current position in the input text."""
+        s = self.get_input_scanned()
+        i = s.rfind('\n') # may be -1, but that's okay in this case
+        return len(s) - (i+1)
+
+    def get_input_scanned(self):
+        """Get the portion of the input that has been tokenized."""
+        return self.input[:self.pos]
+
+    def get_input_unscanned(self):
+        """Get the portion of the input that has not yet been tokenized."""
+        return self.input[self.pos:]
+
+    def interp_token(self, i, restrict=None):
+        """Get the i'th token in the input.
+
+        If i is one past the end, then scan for another token.
+
+        Args:
+
+        restrict : [token, ...] or None; if restrict is None, then any
+        token is allowed.  You may call token(i) more than once.
+        However, the restrict set may never be larger than what was
+        passed in on the first call to token(i).
+
+        """
+        if i == len(self.tokens):
+            self.scan(restrict)
+        if i < len(self.tokens):
+            # Make sure the restriction is more restricted.  This
+            # invariant is needed to avoid ruining tokenization at
+            # position i+1 and higher.
+            if restrict and self.restrictions[i]:
+                for r in restrict:
+                    if r not in self.restrictions[i]:
+                        raise NotImplementedError("Unimplemented: restriction set changed")
+            return self.tokens[i]
+        raise NoMoreTokens()
+
+    def compiled_token(self,i,restrict=0):
+        try:
+            return StarScan.token(i)
+        except IndexError:
+            raise NoMoreTokens()
+
+    def __repr__(self):
+        """Print the last 10 tokens that have been scanned in"""
+        output = ''
+        if self.scantype != "flex":
+            for t in self.tokens[-10:]:
+                output = '%s\n  (@%s)  %s  =  %s' % (output,t[0],t[2],repr(t[3]))
+        else:
+            out_tokens = StarScan.last_ten()
+            for t in out_tokens:
+                output = '%s\n  (~line %s)  %s  =  %s' % (output,t[0],t[2],repr(t[3]))
+        return output
+
+    def interp_scan(self, restrict):
+        """Should scan another token and add it to the list, self.tokens,
+        and add the restriction to self.restrictions"""
+        # Prepare accepted pattern list
+        if restrict:
+           # only patterns in the 'restrict' parameter or in self.ignore
+           # are accepted
+           accepted_patterns=[]
+           for p_name, p_regexp in self.patterns:
+               if p_name not in restrict and p_name not in self.ignore:
+                   pass
+               else:
+                   accepted_patterns.append((p_name,p_regexp))
+        else:
+           # every pattern is good
+           accepted_patterns=self.patterns
+        # Keep looking for a token, ignoring any in self.ignore
+        while 1:
+            # Search the patterns for the longest match, with earlier
+            # tokens in the list having preference
+            best_match = -1
+            best_pat = '(error)'
+            for p,regexp in accepted_patterns:
+                m = regexp.match(self.input, self.pos)
+                if m and len(m.group(0)) > best_match:
+                    # We got a match that's better than the previous one
+                    best_pat = p
+                    best_match = len(m.group(0))
+
+            # If we didn't find anything, raise an error
+            if best_pat == '(error)' and best_match < 0:
+                msg = 'Bad Token'
+                if restrict:
+                    msg = 'Trying to find one of '+', '.join(restrict)
+                raise YappsSyntaxError(self.pos, msg)
+
+            # If we found something that isn't to be ignored, return it
+            if best_pat not in self.ignore:
+                # Create a token with this data
+                token = (self.pos, self.pos+best_match, best_pat,
+                         self.input[self.pos:self.pos+best_match])
+                self.pos = self.pos + best_match
+                # Only add this token if it's not in the list
+                # (to prevent looping)
+                if not self.tokens or token != self.tokens[-1]:
+                    self.tokens.append(token)
+                    self.restrictions.append(restrict)
+                return
+            else:
+                # This token should be ignored ..
+                self.pos = self.pos + best_match
+
+    def compiled_scan(self,restrict):
+        token = StarScan.scan()
+        print("Calling compiled scan, got %s" % repr(token))
+        if token[2] not in restrict:
+            msg = "Bad Token"
+            if restrict:
+               msg = "Trying to find one of " + ", ".join(restrict)
+            raise YappsSyntaxError(self.pos,msg)
+        self.tokens.append(token)
+        self.restrictions.append(restrict)
+        return
+
+class Parser:
+    """Base class for Yapps-generated parsers.
+
+    """
+
+    def __init__(self, scanner):
+        self._scanner = scanner
+        self._pos = 0
+
+    def _peek(self, *types):
+        """Returns the token type for lookahead; if there are any args
+        then the list of args is the set of token types to allow"""
+        tok = self._scanner.token(self._pos, types)
+        return tok[2]
+
+    def _scan(self, type):
+        """Returns the matched text, and moves to the next token"""
+        tok = self._scanner.token(self._pos, [type])
+        if tok[2] != type:
+            raise YappsSyntaxError(tok[0], 'Trying to find '+type+' :'+ ' ,')
+        self._pos = 1 + self._pos
+        return tok[3]
+
+class Context:
+    """Class to represent the parser's call stack.
+
+    Every rule creates a Context that links to its parent rule.  The
+    contexts can be used for debugging.
+
+    """
+
+    def __init__(self, parent, scanner, tokenpos, rule, args=()):
+        """Create a new context.
+
+        Args:
+        parent: Context object or None
+        scanner: Scanner object
+        pos: integer (scanner token position)
+        rule: string (name of the rule)
+        args: tuple listing parameters to the rule
+
+        """
+        self.parent = parent
+        self.scanner = scanner
+        self.tokenpos = tokenpos
+        self.rule = rule
+        self.args = args
+
+    def __str__(self):
+        output = ''
+        if self.parent: output = str(self.parent) + ' > '
+        output += self.rule
+        return output
+
+#
+#  Note that this sort of error printout is useless with the
+#  compiled scanner
+#
+
+def print_line_with_pointer(text, p):
+    """Print the line of 'text' that includes position 'p',
+    along with a second line with a single caret (^) at position p"""
+
+    # TODO: separate out the logic for determining the line/character
+    # location from the logic for determining how to display an
+    # 80-column line to stderr.
+
+    # Now try printing part of the line
+    text = text[max(p-80, 0):p+80]
+    p = p - max(p-80, 0)
+
+    # Strip to the left
+    i = text[:p].rfind('\n')
+    j = text[:p].rfind('\r')
+    if i < 0 or (0 <= j < i): i = j
+    if 0 <= i < p:
+        p = p - i - 1
+        text = text[i+1:]
+
+    # Strip to the right
+    i = text.find('\n', p)
+    j = text.find('\r', p)
+    if i < 0 or (0 <= j < i): i = j
+    if i >= 0:
+        text = text[:i]
+
+    # Now shorten the text
+    while len(text) > 70 and p > 60:
+        # Cut off 10 chars
+        text = "..." + text[10:]
+        p = p - 7
+
+    # Now print the string, along with an indicator
+    print('> ',text,file=sys.stderr)
+    print('> ',' '*p + '^',file=sys.stderr)
+
+def print_error(input, err, scanner):
+    """Print error messages, the parser stack, and the input text -- for human-readable error messages."""
+    # NOTE: this function assumes 80 columns :-(
+    # Figure out the line number
+    line_number = scanner.get_line_number()
+    column_number = scanner.get_column_number()
+    print('%d:%d: %s' % (line_number, column_number, err.msg),file=sys.stderr)
+
+    context = err.context
+    if not context:
+        print_line_with_pointer(input, err.charpos)
+
+    while context:
+        # TODO: add line number
+        print('while parsing %s%s:' % (context.rule, tuple(context.args)),file=sys.stderr)
+        print_line_with_pointer(input, context.scanner.get_prev_char_pos(context.tokenpos))
+        context = context.parent
+
+def wrap_error_reporter(parser, rule):
+    try:
+        return getattr(parser, rule)()
+    except YappsSyntaxError as e:
+        input = parser._scanner.input
+        print_error(input, e, parser._scanner)
+    except NoMoreTokens:
+        print('Could not complete parsing; stopped around here:',file=sys.stderr)
+        print(parser._scanner,file=sys.stderr)
```

### Comparing `pyemaps-1.0.8/__config__.py` & `pyemaps-1.0.9/__config__.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/__init__.py` & `pyemaps-1.0.9/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -221,8 +221,8 @@
 except ImportError as e:
     print(f'Error importing kinematic constants: {e}')
 
 #--------------ediom features -------------------------------
 from .stackimg import StackImage
 
 #--------------Pyemaps Display Functions-------------------------------------
-from .display import showDif, showBloch, showStereo
+from .display import showDif, showBloch, showStereo, plot2Powder
```

### Comparing `pyemaps-1.0.8/__main__.py` & `pyemaps-1.0.9/__main__.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/BiMnO3.xtl` & `pyemaps-1.0.9/cdata/BiMnO3.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/Boron_Tetra.xtl` & `pyemaps-1.0.9/cdata/Boron_Tetra.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/ErbiumPyrogermanate.xtl` & `pyemaps-1.0.9/cdata/ErbiumPyrogermanate.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/FeS2_Pyrite.xtl` & `pyemaps-1.0.9/cdata/FeS2_Pyrite.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/LeadZirconateTitanate.xtl` & `pyemaps-1.0.9/cdata/LeadZirconateTitanate.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/Li2MnO3.xtl` & `pyemaps-1.0.9/cdata/Li2MnO3.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/Pentacene.xtl` & `pyemaps-1.0.9/cdata/Pentacene.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/cdata/SiAlONa.xtl` & `pyemaps-1.0.9/cdata/SiAlONa.xtl`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/crystals.py` & `pyemaps-1.0.9/crystals.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/ddiffs.py` & `pyemaps-1.0.9/ddiffs.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/diffract/__init__.py` & `pyemaps-1.0.9/diffract/__init__.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/diffract/bloch_dec.py` & `pyemaps-1.0.9/diffract/bloch_dec.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,7 +1,32 @@
+'''
+This file is part of pyemaps
+___________________________
+
+pyemaps is free software for non-comercial use: you can 
+redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation, either 
+version 3 of the License, or (at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+
+
+Author:             EMLab Solutions, Inc.
+Date Created:       May 07, 2022  
+
+'''
 def add_bloch(target):    
     """
     
     Dynamic Simulation Specific Controls Default Values:
     ---------------------------------------------------- 
 
     .. data:: DEF_APERTURE
```

### Comparing `pyemaps-1.0.8/diffract/csf_dec.py` & `pyemaps-1.0.9/diffract/csf_dec.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,7 +1,32 @@
+'''
+This file is part of pyemaps
+___________________________
+
+pyemaps is free software for non-comercial use: you can 
+redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation, either 
+version 3 of the License, or (at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+
+
+Author:             EMLab Solutions, Inc.
+Date Created:       May 07, 2022  
+
+'''
 def add_csf(target):
     '''
       Generate crystal structure factors. The following types 
       Structure Factors are currently supported:
 
       * x-ray structure factor (default)
       * electron structure factor in volts (V)
```

### Comparing `pyemaps-1.0.8/diffract/dif_dec.py` & `pyemaps-1.0.9/diffract/dif_dec.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,33 @@
+'''
+This file is part of pyemaps
+___________________________
+
+pyemaps is free software for non-comercial use: you can 
+redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation, either 
+version 3 of the License, or (at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+
+
+Author:             EMLab Solutions, Inc.
+Date Created:       May 07, 2022  
+
+'''
 def add_dif(target):
-    
-        
     import numpy as np
     from numpy import asfortranarray as farray
 
     from . import dif
     from .. import EMC, DP
     from .. import DEF_MODE, DEF_CBED_DSIZE, DEF_XAXIS
     from .. import EMCError,DPListError,CrystalClassError,DPError
```

### Comparing `pyemaps-1.0.8/diffract/dpgen_dec.py` & `pyemaps-1.0.9/diffract/dpgen_dec.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,32 @@
+'''
+This file is part of pyemaps
+___________________________
 
+pyemaps is free software for non-comercial use: you can 
+redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation, either 
+version 3 of the License, or (at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+
+
+Author:             EMLab Solutions, Inc.
+Date Created:       May 07, 2022  
+
+'''
 def add_dpgen(target):
     try:
         from . import dif, dpgen
 
     except ImportError as e:             
         # return an empty target if non-extant
         return target
```

### Comparing `pyemaps-1.0.8/diffract/mxtal_dec.py` & `pyemaps-1.0.9/diffract/mxtal_dec.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,32 @@
+'''
+This file is part of pyemaps
+___________________________
 
+pyemaps is free software for non-comercial use: you can 
+redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation, either 
+version 3 of the License, or (at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+
+
+Author:             EMLab Solutions, Inc.
+Date Created:       May 07, 2022  
+
+'''
 def add_mxtal(target):
     from . import dif
     from .. import (ID_MATRIX, MLEN, DEF_CELLBOX, 
                    DEF_XZ, DEF_ORSHIFT, DEF_TRSHIFT,
                    DEF_LOCASPACE)
     from .. import MxtalError
     from ..fileutils import compose_ofn
```

### Comparing `pyemaps-1.0.8/diffract/stereo_dec.py` & `pyemaps-1.0.9/diffract/stereo_dec.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,7 +1,32 @@
+'''
+This file is part of pyemaps
+___________________________
+
+pyemaps is free software for non-comercial use: you can 
+redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation, either 
+version 3 of the License, or (at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+
+
+Author:             EMLab Solutions, Inc.
+Date Created:       May 07, 2022  
+
+'''
 def add_stereo(target):
     def generateStereo(self, xa = (0,2,0), 
                             tilt=(0.0,0.0),
                             zone = (0, 0, 1)):
         """
         Generate stereodiagram.
```

### Comparing `pyemaps-1.0.8/display.py` & `pyemaps-1.0.9/display.py`

 * *Files 8% similar despite different names*

```diff
@@ -29,14 +29,16 @@
 
 """
 import matplotlib, sys, os
 hasDisplay = True
 if 'linux' in sys.platform and "DISPLAY" not in os.environ:
     hasDisplay = False
     matplotlib.use('Agg')
+elif 'win32' in sys.platform:
+    matplotlib.use('TkAgg') # make sure that the backend is Tkinker
 
 import matplotlib.pyplot as plt
 import matplotlib.patches as patches
 import multiprocessing as mp
 
 from pyemaps import BlochListError
 from pyemaps import DP
@@ -195,15 +197,15 @@
                         verticalalignment='bottom' if mode == 1 else 'center')
            
         if self.cShow:
             self.plotControls(emc,iax)
 
 
     def plotDDif(self):
-        # import matplotlib.colors as colors
+        
         from matplotlib.colors import LinearSegmentedColormap
 
         idx, emc, img, color = self.difData
         
         if self.layout == 'table':
             n1, n2 = _getGridPos(idx, 3)
         else:
@@ -347,14 +349,15 @@
                 plt.pause(1.0)
 
         return True
 
     def showImage(self):
         if _isLinux() and not hasDisplay:
             return
+        
         plt.show()
         
 
     def position_fig(self, x, y):
         backend = matplotlib.get_backend()
         if backend == 'TkAgg':
             self.fig.canvas.manager.window.wm_geometry("+%d+%d" % (x, y))
@@ -739,9 +742,36 @@
 
                 if iShow:
                     ax.text(centre[0],centre[1], 
                         str(indx),
                         {'color': 'red', 'fontsize': 1.4},
                         horizontalalignment='center',
                         verticalalignment='bottom')
-        
-        plt.show()
+                    
+        plt.show()
+
+def plot2Powder(pw1, pw2):
+    """
+    plot multiple powder diffraction in one plt plot
+    """
+
+    fig, (ax1, ax2) = plt.subplots(nrows = 2)
+    
+    title = 'PYEMAPS - Powder Diffraction'
+    if fig.canvas.manager is not None:
+        fig.canvas.manager.set_window_title(title)
+    else:
+        fig.canvas.set_window_title(title)    
+    
+    ax1.plot(pw1[0], pw1[1], 'r')
+    ax1.set_title('Silicon')
+    ax2.plot(pw2[0], pw2[1], 'b')
+    ax2.set_title('Diamond')
+    
+    ax1.set_ylabel('Intensity')
+    ax2.set_ylabel('Intensity /w Absorption')
+    ax2.set_xlabel('Scattering Angle 2\u03F4 (Rad)')
+
+    fig.suptitle("Electron Powder Diffraction", fontsize=14, fontweight='bold')
+    plt.subplots_adjust(hspace = 0.4)
+
+    plt.show()
```

### Comparing `pyemaps-1.0.8/emcontrols.py` & `pyemaps-1.0.9/emcontrols.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/errors.py` & `pyemaps-1.0.9/errors.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/fileutils.py` & `pyemaps-1.0.9/fileutils.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/kdiffs.py` & `pyemaps-1.0.9/kdiffs.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/license.txt` & `pyemaps-1.0.9/license.txt`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/pyemaps.egg-info/SOURCES.txt` & `pyemaps-1.0.9/pyemaps.egg-info/SOURCES.txt`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/adf.py` & `pyemaps-1.0.9/samples/adf.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/al.img` & `pyemaps-1.0.9/samples/al.img`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/al_dpgen.py` & `pyemaps-1.0.9/samples/al_dpgen.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/al_ediom.py` & `pyemaps-1.0.9/samples/al_ediom.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/dm_diff.py` & `pyemaps-1.0.9/samples/dm_diff.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/powder.py` & `pyemaps-1.0.9/samples/si_pyemaps.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-'''
+"""
 This file is part of pyemaps
 ___________________________
 
 pyemaps is free software for non-comercial use: you can 
 redistribute it and/or modify it under the terms of the GNU General 
 Public License as published by the Free Software Foundation, either 
 version 3 of the License, or (at your option) any later version.
@@ -14,61 +14,67 @@
 
 You should have received a copy of the GNU General Public License
 along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
 
 Contact supprort@emlabsoftware.com for any questions and comments.
 ___________________________
 
-Author:     EMLab Solutions, Inc.
-Date:       May 31, 2022    
+An example of using pyemaps crystal and diffraction modules to 
+1) create a crystal from built-in data for Silicon 
+2) generate kinematical diffraction patterns
+3) display the diffraction pattern using pyemaps's built-in plot function 
 
+See https://emlab-solutions.github.io/pyemaps/ for pemaps usage
 
-This sample code is to demonstrate how to generate powder diffraction.
-'''
+Author:     EMLab Solutions, Inc.
+Date:       May 07, 2022    
 
-def plot2Powder(pw1, pw2):
-    """
-    plot multiple powder diffraction in one plt plot
-    """
+"""
 
-    import matplotlib.pyplot as plt
 
-    fig, (ax1, ax2) = plt.subplots(nrows = 2)
-    
-    title = 'PYEMAPS - Powder Diffraction'
-    if fig.canvas.manager is not None:
-        fig.canvas.manager.set_window_title(title)
-    else:
-        fig.canvas.set_window_title(title)    
-    
-    ax1.plot(pw1[0], pw1[1], 'r')
-    ax1.set_title('Silicon')
-    ax2.plot(pw2[0], pw2[1], 'b')
-    ax2.set_title('Diamond')
+def run_si_sample():
+    #import Crystal class from pyemaps as cryst
+    from pyemaps import Crystal as cr
+    from pyemaps import showDif, showBloch
+    from pyemaps import DPList
+    from pyemaps import BImgList
+    # create a crystal class instance and load it with builtin silicon data
+    c_name = 'Silicon'
+    si = cr.from_builtin(c_name)
+
+    # generate diffraction on the crystal instance with all default controls
+    # parameters, default controls returned as the first output ignored
     
-    ax1.set_ylabel('Intensity')
-    ax2.set_ylabel('Intensity /w Absorption')
-    ax2.set_xlabel('Scattering Angle 2\u03F4 (Rad)')
+    dpl = DPList(c_name)
 
-    fig.suptitle("Electron Powder Diffraction", fontsize=14, fontweight='bold')
-    plt.subplots_adjust(hspace = 0.4)
+    emc, si_dp = si.generateDP()
+    dpl.add(emc, si_dp) 
+    
+    #plot and show the diffraction pattern using pyemaps built-in plot function
+    showDif(dpl)
 
-    plt.show()
+    #hide Kikuchi lines
+    showDif(dpl, kShow=False, bClose=True) 
 
-def runPowderTests():
-    from pyemaps import Crystal as cryst
-    import time
+    #plot the following two DP in CBED mode (mode = 2)
+    dpl = DPList(c_name, mode = 2)
 
-    si = cryst.from_builtin('Silicon')
-    print(si)
-    psi = si.generatePowder() 
+    emc, si_dp = si.generateDP(mode = 2)
+    dpl.add(emc, si_dp) 
 
-    # si.plotPowder(psi)
-    di = cryst.from_builtin('Diamond')
-    print(di)
-    pdi = di.generatePowder(absp = 1)
+    #hide both Kukuchi line and Miller Indices
+    showDif(dpl, kShow=False, iShow=False, bClose=True) 
 
-    plot2Powder(psi, pdi)
+    #hide Miller Indices
+    showDif(dpl, iShow=False, bClose=True)
 
-if __name__ == "__main__":
+    #Generate dynamic diffraction patterns using pyemaps' bloch module
     
-    runPowderTests()
+    try:
+      bloch_imgs_list = si.generateBloch(sampling = 20) 
+      
+    except Exception as e:
+      print(f'Error: {e}')
+
+    else:        
+      showBloch(bloch_imgs_list, bClose=True) #grey color map
+      showBloch(bloch_imgs_list, bColor=True, bClose=True) #with predefined color map
```

### Comparing `pyemaps-1.0.8/samples/si_bloch.py` & `pyemaps-1.0.9/samples/si_bloch.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/si_constructor.py` & `pyemaps-1.0.9/samples/si_constructor.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/si_csf.py` & `pyemaps-1.0.9/samples/si_csf.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/si_dif.py` & `pyemaps-1.0.9/samples/si_dif.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/si_lacbed.py` & `pyemaps-1.0.9/samples/si_lacbed.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/samples/si_pyemaps.py` & `pyemaps-1.0.9/samples/si_stereo.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,7 +1,8 @@
+
 """
 This file is part of pyemaps
 ___________________________
 
 pyemaps is free software for non-comercial use: you can 
 redistribute it and/or modify it under the terms of the GNU General 
 Public License as published by the Free Software Foundation, either 
@@ -14,67 +15,101 @@
 
 You should have received a copy of the GNU General Public License
 along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
 
 Contact supprort@emlabsoftware.com for any questions and comments.
 ___________________________
 
-An example of using pyemaps crystal and diffraction modules to 
-1) create a crystal from built-in data for Silicon 
-2) generate kinematical diffraction patterns
-3) display the diffraction pattern using pyemaps's built-in plot function 
-
-See https://emlab-solutions.github.io/pyemaps/ for pemaps usage
+```
 
 Author:     EMLab Solutions, Inc.
-Date:       May 07, 2022    
-
+Date:       September 26th, 2022    
 """
 
+import concurrent.futures
+from re import S
+from pyemaps import EMC, DPError,EMCError
 
-def run_si_sample():
-    #import Crystal class from pyemaps as cryst
-    from pyemaps import Crystal as cr
-    from pyemaps import showDif, showBloch
-    from pyemaps import DPList
-    from pyemaps import BImgList
-    # create a crystal class instance and load it with builtin silicon data
-    c_name = 'Silicon'
-    si = cr.from_builtin(c_name)
+MAX_PROCWORKERS = 4
 
-    # generate diffraction on the crystal instance with all default controls
-    # parameters, default controls returned as the first output ignored
+def getStereo(cn, emc = EMC(), ckey='tilt'):
+    from pyemaps import Crystal as cr
     
-    dpl = DPList(c_name)
-
-    emc, si_dp = si.generateDP()
-    dpl.add(emc, si_dp) 
+    if cn is None:
+        return None
     
-    #plot and show the diffraction pattern using pyemaps built-in plot function
-    showDif(dpl)
-
-    #hide Kikuchi lines
-    showDif(dpl, kShow=False, bClose=True) 
-
-    #plot the following two DP in CBED mode (mode = 2)
-    dpl = DPList(c_name, mode = 2)
-
-    emc, si_dp = si.generateDP(mode = 2)
-    dpl.add(emc, si_dp) 
-
-    #hide both Kukuchi line and Miller Indices
-    showDif(dpl, kShow=False, iShow=False, bClose=True) 
-
-    #hide Miller Indices
-    showDif(dpl, iShow=False, bClose=True)
-
-    #Generate dynamic diffraction patterns using pyemaps' bloch module
+    cc = cr.from_builtin(cn)
     
-    try:
-      bloch_imgs_list = si.generateBloch(sampling = 20) 
-      
-    except Exception as e:
-      print(f'Error: {e}')
+    if ckey is None:
+        stereo = cc.generateStereo()
+        return cn, emc, stereo
+
+    if ckey == 'tilt':
+        stereo = cc.generateStereo(tilt = emc.tilt) 
+        return cn, emc, stereo
+    elif (ckey == 'zone'): 
+        stereo = cc.generateStereo(zone = emc.zone)
+        return cn, emc, stereo
+    else:
+        return None
+
+
+def generate_stereo(name = 'Silicon', ckey = 'tilt'):
+    '''
+    This routine demonstrate how to use pyemaps stereo module 
+    to generate stereodiagram
+    
+    : name: crystal name from builtin database
+    : ckey: emcontrol key name to change
+    
+    '''
+    
+    emclist = []
+    for i in range(-3,3): 
+        
+        if ckey == 'tilt':
+            emclist.append(EMC(tilt=(i*0.5, 0.0)))
+  
+        if ckey == 'zone':
+            emclist.append(EMC(zone=(i,-i,1)))
 
-    else:        
-      showBloch(bloch_imgs_list, bClose=True) #grey color map
-      showBloch(bloch_imgs_list, bColor=True, bClose=True) #with predefined color map
+    
+    fs = []
+    slist=[]
+    with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_PROCWORKERS) as e:
+        
+        for ec in emclist:
+            fs.append(e.submit(getStereo, cn = name, emc = ec, ckey = ckey))
+
+        for f in concurrent.futures.as_completed(fs):
+            try:
+                _, emc, stereo = f.result()               
+            except Exception as e:
+                print('failed to generate stereodiagram with ' + str(e))
+                exit(1)
+            else:
+                slist.append((emc, stereo))  
+                    
+    #  sorting the list by controls
+    slist.sort(key=lambda x: x[0])
+
+    return slist
+
+if __name__ == '__main__':
+    from pyemaps import showStereo
+
+    # display in table format
+    stereoList = generate_stereo(ckey='tilt')
+    showStereo(stereoList, 
+               name='Silicon', 
+               layout='table',
+               iShow=True,
+               bClose=True, 
+               zLimit = 1)
+
+    # display in individual syereodiagram
+    stereoList = generate_stereo(ckey='zone')
+    showStereo(stereoList, 
+               name='Silicon',
+               iShow=True,
+               bClose=True, 
+               zLimit = 1)
```

### Comparing `pyemaps-1.0.8/samples/si_scm.py` & `pyemaps-1.0.9/samples/si_scm.py`

 * *Files identical despite different names*

### Comparing `pyemaps-1.0.8/scattering/__init__.py` & `pyemaps-1.0.9/spg/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# '''
-# This file is part of pyemaps
-# ___________________________
-#
-# pyemaps is free software: you can redistribute it and/or modify
-# it under the terms of the GNU General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# pyemaps is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU General Public License for more details.
-#
-# You should have received a copy of the GNU General Public License
-# along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-# Contact supprort@emlabsoftware.com for any questions and comments.
-# ___________________________
-# '''
+'''
+This module is part of pyemaps.
+___________________________
 
-# root directory for all emaps modules
-from emaps import sct
+pyemaps is free software: you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation, either version 3 of the License, or
+(at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+'''
+
+from emaps import spgseek
```

### Comparing `pyemaps-1.0.8/setup.cfg` & `pyemaps-1.0.9/setup.cfg`

 * *Files 13% similar despite different names*

```diff
@@ -33,15 +33,11 @@
 00000200: 6772 6170 6879 0d0a 0950 7974 686f 6e0d  graphy...Python.
 00000210: 0a75 726c 203d 2068 7474 7073 3a2f 2f77  .url = https://w
 00000220: 7777 2e65 6d6c 6162 736f 6c75 7469 6f6e  ww.emlabsolution
 00000230: 732e 636f 6d0d 0a0d 0a5b 6f70 7469 6f6e  s.com....[option
 00000240: 735d 0d0a 7079 7468 6f6e 5f72 6571 7569  s]..python_requi
 00000250: 7265 7320 3d20 3e3d 2033 2e37 0d0a 7175  res = >= 3.7..qu
 00000260: 6965 7420 3d20 310d 0a0d 0a5b 6275 696c  iet = 1....[buil
-00000270: 645f 6578 745d 0d0a 696e 636c 7564 655f  d_ext]..include_
-00000280: 6469 7273 203d 2065 6d61 7073 0d0a 6465  dirs = emaps..de
-00000290: 6669 6e65 203d 204c 4f53 0d0a 6663 6f6d  fine = LOS..fcom
-000002a0: 7069 6c65 7220 3d20 696e 7465 6c76 656d  piler = intelvem
-000002b0: 0d0a 636f 6d70 696c 6572 203d 206d 7376  ..compiler = msv
-000002c0: 630d 0a0d 0a5b 6567 675f 696e 666f 5d0d  c....[egg_info].
-000002d0: 0a74 6167 5f62 7569 6c64 203d 200d 0a74  .tag_build = ..t
-000002e0: 6167 5f64 6174 6520 3d20 300d 0a0d 0a    ag_date = 0....
+00000270: 645f 6578 745d 0d0a 0d0a 5b65 6767 5f69  d_ext]....[egg_i
+00000280: 6e66 6f5d 0d0a 7461 675f 6275 696c 6420  nfo]..tag_build 
+00000290: 3d20 0d0a 7461 675f 6461 7465 203d 2030  = ..tag_date = 0
+000002a0: 0d0a 0d0a                                ....
```

### Comparing `pyemaps-1.0.8/setup.py` & `pyemaps-1.0.9/setup.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,7 +1,32 @@
+# '''
+# This file is part of pyemaps
+# ___________________________
+
+# pyemaps is free software for non-comercial use: you can 
+# redistribute it and/or modify it under the terms of the GNU General 
+# Public License as published by the Free Software Foundation, either 
+# version 3 of the License, or (at your option) any later version.
+
+# pyemaps is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+
+# You should have received a copy of the GNU General Public License
+# along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+# Contact supprort@emlabsoftware.com for any questions and comments.
+# ___________________________
+
+
+# Author:             EMLab Solutions, Inc.
+# Date Created:       May 07, 2022  
+
+# '''
 from ast import keyword
 from ensurepip import version
 from multiprocessing import AuthenticationError
 from nturl2path import url2pathname
 from random import sample
 from ssl import Options
 
@@ -20,29 +45,30 @@
             ]
 
 def get_cifreader_source():
     current_path = Path(os.path.abspath(__file__))
     pyemaps_parent_path = current_path.parent.absolute()
     cifreader_path = os.path.join(pyemaps_parent_path, 'CifFile')
 
-    print(f'-----------CifReader Source path: {cifreader_path}')
+    # print(f'-----------CifReader Source path: {cifreader_path}')
 
     src_files = ["src/lib/lex.yy.c","src/lib/py_star_scan.c"]
     return [os.path.join(cifreader_path, s) for s in src_files]
 
 def get_samples(sdn = 'samples'):
     '''
     input: sdn = sample directory name under pyemaps
     '''
 
     import os, glob
     base_dir = os.path.realpath(__file__)
     samples_base_dir = os.path.join(os.path.dirname(base_dir), sdn)
     sbase_files = os.path.join(samples_base_dir, '*.py')
     sfile_list = glob.glob(sbase_files)
+    # for full package only
     # sfile_list.append('al_db.bin')
     sfile_list.append('al.img')
 
     return [os.path.join(sdn, os.path.basename(name)) for name in sfile_list]
 
 def get_cdata(sdn = 'cdata'):
     '''
@@ -148,14 +174,19 @@
                                                 '*.cpp', 
                                                 '*.f90',
                                                 '*.pyd', 
                                                 '*.toml', 
                                                 '*.in', 
                                                 '__pycache__/*.pyc',
                                                 '*.egg-info/*'
+                                                'setup.py',
+                                                'setup_win.cfg',
+                                                'setup_lin.cfg',
+                                                'README.md',
+                                                'CONTRIBUTING.md'
                                                 ],
                                             'pyemaps.ediom':['*.i', 
                                                             '*.cpp',
                                                             '__pycache__/*.pyc'
                                                             ]
                                             }
 )
```

### Comparing `pyemaps-1.0.8/spg/__init__.py` & `pyemaps-1.0.9/scattering/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 '''
-This module is part of pyemaps.
+This file is part of pyemaps
 ___________________________
 
 pyemaps is free software: you can redistribute it and/or modify
 it under the terms of the GNU General Public License as published by
 the Free Software Foundation, either version 3 of the License, or
 (at your option) any later version.
 
@@ -15,8 +15,9 @@
 You should have received a copy of the GNU General Public License
 along with this program.  If not, see <https://www.gnu.org/licenses/>.
 
 Contact supprort@emlabsoftware.com for any questions and comments.
 ___________________________
 '''
 
-from emaps import spgseek
+# root directory for all emaps modules
+from emaps import sct
```

### Comparing `pyemaps-1.0.8/stackimg.py` & `pyemaps-1.0.9/stackimg.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,35 +1,33 @@
-#'''
-# This file is part of pyemaps
-# ___________________________
-
-# pyemaps is free software for non-comercial use: you can 
-# redistribute it and/or modify it under the terms of the GNU General 
-# Public License as published by the Free Software Foundation, either 
-# version 3 of the License, or (at your option) any later version.
-
-# pyemaps is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU General Public License for more details.
-
-# You should have received a copy of the GNU General Public License
-# along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
-
-# Contact supprort@emlabsoftware.com for any questions and comments.
-# ___________________________
-
-# Author:     EMLab Solutions, Inc.
-# Date:       May 16, 2023   
-#'''
-
 '''
+This file is part of pyemaps
+___________________________
+
+pyemaps is free software for non-comercial use: you can 
+redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation, either 
+version 3 of the License, or (at your option) any later version.
+
+pyemaps is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with pyemaps.  If not, see <https://www.gnu.org/licenses/>.
+
+Contact supprort@emlabsoftware.com for any questions and comments.
+___________________________
+
+Author:     EMLab Solutions, Inc.
+Date:       May 16, 2023   
+
 EDIOM (Electron Diffraction Indexing and Orientation Mapping) module 
 in pyemaps contains a rich set of diffraction pattern search and recognition
-functions, as well as those for orientation mapping.
+functions. Future feature addition include orientation mapping.
 
 *StachImage* class is designed to interface with EDIOM functions to provide
 users easy access to the collection of EDIOM features. 
 
 Most of the current and future EDIOM interfaces shown as StackImage
 class methods will be in full pyemaps package, with the exception
 of diffraction indexing method in demo mode in free package.
```

