# Comparing `tmp/SuPyMode-1.2.0-cp312-cp312-win_amd64.whl.zip` & `tmp/SuPyMode-1.2.1-cp312-cp312-macosx_11_0_arm64.whl.zip`

## zipinfo {}

```diff
@@ -1,144 +1,176 @@
-Zip file size: 3863015 bytes, number of entries: 142
--rw-rw-rw-  2.0 fat        7 b- defN 24-May-29 17:34 SuPyMode/VERSION
--rw-rw-rw-  2.0 fat       52 b- defN 24-May-29 17:34 SuPyMode/__init__.py
--rw-rw-rw-  2.0 fat     1165 b- defN 24-May-29 17:34 SuPyMode/directories.py
--rw-rw-rw-  2.0 fat     5219 b- defN 24-May-29 17:34 SuPyMode/mode_label.py
--rw-rw-rw-  2.0 fat    31102 b- defN 24-May-29 17:34 SuPyMode/profiles.py
--rw-rw-rw-  2.0 fat     9049 b- defN 24-May-29 17:34 SuPyMode/solver.py
--rw-rw-rw-  2.0 fat     4775 b- defN 24-May-29 17:34 SuPyMode/special.py
--rw-rw-rw-  2.0 fat    10578 b- defN 24-May-29 17:34 SuPyMode/supermode.py
--rw-rw-rw-  2.0 fat    41698 b- defN 24-May-29 17:34 SuPyMode/superset.py
--rw-rw-rw-  2.0 fat     9808 b- defN 24-May-29 17:34 SuPyMode/utils.py
--rw-rw-rw-  2.0 fat    14653 b- defN 24-May-29 17:34 SuPyMode/workflow.py
--rw-rw-rw-  2.0 fat  1485312 b- defN 24-May-29 17:37 SuPyMode/binary/CppSolver.cp311-win_amd64.pyd
--rw-rw-rw-  2.0 fat  1483776 b- defN 24-May-29 17:42 SuPyMode/binary/CppSolver.cp312-win_amd64.pyd
--rw-rw-rw-  2.0 fat  1078272 b- defN 24-May-29 17:37 SuPyMode/binary/Example.cp311-win_amd64.pyd
--rw-rw-rw-  2.0 fat  1078272 b- defN 24-May-29 17:42 SuPyMode/binary/Example.cp312-win_amd64.pyd
--rw-rw-rw-  2.0 fat  1122816 b- defN 24-May-29 17:37 SuPyMode/binary/ModelParameters.cp311-win_amd64.pyd
--rw-rw-rw-  2.0 fat  1123328 b- defN 24-May-29 17:42 SuPyMode/binary/ModelParameters.cp312-win_amd64.pyd
--rw-rw-rw-  2.0 fat  1157120 b- defN 24-May-29 17:37 SuPyMode/binary/SuperMode.cp311-win_amd64.pyd
--rw-rw-rw-  2.0 fat  1156608 b- defN 24-May-29 17:42 SuPyMode/binary/SuperMode.cp312-win_amd64.pyd
--rw-rw-rw-  2.0 fat        2 b- defN 24-May-29 17:34 SuPyMode/binary/__init__.py
--rw-rw-rw-  2.0 fat      253 b- defN 24-May-29 17:34 SuPyMode/representation/__init__.py
--rw-rw-rw-  2.0 fat     3964 b- defN 24-May-29 17:34 SuPyMode/representation/adiabatic.py
--rw-rw-rw-  2.0 fat     4205 b- defN 24-May-29 17:34 SuPyMode/representation/base.py
--rw-rw-rw-  2.0 fat     3473 b- defN 24-May-29 17:34 SuPyMode/representation/beating_length.py
--rw-rw-rw-  2.0 fat     2762 b- defN 24-May-29 17:34 SuPyMode/representation/beta.py
--rw-rw-rw-  2.0 fat     2501 b- defN 24-May-29 17:34 SuPyMode/representation/eigen_value.py
--rw-rw-rw-  2.0 fat    12984 b- defN 24-May-29 17:34 SuPyMode/representation/field.py
--rw-rw-rw-  2.0 fat     2667 b- defN 24-May-29 17:34 SuPyMode/representation/index.py
--rw-rw-rw-  2.0 fat     3831 b- defN 24-May-29 17:34 SuPyMode/representation/normalized_coupling.py
--rw-rw-rw-  2.0 fat        0 b- defN 24-May-29 17:34 SuPyMode/tools/__init__.py
--rw-rw-rw-  2.0 fat     4775 b- defN 24-May-29 17:34 SuPyMode/tools/special.py
--rw-rw-rw-  2.0 fat     8943 b- defN 24-May-29 17:34 SuPyMode/tools/utils.py
--rw-rw-rw-  2.0 fat     4073 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP02.csv
--rw-rw-rw-  2.0 fat     3640 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP21.csv
--rw-rw-rw-  2.0 fat     3552 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP41.csv
--rw-rw-rw-  2.0 fat     3435 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP12.csv
--rw-rw-rw-  2.0 fat     3871 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP31.csv
--rw-rw-rw-  2.0 fat     3351 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP51.csv
--rw-rw-rw-  2.0 fat    11801 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP02.csv
--rw-rw-rw-  2.0 fat     3180 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP21.csv
--rw-rw-rw-  2.0 fat     9766 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP41.csv
--rw-rw-rw-  2.0 fat     5278 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP12.csv
--rw-rw-rw-  2.0 fat     6584 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP31.csv
--rw-rw-rw-  2.0 fat     9280 b- defN 24-May-29 17:34 SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP51.csv
--rw-rw-rw-  2.0 fat     1129 b- defN 24-May-29 17:34 developments/gradient_tests_2.py
--rw-rw-rw-  2.0 fat     4038 b- defN 24-May-29 17:34 developments/validation.py
--rw-rw-rw-  2.0 fat     4045 b- defN 24-May-29 17:34 developments/validation_2.py
--rw-rw-rw-  2.0 fat      718 b- defN 24-May-29 17:34 docs/examples/basic/plot_alpha_profile_0.py
--rw-rw-rw-  2.0 fat      757 b- defN 24-May-29 17:34 docs/examples/basic/plot_alpha_profile_1.py
--rw-rw-rw-  2.0 fat     3117 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_01.py
--rw-rw-rw-  2.0 fat     3195 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_02.py
--rw-rw-rw-  2.0 fat     3644 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_03.py
--rw-rw-rw-  2.0 fat     3244 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_04.py
--rw-rw-rw-  2.0 fat     3615 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_05.py
--rw-rw-rw-  2.0 fat     3699 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_06.py
--rw-rw-rw-  2.0 fat     3321 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_07.py
--rw-rw-rw-  2.0 fat     3300 b- defN 24-May-29 17:34 docs/examples/basic/plot_workflow_08.py
--rw-rw-rw-  2.0 fat     3580 b- defN 24-May-29 17:34 docs/examples/validation/plot_beta_DCF.py
--rw-rw-rw-  2.0 fat     3573 b- defN 24-May-29 17:34 docs/examples/validation/plot_beta_SMF28.py
--rw-rw-rw-  2.0 fat     3743 b- defN 24-May-29 17:34 docs/examples/validation/plot_normalized_coupling_DCF.py
--rw-rw-rw-  2.0 fat     3912 b- defN 24-May-29 17:34 docs/examples/validation/plot_normalized_coupling_SMF28.py
--rw-rw-rw-  2.0 fat     5878 b- defN 24-May-29 17:34 docs/examples/validation/plot_validation.py
--rw-rw-rw-  2.0 fat     1726 b- defN 24-May-29 17:34 docs/legacy/__debug__.py
--rw-rw-rw-  2.0 fat        0 b- defN 24-May-29 17:34 docs/legacy/python_debuging/__init__.py
--rw-rw-rw-  2.0 fat    11485 b- defN 24-May-29 17:34 docs/legacy/python_debuging/eigen_solver.py
--rw-rw-rw-  2.0 fat    13021 b- defN 24-May-29 17:34 docs/legacy/python_debuging/mode_solver.py
--rw-rw-rw-  2.0 fat     4479 b- defN 24-May-29 17:34 docs/source/conf.py
--rw-rw-rw-  2.0 fat       23 b- defN 24-May-29 17:34 extern/eigen/debug/gdb/__init__.py
--rw-rw-rw-  2.0 fat     9931 b- defN 24-May-29 17:34 extern/eigen/debug/gdb/printers.py
--rw-rw-rw-  2.0 fat     2437 b- defN 24-May-29 17:34 extern/eigen/scripts/relicense.py
--rw-rw-rw-  2.0 fat     2853 b- defN 24-May-29 17:34 extern/pybind11/noxfile.py
--rw-rw-rw-  2.0 fat     5005 b- defN 24-May-29 17:34 extern/pybind11/setup.py
--rw-rw-rw-  2.0 fat     2940 b- defN 24-May-29 17:34 extern/pybind11/docs/benchmark.py
--rw-rw-rw-  2.0 fat    11942 b- defN 24-May-29 17:34 extern/pybind11/docs/conf.py
--rw-rw-rw-  2.0 fat      446 b- defN 24-May-29 17:34 extern/pybind11/pybind11/__init__.py
--rw-rw-rw-  2.0 fat     1606 b- defN 24-May-29 17:34 extern/pybind11/pybind11/__main__.py
--rw-rw-rw-  2.0 fat      245 b- defN 24-May-29 17:34 extern/pybind11/pybind11/_version.py
--rw-rw-rw-  2.0 fat     1244 b- defN 24-May-29 17:34 extern/pybind11/pybind11/commands.py
--rw-rw-rw-  2.0 fat        0 b- defN 24-May-29 17:34 extern/pybind11/pybind11/py.typed
--rw-rw-rw-  2.0 fat    17992 b- defN 24-May-29 17:34 extern/pybind11/pybind11/setup_helpers.py
--rw-rw-rw-  2.0 fat     5840 b- defN 24-May-29 17:34 extern/pybind11/tests/conftest.py
--rw-rw-rw-  2.0 fat      953 b- defN 24-May-29 17:34 extern/pybind11/tests/env.py
--rw-rw-rw-  2.0 fat      560 b- defN 24-May-29 17:34 extern/pybind11/tests/test_async.py
--rw-rw-rw-  2.0 fat     7352 b- defN 24-May-29 17:34 extern/pybind11/tests/test_buffers.py
--rw-rw-rw-  2.0 fat    17771 b- defN 24-May-29 17:34 extern/pybind11/tests/test_builtin_casters.py
--rw-rw-rw-  2.0 fat     6796 b- defN 24-May-29 17:34 extern/pybind11/tests/test_call_policies.py
--rw-rw-rw-  2.0 fat     7180 b- defN 24-May-29 17:34 extern/pybind11/tests/test_callbacks.py
--rw-rw-rw-  2.0 fat     5896 b- defN 24-May-29 17:34 extern/pybind11/tests/test_chrono.py
--rw-rw-rw-  2.0 fat    15686 b- defN 24-May-29 17:34 extern/pybind11/tests/test_class.py
--rw-rw-rw-  2.0 fat      622 b- defN 24-May-29 17:34 extern/pybind11/tests/test_const_name.py
--rw-rw-rw-  2.0 fat     1607 b- defN 24-May-29 17:34 extern/pybind11/tests/test_constants_and_functions.py
--rw-rw-rw-  2.0 fat     4928 b- defN 24-May-29 17:34 extern/pybind11/tests/test_copy_move.py
--rw-rw-rw-  2.0 fat     4114 b- defN 24-May-29 17:34 extern/pybind11/tests/test_custom_type_casters.py
--rw-rw-rw-  2.0 fat     1139 b- defN 24-May-29 17:34 extern/pybind11/tests/test_custom_type_setup.py
--rw-rw-rw-  2.0 fat     2487 b- defN 24-May-29 17:34 extern/pybind11/tests/test_docstring_options.py
--rw-rw-rw-  2.0 fat    29962 b- defN 24-May-29 17:34 extern/pybind11/tests/test_eigen_matrix.py
--rw-rw-rw-  2.0 fat     9702 b- defN 24-May-29 17:34 extern/pybind11/tests/test_eigen_tensor.py
--rw-rw-rw-  2.0 fat     9338 b- defN 24-May-29 17:34 extern/pybind11/tests/test_enum.py
--rw-rw-rw-  2.0 fat     1193 b- defN 24-May-29 17:34 extern/pybind11/tests/test_eval.py
--rw-rw-rw-  2.0 fat      123 b- defN 24-May-29 17:34 extern/pybind11/tests/test_eval_call.py
--rw-rw-rw-  2.0 fat    14586 b- defN 24-May-29 17:34 extern/pybind11/tests/test_exceptions.py
--rw-rw-rw-  2.0 fat    17007 b- defN 24-May-29 17:34 extern/pybind11/tests/test_factory_constructors.py
--rw-rw-rw-  2.0 fat     8749 b- defN 24-May-29 17:34 extern/pybind11/tests/test_gil_scoped.py
--rw-rw-rw-  2.0 fat     7435 b- defN 24-May-29 17:34 extern/pybind11/tests/test_iostream.py
--rw-rw-rw-  2.0 fat    15281 b- defN 24-May-29 17:34 extern/pybind11/tests/test_kwargs_and_defaults.py
--rw-rw-rw-  2.0 fat     8311 b- defN 24-May-29 17:34 extern/pybind11/tests/test_local_bindings.py
--rw-rw-rw-  2.0 fat    18963 b- defN 24-May-29 17:34 extern/pybind11/tests/test_methods_and_attributes.py
--rw-rw-rw-  2.0 fat     4079 b- defN 24-May-29 17:34 extern/pybind11/tests/test_modules.py
--rw-rw-rw-  2.0 fat    12367 b- defN 24-May-29 17:34 extern/pybind11/tests/test_multiple_inheritance.py
--rw-rw-rw-  2.0 fat    23560 b- defN 24-May-29 17:34 extern/pybind11/tests/test_numpy_array.py
--rw-rw-rw-  2.0 fat    14712 b- defN 24-May-29 17:34 extern/pybind11/tests/test_numpy_dtypes.py
--rw-rw-rw-  2.0 fat     9924 b- defN 24-May-29 17:34 extern/pybind11/tests/test_numpy_vectorize.py
--rw-rw-rw-  2.0 fat     1905 b- defN 24-May-29 17:34 extern/pybind11/tests/test_opaque_types.py
--rw-rw-rw-  2.0 fat     4483 b- defN 24-May-29 17:34 extern/pybind11/tests/test_operator_overloading.py
--rw-rw-rw-  2.0 fat     2813 b- defN 24-May-29 17:34 extern/pybind11/tests/test_pickling.py
--rw-rw-rw-  2.0 fat      894 b- defN 24-May-29 17:34 extern/pybind11/tests/test_python_multiple_inheritance.py
--rw-rw-rw-  2.0 fat    26013 b- defN 24-May-29 17:34 extern/pybind11/tests/test_pytypes.py
--rw-rw-rw-  2.0 fat     8924 b- defN 24-May-29 17:34 extern/pybind11/tests/test_sequences_and_iterators.py
--rw-rw-rw-  2.0 fat     9845 b- defN 24-May-29 17:34 extern/pybind11/tests/test_smart_ptr.py
--rw-rw-rw-  2.0 fat    12688 b- defN 24-May-29 17:34 extern/pybind11/tests/test_stl.py
--rw-rw-rw-  2.0 fat    10150 b- defN 24-May-29 17:34 extern/pybind11/tests/test_stl_binders.py
--rw-rw-rw-  2.0 fat      769 b- defN 24-May-29 17:34 extern/pybind11/tests/test_tagbased_polymorphic.py
--rw-rw-rw-  2.0 fat      868 b- defN 24-May-29 17:34 extern/pybind11/tests/test_thread.py
--rw-rw-rw-  2.0 fat     3364 b- defN 24-May-29 17:34 extern/pybind11/tests/test_type_caster_pyobject_ptr.py
--rw-rw-rw-  2.0 fat      156 b- defN 24-May-29 17:34 extern/pybind11/tests/test_union.py
--rw-rw-rw-  2.0 fat     1175 b- defN 24-May-29 17:34 extern/pybind11/tests/test_unnamed_namespace_a.py
--rw-rw-rw-  2.0 fat      148 b- defN 24-May-29 17:34 extern/pybind11/tests/test_unnamed_namespace_b.py
--rw-rw-rw-  2.0 fat      343 b- defN 24-May-29 17:34 extern/pybind11/tests/test_vector_unique_ptr_member.py
--rw-rw-rw-  2.0 fat    13371 b- defN 24-May-29 17:34 extern/pybind11/tests/test_virtual_functions.py
--rw-rw-rw-  2.0 fat     8774 b- defN 24-May-29 17:34 extern/pybind11/tests/extra_python_package/test_files.py
--rw-rw-rw-  2.0 fat     4304 b- defN 24-May-29 17:34 extern/pybind11/tests/extra_setuptools/test_setuphelper.py
--rw-rw-rw-  2.0 fat      206 b- defN 24-May-29 17:34 extern/pybind11/tests/test_cmake_build/test.py
--rw-rw-rw-  2.0 fat      251 b- defN 24-May-29 17:34 extern/pybind11/tests/test_embed/test_interpreter.py
--rw-rw-rw-  2.0 fat      291 b- defN 24-May-29 17:34 extern/pybind11/tests/test_embed/test_trampoline.py
--rw-rw-rw-  2.0 fat     1156 b- defN 24-May-29 17:34 extern/pybind11/tools/codespell_ignore_lines_from_errors.py
--rw-rw-rw-  2.0 fat     1067 b- defN 24-May-29 17:34 extern/pybind11/tools/libsize.py
--rw-rw-rw-  2.0 fat     2135 b- defN 24-May-29 17:34 extern/pybind11/tools/make_changelog.py
--rw-rw-rw-  2.0 fat     1093 b- defN 24-May-29 17:42 SuPyMode-1.2.0.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     5624 b- defN 24-May-29 17:42 SuPyMode-1.2.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat      102 b- defN 24-May-29 17:42 SuPyMode-1.2.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       73 b- defN 24-May-29 17:42 SuPyMode-1.2.0.dist-info/top_level.txt
--rw-rw-r--  2.0 fat    13695 b- defN 24-May-29 17:42 SuPyMode-1.2.0.dist-info/RECORD
-142 files, 10502567 bytes uncompressed, 3840907 bytes compressed:  63.4%
+Zip file size: 2411097 bytes, number of entries: 174
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 developments/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 docs/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode-1.2.1.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/
+-rw-r--r--  2.0 unx     1083 b- defN 24-May-30 14:59 developments/gradient_tests_2.py
+-rw-r--r--  2.0 unx     3920 b- defN 24-May-30 14:59 developments/validation_2.py
+-rw-r--r--  2.0 unx      112 b- defN 24-May-30 14:59 developments/pydantic_test.py
+-rw-r--r--  2.0 unx     3913 b- defN 24-May-30 14:59 developments/validation.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 docs/source/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 docs/legacy/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 docs/examples/
+-rw-r--r--  2.0 unx     4292 b- defN 24-May-30 14:59 docs/source/conf.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 docs/legacy/python_debuging/
+-rw-r--r--  2.0 unx     1659 b- defN 24-May-30 14:59 docs/legacy/__debug__.py
+-rw-r--r--  2.0 unx    11163 b- defN 24-May-30 14:59 docs/legacy/python_debuging/eigen_solver.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-30 14:59 docs/legacy/python_debuging/__init__.py
+-rw-r--r--  2.0 unx    12623 b- defN 24-May-30 14:59 docs/legacy/python_debuging/mode_solver.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 docs/examples/basic/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 docs/examples/validation/
+-rw-r--r--  2.0 unx     3608 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_06.py
+-rw-r--r--  2.0 unx     3118 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_02.py
+-rw-r--r--  2.0 unx     3550 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_03.py
+-rw-r--r--  2.0 unx     3242 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_07.py
+-rw-r--r--  2.0 unx     3224 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_08.py
+-rw-r--r--  2.0 unx      722 b- defN 24-May-30 14:59 docs/examples/basic/plot_alpha_profile_1.py
+-rw-r--r--  2.0 unx     3167 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_04.py
+-rw-r--r--  2.0 unx     3529 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_05.py
+-rw-r--r--  2.0 unx     3041 b- defN 24-May-30 14:59 docs/examples/basic/plot_workflow_01.py
+-rw-r--r--  2.0 unx      685 b- defN 24-May-30 14:59 docs/examples/basic/plot_alpha_profile_0.py
+-rw-r--r--  2.0 unx     3477 b- defN 24-May-30 14:59 docs/examples/validation/plot_beta_SMF28.py
+-rw-r--r--  2.0 unx     3484 b- defN 24-May-30 14:59 docs/examples/validation/plot_beta_DCF.py
+-rw-r--r--  2.0 unx     5713 b- defN 24-May-30 14:59 docs/examples/validation/plot_validation.py
+-rw-rw-r--  2.0 unx    13890 b- defN 24-May-30 15:21 SuPyMode-1.2.1.dist-info/RECORD
+-rw-r--r--  2.0 unx     1072 b- defN 24-May-30 15:21 SuPyMode-1.2.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx      110 b- defN 24-May-30 15:21 SuPyMode-1.2.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       61 b- defN 24-May-30 15:21 SuPyMode-1.2.1.dist-info/top_level.txt
+-rw-r--r--  2.0 unx     5486 b- defN 24-May-30 15:21 SuPyMode-1.2.1.dist-info/METADATA
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/tools/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/.dylibs/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/validation_data/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/representation/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/binary/
+-rw-r--r--  2.0 unx    39705 b- defN 24-May-30 14:59 SuPyMode/superset.py
+-rw-r--r--  2.0 unx     8867 b- defN 24-May-30 14:59 SuPyMode/solver.py
+-rw-r--r--  2.0 unx     1113 b- defN 24-May-30 14:59 SuPyMode/directories.py
+-rw-r--r--  2.0 unx       52 b- defN 24-May-30 14:59 SuPyMode/__init__.py
+-rw-r--r--  2.0 unx     5091 b- defN 24-May-30 14:59 SuPyMode/mode_label.py
+-rw-r--r--  2.0 unx        6 b- defN 24-May-30 14:59 SuPyMode/VERSION
+-rw-r--r--  2.0 unx     9562 b- defN 24-May-30 14:59 SuPyMode/utils.py
+-rw-r--r--  2.0 unx    10304 b- defN 24-May-30 14:59 SuPyMode/supermode.py
+-rw-r--r--  2.0 unx    15735 b- defN 24-May-30 14:59 SuPyMode/workflow.py
+-rw-r--r--  2.0 unx     4612 b- defN 24-May-30 14:59 SuPyMode/special.py
+-rw-r--r--  2.0 unx    30289 b- defN 24-May-30 14:59 SuPyMode/profiles.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-30 14:59 SuPyMode/tools/__init__.py
+-rw-r--r--  2.0 unx     8688 b- defN 24-May-30 14:59 SuPyMode/tools/utils.py
+-rw-r--r--  2.0 unx     4612 b- defN 24-May-30 14:59 SuPyMode/tools/special.py
+-r--r--r--  2.0 unx  4016064 b- defN 24-May-30 15:21 SuPyMode/.dylibs/libstdc++.6.dylib
+-r--r--r--  2.0 unx   205680 b- defN 24-May-30 15:21 SuPyMode/.dylibs/libgcc_s.1.1.dylib
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/validation_data/SBB_figure_4_16_a/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 SuPyMode/validation_data/SBB_figure_4_16_b/
+-rw-r--r--  2.0 unx     3975 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP02.csv
+-rw-r--r--  2.0 unx     3353 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP12.csv
+-rw-r--r--  2.0 unx     3466 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP41.csv
+-rw-r--r--  2.0 unx     3776 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP31.csv
+-rw-r--r--  2.0 unx     3552 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP21.csv
+-rw-r--r--  2.0 unx     3270 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP51.csv
+-rw-r--r--  2.0 unx    11516 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP02.csv
+-rw-r--r--  2.0 unx     5152 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP12.csv
+-rw-r--r--  2.0 unx     9529 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP41.csv
+-rw-r--r--  2.0 unx     6428 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP31.csv
+-rw-r--r--  2.0 unx     3105 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP21.csv
+-rw-r--r--  2.0 unx     9056 b- defN 24-May-30 14:59 SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP51.csv
+-rw-r--r--  2.0 unx    12613 b- defN 24-May-30 14:59 SuPyMode/representation/field.py
+-rw-r--r--  2.0 unx     2584 b- defN 24-May-30 14:59 SuPyMode/representation/index.py
+-rw-r--r--  2.0 unx     2677 b- defN 24-May-30 14:59 SuPyMode/representation/beta.py
+-rw-r--r--  2.0 unx     3857 b- defN 24-May-30 14:59 SuPyMode/representation/adiabatic.py
+-rw-r--r--  2.0 unx     3727 b- defN 24-May-30 14:59 SuPyMode/representation/normalized_coupling.py
+-rw-r--r--  2.0 unx      241 b- defN 24-May-30 14:59 SuPyMode/representation/__init__.py
+-rw-r--r--  2.0 unx     3379 b- defN 24-May-30 14:59 SuPyMode/representation/beating_length.py
+-rw-r--r--  2.0 unx     2423 b- defN 24-May-30 14:59 SuPyMode/representation/eigen_value.py
+-rw-r--r--  2.0 unx     4060 b- defN 24-May-30 14:59 SuPyMode/representation/base.py
+-rwxr-xr-x  2.0 unx   241216 b- defN 24-May-30 15:21 SuPyMode/binary/ModelParameters.cpython-312-darwin.so
+-rwxr-xr-x  2.0 unx   562992 b- defN 24-May-30 15:21 SuPyMode/binary/CppSolver.cpython-312-darwin.so
+-rwxr-xr-x  2.0 unx   274512 b- defN 24-May-30 15:21 SuPyMode/binary/SuperMode.cpython-312-darwin.so
+-rw-r--r--  2.0 unx        1 b- defN 24-May-30 14:59 SuPyMode/binary/__init__.py
+-rwxr-xr-x  2.0 unx   190064 b- defN 24-May-30 15:21 SuPyMode/binary/Example.cpython-312-darwin.so
+-rwxr-xr-x  2.0 unx   563792 b- defN 24-May-30 15:21 SuPyMode/binary/CppSolver.cpython-311-darwin.so
+-rwxr-xr-x  2.0 unx   275152 b- defN 24-May-30 15:21 SuPyMode/binary/SuperMode.cpython-311-darwin.so
+-rwxr-xr-x  2.0 unx   190592 b- defN 24-May-30 15:21 SuPyMode/binary/Example.cpython-311-darwin.so
+-rwxr-xr-x  2.0 unx   241968 b- defN 24-May-30 15:21 SuPyMode/binary/ModelParameters.cpython-311-darwin.so
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/eigen/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/tools/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/pybind11/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/tests/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/docs/
+-rw-r--r--  2.0 unx     4855 b- defN 24-May-30 14:59 extern/pybind11/setup.py
+-rw-r--r--  2.0 unx     2746 b- defN 24-May-30 14:59 extern/pybind11/noxfile.py
+-rw-r--r--  2.0 unx     1031 b- defN 24-May-30 14:59 extern/pybind11/tools/libsize.py
+-rw-r--r--  2.0 unx     2047 b- defN 24-May-30 14:59 extern/pybind11/tools/make_changelog.py
+-rw-r--r--  2.0 unx     1117 b- defN 24-May-30 14:59 extern/pybind11/tools/codespell_ignore_lines_from_errors.py
+-rw-r--r--  2.0 unx    17492 b- defN 24-May-30 14:59 extern/pybind11/pybind11/setup_helpers.py
+-rw-r--r--  2.0 unx      233 b- defN 24-May-30 14:59 extern/pybind11/pybind11/_version.py
+-rw-r--r--  2.0 unx      429 b- defN 24-May-30 14:59 extern/pybind11/pybind11/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-30 14:59 extern/pybind11/pybind11/py.typed
+-rw-r--r--  2.0 unx     1207 b- defN 24-May-30 14:59 extern/pybind11/pybind11/commands.py
+-rw-r--r--  2.0 unx     1544 b- defN 24-May-30 14:59 extern/pybind11/pybind11/__main__.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/tests/test_embed/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/tests/test_cmake_build/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/tests/extra_setuptools/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/pybind11/tests/extra_python_package/
+-rw-r--r--  2.0 unx     9795 b- defN 24-May-30 14:59 extern/pybind11/tests/test_stl_binders.py
+-rw-r--r--  2.0 unx    18426 b- defN 24-May-30 14:59 extern/pybind11/tests/test_methods_and_attributes.py
+-rw-r--r--  2.0 unx     8659 b- defN 24-May-30 14:59 extern/pybind11/tests/test_sequences_and_iterators.py
+-rw-r--r--  2.0 unx      329 b- defN 24-May-30 14:59 extern/pybind11/tests/test_vector_unique_ptr_member.py
+-rw-r--r--  2.0 unx     9658 b- defN 24-May-30 14:59 extern/pybind11/tests/test_numpy_vectorize.py
+-rw-r--r--  2.0 unx     5691 b- defN 24-May-30 14:59 extern/pybind11/tests/test_chrono.py
+-rw-r--r--  2.0 unx     5619 b- defN 24-May-30 14:59 extern/pybind11/tests/conftest.py
+-rw-r--r--  2.0 unx      859 b- defN 24-May-30 14:59 extern/pybind11/tests/test_python_multiple_inheritance.py
+-rw-r--r--  2.0 unx     6955 b- defN 24-May-30 14:59 extern/pybind11/tests/test_callbacks.py
+-rw-r--r--  2.0 unx    25066 b- defN 24-May-30 14:59 extern/pybind11/tests/test_pytypes.py
+-rw-r--r--  2.0 unx    15187 b- defN 24-May-30 14:59 extern/pybind11/tests/test_class.py
+-rw-r--r--  2.0 unx      926 b- defN 24-May-30 14:59 extern/pybind11/tests/env.py
+-rw-r--r--  2.0 unx     9414 b- defN 24-May-30 14:59 extern/pybind11/tests/test_eigen_tensor.py
+-rw-r--r--  2.0 unx     2423 b- defN 24-May-30 14:59 extern/pybind11/tests/test_docstring_options.py
+-rw-r--r--  2.0 unx      536 b- defN 24-May-30 14:59 extern/pybind11/tests/test_async.py
+-rw-r--r--  2.0 unx     1141 b- defN 24-May-30 14:59 extern/pybind11/tests/test_unnamed_namespace_a.py
+-rw-r--r--  2.0 unx     8054 b- defN 24-May-30 14:59 extern/pybind11/tests/test_local_bindings.py
+-rw-r--r--  2.0 unx     9530 b- defN 24-May-30 14:59 extern/pybind11/tests/test_smart_ptr.py
+-rw-r--r--  2.0 unx    22892 b- defN 24-May-30 14:59 extern/pybind11/tests/test_numpy_array.py
+-rw-r--r--  2.0 unx    17243 b- defN 24-May-30 14:59 extern/pybind11/tests/test_builtin_casters.py
+-rw-r--r--  2.0 unx     1551 b- defN 24-May-30 14:59 extern/pybind11/tests/test_constants_and_functions.py
+-rw-r--r--  2.0 unx    14165 b- defN 24-May-30 14:59 extern/pybind11/tests/test_exceptions.py
+-rw-r--r--  2.0 unx    16491 b- defN 24-May-30 14:59 extern/pybind11/tests/test_factory_constructors.py
+-rw-r--r--  2.0 unx     7144 b- defN 24-May-30 14:59 extern/pybind11/tests/test_iostream.py
+-rw-r--r--  2.0 unx     4332 b- defN 24-May-30 14:59 extern/pybind11/tests/test_operator_overloading.py
+-rw-r--r--  2.0 unx      148 b- defN 24-May-30 14:59 extern/pybind11/tests/test_union.py
+-rw-r--r--  2.0 unx    14856 b- defN 24-May-30 14:59 extern/pybind11/tests/test_kwargs_and_defaults.py
+-rw-r--r--  2.0 unx     3260 b- defN 24-May-30 14:59 extern/pybind11/tests/test_type_caster_pyobject_ptr.py
+-rw-r--r--  2.0 unx      826 b- defN 24-May-30 14:59 extern/pybind11/tests/test_thread.py
+-rw-r--r--  2.0 unx     2720 b- defN 24-May-30 14:59 extern/pybind11/tests/test_pickling.py
+-rw-r--r--  2.0 unx      143 b- defN 24-May-30 14:59 extern/pybind11/tests/test_unnamed_namespace_b.py
+-rw-r--r--  2.0 unx     4796 b- defN 24-May-30 14:59 extern/pybind11/tests/test_copy_move.py
+-rw-r--r--  2.0 unx      119 b- defN 24-May-30 14:59 extern/pybind11/tests/test_eval_call.py
+-rw-r--r--  2.0 unx     3992 b- defN 24-May-30 14:59 extern/pybind11/tests/test_custom_type_casters.py
+-rw-r--r--  2.0 unx    12307 b- defN 24-May-30 14:59 extern/pybind11/tests/test_stl.py
+-rw-r--r--  2.0 unx    14272 b- defN 24-May-30 14:59 extern/pybind11/tests/test_numpy_dtypes.py
+-rw-r--r--  2.0 unx    29150 b- defN 24-May-30 14:59 extern/pybind11/tests/test_eigen_matrix.py
+-rw-r--r--  2.0 unx     1847 b- defN 24-May-30 14:59 extern/pybind11/tests/test_opaque_types.py
+-rw-r--r--  2.0 unx    12913 b- defN 24-May-30 14:59 extern/pybind11/tests/test_virtual_functions.py
+-rw-r--r--  2.0 unx      593 b- defN 24-May-30 14:59 extern/pybind11/tests/test_const_name.py
+-rw-r--r--  2.0 unx     6549 b- defN 24-May-30 14:59 extern/pybind11/tests/test_call_policies.py
+-rw-r--r--  2.0 unx     1091 b- defN 24-May-30 14:59 extern/pybind11/tests/test_custom_type_setup.py
+-rw-r--r--  2.0 unx     7124 b- defN 24-May-30 14:59 extern/pybind11/tests/test_buffers.py
+-rw-r--r--  2.0 unx     3963 b- defN 24-May-30 14:59 extern/pybind11/tests/test_modules.py
+-rw-r--r--  2.0 unx     8507 b- defN 24-May-30 14:59 extern/pybind11/tests/test_gil_scoped.py
+-rw-r--r--  2.0 unx    11874 b- defN 24-May-30 14:59 extern/pybind11/tests/test_multiple_inheritance.py
+-rw-r--r--  2.0 unx      741 b- defN 24-May-30 14:59 extern/pybind11/tests/test_tagbased_polymorphic.py
+-rw-r--r--  2.0 unx     1143 b- defN 24-May-30 14:59 extern/pybind11/tests/test_eval.py
+-rw-r--r--  2.0 unx     9069 b- defN 24-May-30 14:59 extern/pybind11/tests/test_enum.py
+-rw-r--r--  2.0 unx      275 b- defN 24-May-30 14:59 extern/pybind11/tests/test_embed/test_trampoline.py
+-rw-r--r--  2.0 unx      237 b- defN 24-May-30 14:59 extern/pybind11/tests/test_embed/test_interpreter.py
+-rw-r--r--  2.0 unx      198 b- defN 24-May-30 14:59 extern/pybind11/tests/test_cmake_build/test.py
+-rw-r--r--  2.0 unx     4153 b- defN 24-May-30 14:59 extern/pybind11/tests/extra_setuptools/test_setuphelper.py
+-rw-r--r--  2.0 unx     8481 b- defN 24-May-30 14:59 extern/pybind11/tests/extra_python_package/test_files.py
+-rw-r--r--  2.0 unx     2853 b- defN 24-May-30 14:59 extern/pybind11/docs/benchmark.py
+-rw-r--r--  2.0 unx    11574 b- defN 24-May-30 14:59 extern/pybind11/docs/conf.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/eigen/scripts/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/eigen/debug/
+-rw-r--r--  2.0 unx     2368 b- defN 24-May-30 14:59 extern/eigen/scripts/relicense.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-30 15:21 extern/eigen/debug/gdb/
+-rw-r--r--  2.0 unx       22 b- defN 24-May-30 14:59 extern/eigen/debug/gdb/__init__.py
+-rw-r--r--  2.0 unx     9617 b- defN 24-May-30 14:59 extern/eigen/debug/gdb/printers.py
+174 files, 7548920 bytes uncompressed, 2385179 bytes compressed:  68.4%
```

## zipnote {}

```diff
@@ -1,427 +1,523 @@
-Filename: SuPyMode/VERSION
+Filename: developments/
 Comment: 
 
-Filename: SuPyMode/__init__.py
+Filename: docs/
 Comment: 
 
-Filename: SuPyMode/directories.py
+Filename: SuPyMode-1.2.1.dist-info/
 Comment: 
 
-Filename: SuPyMode/mode_label.py
+Filename: SuPyMode/
 Comment: 
 
-Filename: SuPyMode/profiles.py
+Filename: extern/
 Comment: 
 
-Filename: SuPyMode/solver.py
+Filename: developments/gradient_tests_2.py
 Comment: 
 
-Filename: SuPyMode/special.py
+Filename: developments/validation_2.py
 Comment: 
 
-Filename: SuPyMode/supermode.py
+Filename: developments/pydantic_test.py
 Comment: 
 
-Filename: SuPyMode/superset.py
+Filename: developments/validation.py
 Comment: 
 
-Filename: SuPyMode/utils.py
+Filename: docs/source/
 Comment: 
 
-Filename: SuPyMode/workflow.py
+Filename: docs/legacy/
 Comment: 
 
-Filename: SuPyMode/binary/CppSolver.cp311-win_amd64.pyd
+Filename: docs/examples/
 Comment: 
 
-Filename: SuPyMode/binary/CppSolver.cp312-win_amd64.pyd
+Filename: docs/source/conf.py
 Comment: 
 
-Filename: SuPyMode/binary/Example.cp311-win_amd64.pyd
+Filename: docs/legacy/python_debuging/
 Comment: 
 
-Filename: SuPyMode/binary/Example.cp312-win_amd64.pyd
+Filename: docs/legacy/__debug__.py
 Comment: 
 
-Filename: SuPyMode/binary/ModelParameters.cp311-win_amd64.pyd
+Filename: docs/legacy/python_debuging/eigen_solver.py
 Comment: 
 
-Filename: SuPyMode/binary/ModelParameters.cp312-win_amd64.pyd
+Filename: docs/legacy/python_debuging/__init__.py
 Comment: 
 
-Filename: SuPyMode/binary/SuperMode.cp311-win_amd64.pyd
+Filename: docs/legacy/python_debuging/mode_solver.py
 Comment: 
 
-Filename: SuPyMode/binary/SuperMode.cp312-win_amd64.pyd
+Filename: docs/examples/basic/
 Comment: 
 
-Filename: SuPyMode/binary/__init__.py
+Filename: docs/examples/validation/
 Comment: 
 
-Filename: SuPyMode/representation/__init__.py
+Filename: docs/examples/basic/plot_workflow_06.py
 Comment: 
 
-Filename: SuPyMode/representation/adiabatic.py
+Filename: docs/examples/basic/plot_workflow_02.py
 Comment: 
 
-Filename: SuPyMode/representation/base.py
+Filename: docs/examples/basic/plot_workflow_03.py
 Comment: 
 
-Filename: SuPyMode/representation/beating_length.py
+Filename: docs/examples/basic/plot_workflow_07.py
 Comment: 
 
-Filename: SuPyMode/representation/beta.py
+Filename: docs/examples/basic/plot_workflow_08.py
 Comment: 
 
-Filename: SuPyMode/representation/eigen_value.py
+Filename: docs/examples/basic/plot_alpha_profile_1.py
 Comment: 
 
-Filename: SuPyMode/representation/field.py
+Filename: docs/examples/basic/plot_workflow_04.py
 Comment: 
 
-Filename: SuPyMode/representation/index.py
+Filename: docs/examples/basic/plot_workflow_05.py
 Comment: 
 
-Filename: SuPyMode/representation/normalized_coupling.py
+Filename: docs/examples/basic/plot_workflow_01.py
+Comment: 
+
+Filename: docs/examples/basic/plot_alpha_profile_0.py
+Comment: 
+
+Filename: docs/examples/validation/plot_beta_SMF28.py
+Comment: 
+
+Filename: docs/examples/validation/plot_beta_DCF.py
+Comment: 
+
+Filename: docs/examples/validation/plot_validation.py
+Comment: 
+
+Filename: SuPyMode-1.2.1.dist-info/RECORD
+Comment: 
+
+Filename: SuPyMode-1.2.1.dist-info/LICENSE
+Comment: 
+
+Filename: SuPyMode-1.2.1.dist-info/WHEEL
+Comment: 
+
+Filename: SuPyMode-1.2.1.dist-info/top_level.txt
+Comment: 
+
+Filename: SuPyMode-1.2.1.dist-info/METADATA
+Comment: 
+
+Filename: SuPyMode/tools/
+Comment: 
+
+Filename: SuPyMode/.dylibs/
+Comment: 
+
+Filename: SuPyMode/validation_data/
+Comment: 
+
+Filename: SuPyMode/representation/
+Comment: 
+
+Filename: SuPyMode/binary/
+Comment: 
+
+Filename: SuPyMode/superset.py
+Comment: 
+
+Filename: SuPyMode/solver.py
+Comment: 
+
+Filename: SuPyMode/directories.py
+Comment: 
+
+Filename: SuPyMode/__init__.py
+Comment: 
+
+Filename: SuPyMode/mode_label.py
+Comment: 
+
+Filename: SuPyMode/VERSION
+Comment: 
+
+Filename: SuPyMode/utils.py
+Comment: 
+
+Filename: SuPyMode/supermode.py
+Comment: 
+
+Filename: SuPyMode/workflow.py
+Comment: 
+
+Filename: SuPyMode/special.py
+Comment: 
+
+Filename: SuPyMode/profiles.py
 Comment: 
 
 Filename: SuPyMode/tools/__init__.py
 Comment: 
 
+Filename: SuPyMode/tools/utils.py
+Comment: 
+
 Filename: SuPyMode/tools/special.py
 Comment: 
 
-Filename: SuPyMode/tools/utils.py
+Filename: SuPyMode/.dylibs/libstdc++.6.dylib
 Comment: 
 
-Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP02.csv
+Filename: SuPyMode/.dylibs/libgcc_s.1.1.dylib
 Comment: 
 
-Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP21.csv
+Filename: SuPyMode/validation_data/SBB_figure_4_16_a/
 Comment: 
 
-Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP41.csv
+Filename: SuPyMode/validation_data/SBB_figure_4_16_b/
+Comment: 
+
+Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP02.csv
 Comment: 
 
 Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP12.csv
 Comment: 
 
+Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP41.csv
+Comment: 
+
 Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP31.csv
 Comment: 
 
+Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP21.csv
+Comment: 
+
 Filename: SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP51.csv
 Comment: 
 
 Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP02.csv
 Comment: 
 
-Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP21.csv
+Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP12.csv
 Comment: 
 
 Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP41.csv
 Comment: 
 
-Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP12.csv
+Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP31.csv
 Comment: 
 
-Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP31.csv
+Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP21.csv
 Comment: 
 
 Filename: SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP51.csv
 Comment: 
 
-Filename: developments/gradient_tests_2.py
+Filename: SuPyMode/representation/field.py
 Comment: 
 
-Filename: developments/validation.py
+Filename: SuPyMode/representation/index.py
 Comment: 
 
-Filename: developments/validation_2.py
+Filename: SuPyMode/representation/beta.py
 Comment: 
 
-Filename: docs/examples/basic/plot_alpha_profile_0.py
+Filename: SuPyMode/representation/adiabatic.py
 Comment: 
 
-Filename: docs/examples/basic/plot_alpha_profile_1.py
+Filename: SuPyMode/representation/normalized_coupling.py
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_01.py
+Filename: SuPyMode/representation/__init__.py
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_02.py
+Filename: SuPyMode/representation/beating_length.py
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_03.py
+Filename: SuPyMode/representation/eigen_value.py
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_04.py
+Filename: SuPyMode/representation/base.py
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_05.py
+Filename: SuPyMode/binary/ModelParameters.cpython-312-darwin.so
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_06.py
+Filename: SuPyMode/binary/CppSolver.cpython-312-darwin.so
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_07.py
+Filename: SuPyMode/binary/SuperMode.cpython-312-darwin.so
 Comment: 
 
-Filename: docs/examples/basic/plot_workflow_08.py
+Filename: SuPyMode/binary/__init__.py
 Comment: 
 
-Filename: docs/examples/validation/plot_beta_DCF.py
+Filename: SuPyMode/binary/Example.cpython-312-darwin.so
 Comment: 
 
-Filename: docs/examples/validation/plot_beta_SMF28.py
+Filename: SuPyMode/binary/CppSolver.cpython-311-darwin.so
 Comment: 
 
-Filename: docs/examples/validation/plot_normalized_coupling_DCF.py
+Filename: SuPyMode/binary/SuperMode.cpython-311-darwin.so
 Comment: 
 
-Filename: docs/examples/validation/plot_normalized_coupling_SMF28.py
+Filename: SuPyMode/binary/Example.cpython-311-darwin.so
 Comment: 
 
-Filename: docs/examples/validation/plot_validation.py
+Filename: SuPyMode/binary/ModelParameters.cpython-311-darwin.so
 Comment: 
 
-Filename: docs/legacy/__debug__.py
+Filename: extern/pybind11/
 Comment: 
 
-Filename: docs/legacy/python_debuging/__init__.py
+Filename: extern/eigen/
 Comment: 
 
-Filename: docs/legacy/python_debuging/eigen_solver.py
+Filename: extern/pybind11/tools/
 Comment: 
 
-Filename: docs/legacy/python_debuging/mode_solver.py
+Filename: extern/pybind11/pybind11/
 Comment: 
 
-Filename: docs/source/conf.py
+Filename: extern/pybind11/tests/
 Comment: 
 
-Filename: extern/eigen/debug/gdb/__init__.py
+Filename: extern/pybind11/docs/
 Comment: 
 
-Filename: extern/eigen/debug/gdb/printers.py
+Filename: extern/pybind11/setup.py
 Comment: 
 
-Filename: extern/eigen/scripts/relicense.py
+Filename: extern/pybind11/noxfile.py
 Comment: 
 
-Filename: extern/pybind11/noxfile.py
+Filename: extern/pybind11/tools/libsize.py
 Comment: 
 
-Filename: extern/pybind11/setup.py
+Filename: extern/pybind11/tools/make_changelog.py
 Comment: 
 
-Filename: extern/pybind11/docs/benchmark.py
+Filename: extern/pybind11/tools/codespell_ignore_lines_from_errors.py
 Comment: 
 
-Filename: extern/pybind11/docs/conf.py
+Filename: extern/pybind11/pybind11/setup_helpers.py
 Comment: 
 
-Filename: extern/pybind11/pybind11/__init__.py
+Filename: extern/pybind11/pybind11/_version.py
 Comment: 
 
-Filename: extern/pybind11/pybind11/__main__.py
+Filename: extern/pybind11/pybind11/__init__.py
 Comment: 
 
-Filename: extern/pybind11/pybind11/_version.py
+Filename: extern/pybind11/pybind11/py.typed
 Comment: 
 
 Filename: extern/pybind11/pybind11/commands.py
 Comment: 
 
-Filename: extern/pybind11/pybind11/py.typed
+Filename: extern/pybind11/pybind11/__main__.py
 Comment: 
 
-Filename: extern/pybind11/pybind11/setup_helpers.py
+Filename: extern/pybind11/tests/test_embed/
 Comment: 
 
-Filename: extern/pybind11/tests/conftest.py
+Filename: extern/pybind11/tests/test_cmake_build/
 Comment: 
 
-Filename: extern/pybind11/tests/env.py
+Filename: extern/pybind11/tests/extra_setuptools/
 Comment: 
 
-Filename: extern/pybind11/tests/test_async.py
+Filename: extern/pybind11/tests/extra_python_package/
 Comment: 
 
-Filename: extern/pybind11/tests/test_buffers.py
+Filename: extern/pybind11/tests/test_stl_binders.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_builtin_casters.py
+Filename: extern/pybind11/tests/test_methods_and_attributes.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_call_policies.py
+Filename: extern/pybind11/tests/test_sequences_and_iterators.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_callbacks.py
+Filename: extern/pybind11/tests/test_vector_unique_ptr_member.py
+Comment: 
+
+Filename: extern/pybind11/tests/test_numpy_vectorize.py
 Comment: 
 
 Filename: extern/pybind11/tests/test_chrono.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_class.py
+Filename: extern/pybind11/tests/conftest.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_const_name.py
+Filename: extern/pybind11/tests/test_python_multiple_inheritance.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_constants_and_functions.py
+Filename: extern/pybind11/tests/test_callbacks.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_copy_move.py
+Filename: extern/pybind11/tests/test_pytypes.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_custom_type_casters.py
+Filename: extern/pybind11/tests/test_class.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_custom_type_setup.py
+Filename: extern/pybind11/tests/env.py
+Comment: 
+
+Filename: extern/pybind11/tests/test_eigen_tensor.py
 Comment: 
 
 Filename: extern/pybind11/tests/test_docstring_options.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_eigen_matrix.py
+Filename: extern/pybind11/tests/test_async.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_eigen_tensor.py
+Filename: extern/pybind11/tests/test_unnamed_namespace_a.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_enum.py
+Filename: extern/pybind11/tests/test_local_bindings.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_eval.py
+Filename: extern/pybind11/tests/test_smart_ptr.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_eval_call.py
+Filename: extern/pybind11/tests/test_numpy_array.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_exceptions.py
+Filename: extern/pybind11/tests/test_builtin_casters.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_factory_constructors.py
+Filename: extern/pybind11/tests/test_constants_and_functions.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_gil_scoped.py
+Filename: extern/pybind11/tests/test_exceptions.py
+Comment: 
+
+Filename: extern/pybind11/tests/test_factory_constructors.py
 Comment: 
 
 Filename: extern/pybind11/tests/test_iostream.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_kwargs_and_defaults.py
+Filename: extern/pybind11/tests/test_operator_overloading.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_local_bindings.py
+Filename: extern/pybind11/tests/test_union.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_methods_and_attributes.py
+Filename: extern/pybind11/tests/test_kwargs_and_defaults.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_modules.py
+Filename: extern/pybind11/tests/test_type_caster_pyobject_ptr.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_multiple_inheritance.py
+Filename: extern/pybind11/tests/test_thread.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_numpy_array.py
+Filename: extern/pybind11/tests/test_pickling.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_numpy_dtypes.py
+Filename: extern/pybind11/tests/test_unnamed_namespace_b.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_numpy_vectorize.py
+Filename: extern/pybind11/tests/test_copy_move.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_opaque_types.py
+Filename: extern/pybind11/tests/test_eval_call.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_operator_overloading.py
+Filename: extern/pybind11/tests/test_custom_type_casters.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_pickling.py
+Filename: extern/pybind11/tests/test_stl.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_python_multiple_inheritance.py
+Filename: extern/pybind11/tests/test_numpy_dtypes.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_pytypes.py
+Filename: extern/pybind11/tests/test_eigen_matrix.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_sequences_and_iterators.py
+Filename: extern/pybind11/tests/test_opaque_types.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_smart_ptr.py
+Filename: extern/pybind11/tests/test_virtual_functions.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_stl.py
+Filename: extern/pybind11/tests/test_const_name.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_stl_binders.py
+Filename: extern/pybind11/tests/test_call_policies.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_tagbased_polymorphic.py
+Filename: extern/pybind11/tests/test_custom_type_setup.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_thread.py
+Filename: extern/pybind11/tests/test_buffers.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_type_caster_pyobject_ptr.py
+Filename: extern/pybind11/tests/test_modules.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_union.py
+Filename: extern/pybind11/tests/test_gil_scoped.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_unnamed_namespace_a.py
+Filename: extern/pybind11/tests/test_multiple_inheritance.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_unnamed_namespace_b.py
+Filename: extern/pybind11/tests/test_tagbased_polymorphic.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_vector_unique_ptr_member.py
+Filename: extern/pybind11/tests/test_eval.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_virtual_functions.py
+Filename: extern/pybind11/tests/test_enum.py
 Comment: 
 
-Filename: extern/pybind11/tests/extra_python_package/test_files.py
+Filename: extern/pybind11/tests/test_embed/test_trampoline.py
 Comment: 
 
-Filename: extern/pybind11/tests/extra_setuptools/test_setuphelper.py
+Filename: extern/pybind11/tests/test_embed/test_interpreter.py
 Comment: 
 
 Filename: extern/pybind11/tests/test_cmake_build/test.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_embed/test_interpreter.py
+Filename: extern/pybind11/tests/extra_setuptools/test_setuphelper.py
 Comment: 
 
-Filename: extern/pybind11/tests/test_embed/test_trampoline.py
+Filename: extern/pybind11/tests/extra_python_package/test_files.py
 Comment: 
 
-Filename: extern/pybind11/tools/codespell_ignore_lines_from_errors.py
+Filename: extern/pybind11/docs/benchmark.py
 Comment: 
 
-Filename: extern/pybind11/tools/libsize.py
+Filename: extern/pybind11/docs/conf.py
 Comment: 
 
-Filename: extern/pybind11/tools/make_changelog.py
+Filename: extern/eigen/scripts/
 Comment: 
 
-Filename: SuPyMode-1.2.0.dist-info/LICENSE
+Filename: extern/eigen/debug/
 Comment: 
 
-Filename: SuPyMode-1.2.0.dist-info/METADATA
+Filename: extern/eigen/scripts/relicense.py
 Comment: 
 
-Filename: SuPyMode-1.2.0.dist-info/WHEEL
+Filename: extern/eigen/debug/gdb/
 Comment: 
 
-Filename: SuPyMode-1.2.0.dist-info/top_level.txt
+Filename: extern/eigen/debug/gdb/__init__.py
 Comment: 
 
-Filename: SuPyMode-1.2.0.dist-info/RECORD
+Filename: extern/eigen/debug/gdb/printers.py
 Comment: 
 
 Zip file comment:
```

## filetype from file(1)

```diff
@@ -1 +1 @@
-Zip archive data, at least v2.0 to extract, compression method=deflate
+Zip archive data, at least v2.0 to extract, compression method=store
```

## SuPyMode/VERSION

```diff
@@ -1 +1 @@
-1.2.0
+1.2.1
```

## SuPyMode/directories.py

 * *Ordering differences only*

```diff
@@ -1,52 +1,52 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-from pathlib import Path
-import SuPyMode
-
-
-__all__ = [
-    'root_path',
-    'project_path',
-    'test_path',
-    'instance_directory',
-    'version_path',
-    'validation_data_path',
-    'doc_path',
-    'static_doc_path',
-    'logo_path',
-    'doc_css_path',
-]
-
-root_path = Path(SuPyMode.__path__[0])
-
-project_path = root_path.parents[0]
-
-test_path = project_path.joinpath('tests')
-
-instance_directory = root_path.joinpath('superset_instances')
-
-reports_path = root_path.joinpath('reports')
-
-version_path = root_path.joinpath('VERSION')
-
-validation_data_path = root_path.joinpath('validation_data')
-
-doc_path = root_path.parents[0].joinpath('docs')
-
-static_doc_path = doc_path.joinpath('images')
-
-logo_path = static_doc_path.joinpath('logo.png')
-
-doc_css_path = doc_path.joinpath('source/_static/default.css')
-
-rtd_example = 'https://supymode.readthedocs.io/en/latest/examples.html'
-
-
-if __name__ == '__main__':
-    for path_name in __all__:
-        path = locals()[path_name]
-        print(path)
-        assert path.exists(), f"Path {path_name} do not exists"
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+from pathlib import Path
+import SuPyMode
+
+
+__all__ = [
+    'root_path',
+    'project_path',
+    'test_path',
+    'instance_directory',
+    'version_path',
+    'validation_data_path',
+    'doc_path',
+    'static_doc_path',
+    'logo_path',
+    'doc_css_path',
+]
+
+root_path = Path(SuPyMode.__path__[0])
+
+project_path = root_path.parents[0]
+
+test_path = project_path.joinpath('tests')
+
+instance_directory = root_path.joinpath('superset_instances')
+
+reports_path = root_path.joinpath('reports')
+
+version_path = root_path.joinpath('VERSION')
+
+validation_data_path = root_path.joinpath('validation_data')
+
+doc_path = root_path.parents[0].joinpath('docs')
+
+static_doc_path = doc_path.joinpath('images')
+
+logo_path = static_doc_path.joinpath('logo.png')
+
+doc_css_path = doc_path.joinpath('source/_static/default.css')
+
+rtd_example = 'https://supymode.readthedocs.io/en/latest/examples.html'
+
+
+if __name__ == '__main__':
+    for path_name in __all__:
+        path = locals()[path_name]
+        print(path)
+        assert path.exists(), f"Path {path_name} do not exists"
+
+# -
```

## SuPyMode/mode_label.py

 * *Ordering differences only*

```diff
@@ -1,128 +1,128 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-from PyFinitDiff.finite_difference_2D import Boundaries
-
-
-mode_dict = [
-    {'mode': (0, 1, ""), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (1, 1, r"_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
-    {'mode': (1, 1, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
-    {'mode': (2, 1, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (2, 1, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
-    {'mode': (0, 2, ""), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (3, 1, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
-    {'mode': (3, 1, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
-    {'mode': (1, 2, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
-    {'mode': (1, 2, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
-    {'mode': (4, 1, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (4, 1, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
-    {'mode': (2, 2, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (2, 2, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
-    {'mode': (0, 3, ""), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (5, 1, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
-    {'mode': (5, 1, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
-    {'mode': (3, 2, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
-    {'mode': (3, 2, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
-    {'mode': (1, 3, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
-    {'mode': (1, 3, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
-    {'mode': (6, 1, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (6, 1, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
-    {'mode': (4, 2, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
-    {'mode': (4, 2, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
-]
-
-
-class ModeLabel:
-    """
-    A class to represent the LP mode label of an optical fiber based on boundary conditions and mode number.
-
-    Attributes:
-        boundaries (Boundaries): The boundary conditions for the mode.
-        mode_number (int): The mode number.
-        x_parity (str): The parity in the x direction (symmetric, anti-symmetric, or zero).
-        y_parity (str): The parity in the y direction (symmetric, anti-symmetric, or zero).
-        azimuthal (int): The azimuthal mode number.
-        radial (int): The radial mode number.
-        sub_label (str): The sub-label for the mode.
-    """
-
-    def __init__(self, boundaries: Boundaries, mode_number: int):
-        """
-        Initializes the ModeLabel with given boundary conditions and mode number.
-
-        Args:
-            boundaries (Boundaries): The boundary conditions.
-            mode_number (int): The mode number.
-        """
-        self.boundaries = boundaries
-        self.mode_number = mode_number
-
-        self.initialize()
-
-    def initialize(self) -> None:
-        self.x_parity = self._get_x_parity()
-        self.y_parity = self._get_y_parity()
-
-        filtered_modes = self.get_filtered_mode_list()
-
-        if self.mode_number >= len(filtered_modes):
-            self.azimuthal, self.radial, self.sub_label = None, None, None
-            self.raw_label = f"Mode{self.mode_number}"
-            self.label = self.raw_label
-
-        else:
-            self.azimuthal, self.radial, self.sub_label = filtered_modes[self.mode_number]
-            self.raw_label = f"LP{self.azimuthal}{self.radial}"
-            self.label = f"{self.raw_label}{self.sub_label}"
-
-    def get_filtered_mode_list(self) -> list[tuple]:
-        return [m['mode'] for m in mode_dict if self.x_parity in [m['x'], 'zero'] and self.y_parity in [m['y'], 'zero']]
-
-    def _get_x_parity(self) -> str:
-        """
-        Determines the parity in the x direction based on boundary conditions.
-
-        Returns:
-            str: The x parity (symmetric, anti-symmetric, or zero).
-        """
-        if self.boundaries.left == 'symmetric' or self.boundaries.right == 'symmetric':
-            return 'symmetric'
-        elif self.boundaries.left == 'anti-symmetric' or self.boundaries.right == 'anti-symmetric':
-            return 'anti-symmetric'
-        else:
-            return 'zero'
-
-    def _get_y_parity(self) -> str:
-        """
-        Determines the parity in the y direction based on boundary conditions.
-
-        Returns:
-            str: The y parity (symmetric, anti-symmetric, or zero).
-        """
-        if self.boundaries.top == 'symmetric' or self.boundaries.bottom == 'symmetric':
-            return 'symmetric'
-        elif self.boundaries.top == 'anti-symmetric' or self.boundaries.bottom == 'anti-symmetric':
-            return 'anti-symmetric'
-        else:
-            return 'zero'
-
-    def __repr__(self) -> str:
-        """
-        Returns the string representation of the ModeLabel.
-
-        Returns:
-            str: The LP mode label.
-        """
-        return self.label
-
-    def __str__(self) -> str:
-        """
-        Returns the string representation of the ModeLabel.
-
-        Returns:
-            str: The LP mode label.
-        """
-        return self.__repr__()
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+from PyFinitDiff.finite_difference_2D import Boundaries
+
+
+mode_dict = [
+    {'mode': (0, 1, ""), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (1, 1, r"_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
+    {'mode': (1, 1, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
+    {'mode': (2, 1, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (2, 1, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
+    {'mode': (0, 2, ""), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (3, 1, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
+    {'mode': (3, 1, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
+    {'mode': (1, 2, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
+    {'mode': (1, 2, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
+    {'mode': (4, 1, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (4, 1, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
+    {'mode': (2, 2, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (2, 2, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
+    {'mode': (0, 3, ""), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (5, 1, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
+    {'mode': (5, 1, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
+    {'mode': (3, 2, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
+    {'mode': (3, 2, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
+    {'mode': (1, 3, "_a"), 'x': 'symmetric', 'y': 'anti-symmetric'},
+    {'mode': (1, 3, "_b"), 'x': 'anti-symmetric', 'y': 'symmetric'},
+    {'mode': (6, 1, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (6, 1, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
+    {'mode': (4, 2, "_a"), 'x': 'symmetric', 'y': 'symmetric'},
+    {'mode': (4, 2, "_b"), 'x': 'anti-symmetric', 'y': 'anti-symmetric'},
+]
+
+
+class ModeLabel:
+    """
+    A class to represent the LP mode label of an optical fiber based on boundary conditions and mode number.
+
+    Attributes:
+        boundaries (Boundaries): The boundary conditions for the mode.
+        mode_number (int): The mode number.
+        x_parity (str): The parity in the x direction (symmetric, anti-symmetric, or zero).
+        y_parity (str): The parity in the y direction (symmetric, anti-symmetric, or zero).
+        azimuthal (int): The azimuthal mode number.
+        radial (int): The radial mode number.
+        sub_label (str): The sub-label for the mode.
+    """
+
+    def __init__(self, boundaries: Boundaries, mode_number: int):
+        """
+        Initializes the ModeLabel with given boundary conditions and mode number.
+
+        Args:
+            boundaries (Boundaries): The boundary conditions.
+            mode_number (int): The mode number.
+        """
+        self.boundaries = boundaries
+        self.mode_number = mode_number
+
+        self.initialize()
+
+    def initialize(self) -> None:
+        self.x_parity = self._get_x_parity()
+        self.y_parity = self._get_y_parity()
+
+        filtered_modes = self.get_filtered_mode_list()
+
+        if self.mode_number >= len(filtered_modes):
+            self.azimuthal, self.radial, self.sub_label = None, None, None
+            self.raw_label = f"Mode{self.mode_number}"
+            self.label = self.raw_label
+
+        else:
+            self.azimuthal, self.radial, self.sub_label = filtered_modes[self.mode_number]
+            self.raw_label = f"LP{self.azimuthal}{self.radial}"
+            self.label = f"{self.raw_label}{self.sub_label}"
+
+    def get_filtered_mode_list(self) -> list[tuple]:
+        return [m['mode'] for m in mode_dict if self.x_parity in [m['x'], 'zero'] and self.y_parity in [m['y'], 'zero']]
+
+    def _get_x_parity(self) -> str:
+        """
+        Determines the parity in the x direction based on boundary conditions.
+
+        Returns:
+            str: The x parity (symmetric, anti-symmetric, or zero).
+        """
+        if self.boundaries.left == 'symmetric' or self.boundaries.right == 'symmetric':
+            return 'symmetric'
+        elif self.boundaries.left == 'anti-symmetric' or self.boundaries.right == 'anti-symmetric':
+            return 'anti-symmetric'
+        else:
+            return 'zero'
+
+    def _get_y_parity(self) -> str:
+        """
+        Determines the parity in the y direction based on boundary conditions.
+
+        Returns:
+            str: The y parity (symmetric, anti-symmetric, or zero).
+        """
+        if self.boundaries.top == 'symmetric' or self.boundaries.bottom == 'symmetric':
+            return 'symmetric'
+        elif self.boundaries.top == 'anti-symmetric' or self.boundaries.bottom == 'anti-symmetric':
+            return 'anti-symmetric'
+        else:
+            return 'zero'
+
+    def __repr__(self) -> str:
+        """
+        Returns the string representation of the ModeLabel.
+
+        Returns:
+            str: The LP mode label.
+        """
+        return self.label
+
+    def __str__(self) -> str:
+        """
+        Returns the string representation of the ModeLabel.
+
+        Returns:
+            str: The LP mode label.
+        """
+        return self.__repr__()
+
+# -
```

## SuPyMode/profiles.py

 * *Ordering differences only*

```diff
@@ -1,813 +1,813 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-from typing import Tuple, Callable
-import numpy
-from scipy.interpolate import interp1d
-import matplotlib.pyplot as plt
-
-from SuPyMode import representation
-from MPSPlots.render2D import SceneList, Axis
-from matplotlib.animation import FuncAnimation, PillowWriter
-
-from dataclasses import dataclass, field
-
-
-@dataclass
-class TaperSection():
-    """
-    A class to represent a taper section in optical fiber simulations.
-
-    Attributes:
-        z_array (np.ndarray): The array of longitudinal positions along the taper (z-coordinates).
-        radius_array (np.ndarray): The array of taper radii corresponding to the z positions.
-        heating_length_initial (float, optional): The initial heating length of the taper section.
-        heating_length_final (float, optional): The final heating length of the taper section.
-
-    Properties:
-        z_initial (float): Returns the initial z position of the taper.
-        z_final (float): Returns the final z position of the taper.
-        radius_initial (float): Returns the initial radius at the start of the taper.
-        radius_final (float): Returns the radius at the end of the taper.
-        is_constant (bool): Determines if the taper's radius is constant throughout.
-        interpolation (callable): Provides an interpolation function for the radius over z.
-    """
-
-    z_array: numpy.ndarray
-    radius_array: numpy.ndarray
-    heating_length_initial: float = None
-    heating_length_final: float = None
-
-    @property
-    def z_initial(self) -> float:
-        """ Returns the initial z-coordinate of the taper section. """
-        return self.z_array[0]
-
-    @property
-    def is_constant(self) -> float:
-        """ Checks if the taper section's radius remains constant over its length. """
-        return self.radius_array[0] == self.radius_array[-1]
-
-    @property
-    def z_final(self) -> float:
-        """ Returns the final z-coordinate of the taper section. """
-        return self.z_array[-1]
-
-    @property
-    def radius_initial(self) -> float:
-        """ Returns the initial radius of the taper section. """
-        return self.radius_array[0]
-
-    @property
-    def radius_final(self) -> float:
-        """ Returns the final radius of the taper section. """
-        return self.radius_array[-1]
-
-    @property
-    def interpolation(self):
-        """
-        Provides an interpolation function for radius as a function of z-coordinate.
-
-        Returns:
-            interp1d: An interpolator that estimates the radius at any z within the bounds
-                      of z_array, with extrapolation set to zero outside the bounds.
-        """
-        return interp1d(
-            x=self.z_array,
-            y=self.radius_array,
-            bounds_error=False,
-            fill_value=0
-        )
-
-
-@dataclass
-class AlphaProfile():
-    r"""
-    Represents a Gaussian profile for an optical fiber coupler.
-
-    Translation table from article to class:
-        - :math:`rho_w` = radius_segment
-        - :math:`rho_0` = initial_radius
-        - :math:`l_w` = heating_length_segment
-        - :math:`x_0` = stretching_length
-
-    Attributes:
-        initial_radius (float): Initial radius of the taper structure, defaults to 1.
-        n_point (int): Number of points for differential equation resolution, recommended 200+.
-        symmetric (bool): If true, the taper structure is considered symmetric about z.
-        label (str): Label for the profile, used in plotting.
-        add_end_of_taper_section (bool): If true, adds a constant section at the end of the taper.
-        line_color (str): Line color for plots, not part of the main data model.
-        line_style (str): Line style for plots, not part of the main data model.
-    """
-    initial_radius: float = 1
-    n_point: int = 200
-    symmetric: bool = False
-    label: str = 'profile'
-    add_end_of_taper_section: bool = True
-    line_color: str = field(default='black', repr=False)
-    line_style: str = field(default='--', repr=False)
-
-    def __post_init__(self):
-        """
-        Initialize the section list after the dataclass fields are set. This method
-        prepares the profile object for further operations such as adding sections
-        or computing properties.
-        """
-        self.section_list = []
-
-    @property
-    def first_section(self) -> TaperSection:
-        """
-        Retrieves the first taper section added to the profile.
-
-        Returns:
-            TaperSection: The first taper section object in the section list.
-        """
-        return self.section_list[0]
-
-    @property
-    def last_section(self) -> TaperSection:
-        """
-        Retrieves the last taper section added to the profile.
-
-        Returns:
-            TaperSection: The last taper section object in the section list.
-        """
-        return self.section_list[-1]
-
-    def add_constant_segment(self, *, length: float, n_point: int = 100) -> None:
-        """
-        Adds a constant section at the specified length with a given number of points to the profile.
-
-        Parameters:
-            length (float): Length of the constant section to be added.
-            n_point (int): Number of points along the section for detailed resolution, defaults to 100.
-
-        Returns:
-            None
-        """
-        section = self.get_constant_custom_section(
-            length=length,
-            rho=self.last_radius,
-            start_z=self.last_z,
-            n_point=n_point
-        )
-
-        self.section_list.append(section)
-
-    def add_end_of_taper_segment(self, *, n_point: int = 100) -> None:
-        """
-        Adds a constant segment at the end of the taper if the last section is not constant. This method
-        ensures the taper ends smoothly or extends as needed.
-
-        Parameters:
-            n_point (int): Number of points along the section, defaults to 100.
-
-        Returns:
-            None
-        """
-        if self.last_section.is_constant:
-            return
-
-        length = self.last_section.heating_length_final / 2
-
-        section = self.get_constant_custom_section(
-            length=length,
-            radius=self.last_radius,
-            start_z=self.last_z,
-            n_point=n_point
-        )
-
-        self.section_list.append(section)
-
-    def get_constant_custom_section(
-            self, *,
-            length: float,
-            radius: float,
-            start_z: float = 0,
-            n_point: int = 100) -> None:
-        """
-        Creates a constant section with specified parameters and adds it to the profile.
-
-        Parameters:
-            length (float): Length of the constant section to be added.
-            radius (float): Radius of the section.
-            start_z (float): Starting z-position for the section, defaults to 0.
-            n_point (int): Number of points for resolution within the section, defaults to 100.
-
-        Returns:
-            TaperSection: The newly created taper section.
-        """
-        z_array = numpy.linspace(start_z, length + start_z, n_point)
-
-        radius_array = numpy.ones(n_point) * radius
-
-        section = TaperSection(
-            z_array=z_array,
-            radius_array=radius_array,
-        )
-
-        return section
-
-    def evaluate_adiabatic_factor(self, itr: numpy.ndarray) -> numpy.ndarray:
-        """
-        Evaluates the adiabatic factor for given inverse taper ratios (ITR).
-
-        Parameters:
-            itr (numpy.ndarray): Array of inverse taper ratios.
-
-        Returns:
-            numpy.ndarray: Array of adiabatic factors corresponding to the provided ITRs.
-        """
-        interpolation = interp1d(
-            x=self.itr_list,
-            y=self.adiabatic,
-            bounds_error=False,
-            fill_value=numpy.nan
-        )
-
-        return interpolation(itr)
-
-    def evaluate_distance_vs_itr(self, distance: numpy.ndarray) -> numpy.ndarray:
-        """
-        Evaluates the function of distance versus inverse taper ratio using interpolation.
-
-        Parameters:
-            distance (numpy.ndarray): Array of distances at which the ITR needs to be evaluated.
-
-        Returns:
-            numpy.ndarray: Array of ITRs at the specified distances.
-        """
-        interpolation = interp1d(
-            x=self.itr_list,
-            y=self.distance,
-            bounds_error=True,
-        )
-
-        return interpolation(distance)
-
-    def compute_radius_from_segment(
-            self, *,
-            alpha: float,
-            initial_heating_length: float,
-            stretching_length: float,
-            initial_radius: float,
-            distance: numpy.ndarray) -> Tuple[numpy.ndarray, float, float]:
-        """
-        Computes the radius as a function of the distance for a specific segment,
-        applying a tapering formula based on the provided parameters.
-
-        Args:
-            alpha (float): Rate at which the heating section's influence changes over time.
-            initial_heating_length (float): Initial length of the heating section.
-            initial_radius (float): Radius at the start of the segment.
-            stretching_length (float): Total length over which the segment is elongated.
-            distance (numpy.ndarray): Array representing the z-distance.
-
-        Returns:
-            Tuple[numpy.ndarray, float, float]: A tuple containing:
-                - radius (numpy.ndarray): Computed radius at each point in 'distance'.
-                - final_radius (float): Radius at the end of the segment.
-                - final_heating_length (float): Total length of the heating section after stretching.
-
-        Raises:
-            ValueError: If input conditions are not physically or mathematically valid.
-        """
-        self.assert_conditions(
-            alpha=alpha,
-            stretching_length=stretching_length,
-            initial_heating_length=initial_heating_length
-        )
-
-        term0 = 2 * alpha * distance
-        term2 = (1 - alpha) * initial_heating_length
-        term3 = -1 / (2 * alpha)
-
-        radius = initial_radius * (1 + term0 / term2)**term3
-        final_radius = initial_radius * (1 + alpha * stretching_length / initial_heating_length)**(-1 / (2 * alpha))
-        final_heating_length = initial_heating_length + alpha * stretching_length
-
-        if numpy.any(radius <= 0):
-            raise ValueError("Computed radius values contain non-physical negative or zero values.")
-
-        return radius, final_radius, final_heating_length
-
-    def assert_conditions(
-            self, *,
-            alpha: float,
-            stretching_length: float,
-            initial_heating_length: float) -> None:
-        """
-        Validates conditions for computing the taper segment.
-
-        Args:
-            alpha (float): Alpha parameter, non-zero to avoid division by zero.
-            stretching_length (float): Length over which the segment is elongated.
-            initial_heating_length (float): Initial length of the heating section.
-
-        Raises:
-            ValueError: If any condition that ensures a physically viable profile is violated.
-        """
-        if initial_heating_length <= 0:
-            raise ValueError("Initial heating length must be positive.")
-
-        if alpha == 0:
-            raise ValueError("Alpha must not be zero to avoid division by zero in formula.")
-
-        if alpha < 0 and stretching_length >= initial_heating_length / abs(alpha):
-            raise ValueError("Stretching length for negative alpha exceeds the physically viable limit.")
-
-    def add_taper_custom_segment(
-            self, *,
-            alpha: float,
-            initial_heating_length: float,
-            initial_radius: float,
-            stretching_length: float,
-            start_z: float = 0,
-            n_point: int = 100) -> None:
-        """
-        Adds a custom tapered section to the profile based on specified parameters. This method is useful for creating
-        detailed and specific taper geometries within the optical fiber.
-
-        Parameters:
-            alpha (float): Rate at which the heating section's influence changes over time.
-            initial_heating_length (float): Initial length of the heating section before any stretching.
-            initial_radius (float): Initial radius at the start of the taper segment.
-            stretching_length (float): Length over which the taper is stretched.
-            start_z (float): Starting z-coordinate for the taper segment, defaults to 0.
-            n_point (int): Number of points along the taper for resolution, defaults to 100.
-
-        Returns:
-            None
-        """
-        alpha = 0.01 if alpha == 0 else alpha
-
-        z_0 = (1 - alpha) * stretching_length / 2
-
-        distance = numpy.linspace(0, z_0, n_point)
-
-        assert distance[0] == 0, "Computation of taper section takes z as a reference and thus has to start with 0."
-
-        radius, final_radius, final_heating_length = self.compute_radius_from_segment(
-            alpha=alpha,
-            initial_heating_length=initial_heating_length,
-            stretching_length=stretching_length,
-            initial_radius=initial_radius,
-            distance=distance
-        )
-
-        section = TaperSection(
-            z_array=distance + start_z,
-            radius_array=radius,
-            heating_length_initial=initial_heating_length,
-            heating_length_final=final_heating_length
-        )
-
-        self.section_list.append(section)
-
-    def compute_adiabatic(self, distance: numpy.ndarray, radius: numpy.ndarray) -> numpy.ndarray:
-        """
-        Computes the adiabatic factor, a measure of how gradually a taper changes, which is crucial for ensuring minimal
-        light loss due to mode conversion.
-
-        .. math::
-            f_c = \frac{1}{\rho} \frac{d \rho}{d z}
-
-        Parameters:
-            distance (numpy.ndarray): Array of distances along the taper.
-            radius (numpy.ndarray): Array of radii corresponding to each distance.
-
-        Returns:
-            numpy.ndarray: Array of adiabatic factors for the given distances and radii.
-        """
-        dz = numpy.gradient(distance, axis=0, edge_order=2)
-
-        ditr = numpy.gradient(numpy.log(radius), axis=0, edge_order=2)
-
-        return abs(ditr / dz)
-
-    def compute_taper_angle(self, distance: numpy.ndarray, radius: numpy.ndarray) -> numpy.ndarray:
-        r"""
-        Computes the taper angle for a given set of distances and corresponding radii in the taper structure. This angle
-        can provide insights into the performance and behavior of the taper under different conditions.
-        From Tapered single-mode fibres and devices. Part 1: Adiabaticity criteria.
-
-        .. math::
-            f_c = \frac{d \rho}{d z} = \Omega
-
-
-        Parameters:
-            distance (numpy.ndarray): Array of distances along the taper.
-            radius (numpy.ndarray): Array of radii corresponding to each distance.
-
-        Returns:
-            numpy.ndarray: Array of taper angles calculated from the rate of change of the radius with respect to the distance.
-        """
-        d_z = numpy.gradient(distance, axis=0, edge_order=2)
-
-        d_rho = numpy.gradient(radius, axis=0, edge_order=2)
-
-        return abs(d_rho / d_z)
-
-    @property
-    def smallest_itr(self) -> float:
-        """
-        Retrieves the smallest inverse taper ratio (ITR) of the taper structure. The smallest ITR can indicate the
-        tightest part of the taper, which is critical for applications requiring precise control over light propagation.
-
-        Returns:
-            float: The smallest ITR value found in the taper profile.
-        """
-        return self.itr_list.min()
-
-    @property
-    def last_z(self) -> float:
-        """
-        Retrieves the last, or maximum, z-coordinate computed for the taper sections, which represents the end point
-        of the taper structure.
-
-        Returns:
-            float: The last z-coordinate value in the taper structure.
-        """
-        if len(self.section_list) == 0:
-            return 0
-        else:
-            return self.last_section.z_final
-
-    @property
-    def total_length(self) -> float:
-        """
-        Computes the total length of the taper structure, including both taper and constant sections, providing an overall
-        size of the taper profile.
-
-        Returns:
-            float: Total length of the taper structure.
-        """
-        return self.last_section.z_final
-
-    @property
-    def last_radius(self) -> float:
-        """
-        Retrieves the radius at the last computed z-position, which represents the end radius of the taper structure.
-
-        Returns:
-            float: Radius at the last z-coordinate in the taper profile.
-        """
-        if len(self.section_list) == 0:
-            return self.initial_radius
-        else:
-            return self.last_section.radius_final
-
-    def initialize(self) -> None:
-        """
-        Initializes or re-initializes the profile, typically called after making modifications to the taper sections. This method
-        recalculates and updates internal parameters to reflect the current state of the taper structure.
-
-        Returns:
-            None
-        """
-        if self.add_end_of_taper_section:
-            self.add_end_of_taper_segment()
-
-        distance = numpy.linspace(0, self.last_z, self.n_point)
-        radius = self.compute_radius_from_segment_from_interpolation(distance)
-        itr_list = radius / self.initial_radius
-        adiabatic = self.compute_adiabatic(distance=distance, radius=radius)
-        taper_angle = self.compute_taper_angle(distance=distance, radius=radius)
-
-        if self.symmetric:
-            self._distance = numpy.linspace(distance[0], 2 * distance[-1], 2 * distance.size - 1)
-            self._itr_list = numpy.r_[itr_list, itr_list[-2::-1]]
-            self._radius = numpy.r_[radius, radius[-2::-1]]
-            self._adiabatic = numpy.r_[adiabatic, adiabatic[-2::-1]]
-            self._taper_angle = numpy.r_[taper_angle, taper_angle[-2::-1]]
-        else:
-            self._distance = distance
-            self._radius = radius
-            self._itr_list = itr_list
-            self._adiabatic = adiabatic
-            self._taper_angle = taper_angle
-
-    @property
-    def distance(self) -> numpy.ndarray:
-        try:
-            return self._distance
-        except AttributeError:
-            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
-
-    @property
-    def radius(self) -> numpy.ndarray:
-        try:
-            return self._radius
-        except AttributeError:
-            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
-
-    @property
-    def itr_list(self) -> numpy.ndarray:
-        try:
-            return self._itr_list
-        except AttributeError:
-            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
-
-    @property
-    def adiabatic(self) -> numpy.ndarray:
-        try:
-            return self._adiabatic
-        except AttributeError:
-            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
-
-    @property
-    def taper_angle(self) -> numpy.ndarray:
-        try:
-            return self._taper_angle
-        except AttributeError:
-            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
-
-    def compute_radius_from_segment_from_interpolation(self, z: numpy.ndarray) -> numpy.ndarray:
-        """
-        Computes the radius at specified z-distances based on interpolation from existing taper sections, providing a continuous
-        profile of the radius along the taper.
-
-        Parameters:
-            z (numpy.ndarray): Array of z-distances at which to evaluate the radius.
-
-        Returns:
-            numpy.ndarray: Array of radius values interpolated along the given z-distances.
-        """
-        radius = numpy.zeros(z.size)
-
-        for section in self.section_list:
-            evaluation = section.interpolation(z)
-            idx_non_null = evaluation != 0
-            radius[idx_non_null] = evaluation[idx_non_null]
-
-        return radius
-
-    def add_taper_segment(
-            self, *,
-            alpha: float,
-            initial_heating_length: float,
-            stretching_length: float,
-            initial_radius: float = None,
-            n_point: int = 100) -> None:
-        """
-        Adds a tapered section following the previously defined section, using provided taper parameters to define the new section's
-        geometry and behavior.
-
-        Parameters:
-            alpha (float): Rate at which the heating section's influence changes over time.
-            initial_heating_length (float): Initial length of the heating section.
-            stretching_length (float): Total length over which the segment is stretched.
-            initial_radius (float): Radius at the start of the segment, defaults to the last radius if not provided.
-            n_point (int): Number of points along the section for resolution, defaults to 100.
-
-        Returns:
-            None
-        """
-        return self.add_taper_custom_segment(
-            alpha=alpha,
-            initial_heating_length=initial_heating_length,
-            initial_radius=self.last_radius,
-            stretching_length=stretching_length,
-            start_z=self.last_z,
-            n_point=n_point
-        )
-
-    def get_itr_vs_distance_interpolation(self) -> Callable:
-        """
-        Generates an interpolation function for inverse taper ratio (ITR) as a function of distance.
-        This allows for quick lookups of ITR at arbitrary distances along the taper.
-
-        Returns:
-            Callable: A function that interpolates ITR based on given distances.
-        """
-        return interp1d(
-            x=self.distance,
-            y=self.itr_list,
-            bounds_error=False,
-            fill_value=0
-        )
-
-    def single_plot(function) -> Callable:
-        """
-        Decorator to apply a standard plotting style to any plotting function within this class.
-        It automatically sets line styles, colors, and labels from the class attributes.
-
-        Parameters:
-            function (Callable): The plotting function to decorate.
-
-        Returns:
-            Callable: A wrapped plotting function that integrates additional styling and annotations.
-        """
-
-        def wrapper(self, ax: Axis, line_color: str = None, line_style: str = None, **kwargs):
-            line_style = self.line_style if line_style is None else line_style
-            line_color = self.line_color if line_color is None else line_color
-
-            x, y = function(self, ax=ax, line_color=line_color, line_style=line_style, **kwargs)
-
-            ax.add_line(x=x, y=y, label=self.label, line_style=line_style, color=line_color)
-
-        return wrapper
-
-    @single_plot
-    def render_itr_vs_z_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
-        """
-        Renders a plot of inverse taper ratio (ITR) versus z-distance onto a given axis. This method is typically
-        used for visualizing how the ITR changes along the length of the taper.
-
-        Parameters:
-            ax (Axis): The matplotlib axis on which to plot.
-            line_style (str, optional): Line style for the plot, defaults to class attribute.
-            line_color (str, optional): Line color for the plot, defaults to class attribute.
-
-        Returns:
-            tuple[numpy.ndarray, numpy.ndarray]
-        """
-        ax.set_style(
-            show_legend=False,
-            y_limits=[0, None],
-            x_label='Z-propagation [mm]',
-            y_label='Inverse taper ratio [ITR]',
-            x_scale_factor=1e3,
-            y_scale="linear",
-            line_width=2
-        )
-
-        return self.distance, self.itr_list
-
-    @single_plot
-    def render_taper_angle_vs_z_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
-        """
-        Plots the taper angle as a function of z-distance on a provided axis. Useful for understanding the geometric
-        changes in the taper profile over its length.
-
-        Parameters:
-            ax (Axis): The matplotlib axis on which to plot.
-            line_style (str, optional): Specifies the style of the plot line, if different from the class default.
-            line_color (str, optional): Specifies the color of the plot line, if different from the class default.
-
-        Returns:
-            tuple[numpy.ndarray, numpy.ndarray]
-        """
-        ax.set_style(
-            show_legend=False,
-            y_limits=[0, None],
-            y_label='Taper angle [rad]',
-            x_label='Z-propagation [mm]',
-            x_scale_factor=1e3,
-            y_scale="linear",
-            line_width=2
-        )
-
-        return self.distance, self.taper_angle
-
-    @single_plot
-    def render_adiabatic_factor_vs_z_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
-        """
-        Plots the adiabatic criterion versus z-distance on the specified axis. This plot helps assess the
-        efficiency and effectiveness of the taper in maintaining adiabatic conditions throughout its course.
-
-        Parameters:
-            ax (Axis): The matplotlib axis on which to plot.
-            line_style (str, optional): Line style for the plot, can override default.
-            line_color (str, optional): Line color for the plot, can override default.
-
-        Returns:
-            tuple[numpy.ndarray, numpy.ndarray]
-        """
-        ax.set_style(
-            y_scale='log',
-            y_label='Adiabatic criterion',
-            x_label='z-distance'
-        )
-
-        return self.distance, self.adiabatic
-
-    @single_plot
-    def render_adiabatic_factor_vs_itr_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
-        """
-        Add adiabatic criterion vs ITR plot to axis
-
-        :param      ax:   The axis on which to add the plot
-        :type       ax:   Axis
-        """
-        ax.set_style(**representation.adiabatic.Adiabatic.plot_style)
-
-        return self.itr_list, self.adiabatic
-
-    def plot(
-            self,
-            show_radius: bool = True,
-            show_adiabatic: bool = True,
-            show_taper_angle: bool = True) -> SceneList:
-        """
-        Generates plots based on the current state of the taper profile. This can include plots of radius vs. z-distance,
-        adiabatic factor vs. ITR, and taper angle vs. z-distance, based on the specified flags.
-
-        Parameters:
-            show_radius (bool): If True, includes a plot of radius vs. z-distance.
-            show_adiabatic (bool): If True, includes a plot of adiabatic factor vs. ITR.
-            show_taper_angle (bool): If True, includes a plot of taper angle vs. z-distance.
-
-        Returns:
-            SceneList: A collection of matplotlib axes with the requested plots.
-        """
-        figure = SceneList(
-            title=f'Minimum ITR: {self.smallest_itr:.4f}',
-            ax_orientation='vertical',
-            unit_size=(8, 3)
-        )
-
-        if show_radius:
-            ax = figure.append_ax()
-            self.render_itr_vs_z_on_ax(ax=ax)
-
-        if show_taper_angle:
-            ax = figure.append_ax()
-            self.render_taper_angle_vs_z_on_ax(ax=ax)
-
-        if show_adiabatic:
-            ax = figure.append_ax()
-            self.render_adiabatic_factor_vs_itr_on_ax(ax=ax)
-
-        figure.annotate_axis(position=(-0.15, 1.15))
-
-        return figure
-
-    def generate_propagation_gif(
-            self,
-            output_directory: str = './new_gif.gif',
-            dpi: int = 100,
-            fps: int = 20,
-            number_of_frames: int = 200,
-            dark_background: bool = True) -> None:
-        """
-        Generates an animated GIF of light propagation in a taper structure.
-
-        Parameters:
-            output_directory (str): Path where the GIF will be saved.
-            dpi (int): Dots per inch for the output GIF.
-            fps (int): Frames per second for the animation.
-            number_of_frames (int): Total number of frames in the animation.
-            dark_background (bool): If True, use a dark background for the GIF.
-
-        Returns:
-            None
-        """
-        figure, ax = plt.subplots(figsize=(12, 6))
-        ax.set_xlabel('Propagation axis [mm]', color='white' if dark_background else 'black')
-        style_context = "dark_background" if dark_background else "default"
-
-        sub_sampling_factor = int(self.distance.size / number_of_frames)
-
-        sub_distance = self.distance[::sub_sampling_factor] * 1e3
-        sub_radius = self.radius[::sub_sampling_factor]
-        sub_itr_list = self.itr_list[::sub_sampling_factor]
-
-        with plt.style.context(style_context):
-            def init_func() -> tuple:
-                line_0 = ax.plot(sub_distance, sub_radius, color='black')
-                line_1 = ax.plot(sub_distance, -sub_radius, color='black')
-
-                line_2 = ax.fill_between(
-                    sub_distance,
-                    +sub_radius,
-                    -sub_radius,
-                    color='lightblue',
-                    alpha=0.8
-                )
-
-                return [*line_0, *line_1, line_2]
-
-            def animate(slice_number: int) -> tuple:
-                position = sub_distance[slice_number]
-                itr = sub_itr_list[slice_number]
-                title = f'[slice: {slice_number} - ITR: {itr:.3f}]'
-
-                if slice_number > 0:
-                    ax.lines[-1].remove()
-
-                line_0 = ax.set_title(title, color='white')
-
-                line_1 = ax.axvline(position, linestyle='--', linewidth=2, color='red')
-
-                return line_0, line_1
-
-        animation = FuncAnimation(
-            fig=figure,
-            func=animate,
-            init_func=init_func,
-            blit=True,
-            repeat=True,
-            frames=sub_itr_list.size
-        )
-
-        animation.save(
-            output_directory,
-            dpi=dpi,
-            writer=PillowWriter(fps=fps)
-        )
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+from typing import Tuple, Callable
+import numpy
+from scipy.interpolate import interp1d
+import matplotlib.pyplot as plt
+
+from SuPyMode import representation
+from MPSPlots.render2D import SceneList, Axis
+from matplotlib.animation import FuncAnimation, PillowWriter
+
+from dataclasses import dataclass, field
+
+
+@dataclass
+class TaperSection():
+    """
+    A class to represent a taper section in optical fiber simulations.
+
+    Attributes:
+        z_array (np.ndarray): The array of longitudinal positions along the taper (z-coordinates).
+        radius_array (np.ndarray): The array of taper radii corresponding to the z positions.
+        heating_length_initial (float, optional): The initial heating length of the taper section.
+        heating_length_final (float, optional): The final heating length of the taper section.
+
+    Properties:
+        z_initial (float): Returns the initial z position of the taper.
+        z_final (float): Returns the final z position of the taper.
+        radius_initial (float): Returns the initial radius at the start of the taper.
+        radius_final (float): Returns the radius at the end of the taper.
+        is_constant (bool): Determines if the taper's radius is constant throughout.
+        interpolation (callable): Provides an interpolation function for the radius over z.
+    """
+
+    z_array: numpy.ndarray
+    radius_array: numpy.ndarray
+    heating_length_initial: float = None
+    heating_length_final: float = None
+
+    @property
+    def z_initial(self) -> float:
+        """ Returns the initial z-coordinate of the taper section. """
+        return self.z_array[0]
+
+    @property
+    def is_constant(self) -> float:
+        """ Checks if the taper section's radius remains constant over its length. """
+        return self.radius_array[0] == self.radius_array[-1]
+
+    @property
+    def z_final(self) -> float:
+        """ Returns the final z-coordinate of the taper section. """
+        return self.z_array[-1]
+
+    @property
+    def radius_initial(self) -> float:
+        """ Returns the initial radius of the taper section. """
+        return self.radius_array[0]
+
+    @property
+    def radius_final(self) -> float:
+        """ Returns the final radius of the taper section. """
+        return self.radius_array[-1]
+
+    @property
+    def interpolation(self):
+        """
+        Provides an interpolation function for radius as a function of z-coordinate.
+
+        Returns:
+            interp1d: An interpolator that estimates the radius at any z within the bounds
+                      of z_array, with extrapolation set to zero outside the bounds.
+        """
+        return interp1d(
+            x=self.z_array,
+            y=self.radius_array,
+            bounds_error=False,
+            fill_value=0
+        )
+
+
+@dataclass
+class AlphaProfile():
+    r"""
+    Represents a Gaussian profile for an optical fiber coupler.
+
+    Translation table from article to class:
+        - :math:`rho_w` = radius_segment
+        - :math:`rho_0` = initial_radius
+        - :math:`l_w` = heating_length_segment
+        - :math:`x_0` = stretching_length
+
+    Attributes:
+        initial_radius (float): Initial radius of the taper structure, defaults to 1.
+        n_point (int): Number of points for differential equation resolution, recommended 200+.
+        symmetric (bool): If true, the taper structure is considered symmetric about z.
+        label (str): Label for the profile, used in plotting.
+        add_end_of_taper_section (bool): If true, adds a constant section at the end of the taper.
+        line_color (str): Line color for plots, not part of the main data model.
+        line_style (str): Line style for plots, not part of the main data model.
+    """
+    initial_radius: float = 1
+    n_point: int = 200
+    symmetric: bool = False
+    label: str = 'profile'
+    add_end_of_taper_section: bool = True
+    line_color: str = field(default='black', repr=False)
+    line_style: str = field(default='--', repr=False)
+
+    def __post_init__(self):
+        """
+        Initialize the section list after the dataclass fields are set. This method
+        prepares the profile object for further operations such as adding sections
+        or computing properties.
+        """
+        self.section_list = []
+
+    @property
+    def first_section(self) -> TaperSection:
+        """
+        Retrieves the first taper section added to the profile.
+
+        Returns:
+            TaperSection: The first taper section object in the section list.
+        """
+        return self.section_list[0]
+
+    @property
+    def last_section(self) -> TaperSection:
+        """
+        Retrieves the last taper section added to the profile.
+
+        Returns:
+            TaperSection: The last taper section object in the section list.
+        """
+        return self.section_list[-1]
+
+    def add_constant_segment(self, *, length: float, n_point: int = 100) -> None:
+        """
+        Adds a constant section at the specified length with a given number of points to the profile.
+
+        Parameters:
+            length (float): Length of the constant section to be added.
+            n_point (int): Number of points along the section for detailed resolution, defaults to 100.
+
+        Returns:
+            None
+        """
+        section = self.get_constant_custom_section(
+            length=length,
+            rho=self.last_radius,
+            start_z=self.last_z,
+            n_point=n_point
+        )
+
+        self.section_list.append(section)
+
+    def add_end_of_taper_segment(self, *, n_point: int = 100) -> None:
+        """
+        Adds a constant segment at the end of the taper if the last section is not constant. This method
+        ensures the taper ends smoothly or extends as needed.
+
+        Parameters:
+            n_point (int): Number of points along the section, defaults to 100.
+
+        Returns:
+            None
+        """
+        if self.last_section.is_constant:
+            return
+
+        length = self.last_section.heating_length_final / 2
+
+        section = self.get_constant_custom_section(
+            length=length,
+            radius=self.last_radius,
+            start_z=self.last_z,
+            n_point=n_point
+        )
+
+        self.section_list.append(section)
+
+    def get_constant_custom_section(
+            self, *,
+            length: float,
+            radius: float,
+            start_z: float = 0,
+            n_point: int = 100) -> None:
+        """
+        Creates a constant section with specified parameters and adds it to the profile.
+
+        Parameters:
+            length (float): Length of the constant section to be added.
+            radius (float): Radius of the section.
+            start_z (float): Starting z-position for the section, defaults to 0.
+            n_point (int): Number of points for resolution within the section, defaults to 100.
+
+        Returns:
+            TaperSection: The newly created taper section.
+        """
+        z_array = numpy.linspace(start_z, length + start_z, n_point)
+
+        radius_array = numpy.ones(n_point) * radius
+
+        section = TaperSection(
+            z_array=z_array,
+            radius_array=radius_array,
+        )
+
+        return section
+
+    def evaluate_adiabatic_factor(self, itr: numpy.ndarray) -> numpy.ndarray:
+        """
+        Evaluates the adiabatic factor for given inverse taper ratios (ITR).
+
+        Parameters:
+            itr (numpy.ndarray): Array of inverse taper ratios.
+
+        Returns:
+            numpy.ndarray: Array of adiabatic factors corresponding to the provided ITRs.
+        """
+        interpolation = interp1d(
+            x=self.itr_list,
+            y=self.adiabatic,
+            bounds_error=False,
+            fill_value=numpy.nan
+        )
+
+        return interpolation(itr)
+
+    def evaluate_distance_vs_itr(self, distance: numpy.ndarray) -> numpy.ndarray:
+        """
+        Evaluates the function of distance versus inverse taper ratio using interpolation.
+
+        Parameters:
+            distance (numpy.ndarray): Array of distances at which the ITR needs to be evaluated.
+
+        Returns:
+            numpy.ndarray: Array of ITRs at the specified distances.
+        """
+        interpolation = interp1d(
+            x=self.itr_list,
+            y=self.distance,
+            bounds_error=True,
+        )
+
+        return interpolation(distance)
+
+    def compute_radius_from_segment(
+            self, *,
+            alpha: float,
+            initial_heating_length: float,
+            stretching_length: float,
+            initial_radius: float,
+            distance: numpy.ndarray) -> Tuple[numpy.ndarray, float, float]:
+        """
+        Computes the radius as a function of the distance for a specific segment,
+        applying a tapering formula based on the provided parameters.
+
+        Args:
+            alpha (float): Rate at which the heating section's influence changes over time.
+            initial_heating_length (float): Initial length of the heating section.
+            initial_radius (float): Radius at the start of the segment.
+            stretching_length (float): Total length over which the segment is elongated.
+            distance (numpy.ndarray): Array representing the z-distance.
+
+        Returns:
+            Tuple[numpy.ndarray, float, float]: A tuple containing:
+                - radius (numpy.ndarray): Computed radius at each point in 'distance'.
+                - final_radius (float): Radius at the end of the segment.
+                - final_heating_length (float): Total length of the heating section after stretching.
+
+        Raises:
+            ValueError: If input conditions are not physically or mathematically valid.
+        """
+        self.assert_conditions(
+            alpha=alpha,
+            stretching_length=stretching_length,
+            initial_heating_length=initial_heating_length
+        )
+
+        term0 = 2 * alpha * distance
+        term2 = (1 - alpha) * initial_heating_length
+        term3 = -1 / (2 * alpha)
+
+        radius = initial_radius * (1 + term0 / term2)**term3
+        final_radius = initial_radius * (1 + alpha * stretching_length / initial_heating_length)**(-1 / (2 * alpha))
+        final_heating_length = initial_heating_length + alpha * stretching_length
+
+        if numpy.any(radius <= 0):
+            raise ValueError("Computed radius values contain non-physical negative or zero values.")
+
+        return radius, final_radius, final_heating_length
+
+    def assert_conditions(
+            self, *,
+            alpha: float,
+            stretching_length: float,
+            initial_heating_length: float) -> None:
+        """
+        Validates conditions for computing the taper segment.
+
+        Args:
+            alpha (float): Alpha parameter, non-zero to avoid division by zero.
+            stretching_length (float): Length over which the segment is elongated.
+            initial_heating_length (float): Initial length of the heating section.
+
+        Raises:
+            ValueError: If any condition that ensures a physically viable profile is violated.
+        """
+        if initial_heating_length <= 0:
+            raise ValueError("Initial heating length must be positive.")
+
+        if alpha == 0:
+            raise ValueError("Alpha must not be zero to avoid division by zero in formula.")
+
+        if alpha < 0 and stretching_length >= initial_heating_length / abs(alpha):
+            raise ValueError("Stretching length for negative alpha exceeds the physically viable limit.")
+
+    def add_taper_custom_segment(
+            self, *,
+            alpha: float,
+            initial_heating_length: float,
+            initial_radius: float,
+            stretching_length: float,
+            start_z: float = 0,
+            n_point: int = 100) -> None:
+        """
+        Adds a custom tapered section to the profile based on specified parameters. This method is useful for creating
+        detailed and specific taper geometries within the optical fiber.
+
+        Parameters:
+            alpha (float): Rate at which the heating section's influence changes over time.
+            initial_heating_length (float): Initial length of the heating section before any stretching.
+            initial_radius (float): Initial radius at the start of the taper segment.
+            stretching_length (float): Length over which the taper is stretched.
+            start_z (float): Starting z-coordinate for the taper segment, defaults to 0.
+            n_point (int): Number of points along the taper for resolution, defaults to 100.
+
+        Returns:
+            None
+        """
+        alpha = 0.01 if alpha == 0 else alpha
+
+        z_0 = (1 - alpha) * stretching_length / 2
+
+        distance = numpy.linspace(0, z_0, n_point)
+
+        assert distance[0] == 0, "Computation of taper section takes z as a reference and thus has to start with 0."
+
+        radius, final_radius, final_heating_length = self.compute_radius_from_segment(
+            alpha=alpha,
+            initial_heating_length=initial_heating_length,
+            stretching_length=stretching_length,
+            initial_radius=initial_radius,
+            distance=distance
+        )
+
+        section = TaperSection(
+            z_array=distance + start_z,
+            radius_array=radius,
+            heating_length_initial=initial_heating_length,
+            heating_length_final=final_heating_length
+        )
+
+        self.section_list.append(section)
+
+    def compute_adiabatic(self, distance: numpy.ndarray, radius: numpy.ndarray) -> numpy.ndarray:
+        """
+        Computes the adiabatic factor, a measure of how gradually a taper changes, which is crucial for ensuring minimal
+        light loss due to mode conversion.
+
+        .. math::
+            f_c = \frac{1}{\rho} \frac{d \rho}{d z}
+
+        Parameters:
+            distance (numpy.ndarray): Array of distances along the taper.
+            radius (numpy.ndarray): Array of radii corresponding to each distance.
+
+        Returns:
+            numpy.ndarray: Array of adiabatic factors for the given distances and radii.
+        """
+        dz = numpy.gradient(distance, axis=0, edge_order=2)
+
+        ditr = numpy.gradient(numpy.log(radius), axis=0, edge_order=2)
+
+        return abs(ditr / dz)
+
+    def compute_taper_angle(self, distance: numpy.ndarray, radius: numpy.ndarray) -> numpy.ndarray:
+        r"""
+        Computes the taper angle for a given set of distances and corresponding radii in the taper structure. This angle
+        can provide insights into the performance and behavior of the taper under different conditions.
+        From Tapered single-mode fibres and devices. Part 1: Adiabaticity criteria.
+
+        .. math::
+            f_c = \frac{d \rho}{d z} = \Omega
+
+
+        Parameters:
+            distance (numpy.ndarray): Array of distances along the taper.
+            radius (numpy.ndarray): Array of radii corresponding to each distance.
+
+        Returns:
+            numpy.ndarray: Array of taper angles calculated from the rate of change of the radius with respect to the distance.
+        """
+        d_z = numpy.gradient(distance, axis=0, edge_order=2)
+
+        d_rho = numpy.gradient(radius, axis=0, edge_order=2)
+
+        return abs(d_rho / d_z)
+
+    @property
+    def smallest_itr(self) -> float:
+        """
+        Retrieves the smallest inverse taper ratio (ITR) of the taper structure. The smallest ITR can indicate the
+        tightest part of the taper, which is critical for applications requiring precise control over light propagation.
+
+        Returns:
+            float: The smallest ITR value found in the taper profile.
+        """
+        return self.itr_list.min()
+
+    @property
+    def last_z(self) -> float:
+        """
+        Retrieves the last, or maximum, z-coordinate computed for the taper sections, which represents the end point
+        of the taper structure.
+
+        Returns:
+            float: The last z-coordinate value in the taper structure.
+        """
+        if len(self.section_list) == 0:
+            return 0
+        else:
+            return self.last_section.z_final
+
+    @property
+    def total_length(self) -> float:
+        """
+        Computes the total length of the taper structure, including both taper and constant sections, providing an overall
+        size of the taper profile.
+
+        Returns:
+            float: Total length of the taper structure.
+        """
+        return self.last_section.z_final
+
+    @property
+    def last_radius(self) -> float:
+        """
+        Retrieves the radius at the last computed z-position, which represents the end radius of the taper structure.
+
+        Returns:
+            float: Radius at the last z-coordinate in the taper profile.
+        """
+        if len(self.section_list) == 0:
+            return self.initial_radius
+        else:
+            return self.last_section.radius_final
+
+    def initialize(self) -> None:
+        """
+        Initializes or re-initializes the profile, typically called after making modifications to the taper sections. This method
+        recalculates and updates internal parameters to reflect the current state of the taper structure.
+
+        Returns:
+            None
+        """
+        if self.add_end_of_taper_section:
+            self.add_end_of_taper_segment()
+
+        distance = numpy.linspace(0, self.last_z, self.n_point)
+        radius = self.compute_radius_from_segment_from_interpolation(distance)
+        itr_list = radius / self.initial_radius
+        adiabatic = self.compute_adiabatic(distance=distance, radius=radius)
+        taper_angle = self.compute_taper_angle(distance=distance, radius=radius)
+
+        if self.symmetric:
+            self._distance = numpy.linspace(distance[0], 2 * distance[-1], 2 * distance.size - 1)
+            self._itr_list = numpy.r_[itr_list, itr_list[-2::-1]]
+            self._radius = numpy.r_[radius, radius[-2::-1]]
+            self._adiabatic = numpy.r_[adiabatic, adiabatic[-2::-1]]
+            self._taper_angle = numpy.r_[taper_angle, taper_angle[-2::-1]]
+        else:
+            self._distance = distance
+            self._radius = radius
+            self._itr_list = itr_list
+            self._adiabatic = adiabatic
+            self._taper_angle = taper_angle
+
+    @property
+    def distance(self) -> numpy.ndarray:
+        try:
+            return self._distance
+        except AttributeError:
+            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
+
+    @property
+    def radius(self) -> numpy.ndarray:
+        try:
+            return self._radius
+        except AttributeError:
+            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
+
+    @property
+    def itr_list(self) -> numpy.ndarray:
+        try:
+            return self._itr_list
+        except AttributeError:
+            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
+
+    @property
+    def adiabatic(self) -> numpy.ndarray:
+        try:
+            return self._adiabatic
+        except AttributeError:
+            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
+
+    @property
+    def taper_angle(self) -> numpy.ndarray:
+        try:
+            return self._taper_angle
+        except AttributeError:
+            raise AttributeError('Profile has not been initialized yet. The user need to run the initialize() method first. ')
+
+    def compute_radius_from_segment_from_interpolation(self, z: numpy.ndarray) -> numpy.ndarray:
+        """
+        Computes the radius at specified z-distances based on interpolation from existing taper sections, providing a continuous
+        profile of the radius along the taper.
+
+        Parameters:
+            z (numpy.ndarray): Array of z-distances at which to evaluate the radius.
+
+        Returns:
+            numpy.ndarray: Array of radius values interpolated along the given z-distances.
+        """
+        radius = numpy.zeros(z.size)
+
+        for section in self.section_list:
+            evaluation = section.interpolation(z)
+            idx_non_null = evaluation != 0
+            radius[idx_non_null] = evaluation[idx_non_null]
+
+        return radius
+
+    def add_taper_segment(
+            self, *,
+            alpha: float,
+            initial_heating_length: float,
+            stretching_length: float,
+            initial_radius: float = None,
+            n_point: int = 100) -> None:
+        """
+        Adds a tapered section following the previously defined section, using provided taper parameters to define the new section's
+        geometry and behavior.
+
+        Parameters:
+            alpha (float): Rate at which the heating section's influence changes over time.
+            initial_heating_length (float): Initial length of the heating section.
+            stretching_length (float): Total length over which the segment is stretched.
+            initial_radius (float): Radius at the start of the segment, defaults to the last radius if not provided.
+            n_point (int): Number of points along the section for resolution, defaults to 100.
+
+        Returns:
+            None
+        """
+        return self.add_taper_custom_segment(
+            alpha=alpha,
+            initial_heating_length=initial_heating_length,
+            initial_radius=self.last_radius,
+            stretching_length=stretching_length,
+            start_z=self.last_z,
+            n_point=n_point
+        )
+
+    def get_itr_vs_distance_interpolation(self) -> Callable:
+        """
+        Generates an interpolation function for inverse taper ratio (ITR) as a function of distance.
+        This allows for quick lookups of ITR at arbitrary distances along the taper.
+
+        Returns:
+            Callable: A function that interpolates ITR based on given distances.
+        """
+        return interp1d(
+            x=self.distance,
+            y=self.itr_list,
+            bounds_error=False,
+            fill_value=0
+        )
+
+    def single_plot(function) -> Callable:
+        """
+        Decorator to apply a standard plotting style to any plotting function within this class.
+        It automatically sets line styles, colors, and labels from the class attributes.
+
+        Parameters:
+            function (Callable): The plotting function to decorate.
+
+        Returns:
+            Callable: A wrapped plotting function that integrates additional styling and annotations.
+        """
+
+        def wrapper(self, ax: Axis, line_color: str = None, line_style: str = None, **kwargs):
+            line_style = self.line_style if line_style is None else line_style
+            line_color = self.line_color if line_color is None else line_color
+
+            x, y = function(self, ax=ax, line_color=line_color, line_style=line_style, **kwargs)
+
+            ax.add_line(x=x, y=y, label=self.label, line_style=line_style, color=line_color)
+
+        return wrapper
+
+    @single_plot
+    def render_itr_vs_z_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
+        """
+        Renders a plot of inverse taper ratio (ITR) versus z-distance onto a given axis. This method is typically
+        used for visualizing how the ITR changes along the length of the taper.
+
+        Parameters:
+            ax (Axis): The matplotlib axis on which to plot.
+            line_style (str, optional): Line style for the plot, defaults to class attribute.
+            line_color (str, optional): Line color for the plot, defaults to class attribute.
+
+        Returns:
+            tuple[numpy.ndarray, numpy.ndarray]
+        """
+        ax.set_style(
+            show_legend=False,
+            y_limits=[0, None],
+            x_label='Z-propagation [mm]',
+            y_label='Inverse taper ratio [ITR]',
+            x_scale_factor=1e3,
+            y_scale="linear",
+            line_width=2
+        )
+
+        return self.distance, self.itr_list
+
+    @single_plot
+    def render_taper_angle_vs_z_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
+        """
+        Plots the taper angle as a function of z-distance on a provided axis. Useful for understanding the geometric
+        changes in the taper profile over its length.
+
+        Parameters:
+            ax (Axis): The matplotlib axis on which to plot.
+            line_style (str, optional): Specifies the style of the plot line, if different from the class default.
+            line_color (str, optional): Specifies the color of the plot line, if different from the class default.
+
+        Returns:
+            tuple[numpy.ndarray, numpy.ndarray]
+        """
+        ax.set_style(
+            show_legend=False,
+            y_limits=[0, None],
+            y_label='Taper angle [rad]',
+            x_label='Z-propagation [mm]',
+            x_scale_factor=1e3,
+            y_scale="linear",
+            line_width=2
+        )
+
+        return self.distance, self.taper_angle
+
+    @single_plot
+    def render_adiabatic_factor_vs_z_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
+        """
+        Plots the adiabatic criterion versus z-distance on the specified axis. This plot helps assess the
+        efficiency and effectiveness of the taper in maintaining adiabatic conditions throughout its course.
+
+        Parameters:
+            ax (Axis): The matplotlib axis on which to plot.
+            line_style (str, optional): Line style for the plot, can override default.
+            line_color (str, optional): Line color for the plot, can override default.
+
+        Returns:
+            tuple[numpy.ndarray, numpy.ndarray]
+        """
+        ax.set_style(
+            y_scale='log',
+            y_label='Adiabatic criterion',
+            x_label='z-distance'
+        )
+
+        return self.distance, self.adiabatic
+
+    @single_plot
+    def render_adiabatic_factor_vs_itr_on_ax(self, ax: Axis, **kwargs) -> tuple[numpy.ndarray, numpy.ndarray]:
+        """
+        Add adiabatic criterion vs ITR plot to axis
+
+        :param      ax:   The axis on which to add the plot
+        :type       ax:   Axis
+        """
+        ax.set_style(**representation.adiabatic.Adiabatic.plot_style)
+
+        return self.itr_list, self.adiabatic
+
+    def plot(
+            self,
+            show_radius: bool = True,
+            show_adiabatic: bool = True,
+            show_taper_angle: bool = True) -> SceneList:
+        """
+        Generates plots based on the current state of the taper profile. This can include plots of radius vs. z-distance,
+        adiabatic factor vs. ITR, and taper angle vs. z-distance, based on the specified flags.
+
+        Parameters:
+            show_radius (bool): If True, includes a plot of radius vs. z-distance.
+            show_adiabatic (bool): If True, includes a plot of adiabatic factor vs. ITR.
+            show_taper_angle (bool): If True, includes a plot of taper angle vs. z-distance.
+
+        Returns:
+            SceneList: A collection of matplotlib axes with the requested plots.
+        """
+        figure = SceneList(
+            title=f'Minimum ITR: {self.smallest_itr:.4f}',
+            ax_orientation='vertical',
+            unit_size=(8, 3)
+        )
+
+        if show_radius:
+            ax = figure.append_ax()
+            self.render_itr_vs_z_on_ax(ax=ax)
+
+        if show_taper_angle:
+            ax = figure.append_ax()
+            self.render_taper_angle_vs_z_on_ax(ax=ax)
+
+        if show_adiabatic:
+            ax = figure.append_ax()
+            self.render_adiabatic_factor_vs_itr_on_ax(ax=ax)
+
+        figure.annotate_axis(position=(-0.15, 1.15))
+
+        return figure
+
+    def generate_propagation_gif(
+            self,
+            output_directory: str = './new_gif.gif',
+            dpi: int = 100,
+            fps: int = 20,
+            number_of_frames: int = 200,
+            dark_background: bool = True) -> None:
+        """
+        Generates an animated GIF of light propagation in a taper structure.
+
+        Parameters:
+            output_directory (str): Path where the GIF will be saved.
+            dpi (int): Dots per inch for the output GIF.
+            fps (int): Frames per second for the animation.
+            number_of_frames (int): Total number of frames in the animation.
+            dark_background (bool): If True, use a dark background for the GIF.
+
+        Returns:
+            None
+        """
+        figure, ax = plt.subplots(figsize=(12, 6))
+        ax.set_xlabel('Propagation axis [mm]', color='white' if dark_background else 'black')
+        style_context = "dark_background" if dark_background else "default"
+
+        sub_sampling_factor = int(self.distance.size / number_of_frames)
+
+        sub_distance = self.distance[::sub_sampling_factor] * 1e3
+        sub_radius = self.radius[::sub_sampling_factor]
+        sub_itr_list = self.itr_list[::sub_sampling_factor]
+
+        with plt.style.context(style_context):
+            def init_func() -> tuple:
+                line_0 = ax.plot(sub_distance, sub_radius, color='black')
+                line_1 = ax.plot(sub_distance, -sub_radius, color='black')
+
+                line_2 = ax.fill_between(
+                    sub_distance,
+                    +sub_radius,
+                    -sub_radius,
+                    color='lightblue',
+                    alpha=0.8
+                )
+
+                return [*line_0, *line_1, line_2]
+
+            def animate(slice_number: int) -> tuple:
+                position = sub_distance[slice_number]
+                itr = sub_itr_list[slice_number]
+                title = f'[slice: {slice_number} - ITR: {itr:.3f}]'
+
+                if slice_number > 0:
+                    ax.lines[-1].remove()
+
+                line_0 = ax.set_title(title, color='white')
+
+                line_1 = ax.axvline(position, linestyle='--', linewidth=2, color='red')
+
+                return line_0, line_1
+
+        animation = FuncAnimation(
+            fig=figure,
+            func=animate,
+            init_func=init_func,
+            blit=True,
+            repeat=True,
+            frames=sub_itr_list.size
+        )
+
+        animation.save(
+            output_directory,
+            dpi=dpi,
+            writer=PillowWriter(fps=fps)
+        )
+
+# -
```

## SuPyMode/solver.py

```diff
@@ -1,223 +1,224 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-# Third-party imports
-import numpy
-from dataclasses import dataclass, field
-from PyFinitDiff.finite_difference_2D import FiniteDifference
-from PyFinitDiff.finite_difference_2D import Boundaries
-from FiberFusing.geometry import Geometry
-from FiberFusing.coordinate_system import CoordinateSystem
-
-# Local imports
-from SuPyMode.superset import SuperSet
-from SuPyMode.supermode import SuperMode
-from SuPyMode.binary.CppSolver import CppSolver
-from SuPyMode.binary.ModelParameters import ModelParameters
-from SuPyMode.binary.SuperMode import SuperMode as BindingSuperMode  # noqa: F401 It has to be imported in order for pybind11 to know the type
-from SuPyMode.mode_label import ModeLabel
-
-
-@dataclass()
-class SuPySolver(object):
-    """
-    Solver class integrating a C++ eigensolver to compute eigenvalues for optical fiber geometries.
-    This class manages the eigenvalue problems and returns collections of computed SuperModes.
-
-    Attributes:
-        geometry (Geometry | np.ndarray): The refractive index geometry of the optical structure.
-        tolerance (float): Absolute tolerance for the propagation constant computation.
-        max_iter (int): Maximum iterations for the C++ eigensolver.
-        accuracy (int): Accuracy level of the finite difference method.
-        extrapolation_order (int): Order of Taylor series used to extrapolate eigenvalues.
-        debug_mode (int): Debug output level from the C++ binding (0, 1, 2).
-        coordinate_system (Optional[CoordinateSystem]): The coordinate system linked with the geometry.
-    """
-    geometry: Geometry | numpy.ndarray = field(repr=False)
-    tolerance: float = 1e-8
-    max_iter: int = 10_000
-    accuracy: int = 2
-    extrapolation_order: int = 2
-    debug_mode: int = 1
-    coordinate_system: CoordinateSystem | None = None
-
-    def __post_init__(self):
-        if isinstance(self.geometry, numpy.ndarray):
-            assert self.coordinate_system is not None, "Geometry provided without its coordinate system"
-            self.mesh = self.geometry
-        else:
-            self.geometry.generate_coordinate_system()
-            self.mesh = self.geometry.generate_mesh()
-            self.coordinate_system = self.geometry.coordinate_system
-
-        self.mode_number = 0
-        self.solver_number = 0
-
-    def initialize_binding(self, n_sorted_mode: int, boundaries: Boundaries, n_added_mode: int) -> CppSolver:
-        """
-        Initializes and configures the C++ solver binding for eigenvalue computations.
-
-        Args:
-            n_sorted_mode (int): Number of modes to sort and retrieve from the solver.
-            boundaries (Boundaries): Boundary conditions for the finite difference system.
-            n_added_mode (int): Number of extra modes calculated for accuracy and reliability.
-
-        Returns:
-            CppSolver: Configured C++ solver instance.
-        """
-        self.FD = FiniteDifference(
-            n_x=self.coordinate_system.nx,
-            n_y=self.coordinate_system.ny,
-            dx=self.coordinate_system.dx,
-            dy=self.coordinate_system.dy,
-            derivative=2,
-            accuracy=self.accuracy,
-            boundaries=boundaries
-        )
-
-        self.FD.construct_triplet()
-
-        new_array = numpy.c_[
-            self.FD._triplet.array[:, 1],
-            self.FD._triplet.array[:, 0],
-            self.FD._triplet.array[:, 2]
-        ]
-
-        self.model_parameters = ModelParameters(
-            dx=self.coordinate_system.dx,
-            dy=self.coordinate_system.dy,
-            wavelength=self.wavelength,
-            itr_list=self.itr_list,
-            mesh=self.mesh,
-            x_vector=self.coordinate_system.x_vector,
-            y_vector=self.coordinate_system.y_vector,
-            left_boundary=boundaries.left,
-            right_boundary=boundaries.right,
-            top_boundary=boundaries.top,
-            bottom_boundary=boundaries.bottom,
-            debug_mode=self.debug_mode
-        )
-
-        solver = CppSolver(
-            model_parameters=self.model_parameters,
-            finit_matrix=new_array.T,
-            n_computed_mode=n_sorted_mode + n_added_mode,
-            n_sorted_mode=n_sorted_mode,
-            max_iter=self.max_iter,
-            tolerance=self.tolerance
-        )
-
-        solver.compute_laplacian()
-
-        return solver
-
-    def init_superset(self, wavelength: float, n_step: int = 300, itr_initial: float = 1.0, itr_final: float = 0.1) -> None:
-        """
-        Initializes a SuperSet instance containing computed supermodes over a range of inverse taper ratios (ITR).
-
-        Args:
-            wavelength (float): Wavelength for the mode computation.
-            n_step (int): Number of steps for the ITR interpolation.
-            itr_initial (float): Initial ITR value.
-            itr_final (float): Final ITR value.
-        """
-        self.wavelength = wavelength
-        self.wavenumber = 2 * numpy.pi / wavelength
-        self.itr_list = numpy.linspace(itr_initial, itr_final, n_step)
-        self.superset = SuperSet(parent_solver=self, wavelength=wavelength)
-
-    def index_to_eigen_value(self, index: float) -> float:
-        """
-        Converts a refractive index to the corresponding eigenvalue for the solver.
-
-        Args:
-            index (float): Refractive index to convert.
-
-        Returns:
-            float: Calculated eigenvalue based on the given index and the wavenumber.
-        """
-        return -(index * self.wavenumber)**2
-
-    def eigen_value_to_index(self, eigen_value: float) -> float:
-        """
-        Converts an eigenvalue from the solver to the corresponding refractive index.
-
-        Args:
-            eigen_value (float): Eigenvalue to convert.
-
-        Returns:
-            float: Equivalent refractive index calculated from the eigenvalue and the wavenumber.
-        """
-        return numpy.sqrt(eigen_value) / self.wavenumber
-
-    def get_supermode_labels(self, n_modes: int, boundaries: Boundaries, auto_label: bool) -> list:
-        """
-        Generates labels for supermodes based on boundary conditions and whether auto-labeling is enabled.
-
-        Args:
-            n_modes (int): Number of modes for which labels are needed.
-            boundaries (Boundaries): Boundary conditions that affect mode symmetries.
-            auto_label (bool): If True, automatically generates labels based on mode symmetries; otherwise, generates generic labels.
-
-        Returns:
-            list: List of labels for the supermodes.
-        """
-        if auto_label:
-            return [ModeLabel(boundaries=boundaries, mode_number=n).label for n in range(n_modes)]
-        else:
-            return ["mode_" + "{" + str(n) + "}" for n in range(n_modes)]
-
-    def add_modes(self, n_sorted_mode: int, boundaries: Boundaries, n_added_mode: int = 4, index_guess: float = 0., auto_label: bool = True) -> None:
-        """
-        Computes and adds a specified number of supermodes to the solver's collection, using given boundary conditions and mode sorting criteria.
-
-        Args:
-            n_sorted_mode (int): Number of modes to output and sort from the solver.
-            boundaries (Boundaries): Boundary conditions for the finite difference calculations.
-            n_added_mode (int): Additional modes computed to ensure mode matching accuracy.
-            index_guess (float): Starting guess for the refractive index used in calculations (if 0, auto evaluated).
-            auto_label (bool): If True, enables automatic labeling of modes based on symmetry.
-
-        Returns:
-            None: This method updates the solver's internal state but does not return any value.
-        """
-        alpha = self.index_to_eigen_value(index_guess)
-
-        cpp_solver = self.initialize_binding(
-            boundaries=boundaries,
-            n_added_mode=n_added_mode,
-            n_sorted_mode=n_sorted_mode
-        )
-
-        self.superset.model_parameters = self.model_parameters
-
-        cpp_solver.loop_over_itr(
-            extrapolation_order=self.extrapolation_order,
-            alpha=alpha
-        )
-
-        mode_labels = self.get_supermode_labels(
-            n_modes=n_sorted_mode,
-            boundaries=boundaries,
-            auto_label=auto_label
-        )
-
-        for binding_number, label in enumerate(mode_labels):
-            supermode = SuperMode(
-                parent_set=self.superset,
-                binded_supermode=cpp_solver.get_mode(binding_number),
-                mode_number=self.mode_number,
-                solver_number=self.solver_number,
-                boundaries=boundaries,
-                label=label
-            )
-
-            self.superset.supermodes.append(supermode)
-
-            setattr(self.superset, label, supermode)
-
-            self.mode_number += 1
-
-        self.solver_number += 1
-
-# ---
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+# Third-party imports
+import numpy
+from dataclasses import dataclass, field
+from PyFinitDiff.finite_difference_2D import FiniteDifference
+from PyFinitDiff.finite_difference_2D import Boundaries
+from FiberFusing.geometry import Geometry
+from FiberFusing.coordinate_system import CoordinateSystem
+
+# Local imports
+from SuPyMode.superset import SuperSet
+from SuPyMode.supermode import SuperMode
+from SuPyMode.binary.CppSolver import CppSolver
+from SuPyMode.binary.ModelParameters import ModelParameters
+from SuPyMode.binary.SuperMode import SuperMode as BindingSuperMode  # noqa: F401 It has to be imported in order for pybind11 to know the type
+from SuPyMode.mode_label import ModeLabel
+
+
+@dataclass()
+class SuPySolver(object):
+    """
+    Solver class integrating a C++ eigensolver to compute eigenvalues for optical fiber geometries.
+    This class manages the eigenvalue problems and returns collections of computed SuperModes.
+
+    Attributes:
+        geometry (Geometry | np.ndarray): The refractive index geometry of the optical structure.
+        tolerance (float): Absolute tolerance for the propagation constant computation.
+        max_iter (int): Maximum iterations for the C++ eigensolver.
+        accuracy (int): Accuracy level of the finite difference method.
+        extrapolation_order (int): Order of Taylor series used to extrapolate eigenvalues.
+        debug_mode (int): Debug output level from the C++ binding (0, 1, 2).
+        coordinate_system (Optional[CoordinateSystem]): The coordinate system linked with the geometry.
+    """
+    geometry: Geometry | numpy.ndarray = field(repr=False)
+    tolerance: float = 1e-8
+    max_iter: int = 10_000
+    accuracy: int = 2
+    extrapolation_order: int = 2
+    debug_mode: int = 1
+    coordinate_system: CoordinateSystem | None = None
+
+    def __post_init__(self):
+        if isinstance(self.geometry, numpy.ndarray):
+            assert self.coordinate_system is not None, "Geometry provided without its coordinate system"
+            self.mesh = self.geometry
+        else:
+            self.geometry.generate_coordinate_system()
+            self.mesh = self.geometry.generate_mesh()
+            self.coordinate_system = self.geometry.coordinate_system
+
+        self.mode_number = 0
+        self.solver_number = 0
+
+    def initialize_binding(self, n_sorted_mode: int, boundaries: Boundaries, n_added_mode: int) -> CppSolver:
+        """
+        Initializes and configures the C++ solver binding for eigenvalue computations.
+
+        Args:
+            n_sorted_mode (int): Number of modes to sort and retrieve from the solver.
+            boundaries (Boundaries): Boundary conditions for the finite difference system.
+            n_added_mode (int): Number of extra modes calculated for accuracy and reliability.
+
+        Returns:
+            CppSolver: Configured C++ solver instance.
+        """
+        self.FD = FiniteDifference(
+            n_x=self.coordinate_system.nx,
+            n_y=self.coordinate_system.ny,
+            dx=self.coordinate_system.dx,
+            dy=self.coordinate_system.dy,
+            derivative=2,
+            accuracy=self.accuracy,
+            boundaries=boundaries
+        )
+
+        self.FD.construct_triplet()
+
+        new_array = numpy.c_[
+            self.FD._triplet.array[:, 1],
+            self.FD._triplet.array[:, 0],
+            self.FD._triplet.array[:, 2]
+        ]
+
+        solver = CppSolver(
+            model_parameters=self.model_parameters,
+            finit_matrix=new_array.T,
+            n_computed_mode=n_sorted_mode + n_added_mode,
+            n_sorted_mode=n_sorted_mode,
+            max_iter=self.max_iter,
+            tolerance=self.tolerance,
+            left_boundary=boundaries.left,
+            right_boundary=boundaries.right,
+            top_boundary=boundaries.top,
+            bottom_boundary=boundaries.bottom,
+        )
+
+        solver.compute_laplacian()
+
+        return solver
+
+    def init_superset(self, wavelength: float, n_step: int = 300, itr_initial: float = 1.0, itr_final: float = 0.1) -> None:
+        """
+        Initializes a SuperSet instance containing computed supermodes over a range of inverse taper ratios (ITR).
+
+        Args:
+            wavelength (float): Wavelength for the mode computation.
+            n_step (int): Number of steps for the ITR interpolation.
+            itr_initial (float): Initial ITR value.
+            itr_final (float): Final ITR value.
+        """
+        self.wavelength = wavelength
+        self.wavenumber = 2 * numpy.pi / wavelength
+        self.itr_list = numpy.linspace(itr_initial, itr_final, n_step)
+
+        self.model_parameters = ModelParameters(
+            dx=self.coordinate_system.dx,
+            dy=self.coordinate_system.dy,
+            wavelength=wavelength,
+            itr_list=self.itr_list,
+            mesh=self.mesh,
+            x_vector=self.coordinate_system.x_vector,
+            y_vector=self.coordinate_system.y_vector,
+            debug_mode=self.debug_mode
+        )
+
+        self.superset = SuperSet(geometry=self.geometry, wavelength=wavelength, model_parameters=self.model_parameters)
+
+    def index_to_eigen_value(self, index: float) -> float:
+        """
+        Converts a refractive index to the corresponding eigenvalue for the solver.
+
+        Args:
+            index (float): Refractive index to convert.
+
+        Returns:
+            float: Calculated eigenvalue based on the given index and the wavenumber.
+        """
+        return -(index * self.wavenumber)**2
+
+    def eigen_value_to_index(self, eigen_value: float) -> float:
+        """
+        Converts an eigenvalue from the solver to the corresponding refractive index.
+
+        Args:
+            eigen_value (float): Eigenvalue to convert.
+
+        Returns:
+            float: Equivalent refractive index calculated from the eigenvalue and the wavenumber.
+        """
+        return numpy.sqrt(eigen_value) / self.wavenumber
+
+    def get_supermode_labels(self, n_modes: int, boundaries: Boundaries, auto_label: bool) -> list:
+        """
+        Generates labels for supermodes based on boundary conditions and whether auto-labeling is enabled.
+
+        Args:
+            n_modes (int): Number of modes for which labels are needed.
+            boundaries (Boundaries): Boundary conditions that affect mode symmetries.
+            auto_label (bool): If True, automatically generates labels based on mode symmetries; otherwise, generates generic labels.
+
+        Returns:
+            list: List of labels for the supermodes.
+        """
+        if auto_label:
+            return [ModeLabel(boundaries=boundaries, mode_number=n).label for n in range(n_modes)]
+        else:
+            return ["mode_" + "{" + str(n) + "}" for n in range(n_modes)]
+
+    def add_modes(self, n_sorted_mode: int, boundaries: Boundaries, n_added_mode: int = 4, index_guess: float = 0., auto_label: bool = True) -> None:
+        """
+        Computes and adds a specified number of supermodes to the solver's collection, using given boundary conditions and mode sorting criteria.
+
+        Args:
+            n_sorted_mode (int): Number of modes to output and sort from the solver.
+            boundaries (Boundaries): Boundary conditions for the finite difference calculations.
+            n_added_mode (int): Additional modes computed to ensure mode matching accuracy.
+            index_guess (float): Starting guess for the refractive index used in calculations (if 0, auto evaluated).
+            auto_label (bool): If True, enables automatic labeling of modes based on symmetry.
+
+        Returns:
+            None: This method updates the solver's internal state but does not return any value.
+        """
+        alpha = self.index_to_eigen_value(index_guess)
+
+        cpp_solver = self.initialize_binding(
+            boundaries=boundaries,
+            n_added_mode=n_added_mode,
+            n_sorted_mode=n_sorted_mode
+        )
+
+        self.superset.model_parameters = self.model_parameters
+
+        cpp_solver.loop_over_itr(
+            extrapolation_order=self.extrapolation_order,
+            alpha=alpha
+        )
+
+        mode_labels = self.get_supermode_labels(
+            n_modes=n_sorted_mode,
+            boundaries=boundaries,
+            auto_label=auto_label
+        )
+
+        for binding_number, label in enumerate(mode_labels):
+            supermode = SuperMode(
+                parent_set=self.superset,
+                binded_supermode=cpp_solver.get_mode(binding_number),
+                mode_number=self.mode_number,
+                solver_number=self.solver_number,
+                boundaries=boundaries,
+                label=label
+            )
+
+            self.superset.supermodes.append(supermode)
+
+            setattr(self.superset, label, supermode)
+
+            self.mode_number += 1
+
+        self.solver_number += 1
+
+# ---
```

## SuPyMode/special.py

 * *Ordering differences only*

```diff
@@ -1,163 +1,163 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import matplotlib.pyplot as plt
-
-from MPSPlots import CMAP
-from matplotlib.animation import FuncAnimation, PillowWriter
-
-
-def get_3_figures():
-
-    fig = plt.figure(figsize=(8, 6))
-
-    gs = fig.add_gridspec(
-        2, 2,
-        width_ratios=(1, 1),
-        height_ratios=(1, 1),
-        left=0.1,
-        right=0.9,
-        bottom=0.1,
-        top=0.9,
-        wspace=0.5 * 2,
-        hspace=0.15)
-
-    ax0 = fig.add_subplot(gs[0, 0:])
-    ax1 = fig.add_subplot(gs[1, 0])
-    ax2 = fig.add_subplot(gs[1, 1])
-
-    ax1.tick_params(
-        axis='both',
-        which='both',
-        top=False,
-        bottom=False,
-        right=False,
-        left=False,
-        labelleft=False,
-        labelbottom=False,
-        grid_alpha=0
-    )
-    ax2.tick_params(
-        axis='both',
-        which='both',
-        top=False,
-        bottom=False,
-        right=False,
-        left=False,
-        labelleft=False,
-        labelbottom=False,
-        grid_alpha=0
-    )
-
-    ax1.set_aspect('equal')
-    ax2.set_aspect('equal')
-
-    return fig, ax0, ax1, ax2
-
-
-class ModePropagationGifCreator():
-    def __init__(
-            self,
-            superset,
-            profile,
-            max_number_of_mode: int = None,
-            dark_background: bool = True):
-
-        self.superset = superset
-        self.profile = profile
-        self.dark_background = dark_background
-
-        if max_number_of_mode is None:
-            self.number_of_mode = len(superset.supermodes)
-        else:
-            self.number_of_mode = max_number_of_mode
-
-        self.generate_figure()
-
-    def generate_profile_ax(self):
-        self.ax_profile = self.figure.add_subplot(self.grid_spec[0, :])
-        self.ax_profile.set_xlabel('Propagation distance z')
-        self.ax_profile.set_ylabel('Coupler profile')
-
-        top = self.profile.radius
-        bottom = -self.profile.radius
-
-        self.ax_profile.plot(self.profile.distance, top, color='black')
-        self.ax_profile.plot(self.profile.distance, bottom, color='black')
-        self.ax_profile.fill_between(self.profile.distance, top, bottom, color='lightblue', alpha=0.8)
-
-    def generate_field_ax(self):
-        self.field_axes = []
-        for mode in range(self.number_of_mode):
-            ax = self.figure.add_subplot(self.grid_spec[1, mode])
-            ax.set_aspect('equal')
-            ax.set_xticks([])
-            ax.set_yticks([])
-            self.field_axes.append(ax)
-            ax.set_title(self.superset[mode].stylized_name)
-
-    def generate_figure(self, unit_size: tuple = (3, 6)) -> None:
-        figure_size = (unit_size[0] * self.number_of_mode, unit_size[1])
-        self.figure = plt.figure(figsize=figure_size)
-
-        self.grid_spec = self.figure.add_gridspec(
-            2,
-            self.number_of_mode,
-            left=0.1,
-            right=0.95,
-            bottom=0.1,
-            top=0.9,
-            wspace=0.5,
-            hspace=0.35
-        )
-
-        self.generate_profile_ax()
-
-        self.generate_field_ax()
-
-    def populate_axes(self, z: float):
-        itr = self.profile.master_interpolation_z_to_itr(z)
-        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
-
-        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
-        self.profile_line = self.ax_profile.axvline(z, linestyle='--', color='red')
-
-        for ax, field in zip(self.field_axes, slice_structure.fields):
-            ax.pcolormesh(field, cmap=CMAP.BKR)
-
-    def update_axes(self, z: float):
-        itr = self.profile.master_interpolation_z_to_itr(z)
-        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
-        self.profile_line.set_xdata(z)
-        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
-
-        for ax, field in zip(self.field_axes, slice_structure.fields):
-            ax.clear()
-            ax.pcolormesh(field, cmap=CMAP.BKR)
-
-    def make_animation(self, n_step: int = 20, dpi: float = 100, fps: int = 50):
-        self.populate_axes(z=0e-3)
-
-        factor = self.profile.length / n_step
-
-        def animate(iteration):
-            distance = iteration * factor
-            print(f"iteration: {iteration} / {n_step}")
-
-            self.update_axes(distance)
-
-        ani = FuncAnimation(
-            self.figure,
-            animate,
-            interval=40,
-            blit=True,
-            repeat=True,
-            frames=n_step
-        )
-
-        ani.save(
-            "propagation.gif",
-            dpi=dpi,
-            writer=PillowWriter(fps=fps)
-        )
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+import matplotlib.pyplot as plt
+
+from MPSPlots import CMAP
+from matplotlib.animation import FuncAnimation, PillowWriter
+
+
+def get_3_figures():
+
+    fig = plt.figure(figsize=(8, 6))
+
+    gs = fig.add_gridspec(
+        2, 2,
+        width_ratios=(1, 1),
+        height_ratios=(1, 1),
+        left=0.1,
+        right=0.9,
+        bottom=0.1,
+        top=0.9,
+        wspace=0.5 * 2,
+        hspace=0.15)
+
+    ax0 = fig.add_subplot(gs[0, 0:])
+    ax1 = fig.add_subplot(gs[1, 0])
+    ax2 = fig.add_subplot(gs[1, 1])
+
+    ax1.tick_params(
+        axis='both',
+        which='both',
+        top=False,
+        bottom=False,
+        right=False,
+        left=False,
+        labelleft=False,
+        labelbottom=False,
+        grid_alpha=0
+    )
+    ax2.tick_params(
+        axis='both',
+        which='both',
+        top=False,
+        bottom=False,
+        right=False,
+        left=False,
+        labelleft=False,
+        labelbottom=False,
+        grid_alpha=0
+    )
+
+    ax1.set_aspect('equal')
+    ax2.set_aspect('equal')
+
+    return fig, ax0, ax1, ax2
+
+
+class ModePropagationGifCreator():
+    def __init__(
+            self,
+            superset,
+            profile,
+            max_number_of_mode: int = None,
+            dark_background: bool = True):
+
+        self.superset = superset
+        self.profile = profile
+        self.dark_background = dark_background
+
+        if max_number_of_mode is None:
+            self.number_of_mode = len(superset.supermodes)
+        else:
+            self.number_of_mode = max_number_of_mode
+
+        self.generate_figure()
+
+    def generate_profile_ax(self):
+        self.ax_profile = self.figure.add_subplot(self.grid_spec[0, :])
+        self.ax_profile.set_xlabel('Propagation distance z')
+        self.ax_profile.set_ylabel('Coupler profile')
+
+        top = self.profile.radius
+        bottom = -self.profile.radius
+
+        self.ax_profile.plot(self.profile.distance, top, color='black')
+        self.ax_profile.plot(self.profile.distance, bottom, color='black')
+        self.ax_profile.fill_between(self.profile.distance, top, bottom, color='lightblue', alpha=0.8)
+
+    def generate_field_ax(self):
+        self.field_axes = []
+        for mode in range(self.number_of_mode):
+            ax = self.figure.add_subplot(self.grid_spec[1, mode])
+            ax.set_aspect('equal')
+            ax.set_xticks([])
+            ax.set_yticks([])
+            self.field_axes.append(ax)
+            ax.set_title(self.superset[mode].stylized_name)
+
+    def generate_figure(self, unit_size: tuple = (3, 6)) -> None:
+        figure_size = (unit_size[0] * self.number_of_mode, unit_size[1])
+        self.figure = plt.figure(figsize=figure_size)
+
+        self.grid_spec = self.figure.add_gridspec(
+            2,
+            self.number_of_mode,
+            left=0.1,
+            right=0.95,
+            bottom=0.1,
+            top=0.9,
+            wspace=0.5,
+            hspace=0.35
+        )
+
+        self.generate_profile_ax()
+
+        self.generate_field_ax()
+
+    def populate_axes(self, z: float):
+        itr = self.profile.master_interpolation_z_to_itr(z)
+        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
+
+        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
+        self.profile_line = self.ax_profile.axvline(z, linestyle='--', color='red')
+
+        for ax, field in zip(self.field_axes, slice_structure.fields):
+            ax.pcolormesh(field, cmap=CMAP.BKR)
+
+    def update_axes(self, z: float):
+        itr = self.profile.master_interpolation_z_to_itr(z)
+        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
+        self.profile_line.set_xdata(z)
+        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
+
+        for ax, field in zip(self.field_axes, slice_structure.fields):
+            ax.clear()
+            ax.pcolormesh(field, cmap=CMAP.BKR)
+
+    def make_animation(self, n_step: int = 20, dpi: float = 100, fps: int = 50):
+        self.populate_axes(z=0e-3)
+
+        factor = self.profile.length / n_step
+
+        def animate(iteration):
+            distance = iteration * factor
+            print(f"iteration: {iteration} / {n_step}")
+
+            self.update_axes(distance)
+
+        ani = FuncAnimation(
+            self.figure,
+            animate,
+            interval=40,
+            blit=True,
+            repeat=True,
+            frames=n_step
+        )
+
+        ani.save(
+            "propagation.gif",
+            dpi=dpi,
+            writer=PillowWriter(fps=fps)
+        )
+# -
```

## SuPyMode/supermode.py

 * *Ordering differences only*

```diff
@@ -1,274 +1,274 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from typing import Self
-# Built-in imports
-import numpy
-from dataclasses import dataclass, field as field_arg
-from scipy.interpolate import RectBivariateSpline
-
-# Local imports
-from SuPyMode import representation
-from SuPyMode.binary.ModelParameters import ModelParameters
-from SuPyMode.utils import interpret_slice_number_and_itr, get_symmetrized_vector
-
-
-@dataclass(kw_only=True)
-class SuperMode():
-    """
-    Represents supermodes within fiber optic structures. This class serves as a Python
-    counterpart to a C++ SuperMode class, facilitating integration and computation via
-    the SuPySolver. Instances of this class belong to a SuperSet, and each supermode
-    is uniquely identified within its symmetry set by a mode number.
-
-    Attributes:
-        parent_set (None): The SuperSet instance associated with this supermode.
-        binded_supermode (None): The corresponding C++ bound supermode object.
-        solver_number (int): Identifier linking this supermode to a specific Python solver.
-        mode_number (int): Unique identifier for this mode within a symmetry set.
-        boundaries (dict): Specifications of the boundary conditions for the supermode.
-        label (str, optional): An arbitrary descriptive label for the supermode.
-    """
-    parent_set: object
-    binded_supermode: object
-    solver_number: int
-    mode_number: int
-    boundaries: dict
-    label: str = None
-    ID: list = field_arg(init=False)
-    # Other representations
-    field: representation.Field = field_arg(init=False)
-    index: representation.Index = field_arg(init=False)
-    beta: representation.Beta = field_arg(init=False)
-    normalized_coupling: representation.NormalizedCoupling = field_arg(init=False)
-    adiabatic: representation.Adiabatic = field_arg(init=False)
-    eigen_value: representation.EigenValue = field_arg(init=False)
-    beating_length: representation.BeatingLength = field_arg(init=False)
-
-    def __post_init__(self):
-        self.ID = [self.solver_number, self.binding_number]
-        self.field = representation.Field(parent_supermode=self)
-        self.index = representation.Index(parent_supermode=self)
-        self.beta = representation.Beta(parent_supermode=self)
-        self.normalized_coupling = representation.NormalizedCoupling(parent_supermode=self)
-        self.adiabatic = representation.Adiabatic(parent_supermode=self)
-        self.eigen_value = representation.EigenValue(parent_supermode=self)
-        self.beating_length = representation.BeatingLength(parent_supermode=self)
-
-    def __hash__(self):
-        """
-        Returns a hash based on the binded supermode object, allowing this class
-        instance to be used in hash-based collections like sets and dictionaries.
-
-        Returns:
-            int: The hash value of the binded supermode object.
-        """
-        return hash(self.binded_supermode)
-
-    @property
-    def binding_number(self) -> int:
-        """Retrieves the binding number specific to the linked C++ solver."""
-        return self.binded_supermode.binding_number
-
-    @property
-    def geometry(self) -> object:
-        """
-        Provides access to the geometric configuration associated with the supermode.
-
-        Returns:
-            object: The geometry of the parent SuperSet.
-        """
-        return self.parent_set.geometry
-
-    @property
-    def coordinate_system(self) -> object:
-        """
-        Accesses the coordinate system used by the supermode.
-
-        Returns:
-            object: The coordinate system of the parent SuperSet.
-        """
-        return self.parent_set.coordinate_system
-
-    @property
-    def itr_list(self) -> numpy.ndarray:
-        """Provides a list of iteration parameters from the model."""
-        return self.binded_supermode.model_parameters.itr_list
-
-    @property
-    def model_parameters(self) -> ModelParameters:
-        """
-        Retrieves parameters defining the model's computational aspects.
-
-        Returns:
-            ModelParameters: Computational parameters from the binded supermode.
-        """
-        return self.binded_supermode.model_parameters
-
-    @property
-    def mesh_gradient(self) -> numpy.ndarray:
-        """Accesses the gradient mesh associated with the supermode."""
-        return self.binded_supermode.mesh_gradient
-
-    @property
-    def amplitudes(self) -> numpy.ndarray:
-        """
-        Computes the amplitude array for this supermode, setting its own mode number
-        to 1 and all others to 0.
-
-        Returns:
-            numpy.ndarray: Array of complex numbers representing amplitudes.
-        """
-        n_mode = len(self.parent_set.supermodes)
-        amplitudes = numpy.zeros(n_mode, dtype=complex)
-        amplitudes[self.mode_number] = 1
-        return amplitudes
-
-    @property
-    def stylized_label(self) -> str:
-        """
-        Provides a stylized label for the supermode. If no custom label is provided,
-        it defaults to a generic label with the mode ID.
-
-        Returns:
-            str: The stylized or default label.
-        """
-        if self.label is None:
-            return f"Mode: {self.ID}"
-        else:
-            return f"${self.label}$"
-
-    def is_computation_compatible(self, other: Self) -> bool:
-        """
-        Determines if another supermode is compatible for computation, based on unique
-        identifiers and boundary conditions.
-
-        Parameters:
-            other (SuperMode): The other supermode to compare.
-
-        Returns:
-            bool: True if the supermodes are compatible for computation, False otherwise.
-        """
-        return self.binded_supermode.is_computation_compatible(other.binded_supermode)
-
-    def is_symmetry_compatible(self, other: Self) -> bool:
-        """
-        Determines whether the specified other supermode has same symmetry.
-
-        :param      other:  The other supermode
-        :type       other:  SuperMode
-
-        :returns:   True if the specified other is symmetry compatible, False otherwise.
-        :rtype:     bool
-        """
-        return self.boundaries == other.boundaries
-
-    def get_field_interpolation(self, itr: float = None, slice_number: int = None) -> RectBivariateSpline:
-        """
-        Computes the field interpolation for a given iteration or slice number. Requires
-        exactly one of the parameters to be specified.
-
-        Parameters:
-            itr (float, optional): The iteration number for which to compute the interpolation.
-            slice_number (int, optional): The slice number for which to compute the interpolation.
-
-        Returns:
-            RectBivariateSpline: Interpolated field values over a grid.
-
-        Raises:
-            ValueError: If neither or both parameters are specified.
-        """
-        if (itr is None) == (slice_number is None):
-            raise ValueError("Exactly one of itr or slice_number must be provided.")
-
-        if slice_number is None:
-            slice_number = self.parent_set.itr_to_slice(itr_list=itr)
-
-        if itr is None:
-            slice_number, itr = interpret_slice_number_and_itr(
-                itr_baseline=self.itr_list,
-                slice_list=slice_number
-            )
-
-        field = self.field.get_field(slice_number=slice_number, add_symmetries=True)
-
-        x_axis, y_axis = self.get_axis(slice_number=slice_number, add_symmetries=True)
-
-        field_interpolation = RectBivariateSpline(
-            x=x_axis * itr,
-            y=y_axis * itr,
-            z=field,
-        )
-
-        return field_interpolation
-
-    def _get_axis_vector(self, add_symmetries: bool = True) -> tuple:
-        full_x_axis = self.coordinate_system.x_vector
-        full_y_axis = self.coordinate_system.y_vector
-
-        if not add_symmetries:
-            return full_x_axis, full_y_axis
-
-        if self.boundaries.right in ['symmetric', 'anti-symmetric']:
-            full_x_axis = get_symmetrized_vector(full_x_axis, symmetry_type='last')
-            full_x_axis.sort()
-
-        if self.boundaries.left in ['symmetric', 'anti-symmetric']:
-            full_x_axis = get_symmetrized_vector(full_x_axis, symmetry_type='first')
-            full_x_axis.sort()
-
-        if self.boundaries.top in ['symmetric', 'anti-symmetric']:
-            full_y_axis = get_symmetrized_vector(full_y_axis, symmetry_type='last')
-            full_y_axis.sort()
-
-        if self.boundaries.bottom in ['symmetric', 'anti-symmetric']:
-            full_y_axis = get_symmetrized_vector(full_y_axis, symmetry_type='first')
-            full_y_axis.sort()
-
-        return full_x_axis, full_y_axis
-
-    def get_axis(self, slice_number: int, add_symmetries: bool = True) -> tuple:
-        itr = self.model_parameters.itr_list[slice_number]
-
-        x_axis, y_axis = self._get_axis_vector(add_symmetries=add_symmetries)
-
-        return (x_axis * itr, y_axis * itr)
-
-    def __repr__(self) -> str:
-        return self.label
-
-    def plot(self, plot_type: str, **kwargs):
-        """
-        Plots various properties of the supermode based on specified type.
-
-        Parameters:
-            plot_type (str): The type of plot to generate (e.g., 'field', 'beta').
-            *args: Additional positional arguments for the plot function.
-            **kwargs: Additional keyword arguments for the plot function.
-
-        Returns:
-            The result of the plotting function, typically a plot object.
-
-        Raises:
-            ValueError: If an invalid plot type is specified.
-        """
-        match plot_type.lower():
-            case 'field':
-                return self.field.plot(**kwargs)
-            case 'beta':
-                return self.beta.plot(**kwargs)
-            case 'index':
-                return self.index.plot(**kwargs)
-            case 'eigen-value':
-                return self.eigen_value.plot(**kwargs)
-            case 'beating-length':
-                return self.beating_length.plot(**kwargs)
-            case 'adiabatic':
-                return self.adiabatic.plot(**kwargs)
-            case 'normalized-coupling':
-                return self.normalized_coupling.plot(**kwargs)
-            case _:
-                raise ValueError(f'Invalid plot type: {plot_type}. Options are: index, beta, eigen-value, field, beating-length, adiabatic, normalized-coupling')
-
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from typing import Self
+# Built-in imports
+import numpy
+from dataclasses import dataclass, field as field_arg
+from scipy.interpolate import RectBivariateSpline
+
+# Local imports
+from SuPyMode import representation
+from SuPyMode.binary.ModelParameters import ModelParameters
+from SuPyMode.utils import interpret_slice_number_and_itr, get_symmetrized_vector
+
+
+@dataclass(kw_only=True)
+class SuperMode():
+    """
+    Represents supermodes within fiber optic structures. This class serves as a Python
+    counterpart to a C++ SuperMode class, facilitating integration and computation via
+    the SuPySolver. Instances of this class belong to a SuperSet, and each supermode
+    is uniquely identified within its symmetry set by a mode number.
+
+    Attributes:
+        parent_set (None): The SuperSet instance associated with this supermode.
+        binded_supermode (None): The corresponding C++ bound supermode object.
+        solver_number (int): Identifier linking this supermode to a specific Python solver.
+        mode_number (int): Unique identifier for this mode within a symmetry set.
+        boundaries (dict): Specifications of the boundary conditions for the supermode.
+        label (str, optional): An arbitrary descriptive label for the supermode.
+    """
+    parent_set: object
+    binded_supermode: object
+    solver_number: int
+    mode_number: int
+    boundaries: dict
+    label: str = None
+    ID: list = field_arg(init=False)
+    # Other representations
+    field: representation.Field = field_arg(init=False)
+    index: representation.Index = field_arg(init=False)
+    beta: representation.Beta = field_arg(init=False)
+    normalized_coupling: representation.NormalizedCoupling = field_arg(init=False)
+    adiabatic: representation.Adiabatic = field_arg(init=False)
+    eigen_value: representation.EigenValue = field_arg(init=False)
+    beating_length: representation.BeatingLength = field_arg(init=False)
+
+    def __post_init__(self):
+        self.ID = [self.solver_number, self.binding_number]
+        self.field = representation.Field(parent_supermode=self)
+        self.index = representation.Index(parent_supermode=self)
+        self.beta = representation.Beta(parent_supermode=self)
+        self.normalized_coupling = representation.NormalizedCoupling(parent_supermode=self)
+        self.adiabatic = representation.Adiabatic(parent_supermode=self)
+        self.eigen_value = representation.EigenValue(parent_supermode=self)
+        self.beating_length = representation.BeatingLength(parent_supermode=self)
+
+    def __hash__(self):
+        """
+        Returns a hash based on the binded supermode object, allowing this class
+        instance to be used in hash-based collections like sets and dictionaries.
+
+        Returns:
+            int: The hash value of the binded supermode object.
+        """
+        return hash(self.binded_supermode)
+
+    @property
+    def binding_number(self) -> int:
+        """Retrieves the binding number specific to the linked C++ solver."""
+        return self.binded_supermode.binding_number
+
+    @property
+    def geometry(self) -> object:
+        """
+        Provides access to the geometric configuration associated with the supermode.
+
+        Returns:
+            object: The geometry of the parent SuperSet.
+        """
+        return self.parent_set.geometry
+
+    @property
+    def coordinate_system(self) -> object:
+        """
+        Accesses the coordinate system used by the supermode.
+
+        Returns:
+            object: The coordinate system of the parent SuperSet.
+        """
+        return self.parent_set.coordinate_system
+
+    @property
+    def itr_list(self) -> numpy.ndarray:
+        """Provides a list of iteration parameters from the model."""
+        return self.binded_supermode.model_parameters.itr_list
+
+    @property
+    def model_parameters(self) -> ModelParameters:
+        """
+        Retrieves parameters defining the model's computational aspects.
+
+        Returns:
+            ModelParameters: Computational parameters from the binded supermode.
+        """
+        return self.binded_supermode.model_parameters
+
+    @property
+    def mesh_gradient(self) -> numpy.ndarray:
+        """Accesses the gradient mesh associated with the supermode."""
+        return self.binded_supermode.mesh_gradient
+
+    @property
+    def amplitudes(self) -> numpy.ndarray:
+        """
+        Computes the amplitude array for this supermode, setting its own mode number
+        to 1 and all others to 0.
+
+        Returns:
+            numpy.ndarray: Array of complex numbers representing amplitudes.
+        """
+        n_mode = len(self.parent_set.supermodes)
+        amplitudes = numpy.zeros(n_mode, dtype=complex)
+        amplitudes[self.mode_number] = 1
+        return amplitudes
+
+    @property
+    def stylized_label(self) -> str:
+        """
+        Provides a stylized label for the supermode. If no custom label is provided,
+        it defaults to a generic label with the mode ID.
+
+        Returns:
+            str: The stylized or default label.
+        """
+        if self.label is None:
+            return f"Mode: {self.ID}"
+        else:
+            return f"${self.label}$"
+
+    def is_computation_compatible(self, other: Self) -> bool:
+        """
+        Determines if another supermode is compatible for computation, based on unique
+        identifiers and boundary conditions.
+
+        Parameters:
+            other (SuperMode): The other supermode to compare.
+
+        Returns:
+            bool: True if the supermodes are compatible for computation, False otherwise.
+        """
+        return self.binded_supermode.is_computation_compatible(other.binded_supermode)
+
+    def is_symmetry_compatible(self, other: Self) -> bool:
+        """
+        Determines whether the specified other supermode has same symmetry.
+
+        :param      other:  The other supermode
+        :type       other:  SuperMode
+
+        :returns:   True if the specified other is symmetry compatible, False otherwise.
+        :rtype:     bool
+        """
+        return self.boundaries == other.boundaries
+
+    def get_field_interpolation(self, itr: float = None, slice_number: int = None) -> RectBivariateSpline:
+        """
+        Computes the field interpolation for a given iteration or slice number. Requires
+        exactly one of the parameters to be specified.
+
+        Parameters:
+            itr (float, optional): The iteration number for which to compute the interpolation.
+            slice_number (int, optional): The slice number for which to compute the interpolation.
+
+        Returns:
+            RectBivariateSpline: Interpolated field values over a grid.
+
+        Raises:
+            ValueError: If neither or both parameters are specified.
+        """
+        if (itr is None) == (slice_number is None):
+            raise ValueError("Exactly one of itr or slice_number must be provided.")
+
+        if slice_number is None:
+            slice_number = self.parent_set.itr_to_slice(itr_list=itr)
+
+        if itr is None:
+            slice_number, itr = interpret_slice_number_and_itr(
+                itr_baseline=self.itr_list,
+                slice_list=slice_number
+            )
+
+        field = self.field.get_field(slice_number=slice_number, add_symmetries=True)
+
+        x_axis, y_axis = self.get_axis(slice_number=slice_number, add_symmetries=True)
+
+        field_interpolation = RectBivariateSpline(
+            x=x_axis * itr,
+            y=y_axis * itr,
+            z=field,
+        )
+
+        return field_interpolation
+
+    def _get_axis_vector(self, add_symmetries: bool = True) -> tuple:
+        full_x_axis = self.coordinate_system.x_vector
+        full_y_axis = self.coordinate_system.y_vector
+
+        if not add_symmetries:
+            return full_x_axis, full_y_axis
+
+        if self.boundaries.right in ['symmetric', 'anti-symmetric']:
+            full_x_axis = get_symmetrized_vector(full_x_axis, symmetry_type='last')
+            full_x_axis.sort()
+
+        if self.boundaries.left in ['symmetric', 'anti-symmetric']:
+            full_x_axis = get_symmetrized_vector(full_x_axis, symmetry_type='first')
+            full_x_axis.sort()
+
+        if self.boundaries.top in ['symmetric', 'anti-symmetric']:
+            full_y_axis = get_symmetrized_vector(full_y_axis, symmetry_type='last')
+            full_y_axis.sort()
+
+        if self.boundaries.bottom in ['symmetric', 'anti-symmetric']:
+            full_y_axis = get_symmetrized_vector(full_y_axis, symmetry_type='first')
+            full_y_axis.sort()
+
+        return full_x_axis, full_y_axis
+
+    def get_axis(self, slice_number: int, add_symmetries: bool = True) -> tuple:
+        itr = self.model_parameters.itr_list[slice_number]
+
+        x_axis, y_axis = self._get_axis_vector(add_symmetries=add_symmetries)
+
+        return (x_axis * itr, y_axis * itr)
+
+    def __repr__(self) -> str:
+        return self.label
+
+    def plot(self, plot_type: str, **kwargs):
+        """
+        Plots various properties of the supermode based on specified type.
+
+        Parameters:
+            plot_type (str): The type of plot to generate (e.g., 'field', 'beta').
+            *args: Additional positional arguments for the plot function.
+            **kwargs: Additional keyword arguments for the plot function.
+
+        Returns:
+            The result of the plotting function, typically a plot object.
+
+        Raises:
+            ValueError: If an invalid plot type is specified.
+        """
+        match plot_type.lower():
+            case 'field':
+                return self.field.plot(**kwargs)
+            case 'beta':
+                return self.beta.plot(**kwargs)
+            case 'index':
+                return self.index.plot(**kwargs)
+            case 'eigen-value':
+                return self.eigen_value.plot(**kwargs)
+            case 'beating-length':
+                return self.beating_length.plot(**kwargs)
+            case 'adiabatic':
+                return self.adiabatic.plot(**kwargs)
+            case 'normalized-coupling':
+                return self.normalized_coupling.plot(**kwargs)
+            case _:
+                raise ValueError(f'Invalid plot type: {plot_type}. Options are: index, beta, eigen-value, field, beating-length, adiabatic, normalized-coupling')
+
+
+# -
```

## SuPyMode/superset.py

```diff
@@ -1,1080 +1,1053 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-# Built-in imports
-import pickle
-import numpy
-import logging
-from dataclasses import dataclass
-from pathlib import Path
-from itertools import combinations, product
-from pathvalidate import sanitize_filepath
-from typing import Optional, Tuple, List, Callable
-
-# Third-party imports
-from scipy.interpolate import interp1d
-from scipy.integrate import solve_ivp
-import pyvista
-
-# Local imports
-from SuPyMode.supermode import SuperMode
-from SuPyMode import representation
-from SuPyMode.utils import test_valid_input, get_intersection, interpret_slice_number_and_itr, interpret_mode_of_interest
-from SuPyMode.profiles import AlphaProfile
-from SuPyMode import directories
-from MPSPlots.render2D import SceneMatrix, SceneList, Axis, Multipage
-
-
-@dataclass
-class SuperSet(object):
-    """
-    A class representing a set of supermodes calculated for a specific optical fiber configuration.
-    It facilitates operations on supermodes like sorting, plotting, and computations related to fiber optics simulations.
-
-    Attributes:
-        parent_solver (object): The solver instance that generated this SuperSet.
-        wavelength (float): The wavelength used in the solver, in meters.
-    """
-    parent_solver: object
-    wavelength: float
-
-    def __post_init__(self):
-        self.wavenumber = 2 * numpy.pi / self.wavelength
-        self._transmission_matrix = None
-        self.supermodes = []
-        self._itr_to_slice = interp1d(self.itr_list, numpy.arange(self.itr_list.size))
-
-    def __getitem__(self, idx: int) -> SuperMode:
-        return self.supermodes[idx]
-
-    def __setitem__(self, idx: int, value: SuperMode) -> None:
-        self.supermodes[idx] = value
-
-    @property
-    def geometry(self):
-        """
-        Return geometry of the coupler structure
-        """
-        return self.parent_solver.geometry
-
-    @property
-    def itr_list(self) -> numpy.ndarray:
-        """
-        Return list of itr value that are used to compute the supermodes
-        """
-        return self.parent_solver.itr_list
-
-    @property
-    def coordinate_system(self):
-        """
-        Return axes object of the geometry
-        """
-        return self.parent_solver.geometry.coordinate_system
-
-    @property
-    def fundamental_supermodes(self) -> list[SuperMode]:
-        """
-        Identifies and returns fundamental supermodes based on the highest beta values and minimal spatial overlap.
-
-        Args:
-            tolerance (float): The spatial overlap tolerance for mode distinction.
-
-        Returns:
-            list[SuperMode]: A list of fundamental supermodes.
-        """
-        return self.get_fundamental_supermodes(tolerance=1e-2)
-
-    @property
-    def non_fundamental_supermodes(self) -> list[SuperMode]:
-        """
-        Identifies and returns non-fundamental supermodes based on the specified spatial overlap tolerance.
-
-        Args:
-            tolerance (float): The spatial overlap tolerance for distinguishing between fundamental and other modes.
-
-        Returns:
-            list[SuperMode]: A list of non-fundamental supermodes.
-        """
-        return self.get_non_fundamental_supermodes(tolerance=1e-2)
-
-    @property
-    def transmission_matrix(self) -> numpy.ndarray:
-        """
-        Return supermode transfert matrix
-        """
-        if self._transmission_matrix is None:
-            self.compute_transmission_matrix()
-
-        return self._transmission_matrix
-
-    def itr_to_slice(self, itr_list: list[float]) -> list[int]:
-        """
-        Return slice number associated to itr value
-
-        :param      itr_list:      Inverse taper ration value to evaluate the slice.
-        :type       itr_list:      list[float]
-
-        :returns:   List of itr values,
-        :rtype:     list[int]
-        """
-        itr_list = numpy.asarray(itr_list)
-
-        return numpy.floor(self._itr_to_slice(itr_list)).astype(int)
-
-    def get_fundamental_supermodes(self, *, tolerance: float = 0.1) -> list[SuperMode]:
-        """
-        Returns list of modes that do not spatially overlap and that have the highest
-        propagation constant values.
-
-        :param      tolerance:  The tolerance to which consider the spatial overlap
-        :type       tolerance:  float
-
-        :returns:   List of the fundamental modes.
-        :rtype:     list[SuperMode]
-        """
-        self.sort_modes_by_beta()
-
-        fundamental_supermodes = [self.supermodes[0]]
-
-        def absolute_overlap(mode_0: SuperMode, mode_1: SuperMode) -> float:
-            field_0 = numpy.abs(mode_0.field.data[0])
-            norm_0 = field_0.sum()
-            field_0 /= numpy.sqrt(norm_0)
-
-            field_1 = numpy.abs(mode_1.field.data[0])
-            norm_1 = field_1.sum()
-            field_1 /= numpy.sqrt(norm_1)
-
-            overlap = numpy.sum(field_0 * field_1)
-
-            return overlap
-
-        for mode_0 in self.supermodes:
-            abs_overlap = [
-                absolute_overlap(mode_0, mode_1) for mode_1 in fundamental_supermodes
-            ]
-
-            abs_overlaps = numpy.asarray(abs_overlap)
-
-            if numpy.any(abs_overlaps > tolerance):
-                continue
-
-            fundamental_supermodes.append(mode_0)
-
-        return fundamental_supermodes
-
-    def get_non_fundamental_supermodes(self, *, tolerance: float = 0.1) -> list[SuperMode]:
-        """
-        Returns list of modes that do not spatially don't overlap with the fundamental modes.
-        Those mode are usually related to higher-order or cladding supermodes.
-
-        :param      tolerance:  The tolerance to which consider the spatial overlap
-        :type       tolerance:  float
-
-        :returns:   List of the non-fundamental modes.
-        :rtype:     list
-        """
-        non_fundamental_supermodes = self.supermodes
-
-        for supermodes in self.get_fundamental_supermodes(tolerance=tolerance):
-            non_fundamental_supermodes.remove(supermodes)
-
-        return non_fundamental_supermodes
-
-    def get_mode_solver_classification(self) -> list[list[SuperMode]]:
-        """
-        Returns a list containing the modes ordered per solver number.
-
-        :returns:   The mode solver classification.
-        :rtype:     list[list[SuperMode]]
-        """
-        solver_numbers = [mode.solver_number for mode in self]
-
-        number_of_solvers = len(set(solver_numbers))
-
-        mode_solver_array = [
-            [] for i in range(number_of_solvers)
-        ]
-
-        for mode in self:
-            mode_solver_array[mode.solver_number].append(mode)
-
-        return mode_solver_array
-
-    def label_supermodes(self, *label_list) -> None:
-        for n, label in enumerate(label_list):
-            self[n].label = label
-
-            setattr(self, label, self[n])
-
-    def reset_labels(self) -> None:
-        for n, super_mode in self:
-            super_mode.label = f'mode_{n}'
-
-    def swap_supermode_order(self, idx0: int, idx1: int) -> "SuperSet":
-        """
-        Swap two supermodes.
-        it doesn't change any of their characteristic, it only changes the
-        order on whihc they will appear, notably for the plots.
-
-        :param      idx0:            Index of the first mode to swap
-        :type       idx0:            int
-        :param      idx1:            Index of the second mode to swap
-        :type       idx1:            int
-        """
-        self.supermodes[idx0], self.supermodes[idx1] = self.supermodes[idx1], self.supermodes[idx0]
-
-        return self
-
-    def compute_transmission_matrix(self) -> None:
-        """
-        Calculates the transmission matrix with only the propagation constant included.
-
-        :returns:   The transmission matrix.
-        :rtype:     numpy.ndarray
-        """
-        shape = [
-            len(self.supermodes),
-            len(self.supermodes),
-            len(self.itr_list)
-        ]
-
-        self._transmission_matrix = numpy.zeros(shape)
-
-        for mode in self.supermodes:
-            self._transmission_matrix[mode.mode_number, mode.mode_number, :] = mode.beta.data * 2.0 * numpy.pi
-
-    def add_coupling_to_t_matrix(self, *, t_matrix: numpy.ndarray, adiabatic_factor: numpy.ndarray) -> numpy.ndarray:
-        """
-        Add the coupling coefficients to the transmission matrix.
-
-        :param      t_matrix:          The t matrix to which add the coupling values
-        :type       t_matrix:          numpy.ndarray
-        :param      adiabatic_factor:  The adiabatic factor, if None, it is set to one meaning normalized coupling [z-independent]
-        :type       adiabatic_factor:  numpy.ndarray
-
-        :returns:   The transmission matrix.
-        :rtype:     numpy.ndarray
-        """
-        size = t_matrix.shape[-1]
-
-        t_matrix = t_matrix.astype(complex)
-
-        for mode_0, mode_1 in combinations(self.supermodes, 2):
-
-            coupling = mode_0.normalized_coupling.get_values(mode_1)[:size]
-
-            coupling *= adiabatic_factor
-
-            t_matrix[mode_0.mode_number, mode_1.mode_number, :] = - coupling
-            t_matrix[mode_1.mode_number, mode_0.mode_number, :] = + coupling
-
-        if numpy.isnan(t_matrix).any():
-            raise ValueError('Nan values detected in transmission matrix.')
-        if numpy.isinf(t_matrix).any():
-            raise ValueError('Inf values detected in transmission matrix, verify that there is no hybrid mode in the computation.')
-
-        return t_matrix
-
-    def compute_coupling_factor(self, *, coupler_length: float) -> numpy.ndarray:
-        r"""
-        Compute the coupling factor defined as:
-
-        .. math::
-            f_c = \frac{1}{\rho} \frac{d \rho}{d z}
-
-        :param      coupler_length:     The length of the coupler
-        :type       coupler_length:     float
-
-        :returns:   The amplitudes as a function of the distance in the coupler
-        :rtype:     numpy.ndarray
-        """
-
-        dx = coupler_length / (self.itr_list.size)
-
-        ditr = numpy.gradient(numpy.log(self.itr_list), axis=0)
-
-        return ditr / dx
-
-    def get_transmision_matrix_from_profile(self, *, profile: AlphaProfile, add_coupling: bool = True) -> tuple:
-        """
-        Gets the transmision matrix from profile.
-
-        :param      profile:          The z-profile of the coupler
-        :type       profile:          object
-        :param      add_coupling:     Add coupling to the transmission matrix
-        :type       add_coupling:     bool
-        """
-        profile.initialize()
-
-        final_slice = self.itr_to_slice(itr_list=profile.smallest_itr)
-
-        sub_t_matrix = self.transmission_matrix[..., :final_slice]
-
-        sub_itr_vector = self.itr_list[: final_slice]
-
-        if add_coupling:
-            sub_t_matrix = self.add_coupling_to_t_matrix(
-                t_matrix=sub_t_matrix,
-                adiabatic_factor=profile.evaluate_adiabatic_factor(itr=sub_itr_vector)
-            )
-
-        sub_distance = profile.evaluate_distance_vs_itr(sub_itr_vector)
-
-        return sub_distance, sub_itr_vector, sub_t_matrix
-
-    def propagate(
-            self, *,
-            profile: AlphaProfile,
-            initial_amplitude: list,
-            max_step: Optional[float] = None,
-            n_step: Optional[int] = None,
-            add_coupling: bool = True,
-            method: str = 'RK45',
-            **kwargs: dict) -> Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]:
-        """
-        Propagates the amplitudes of the supermodes in a coupler based on a given profile.
-
-        Args:
-            profile (AlphaProfile): The z-profile of the coupler.
-            initial_amplitude (list): The initial amplitude as a list.
-            max_step (float, optional): The maximum step size used by the solver. Defaults to None.
-            n_step (int, optional): Number of steps used by the solver (not currently used in this method).
-            add_coupling (bool): Flag to add coupling to the transmission matrix. Defaults to True.
-            method (str): Integration method to be used by the solver. Defaults to 'RK45'.
-            **kwargs (Dict[str, Any]): Additional keyword arguments to be passed to the solver.
-
-        Returns:
-            Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]: A tuple containing the times of the solution,
-                                                       the solution array of amplitudes, and the interpolated
-                                                       index of refraction at those times.
-        """
-        initial_amplitude = numpy.asarray(initial_amplitude, dtype=complex)
-
-        if max_step is None:
-            max_step = self.parent_solver.wavelength / 200
-
-        sub_distance, sub_itr_vector, sub_t_matrix = self.get_transmision_matrix_from_profile(
-            profile=profile,
-            add_coupling=add_coupling
-        )
-
-        z_to_itr = interp1d(profile.distance, profile.itr_list, bounds_error=False, fill_value='extrapolate')
-        itr_to_t_matrix = interp1d(sub_itr_vector, sub_t_matrix, bounds_error=False, fill_value='extrapolate')
-
-        def model(z, y):
-            itr = z_to_itr(z)
-            return 1j * itr_to_t_matrix(itr) @ y
-
-        sol = solve_ivp(
-            fun=model,
-            y0=initial_amplitude,
-            t_span=[0, profile.total_length],
-            method=method,
-            vectorized=True,
-            max_step=max_step,
-            **kwargs
-        )
-
-        # Check power conservation across the propagation
-        norm = numpy.sum(numpy.abs(sol.y)**2, axis=0)
-        if not numpy.allclose(norm, 1.0, atol=1e-1):
-            logging.warning(f'Power conservation not achieved [{max_step = }, atol = 1e-1].')
-
-        return sol.t, sol.y, z_to_itr(sol.t)
-
-    def interpret_initial_input(self, initial_amplitude: list | SuperMode) -> numpy.ndarray:
-        """
-        Interprets the initial amplitude input, ensuring compatibility with the expected number of supermodes.
-
-        Args:
-            initial_amplitude (list | SuperMode): The initial amplitude as either a list of complex numbers or a SuperMode object.
-
-        Returns:
-            numpy.ndarray: The initial amplitudes as a NumPy array of complex numbers.
-
-        Raises:
-            ValueError: If the length of the initial amplitude list does not match the number of supermodes.
-        """
-        if isinstance(initial_amplitude, SuperMode):
-            amplitudes = initial_amplitude.amplitudes
-        else:
-            amplitudes = initial_amplitude
-
-        amplitude_size = len(amplitudes)
-        number_of_supermodes = len(self.supermodes)
-
-        if amplitude_size != number_of_supermodes:
-            raise ValueError(f'Amplitudes size: {amplitude_size} does not match with the number of supermodes: {number_of_supermodes}')
-
-        return numpy.asarray(amplitudes, dtype=complex)
-
-    def plot_propagation(
-            self, *,
-            profile: AlphaProfile,
-            initial_amplitude,
-            max_step: Optional[float] = None,
-            add_coupling: bool = True,
-            method: str = 'RK45',
-            sub_sampling: int = 5,
-            show_energy: bool = True,
-            show_amplitudes: bool = True,
-            **kwargs: dict) -> Tuple[SceneList, Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]:
-        """
-        Plots the propagation of amplitudes over a given profile, showing energy and amplitude plots.
-
-        Args:
-            profile (AlphaProfile): The profile to propagate.
-            initial_amplitude: The initial amplitudes, either as a list or a SuperMode object.
-            max_step (Optional[float]): The maximum step size for the solver.
-            add_coupling (bool): Whether to add coupling in the transmission matrix.
-            method (str): Numerical method for solving the propagation.
-            sub_sampling (int): The factor for sub-sampling data for plotting.
-            show_energy (bool): Whether to plot the energy of the modes.
-            show_amplitudes (bool): Whether to plot the real part of the amplitudes.
-            **kwargs (Dict[str, Any]): Additional keyword arguments for solver.
-
-        Returns:
-            Tuple[SceneList, Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]: A tuple containing the matplotlib figure object
-                                                                          and a tuple with propagation distances, amplitudes,
-                                                                          and inverse taper ratios.
-        """
-        initial_amplitude = self.interpret_initial_input(initial_amplitude)
-
-        z, amplitudes, itr_list = self.propagate(
-            initial_amplitude=initial_amplitude,
-            profile=profile,
-            add_coupling=add_coupling,
-            max_step=max_step,
-            method=method,
-            **kwargs
-        )
-
-        figure = SceneList(unit_size=(12, 4))
-        ax = figure.append_ax(line_width=2, show_legend=True, x_label='Propagation distance z', y_label='Inverse taper ratio [ITR]')
-
-        for idx, mode in enumerate(self.supermodes):
-            color = f"C{idx}"
-            x_values = z[::sub_sampling]
-            y_energy = numpy.abs(amplitudes[idx, ::sub_sampling])**2
-            y_amplitude = amplitudes[idx, ::sub_sampling].real
-
-            if show_energy:
-                ax.add_line(x=x_values, y=y_energy, label=mode.stylized_label, line_width=2.0, line_style='-', color=color)
-            if show_amplitudes:
-                ax.add_line(x=x_values, y=y_amplitude, label=mode.stylized_label + ' Amplitude', line_width=2.0, line_style='--', color=color)
-
-        if show_energy:
-            total_energy = numpy.sqrt(numpy.sum(numpy.abs(amplitudes)**2, axis=0))[::sub_sampling]
-            ax.add_line(x=x_values, y=total_energy, label='Total energy', line_width=3.0, line_style='--', color='black')
-
-        return figure.fig, (z, amplitudes, itr_list)
-
-    def generate_propagation_gif(
-            self, *,
-            profile: AlphaProfile,
-            initial_amplitude,
-            max_step: float = None,
-            coupling: str = 'normalized',
-            method: str = 'RK45',
-            sub_sampling: int = 5,
-            mutliplicative_factor: float = 1,
-            save_directory: str = 'new_figure.gif',
-            delta_azimuth: float = 0,
-            **kwargs) -> tuple:
-        """
-        Generates a gif video of the mode propagation.
-
-        :param      initial_amplitude:  The initial amplitude
-        :type       initial_amplitude:  list
-        :param      coupler_length:     The length of the coupler
-        :type       coupler_length:     float
-        :param      max_step:           The maximum stride to use in the solver
-        :type       max_step:           float
-        :param      sub_sampling:       Propagation undersampling factor for the video production
-        :type       sub_sampling:       int
-        :param      kwargs:             The keywords arguments
-        :type       kwargs:             dictionary
-        """
-
-        initial_amplitude = self.interpret_initial_input(
-            initial_amplitude=initial_amplitude
-        )
-
-        z_list, amplitudes_list, itr_list = self.propagate(
-            initial_amplitude=initial_amplitude,
-            profile=profile,
-            coupling=coupling,
-            max_step=max_step,
-            method=method
-        )
-
-        self.generate_propagation_gif_from_values(
-            amplitudes_list=amplitudes_list,
-            itr_list=itr_list,
-            z_list=z_list,
-            mutliplicative_factor=mutliplicative_factor,
-            save_directory=save_directory,
-            delta_azimuth=delta_azimuth,
-            sub_sampling=sub_sampling
-        )
-
-        return z_list, amplitudes_list, itr_list
-
-    def generate_propagation_gif_from_values(
-            self, *,
-            amplitudes_list: numpy.ndarray,
-            itr_list: numpy.ndarray,
-            z_list: numpy.ndarray,
-            sub_sampling: int = 10000,
-            mutliplicative_factor: float = -100,
-            delta_azimuth: float = 0,
-            save_directory: str = 'new_figure.gif',
-            colormap: str = 'bwr',
-            **kwargs) -> None:
-        """
-        Generates a gif video of the mode propagation.
-
-        :param      initial_amplitude:  The initial amplitude
-        :type       initial_amplitude:  list
-        :param      coupler_length:     The length of the coupler
-        :type       coupler_length:     float
-        :param      max_step:           The maximum stride to use in the solver
-        :type       max_step:           float
-        :param      sub_sampling:       Propagation undersampling factor for the video production
-        :type       sub_sampling:       int
-        :param      kwargs:             The keywords arguments
-        :type       kwargs:             dictionary
-        """
-        amplitudes_list = amplitudes_list[:, ::sub_sampling]
-        itr_list = itr_list[::sub_sampling]
-        z_list = z_list[::sub_sampling]
-
-        structure = self.get_slice_structure(itr=1.0, add_symmetries=True)
-        total_field = structure.get_field_combination(amplitudes_list[:, 0], Linf_normalization=True) * mutliplicative_factor
-
-        x, y = numpy.mgrid[0: total_field.shape[0], 0: total_field.shape[1]]
-        grid = pyvista.StructuredGrid(x, y, total_field)
-
-        plotter = pyvista.Plotter(notebook=False, off_screen=True)
-        plotter.open_gif(save_directory, fps=20)
-        plotter.view_isometric()
-        # plotter.set_background('black', top='white')
-
-        plotter.add_mesh(
-            grid,
-            scalars=total_field,
-            style='surface',
-            show_edges=True,
-            edge_color='k',
-            colormap=colormap,
-            show_scalar_bar=False,
-            clim=[-100, 100]
-        )
-
-        pts = grid.points.copy()
-        azimuth = 0
-        for z, amplitudes, itr in zip(z_list, amplitudes_list.T, itr_list):
-            print(f'itr: {itr}')
-            plotter.camera.elevation = -20
-            plotter.camera.azimuth = azimuth
-            azimuth += delta_azimuth
-
-            structure = self.get_slice_structure(itr=itr, add_symmetries=True)
-            total_field = structure.get_field_combination(amplitudes, Linf_normalization=True) * mutliplicative_factor
-
-            pts[:, -1] = total_field.T.ravel()
-            plotter.update_coordinates(pts, render=True)
-            plotter.update_scalars(total_field.T.ravel(), render=False)
-            plotter.add_title(f'ITR: {itr: .3f}\t  z: {z: .3e}', font='courier', color='w', font_size=20)
-
-            plotter.write_frame()
-
-        plotter.close()
-
-    def _sort_modes(self, *ordering_keys) -> List[SuperMode]:
-        """
-        Sorts supermodes using specified keys provided as tuples in ordering_keys.
-
-        Args:
-            ordering_keys (tuple): Tuple containing keys to sort by.
-
-        Returns:
-            List[SuperMode]: Sorted list of supermodes.
-        """
-        order = numpy.lexsort(ordering_keys)
-        sorted_supermodes = [self.supermodes[idx] for idx in order]
-        for i, supermode in enumerate(sorted_supermodes):
-            supermode.mode_number = i
-        return sorted_supermodes
-
-    def sort_modes_by_beta(self) -> None:
-        """
-        Sorts supermodes in descending order of their propagation constants (beta).
-        """
-        self.all_supermodes = self._sort_modes([-mode.beta.data[-1] for mode in self.supermodes])
-
-    def sort_modes(self, sorting_method: str = "beta", keep_only: Optional[int] = None) -> None:
-        """
-        Sorts supermodes according to the specified method, optionally limiting the number of modes retained.
-
-        Args:
-            sorting_method (str): Sorting method to use, either "beta" or "symmetry+beta".
-            keep_only (int, optional): Number of supermodes to retain after sorting.
-
-        Raises:
-            ValueError: If an unrecognized sorting method is provided.
-        """
-        match sorting_method.lower():
-            case 'beta':
-                self.sort_modes_by_beta()
-            case 'symmetry+beta':
-                self.sort_modes_by_solver_and_beta()
-            case _:
-                raise ValueError(f"Unrecognized sorting method: {sorting_method}, accepted values are ['beta', 'symmetry+beta']")
-
-        self.supermodes = self.all_supermodes[:keep_only] if keep_only is not None else self.all_supermodes
-
-    def sort_modes_by_solver_and_beta(self) -> None:
-        """
-        Sorts supermodes primarily by solver number and secondarily by descending propagation constant (beta).
-        """
-        self.all_supermodes = self._sort_modes(
-            ([mode.solver_number for mode in self.supermodes],
-             [-mode.beta[-1] for mode in self.supermodes])
-        )
-
-    @staticmethod
-    def single_plot(plot_function) -> Callable:
-        def wrapper(self, *args, mode_of_interest='all', **kwargs):
-            mode_of_interest = interpret_mode_of_interest(
-                superset=self,
-                mode_of_interest=mode_of_interest
-            )
-
-            figure = SceneList(unit_size=(16, 6), ax_orientation='vertical')
-
-            ax = figure.append_ax()
-
-            plot_function(self, ax=ax, *args, mode_of_interest=mode_of_interest, **kwargs)
-
-            return figure
-
-        return wrapper
-
-    @staticmethod
-    def combination_plot(plot_function) -> Callable:
-        def wrapper(self, *args, mode_of_interest='all', mode_selection: str = 'pairs', **kwargs):
-            mode_of_interest = interpret_mode_of_interest(
-                superset=self,
-                mode_of_interest=mode_of_interest
-            )
-
-            combination = self.interpret_mode_selection(
-                mode_of_interest=mode_of_interest,
-                mode_selection=mode_selection
-            )
-
-            figure = SceneList(unit_size=(16, 6), ax_orientation='vertical')
-
-            ax = figure.append_ax()
-
-            plot_function(self, ax=ax, *args, mode_of_interest=mode_of_interest, combination=combination, **kwargs)
-
-            return figure
-
-        return wrapper
-
-    @single_plot
-    def plot_index(
-            self,
-            ax: Axis,
-            show_crossings: bool = False,
-            mode_of_interest: str | list[SuperMode] = 'all') -> SceneList:
-        """
-        Plot effective index for each mode as a function of itr
-
-        :param      mode_of_interest:  The mode of interest
-        :type       mode_of_interest:  str
-        :param      artist_kwargs:     The keywords arguments
-        :type       artist_kwargs:     dictionary
-
-        :returns:   figure instance, to plot the show() method.
-        :rtype:     SceneList
-        """
-        ax.set_style(**representation.index.Index.plot_style)
-
-        for mode in mode_of_interest:
-            mode.index.render_on_ax(ax=ax)
-
-        if show_crossings:
-            self.add_crossings_to_ax(ax=ax, mode_of_interest=mode_of_interest, data_type='index')
-
-    @single_plot
-    def plot_beta(
-            self,
-            ax: Axis,
-            show_crossings: bool = False,
-            mode_of_interest: str | list[SuperMode] = 'all') -> SceneList:
-        """
-        Plot propagation constant for each mode as a function of itr
-
-        :param      mode_of_interest:  The mode of interest
-        :type       mode_of_interest:  str
-        :param      artist_kwargs:     The keywords arguments
-        :type       artist_kwargs:     dictionary
-
-        :returns:   figure instance, to plot the show() method.
-        :rtype:     SceneList
-        """
-        ax.set_style(**representation.beta.Beta.plot_style)
-
-        for mode in mode_of_interest:
-            mode.beta.render_on_ax(ax=ax)
-
-        if show_crossings:
-            self.add_crossings_to_ax(ax=ax, mode_of_interest=mode_of_interest, data_type='beta')
-
-    @single_plot
-    def plot_eigen_value(
-            self,
-            ax: Axis,
-            mode_of_interest: str | list[SuperMode] = 'all',
-            show_crossings: bool = False) -> SceneList:
-        """
-        Plot propagation constant for each mode as a function of itr
-
-        :param      mode_of_interest:  The mode of interest
-        :type       mode_of_interest:  str
-        :param      artist_kwargs:     The keywords arguments
-        :type       artist_kwargs:     dictionary
-
-        :returns:   figure instance, to plot the show() method.
-        :rtype:     SceneList
-        """
-        ax.set_style(**representation.eigen_value.EigenValue.plot_style)
-
-        for mode in mode_of_interest:
-            mode.index.render_on_ax(ax=ax)
-
-        if show_crossings:
-            self.add_crossings_to_ax(ax=ax, mode_of_interest=mode_of_interest, data_type='eigen_value')
-
-    @combination_plot
-    def plot_normalized_coupling(
-            self,
-            ax: Axis,
-            mode_of_interest: list[SuperMode],
-            combination: list) -> SceneList:
-        """
-        Plot normalized coupling value for each mode as a function of itr.
-
-        :param      mode_of_interest:  The mode of interest
-        :type       mode_of_interest:  str
-        :param      mode_selection:    The mode selection
-        :type       mode_selection:    str
-        :param      artist_kwargs:     The keywords arguments
-        :type       artist_kwargs:     dictionary
-
-        :returns:   figure instance, to plot the show() method.
-        :rtype:     SceneList
-        """
-        ax.set_style(**representation.normalized_coupling.NormalizedCoupling.plot_style)
-
-        for mode_0, mode_1 in combination:
-            mode_0.normalized_coupling.render_on_ax(ax=ax, other_supermode=mode_1)
-
-    @combination_plot
-    def plot_beating_length(
-            self,
-            ax: Axis,
-            mode_of_interest: list[SuperMode],
-            combination: list) -> SceneList:
-        """
-        Plot coupling value for each mode as a function of itr
-
-        :param      mode_of_interest:  List of the mode that are to be considered in the adiabatic criterion plotting.
-        :type       mode_of_interest:  list
-
-        :returns:   figure instance, to plot the show() method.
-        :rtype:     SceneList
-        """
-        for mode_0, mode_1 in combination:
-            ax.set_style(**mode_0.beating_length.BeatingLength.plot_style)
-            mode_0.beating_length.render_on_ax(ax=ax, other_supermode=mode_1)
-
-    @combination_plot
-    def plot_adiabatic(
-            self,
-            ax: Axis,
-            mode_of_interest: list[SuperMode],
-            combination: list,
-            add_profile: list[AlphaProfile] = []) -> SceneList:
-        """
-        Plot adiabatic criterion for each mode as a function of itr
-
-        :param      pair_of_interest:  List of the mode that are to be considered in the adiabatic criterion plotting.
-        :type       pair_of_interest:  list
-        :param      mode_selection:    The type of combination to be plotted, either 'specific/all/pairs'
-        :type       mode_selection:    str
-        :param      artist_kwargs:     The keywords arguments
-        :type       artist_kwargs:     dictionary
-
-        :returns:   figure instance, to plot the show() method.
-        :rtype:     SceneList
-        """
-        ax.set_style(**representation.adiabatic.Adiabatic.plot_style)
-        for mode_0, mode_1 in combination:
-            mode_0.adiabatic.render_on_ax(ax=ax, other_supermode=mode_1)
-
-        for profile in numpy.atleast_1d(add_profile):
-            profile.render_adiabatic_factor_vs_itr_on_ax(ax=ax, line_style='--')
-
-    def is_compute_compatible(self, pair_of_mode: tuple) -> bool:
-        """
-        Determines whether the specified pair of mode is compatible for computation.
-
-        :param      pair_of_mode:  The pair of mode
-        :type       pair_of_mode:  tuple
-
-        :returns:   True if the specified pair of mode is compute compatible, False otherwise.
-        :rtype:     bool
-        """
-        mode_0, mode_1 = pair_of_mode
-        return mode_0.is_computation_compatible(mode_1)
-
-    def remove_duplicate_combination(self, supermodes_list: list) -> list[SuperMode]:
-        """
-        Removes a duplicate combination in the mode combination list irrespectively of the order.
-
-        :param      supermodes_list:  The supermodes list
-        :type       supermodes_list:  list
-
-        :returns:   The reduced supermode list
-        :rtype:     list
-        """
-        output_list = []
-
-        for mode0, mode1 in supermodes_list:
-            if (mode0, mode1) not in output_list and (mode1, mode0) not in output_list:
-                output_list.append((mode0, mode1))
-
-        return output_list
-
-    def interpret_mode_selection(self, mode_of_interest: list, mode_selection: str) -> set:
-        """
-        Interpret user input for mode selection and return the combination of mode to consider.
-
-        :param      mode_of_interest:  The mode of interest
-        :type       mode_of_interest:  list
-        :param      mode_selection:    The mode selection
-        :type       mode_selection:    str
-        """
-        test_valid_input(
-            variable_name='mode_selection',
-            user_input=mode_selection,
-            valid_inputs=['pairs', 'specific']
-        )
-
-        match mode_selection:
-            case 'pairs':
-                mode_combinations = product(mode_of_interest, mode_of_interest)
-            case 'specific':
-                mode_combinations = product(mode_of_interest, self.supermodes)
-
-        mode_combinations = filter(self.is_compute_compatible, mode_combinations)
-
-        mode_combinations = self.remove_duplicate_combination(mode_combinations)
-
-        return set(mode_combinations)
-
-    def plot_field(
-            self,
-            mode_of_interest: list = 'all',
-            itr_list: list[float] = None,
-            slice_list: list[int] = None,
-            show_mode_label: bool = True,
-            show_itr: bool = True,
-            show_slice: bool = True) -> SceneList:
-        """
-        Plot each of the mode field for different itr value or slice number.
-
-        :param      itr_list:    List of itr value to evaluate the mode field
-        :type       itr_list:    list
-        :param      slice_list:  List of integer reprenting the slice where the mode field is evaluated
-        :type       slice_list:  list
-
-        :returns:   The figure
-        :rtype:     SceneMatrix
-        """
-        figure = SceneMatrix(unit_size=(3, 3))
-
-        slice_list, itr_list = interpret_slice_number_and_itr(
-            itr_baseline=self.itr_list,
-            itr_list=itr_list,
-            slice_list=slice_list
-        )
-
-        mode_of_interest = interpret_mode_of_interest(
-            superset=self,
-            mode_of_interest=mode_of_interest
-        )
-
-        for m, mode in enumerate(mode_of_interest):
-            for n, slice_number in enumerate(slice_list):
-                ax = figure.append_ax(row=n, column=m)
-
-                ax.set_style(**representation.field.Field.plot_style)
-
-                mode.field.render_on_ax(
-                    ax=ax,
-                    slice_number=slice_number,
-                    show_mode_label=show_mode_label,
-                    show_itr=show_itr,
-                    show_slice=show_slice
-                )
-
-        return figure
-
-    def plot(self, plot_type: str, **kwargs) -> SceneList:
-        """
-        General plotting function to handle different types of supermode plots.
-
-        Args:
-            plot_type (str): The type of plot to generate. Options include 'index', 'beta', 'eigen-value', etc.
-            **kwargs: Additional keyword arguments for specific plot configurations.
-
-        Returns:
-            SceneList: The generated plot as a SceneList object.
-
-        Raises:
-            ValueError: If an unrecognized plot type is specified.
-        """
-        match plot_type.lower():
-            case 'index':
-                return self.plot_index(**kwargs)
-            case 'beta':
-                return self.plot_beta(**kwargs)
-            case 'eigen-value':
-                return self.plot_eigen_value(**kwargs)
-            case 'normalized-coupling':
-                return self.plot_normalized_coupling(**kwargs)
-            case 'overlap':
-                return self.plot_overlap(**kwargs)
-            case 'adiabatic':
-                return self.plot_adiabatic(**kwargs)
-            case 'field':
-                return self.plot_field(**kwargs)
-            case 'beating-length':
-                return self.plot_beating_length(**kwargs)
-            case 'normalized-adiabatic':
-                return self.plot_normalized_adiabatic(**kwargs)
-            case _:
-                raise ValueError(f'Invalid plot type: {plot_type}. Options are: index, beta, eigen-value, adiabatic, normalized-adiabatic, normalized-coupling, field, beating-length')
-
-    def generate_pdf_report(
-            self,
-            filename: str = "report",
-            directory: str = '.',
-            itr_list: list[float] | None = None,
-            slice_list: list[int] | None = None,
-            dpi: int = 200,
-            mode_of_interest: list = 'all',
-            mode_selection: str = 'specific') -> None:
-        """
-        Generate a full report of the coupler properties as a .pdf file
-
-        :param      filename:          Name of the Report file to be outputed.
-        :type       filename:          str
-        :param      itr_list:          List of itr value to evaluate the mode field.
-        :type       itr_list:          Array
-        :param      slice_list:        List of slice value to evaluate the mode field.
-        :type       slice_list:        Array
-        :param      dpi:               Pixel density for the image included in the report.
-        :type       dpi:               int
-        :param      mode_of_interest:  List of the mode that are to be considered in the adiabatic criterion plotting.
-        :type       mode_of_interest:  list
-
-        :returns:   No return
-        :rtype:     None
-        """
-        if directory == 'auto':
-            directory = directories.reports_path
-
-        filename = Path(directory).joinpath(filename).with_suffix('.pdf')
-
-        logging.info(f"Saving report pdf into: {filename}")
-
-        figure_list = []
-
-        figure_list.append(self.geometry.plot()._render_())
-
-        figure_list.append(self.plot_field(itr_list=itr_list, slice_list=slice_list)._render_())
-
-        figure_list.append(self.plot_index()._render_())
-
-        figure_list.append(self.plot_beta()._render_())
-
-        figure_list.append(self.plot_normalized_coupling(mode_of_interest=mode_of_interest, mode_selection=mode_selection)._render_())
-
-        figure_list.append(self.plot_adiabatic(mode_of_interest=mode_of_interest, mode_selection=mode_selection)._render_())
-
-        Multipage(filename, figs=figure_list, dpi=dpi)
-
-        for figure in figure_list:
-            figure.close()
-
-    def save_instance(self, filename: str, directory: str = 'auto') -> Path:
-        """
-        Saves the superset instance as a serialized pickle file.
-
-        :param      filename:  The directory where to save the file, 'auto' options means the superset_instance folder
-        :type       filename:  str
-        :param      filename:  The filename
-        :type       filename:  str
-
-        :returns:   The path directory of the saved instance
-        :rtype:     Path
-        """
-        if directory == 'auto':
-            directory = directories.instance_directory
-
-        filename = Path(filename).with_suffix('.pickle')
-
-        filename = sanitize_filepath(filename)
-
-        filename = Path(directory).joinpath(filename)
-
-        logging.info(f"Saving pickled superset into: {filename}")
-
-        with open(filename, 'wb') as output_file:
-            pickle.dump(self, output_file, pickle.HIGHEST_PROTOCOL)
-
-        return filename
-
-    def add_crossings_to_ax(self, ax: Axis, mode_of_interest: list, data_type: str) -> None:
-        combination = self.interpret_mode_selection(
-            mode_of_interest=mode_of_interest,
-            mode_selection='pairs'
-        )
-
-        for mode_0, mode_1 in combination:
-            x, y = get_intersection(
-                x=self.itr_list,
-                y0=getattr(mode_0, data_type).data,
-                y1=getattr(mode_1, data_type).data,
-                average=True
-            )
-
-            if x is not None:
-                ax.add_scatter(
-                    x=x,
-                    y=y,
-                    marker='o',
-                    color='black',
-                    marker_size=20,
-                    label='mode crossing'
-                )
-
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+# Built-in imports
+import pickle
+import numpy
+import logging
+from dataclasses import dataclass
+from pathlib import Path
+from itertools import combinations, product
+from pathvalidate import sanitize_filepath
+from typing import Optional, Tuple, List, Callable
+from FiberFusing.geometry import Geometry
+
+# Third-party imports
+from scipy.interpolate import interp1d
+from scipy.integrate import solve_ivp
+import pyvista
+
+# Local imports
+from SuPyMode.binary.ModelParameters import ModelParameters
+from SuPyMode.supermode import SuperMode
+from SuPyMode import representation
+from SuPyMode.utils import test_valid_input, get_intersection, interpret_slice_number_and_itr, interpret_mode_of_interest
+from SuPyMode.profiles import AlphaProfile
+from SuPyMode import directories
+from MPSPlots.render2D import SceneMatrix, SceneList, Axis, Multipage
+
+
+@dataclass
+class SuperSet(object):
+    """
+    A class representing a set of supermodes calculated for a specific optical fiber configuration.
+    It facilitates operations on supermodes like sorting, plotting, and computations related to fiber optics simulations.
+
+    Attributes:
+        model_parameters (ModelParameters):
+        wavelength (float): The wavelength used in the solver, in meters.
+        geometry (object):
+    """
+    model_parameters: ModelParameters
+    wavelength: float
+    geometry: Geometry
+
+    def __post_init__(self):
+        self._transmission_matrix = None
+        self.supermodes = []
+        self._itr_to_slice = interp1d(self.model_parameters.itr_list, numpy.arange(self.model_parameters.n_slice))
+
+    def __getitem__(self, idx: int) -> SuperMode:
+        return self.supermodes[idx]
+
+    def __setitem__(self, idx: int, value: SuperMode) -> None:
+        self.supermodes[idx] = value
+
+    @property
+    def coordinate_system(self):
+        """
+        Return axes object of the geometry
+        """
+        return self.geometry.coordinate_system
+
+    @property
+    def fundamental_supermodes(self) -> list[SuperMode]:
+        """
+        Identifies and returns fundamental supermodes based on the highest beta values and minimal spatial overlap.
+
+        Args:
+            tolerance (float): The spatial overlap tolerance for mode distinction.
+
+        Returns:
+            list[SuperMode]: A list of fundamental supermodes.
+        """
+        return self.get_fundamental_supermodes(tolerance=1e-2)
+
+    @property
+    def non_fundamental_supermodes(self) -> list[SuperMode]:
+        """
+        Identifies and returns non-fundamental supermodes based on the specified spatial overlap tolerance.
+
+        Args:
+            tolerance (float): The spatial overlap tolerance for distinguishing between fundamental and other modes.
+
+        Returns:
+            list[SuperMode]: A list of non-fundamental supermodes.
+        """
+        return self.get_non_fundamental_supermodes(tolerance=1e-2)
+
+    @property
+    def transmission_matrix(self) -> numpy.ndarray:
+        """
+        Return supermode transfert matrix
+        """
+        if self._transmission_matrix is None:
+            self.compute_transmission_matrix()
+
+        return self._transmission_matrix
+
+    def itr_to_slice(self, itr_list: list[float]) -> list[int]:
+        """
+        Return slice number associated to itr value
+
+        :param      itr_list:      Inverse taper ration value to evaluate the slice.
+        :type       itr_list:      list[float]
+
+        :returns:   List of itr values,
+        :rtype:     list[int]
+        """
+        itr_list = numpy.asarray(itr_list)
+
+        return numpy.floor(self._itr_to_slice(itr_list)).astype(int)
+
+    def get_fundamental_supermodes(self, *, tolerance: float = 0.1) -> list[SuperMode]:
+        """
+        Returns list of modes that do not spatially overlap and that have the highest
+        propagation constant values.
+
+        :param      tolerance:  The tolerance to which consider the spatial overlap
+        :type       tolerance:  float
+
+        :returns:   List of the fundamental modes.
+        :rtype:     list[SuperMode]
+        """
+        self.sort_modes_by_beta()
+
+        fundamental_supermodes = [self.supermodes[0]]
+
+        def absolute_overlap(mode_0: SuperMode, mode_1: SuperMode) -> float:
+            field_0 = numpy.abs(mode_0.field.data[0])
+            norm_0 = field_0.sum()
+            field_0 /= numpy.sqrt(norm_0)
+
+            field_1 = numpy.abs(mode_1.field.data[0])
+            norm_1 = field_1.sum()
+            field_1 /= numpy.sqrt(norm_1)
+
+            overlap = numpy.sum(field_0 * field_1)
+
+            return overlap
+
+        for mode_0 in self.supermodes:
+            abs_overlap = [
+                absolute_overlap(mode_0, mode_1) for mode_1 in fundamental_supermodes
+            ]
+
+            abs_overlaps = numpy.asarray(abs_overlap)
+
+            if numpy.any(abs_overlaps > tolerance):
+                continue
+
+            fundamental_supermodes.append(mode_0)
+
+        return fundamental_supermodes
+
+    def get_non_fundamental_supermodes(self, *, tolerance: float = 0.1) -> list[SuperMode]:
+        """
+        Returns list of modes that do not spatially don't overlap with the fundamental modes.
+        Those mode are usually related to higher-order or cladding supermodes.
+
+        :param      tolerance:  The tolerance to which consider the spatial overlap
+        :type       tolerance:  float
+
+        :returns:   List of the non-fundamental modes.
+        :rtype:     list
+        """
+        non_fundamental_supermodes = self.supermodes
+
+        for supermodes in self.get_fundamental_supermodes(tolerance=tolerance):
+            non_fundamental_supermodes.remove(supermodes)
+
+        return non_fundamental_supermodes
+
+    def get_mode_solver_classification(self) -> list[list[SuperMode]]:
+        """
+        Returns a list containing the modes ordered per solver number.
+
+        :returns:   The mode solver classification.
+        :rtype:     list[list[SuperMode]]
+        """
+        solver_numbers = [mode.solver_number for mode in self]
+
+        number_of_solvers = len(set(solver_numbers))
+
+        mode_solver_array = [
+            [] for i in range(number_of_solvers)
+        ]
+
+        for mode in self:
+            mode_solver_array[mode.solver_number].append(mode)
+
+        return mode_solver_array
+
+    def label_supermodes(self, *label_list) -> None:
+        for n, label in enumerate(label_list):
+            self[n].label = label
+
+            setattr(self, label, self[n])
+
+    def reset_labels(self) -> None:
+        for n, super_mode in self:
+            super_mode.label = f'mode_{n}'
+
+    def compute_transmission_matrix(self) -> None:
+        """
+        Calculates the transmission matrix with only the propagation constant included.
+
+        :returns:   The transmission matrix.
+        :rtype:     numpy.ndarray
+        """
+        shape = [
+            len(self.supermodes),
+            len(self.supermodes),
+            len(self.model_parameters.itr_list)
+        ]
+
+        self._transmission_matrix = numpy.zeros(shape)
+
+        for mode in self.supermodes:
+            self._transmission_matrix[mode.mode_number, mode.mode_number, :] = mode.beta.data * 2.0 * numpy.pi
+
+    def add_coupling_to_t_matrix(self, *, t_matrix: numpy.ndarray, adiabatic_factor: numpy.ndarray) -> numpy.ndarray:
+        """
+        Add the coupling coefficients to the transmission matrix.
+
+        :param      t_matrix:          The t matrix to which add the coupling values
+        :type       t_matrix:          numpy.ndarray
+        :param      adiabatic_factor:  The adiabatic factor, if None, it is set to one meaning normalized coupling [z-independent]
+        :type       adiabatic_factor:  numpy.ndarray
+
+        :returns:   The transmission matrix.
+        :rtype:     numpy.ndarray
+        """
+        size = t_matrix.shape[-1]
+
+        t_matrix = t_matrix.astype(complex)
+
+        for mode_0, mode_1 in combinations(self.supermodes, 2):
+
+            coupling = mode_0.normalized_coupling.get_values(mode_1)[:size]
+
+            coupling *= adiabatic_factor
+
+            t_matrix[mode_0.mode_number, mode_1.mode_number, :] = - coupling
+            t_matrix[mode_1.mode_number, mode_0.mode_number, :] = + coupling
+
+        if numpy.isnan(t_matrix).any():
+            raise ValueError('Nan values detected in transmission matrix.')
+        if numpy.isinf(t_matrix).any():
+            raise ValueError('Inf values detected in transmission matrix, verify that there is no hybrid mode in the computation.')
+
+        return t_matrix
+
+    def compute_coupling_factor(self, *, coupler_length: float) -> numpy.ndarray:
+        r"""
+        Compute the coupling factor defined as:
+
+        .. math::
+            f_c = \frac{1}{\rho} \frac{d \rho}{d z}
+
+        :param      coupler_length:     The length of the coupler
+        :type       coupler_length:     float
+
+        :returns:   The amplitudes as a function of the distance in the coupler
+        :rtype:     numpy.ndarray
+        """
+
+        dx = coupler_length / (self.model_parameters.n_slice)
+
+        ditr = numpy.gradient(numpy.log(self.model_parameters.itr_list), axis=0)
+
+        return ditr / dx
+
+    def get_transmision_matrix_from_profile(self, *, profile: AlphaProfile, add_coupling: bool = True) -> tuple:
+        """
+        Gets the transmision matrix from profile.
+
+        :param      profile:          The z-profile of the coupler
+        :type       profile:          object
+        :param      add_coupling:     Add coupling to the transmission matrix
+        :type       add_coupling:     bool
+        """
+        profile.initialize()
+
+        final_slice = self.itr_to_slice(itr_list=profile.smallest_itr)
+
+        sub_t_matrix = self.transmission_matrix[..., :final_slice]
+
+        sub_itr_vector = self.model_parameters.itr_list[: final_slice]
+
+        if add_coupling:
+            sub_t_matrix = self.add_coupling_to_t_matrix(
+                t_matrix=sub_t_matrix,
+                adiabatic_factor=profile.evaluate_adiabatic_factor(itr=sub_itr_vector)
+            )
+
+        sub_distance = profile.evaluate_distance_vs_itr(sub_itr_vector)
+
+        return sub_distance, sub_itr_vector, sub_t_matrix
+
+    def propagate(
+            self, *,
+            profile: AlphaProfile,
+            initial_amplitude: list,
+            max_step: Optional[float] = None,
+            n_step: Optional[int] = None,
+            add_coupling: bool = True,
+            method: str = 'RK45',
+            **kwargs: dict) -> Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]:
+        """
+        Propagates the amplitudes of the supermodes in a coupler based on a given profile.
+
+        Args:
+            profile (AlphaProfile): The z-profile of the coupler.
+            initial_amplitude (list): The initial amplitude as a list.
+            max_step (float, optional): The maximum step size used by the solver. Defaults to None.
+            n_step (int, optional): Number of steps used by the solver (not currently used in this method).
+            add_coupling (bool): Flag to add coupling to the transmission matrix. Defaults to True.
+            method (str): Integration method to be used by the solver. Defaults to 'RK45'.
+            **kwargs (Dict[str, Any]): Additional keyword arguments to be passed to the solver.
+
+        Returns:
+            Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]: A tuple containing the times of the solution,
+                                                       the solution array of amplitudes, and the interpolated
+                                                       index of refraction at those times.
+        """
+        initial_amplitude = numpy.asarray(initial_amplitude, dtype=complex)
+
+        if max_step is None:
+            max_step = self.model_parameters.wavelength / 200
+
+        sub_distance, sub_itr_vector, sub_t_matrix = self.get_transmision_matrix_from_profile(
+            profile=profile,
+            add_coupling=add_coupling
+        )
+
+        z_to_itr = interp1d(profile.distance, profile.itr_list, bounds_error=False, fill_value='extrapolate')
+        itr_to_t_matrix = interp1d(sub_itr_vector, sub_t_matrix, bounds_error=False, fill_value='extrapolate')
+
+        def model(z, y):
+            itr = z_to_itr(z)
+            return 1j * itr_to_t_matrix(itr) @ y
+
+        sol = solve_ivp(
+            fun=model,
+            y0=initial_amplitude,
+            t_span=[0, profile.total_length],
+            method=method,
+            vectorized=True,
+            max_step=max_step,
+            **kwargs
+        )
+
+        # Check power conservation across the propagation
+        norm = numpy.sum(numpy.abs(sol.y)**2, axis=0)
+        if not numpy.allclose(norm, 1.0, atol=1e-1):
+            logging.warning(f'Power conservation not achieved [{max_step = }, atol = 1e-1].')
+
+        return sol.t, sol.y, z_to_itr(sol.t)
+
+    def interpret_initial_input(self, initial_amplitude: list | SuperMode) -> numpy.ndarray:
+        """
+        Interprets the initial amplitude input, ensuring compatibility with the expected number of supermodes.
+
+        Args:
+            initial_amplitude (list | SuperMode): The initial amplitude as either a list of complex numbers or a SuperMode object.
+
+        Returns:
+            numpy.ndarray: The initial amplitudes as a NumPy array of complex numbers.
+
+        Raises:
+            ValueError: If the length of the initial amplitude list does not match the number of supermodes.
+        """
+        if isinstance(initial_amplitude, SuperMode):
+            amplitudes = initial_amplitude.amplitudes
+        else:
+            amplitudes = initial_amplitude
+
+        amplitude_size = len(amplitudes)
+        number_of_supermodes = len(self.supermodes)
+
+        if amplitude_size != number_of_supermodes:
+            raise ValueError(f'Amplitudes size: {amplitude_size} does not match with the number of supermodes: {number_of_supermodes}')
+
+        return numpy.asarray(amplitudes, dtype=complex)
+
+    def plot_propagation(
+            self, *,
+            profile: AlphaProfile,
+            initial_amplitude,
+            max_step: Optional[float] = None,
+            add_coupling: bool = True,
+            method: str = 'RK45',
+            sub_sampling: int = 5,
+            show_energy: bool = True,
+            show_amplitudes: bool = True,
+            **kwargs: dict) -> Tuple[SceneList, Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]:
+        """
+        Plots the propagation of amplitudes over a given profile, showing energy and amplitude plots.
+
+        Args:
+            profile (AlphaProfile): The profile to propagate.
+            initial_amplitude: The initial amplitudes, either as a list or a SuperMode object.
+            max_step (Optional[float]): The maximum step size for the solver.
+            add_coupling (bool): Whether to add coupling in the transmission matrix.
+            method (str): Numerical method for solving the propagation.
+            sub_sampling (int): The factor for sub-sampling data for plotting.
+            show_energy (bool): Whether to plot the energy of the modes.
+            show_amplitudes (bool): Whether to plot the real part of the amplitudes.
+            **kwargs (Dict[str, Any]): Additional keyword arguments for solver.
+
+        Returns:
+            Tuple[SceneList, Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]:
+            A tuple containing the matplotlib figure object and a tuple with propagation distances, amplitudes, and inverse taper ratios.
+        """
+        initial_amplitude = self.interpret_initial_input(initial_amplitude)
+
+        z, amplitudes, itr_list = self.propagate(
+            initial_amplitude=initial_amplitude,
+            profile=profile,
+            add_coupling=add_coupling,
+            max_step=max_step,
+            method=method,
+            **kwargs
+        )
+
+        figure = SceneList(unit_size=(12, 4))
+        ax = figure.append_ax(line_width=2, show_legend=True, x_label='Propagation distance z', y_label='Inverse taper ratio [ITR]')
+
+        for idx, mode in enumerate(self.supermodes):
+            color = f"C{idx}"
+            x_values = z[::sub_sampling]
+            y_energy = numpy.abs(amplitudes[idx, ::sub_sampling])**2
+            y_amplitude = amplitudes[idx, ::sub_sampling].real
+
+            if show_energy:
+                ax.add_line(x=x_values, y=y_energy, label=mode.stylized_label, line_width=2.0, line_style='-', color=color)
+            if show_amplitudes:
+                ax.add_line(x=x_values, y=y_amplitude, label=mode.stylized_label + ' Amplitude', line_width=2.0, line_style='--', color=color)
+
+        if show_energy:
+            total_energy = numpy.sqrt(numpy.sum(numpy.abs(amplitudes)**2, axis=0))[::sub_sampling]
+            ax.add_line(x=x_values, y=total_energy, label='Total energy', line_width=3.0, line_style='--', color='black')
+
+        return figure.fig, (z, amplitudes, itr_list)
+
+    def generate_propagation_gif(
+            self, *,
+            profile: AlphaProfile,
+            initial_amplitude,
+            max_step: float = None,
+            coupling: str = 'normalized',
+            method: str = 'RK45',
+            sub_sampling: int = 5,
+            mutliplicative_factor: float = 1,
+            save_directory: str = 'new_figure.gif',
+            delta_azimuth: float = 0,
+            **kwargs) -> tuple:
+        """
+        Generates a gif video of the mode propagation.
+
+        :param      initial_amplitude:  The initial amplitude
+        :type       initial_amplitude:  list
+        :param      coupler_length:     The length of the coupler
+        :type       coupler_length:     float
+        :param      max_step:           The maximum stride to use in the solver
+        :type       max_step:           float
+        :param      sub_sampling:       Propagation undersampling factor for the video production
+        :type       sub_sampling:       int
+        :param      kwargs:             The keywords arguments
+        :type       kwargs:             dictionary
+        """
+
+        initial_amplitude = self.interpret_initial_input(
+            initial_amplitude=initial_amplitude
+        )
+
+        z_list, amplitudes_list, itr_list = self.propagate(
+            initial_amplitude=initial_amplitude,
+            profile=profile,
+            coupling=coupling,
+            max_step=max_step,
+            method=method
+        )
+
+        self.generate_propagation_gif_from_values(
+            amplitudes_list=amplitudes_list,
+            itr_list=itr_list,
+            z_list=z_list,
+            mutliplicative_factor=mutliplicative_factor,
+            save_directory=save_directory,
+            delta_azimuth=delta_azimuth,
+            sub_sampling=sub_sampling
+        )
+
+        return z_list, amplitudes_list, itr_list
+
+    def generate_propagation_gif_from_values(
+            self, *,
+            amplitudes_list: numpy.ndarray,
+            itr_list: numpy.ndarray,
+            z_list: numpy.ndarray,
+            sub_sampling: int = 10000,
+            mutliplicative_factor: float = -100,
+            delta_azimuth: float = 0,
+            save_directory: str = 'new_figure.gif',
+            colormap: str = 'bwr',
+            **kwargs) -> None:
+        """
+        Generates a gif video of the mode propagation.
+
+        :param      initial_amplitude:  The initial amplitude
+        :type       initial_amplitude:  list
+        :param      coupler_length:     The length of the coupler
+        :type       coupler_length:     float
+        :param      max_step:           The maximum stride to use in the solver
+        :type       max_step:           float
+        :param      sub_sampling:       Propagation undersampling factor for the video production
+        :type       sub_sampling:       int
+        :param      kwargs:             The keywords arguments
+        :type       kwargs:             dictionary
+        """
+        amplitudes_list = amplitudes_list[:, ::sub_sampling]
+        itr_list = itr_list[::sub_sampling]
+        z_list = z_list[::sub_sampling]
+
+        structure = self.get_slice_structure(itr=1.0, add_symmetries=True)
+        total_field = structure.get_field_combination(amplitudes_list[:, 0], Linf_normalization=True) * mutliplicative_factor
+
+        x, y = numpy.mgrid[0: total_field.shape[0], 0: total_field.shape[1]]
+        grid = pyvista.StructuredGrid(x, y, total_field)
+
+        plotter = pyvista.Plotter(notebook=False, off_screen=True)
+        plotter.open_gif(save_directory, fps=20)
+        plotter.view_isometric()
+        # plotter.set_background('black', top='white')
+
+        plotter.add_mesh(
+            grid,
+            scalars=total_field,
+            style='surface',
+            show_edges=True,
+            edge_color='k',
+            colormap=colormap,
+            show_scalar_bar=False,
+            clim=[-100, 100]
+        )
+
+        pts = grid.points.copy()
+        azimuth = 0
+        for z, amplitudes, itr in zip(z_list, amplitudes_list.T, itr_list):
+            print(f'itr: {itr}')
+            plotter.camera.elevation = -20
+            plotter.camera.azimuth = azimuth
+            azimuth += delta_azimuth
+
+            structure = self.get_slice_structure(itr=itr, add_symmetries=True)
+            total_field = structure.get_field_combination(amplitudes, Linf_normalization=True) * mutliplicative_factor
+
+            pts[:, -1] = total_field.T.ravel()
+            plotter.update_coordinates(pts, render=True)
+            plotter.update_scalars(total_field.T.ravel(), render=False)
+            plotter.add_title(f'ITR: {itr: .3f}\t  z: {z: .3e}', font='courier', color='w', font_size=20)
+
+            plotter.write_frame()
+
+        plotter.close()
+
+    def _sort_modes(self, *ordering_keys) -> List[SuperMode]:
+        """
+        Sorts supermodes using specified keys provided as tuples in ordering_keys.
+
+        Args:
+            ordering_keys (tuple): Tuple containing keys to sort by.
+
+        Returns:
+            List[SuperMode]: Sorted list of supermodes.
+        """
+        order = numpy.lexsort(ordering_keys)
+        sorted_supermodes = [self.supermodes[idx] for idx in order]
+        for i, supermode in enumerate(sorted_supermodes):
+            supermode.mode_number = i
+        return sorted_supermodes
+
+    def sort_modes_by_beta(self) -> None:
+        """
+        Sorts supermodes in descending order of their propagation constants (beta).
+        """
+        self.all_supermodes = self._sort_modes([-mode.beta.data[-1] for mode in self.supermodes])
+
+    def sort_modes(self, sorting_method: str = "beta", keep_only: Optional[int] = None) -> None:
+        """
+        Sorts supermodes according to the specified method, optionally limiting the number of modes retained.
+
+        Args:
+            sorting_method (str): Sorting method to use, either "beta" or "symmetry+beta".
+            keep_only (int, optional): Number of supermodes to retain after sorting.
+
+        Raises:
+            ValueError: If an unrecognized sorting method is provided.
+        """
+        match sorting_method.lower():
+            case 'beta':
+                self.sort_modes_by_beta()
+            case 'symmetry+beta':
+                self.sort_modes_by_solver_and_beta()
+            case _:
+                raise ValueError(f"Unrecognized sorting method: {sorting_method}, accepted values are ['beta', 'symmetry+beta']")
+
+        self.supermodes = self.all_supermodes[:keep_only] if keep_only is not None else self.all_supermodes
+
+    def sort_modes_by_solver_and_beta(self) -> None:
+        """
+        Sorts supermodes primarily by solver number and secondarily by descending propagation constant (beta).
+        """
+        self.all_supermodes = self._sort_modes(
+            ([mode.solver_number for mode in self.supermodes],
+             [-mode.beta[-1] for mode in self.supermodes])
+        )
+
+    @staticmethod
+    def single_plot(plot_function) -> Callable:
+        def wrapper(self, *args, mode_of_interest='all', **kwargs):
+            mode_of_interest = interpret_mode_of_interest(
+                superset=self,
+                mode_of_interest=mode_of_interest
+            )
+
+            figure = SceneList(unit_size=(16, 6), ax_orientation='vertical')
+
+            ax = figure.append_ax()
+
+            plot_function(self, ax=ax, *args, mode_of_interest=mode_of_interest, **kwargs)
+
+            return figure
+
+        return wrapper
+
+    @staticmethod
+    def combination_plot(plot_function) -> Callable:
+        def wrapper(self, *args, mode_of_interest='all', mode_selection: str = 'pairs', **kwargs):
+            mode_of_interest = interpret_mode_of_interest(
+                superset=self,
+                mode_of_interest=mode_of_interest
+            )
+
+            combination = self.interpret_mode_selection(
+                mode_of_interest=mode_of_interest,
+                mode_selection=mode_selection
+            )
+
+            figure = SceneList(unit_size=(16, 6), ax_orientation='vertical')
+
+            ax = figure.append_ax()
+
+            plot_function(self, ax=ax, *args, mode_of_interest=mode_of_interest, combination=combination, **kwargs)
+
+            return figure
+
+        return wrapper
+
+    @single_plot
+    def plot_index(
+            self,
+            ax: Axis,
+            show_crossings: bool = False,
+            mode_of_interest: str | list[SuperMode] = 'all') -> SceneList:
+        """
+        Plot effective index for each mode as a function of itr
+
+        :param      mode_of_interest:  The mode of interest
+        :type       mode_of_interest:  str
+        :param      artist_kwargs:     The keywords arguments
+        :type       artist_kwargs:     dictionary
+
+        :returns:   figure instance, to plot the show() method.
+        :rtype:     SceneList
+        """
+        ax.set_style(**representation.index.Index.plot_style)
+
+        for mode in mode_of_interest:
+            mode.index.render_on_ax(ax=ax)
+
+        if show_crossings:
+            self.add_crossings_to_ax(ax=ax, mode_of_interest=mode_of_interest, data_type='index')
+
+    @single_plot
+    def plot_beta(
+            self,
+            ax: Axis,
+            show_crossings: bool = False,
+            mode_of_interest: str | list[SuperMode] = 'all') -> SceneList:
+        """
+        Plot propagation constant for each mode as a function of itr
+
+        :param      mode_of_interest:  The mode of interest
+        :type       mode_of_interest:  str
+        :param      artist_kwargs:     The keywords arguments
+        :type       artist_kwargs:     dictionary
+
+        :returns:   figure instance, to plot the show() method.
+        :rtype:     SceneList
+        """
+        ax.set_style(**representation.beta.Beta.plot_style)
+
+        for mode in mode_of_interest:
+            mode.beta.render_on_ax(ax=ax)
+
+        if show_crossings:
+            self.add_crossings_to_ax(ax=ax, mode_of_interest=mode_of_interest, data_type='beta')
+
+    @single_plot
+    def plot_eigen_value(
+            self,
+            ax: Axis,
+            mode_of_interest: str | list[SuperMode] = 'all',
+            show_crossings: bool = False) -> SceneList:
+        """
+        Plot propagation constant for each mode as a function of itr
+
+        :param      mode_of_interest:  The mode of interest
+        :type       mode_of_interest:  str
+        :param      artist_kwargs:     The keywords arguments
+        :type       artist_kwargs:     dictionary
+
+        :returns:   figure instance, to plot the show() method.
+        :rtype:     SceneList
+        """
+        ax.set_style(**representation.eigen_value.EigenValue.plot_style)
+
+        for mode in mode_of_interest:
+            mode.index.render_on_ax(ax=ax)
+
+        if show_crossings:
+            self.add_crossings_to_ax(ax=ax, mode_of_interest=mode_of_interest, data_type='eigen_value')
+
+    @combination_plot
+    def plot_normalized_coupling(
+            self,
+            ax: Axis,
+            mode_of_interest: list[SuperMode],
+            combination: list) -> SceneList:
+        """
+        Plot normalized coupling value for each mode as a function of itr.
+
+        :param      mode_of_interest:  The mode of interest
+        :type       mode_of_interest:  str
+        :param      mode_selection:    The mode selection
+        :type       mode_selection:    str
+        :param      artist_kwargs:     The keywords arguments
+        :type       artist_kwargs:     dictionary
+
+        :returns:   figure instance, to plot the show() method.
+        :rtype:     SceneList
+        """
+        ax.set_style(**representation.normalized_coupling.NormalizedCoupling.plot_style)
+
+        for mode_0, mode_1 in combination:
+            mode_0.normalized_coupling.render_on_ax(ax=ax, other_supermode=mode_1)
+
+    @combination_plot
+    def plot_beating_length(
+            self,
+            ax: Axis,
+            mode_of_interest: list[SuperMode],
+            combination: list) -> SceneList:
+        """
+        Plot coupling value for each mode as a function of itr
+
+        :param      mode_of_interest:  List of the mode that are to be considered in the adiabatic criterion plotting.
+        :type       mode_of_interest:  list
+
+        :returns:   figure instance, to plot the show() method.
+        :rtype:     SceneList
+        """
+        for mode_0, mode_1 in combination:
+            ax.set_style(**mode_0.beating_length.BeatingLength.plot_style)
+            mode_0.beating_length.render_on_ax(ax=ax, other_supermode=mode_1)
+
+    @combination_plot
+    def plot_adiabatic(
+            self,
+            ax: Axis,
+            mode_of_interest: list[SuperMode],
+            combination: list,
+            add_profile: list[AlphaProfile] = []) -> SceneList:
+        """
+        Plot adiabatic criterion for each mode as a function of itr
+
+        :param      pair_of_interest:  List of the mode that are to be considered in the adiabatic criterion plotting.
+        :type       pair_of_interest:  list
+        :param      mode_selection:    The type of combination to be plotted, either 'specific/all/pairs'
+        :type       mode_selection:    str
+        :param      artist_kwargs:     The keywords arguments
+        :type       artist_kwargs:     dictionary
+
+        :returns:   figure instance, to plot the show() method.
+        :rtype:     SceneList
+        """
+        ax.set_style(**representation.adiabatic.Adiabatic.plot_style)
+        for mode_0, mode_1 in combination:
+            mode_0.adiabatic.render_on_ax(ax=ax, other_supermode=mode_1)
+
+        for profile in numpy.atleast_1d(add_profile):
+            profile.render_adiabatic_factor_vs_itr_on_ax(ax=ax, line_style='--')
+
+    def is_compute_compatible(self, pair_of_mode: tuple) -> bool:
+        """
+        Determines whether the specified pair of mode is compatible for computation.
+
+        :param      pair_of_mode:  The pair of mode
+        :type       pair_of_mode:  tuple
+
+        :returns:   True if the specified pair of mode is compute compatible, False otherwise.
+        :rtype:     bool
+        """
+        mode_0, mode_1 = pair_of_mode
+        return mode_0.is_computation_compatible(mode_1)
+
+    def remove_duplicate_combination(self, supermodes_list: list) -> list[SuperMode]:
+        """
+        Removes a duplicate combination in the mode combination list irrespectively of the order.
+
+        :param      supermodes_list:  The supermodes list
+        :type       supermodes_list:  list
+
+        :returns:   The reduced supermode list
+        :rtype:     list
+        """
+        output_list = []
+
+        for mode0, mode1 in supermodes_list:
+            if (mode0, mode1) not in output_list and (mode1, mode0) not in output_list:
+                output_list.append((mode0, mode1))
+
+        return output_list
+
+    def interpret_mode_selection(self, mode_of_interest: list, mode_selection: str) -> set:
+        """
+        Interpret user input for mode selection and return the combination of mode to consider.
+
+        :param      mode_of_interest:  The mode of interest
+        :type       mode_of_interest:  list
+        :param      mode_selection:    The mode selection
+        :type       mode_selection:    str
+        """
+        test_valid_input(
+            variable_name='mode_selection',
+            user_input=mode_selection,
+            valid_inputs=['pairs', 'specific']
+        )
+
+        match mode_selection:
+            case 'pairs':
+                mode_combinations = product(mode_of_interest, mode_of_interest)
+            case 'specific':
+                mode_combinations = product(mode_of_interest, self.supermodes)
+
+        mode_combinations = filter(self.is_compute_compatible, mode_combinations)
+
+        mode_combinations = self.remove_duplicate_combination(mode_combinations)
+
+        return set(mode_combinations)
+
+    def plot_field(
+            self,
+            mode_of_interest: list = 'all',
+            itr_list: list[float] = None,
+            slice_list: list[int] = None,
+            show_mode_label: bool = True,
+            show_itr: bool = True,
+            show_slice: bool = True) -> SceneList:
+        """
+        Plot each of the mode field for different itr value or slice number.
+
+        :param      itr_list:    List of itr value to evaluate the mode field
+        :type       itr_list:    list
+        :param      slice_list:  List of integer reprenting the slice where the mode field is evaluated
+        :type       slice_list:  list
+
+        :returns:   The figure
+        :rtype:     SceneMatrix
+        """
+        figure = SceneMatrix(unit_size=(3, 3))
+
+        slice_list, itr_list = interpret_slice_number_and_itr(
+            itr_baseline=self.model_parameters.itr_list,
+            itr_list=itr_list,
+            slice_list=slice_list
+        )
+
+        mode_of_interest = interpret_mode_of_interest(
+            superset=self,
+            mode_of_interest=mode_of_interest
+        )
+
+        for m, mode in enumerate(mode_of_interest):
+            for n, slice_number in enumerate(slice_list):
+                ax = figure.append_ax(row=n, column=m)
+
+                ax.set_style(**representation.field.Field.plot_style)
+
+                mode.field.render_on_ax(
+                    ax=ax,
+                    slice_number=slice_number,
+                    show_mode_label=show_mode_label,
+                    show_itr=show_itr,
+                    show_slice=show_slice
+                )
+
+        return figure
+
+    def plot(self, plot_type: str, **kwargs) -> SceneList:
+        """
+        General plotting function to handle different types of supermode plots.
+
+        Args:
+            plot_type (str): The type of plot to generate. Options include 'index', 'beta', 'eigen-value', etc.
+            **kwargs: Additional keyword arguments for specific plot configurations.
+
+        Returns:
+            SceneList: The generated plot as a SceneList object.
+
+        Raises:
+            ValueError: If an unrecognized plot type is specified.
+        """
+        match plot_type.lower():
+            case 'index':
+                return self.plot_index(**kwargs)
+            case 'beta':
+                return self.plot_beta(**kwargs)
+            case 'eigen-value':
+                return self.plot_eigen_value(**kwargs)
+            case 'normalized-coupling':
+                return self.plot_normalized_coupling(**kwargs)
+            case 'overlap':
+                return self.plot_overlap(**kwargs)
+            case 'adiabatic':
+                return self.plot_adiabatic(**kwargs)
+            case 'field':
+                return self.plot_field(**kwargs)
+            case 'beating-length':
+                return self.plot_beating_length(**kwargs)
+            case 'normalized-adiabatic':
+                return self.plot_normalized_adiabatic(**kwargs)
+            case _:
+                raise ValueError(f'Invalid plot type: {plot_type}. Options are: index, beta, eigen-value, adiabatic, normalized-adiabatic, normalized-coupling, field, beating-length')
+
+    def generate_pdf_report(
+            self,
+            filename: str = "report",
+            directory: str = '.',
+            itr_list: list[float] | None = None,
+            slice_list: list[int] | None = None,
+            dpi: int = 200,
+            mode_of_interest: list = 'all',
+            mode_selection: str = 'specific') -> None:
+        """
+        Generate a full report of the coupler properties as a .pdf file
+
+        :param      filename:          Name of the Report file to be outputed.
+        :type       filename:          str
+        :param      itr_list:          List of itr value to evaluate the mode field.
+        :type       itr_list:          Array
+        :param      slice_list:        List of slice value to evaluate the mode field.
+        :type       slice_list:        Array
+        :param      dpi:               Pixel density for the image included in the report.
+        :type       dpi:               int
+        :param      mode_of_interest:  List of the mode that are to be considered in the adiabatic criterion plotting.
+        :type       mode_of_interest:  list
+
+        :returns:   No return
+        :rtype:     None
+        """
+        if directory == 'auto':
+            directory = directories.reports_path
+
+        filename = Path(directory).joinpath(filename).with_suffix('.pdf')
+
+        logging.info(f"Saving report pdf into: {filename}")
+
+        figure_list = []
+
+        figure_list.append(self.geometry.plot()._render_())
+
+        figure_list.append(self.plot_field(itr_list=itr_list, slice_list=slice_list)._render_())
+
+        figure_list.append(self.plot_index()._render_())
+
+        figure_list.append(self.plot_beta()._render_())
+
+        figure_list.append(self.plot_normalized_coupling(mode_of_interest=mode_of_interest, mode_selection=mode_selection)._render_())
+
+        figure_list.append(self.plot_adiabatic(mode_of_interest=mode_of_interest, mode_selection=mode_selection)._render_())
+
+        Multipage(filename, figs=figure_list, dpi=dpi)
+
+        for figure in figure_list:
+            figure.close()
+
+    def save_instance(self, filename: str, directory: str = 'auto') -> Path:
+        """
+        Saves the superset instance as a serialized pickle file.
+
+        :param      filename:  The directory where to save the file, 'auto' options means the superset_instance folder
+        :type       filename:  str
+        :param      filename:  The filename
+        :type       filename:  str
+
+        :returns:   The path directory of the saved instance
+        :rtype:     Path
+        """
+        if directory == 'auto':
+            directory = directories.instance_directory
+
+        filename = Path(filename).with_suffix('.pickle')
+
+        filename = sanitize_filepath(filename)
+
+        filename = Path(directory).joinpath(filename)
+
+        logging.info(f"Saving pickled superset into: {filename}")
+
+        with open(filename, 'wb') as output_file:
+            pickle.dump(self, output_file, pickle.HIGHEST_PROTOCOL)
+
+        return filename
+
+    def add_crossings_to_ax(self, ax: Axis, mode_of_interest: list, data_type: str) -> None:
+        combination = self.interpret_mode_selection(
+            mode_of_interest=mode_of_interest,
+            mode_selection='pairs'
+        )
+
+        for mode_0, mode_1 in combination:
+            x, y = get_intersection(
+                x=self.model_parameters.itr_list,
+                y0=getattr(mode_0, data_type).data,
+                y1=getattr(mode_1, data_type).data,
+                average=True
+            )
+
+            if x is not None:
+                ax.add_scatter(
+                    x=x,
+                    y=y,
+                    marker='o',
+                    color='black',
+                    marker_size=20,
+                    label='mode crossing'
+                )
+
+
+# -
```

## SuPyMode/utils.py

 * *Ordering differences only*

```diff
@@ -1,246 +1,246 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-from typing import Union, List, Iterable
-if TYPE_CHECKING:
-    from SuPyMode.superset import SuperSet
-    from SuPyMode.supermode import SuperMode
-
-import numpy
-import pickle
-from pathlib import Path
-from SuPyMode.directories import instance_directory
-
-
-def load_superset(filename: str, directory: str = 'auto'):
-    """
-    Saves the superset instance as a serialized pickle file.
-
-    :param      filename:  The filename
-    :type       filename:  str
-    """
-    if directory == 'auto':
-        directory = instance_directory
-
-    filename = Path(directory).joinpath(filename).with_suffix('.pickle')
-
-    with open(filename, 'rb') as input_file:
-        superset = pickle.load(input_file)
-
-    return superset
-
-
-def get_close_points(tolerane: float, y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray = None):
-    idx = numpy.argwhere(numpy.abs(y0 - y1) < tolerane)
-
-    if x is not None:
-        return x[idx], y0[idx]
-
-    return y0[idx]
-
-
-def get_intersection_(y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray = None):
-    idx = numpy.argwhere(numpy.diff(numpy.sign(y0 - y1))).flatten()
-
-    if x is not None:
-        return x[idx], y0[idx]
-
-    return y0[idx]
-
-
-def get_intersection(y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray, average: bool = True):
-
-    idx = numpy.argwhere(numpy.diff(numpy.sign(y0 - y1))).flatten()
-
-    if len(idx) == 0:  # No intersection
-        return None, None
-
-    if not average:
-        return y0[idx]
-
-    else:
-        x_mean = (x[idx + 1] + x[idx]) / 2
-        y_mean = (y0[idx + 1] + y0[idx]) / 2
-
-        return x_mean, y_mean
-
-
-def test_valid_input(user_input, valid_inputs: list, variable_name: str = '') -> None:
-    if user_input not in valid_inputs:
-        raise ValueError(f"[{variable_name}] user_input: {user_input} argument not valid. Valid choices are: {valid_inputs}")
-
-
-def itr_to_slice(itr_list: numpy.ndarray, itr: float | list) -> int | list:
-    """
-    Converts an inverse taper ratio (itr) or a list of itrs to their closest corresponding slice numbers
-    in the provided itr_list. If a single itr is provided, returns a single slice number. If a list of
-    itrs is provided, returns a list of slice numbers.
-
-    Parameters:
-        itr_list (np.ndarray): Array of itrs, typically representing a continuous range of values.
-        itr (Union[float, List[float]]): A single itr value or a list of itr values.
-
-    Returns:
-        Union[int, List[int]]: The closest slice number or list of slice numbers corresponding to the provided itr or itrs.
-
-    """
-    if numpy.isscalar(itr):
-        return numpy.argmin(abs(itr_list - itr))
-
-    if isinstance(itr_list, Iterable):
-        return [numpy.argmin(abs(itr_list - value)) for value in itr]
-
-    raise TypeError("itr must be a float or a list of floats.")
-
-
-def slice_to_itr(itr_list: numpy.ndarray, slice_number: int | list) -> float | list:
-    """
-    Converts a slice number or a list of slice numbers to their corresponding inverse taper ratios (itrs)
-    from the provided itr_list. If a single slice number is provided, returns a single itr value.
-    If a list of slice numbers is provided, returns a list of itr values.
-
-    Parameters:
-        - itr_list (np.ndarray): Array of itrs, typically representing a continuous range of values.
-        - slice_number (Union[int, List[int]]): A single slice index or a list of slice indices.
-
-    Returns:
-         - Union[float, List[float]]: The itr or list of itrs corresponding to the given slice numbers.
-
-    """
-    if numpy.isscalar(slice_number):
-        return itr_list[slice_number]
-
-    if isinstance(slice_number, Iterable):
-        return numpy.take(itr_list, slice_number)
-
-    raise TypeError("itr_list must be an scalar or a list of scalar.")
-
-
-def interpret_slice_number_and_itr(
-        itr_baseline: numpy.ndarray,
-        slice_list: Union[int, List[int], None] = None,
-        itr_list: Union[float, List[float], None] = None,
-        sort_slice_number: bool = True) -> tuple:
-    """
-    Interprets slice numbers and corresponding inverse taper ratios (ITRs), returning arrays of slice numbers
-    and their respective ITRs based on the provided lists of slices and ITRs.
-
-    Parameters:
-        - itr_baseline (numpy.ndarray): Array of baseline ITR values, typically equidistant, representing the full range.
-        - slice_list (Union[int, List[int]], optional): A single slice index or a list of slice indices. If None and itr_list is also None, defaults to [0, -1].
-        - itr_list (Union[float, List[float]], optional): A single ITR value or a list of ITR values to be converted to slice indices. If provided, slice_list defaults to an empty list unless specified.
-        - sort_slice_number (bool, optional): Whether to sort the resulting slice numbers and corresponding ITRs in descending order. Default is False.
-
-    Returns:
-        - Tuple[numpy.ndarray, numpy.ndarray]: Two numpy arrays, the first containing slice indices and the second containing the corresponding ITR values.
-
-    Raises:
-        - ValueError: If the provided ITRs or slice indices are outside the bounds of the baseline ITR array.
-    """
-
-    if slice_list is None and itr_list is None:
-        slice_list = [0, -1]
-    elif itr_list is not None and slice_list is None:
-        slice_list = []
-
-    slice_list = numpy.atleast_1d(slice_list)
-    itr_list = numpy.atleast_1d(itr_list) if itr_list is not None else numpy.array([])
-
-    # Logic to convert ITRs to slice indices, and combine lists
-    slice_from_itr = itr_to_slice(itr_baseline, itr=itr_list) if itr_list.size > 0 else numpy.array([])
-    total_slice_list = numpy.concatenate([slice_list, slice_from_itr]).astype(int)
-
-    total_itr_list = slice_to_itr(itr_baseline, slice_number=total_slice_list)
-
-    # Sort if required
-    if sort_slice_number:
-        indices = numpy.argsort(total_itr_list)
-        total_slice_list = total_slice_list[indices][::-1]  # Descending order
-        total_itr_list = total_itr_list[indices][::-1]
-
-    return total_slice_list, total_itr_list
-
-
-def interpret_mode_of_interest(superset: SuperSet, mode_of_interest: str | SuperMode | list[SuperMode]) -> list[SuperMode]:
-    """
-    Resolves the mode of interest from user input to the appropriate list of SuperMode instances
-    based on the specified criteria or direct references.
-
-    Parameters:
-        - superset (SuperSet): The superset containing all supermodes, including fundamental and non-fundamental modes.
-        - mode_of_interest (Union[str, SuperMode, List[SuperMode]]): This parameter can be a string specifying a category
-          of modes such as 'fundamental', 'non-fundamental', 'all', a single SuperMode instance, or a list of SuperMode instances.
-
-    Returns:
-        - List[SuperMode]: A list of SuperMode instances corresponding to the specified mode of interest.
-
-    Raises:
-        - ValueError: If the mode_of_interest is not one of the expected types or if the string input does not match
-        any known category.
-    """
-    if isinstance(mode_of_interest, str):
-        match mode_of_interest:
-            case 'fundamental':
-                return superset.fundamental_supermodes
-            case 'non-fundamental':
-                return superset.non_fundamental_supermodes
-            case 'all':
-                return superset.supermodes
-            case _:
-                raise ValueError(f"Unrecognized mode category '{mode_of_interest}'. Expected 'fundamental', 'non-fundamental', or 'all'.")
-
-    if isinstance(mode_of_interest, SuperMode):
-        return [mode_of_interest]
-
-    if isinstance(mode_of_interest, list) and all(isinstance(item, SuperMode) for item in mode_of_interest):
-        return mode_of_interest
-
-    raise ValueError("mode_of_interest must be either 'fundamental', 'non-fundamental', 'all', a SuperMode instance, or a list of SuperMode instances.")
-
-
-def get_symmetrized_vector(vector: numpy.ndarray, symmetry_type: str = 'last') -> numpy.ndarray:
-    """
-    Generate a symmetric version of the input vector based on the specified symmetry type.
-
-    Parameters:
-    -----------
-    vector : numpy.ndarray
-        A one-dimensional array for which the symmetric version is to be calculated.
-    symmetry_type : str, optional
-        Type of symmetry to apply. Supported types:
-        - 'last': Symmetrize using the last element as reference.
-        - 'first': Symmetrize using the first element as reference.
-        Default is 'last'.
-
-    Returns:
-    --------
-    numpy.ndarray
-        A new vector that is the symmetrized version of the input vector.
-
-    Raises:
-    -------
-    ValueError
-        If the input vector is not one-dimensional or the symmetry type is unsupported.
-    """
-
-    if vector.ndim != 1:
-        raise ValueError(f"Expected a 1-dimensional vector, but got a {vector.ndim}-dimensional vector instead.")
-
-    if symmetry_type.lower() not in ['last', 'first']:
-        raise ValueError("Symmetry type must be 'last' or 'first'.")
-
-    size = len(vector)
-    dx = numpy.diff(vector)[0]  # More robust than assuming vector[1] - vector[0]
-
-    if symmetry_type.lower() == 'last':
-        start_value = vector[-1]
-        expanded = numpy.arange(0, 2 * size - 1) * dx
-        return start_value - expanded[::-1] if dx > 0 else start_value + expanded[::-1]
-    else:  # 'first'
-        start_value = vector[0]
-        expanded = numpy.arange(0, 2 * size - 1) * dx
-        return start_value + expanded
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+from typing import Union, List, Iterable
+if TYPE_CHECKING:
+    from SuPyMode.superset import SuperSet
+    from SuPyMode.supermode import SuperMode
+
+import numpy
+import pickle
+from pathlib import Path
+from SuPyMode.directories import instance_directory
+
+
+def load_superset(filename: str, directory: str = 'auto'):
+    """
+    Saves the superset instance as a serialized pickle file.
+
+    :param      filename:  The filename
+    :type       filename:  str
+    """
+    if directory == 'auto':
+        directory = instance_directory
+
+    filename = Path(directory).joinpath(filename).with_suffix('.pickle')
+
+    with open(filename, 'rb') as input_file:
+        superset = pickle.load(input_file)
+
+    return superset
+
+
+def get_close_points(tolerane: float, y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray = None):
+    idx = numpy.argwhere(numpy.abs(y0 - y1) < tolerane)
+
+    if x is not None:
+        return x[idx], y0[idx]
+
+    return y0[idx]
+
+
+def get_intersection_(y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray = None):
+    idx = numpy.argwhere(numpy.diff(numpy.sign(y0 - y1))).flatten()
+
+    if x is not None:
+        return x[idx], y0[idx]
+
+    return y0[idx]
+
+
+def get_intersection(y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray, average: bool = True):
+
+    idx = numpy.argwhere(numpy.diff(numpy.sign(y0 - y1))).flatten()
+
+    if len(idx) == 0:  # No intersection
+        return None, None
+
+    if not average:
+        return y0[idx]
+
+    else:
+        x_mean = (x[idx + 1] + x[idx]) / 2
+        y_mean = (y0[idx + 1] + y0[idx]) / 2
+
+        return x_mean, y_mean
+
+
+def test_valid_input(user_input, valid_inputs: list, variable_name: str = '') -> None:
+    if user_input not in valid_inputs:
+        raise ValueError(f"[{variable_name}] user_input: {user_input} argument not valid. Valid choices are: {valid_inputs}")
+
+
+def itr_to_slice(itr_list: numpy.ndarray, itr: float | list) -> int | list:
+    """
+    Converts an inverse taper ratio (itr) or a list of itrs to their closest corresponding slice numbers
+    in the provided itr_list. If a single itr is provided, returns a single slice number. If a list of
+    itrs is provided, returns a list of slice numbers.
+
+    Parameters:
+        itr_list (np.ndarray): Array of itrs, typically representing a continuous range of values.
+        itr (Union[float, List[float]]): A single itr value or a list of itr values.
+
+    Returns:
+        Union[int, List[int]]: The closest slice number or list of slice numbers corresponding to the provided itr or itrs.
+
+    """
+    if numpy.isscalar(itr):
+        return numpy.argmin(abs(itr_list - itr))
+
+    if isinstance(itr_list, Iterable):
+        return [numpy.argmin(abs(itr_list - value)) for value in itr]
+
+    raise TypeError("itr must be a float or a list of floats.")
+
+
+def slice_to_itr(itr_list: numpy.ndarray, slice_number: int | list) -> float | list:
+    """
+    Converts a slice number or a list of slice numbers to their corresponding inverse taper ratios (itrs)
+    from the provided itr_list. If a single slice number is provided, returns a single itr value.
+    If a list of slice numbers is provided, returns a list of itr values.
+
+    Parameters:
+        - itr_list (np.ndarray): Array of itrs, typically representing a continuous range of values.
+        - slice_number (Union[int, List[int]]): A single slice index or a list of slice indices.
+
+    Returns:
+         - Union[float, List[float]]: The itr or list of itrs corresponding to the given slice numbers.
+
+    """
+    if numpy.isscalar(slice_number):
+        return itr_list[slice_number]
+
+    if isinstance(slice_number, Iterable):
+        return numpy.take(itr_list, slice_number)
+
+    raise TypeError("itr_list must be an scalar or a list of scalar.")
+
+
+def interpret_slice_number_and_itr(
+        itr_baseline: numpy.ndarray,
+        slice_list: Union[int, List[int], None] = None,
+        itr_list: Union[float, List[float], None] = None,
+        sort_slice_number: bool = True) -> tuple:
+    """
+    Interprets slice numbers and corresponding inverse taper ratios (ITRs), returning arrays of slice numbers
+    and their respective ITRs based on the provided lists of slices and ITRs.
+
+    Parameters:
+        - itr_baseline (numpy.ndarray): Array of baseline ITR values, typically equidistant, representing the full range.
+        - slice_list (Union[int, List[int]], optional): A single slice index or a list of slice indices. If None and itr_list is also None, defaults to [0, -1].
+        - itr_list (Union[float, List[float]], optional): A single ITR value or a list of ITR values to be converted to slice indices. If provided, slice_list defaults to an empty list unless specified.
+        - sort_slice_number (bool, optional): Whether to sort the resulting slice numbers and corresponding ITRs in descending order. Default is False.
+
+    Returns:
+        - Tuple[numpy.ndarray, numpy.ndarray]: Two numpy arrays, the first containing slice indices and the second containing the corresponding ITR values.
+
+    Raises:
+        - ValueError: If the provided ITRs or slice indices are outside the bounds of the baseline ITR array.
+    """
+
+    if slice_list is None and itr_list is None:
+        slice_list = [0, -1]
+    elif itr_list is not None and slice_list is None:
+        slice_list = []
+
+    slice_list = numpy.atleast_1d(slice_list)
+    itr_list = numpy.atleast_1d(itr_list) if itr_list is not None else numpy.array([])
+
+    # Logic to convert ITRs to slice indices, and combine lists
+    slice_from_itr = itr_to_slice(itr_baseline, itr=itr_list) if itr_list.size > 0 else numpy.array([])
+    total_slice_list = numpy.concatenate([slice_list, slice_from_itr]).astype(int)
+
+    total_itr_list = slice_to_itr(itr_baseline, slice_number=total_slice_list)
+
+    # Sort if required
+    if sort_slice_number:
+        indices = numpy.argsort(total_itr_list)
+        total_slice_list = total_slice_list[indices][::-1]  # Descending order
+        total_itr_list = total_itr_list[indices][::-1]
+
+    return total_slice_list, total_itr_list
+
+
+def interpret_mode_of_interest(superset: SuperSet, mode_of_interest: str | SuperMode | list[SuperMode]) -> list[SuperMode]:
+    """
+    Resolves the mode of interest from user input to the appropriate list of SuperMode instances
+    based on the specified criteria or direct references.
+
+    Parameters:
+        - superset (SuperSet): The superset containing all supermodes, including fundamental and non-fundamental modes.
+        - mode_of_interest (Union[str, SuperMode, List[SuperMode]]): This parameter can be a string specifying a category
+          of modes such as 'fundamental', 'non-fundamental', 'all', a single SuperMode instance, or a list of SuperMode instances.
+
+    Returns:
+        - List[SuperMode]: A list of SuperMode instances corresponding to the specified mode of interest.
+
+    Raises:
+        - ValueError: If the mode_of_interest is not one of the expected types or if the string input does not match
+        any known category.
+    """
+    if isinstance(mode_of_interest, str):
+        match mode_of_interest:
+            case 'fundamental':
+                return superset.fundamental_supermodes
+            case 'non-fundamental':
+                return superset.non_fundamental_supermodes
+            case 'all':
+                return superset.supermodes
+            case _:
+                raise ValueError(f"Unrecognized mode category '{mode_of_interest}'. Expected 'fundamental', 'non-fundamental', or 'all'.")
+
+    if isinstance(mode_of_interest, SuperMode):
+        return [mode_of_interest]
+
+    if isinstance(mode_of_interest, list) and all(isinstance(item, SuperMode) for item in mode_of_interest):
+        return mode_of_interest
+
+    raise ValueError("mode_of_interest must be either 'fundamental', 'non-fundamental', 'all', a SuperMode instance, or a list of SuperMode instances.")
+
+
+def get_symmetrized_vector(vector: numpy.ndarray, symmetry_type: str = 'last') -> numpy.ndarray:
+    """
+    Generate a symmetric version of the input vector based on the specified symmetry type.
+
+    Parameters:
+    -----------
+    vector : numpy.ndarray
+        A one-dimensional array for which the symmetric version is to be calculated.
+    symmetry_type : str, optional
+        Type of symmetry to apply. Supported types:
+        - 'last': Symmetrize using the last element as reference.
+        - 'first': Symmetrize using the first element as reference.
+        Default is 'last'.
+
+    Returns:
+    --------
+    numpy.ndarray
+        A new vector that is the symmetrized version of the input vector.
+
+    Raises:
+    -------
+    ValueError
+        If the input vector is not one-dimensional or the symmetry type is unsupported.
+    """
+
+    if vector.ndim != 1:
+        raise ValueError(f"Expected a 1-dimensional vector, but got a {vector.ndim}-dimensional vector instead.")
+
+    if symmetry_type.lower() not in ['last', 'first']:
+        raise ValueError("Symmetry type must be 'last' or 'first'.")
+
+    size = len(vector)
+    dx = numpy.diff(vector)[0]  # More robust than assuming vector[1] - vector[0]
+
+    if symmetry_type.lower() == 'last':
+        start_value = vector[-1]
+        expanded = numpy.arange(0, 2 * size - 1) * dx
+        return start_value - expanded[::-1] if dx > 0 else start_value + expanded[::-1]
+    else:  # 'first'
+        start_value = vector[0]
+        expanded = numpy.arange(0, 2 * size - 1) * dx
+        return start_value + expanded
+
+# -
```

## SuPyMode/workflow.py

```diff
@@ -1,383 +1,389 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-from typing import List, Union, Optional
-from dataclasses import dataclass
-from pathlib import Path
-
-from FiberFusing import Geometry, BackGround
-from SuPyMode.solver import SuPySolver
-from FiberFusing.fiber import catalogue as fiber_catalogue
-from SuPyMode.profiles import AlphaProfile  # noqa: F401
-from FiberFusing import configuration  # noqa: F401
-
-from PyFinitDiff.finite_difference_2D import Boundaries
-from pathvalidate import sanitize_filepath
-
-
-def prepare_simulation_geometry(
-        wavelength: float,
-        clad_structure: object,
-        fiber_list: List[object],
-        capillary_tube: Optional[object] = None,
-        fusion_degree: Union[float, str] = 'auto',
-        fiber_radius: Optional[float] = None,
-        x_bounds: Union[str, List[float]] = '',
-        y_bounds: Union[str, List[float]] = '',
-        clad_index: Union[float, str] = 'silica',
-        core_position_scrambling: float = 0,
-        index_scrambling: float = 0,
-        resolution: int = 150,
-        rotation: float = 0,
-        boundary_pad_factor: float = 1.2,
-        gaussian_filter: float = 0,
-        background_index: float = 1) -> Geometry:
-    """
-    Prepares and returns the simulation geometry for optical fiber configurations,
-    incorporating fused structures, optional capillary tubes, and specific boundary conditions.
-
-    Args:
-        wavelength (float): Wavelength for refractive index calculation.
-        clad_structure (object): Cladding or structural template for fibers.
-        fiber_list (List[object]): List of fibers to be included in the simulation.
-        capillary_tube (Optional[object]): Optional capillary structure to add.
-        fusion_degree (Union[float, str]): Degree of fusion, specifying overlap between fibers.
-        fiber_radius (Optional[float]): Uniform radius for all fibers, if specified.
-        x_bounds (Union[str, List[float]]): X-axis boundary conditions or limits.
-        y_bounds (Union[str, List[float]]): Y-axis boundary conditions or limits.
-        clad_index (Union[float, str]): Refractive index for the cladding material, can be a known string identifier.
-        core_position_scrambling (float): Random displacement added to fiber core positions to simulate imperfections.
-        index_scrambling (float): Noise level to simulate index inhomogeneity.
-        resolution (int): Resolution of the geometry mesh grid.
-        rotation (float): Rotation angle for the structure (degrees).
-        boundary_pad_factor (float): Padding factor for boundary adjustments.
-        gaussian_filter (float): Standard deviation for Gaussian blur to smooth sharp transitions.
-        background_index (float): Background refractive index for the simulation area.
-
-    Returns:
-        Geometry: Configured geometry object ready for simulation.
-    """
-    if isinstance(clad_index, str) and clad_index.lower() == 'silica':
-        index = fiber_catalogue.get_silica_index(wavelength=wavelength)
-    elif isinstance(clad_index, (float, int)):
-        index = clad_index
-    else:
-        raise ValueError("Invalid clad_index: must be either 'silica' or a numeric index value.")
-
-    background = BackGround(index=background_index)
-
-    clad_instance = prepare_fused_structure(
-        clad_class=clad_structure,
-        fiber_radius=fiber_radius,
-        fusion_degree=fusion_degree,
-        index=index,
-        core_position_scrambling=core_position_scrambling,
-        rotation=rotation
-    )
-
-    geometry = Geometry(
-        background=background,
-        x_bounds=x_bounds,
-        y_bounds=y_bounds,
-        resolution=resolution,
-        index_scrambling=index_scrambling,
-        boundary_pad_factor=boundary_pad_factor,
-        gaussian_filter=gaussian_filter
-    )
-
-    if capillary_tube is not None:
-        geometry.add_structure(capillary_tube)
-
-    if clad_instance is not None:
-        geometry.add_structure(clad_instance)
-
-    if clad_instance is not None:
-        for fiber, core in zip(fiber_list, clad_instance.cores):
-            fiber.set_position(core)
-
-    geometry.add_fiber(*fiber_list)
-
-    return geometry
-
-
-def prepare_fused_structure(
-        clad_class: type,
-        fiber_radius: float,
-        fusion_degree: float,
-        index: float,
-        core_position_scrambling: float,
-        rotation: float) -> object:
-    """
-    Prepare and returns a clad instance according to the clad class given as input.
-
-    :param      clad_class:                The clad class
-    :type       clad_class:                type
-    :param      fiber_radius:              The fiber radius
-    :type       fiber_radius:              float
-    :param      fusion_degree:             The fusion degree
-    :type       fusion_degree:             float
-    :param      index:                     The index
-    :type       index:                     float
-    :param      core_position_scrambling:  The core position scrambling
-    :type       core_position_scrambling:  float
-    :param      rotation:                  The rotation
-    :type       rotation:                  float
-
-    :returns:   The clad instance
-    :rtype:     object
-    """
-    if clad_class is None:
-        return None
-
-    clad_instance = clad_class(
-        fiber_radius=fiber_radius,
-        fusion_degree=fusion_degree,
-        index=index,
-        core_position_scrambling=core_position_scrambling
-    )
-
-    if rotation != 0:
-        clad_instance.rotate(rotation)
-
-    return clad_instance
-
-
-@dataclass
-class Workflow():
-    """
-    A class to configure and execute optical simulations using finite difference methods on specified fiber geometries.
-
-    Attributes:
-        wavelength (float): Wavelength at which the simulation is evaluated.
-        resolution (int): Resolution of the simulation mesh.
-        fiber_radius (float): Radius for the fused clad structure.
-        n_sorted_mode (int): Number of modes that are computed and sorted.
-        n_added_mode (int): Additional modes computed beyond the sorted modes for increased accuracy.
-        itr_final (float): Final Inverse Taper Ratio (ITR) for mode evaluation.
-        itr_initial (float): Initial ITR for mode evaluation.
-        n_step (int): Number of steps to iterate through the ITR section.
-        fusion_degree (Union[float, str]): Fusion degree for the clad fused structure; 'auto' for automatic calculation.
-        clad_rotation (float): Rotation of the clad structure in degrees.
-        accuracy (int): Accuracy level of the finite difference method.
-        debug_mode (int): Debug mode level for verbose output during computations.
-        auto_label (bool): If True, automatically labels supermodes.
-        generate_report (bool): If True, generates a PDF report of the simulation results.
-        save_superset (bool): If True, saves the computed superset instance for later use.
-        fiber_list (List[object]): List of fibers included in the optical structure.
-        boundaries (List[Boundaries]): Boundary conditions applied to the simulation.
-        capillary_tube (Optional[object]): Additional capillary structure to include in the simulation.
-        clad_structure (Optional[object]): Initial optical structure used for the simulation.
-        x_bounds (str): Boundary conditions along the x-axis.
-        y_bounds (str): Boundary conditions along the y-axis.
-        air_padding_factor (float): Factor for padding the structure with air to prevent boundary effects.
-        gaussian_filter_factor (Optional[float]): Gaussian blurring factor applied to the structure for smoothing.
-
-    Plotting Flags:
-        Various flags that determine which aspects of the simulation are plotted.
-
-    Methods:
-        __post_init__: Initializes the simulation geometry and solver upon object creation.
-        plot: Plots various simulation outputs based on the provided plot type.
-        save_superset_instance: Saves the computed superset to a file for later use.
-        generate_pdf_report: Generates a comprehensive PDF report of all relevant simulation data and results.
-        _get_auto_generated_filename: Generates a filename based on the simulation parameters.
-    """
-
-    #  Geometry arguments --------------------------
-    wavelength: float
-    clad_rotation: float = 0
-    capillary_tube: object = None
-    resolution: int = 100
-    clad_structure: object = None
-    fiber_list: list = tuple()
-    fiber_radius: float = 62.5e-6
-    fusion_degree: float = 'auto'
-    x_bounds: str = ''
-    y_bounds: str = ''
-    air_padding_factor: float = 1.2
-    gaussian_filter_factor: float = None
-
-    #  Solver arguments --------------------------
-    n_sorted_mode: int = 4
-    n_added_mode: int = 4
-    itr_final: float = 0.05
-    itr_initial: float = 1.0
-    n_step: int = 500
-    extrapolation_order: int = 2
-    core_position_scrambling: float = 0
-    index_scrambling: float = 0
-    boundaries: list = (Boundaries(),)
-    accuracy: int = 2
-
-    #  Plot arguments --------------------------
-    plot_geometry: bool = False
-    plot_cladding: bool = False
-    plot_field: bool = False
-    plot_adiabatic: bool = False
-    plot_coupling: bool = False
-    plot_beating_length: bool = False
-    plot_eigen_values: bool = False
-    plot_index: bool = False
-    plot_beta: bool = False
-
-    #  Extra arguments --------------------------
-    debug_mode: int = 1
-    auto_label: bool = False
-    generate_report: bool = False
-    save_superset: bool = False
-
-    def __post_init__(self):
-        """Initializes the simulation geometry and solver, and optionally plots the initial setup if enabled."""
-        self.geometry = prepare_simulation_geometry(
-            wavelength=self.wavelength,
-            clad_structure=self.clad_structure,
-            fiber_list=self.fiber_list,
-            capillary_tube=self.capillary_tube,
-            fusion_degree=self.fusion_degree,
-            fiber_radius=self.fiber_radius,
-            resolution=self.resolution,
-            y_bounds=self.y_bounds,
-            x_bounds=self.x_bounds,
-            rotation=self.clad_rotation,
-            gaussian_filter=self.gaussian_filter_factor
-        )
-
-        if self.plot_cladding:
-            self.clad_structure.plot().show()
-
-        if self.plot_geometry:
-            self.geometry.plot().show()
-
-        self._initialize_solver_()
-
-        if self.plot_field:
-            self.plot(plot_type='field').show()
-
-        if self.plot_adiabatic:
-            self.plot(plot_type='adiabatic').show()
-
-        if self.plot_coupling:
-            self.plot(plot_type='normalized-coupling').show()
-
-        if self.plot_beating_length:
-            self.plot(plot_type='beating-length').show()
-
-        if self.plot_eigen_values:
-            self.plot(plot_type='eigen-value').show()
-
-        if self.plot_index:
-            self.plot(plot_type='index').show()
-
-        if self.plot_beta:
-            self.plot(plot_type='beta').show()
-
-        if self.generate_report:
-            self.generate_pdf_report()
-
-        if self.save_superset:
-            self.save_superset_instance()
-
-    @property
-    def superset(self):
-        return self.solver.superset
-
-    def _initialize_solver_(self) -> None:
-        """Initializes the solver with the set geometry and starts the mode computation process."""
-
-        self.solver = SuPySolver(
-            geometry=self.geometry,
-            tolerance=1e-20,
-            max_iter=5000,
-            accuracy=self.accuracy,
-            debug_mode=self.debug_mode,
-            extrapolation_order=self.extrapolation_order
-        )
-
-        self.solver.init_superset(
-            wavelength=self.wavelength,
-            n_step=self.n_step,
-            itr_initial=self.itr_initial,
-            itr_final=self.itr_final
-        )
-
-        for boundary in self.boundaries:
-            self.solver.add_modes(
-                n_added_mode=self.n_added_mode,
-                n_sorted_mode=self.n_sorted_mode,
-                boundaries=boundary,
-                auto_label=self.auto_label
-            )
-
-        self.solver.superset.sort_modes(sorting_method='beta')
-
-    def get_superset(self):
-        return self.solver.superset
-
-    def _get_auto_generated_filename_(self) -> str:
-        """
-        Returns an auton-generated filename taking account for:
-        |  structure name
-        |  fiber names
-        |  resolution of the simulations
-        |  wavelength
-
-        :returns:   The automatic generated filename.
-        :rtype:     str
-        """
-        fiber_name = "".join(fiber.__class__.__name__ for fiber in self.fiber_list)
-
-        filename = (
-            f"structure={self.clad_structure.__class__.__name__}_"
-            f"{fiber_name}_"
-            f"resolution={self.resolution}_"
-            f'wavelength={self.wavelength}'
-        )
-
-        return filename.replace('.', '_')
-
-    def save_superset_instance(self, filename: str = 'auto', directory: str = 'auto') -> Path:
-        """Saves the superset instance to a file, defaulting to an auto-generated filename if not specified."""
-        if filename == 'auto':
-            filename = self._get_auto_generated_filename_()
-
-        filename = Path(filename + '.pdf')
-
-        filename = sanitize_filepath(filename)
-
-        self.solver.superset.save_instance(
-            filename=filename,
-            directory=directory
-        )
-
-        return filename
-
-    def generate_pdf_report(self, filename: str = 'auto', **kwargs) -> Path:
-        """
-        Generate a pdf file compiling the essential computed components.
-
-        :param      filename:  The filename
-        :type       filename:  str
-        :param      kwargs:    The keywords arguments
-        :type       kwargs:    dictionary
-
-        :returns:   The path directory of the report
-        :rtype:     Path
-        """
-        if filename == 'auto':
-            filename = self._get_auto_generated_filename_()
-
-        filename = Path(filename).with_suffix('.pdf')
-
-        filename = sanitize_filepath(filename)
-
-        self.solver.superset.generate_pdf_report(filename=filename, **kwargs)
-
-        return filename
-
-    def plot(self, *args, **kwargs):
-        """Plots various types of data from the simulation based on the specified plot type."""
-
-        return self.solver.superset.plot(*args, **kwargs)
-
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+from typing import List, Union, Optional
+from pathlib import Path
+
+from FiberFusing import Geometry, BackGround
+from FiberFusing.fiber.base_class import GenericFiber
+from SuPyMode.solver import SuPySolver
+from FiberFusing.fiber import catalogue as fiber_catalogue
+from SuPyMode.profiles import AlphaProfile  # noqa: F401
+from FiberFusing import configuration  # noqa: F401
+
+from PyFinitDiff.finite_difference_2D import Boundaries
+from pathvalidate import sanitize_filepath
+from pydantic.dataclasses import dataclass
+
+
+def prepare_simulation_geometry(
+        wavelength: float,
+        clad_structure: object,
+        fiber_list: List[object],
+        capillary_tube: Optional[object] = None,
+        fusion_degree: Union[float, str] = 'auto',
+        fiber_radius: Optional[float] = None,
+        x_bounds: Union[str, List[float]] = '',
+        y_bounds: Union[str, List[float]] = '',
+        clad_index: Union[float, str] = 'silica',
+        core_position_scrambling: float = 0,
+        index_scrambling: float = 0,
+        resolution: int = 150,
+        rotation: float = 0,
+        boundary_pad_factor: float = 1.2,
+        gaussian_filter: float = 0,
+        background_index: float = 1) -> Geometry:
+    """
+    Prepares and returns the simulation geometry for optical fiber configurations,
+    incorporating fused structures, optional capillary tubes, and specific boundary conditions.
+
+    Args:
+        wavelength (float): Wavelength for refractive index calculation.
+        clad_structure (object): Cladding or structural template for fibers.
+        fiber_list (List[object]): List of fibers to be included in the simulation.
+        capillary_tube (Optional[object]): Optional capillary structure to add.
+        fusion_degree (Union[float, str]): Degree of fusion, specifying overlap between fibers.
+        fiber_radius (Optional[float]): Uniform radius for all fibers, if specified.
+        x_bounds (Union[str, List[float]]): X-axis boundary conditions or limits.
+        y_bounds (Union[str, List[float]]): Y-axis boundary conditions or limits.
+        clad_index (Union[float, str]): Refractive index for the cladding material, can be a known string identifier.
+        core_position_scrambling (float): Random displacement added to fiber core positions to simulate imperfections.
+        index_scrambling (float): Noise level to simulate index inhomogeneity.
+        resolution (int): Resolution of the geometry mesh grid.
+        rotation (float): Rotation angle for the structure (degrees).
+        boundary_pad_factor (float): Padding factor for boundary adjustments.
+        gaussian_filter (float): Standard deviation for Gaussian blur to smooth sharp transitions.
+        background_index (float): Background refractive index for the simulation area.
+
+    Returns:
+        Geometry: Configured geometry object ready for simulation.
+
+    Raises:
+        ValueError: If clad_index is not 'silica' or a numeric value.
+    """
+
+    def get_clad_index(clad_index: float, wavelength: float):
+        """Retrieve the cladding index based on the input type."""
+        if isinstance(clad_index, str) and clad_index.lower() == 'silica':
+            return fiber_catalogue.get_silica_index(wavelength=wavelength)
+        elif isinstance(clad_index, (float, int)):
+            return clad_index
+        else:
+            raise ValueError("Invalid clad_index: must be either 'silica' or a numeric index value.")
+
+    index = get_clad_index(clad_index, wavelength)
+    background = BackGround(index=background_index)
+
+    clad_instance = prepare_fused_structure(
+        clad_class=clad_structure,
+        fiber_radius=fiber_radius,
+        fusion_degree=fusion_degree,
+        index=index,
+        core_position_scrambling=core_position_scrambling,
+        rotation=rotation
+    )
+
+    geometry = Geometry(
+        background=background,
+        x_bounds=x_bounds,
+        y_bounds=y_bounds,
+        resolution=resolution,
+        index_scrambling=index_scrambling,
+        boundary_pad_factor=boundary_pad_factor,
+        gaussian_filter=gaussian_filter
+    )
+
+    if capillary_tube is not None:
+        geometry.add_structure(capillary_tube)
+
+    if clad_instance is not None:
+        geometry.add_structure(clad_instance)
+
+    if clad_instance is not None:
+        for fiber, core in zip(fiber_list, clad_instance.cores):
+            fiber.set_position(core)
+
+    geometry.add_fiber(*fiber_list)
+
+    return geometry
+
+
+def prepare_fused_structure(
+        clad_class: type,
+        fiber_radius: float,
+        fusion_degree: float | str,
+        index: float,
+        core_position_scrambling: float,
+        rotation: float) -> Optional[object]:
+    """
+    Prepares and returns a clad instance according to the provided clad class and configuration parameters.
+
+    Args:
+        clad_class (type): The class representing the cladding structure.
+        fiber_radius (float): The radius of the fiber.
+        fusion_degree (float): The degree of fusion for the fibers.
+        index (float): The refractive index of the cladding material.
+        core_position_scrambling (float): Random displacement added to fiber core positions to simulate imperfections.
+        rotation (float): Rotation angle for the structure (in degrees).
+
+    Returns:
+        Optional[object]: An instance of the clad structure configured with the provided parameters, or None if no clad class is provided.
+
+    Raises:
+        ValueError: If any of the required parameters are not provided or invalid.
+    """
+    if clad_class is None:
+        return None
+
+    clad_instance = clad_class(
+        fiber_radius=fiber_radius,
+        fusion_degree=fusion_degree,
+        index=index,
+        core_position_scrambling=core_position_scrambling
+    )
+
+    if rotation != 0:
+        clad_instance.rotate(rotation)
+
+    return clad_instance
+
+
+@dataclass
+class Workflow():
+    """
+    Configures and executes optical simulations using finite difference methods on specified fiber geometries.
+
+    Attributes:
+        wavelength (float): Wavelength at which the simulation is evaluated.
+        resolution (int): Resolution of the simulation mesh.
+        fiber_radius (float): Radius for the fused clad structure.
+        n_sorted_mode (int): Number of modes that are computed and sorted.
+        n_added_mode (int): Additional modes computed beyond the sorted modes for increased accuracy.
+        itr_final (float): Final Inverse Taper Ratio (ITR) for mode evaluation.
+        itr_initial (float): Initial ITR for mode evaluation.
+        n_step (int): Number of steps to iterate through the ITR section.
+        fusion_degree (Union[float, str]): Fusion degree for the clad fused structure; 'auto' for automatic calculation.
+        clad_rotation (float): Rotation of the clad structure in degrees.
+        accuracy (int): Accuracy level of the finite difference method.
+        debug_mode (int): Debug mode level for verbose output during computations.
+        auto_label (bool): If True, automatically labels supermodes.
+        generate_report (bool): If True, generates a PDF report of the simulation results.
+        save_superset (bool): If True, saves the computed superset instance for later use.
+        fiber_list (List[GenericFiber]): List of fibers included in the optical structure.
+        boundaries (List[Boundaries]): Boundary conditions applied to the simulation.
+        capillary_tube (Optional[object]): Additional capillary structure to include in the simulation.
+        clad_structure (Optional[object]): Initial optical structure used for the simulation.
+        x_bounds (Union[str, List[float]]): Boundary conditions along the x-axis.
+        y_bounds (Union[str, List[float]]): Boundary conditions along the y-axis.
+        air_padding_factor (float): Factor for padding the structure with air to prevent boundary effects.
+        gaussian_filter_factor (Optional[float]): Gaussian blurring factor applied to the structure for smoothing.
+
+    Plotting Flags:
+        plot_geometry (bool): If True, plots the simulation geometry.
+        plot_cladding (bool): If True, plots the cladding structure.
+        plot_field (bool): If True, plots the field distribution.
+        plot_adiabatic (bool): If True, plots adiabatic transitions.
+        plot_coupling (bool): If True, plots coupling information.
+        plot_beating_length (bool): If True, plots the beating length.
+        plot_eigen_values (bool): If True, plots eigenvalues.
+        plot_index (bool): If True, plots the refractive index distribution.
+        plot_beta (bool): If True, plots propagation constants.
+
+    Methods:
+        __post_init__: Initializes the simulation geometry and solver upon object creation.
+        plot: Plots various simulation outputs based on the provided plot type.
+        save_superset_instance: Saves the computed superset to a file for later use.
+        generate_pdf_report: Generates a comprehensive PDF report of all relevant simulation data and results.
+        _get_auto_generated_filename: Generates a filename based on the simulation parameters.
+    """
+
+    # Geometry attributes
+    wavelength: float
+    boundaries: List[Boundaries]
+    clad_rotation: float = 0
+    capillary_tube: Optional[object] = None
+    resolution: int = 100
+    clad_structure: Optional[object] = None
+    fiber_list: List[GenericFiber] = ()
+    fiber_radius: float = 62.5e-6
+    fusion_degree: Union[float, str] = 'auto'
+    x_bounds: Union[str, List[float]] = ''
+    y_bounds: Union[str, List[float]] = ''
+    air_padding_factor: float = 1.2
+    gaussian_filter_factor: Optional[float] = None
+
+    # Solver attributes
+    n_sorted_mode: int = 4
+    n_added_mode: int = 4
+    itr_final: float = 0.05
+    itr_initial: float = 1.0
+    n_step: int = 500
+    extrapolation_order: int = 2
+    core_position_scrambling: float = 0
+    index_scrambling: float = 0
+    accuracy: int = 2
+
+    # Plotting flags
+    plot_geometry: bool = False
+    plot_cladding: bool = False
+    plot_field: bool = False
+    plot_adiabatic: bool = False
+    plot_coupling: bool = False
+    plot_beating_length: bool = False
+    plot_eigen_values: bool = False
+    plot_index: bool = False
+    plot_beta: bool = False
+
+    # Extra attributes
+    debug_mode: int = 1
+    auto_label: bool = False
+    generate_report: bool = False
+    save_superset: bool = False
+
+    def __post_init__(self):
+        """
+        Initializes the simulation geometry and solver, and optionally plots the initial setup if enabled.
+        """
+        self.geometry = self.prepare_simulation_geometry()
+        self._plot_initial_setup()
+        self._initialize_solver()
+        self._plot_simulation_outputs()
+        self._finalize_workflow()
+
+    def prepare_simulation_geometry(self):
+        """Prepares the simulation geometry."""
+        return prepare_simulation_geometry(
+            wavelength=self.wavelength,
+            clad_structure=self.clad_structure,
+            fiber_list=self.fiber_list,
+            capillary_tube=self.capillary_tube,
+            fusion_degree=self.fusion_degree,
+            fiber_radius=self.fiber_radius,
+            resolution=self.resolution,
+            y_bounds=self.y_bounds,
+            x_bounds=self.x_bounds,
+            rotation=self.clad_rotation,
+            gaussian_filter=self.gaussian_filter_factor
+        )
+
+    def _plot_initial_setup(self):
+        """Plots the initial simulation setup if the respective flags are enabled."""
+        if self.plot_cladding and self.clad_structure:
+            self.clad_structure.plot().show()
+        if self.plot_geometry:
+            self.geometry.plot().show()
+
+    @property
+    def superset(self):
+        return self.solver.superset
+
+    def _initialize_solver(self):
+        """Initializes the solver with the set geometry and starts the mode computation process."""
+        self.solver = SuPySolver(
+            geometry=self.geometry,
+            tolerance=1e-20,
+            max_iter=5000,
+            accuracy=self.accuracy,
+            debug_mode=self.debug_mode,
+            extrapolation_order=self.extrapolation_order
+        )
+
+        self.solver.init_superset(
+            wavelength=self.wavelength,
+            n_step=self.n_step,
+            itr_initial=self.itr_initial,
+            itr_final=self.itr_final
+        )
+
+        for boundary in self.boundaries:
+            self.solver.add_modes(
+                n_added_mode=self.n_added_mode,
+                n_sorted_mode=self.n_sorted_mode,
+                boundaries=boundary,
+                auto_label=self.auto_label
+            )
+
+    def get_superset(self):
+        return self.solver.superset
+
+    def _plot_simulation_outputs(self):
+        """Plots the simulation outputs based on the respective flags."""
+        if self.plot_field:
+            self.plot('field').show()
+        if self.plot_adiabatic:
+            self.plot('adiabatic').show()
+        if self.plot_coupling:
+            self.plot('normalized-coupling').show()
+        if self.plot_beating_length:
+            self.plot('beating-length').show()
+        if self.plot_eigen_values:
+            self.plot('eigen-value').show()
+        if self.plot_index:
+            self.plot('index').show()
+        if self.plot_beta:
+            self.plot('beta').show()
+
+    def _finalize_workflow(self):
+        """Finalizes the workflow by generating reports and saving superset if enabled."""
+        if self.generate_report:
+            self.generate_pdf_report()
+        if self.save_superset:
+            self.save_superset_instance()
+
+    def plot(self, *args, **kwargs):
+        """Plots various types of data from the simulation based on the specified plot type."""
+        return self.solver.superset.plot(*args, **kwargs)
+
+    def save_superset_instance(self, filename: str = 'auto', directory: str = 'auto') -> Path:
+        """
+        Saves the superset instance to a file, defaulting to an auto-generated filename if not specified.
+
+        Args:
+            filename (str): Filename for the saved instance.
+            directory (str): Directory for saving the instance.
+
+        Returns:
+            Path: Path to the saved file.
+        """
+        if filename == 'auto':
+            filename = self._get_auto_generated_filename()
+        filename = Path(filename + '.pdf').with_suffix('.pdf')
+        filename = sanitize_filepath(filename)
+        self.solver.superset.save_instance(filename=filename, directory=directory)
+        return filename
+
+    def generate_pdf_report(self, filename: str = 'auto', **kwargs) -> Path:
+        """
+        Generates a PDF report of all relevant simulation data and results.
+
+        Args:
+            filename (str): Filename for the report.
+            **kwargs: Additional arguments for the report generation.
+
+        Returns:
+            Path: Path to the generated PDF report.
+        """
+        if filename == 'auto':
+            filename = self._get_auto_generated_filename()
+        filename = Path(filename).with_suffix('.pdf')
+        filename = sanitize_filepath(filename)
+        self.solver.superset.generate_pdf_report(filename=filename, **kwargs)
+        return filename
+
+    def _get_auto_generated_filename(self) -> str:
+        """
+        Generates a filename based on the simulation parameters.
+
+        Returns:
+            str: Automatically generated filename.
+        """
+        fiber_name = "".join(fiber.__class__.__name__ for fiber in self.fiber_list)
+        filename = (
+            f"structure={self.clad_structure.__class__.__name__}_"
+            f"{fiber_name}_"
+            f"resolution={self.resolution}_"
+            f"wavelength={self.wavelength}"
+        )
+        return filename.replace('.', '_')
+
+# -
```

## SuPyMode/binary/__init__.py

```diff
@@ -1 +1 @@
-00000000: 0d0a                                     ..
+00000000: 0a                                       .
```

## SuPyMode/representation/__init__.py

 * *Ordering differences only*

```diff
@@ -1,13 +1,13 @@
-from .adiabatic import Adiabatic
-
-from .index import Index
-
-from .beating_length import BeatingLength
-
-from .eigen_value import EigenValue
-
-from .field import Field
-
-from .beta import Beta
-
+from .adiabatic import Adiabatic
+
+from .index import Index
+
+from .beating_length import BeatingLength
+
+from .eigen_value import EigenValue
+
+from .field import Field
+
+from .beta import Beta
+
 from .normalized_coupling import NormalizedCoupling
```

## SuPyMode/representation/adiabatic.py

 * *Ordering differences only*

```diff
@@ -1,107 +1,107 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-import numpy
-
-from SuPyMode.representation.base import InheritFromSuperMode, BaseMultiModePlot
-from MPSPlots.render2D import SceneList, Axis
-
-
-class Adiabatic(InheritFromSuperMode, BaseMultiModePlot):
-    """
-    Represents the adiabatic criterion between modes of different supermodes in optical fiber simulations.
-
-    This class extends from `InheritFromSuperMode` for accessing supermode-related data and `BaseMultiModePlot`
-    for plotting functionalities tailored to visualize adiabatic transition measurements.
-
-    Class Attributes:
-        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
-    """
-
-    plot_style = dict(
-        show_legend=True,
-        x_label='Inverse taper ratio',
-        y_label=r'Adiabatic criterion [$\mu$m$^{-1}$]',
-        y_scale='log',
-        y_scale_factor=1e-6,
-        y_limits=[1e-5, 1],
-        line_width=2
-    )
-
-    def __init__(self, parent_supermode: SuperMode):
-        """
-        Initializes an Adiabatic object with a reference to a parent supermode.
-
-        Args:
-            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
-        """
-        self.parent_supermode = parent_supermode
-
-    def get_values(self, other_supermode: SuperMode) -> numpy.ndarray:
-        """
-        Calculates the adiabatic transition measure between the parent supermode and another specified supermode.
-
-        Args:
-            other_supermode (SuperMode): The supermode with which to compare the parent supermode.
-
-        Returns:
-            numpy.ndarray: An array of adiabatic transition measures calculated between the two supermodes,
-                           possibly adjusted by compatibility considerations.
-        """
-        output = self.parent_supermode.binded_supermode.get_adiabatic_with_mode(other_supermode.binded_supermode)
-
-        if not self.parent_supermode.is_computation_compatible(other_supermode):
-            output *= numpy.inf
-
-        return output
-
-    def render_on_ax(self, ax: Axis, other_supermode: SuperMode) -> None:
-        """
-        Renders adiabatic transition data as a line plot on the provided Axis object, comparing the parent supermode
-        with another supermode.
-
-        Args:
-            ax (Axis): The Axis object on which to plot the adiabatic transitions.
-            other_supermode (SuperMode): The other supermode to compare against.
-
-        Note:
-            This method is conditioned on computational compatibility between the supermodes.
-        """
-        if not self.parent_supermode.is_computation_compatible(other_supermode):
-            return
-
-        y = self.get_values(other_supermode=other_supermode)
-
-        ax.add_line(
-            x=self.itr_list,
-            y=numpy.abs(y),
-            label=f'{self.parent_supermode.stylized_label} - {other_supermode.stylized_label}'
-        )
-
-    def plot(self, other_supermode: SuperMode) -> SceneList:
-        """
-        Generates a plot of adiabatic transitions between the parent supermode and another specified supermode using a SceneList.
-
-        This method creates a single-axis plot showing the comparative adiabatic transitions as a function of the inverse taper ratio,
-        formatted according to the predefined plot style.
-
-        Args:
-            other_supermode (SuperMode): The supermode to compare against.
-
-        Returns:
-            SceneList: A scene list containing the plot of adiabatic transitions.
-        """
-        figure = SceneList()
-
-        ax = figure.append_ax(**self.plot_style)
-
-        self.render_on_ax(ax=ax, other_supermode=other_supermode)
-
-        return figure
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+import numpy
+
+from SuPyMode.representation.base import InheritFromSuperMode, BaseMultiModePlot
+from MPSPlots.render2D import SceneList, Axis
+
+
+class Adiabatic(InheritFromSuperMode, BaseMultiModePlot):
+    """
+    Represents the adiabatic criterion between modes of different supermodes in optical fiber simulations.
+
+    This class extends from `InheritFromSuperMode` for accessing supermode-related data and `BaseMultiModePlot`
+    for plotting functionalities tailored to visualize adiabatic transition measurements.
+
+    Class Attributes:
+        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
+    """
+
+    plot_style = dict(
+        show_legend=True,
+        x_label='Inverse taper ratio',
+        y_label=r'Adiabatic criterion [$\mu$m$^{-1}$]',
+        y_scale='log',
+        y_scale_factor=1e-6,
+        y_limits=[1e-5, 1],
+        line_width=2
+    )
+
+    def __init__(self, parent_supermode: SuperMode):
+        """
+        Initializes an Adiabatic object with a reference to a parent supermode.
+
+        Args:
+            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
+        """
+        self.parent_supermode = parent_supermode
+
+    def get_values(self, other_supermode: SuperMode) -> numpy.ndarray:
+        """
+        Calculates the adiabatic transition measure between the parent supermode and another specified supermode.
+
+        Args:
+            other_supermode (SuperMode): The supermode with which to compare the parent supermode.
+
+        Returns:
+            numpy.ndarray: An array of adiabatic transition measures calculated between the two supermodes,
+                           possibly adjusted by compatibility considerations.
+        """
+        output = self.parent_supermode.binded_supermode.get_adiabatic_with_mode(other_supermode.binded_supermode)
+
+        if not self.parent_supermode.is_computation_compatible(other_supermode):
+            output *= numpy.inf
+
+        return output
+
+    def render_on_ax(self, ax: Axis, other_supermode: SuperMode) -> None:
+        """
+        Renders adiabatic transition data as a line plot on the provided Axis object, comparing the parent supermode
+        with another supermode.
+
+        Args:
+            ax (Axis): The Axis object on which to plot the adiabatic transitions.
+            other_supermode (SuperMode): The other supermode to compare against.
+
+        Note:
+            This method is conditioned on computational compatibility between the supermodes.
+        """
+        if not self.parent_supermode.is_computation_compatible(other_supermode):
+            return
+
+        y = self.get_values(other_supermode=other_supermode)
+
+        ax.add_line(
+            x=self.itr_list,
+            y=numpy.abs(y),
+            label=f'{self.parent_supermode.stylized_label} - {other_supermode.stylized_label}'
+        )
+
+    def plot(self, other_supermode: SuperMode) -> SceneList:
+        """
+        Generates a plot of adiabatic transitions between the parent supermode and another specified supermode using a SceneList.
+
+        This method creates a single-axis plot showing the comparative adiabatic transitions as a function of the inverse taper ratio,
+        formatted according to the predefined plot style.
+
+        Args:
+            other_supermode (SuperMode): The supermode to compare against.
+
+        Returns:
+            SceneList: A scene list containing the plot of adiabatic transitions.
+        """
+        figure = SceneList()
+
+        ax = figure.append_ax(**self.plot_style)
+
+        self.render_on_ax(ax=ax, other_supermode=other_supermode)
+
+        return figure
+
+# -
```

## SuPyMode/representation/base.py

 * *Ordering differences only*

```diff
@@ -1,145 +1,145 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-
-import numpy
-from MPSPlots.render2D import SceneList, Axis
-
-
-class BaseMultiModePlot():
-    def _render_on_ax_(self, ax: Axis, other_supermode: SuperMode = None):
-        if other_supermode is None:
-            other_supermode = self.parent_supermode.parent_set.supermodes
-        else:
-            other_supermode = numpy.atleast_1d(other_supermode)
-
-        for mode in other_supermode:
-            if mode.ID == self.ID or mode.solver_number != self.solver_number:
-                continue
-
-            ax.add_line(
-                x=self.itr_list,
-                y=self.get_values(mode),
-                label=f'{self.stylized_label} - {mode.stylized_label}'
-            )
-
-            ax.set_style(**self.plot_style)
-
-    def plot(
-            self,
-            other_supermode: SuperMode = None,
-            row: int = 0,
-            col: int = 0) -> None:
-        """
-        Plotting method for the index.
-
-        :param      slice_list:  Value reprenting the slice where the mode field is evaluated.
-        :type       slice_list:  list
-        :param      itr_list:    Value of itr value to evaluate the mode field.
-        :type       itr_list:    list
-
-        :returns:   the figure containing all the plots.
-        :rtype:     SceneList
-        """
-        figure = SceneList(unit_size=(10, 4), tight_layout=True)
-
-        ax = figure.append_ax()
-
-        self._render_on_ax_(ax=ax, other_supermode=other_supermode)
-
-        return figure
-
-
-class BaseSingleModePlot():
-    def __getitem__(self, idx):
-        return self._data[idx]
-
-    def _render_on_ax_(self, ax: Axis) -> None:
-        self._set_axis_(ax)
-
-        ax.set_style(self.plot_style)
-
-        ax.add_line(x=self.itr_list, y=self._data, label=self.stylized_label)
-
-    def plot(self, row: int = 0, col: int = 0) -> None:
-        """
-        Plotting method for the index.
-
-        :param      slice_list:  Value reprenting the slice where the mode field is evaluated.
-        :type       slice_list:  list
-        :param      itr_list:    Value of itr value to evaluate the mode field.
-        :type       itr_list:    list
-
-        :returns:   the figure containing all the plots.
-        :rtype:     SceneList
-        """
-        figure = SceneList(unit_size=(10, 4), tight_layout=True)
-
-        ax = figure.append_ax()
-
-        self._render_on_ax_(ax)
-
-        return figure
-
-
-class InheritFromSuperMode():
-    def _set_axis_(self, ax: Axis):
-        for element, value in self.plot_style.items():
-            setattr(ax, element, value)
-
-    def __getitem__(self, idx):
-        return self._data[idx]
-
-    @property
-    def mode_number(self) -> int:
-        return self.parent_supermode.mode_number
-
-    @property
-    def solver_number(self) -> int:
-        return self.parent_supermode.solver_number
-
-    @property
-    def axes(self):
-        return self.parent_supermode.axes
-
-    @property
-    def boundaries(self):
-        return self.parent_supermode.boundaries
-
-    @property
-    def itr_list(self):
-        return self.parent_supermode.itr_list
-
-    @property
-    def ID(self):
-        return self.parent_supermode.ID
-
-    @property
-    def label(self):
-        return self.parent_supermode.label
-
-    @property
-    def stylized_label(self):
-        return self.parent_supermode.stylized_label
-
-    def slice_to_itr(self, slice: list = []):
-        return self.parent_supermode.parent_set.slice_to_itr(slice)
-
-    def itr_to_slice(self, itr: list = []):
-        return self.parent_supermode.parent_set.itr_to_slice(itr)
-
-    def _get_symmetrize_vector(self, *args, **kwargs):
-        return self.parent_supermode._get_symmetrize_vector(*args, **kwargs)
-
-    def _get_axis_vector(self, *args, **kwargs):
-        return self.parent_supermode._get_axis_vector(*args, **kwargs)
-
-    def get_axis(self, *args, **kwargs):
-        return self.parent_supermode.get_axis(*args, **kwargs)
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+
+import numpy
+from MPSPlots.render2D import SceneList, Axis
+
+
+class BaseMultiModePlot():
+    def _render_on_ax_(self, ax: Axis, other_supermode: SuperMode = None):
+        if other_supermode is None:
+            other_supermode = self.parent_supermode.parent_set.supermodes
+        else:
+            other_supermode = numpy.atleast_1d(other_supermode)
+
+        for mode in other_supermode:
+            if mode.ID == self.ID or mode.solver_number != self.solver_number:
+                continue
+
+            ax.add_line(
+                x=self.itr_list,
+                y=self.get_values(mode),
+                label=f'{self.stylized_label} - {mode.stylized_label}'
+            )
+
+            ax.set_style(**self.plot_style)
+
+    def plot(
+            self,
+            other_supermode: SuperMode = None,
+            row: int = 0,
+            col: int = 0) -> None:
+        """
+        Plotting method for the index.
+
+        :param      slice_list:  Value reprenting the slice where the mode field is evaluated.
+        :type       slice_list:  list
+        :param      itr_list:    Value of itr value to evaluate the mode field.
+        :type       itr_list:    list
+
+        :returns:   the figure containing all the plots.
+        :rtype:     SceneList
+        """
+        figure = SceneList(unit_size=(10, 4), tight_layout=True)
+
+        ax = figure.append_ax()
+
+        self._render_on_ax_(ax=ax, other_supermode=other_supermode)
+
+        return figure
+
+
+class BaseSingleModePlot():
+    def __getitem__(self, idx):
+        return self._data[idx]
+
+    def _render_on_ax_(self, ax: Axis) -> None:
+        self._set_axis_(ax)
+
+        ax.set_style(self.plot_style)
+
+        ax.add_line(x=self.itr_list, y=self._data, label=self.stylized_label)
+
+    def plot(self, row: int = 0, col: int = 0) -> None:
+        """
+        Plotting method for the index.
+
+        :param      slice_list:  Value reprenting the slice where the mode field is evaluated.
+        :type       slice_list:  list
+        :param      itr_list:    Value of itr value to evaluate the mode field.
+        :type       itr_list:    list
+
+        :returns:   the figure containing all the plots.
+        :rtype:     SceneList
+        """
+        figure = SceneList(unit_size=(10, 4), tight_layout=True)
+
+        ax = figure.append_ax()
+
+        self._render_on_ax_(ax)
+
+        return figure
+
+
+class InheritFromSuperMode():
+    def _set_axis_(self, ax: Axis):
+        for element, value in self.plot_style.items():
+            setattr(ax, element, value)
+
+    def __getitem__(self, idx):
+        return self._data[idx]
+
+    @property
+    def mode_number(self) -> int:
+        return self.parent_supermode.mode_number
+
+    @property
+    def solver_number(self) -> int:
+        return self.parent_supermode.solver_number
+
+    @property
+    def axes(self):
+        return self.parent_supermode.axes
+
+    @property
+    def boundaries(self):
+        return self.parent_supermode.boundaries
+
+    @property
+    def itr_list(self):
+        return self.parent_supermode.itr_list
+
+    @property
+    def ID(self):
+        return self.parent_supermode.ID
+
+    @property
+    def label(self):
+        return self.parent_supermode.label
+
+    @property
+    def stylized_label(self):
+        return self.parent_supermode.stylized_label
+
+    def slice_to_itr(self, slice: list = []):
+        return self.parent_supermode.parent_set.slice_to_itr(slice)
+
+    def itr_to_slice(self, itr: list = []):
+        return self.parent_supermode.parent_set.itr_to_slice(itr)
+
+    def _get_symmetrize_vector(self, *args, **kwargs):
+        return self.parent_supermode._get_symmetrize_vector(*args, **kwargs)
+
+    def _get_axis_vector(self, *args, **kwargs):
+        return self.parent_supermode._get_axis_vector(*args, **kwargs)
+
+    def get_axis(self, *args, **kwargs):
+        return self.parent_supermode.get_axis(*args, **kwargs)
+
+# -
```

## SuPyMode/representation/beating_length.py

 * *Ordering differences only*

```diff
@@ -1,94 +1,94 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-import numpy
-
-from SuPyMode.representation.base import InheritFromSuperMode, BaseMultiModePlot
-from MPSPlots.render2D import Axis, SceneList
-
-
-class BeatingLength(InheritFromSuperMode, BaseMultiModePlot):
-    """
-    Represents the beating lengths between modes of different supermodes in optical fiber simulations.
-
-    This class extends from `InheritFromSuperMode` to utilize supermode-related data and from `BaseMultiModePlot`
-    for advanced plotting functionalities tailored to visualize beating length comparisons.
-
-    Class Attributes:
-        plot_style (dict): Default style settings for plots generated by this class.
-    """
-
-    plot_style = dict(
-        show_legend=True,
-        x_label='Inverse taper ratio',
-        y_label='Beating length [m]',
-        y_scale="log",
-        line_width=2
-    )
-
-    def __init__(self, parent_supermode: SuperMode):
-        """
-        Initializes a BeatingLength object with a reference to a parent supermode.
-
-        Args:
-            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
-        """
-        self.parent_supermode = parent_supermode
-
-    def get_values(self, other_supermode: SuperMode) -> numpy.ndarray:
-        """
-        Calculates the beating length between the parent supermode and another specified supermode.
-
-        Args:
-            other_supermode (SuperMode): The supermode with which to compare the parent supermode.
-
-        Returns:
-            numpy.ndarray: An array of beating lengths calculated between the two supermodes.
-        """
-        return self.parent_supermode.binded_supermode.get_beating_length_with_mode(other_supermode.binded_supermode)
-
-    def render_on_ax(self, ax: Axis, other_supermode: SuperMode) -> None:
-        """
-        Renders beating length data as a line plot on the provided Axis object, comparing the parent supermode
-        with another supermode.
-
-        Args:
-            ax (Axis): The Axis object on which to plot the beating lengths.
-            other_supermode (SuperMode): The other supermode to compare against.
-
-        Note:
-            This method utilizes the `plot_style` class attribute to define the appearance of the plot.
-        """
-        y = self.get_values(other_supermode=other_supermode)
-
-        label = f'{self.parent_supermode.stylized_label} - {other_supermode.stylized_label}'
-
-        ax.add_line(x=self.itr_list, y=numpy.abs(y), label=label)
-
-    def plot(self, other_supermode: SuperMode) -> SceneList:
-        """
-        Generates a plot of beating lengths between the parent supermode and another specified supermode using a SceneList.
-
-        This method creates a single-axis plot showing the comparative beating lengths as a function of the inverse taper ratio,
-        formatted according to the predefined plot style.
-
-        Args:
-            other_supermode (SuperMode): The supermode to compare against.
-
-        Returns:
-            SceneList: A scene list containing the plot of beating lengths.
-        """
-        figure = SceneList()
-
-        ax = figure.append_ax(**self.plot_style)
-
-        self.render_on_ax(ax=ax, other_supermode=other_supermode)
-
-        return figure
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+import numpy
+
+from SuPyMode.representation.base import InheritFromSuperMode, BaseMultiModePlot
+from MPSPlots.render2D import Axis, SceneList
+
+
+class BeatingLength(InheritFromSuperMode, BaseMultiModePlot):
+    """
+    Represents the beating lengths between modes of different supermodes in optical fiber simulations.
+
+    This class extends from `InheritFromSuperMode` to utilize supermode-related data and from `BaseMultiModePlot`
+    for advanced plotting functionalities tailored to visualize beating length comparisons.
+
+    Class Attributes:
+        plot_style (dict): Default style settings for plots generated by this class.
+    """
+
+    plot_style = dict(
+        show_legend=True,
+        x_label='Inverse taper ratio',
+        y_label='Beating length [m]',
+        y_scale="log",
+        line_width=2
+    )
+
+    def __init__(self, parent_supermode: SuperMode):
+        """
+        Initializes a BeatingLength object with a reference to a parent supermode.
+
+        Args:
+            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
+        """
+        self.parent_supermode = parent_supermode
+
+    def get_values(self, other_supermode: SuperMode) -> numpy.ndarray:
+        """
+        Calculates the beating length between the parent supermode and another specified supermode.
+
+        Args:
+            other_supermode (SuperMode): The supermode with which to compare the parent supermode.
+
+        Returns:
+            numpy.ndarray: An array of beating lengths calculated between the two supermodes.
+        """
+        return self.parent_supermode.binded_supermode.get_beating_length_with_mode(other_supermode.binded_supermode)
+
+    def render_on_ax(self, ax: Axis, other_supermode: SuperMode) -> None:
+        """
+        Renders beating length data as a line plot on the provided Axis object, comparing the parent supermode
+        with another supermode.
+
+        Args:
+            ax (Axis): The Axis object on which to plot the beating lengths.
+            other_supermode (SuperMode): The other supermode to compare against.
+
+        Note:
+            This method utilizes the `plot_style` class attribute to define the appearance of the plot.
+        """
+        y = self.get_values(other_supermode=other_supermode)
+
+        label = f'{self.parent_supermode.stylized_label} - {other_supermode.stylized_label}'
+
+        ax.add_line(x=self.itr_list, y=numpy.abs(y), label=label)
+
+    def plot(self, other_supermode: SuperMode) -> SceneList:
+        """
+        Generates a plot of beating lengths between the parent supermode and another specified supermode using a SceneList.
+
+        This method creates a single-axis plot showing the comparative beating lengths as a function of the inverse taper ratio,
+        formatted according to the predefined plot style.
+
+        Args:
+            other_supermode (SuperMode): The supermode to compare against.
+
+        Returns:
+            SceneList: A scene list containing the plot of beating lengths.
+        """
+        figure = SceneList()
+
+        ax = figure.append_ax(**self.plot_style)
+
+        self.render_on_ax(ax=ax, other_supermode=other_supermode)
+
+        return figure
+
+# -
```

## SuPyMode/representation/beta.py

 * *Ordering differences only*

```diff
@@ -1,85 +1,85 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-from SuPyMode.representation.base import InheritFromSuperMode, BaseSingleModePlot
-from MPSPlots.render2D import SceneList, Axis
-
-
-class Beta(InheritFromSuperMode, BaseSingleModePlot):
-    """
-    Represents the propagation constants (beta values) of a mode derived from a supermode in optical simulations.
-
-    This class utilizes inheritance from `InheritFromSuperMode` for accessing supermode-related data and
-    `BaseSingleModePlot` for plotting functionalities tailored to propagation constant visualization.
-
-    Class Attributes:
-        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
-
-    Attributes:
-        parent_supermode (InheritFromSuperMode): A reference to the parent supermode object from which beta data is sourced.
-    """
-
-    plot_style = dict(
-        show_legend=True,
-        x_label='Inverse taper ratio',
-        y_label='Propagation constant [rad/M]',
-        y_scale="linear",
-        line_width=2
-    )
-
-    def __init__(self, parent_supermode: SuperMode):
-        """
-        Initializes a Beta object with a reference to a parent supermode.
-
-        Args:
-            parent_supermode (InheritFromSuperMode): The parent supermode object.
-        """
-        self.parent_supermode = parent_supermode
-
-    @property
-    def data(self):
-        return self.parent_supermode.binded_supermode.get_betas()
-
-    def render_on_ax(self, ax: Axis) -> None:
-        """
-        Renders the propagation constants as a line plot on the provided Axis object.
-
-        Args:
-            ax (Axis): The Axis object on which to plot the propagation constants.
-
-        Note:
-            Utilizes the `plot_style` class attribute to define the appearance of the plot.
-        """
-        ax.add_line(
-            x=self.itr_list,
-            y=self.data,
-            label=f'{self.stylized_label}'
-        )
-
-    def plot(self) -> SceneList:
-        """
-        Generates a plot of the propagation constants using a SceneList to manage multiple plots if necessary.
-
-        This method creates a single-axis plot showing the propagation constants as a function of the inverse taper ratio,
-        formatted according to the predefined plot style.
-
-        Returns:
-            SceneList: A scene list containing the plot of propagation constants.
-        """
-        figure = SceneList()
-
-        ax = figure.append_ax()
-
-        ax.set_style(**self.plot_style)
-
-        self.render_on_ax(ax=ax)
-
-        return figure
-
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+from SuPyMode.representation.base import InheritFromSuperMode, BaseSingleModePlot
+from MPSPlots.render2D import SceneList, Axis
+
+
+class Beta(InheritFromSuperMode, BaseSingleModePlot):
+    """
+    Represents the propagation constants (beta values) of a mode derived from a supermode in optical simulations.
+
+    This class utilizes inheritance from `InheritFromSuperMode` for accessing supermode-related data and
+    `BaseSingleModePlot` for plotting functionalities tailored to propagation constant visualization.
+
+    Class Attributes:
+        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
+
+    Attributes:
+        parent_supermode (InheritFromSuperMode): A reference to the parent supermode object from which beta data is sourced.
+    """
+
+    plot_style = dict(
+        show_legend=True,
+        x_label='Inverse taper ratio',
+        y_label='Propagation constant [rad/M]',
+        y_scale="linear",
+        line_width=2
+    )
+
+    def __init__(self, parent_supermode: SuperMode):
+        """
+        Initializes a Beta object with a reference to a parent supermode.
+
+        Args:
+            parent_supermode (InheritFromSuperMode): The parent supermode object.
+        """
+        self.parent_supermode = parent_supermode
+
+    @property
+    def data(self):
+        return self.parent_supermode.binded_supermode.get_betas()
+
+    def render_on_ax(self, ax: Axis) -> None:
+        """
+        Renders the propagation constants as a line plot on the provided Axis object.
+
+        Args:
+            ax (Axis): The Axis object on which to plot the propagation constants.
+
+        Note:
+            Utilizes the `plot_style` class attribute to define the appearance of the plot.
+        """
+        ax.add_line(
+            x=self.itr_list,
+            y=self.data,
+            label=f'{self.stylized_label}'
+        )
+
+    def plot(self) -> SceneList:
+        """
+        Generates a plot of the propagation constants using a SceneList to manage multiple plots if necessary.
+
+        This method creates a single-axis plot showing the propagation constants as a function of the inverse taper ratio,
+        formatted according to the predefined plot style.
+
+        Returns:
+            SceneList: A scene list containing the plot of propagation constants.
+        """
+        figure = SceneList()
+
+        ax = figure.append_ax()
+
+        ax.set_style(**self.plot_style)
+
+        self.render_on_ax(ax=ax)
+
+        return figure
+
+
+# -
```

## SuPyMode/representation/eigen_value.py

 * *Ordering differences only*

```diff
@@ -1,78 +1,78 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-from SuPyMode.representation.base import InheritFromSuperMode, BaseSingleModePlot
-from MPSPlots.render2D import SceneList, Axis
-
-
-class EigenValue(InheritFromSuperMode, BaseSingleModePlot):
-    """
-    Represents the eigenvalues of a mode derived from a supermode in a waveguide or optical fiber simulation.
-
-    This class extends from `InheritFromSuperMode` to access supermode-related data and from `BaseSingleModePlot`
-    to provide plotting capabilities tailored to eigenvalue visualization.
-
-    Attributes:
-        parent_supermode (InheritFromSuperMode): The parent supermode object from which eigenvalue data is derived.
-    """
-
-    plot_style = dict(
-        show_legend=True,
-        x_label='Inverse taper ratio',
-        y_label='Mode eigen values',
-        y_scale="linear",
-        line_width=2
-    )
-
-    def __init__(self, parent_supermode: SuperMode):
-        """
-        Initializes an EigenValue object with a parent supermode reference.
-
-        Args:
-            parent_supermode (InheritFromSuperMode): A reference to the parent supermode object.
-        """
-        self.parent_supermode = parent_supermode
-        self.data = self.parent_supermode.binded_supermode.get_eigen_value()
-
-    def render_on_ax(self, ax: Axis) -> None:
-        """
-        Renders the eigenvalues as a line plot on the provided Axis object.
-
-        Args:
-            ax (Axis): The Axis object on which the eigenvalues will be plotted.
-
-        Note:
-            This method utilizes the plotting configuration set on the Axis to define the appearance of the plot.
-        """
-        ax.add_line(
-            x=self.itr_list,
-            y=self.data,
-            label=f'{self.stylized_label}'
-        )
-
-    def plot(self) -> SceneList:
-        """
-        Generates a plot of the eigenvalues using a SceneList to manage multiple plots if necessary.
-
-        This method creates a single-axis plot showing the mode eigenvalues as a function of the inverse taper ratio.
-
-        Returns:
-            SceneList: A scene list containing the eigenvalue plot.
-        """
-        figure = SceneList()
-
-        ax = figure.append_ax()
-
-        ax.set_style(**self.plot_style)
-
-        self.render_on_ax(ax=ax)
-
-        return figure
-
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+from SuPyMode.representation.base import InheritFromSuperMode, BaseSingleModePlot
+from MPSPlots.render2D import SceneList, Axis
+
+
+class EigenValue(InheritFromSuperMode, BaseSingleModePlot):
+    """
+    Represents the eigenvalues of a mode derived from a supermode in a waveguide or optical fiber simulation.
+
+    This class extends from `InheritFromSuperMode` to access supermode-related data and from `BaseSingleModePlot`
+    to provide plotting capabilities tailored to eigenvalue visualization.
+
+    Attributes:
+        parent_supermode (InheritFromSuperMode): The parent supermode object from which eigenvalue data is derived.
+    """
+
+    plot_style = dict(
+        show_legend=True,
+        x_label='Inverse taper ratio',
+        y_label='Mode eigen values',
+        y_scale="linear",
+        line_width=2
+    )
+
+    def __init__(self, parent_supermode: SuperMode):
+        """
+        Initializes an EigenValue object with a parent supermode reference.
+
+        Args:
+            parent_supermode (InheritFromSuperMode): A reference to the parent supermode object.
+        """
+        self.parent_supermode = parent_supermode
+        self.data = self.parent_supermode.binded_supermode.get_eigen_value()
+
+    def render_on_ax(self, ax: Axis) -> None:
+        """
+        Renders the eigenvalues as a line plot on the provided Axis object.
+
+        Args:
+            ax (Axis): The Axis object on which the eigenvalues will be plotted.
+
+        Note:
+            This method utilizes the plotting configuration set on the Axis to define the appearance of the plot.
+        """
+        ax.add_line(
+            x=self.itr_list,
+            y=self.data,
+            label=f'{self.stylized_label}'
+        )
+
+    def plot(self) -> SceneList:
+        """
+        Generates a plot of the eigenvalues using a SceneList to manage multiple plots if necessary.
+
+        This method creates a single-axis plot showing the mode eigenvalues as a function of the inverse taper ratio.
+
+        Returns:
+            SceneList: A scene list containing the eigenvalue plot.
+        """
+        figure = SceneList()
+
+        ax = figure.append_ax()
+
+        ax.set_style(**self.plot_style)
+
+        self.render_on_ax(ax=ax)
+
+        return figure
+
+
+# -
```

## SuPyMode/representation/field.py

 * *Ordering differences only*

```diff
@@ -1,371 +1,371 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-import numpy
-from MPSPlots.render2D import Axis
-from MPSPlots import colormaps
-from MPSPlots.render2D import SceneMatrix
-
-from SuPyMode.utils import interpret_slice_number_and_itr, slice_to_itr
-
-from SuPyMode.representation.base import InheritFromSuperMode
-
-
-class Field(InheritFromSuperMode):
-    """
-    Represents a field derived from a supermode in a modal analysis framework.
-
-    This class extends functionality from a parent supermode class to manage field data operations,
-    including retrieving and processing field data for visualization and analysis.
-
-    Attributes:
-        parent_supermode (InheritFromSuperMode): Reference to the parent supermode object that provides source data.
-    """
-
-    plot_style = dict(
-        show_legend=False,
-        x_label=r'',
-        y_label=r'',
-        show_ticks=False,
-        x_scale_factor=1e6,
-        y_scale_factor=1e6
-    )
-
-    def __init__(self, parent_supermode: SuperMode):
-        """
-        Initialize the Field object with a reference to a parent supermode.
-
-        Args:
-            parent_supermode (InheritFromSuperMode): The parent supermode from which this field is derived.
-        """
-        self.parent_supermode = parent_supermode
-
-    @property
-    def data(self):
-        return self.parent_supermode.binded_supermode.get_fields()
-
-    def get_norm(self, slice_number: int) -> float:
-        """
-        Calculate the norm of the field for a specific slice.
-
-        Args:
-            slice_number (int): The slice number for which to calculate the norm.
-
-        Returns:
-            float: The norm of the field.
-        """
-        return self.parent_supermode.binded_supermode.get_norm(slice_number)
-
-    @property
-    def itr_list(self) -> numpy.ndarray:
-        """
-        Provides a list of iteration indices available for the fields.
-
-        Returns:
-            numpy.ndarray: An array of iteration indices.
-        """
-        return self.parent_supermode.binded_supermode.model_parameters.itr_list
-
-    @property
-    def parent_superset(self) -> object:
-        """
-        Access the parent set of the supermode.
-
-        Returns:
-            object: The parent set object.
-        """
-        return self.parent_supermode.parent_set
-
-    def get_field(self, slice_number: int = None, itr: float = None, add_symmetries: bool = True) -> numpy.ndarray:
-        """
-        Retrieve a specific field adjusted for boundary conditions and optionally add symmetries.
-
-        Args:
-            slice_number (int): The slice number to retrieve.
-            itr (float): The iteration to use for retrieving the field.
-            add_symmetries (bool): Whether to add boundary symmetries to the field.
-
-        Returns:
-            numpy.ndarray: The requested field as a numpy array.
-
-        Raises:
-            AssertionError: If neither or both of slice_number and itr are defined.
-        """
-        slice_list, itr_list = interpret_slice_number_and_itr(
-            itr_baseline=self.itr_list,
-            itr_list=itr,
-            slice_list=slice_number
-        )
-
-        fields = self.parent_supermode.binded_supermode.get_fields()
-        fields = numpy.take(fields, slice_list, axis=0)
-        if add_symmetries:
-            fields = self._get_symmetrized_field(fields)
-
-        return fields
-
-    def normalize_field(self, field: numpy.ndarray, itr: float, norm_type: str = 'L2') -> numpy.ndarray:
-        """
-        Normalize a field array based on a specified normalization method.
-
-        Currently, this method is deprecated.
-
-        Args:
-            field (numpy.ndarray): The field to normalize.
-            itr (float): The iteration value for normalization scaling.
-            norm_type (str): The type of normalization ('max', 'center', 'L2', 'cmt').
-
-        Returns:
-            numpy.ndarray: The normalized field.
-        """
-        match norm_type.lower():
-            case 'max':
-                norm = abs(field).max()
-            case 'center':
-                idx_x_center = numpy.argmin(abs(self.parent_supermode.parent_set.coordinate_system.x_vector))
-                idx_y_center = numpy.argmin(abs(self.parent_supermode.parent_set.coordinate_system.y_vector))
-                center_value = field[idx_x_center, idx_y_center]
-                norm = center_value
-            case 'l2':
-                dx_scaled = self.parent_supermode.parent_set.coordinate_system.dx * itr
-                dy_scaled = self.parent_supermode.parent_set.coordinate_system.dy * itr
-                norm = numpy.sqrt(numpy.trapz(numpy.trapz(numpy.square(field), dx=dy_scaled, axis=0), dx=dx_scaled, axis=0))
-            case 'cmt':
-                dx_scaled = self.parent_supermode.parent_set.coordinate_system.dx * itr
-                dy_scaled = self.parent_supermode.parent_set.coordinate_system.dy * itr
-                norm = numpy.sqrt(numpy.trapz(numpy.trapz(numpy.square(field), dx=dx_scaled, axis=0), dx=dy_scaled, axis=0))
-
-        return field / norm
-
-    def _get_symmetrized_field_and_axis(self, field: numpy.ndarray) -> tuple:
-        """
-        Generate a symmetrical version of the input field mesh according to defined boundary conditions.
-
-        Args:
-            field (numpy.ndarray): The 2D field mesh to be symmetrized.
-
-        Returns:
-            numpy.ndarray: The symmetrized field mesh.
-
-        Raises:
-            AssertionError: If the input is not a 2D array.
-        """
-        x_axis, y_axis = self._get_axis_vector(add_symmetries=True)
-
-        field = self._get_symmetrized_field(field=field)
-
-        return x_axis, y_axis, field
-
-    def _get_symmetrized_field(self, field: numpy.ndarray) -> numpy.ndarray:
-        """
-        Retrieve the field and axis data adjusted for symmetry.
-
-        This method generates symmetrized versions of the field and its corresponding axis vectors.
-
-        Args:
-            field (numpy.ndarray): The field data array to be symmetrized.
-
-        Returns:
-            tuple: A tuple containing the x-axis, y-axis, and the symmetrized field data.
-        """
-        field = field.squeeze()
-        assert field.ndim == 2, f"Expected a 2-dimensional array, but got {field.ndim}-dimensional."
-
-        symmetric_field = field[:, -2::-1]
-        match self.boundaries.left.lower():
-            case 'symmetric':
-                field = numpy.c_[symmetric_field, field]
-
-            case 'anti-symmetric':
-                field = numpy.c_[-symmetric_field, field]
-
-        match self.boundaries.right.lower():
-            case 'symmetric':
-                field = numpy.c_[field, symmetric_field]
-
-            case 'anti-symmetric':
-                field = numpy.c_[field, -symmetric_field]
-
-        symmetric_field = field[-2::-1, :]
-        match self.boundaries.top.lower():
-            case 'symmetric':
-                field = numpy.r_[field, symmetric_field]
-
-            case 'anti-symmetric':
-                field = numpy.r_[field, -symmetric_field]
-
-        match self.boundaries.bottom.lower():
-            case 'symmetric':
-                field = numpy.r_[symmetric_field, field]
-
-            case 'anti-symmetric':
-                field = numpy.r_[-symmetric_field, field]
-
-        return field
-
-    def _render_on_ax_(self, ax: Axis, slice: int) -> None:
-        """
-        Renders a specified slice of the field data on a provided Axis object.
-
-        This method is typically used to add a field mesh plot to a plotting axis as part of a larger figure or plot matrix.
-
-        Args:
-            ax (Axis): The plotting Axis object to render the field on.
-            slice (int): The slice index of the field data to render.
-
-        Note:
-            This method applies internal colormap settings and adjusts the axis based on the field data.
-        """
-        field = self.parent_supermode.binded_supermode.get_field[slice]
-
-        x, y, field = self._get_symmetrized_field_and_axis(field=field)
-
-        artist = ax.add_mesh(
-            x=x,
-            y=y,
-            scalar=field,
-        )
-
-        ax.add_colorbar(
-            artist=artist,
-            colormap=colormaps.blue_black_red,
-            symmetric=True,
-            position='right'
-        )
-
-    def plot(
-            self,
-            itr_list: list[float] = [],
-            slice_list: list[int] = [0, -1],
-            add_symmetries: bool = True,
-            show_mode_label: bool = True,
-            show_itr: bool = True,
-            show_slice: bool = True) -> SceneMatrix:
-        """
-        Plot the field for specified iterations or slice numbers.
-
-        Args:
-            itr_list (list[float]): List of iterations to evaluate the field.
-            slice_list (list[int]): List of slices to evaluate the field.
-            add_symmetries (bool): Whether to include boundary symmetries in the plot.
-            show_mode_label (bool): Whether to show the mode label.
-            show_itr (bool): Whether to show the iteration value.
-            show_slice (bool): Whether to show the slice number.
-
-        Returns:
-            SceneMatrix: A matrix scene containing the plots.
-        """
-        figure = SceneMatrix(unit_size=(3, 3))
-
-        slice_list, itr_list = interpret_slice_number_and_itr(
-            itr_baseline=self.itr_list,
-            itr_list=itr_list,
-            slice_list=slice_list
-        )
-
-        for n, (itr, slice_number) in enumerate(zip(itr_list, slice_list)):
-            ax = figure.append_ax(row=n, column=0)
-
-            ax.set_style(**self.plot_style)
-
-            self.render_on_ax(
-                ax=ax,
-                slice_number=slice_number,
-                add_symmetries=add_symmetries
-            )
-
-        return figure
-
-    def render_on_ax(
-            self,
-            ax: object,
-            slice_number: int,
-            show_mode_label: bool = True,
-            show_itr: bool = True,
-            show_slice: bool = True,
-            add_symmetries: bool = True) -> None:
-        """
-        Render the mode field at given slice number into input ax.
-
-        :param      ax:               { parameter_description }
-        :type       ax:               object
-        :param      slice_number:     The slice number
-        :type       slice_number:     int
-        :param      show_mode_label:  The show mode label
-        :type       show_mode_label:  bool
-        :param      show_itr:         The show itr
-        :type       show_itr:         bool
-        :param      show_slice:       The show slice
-        :type       show_slice:       bool
-        :param      add_symmetries:   Indicates if the symmetries is added
-        :type       add_symmetries:   bool
-
-        :returns:   No returns
-        :rtype:     None
-        """
-        ax.title = self.get_plot_mode_field_title(
-            slice_number=slice_number,
-            show_mode_label=show_mode_label,
-            show_itr=show_itr,
-            show_slice=show_slice
-        )
-
-        field = self.get_field(
-            slice_number=slice_number,
-            add_symmetries=add_symmetries
-        )
-
-        x, y = self.get_axis(
-            slice_number=slice_number,
-            add_symmetries=add_symmetries
-        )
-
-        artist = ax.add_mesh(
-            x=x,
-            y=y,
-            scalar=field,
-        )
-
-        ax.add_colorbar(
-            artist=artist,
-            colormap=colormaps.blue_black_red,
-            symmetric=True
-        )
-
-    def get_plot_mode_field_title(self, slice_number: int, show_mode_label: bool, show_itr: bool, show_slice: bool) -> str:
-        """
-        Constructs a title for the field plot based on the mode, iteration, and slice number.
-
-        Args:
-            slice_number (int): The slice number for which the field is plotted.
-            show_mode_label (bool): Flag to include the mode label in the title.
-            show_itr (bool): Flag to include the iteration number in the title.
-            show_slice (bool): Flag to include the slice number in the title.
-
-        Returns:
-            str: The constructed title for the plot.
-        """
-        title = ''
-
-        if show_mode_label:
-            title += f'{self.stylized_label}'
-
-        if show_itr or show_slice:
-            itr = slice_to_itr(itr_list=self.itr_list, slice_number=slice_number)
-            title += '\n'
-
-        if show_slice:
-            title += f'slice: {slice_number}'
-
-        if show_itr:
-            title += f'  itr: {itr:.3f}'
-
-        return title
-
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+import numpy
+from MPSPlots.render2D import Axis
+from MPSPlots import colormaps
+from MPSPlots.render2D import SceneMatrix
+
+from SuPyMode.utils import interpret_slice_number_and_itr, slice_to_itr
+
+from SuPyMode.representation.base import InheritFromSuperMode
+
+
+class Field(InheritFromSuperMode):
+    """
+    Represents a field derived from a supermode in a modal analysis framework.
+
+    This class extends functionality from a parent supermode class to manage field data operations,
+    including retrieving and processing field data for visualization and analysis.
+
+    Attributes:
+        parent_supermode (InheritFromSuperMode): Reference to the parent supermode object that provides source data.
+    """
+
+    plot_style = dict(
+        show_legend=False,
+        x_label=r'',
+        y_label=r'',
+        show_ticks=False,
+        x_scale_factor=1e6,
+        y_scale_factor=1e6
+    )
+
+    def __init__(self, parent_supermode: SuperMode):
+        """
+        Initialize the Field object with a reference to a parent supermode.
+
+        Args:
+            parent_supermode (InheritFromSuperMode): The parent supermode from which this field is derived.
+        """
+        self.parent_supermode = parent_supermode
+
+    @property
+    def data(self):
+        return self.parent_supermode.binded_supermode.get_fields()
+
+    def get_norm(self, slice_number: int) -> float:
+        """
+        Calculate the norm of the field for a specific slice.
+
+        Args:
+            slice_number (int): The slice number for which to calculate the norm.
+
+        Returns:
+            float: The norm of the field.
+        """
+        return self.parent_supermode.binded_supermode.get_norm(slice_number)
+
+    @property
+    def itr_list(self) -> numpy.ndarray:
+        """
+        Provides a list of iteration indices available for the fields.
+
+        Returns:
+            numpy.ndarray: An array of iteration indices.
+        """
+        return self.parent_supermode.binded_supermode.model_parameters.itr_list
+
+    @property
+    def parent_superset(self) -> object:
+        """
+        Access the parent set of the supermode.
+
+        Returns:
+            object: The parent set object.
+        """
+        return self.parent_supermode.parent_set
+
+    def get_field(self, slice_number: int = None, itr: float = None, add_symmetries: bool = True) -> numpy.ndarray:
+        """
+        Retrieve a specific field adjusted for boundary conditions and optionally add symmetries.
+
+        Args:
+            slice_number (int): The slice number to retrieve.
+            itr (float): The iteration to use for retrieving the field.
+            add_symmetries (bool): Whether to add boundary symmetries to the field.
+
+        Returns:
+            numpy.ndarray: The requested field as a numpy array.
+
+        Raises:
+            AssertionError: If neither or both of slice_number and itr are defined.
+        """
+        slice_list, itr_list = interpret_slice_number_and_itr(
+            itr_baseline=self.itr_list,
+            itr_list=itr,
+            slice_list=slice_number
+        )
+
+        fields = self.parent_supermode.binded_supermode.get_fields()
+        fields = numpy.take(fields, slice_list, axis=0)
+        if add_symmetries:
+            fields = self._get_symmetrized_field(fields)
+
+        return fields
+
+    def normalize_field(self, field: numpy.ndarray, itr: float, norm_type: str = 'L2') -> numpy.ndarray:
+        """
+        Normalize a field array based on a specified normalization method.
+
+        Currently, this method is deprecated.
+
+        Args:
+            field (numpy.ndarray): The field to normalize.
+            itr (float): The iteration value for normalization scaling.
+            norm_type (str): The type of normalization ('max', 'center', 'L2', 'cmt').
+
+        Returns:
+            numpy.ndarray: The normalized field.
+        """
+        match norm_type.lower():
+            case 'max':
+                norm = abs(field).max()
+            case 'center':
+                idx_x_center = numpy.argmin(abs(self.parent_supermode.parent_set.coordinate_system.x_vector))
+                idx_y_center = numpy.argmin(abs(self.parent_supermode.parent_set.coordinate_system.y_vector))
+                center_value = field[idx_x_center, idx_y_center]
+                norm = center_value
+            case 'l2':
+                dx_scaled = self.parent_supermode.parent_set.coordinate_system.dx * itr
+                dy_scaled = self.parent_supermode.parent_set.coordinate_system.dy * itr
+                norm = numpy.sqrt(numpy.trapz(numpy.trapz(numpy.square(field), dx=dy_scaled, axis=0), dx=dx_scaled, axis=0))
+            case 'cmt':
+                dx_scaled = self.parent_supermode.parent_set.coordinate_system.dx * itr
+                dy_scaled = self.parent_supermode.parent_set.coordinate_system.dy * itr
+                norm = numpy.sqrt(numpy.trapz(numpy.trapz(numpy.square(field), dx=dx_scaled, axis=0), dx=dy_scaled, axis=0))
+
+        return field / norm
+
+    def _get_symmetrized_field_and_axis(self, field: numpy.ndarray) -> tuple:
+        """
+        Generate a symmetrical version of the input field mesh according to defined boundary conditions.
+
+        Args:
+            field (numpy.ndarray): The 2D field mesh to be symmetrized.
+
+        Returns:
+            numpy.ndarray: The symmetrized field mesh.
+
+        Raises:
+            AssertionError: If the input is not a 2D array.
+        """
+        x_axis, y_axis = self._get_axis_vector(add_symmetries=True)
+
+        field = self._get_symmetrized_field(field=field)
+
+        return x_axis, y_axis, field
+
+    def _get_symmetrized_field(self, field: numpy.ndarray) -> numpy.ndarray:
+        """
+        Retrieve the field and axis data adjusted for symmetry.
+
+        This method generates symmetrized versions of the field and its corresponding axis vectors.
+
+        Args:
+            field (numpy.ndarray): The field data array to be symmetrized.
+
+        Returns:
+            tuple: A tuple containing the x-axis, y-axis, and the symmetrized field data.
+        """
+        field = field.squeeze()
+        assert field.ndim == 2, f"Expected a 2-dimensional array, but got {field.ndim}-dimensional."
+
+        symmetric_field = field[:, -2::-1]
+        match self.boundaries.left.lower():
+            case 'symmetric':
+                field = numpy.c_[symmetric_field, field]
+
+            case 'anti-symmetric':
+                field = numpy.c_[-symmetric_field, field]
+
+        match self.boundaries.right.lower():
+            case 'symmetric':
+                field = numpy.c_[field, symmetric_field]
+
+            case 'anti-symmetric':
+                field = numpy.c_[field, -symmetric_field]
+
+        symmetric_field = field[-2::-1, :]
+        match self.boundaries.top.lower():
+            case 'symmetric':
+                field = numpy.r_[field, symmetric_field]
+
+            case 'anti-symmetric':
+                field = numpy.r_[field, -symmetric_field]
+
+        match self.boundaries.bottom.lower():
+            case 'symmetric':
+                field = numpy.r_[symmetric_field, field]
+
+            case 'anti-symmetric':
+                field = numpy.r_[-symmetric_field, field]
+
+        return field
+
+    def _render_on_ax_(self, ax: Axis, slice: int) -> None:
+        """
+        Renders a specified slice of the field data on a provided Axis object.
+
+        This method is typically used to add a field mesh plot to a plotting axis as part of a larger figure or plot matrix.
+
+        Args:
+            ax (Axis): The plotting Axis object to render the field on.
+            slice (int): The slice index of the field data to render.
+
+        Note:
+            This method applies internal colormap settings and adjusts the axis based on the field data.
+        """
+        field = self.parent_supermode.binded_supermode.get_field[slice]
+
+        x, y, field = self._get_symmetrized_field_and_axis(field=field)
+
+        artist = ax.add_mesh(
+            x=x,
+            y=y,
+            scalar=field,
+        )
+
+        ax.add_colorbar(
+            artist=artist,
+            colormap=colormaps.blue_black_red,
+            symmetric=True,
+            position='right'
+        )
+
+    def plot(
+            self,
+            itr_list: list[float] = [],
+            slice_list: list[int] = [0, -1],
+            add_symmetries: bool = True,
+            show_mode_label: bool = True,
+            show_itr: bool = True,
+            show_slice: bool = True) -> SceneMatrix:
+        """
+        Plot the field for specified iterations or slice numbers.
+
+        Args:
+            itr_list (list[float]): List of iterations to evaluate the field.
+            slice_list (list[int]): List of slices to evaluate the field.
+            add_symmetries (bool): Whether to include boundary symmetries in the plot.
+            show_mode_label (bool): Whether to show the mode label.
+            show_itr (bool): Whether to show the iteration value.
+            show_slice (bool): Whether to show the slice number.
+
+        Returns:
+            SceneMatrix: A matrix scene containing the plots.
+        """
+        figure = SceneMatrix(unit_size=(3, 3))
+
+        slice_list, itr_list = interpret_slice_number_and_itr(
+            itr_baseline=self.itr_list,
+            itr_list=itr_list,
+            slice_list=slice_list
+        )
+
+        for n, (itr, slice_number) in enumerate(zip(itr_list, slice_list)):
+            ax = figure.append_ax(row=n, column=0)
+
+            ax.set_style(**self.plot_style)
+
+            self.render_on_ax(
+                ax=ax,
+                slice_number=slice_number,
+                add_symmetries=add_symmetries
+            )
+
+        return figure
+
+    def render_on_ax(
+            self,
+            ax: object,
+            slice_number: int,
+            show_mode_label: bool = True,
+            show_itr: bool = True,
+            show_slice: bool = True,
+            add_symmetries: bool = True) -> None:
+        """
+        Render the mode field at given slice number into input ax.
+
+        :param      ax:               { parameter_description }
+        :type       ax:               object
+        :param      slice_number:     The slice number
+        :type       slice_number:     int
+        :param      show_mode_label:  The show mode label
+        :type       show_mode_label:  bool
+        :param      show_itr:         The show itr
+        :type       show_itr:         bool
+        :param      show_slice:       The show slice
+        :type       show_slice:       bool
+        :param      add_symmetries:   Indicates if the symmetries is added
+        :type       add_symmetries:   bool
+
+        :returns:   No returns
+        :rtype:     None
+        """
+        ax.title = self.get_plot_mode_field_title(
+            slice_number=slice_number,
+            show_mode_label=show_mode_label,
+            show_itr=show_itr,
+            show_slice=show_slice
+        )
+
+        field = self.get_field(
+            slice_number=slice_number,
+            add_symmetries=add_symmetries
+        )
+
+        x, y = self.get_axis(
+            slice_number=slice_number,
+            add_symmetries=add_symmetries
+        )
+
+        artist = ax.add_mesh(
+            x=x,
+            y=y,
+            scalar=field,
+        )
+
+        ax.add_colorbar(
+            artist=artist,
+            colormap=colormaps.blue_black_red,
+            symmetric=True
+        )
+
+    def get_plot_mode_field_title(self, slice_number: int, show_mode_label: bool, show_itr: bool, show_slice: bool) -> str:
+        """
+        Constructs a title for the field plot based on the mode, iteration, and slice number.
+
+        Args:
+            slice_number (int): The slice number for which the field is plotted.
+            show_mode_label (bool): Flag to include the mode label in the title.
+            show_itr (bool): Flag to include the iteration number in the title.
+            show_slice (bool): Flag to include the slice number in the title.
+
+        Returns:
+            str: The constructed title for the plot.
+        """
+        title = ''
+
+        if show_mode_label:
+            title += f'{self.stylized_label}'
+
+        if show_itr or show_slice:
+            itr = slice_to_itr(itr_list=self.itr_list, slice_number=slice_number)
+            title += '\n'
+
+        if show_slice:
+            title += f'slice: {slice_number}'
+
+        if show_itr:
+            title += f'  itr: {itr:.3f}'
+
+        return title
+
+
+# -
```

## SuPyMode/representation/index.py

 * *Ordering differences only*

```diff
@@ -1,83 +1,83 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-from SuPyMode.representation.base import InheritFromSuperMode, BaseSingleModePlot
-from MPSPlots.render2D import SceneList, Axis
-
-
-class Index(InheritFromSuperMode, BaseSingleModePlot):
-    """
-    Represents the effective refractive index of a mode derived from a supermode in optical fiber simulations.
-
-    This class extends from `InheritFromSuperMode` for accessing supermode-related data and `BaseSingleModePlot`
-    for plotting functionalities tailored to visualize the effective refractive index.
-
-    Class Attributes:
-        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
-    """
-
-    plot_style = dict(
-        show_legend=True,
-        x_label='Inverse taper ratio',
-        y_label='Effective refraction index',
-        y_scale="linear",
-        y_limits=[1.44, 1.455],
-        line_width=2
-    )
-
-    def __init__(self, parent_supermode: SuperMode):
-        """
-        Initializes an Index object with a reference to a parent supermode.
-
-        Args:
-            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
-        """
-        self.parent_supermode = parent_supermode
-
-    @property
-    def data(self):
-        return self.parent_supermode.binded_supermode.get_index()
-
-    def render_on_ax(self, ax: Axis) -> None:
-        """
-        Renders the effective refractive index data as a line plot on the provided Axis object.
-
-        Args:
-            ax (Axis): The Axis object on which to plot the effective refractive index.
-
-        Note:
-            This method utilizes the `plot_style` class attribute to define the appearance of the plot.
-        """
-        ax.add_line(
-            x=self.itr_list,
-            y=self.data,
-            label=f'{self.stylized_label}'
-        )
-
-    def plot(self) -> SceneList:
-        """
-        Generates a plot of the effective refractive index using a SceneList.
-
-        This method creates a single-axis plot showing the effective refractive index as a function of the inverse taper ratio,
-        formatted according to the predefined plot style.
-
-        Returns:
-            SceneList: A scene list containing the plot of effective refractive index.
-        """
-        figure = SceneList()
-
-        ax = figure.append_ax()
-
-        ax.set_style(**self.plot_style)
-
-        self.render_on_ax(ax=ax)
-
-        return figure
-
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+from SuPyMode.representation.base import InheritFromSuperMode, BaseSingleModePlot
+from MPSPlots.render2D import SceneList, Axis
+
+
+class Index(InheritFromSuperMode, BaseSingleModePlot):
+    """
+    Represents the effective refractive index of a mode derived from a supermode in optical fiber simulations.
+
+    This class extends from `InheritFromSuperMode` for accessing supermode-related data and `BaseSingleModePlot`
+    for plotting functionalities tailored to visualize the effective refractive index.
+
+    Class Attributes:
+        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
+    """
+
+    plot_style = dict(
+        show_legend=True,
+        x_label='Inverse taper ratio',
+        y_label='Effective refraction index',
+        y_scale="linear",
+        y_limits=[1.44, 1.455],
+        line_width=2
+    )
+
+    def __init__(self, parent_supermode: SuperMode):
+        """
+        Initializes an Index object with a reference to a parent supermode.
+
+        Args:
+            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
+        """
+        self.parent_supermode = parent_supermode
+
+    @property
+    def data(self):
+        return self.parent_supermode.binded_supermode.get_index()
+
+    def render_on_ax(self, ax: Axis) -> None:
+        """
+        Renders the effective refractive index data as a line plot on the provided Axis object.
+
+        Args:
+            ax (Axis): The Axis object on which to plot the effective refractive index.
+
+        Note:
+            This method utilizes the `plot_style` class attribute to define the appearance of the plot.
+        """
+        ax.add_line(
+            x=self.itr_list,
+            y=self.data,
+            label=f'{self.stylized_label}'
+        )
+
+    def plot(self) -> SceneList:
+        """
+        Generates a plot of the effective refractive index using a SceneList.
+
+        This method creates a single-axis plot showing the effective refractive index as a function of the inverse taper ratio,
+        formatted according to the predefined plot style.
+
+        Returns:
+            SceneList: A scene list containing the plot of effective refractive index.
+        """
+        figure = SceneList()
+
+        ax = figure.append_ax()
+
+        ax.set_style(**self.plot_style)
+
+        self.render_on_ax(ax=ax)
+
+        return figure
+
+
+# -
```

## SuPyMode/representation/normalized_coupling.py

 * *Ordering differences only*

```diff
@@ -1,104 +1,104 @@
-# #!/usr/bin/env python
-# # -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from SuPyMode.supermode import SuperMode
-
-import numpy
-
-from SuPyMode.representation.base import InheritFromSuperMode, BaseMultiModePlot
-from MPSPlots.render2D import SceneList, Axis
-
-
-class NormalizedCoupling(InheritFromSuperMode, BaseMultiModePlot):
-    """
-    Represents the normalized mode coupling between modes of different supermodes in optical fiber simulations.
-
-    This class extends from `InheritFromSuperMode` for accessing supermode-related data and `BaseMultiModePlot`
-    for plotting functionalities tailored to visualize mode coupling comparisons.
-
-    Class Attributes:
-        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
-    """
-
-    plot_style = dict(
-        show_legend=True,
-        x_label='Inverse taper ratio',
-        y_label='Mode coupling',
-        y_scale="linear",
-        line_width=2
-    )
-
-    def __init__(self, parent_supermode: SuperMode):
-        """
-        Initializes a NormalizedCoupling object with a reference to a parent supermode.
-
-        Args:
-            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
-        """
-        self.parent_supermode = parent_supermode
-
-    def get_values(self, other_supermode: SuperMode) -> numpy.ndarray:
-        """
-        Calculates the normalized mode coupling between the parent supermode and another specified supermode.
-
-        Args:
-            other_supermode (SuperMode): The supermode with which to compare the parent supermode.
-
-        Returns:
-            numpy.ndarray: An array of normalized mode coupling values, adjusted for computational compatibility.
-        """
-        output = self.parent_supermode.binded_supermode.get_normalized_coupling_with_mode(other_supermode.binded_supermode)
-
-        if not self.parent_supermode.is_computation_compatible(other_supermode):
-            output *= 0
-
-        return output
-
-    def render_on_ax(self, ax: Axis, other_supermode: SuperMode) -> None:
-        """
-        Renders normalized mode coupling data as a line plot on the provided Axis object, comparing the parent supermode
-        with another supermode.
-
-        Args:
-            ax (Axis): The Axis object on which to plot the normalized mode coupling.
-            other_supermode (SuperMode): The other supermode to compare against.
-
-        Note:
-            This method is conditioned on computational compatibility between the supermodes.
-        """
-        if not self.parent_supermode.is_computation_compatible(other_supermode):
-            return
-
-        y = self.get_values(other_supermode=other_supermode)
-
-        ax.add_line(
-            x=self.itr_list,
-            y=numpy.abs(y),
-            label=f'{self.parent_supermode.stylized_label} - {other_supermode.stylized_label}'
-        )
-
-    def plot(self, other_supermode: SuperMode) -> SceneList:
-        """
-        Generates a plot of normalized mode coupling between the parent supermode and another specified supermode using a SceneList.
-
-        This method creates a single-axis plot showing the comparative mode couplings as a function of the inverse taper ratio,
-        formatted according to the predefined plot style.
-
-        Args:
-            other_supermode (SuperMode): The supermode to compare against.
-
-        Returns:
-            SceneList: A scene list containing the plot of normalized mode couplings.
-        """
-        figure = SceneList()
-
-        ax = figure.append_ax(**self.plot_style)
-
-        self.render_on_ax(ax=ax, other_supermode=other_supermode)
-
-        return figure
-
-# -
+# #!/usr/bin/env python
+# # -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from SuPyMode.supermode import SuperMode
+
+import numpy
+
+from SuPyMode.representation.base import InheritFromSuperMode, BaseMultiModePlot
+from MPSPlots.render2D import SceneList, Axis
+
+
+class NormalizedCoupling(InheritFromSuperMode, BaseMultiModePlot):
+    """
+    Represents the normalized mode coupling between modes of different supermodes in optical fiber simulations.
+
+    This class extends from `InheritFromSuperMode` for accessing supermode-related data and `BaseMultiModePlot`
+    for plotting functionalities tailored to visualize mode coupling comparisons.
+
+    Class Attributes:
+        plot_style (dict): A dictionary defining the default style settings for plots generated by this class.
+    """
+
+    plot_style = dict(
+        show_legend=True,
+        x_label='Inverse taper ratio',
+        y_label='Mode coupling',
+        y_scale="linear",
+        line_width=2
+    )
+
+    def __init__(self, parent_supermode: SuperMode):
+        """
+        Initializes a NormalizedCoupling object with a reference to a parent supermode.
+
+        Args:
+            parent_supermode (SuperMode): The parent supermode object that provides the base mode data.
+        """
+        self.parent_supermode = parent_supermode
+
+    def get_values(self, other_supermode: SuperMode) -> numpy.ndarray:
+        """
+        Calculates the normalized mode coupling between the parent supermode and another specified supermode.
+
+        Args:
+            other_supermode (SuperMode): The supermode with which to compare the parent supermode.
+
+        Returns:
+            numpy.ndarray: An array of normalized mode coupling values, adjusted for computational compatibility.
+        """
+        output = self.parent_supermode.binded_supermode.get_normalized_coupling_with_mode(other_supermode.binded_supermode)
+
+        if not self.parent_supermode.is_computation_compatible(other_supermode):
+            output *= 0
+
+        return output
+
+    def render_on_ax(self, ax: Axis, other_supermode: SuperMode) -> None:
+        """
+        Renders normalized mode coupling data as a line plot on the provided Axis object, comparing the parent supermode
+        with another supermode.
+
+        Args:
+            ax (Axis): The Axis object on which to plot the normalized mode coupling.
+            other_supermode (SuperMode): The other supermode to compare against.
+
+        Note:
+            This method is conditioned on computational compatibility between the supermodes.
+        """
+        if not self.parent_supermode.is_computation_compatible(other_supermode):
+            return
+
+        y = self.get_values(other_supermode=other_supermode)
+
+        ax.add_line(
+            x=self.itr_list,
+            y=numpy.abs(y),
+            label=f'{self.parent_supermode.stylized_label} - {other_supermode.stylized_label}'
+        )
+
+    def plot(self, other_supermode: SuperMode) -> SceneList:
+        """
+        Generates a plot of normalized mode coupling between the parent supermode and another specified supermode using a SceneList.
+
+        This method creates a single-axis plot showing the comparative mode couplings as a function of the inverse taper ratio,
+        formatted according to the predefined plot style.
+
+        Args:
+            other_supermode (SuperMode): The supermode to compare against.
+
+        Returns:
+            SceneList: A scene list containing the plot of normalized mode couplings.
+        """
+        figure = SceneList()
+
+        ax = figure.append_ax(**self.plot_style)
+
+        self.render_on_ax(ax=ax, other_supermode=other_supermode)
+
+        return figure
+
+# -
```

## SuPyMode/tools/special.py

 * *Ordering differences only*

```diff
@@ -1,163 +1,163 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import matplotlib.pyplot as plt
-
-from MPSPlots import CMAP
-from matplotlib.animation import FuncAnimation, PillowWriter
-
-
-def get_3_figures():
-
-    fig = plt.figure(figsize=(8, 6))
-
-    gs = fig.add_gridspec(
-        2, 2,
-        width_ratios=(1, 1),
-        height_ratios=(1, 1),
-        left=0.1,
-        right=0.9,
-        bottom=0.1,
-        top=0.9,
-        wspace=0.5 * 2,
-        hspace=0.15)
-
-    ax0 = fig.add_subplot(gs[0, 0:])
-    ax1 = fig.add_subplot(gs[1, 0])
-    ax2 = fig.add_subplot(gs[1, 1])
-
-    ax1.tick_params(
-        axis='both',
-        which='both',
-        top=False,
-        bottom=False,
-        right=False,
-        left=False,
-        labelleft=False,
-        labelbottom=False,
-        grid_alpha=0
-    )
-    ax2.tick_params(
-        axis='both',
-        which='both',
-        top=False,
-        bottom=False,
-        right=False,
-        left=False,
-        labelleft=False,
-        labelbottom=False,
-        grid_alpha=0
-    )
-
-    ax1.set_aspect('equal')
-    ax2.set_aspect('equal')
-
-    return fig, ax0, ax1, ax2
-
-
-class ModePropagationGifCreator():
-    def __init__(
-            self,
-            superset,
-            profile,
-            max_number_of_mode: int = None,
-            dark_background: bool = True):
-
-        self.superset = superset
-        self.profile = profile
-        self.dark_background = dark_background
-
-        if max_number_of_mode is None:
-            self.number_of_mode = len(superset.supermodes)
-        else:
-            self.number_of_mode = max_number_of_mode
-
-        self.generate_figure()
-
-    def generate_profile_ax(self):
-        self.ax_profile = self.figure.add_subplot(self.grid_spec[0, :])
-        self.ax_profile.set_xlabel('Propagation distance z')
-        self.ax_profile.set_ylabel('Coupler profile')
-
-        top = self.profile.radius
-        bottom = -self.profile.radius
-
-        self.ax_profile.plot(self.profile.distance, top, color='black')
-        self.ax_profile.plot(self.profile.distance, bottom, color='black')
-        self.ax_profile.fill_between(self.profile.distance, top, bottom, color='lightblue', alpha=0.8)
-
-    def generate_field_ax(self):
-        self.field_axes = []
-        for mode in range(self.number_of_mode):
-            ax = self.figure.add_subplot(self.grid_spec[1, mode])
-            ax.set_aspect('equal')
-            ax.set_xticks([])
-            ax.set_yticks([])
-            self.field_axes.append(ax)
-            ax.set_title(self.superset[mode].stylized_name)
-
-    def generate_figure(self, unit_size: tuple = (3, 6)) -> None:
-        figure_size = (unit_size[0] * self.number_of_mode, unit_size[1])
-        self.figure = plt.figure(figsize=figure_size)
-
-        self.grid_spec = self.figure.add_gridspec(
-            2,
-            self.number_of_mode,
-            left=0.1,
-            right=0.95,
-            bottom=0.1,
-            top=0.9,
-            wspace=0.5,
-            hspace=0.35
-        )
-
-        self.generate_profile_ax()
-
-        self.generate_field_ax()
-
-    def populate_axes(self, z: float):
-        itr = self.profile.master_interpolation_z_to_itr(z)
-        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
-
-        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
-        self.profile_line = self.ax_profile.axvline(z, linestyle='--', color='red')
-
-        for ax, field in zip(self.field_axes, slice_structure.fields):
-            ax.pcolormesh(field, cmap=CMAP.BKR)
-
-    def update_axes(self, z: float):
-        itr = self.profile.master_interpolation_z_to_itr(z)
-        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
-        self.profile_line.set_xdata(z)
-        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
-
-        for ax, field in zip(self.field_axes, slice_structure.fields):
-            ax.clear()
-            ax.pcolormesh(field, cmap=CMAP.BKR)
-
-    def make_animation(self, n_step: int = 20, dpi: float = 100, fps: int = 50):
-        self.populate_axes(z=0e-3)
-
-        factor = self.profile.length / n_step
-
-        def animate(iteration):
-            distance = iteration * factor
-            print(f"iteration: {iteration} / {n_step}")
-
-            self.update_axes(distance)
-
-        ani = FuncAnimation(
-            self.figure,
-            animate,
-            interval=40,
-            blit=True,
-            repeat=True,
-            frames=n_step
-        )
-
-        ani.save(
-            "propagation.gif",
-            dpi=dpi,
-            writer=PillowWriter(fps=fps)
-        )
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+import matplotlib.pyplot as plt
+
+from MPSPlots import CMAP
+from matplotlib.animation import FuncAnimation, PillowWriter
+
+
+def get_3_figures():
+
+    fig = plt.figure(figsize=(8, 6))
+
+    gs = fig.add_gridspec(
+        2, 2,
+        width_ratios=(1, 1),
+        height_ratios=(1, 1),
+        left=0.1,
+        right=0.9,
+        bottom=0.1,
+        top=0.9,
+        wspace=0.5 * 2,
+        hspace=0.15)
+
+    ax0 = fig.add_subplot(gs[0, 0:])
+    ax1 = fig.add_subplot(gs[1, 0])
+    ax2 = fig.add_subplot(gs[1, 1])
+
+    ax1.tick_params(
+        axis='both',
+        which='both',
+        top=False,
+        bottom=False,
+        right=False,
+        left=False,
+        labelleft=False,
+        labelbottom=False,
+        grid_alpha=0
+    )
+    ax2.tick_params(
+        axis='both',
+        which='both',
+        top=False,
+        bottom=False,
+        right=False,
+        left=False,
+        labelleft=False,
+        labelbottom=False,
+        grid_alpha=0
+    )
+
+    ax1.set_aspect('equal')
+    ax2.set_aspect('equal')
+
+    return fig, ax0, ax1, ax2
+
+
+class ModePropagationGifCreator():
+    def __init__(
+            self,
+            superset,
+            profile,
+            max_number_of_mode: int = None,
+            dark_background: bool = True):
+
+        self.superset = superset
+        self.profile = profile
+        self.dark_background = dark_background
+
+        if max_number_of_mode is None:
+            self.number_of_mode = len(superset.supermodes)
+        else:
+            self.number_of_mode = max_number_of_mode
+
+        self.generate_figure()
+
+    def generate_profile_ax(self):
+        self.ax_profile = self.figure.add_subplot(self.grid_spec[0, :])
+        self.ax_profile.set_xlabel('Propagation distance z')
+        self.ax_profile.set_ylabel('Coupler profile')
+
+        top = self.profile.radius
+        bottom = -self.profile.radius
+
+        self.ax_profile.plot(self.profile.distance, top, color='black')
+        self.ax_profile.plot(self.profile.distance, bottom, color='black')
+        self.ax_profile.fill_between(self.profile.distance, top, bottom, color='lightblue', alpha=0.8)
+
+    def generate_field_ax(self):
+        self.field_axes = []
+        for mode in range(self.number_of_mode):
+            ax = self.figure.add_subplot(self.grid_spec[1, mode])
+            ax.set_aspect('equal')
+            ax.set_xticks([])
+            ax.set_yticks([])
+            self.field_axes.append(ax)
+            ax.set_title(self.superset[mode].stylized_name)
+
+    def generate_figure(self, unit_size: tuple = (3, 6)) -> None:
+        figure_size = (unit_size[0] * self.number_of_mode, unit_size[1])
+        self.figure = plt.figure(figsize=figure_size)
+
+        self.grid_spec = self.figure.add_gridspec(
+            2,
+            self.number_of_mode,
+            left=0.1,
+            right=0.95,
+            bottom=0.1,
+            top=0.9,
+            wspace=0.5,
+            hspace=0.35
+        )
+
+        self.generate_profile_ax()
+
+        self.generate_field_ax()
+
+    def populate_axes(self, z: float):
+        itr = self.profile.master_interpolation_z_to_itr(z)
+        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
+
+        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
+        self.profile_line = self.ax_profile.axvline(z, linestyle='--', color='red')
+
+        for ax, field in zip(self.field_axes, slice_structure.fields):
+            ax.pcolormesh(field, cmap=CMAP.BKR)
+
+    def update_axes(self, z: float):
+        itr = self.profile.master_interpolation_z_to_itr(z)
+        slice_structure = self.superset.get_slice_structure(itr=itr, add_symmetries=True)
+        self.profile_line.set_xdata(z)
+        self.ax_profile.set_title(f'Z-distance: {z:>5.3e}    ITR: {itr:>5.3f}')
+
+        for ax, field in zip(self.field_axes, slice_structure.fields):
+            ax.clear()
+            ax.pcolormesh(field, cmap=CMAP.BKR)
+
+    def make_animation(self, n_step: int = 20, dpi: float = 100, fps: int = 50):
+        self.populate_axes(z=0e-3)
+
+        factor = self.profile.length / n_step
+
+        def animate(iteration):
+            distance = iteration * factor
+            print(f"iteration: {iteration} / {n_step}")
+
+            self.update_axes(distance)
+
+        ani = FuncAnimation(
+            self.figure,
+            animate,
+            interval=40,
+            blit=True,
+            repeat=True,
+            frames=n_step
+        )
+
+        ani.save(
+            "propagation.gif",
+            dpi=dpi,
+            writer=PillowWriter(fps=fps)
+        )
+# -
```

## SuPyMode/tools/utils.py

 * *Ordering differences only*

```diff
@@ -1,255 +1,255 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-from __future__ import annotations
-from typing import TYPE_CHECKING
-from typing import Iterable
-if TYPE_CHECKING:
-    from SuPyMode.superset import SuperSet
-    from SuPyMode.supermode import SuperMode
-
-import numpy
-import pickle
-from pathlib import Path
-from SuPyMode.directories import instance_directory
-
-
-def load_superset(filename: str, directory: str = '.'):
-    """
-    Saves the superset instance as a serialized pickle file.
-
-    :param      filename:  The filename
-    :type       filename:  str
-    """
-    if directory == 'auto':
-        directory = instance_directory
-
-    filename = Path(directory).joinpath(filename).with_suffix('.pickle')
-
-    with open(filename, 'rb') as input_file:
-        superset = pickle.load(input_file)
-
-    return superset
-
-
-def get_close_points(tolerane: float, y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray = None):
-    idx = numpy.argwhere(numpy.abs(y0 - y1) < tolerane)
-
-    if x is not None:
-        return x[idx], y0[idx]
-
-    return y0[idx]
-
-
-def get_intersection(y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray, average: bool = True):
-
-    idx = numpy.argwhere(numpy.diff(numpy.sign(y0 - y1))).flatten()
-
-    if len(idx) == 0:  # No intersection
-        return None, None
-
-    if not average:
-        return y0[idx]
-
-    else:
-        x_mean = (x[idx + 1] + x[idx]) / 2
-        y_mean = (y0[idx + 1] + y0[idx]) / 2
-
-        return x_mean, y_mean
-
-
-def test_valid_input(user_input, valid_inputs: list, variable_name: str = '') -> None:
-    if user_input not in valid_inputs:
-        raise ValueError(f"[{variable_name}] user_input: {user_input} argument not valid. Valid choices are: {valid_inputs}")
-
-
-def itr_to_slice(itr_list: numpy.ndarray, itr: float | list) -> int | list:
-    """
-    Convert itr value to slice number
-
-    :param      itr_list:  The itr list
-    :type       itr_list:  numpy.ndarray
-    :param      itr:       The itr
-    :type       itr:       float | list
-
-    :returns:   The equivalent slice numbers
-    :rtype:     float | list
-    """
-    return_scalar = False
-
-    if numpy.isscalar(itr):
-        return_scalar = True
-        itr = [itr]
-
-    slice_number = [
-        numpy.argmin(abs(itr_list - value)) for value in itr
-    ]
-
-    if return_scalar:
-        return slice_number[0]
-
-    return slice_number
-
-
-def slice_to_itr(itr_list: numpy.ndarray, slice_number: int | list) -> float | list:
-    """
-    Convert itr value to slice number
-
-    :param      itr_list:      The itr list
-    :type       itr_list:      numpy.ndarray
-    :param      slice_number:  The itr
-    :type       slice_number:  int | list
-
-    :returns:   The equivalent slice numbers
-    :rtype:     float | list
-    """
-    return_scalar = False
-
-    if numpy.isscalar(slice_number):
-        return_scalar = True
-        slice_number = [slice_number]
-
-    itr = itr_list[slice_number]
-
-    if return_scalar:
-        return itr[0]
-
-    return itr
-
-
-def interpret_slice_number_and_itr(
-        itr_baseline: numpy.ndarray,
-        slice_list: int | list[int] = [],
-        itr_list: float | list[float] = [],
-        sort_slice_number: bool = False) -> tuple:
-    """
-    Interprets slice numbers and corresponding inverse taper ratios (ITRs), returning arrays of slice numbers
-    and their respective ITRs based on the provided lists of slices and ITRs.
-
-    Parameters:
-    - itr_baseline (numpy.ndarray): Array of baseline ITR values, typically equidistant, representing the full range.
-    - slice_list (Union[int, List[int]], optional): A single slice index or a list of slice indices. Default is an empty list.
-    - itr_list (Union[float, List[float]], optional): A single ITR value or a list of ITR values to be converted to slice indices. Default is an empty list.
-    - sort_slice_number (bool, optional): Whether to sort the resulting slice numbers and corresponding ITRs in descending order. Default is False.
-
-    Returns:
-    - Tuple[numpy.ndarray, numpy.ndarray]: Two numpy arrays, the first containing slice indices and the second containing the corresponding ITR values.
-
-    Raises:
-    - ValueError: If the provided ITRs or slice indices are outside the bounds of the baseline ITR array.
-
-    Note:
-    - This function assumes that the input ITRs and slice numbers are within the range covered by the `itr_baseline`.
-    - The function will also combine and sort the slice indices derived directly and those converted from the given ITRs if `sort_slice_number` is True.
-    """
-    return_as_iterable = False
-
-    if isinstance(slice_list, Iterable) or isinstance(itr_list, Iterable):
-        return_as_iterable = True
-
-    slice_list = numpy.atleast_1d(slice_list)
-
-    slice_from_itr = itr_to_slice(itr_baseline, itr=itr_list)
-
-    slice_from_itr = numpy.atleast_1d(slice_from_itr)
-
-    total_slice_list = [*slice_list, *slice_from_itr]
-
-    total_itr_list = slice_to_itr(itr_baseline, slice_number=total_slice_list)
-
-    slice_list = numpy.asarray(total_slice_list)
-
-    itr_list = numpy.asarray(total_itr_list)
-
-    if sort_slice_number:
-        slice_list = numpy.sort(slice_list)[::-1]
-
-        itr_list = numpy.sort(itr_list)[::-1]
-
-    if not return_as_iterable:
-        return slice_list[0], itr_list[0]
-
-    return slice_list, itr_list
-
-
-def interpret_mode_of_interest(superset: SuperSet, mode_of_interest: str | SuperMode | list[SuperMode]) -> list[SuperMode]:
-    """
-    Resolves the mode of interest from user input to the appropriate list of SuperMode instances
-    based on the specified criteria or direct references.
-
-    Parameters:
-        - superset (SuperSet): The superset containing all supermodes, including fundamental and non-fundamental modes.
-        - mode_of_interest (Union[str, SuperMode, List[SuperMode]]): This parameter can be a string specifying a category
-          of modes such as 'fundamental', 'non-fundamental', 'all', a single SuperMode instance, or a list of SuperMode instances.
-
-    Returns:
-        - List[SuperMode]: A list of SuperMode instances corresponding to the specified mode of interest.
-
-    Raises:
-        - ValueError: If the mode_of_interest is not one of the expected types or if the string input does not match
-        any known category.
-    """
-    if isinstance(mode_of_interest, str):
-        match mode_of_interest:
-            case 'fundamental':
-                return superset.fundamental_supermodes
-            case 'non-fundamental':
-                return superset.non_fundamental_supermodes
-            case 'all':
-                return superset.supermodes
-            case _:
-                raise ValueError(f"Unrecognized mode category '{mode_of_interest}'. Expected 'fundamental', 'non-fundamental', or 'all'.")
-
-    if isinstance(mode_of_interest, SuperMode):
-        return [mode_of_interest]
-
-    if isinstance(mode_of_interest, list) and all(isinstance(item, SuperMode) for item in mode_of_interest):
-        return mode_of_interest
-
-    raise ValueError("mode_of_interest must be either 'fundamental', 'non-fundamental', 'all', a SuperMode instance, or a list of SuperMode instances.")
-
-
-def get_symmetrized_vector(vector: numpy.ndarray, symmetry_type: str = 'last') -> numpy.ndarray:
-    """
-    Generate a symmetric version of the input vector based on the specified symmetry type.
-
-    Parameters:
-    -----------
-    vector : numpy.ndarray
-        A one-dimensional array for which the symmetric version is to be calculated.
-    symmetry_type : str, optional
-        Type of symmetry to apply. Supported types:
-        - 'last': Symmetrize using the last element as reference.
-        - 'first': Symmetrize using the first element as reference.
-        Default is 'last'.
-
-    Returns:
-    --------
-    numpy.ndarray
-        A new vector that is the symmetrized version of the input vector.
-
-    Raises:
-    -------
-    ValueError
-        If the input vector is not one-dimensional or the symmetry type is unsupported.
-    """
-
-    if vector.ndim != 1:
-        raise ValueError(f"Expected a 1-dimensional vector, but got a {vector.ndim}-dimensional vector instead.")
-
-    if symmetry_type.lower() not in ['last', 'first']:
-        raise ValueError("Symmetry type must be 'last' or 'first'.")
-
-    size = len(vector)
-    dx = numpy.diff(vector)[0]  # More robust than assuming vector[1] - vector[0]
-
-    if symmetry_type.lower() == 'last':
-        start_value = vector[-1]
-        expanded = numpy.arange(0, 2 * size - 1) * dx
-        return start_value - expanded[::-1] if dx > 0 else start_value + expanded[::-1]
-    else:  # 'first'
-        start_value = vector[0]
-        expanded = numpy.arange(0, 2 * size - 1) * dx
-        return start_value + expanded
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+from __future__ import annotations
+from typing import TYPE_CHECKING
+from typing import Iterable
+if TYPE_CHECKING:
+    from SuPyMode.superset import SuperSet
+    from SuPyMode.supermode import SuperMode
+
+import numpy
+import pickle
+from pathlib import Path
+from SuPyMode.directories import instance_directory
+
+
+def load_superset(filename: str, directory: str = '.'):
+    """
+    Saves the superset instance as a serialized pickle file.
+
+    :param      filename:  The filename
+    :type       filename:  str
+    """
+    if directory == 'auto':
+        directory = instance_directory
+
+    filename = Path(directory).joinpath(filename).with_suffix('.pickle')
+
+    with open(filename, 'rb') as input_file:
+        superset = pickle.load(input_file)
+
+    return superset
+
+
+def get_close_points(tolerane: float, y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray = None):
+    idx = numpy.argwhere(numpy.abs(y0 - y1) < tolerane)
+
+    if x is not None:
+        return x[idx], y0[idx]
+
+    return y0[idx]
+
+
+def get_intersection(y0: numpy.ndarray, y1: numpy.ndarray, x: numpy.ndarray, average: bool = True):
+
+    idx = numpy.argwhere(numpy.diff(numpy.sign(y0 - y1))).flatten()
+
+    if len(idx) == 0:  # No intersection
+        return None, None
+
+    if not average:
+        return y0[idx]
+
+    else:
+        x_mean = (x[idx + 1] + x[idx]) / 2
+        y_mean = (y0[idx + 1] + y0[idx]) / 2
+
+        return x_mean, y_mean
+
+
+def test_valid_input(user_input, valid_inputs: list, variable_name: str = '') -> None:
+    if user_input not in valid_inputs:
+        raise ValueError(f"[{variable_name}] user_input: {user_input} argument not valid. Valid choices are: {valid_inputs}")
+
+
+def itr_to_slice(itr_list: numpy.ndarray, itr: float | list) -> int | list:
+    """
+    Convert itr value to slice number
+
+    :param      itr_list:  The itr list
+    :type       itr_list:  numpy.ndarray
+    :param      itr:       The itr
+    :type       itr:       float | list
+
+    :returns:   The equivalent slice numbers
+    :rtype:     float | list
+    """
+    return_scalar = False
+
+    if numpy.isscalar(itr):
+        return_scalar = True
+        itr = [itr]
+
+    slice_number = [
+        numpy.argmin(abs(itr_list - value)) for value in itr
+    ]
+
+    if return_scalar:
+        return slice_number[0]
+
+    return slice_number
+
+
+def slice_to_itr(itr_list: numpy.ndarray, slice_number: int | list) -> float | list:
+    """
+    Convert itr value to slice number
+
+    :param      itr_list:      The itr list
+    :type       itr_list:      numpy.ndarray
+    :param      slice_number:  The itr
+    :type       slice_number:  int | list
+
+    :returns:   The equivalent slice numbers
+    :rtype:     float | list
+    """
+    return_scalar = False
+
+    if numpy.isscalar(slice_number):
+        return_scalar = True
+        slice_number = [slice_number]
+
+    itr = itr_list[slice_number]
+
+    if return_scalar:
+        return itr[0]
+
+    return itr
+
+
+def interpret_slice_number_and_itr(
+        itr_baseline: numpy.ndarray,
+        slice_list: int | list[int] = [],
+        itr_list: float | list[float] = [],
+        sort_slice_number: bool = False) -> tuple:
+    """
+    Interprets slice numbers and corresponding inverse taper ratios (ITRs), returning arrays of slice numbers
+    and their respective ITRs based on the provided lists of slices and ITRs.
+
+    Parameters:
+    - itr_baseline (numpy.ndarray): Array of baseline ITR values, typically equidistant, representing the full range.
+    - slice_list (Union[int, List[int]], optional): A single slice index or a list of slice indices. Default is an empty list.
+    - itr_list (Union[float, List[float]], optional): A single ITR value or a list of ITR values to be converted to slice indices. Default is an empty list.
+    - sort_slice_number (bool, optional): Whether to sort the resulting slice numbers and corresponding ITRs in descending order. Default is False.
+
+    Returns:
+    - Tuple[numpy.ndarray, numpy.ndarray]: Two numpy arrays, the first containing slice indices and the second containing the corresponding ITR values.
+
+    Raises:
+    - ValueError: If the provided ITRs or slice indices are outside the bounds of the baseline ITR array.
+
+    Note:
+    - This function assumes that the input ITRs and slice numbers are within the range covered by the `itr_baseline`.
+    - The function will also combine and sort the slice indices derived directly and those converted from the given ITRs if `sort_slice_number` is True.
+    """
+    return_as_iterable = False
+
+    if isinstance(slice_list, Iterable) or isinstance(itr_list, Iterable):
+        return_as_iterable = True
+
+    slice_list = numpy.atleast_1d(slice_list)
+
+    slice_from_itr = itr_to_slice(itr_baseline, itr=itr_list)
+
+    slice_from_itr = numpy.atleast_1d(slice_from_itr)
+
+    total_slice_list = [*slice_list, *slice_from_itr]
+
+    total_itr_list = slice_to_itr(itr_baseline, slice_number=total_slice_list)
+
+    slice_list = numpy.asarray(total_slice_list)
+
+    itr_list = numpy.asarray(total_itr_list)
+
+    if sort_slice_number:
+        slice_list = numpy.sort(slice_list)[::-1]
+
+        itr_list = numpy.sort(itr_list)[::-1]
+
+    if not return_as_iterable:
+        return slice_list[0], itr_list[0]
+
+    return slice_list, itr_list
+
+
+def interpret_mode_of_interest(superset: SuperSet, mode_of_interest: str | SuperMode | list[SuperMode]) -> list[SuperMode]:
+    """
+    Resolves the mode of interest from user input to the appropriate list of SuperMode instances
+    based on the specified criteria or direct references.
+
+    Parameters:
+        - superset (SuperSet): The superset containing all supermodes, including fundamental and non-fundamental modes.
+        - mode_of_interest (Union[str, SuperMode, List[SuperMode]]): This parameter can be a string specifying a category
+          of modes such as 'fundamental', 'non-fundamental', 'all', a single SuperMode instance, or a list of SuperMode instances.
+
+    Returns:
+        - List[SuperMode]: A list of SuperMode instances corresponding to the specified mode of interest.
+
+    Raises:
+        - ValueError: If the mode_of_interest is not one of the expected types or if the string input does not match
+        any known category.
+    """
+    if isinstance(mode_of_interest, str):
+        match mode_of_interest:
+            case 'fundamental':
+                return superset.fundamental_supermodes
+            case 'non-fundamental':
+                return superset.non_fundamental_supermodes
+            case 'all':
+                return superset.supermodes
+            case _:
+                raise ValueError(f"Unrecognized mode category '{mode_of_interest}'. Expected 'fundamental', 'non-fundamental', or 'all'.")
+
+    if isinstance(mode_of_interest, SuperMode):
+        return [mode_of_interest]
+
+    if isinstance(mode_of_interest, list) and all(isinstance(item, SuperMode) for item in mode_of_interest):
+        return mode_of_interest
+
+    raise ValueError("mode_of_interest must be either 'fundamental', 'non-fundamental', 'all', a SuperMode instance, or a list of SuperMode instances.")
+
+
+def get_symmetrized_vector(vector: numpy.ndarray, symmetry_type: str = 'last') -> numpy.ndarray:
+    """
+    Generate a symmetric version of the input vector based on the specified symmetry type.
+
+    Parameters:
+    -----------
+    vector : numpy.ndarray
+        A one-dimensional array for which the symmetric version is to be calculated.
+    symmetry_type : str, optional
+        Type of symmetry to apply. Supported types:
+        - 'last': Symmetrize using the last element as reference.
+        - 'first': Symmetrize using the first element as reference.
+        Default is 'last'.
+
+    Returns:
+    --------
+    numpy.ndarray
+        A new vector that is the symmetrized version of the input vector.
+
+    Raises:
+    -------
+    ValueError
+        If the input vector is not one-dimensional or the symmetry type is unsupported.
+    """
+
+    if vector.ndim != 1:
+        raise ValueError(f"Expected a 1-dimensional vector, but got a {vector.ndim}-dimensional vector instead.")
+
+    if symmetry_type.lower() not in ['last', 'first']:
+        raise ValueError("Symmetry type must be 'last' or 'first'.")
+
+    size = len(vector)
+    dx = numpy.diff(vector)[0]  # More robust than assuming vector[1] - vector[0]
+
+    if symmetry_type.lower() == 'last':
+        start_value = vector[-1]
+        expanded = numpy.arange(0, 2 * size - 1) * dx
+        return start_value - expanded[::-1] if dx > 0 else start_value + expanded[::-1]
+    else:  # 'first'
+        start_value = vector[0]
+        expanded = numpy.arange(0, 2 * size - 1) * dx
+        return start_value + expanded
+
+# -
```

## SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP02.csv

 * *Ordering differences only*

```diff
@@ -1,98 +1,98 @@
-0.020000000000000004, 0.8249134758014961
-0.03, 0.365138782972937
-0.039999999999999994, 0.17842650896491133
-0.05, 0.10877085024652641
-0.06000000000000001, 0.07465917220502982
-0.07000000000000002, 0.05319415898131244
-0.08, 0.040716348314949025
-0.08999999999999998, 0.03243494289089723
-0.09999999999999999, 0.026383498832942165
-0.10914089347079041, 0.02275508147526975
-0.11999999999999998, 0.020365117938598166
-0.12999999999999995, 0.0183660033053568
-0.13999999999999996, 0.01632578976162163
-0.14999999999999997, 0.014353215145811284
-0.15999999999999998, 0.012523429778128979
-0.16999999999999998, 0.0108812831432483
-0.18, 0.009447204466244344
-0.19, 0.008223875688907306
-0.2, 0.007202502514282347
-0.21000000000000002, 0.0063680666594324205
-0.22000000000000003, 0.005703385471084978
-0.23000000000000004, 0.0051920926313168735
-0.24000000000000005, 0.004757583392223299
-0.25000000000000006, 0.004486859619224838
-0.26000000000000006, 0.004099602559840619
-0.2700000000000001, 0.003818827649437257
-0.2800000000000001, 0.0036294662335879394
-0.2900000000000001, 0.0033281047227092294
-0.3000000000000001, 0.0031823319520634524
-0.3100000000000001, 0.0029882299643200724
-0.3200000000000002, 0.0028474337911871834
-0.33000000000000007, 0.0027353728113474842
-0.34000000000000014, 0.002629163567485178
-0.35000000000000014, 0.002518326145374376
-0.36000000000000015, 0.0024160504228849943
-0.37000000000000016, 0.0023132147130202267
-0.38000000000000017, 0.0022688915016602124
-0.39000000000000024, 0.0022254598319485235
-0.40000000000000013, 0.0021800314780090623
-0.41000000000000014, 0.0021337027185190263
-0.42000000000000015, 0.0020901703564934196
-0.43000000000000016, 0.0020900175038884214
-0.44000000000000017, 0.002090017683999846
-0.4500000000000002, 0.002086722384446414
-0.4600000000000002, 0.0021336572552876692
-0.4700000000000002, 0.002177295249606736
-0.4800000000000002, 0.0022232773474854667
-0.4900000000000002, 0.0022708582655766108
-0.5000000000000002, 0.0023677191665626013
-0.5100000000000002, 0.0024185769095793016
-0.5200000000000002, 0.002514114352819277
-0.5300000000000002, 0.002617964576029904
-0.5400000000000003, 0.0028159448184314215
-0.5500000000000003, 0.0029461274312934183
-0.5600000000000003, 0.0030885993792761357
-0.5700000000000003, 0.0032325030798505913
-0.5800000000000003, 0.003364776755717139
-0.5900000000000003, 0.0034976933556842547
-0.6000000000000003, 0.0036882097696743213
-0.6100000000000003, 0.003895523065398759
-0.6200000000000003, 0.004079140025108818
-0.6300000000000004, 0.004307919249530014
-0.6400000000000005, 0.004492202407796801
-0.6500000000000002, 0.004734456318932722
-0.6600000000000003, 0.004951949837248759
-0.6700000000000004, 0.005205527039986248
-0.6800000000000004, 0.005411455937812412
-0.6900000000000004, 0.005635413706703852
-0.7000000000000004, 0.005873854436394826
-0.7100000000000004, 0.006124085905971173
-0.7200000000000004, 0.006325641189434088
-0.7300000000000004, 0.006655273182515841
-0.7400000000000004, 0.006949994897143527
-0.7500000000000004, 0.007053209028418031
-0.7600000000000005, 0.007367822721810779
-0.7700000000000006, 0.0076844864490485726
-0.7800000000000006, 0.007770728860309734
-0.7900000000000004, 0.008022609955346155
-0.8000000000000004, 0.008347679064679201
-0.8100000000000005, 0.008527334390269843
-0.8200000000000005, 0.008507488326664842
-0.8300000000000005, 0.008944383338538081
-0.8400000000000005, 0.009242631415676716
-0.8500000000000005, 0.009344108130985794
-0.8600000000000005, 0.00953588357235412
-0.8700000000000006, 0.00965386859086834
-0.8800000000000006, 0.009895366047267979
-0.8900000000000006, 0.010063216077208923
-0.9000000000000007, 0.01006181544221102
-0.9100000000000005, 0.010062717312160116
-0.9200000000000005, 0.010486610535172032
-0.9300000000000005, 0.010258241778114553
-0.9400000000000005, 0.010271985542128157
-0.9500000000000005, 0.010481123730144377
-0.9600000000000005, 0.010375964050702756
-0.9700000000000005, 0.010272011737671803
-0.9800000000000005, 0.010269874472298013
-0.9900000000000005, 0.010166386694748668
+0.020000000000000004, 0.8249134758014961
+0.03, 0.365138782972937
+0.039999999999999994, 0.17842650896491133
+0.05, 0.10877085024652641
+0.06000000000000001, 0.07465917220502982
+0.07000000000000002, 0.05319415898131244
+0.08, 0.040716348314949025
+0.08999999999999998, 0.03243494289089723
+0.09999999999999999, 0.026383498832942165
+0.10914089347079041, 0.02275508147526975
+0.11999999999999998, 0.020365117938598166
+0.12999999999999995, 0.0183660033053568
+0.13999999999999996, 0.01632578976162163
+0.14999999999999997, 0.014353215145811284
+0.15999999999999998, 0.012523429778128979
+0.16999999999999998, 0.0108812831432483
+0.18, 0.009447204466244344
+0.19, 0.008223875688907306
+0.2, 0.007202502514282347
+0.21000000000000002, 0.0063680666594324205
+0.22000000000000003, 0.005703385471084978
+0.23000000000000004, 0.0051920926313168735
+0.24000000000000005, 0.004757583392223299
+0.25000000000000006, 0.004486859619224838
+0.26000000000000006, 0.004099602559840619
+0.2700000000000001, 0.003818827649437257
+0.2800000000000001, 0.0036294662335879394
+0.2900000000000001, 0.0033281047227092294
+0.3000000000000001, 0.0031823319520634524
+0.3100000000000001, 0.0029882299643200724
+0.3200000000000002, 0.0028474337911871834
+0.33000000000000007, 0.0027353728113474842
+0.34000000000000014, 0.002629163567485178
+0.35000000000000014, 0.002518326145374376
+0.36000000000000015, 0.0024160504228849943
+0.37000000000000016, 0.0023132147130202267
+0.38000000000000017, 0.0022688915016602124
+0.39000000000000024, 0.0022254598319485235
+0.40000000000000013, 0.0021800314780090623
+0.41000000000000014, 0.0021337027185190263
+0.42000000000000015, 0.0020901703564934196
+0.43000000000000016, 0.0020900175038884214
+0.44000000000000017, 0.002090017683999846
+0.4500000000000002, 0.002086722384446414
+0.4600000000000002, 0.0021336572552876692
+0.4700000000000002, 0.002177295249606736
+0.4800000000000002, 0.0022232773474854667
+0.4900000000000002, 0.0022708582655766108
+0.5000000000000002, 0.0023677191665626013
+0.5100000000000002, 0.0024185769095793016
+0.5200000000000002, 0.002514114352819277
+0.5300000000000002, 0.002617964576029904
+0.5400000000000003, 0.0028159448184314215
+0.5500000000000003, 0.0029461274312934183
+0.5600000000000003, 0.0030885993792761357
+0.5700000000000003, 0.0032325030798505913
+0.5800000000000003, 0.003364776755717139
+0.5900000000000003, 0.0034976933556842547
+0.6000000000000003, 0.0036882097696743213
+0.6100000000000003, 0.003895523065398759
+0.6200000000000003, 0.004079140025108818
+0.6300000000000004, 0.004307919249530014
+0.6400000000000005, 0.004492202407796801
+0.6500000000000002, 0.004734456318932722
+0.6600000000000003, 0.004951949837248759
+0.6700000000000004, 0.005205527039986248
+0.6800000000000004, 0.005411455937812412
+0.6900000000000004, 0.005635413706703852
+0.7000000000000004, 0.005873854436394826
+0.7100000000000004, 0.006124085905971173
+0.7200000000000004, 0.006325641189434088
+0.7300000000000004, 0.006655273182515841
+0.7400000000000004, 0.006949994897143527
+0.7500000000000004, 0.007053209028418031
+0.7600000000000005, 0.007367822721810779
+0.7700000000000006, 0.0076844864490485726
+0.7800000000000006, 0.007770728860309734
+0.7900000000000004, 0.008022609955346155
+0.8000000000000004, 0.008347679064679201
+0.8100000000000005, 0.008527334390269843
+0.8200000000000005, 0.008507488326664842
+0.8300000000000005, 0.008944383338538081
+0.8400000000000005, 0.009242631415676716
+0.8500000000000005, 0.009344108130985794
+0.8600000000000005, 0.00953588357235412
+0.8700000000000006, 0.00965386859086834
+0.8800000000000006, 0.009895366047267979
+0.8900000000000006, 0.010063216077208923
+0.9000000000000007, 0.01006181544221102
+0.9100000000000005, 0.010062717312160116
+0.9200000000000005, 0.010486610535172032
+0.9300000000000005, 0.010258241778114553
+0.9400000000000005, 0.010271985542128157
+0.9500000000000005, 0.010481123730144377
+0.9600000000000005, 0.010375964050702756
+0.9700000000000005, 0.010272011737671803
+0.9800000000000005, 0.010269874472298013
+0.9900000000000005, 0.010166386694748668
```

## SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP21.csv

 * *Ordering differences only*

```diff
@@ -1,88 +1,88 @@
-0.039999999999999994, 0.6021558658451275
-0.05, 0.35794888594797314
-0.06000000000000001, 0.24530808896771986
-0.07000000000000002, 0.16871871819011336
-0.08, 0.12607426062712496
-0.08999999999999998, 0.09283650404406438
-0.09999999999999999, 0.07425484984555944
-0.11, 0.07145900581493451
-0.11999999999999998, 0.06530185924575473
-0.12999999999999995, 0.04743962283603081
-0.13999999999999996, 0.04225715468741329
-0.14999999999999997, 0.03713493324360637
-0.15999999999999998, 0.03228752242550649
-0.16999999999999998, 0.027854975157002828
-0.18, 0.023912947799335532
-0.19, 0.020486701811325024
-0.2, 0.017565716574988094
-0.21000000000000002, 0.01511683576352635
-0.22000000000000003, 0.0130949372457094
-0.23000000000000004, 0.011450903528078892
-0.24000000000000005, 0.010137157683853343
-0.25000000000000006, 0.009111273102581667
-0.26000000000000006, 0.0073653685883078865
-0.2700000000000001, 0.006596883147027236
-0.2800000000000001, 0.006347258156660729
-0.2900000000000001, 0.005766993050675578
-0.3000000000000001, 0.005015631685622967
-0.3100000000000001, 0.004265159922209478
-0.3200000000000002, 0.003643602164247986
-0.33000000000000007, 0.003164644359605266
-0.34000000000000014, 0.0028129460828972344
-0.35000000000000014, 0.0025160798904984823
-0.36000000000000015, 0.002186414199983756
-0.37000000000000016, 0.001977028309732844
-0.38000000000000017, 0.0017636224376872665
-0.39000000000000024, 0.0015622846667588586
-0.40000000000000013, 0.0013833309755348383
-0.41000000000000014, 0.001232403601551859
-0.42000000000000015, 0.0011119628822522578
-0.43000000000000016, 0.0010227927622097838
-0.44000000000000017, 0.0009284171003677771
-0.4500000000000002, 0.0009180604811314355
-0.4600000000000002, 0.0008757938580525833
-0.4700000000000002, 0.0008520043461642231
-0.4800000000000002, 0.0008532985815372328
-0.4900000000000002, 0.0008758033361571596
-0.5000000000000002, 0.0009244033090253898
-0.5100000000000002, 0.0010116152037786034
-0.5200000000000002, 0.0011042175966214489
-0.5300000000000002, 0.0011893242368534365
-0.5400000000000003, 0.001315224359869974
-0.5500000000000003, 0.0014705651723387436
-0.5600000000000003, 0.0016601939592810213
-0.5700000000000003, 0.0018839462413950054
-0.5800000000000003, 0.0020958112451592353
-0.5900000000000003, 0.00222816382631459
-0.6000000000000003, 0.002346208055495575
-0.6100000000000003, 0.0027783369982594475
-0.6200000000000003, 0.0032666070892483196
-0.6300000000000004, 0.003573942579338741
-0.6400000000000005, 0.003944816299479933
-0.6500000000000002, 0.004381313877897274
-0.6600000000000003, 0.004883713150176581
-0.6700000000000004, 0.0054492150976873585
-0.6800000000000004, 0.006070515969339024
-0.6900000000000004, 0.006734338439030434
-0.7000000000000004, 0.007420134466451714
-0.7100000000000004, 0.008099271257562808
-0.7200000000000004, 0.008735087746165804
-0.7300000000000004, 0.009937232816929636
-0.7400000000000004, 0.009726726748512734
-0.7500000000000004, 0.01084147500998316
-0.7600000000000005, 0.012223002869247913
-0.7700000000000006, 0.01310848392653875
-0.7800000000000006, 0.01388962909806356
-0.7900000000000004, 0.014775828971999229
-0.8000000000000004, 0.015661844888053233
-0.8100000000000005, 0.016517077475371636
-0.8200000000000005, 0.01747784114301295
-0.8300000000000005, 0.018492811428093274
-0.8400000000000005, 0.01949732107597137
-0.8500000000000005, 0.020412682106168034
-0.8600000000000005, 0.02156738465457111
-0.8700000000000006, 0.022369217876801996
-0.8800000000000006, 0.022950444320737194
-0.8900000000000006, 0.023676980974917855
-0.9000000000000007, 0.02453748428325487
-0.9100000000000005, 0.02529026355865854
+0.039999999999999994, 0.6021558658451275
+0.05, 0.35794888594797314
+0.06000000000000001, 0.24530808896771986
+0.07000000000000002, 0.16871871819011336
+0.08, 0.12607426062712496
+0.08999999999999998, 0.09283650404406438
+0.09999999999999999, 0.07425484984555944
+0.11, 0.07145900581493451
+0.11999999999999998, 0.06530185924575473
+0.12999999999999995, 0.04743962283603081
+0.13999999999999996, 0.04225715468741329
+0.14999999999999997, 0.03713493324360637
+0.15999999999999998, 0.03228752242550649
+0.16999999999999998, 0.027854975157002828
+0.18, 0.023912947799335532
+0.19, 0.020486701811325024
+0.2, 0.017565716574988094
+0.21000000000000002, 0.01511683576352635
+0.22000000000000003, 0.0130949372457094
+0.23000000000000004, 0.011450903528078892
+0.24000000000000005, 0.010137157683853343
+0.25000000000000006, 0.009111273102581667
+0.26000000000000006, 0.0073653685883078865
+0.2700000000000001, 0.006596883147027236
+0.2800000000000001, 0.006347258156660729
+0.2900000000000001, 0.005766993050675578
+0.3000000000000001, 0.005015631685622967
+0.3100000000000001, 0.004265159922209478
+0.3200000000000002, 0.003643602164247986
+0.33000000000000007, 0.003164644359605266
+0.34000000000000014, 0.0028129460828972344
+0.35000000000000014, 0.0025160798904984823
+0.36000000000000015, 0.002186414199983756
+0.37000000000000016, 0.001977028309732844
+0.38000000000000017, 0.0017636224376872665
+0.39000000000000024, 0.0015622846667588586
+0.40000000000000013, 0.0013833309755348383
+0.41000000000000014, 0.001232403601551859
+0.42000000000000015, 0.0011119628822522578
+0.43000000000000016, 0.0010227927622097838
+0.44000000000000017, 0.0009284171003677771
+0.4500000000000002, 0.0009180604811314355
+0.4600000000000002, 0.0008757938580525833
+0.4700000000000002, 0.0008520043461642231
+0.4800000000000002, 0.0008532985815372328
+0.4900000000000002, 0.0008758033361571596
+0.5000000000000002, 0.0009244033090253898
+0.5100000000000002, 0.0010116152037786034
+0.5200000000000002, 0.0011042175966214489
+0.5300000000000002, 0.0011893242368534365
+0.5400000000000003, 0.001315224359869974
+0.5500000000000003, 0.0014705651723387436
+0.5600000000000003, 0.0016601939592810213
+0.5700000000000003, 0.0018839462413950054
+0.5800000000000003, 0.0020958112451592353
+0.5900000000000003, 0.00222816382631459
+0.6000000000000003, 0.002346208055495575
+0.6100000000000003, 0.0027783369982594475
+0.6200000000000003, 0.0032666070892483196
+0.6300000000000004, 0.003573942579338741
+0.6400000000000005, 0.003944816299479933
+0.6500000000000002, 0.004381313877897274
+0.6600000000000003, 0.004883713150176581
+0.6700000000000004, 0.0054492150976873585
+0.6800000000000004, 0.006070515969339024
+0.6900000000000004, 0.006734338439030434
+0.7000000000000004, 0.007420134466451714
+0.7100000000000004, 0.008099271257562808
+0.7200000000000004, 0.008735087746165804
+0.7300000000000004, 0.009937232816929636
+0.7400000000000004, 0.009726726748512734
+0.7500000000000004, 0.01084147500998316
+0.7600000000000005, 0.012223002869247913
+0.7700000000000006, 0.01310848392653875
+0.7800000000000006, 0.01388962909806356
+0.7900000000000004, 0.014775828971999229
+0.8000000000000004, 0.015661844888053233
+0.8100000000000005, 0.016517077475371636
+0.8200000000000005, 0.01747784114301295
+0.8300000000000005, 0.018492811428093274
+0.8400000000000005, 0.01949732107597137
+0.8500000000000005, 0.020412682106168034
+0.8600000000000005, 0.02156738465457111
+0.8700000000000006, 0.022369217876801996
+0.8800000000000006, 0.022950444320737194
+0.8900000000000006, 0.023676980974917855
+0.9000000000000007, 0.02453748428325487
+0.9100000000000005, 0.02529026355865854
```

## SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP41.csv

 * *Ordering differences only*

```diff
@@ -1,86 +1,86 @@
-0.13999999999999996, 0.9326549020850704
-0.14999999999999997, 0.7824763963863587
-0.15999999999999998, 0.6302308952153012
-0.16999999999999998, 0.5295497179503069
-0.18, 0.43790866055301697
-0.19, 0.37031731330082857
-0.2, 0.31290497150352786
-0.21000000000000002, 0.256503222592482
-0.22000000000000003, 0.22390263764244225
-0.23000000000000004, 0.19604280504809907
-0.24000000000000005, 0.16678267457932666
-0.25000000000000006, 0.14042307398859455
-0.26000000000000006, 0.12126100070749664
-0.2700000000000001, 0.10450476667127709
-0.2800000000000001, 0.09021157158143586
-0.2900000000000001, 0.07838315940451865
-0.3000000000000001, 0.06777212786047229
-0.3100000000000001, 0.05933615312084914
-0.3200000000000002, 0.05151538819558096
-0.33000000000000007, 0.04418766195169044
-0.34000000000000014, 0.03805489385783269
-0.35000000000000014, 0.03378445730968002
-0.36000000000000015, 0.029438034025831387
-0.37000000000000016, 0.02485501736142455
-0.38000000000000017, 0.020738270345017393
-0.39000000000000024, 0.01732291839500684
-0.40000000000000013, 0.01362814848600499
-0.41000000000000014, 0.011426672698220192
-0.42000000000000015, 0.009154081410446989
-0.43000000000000016, 0.0076855960419349575
-0.44000000000000017, 0.006434563981875693
-0.4500000000000002, 0.005644940250446222
-0.4600000000000002, 0.004863009001266276
-0.4700000000000002, 0.0044128079719770045
-0.4800000000000002, 0.0040647083205181825
-0.4900000000000002, 0.0038087690820460722
-0.5000000000000002, 0.003653592622672644
-0.5100000000000002, 0.0034842756403011483
-0.5200000000000002, 0.0030962855046397075
-0.5300000000000002, 0.0033245987107141644
-0.5400000000000003, 0.0031305289073558324
-0.5500000000000003, 0.0036835285807601042
-0.5600000000000003, 0.0038914796044229798
-0.5700000000000003, 0.004490470024707854
-0.5800000000000003, 0.00483802490109347
-0.5900000000000003, 0.005162452387464068
-0.6000000000000003, 0.005681180896696126
-0.6100000000000003, 0.006316692136562475
-0.6200000000000003, 0.0069002971656321275
-0.6300000000000004, 0.00749730241050716
-0.6400000000000005, 0.008446042400018092
-0.6500000000000002, 0.00937921197088767
-0.6600000000000003, 0.009941189425362455
-0.6700000000000004, 0.011270614668015926
-0.6800000000000004, 0.012539853885079654
-0.6900000000000004, 0.013915429848684687
-0.7000000000000004, 0.014740371748262274
-0.7100000000000004, 0.01637217194974703
-0.7200000000000004, 0.017627118831007826
-0.7300000000000004, 0.0189658143965737
-0.7400000000000004, 0.020864297440323015
-0.7500000000000004, 0.021816979533427455
-0.7600000000000005, 0.023671716957203253
-0.7700000000000006, 0.026018386771829938
-0.7800000000000006, 0.026821526912957055
-0.7900000000000004, 0.028929289047135164
-0.8000000000000004, 0.03019264061338722
-0.8100000000000005, 0.03213779499623537
-0.8200000000000005, 0.03407357324299317
-0.8300000000000005, 0.03573984212194802
-0.8400000000000005, 0.03779469048821385
-0.8500000000000005, 0.03939122596270858
-0.8600000000000005, 0.04112055731055077
-0.8700000000000006, 0.042787950742395775
-0.8800000000000006, 0.04482899850542682
-0.8900000000000006, 0.04631777190252346
-0.9000000000000007, 0.048438433149974015
-0.9100000000000005, 0.04858772022347478
-0.9200000000000005, 0.0499623117938213
-0.9300000000000005, 0.050506687751334996
-0.9400000000000005, 0.052638901174431846
-0.9500000000000005, 0.053684220884096974
-0.9600000000000005, 0.05487696260901973
-0.9700000000000005, 0.054775381803112505
-0.9800000000000005, 0.055973971216674946
-0.9900000000000005, 0.055986359148468154
+0.13999999999999996, 0.9326549020850704
+0.14999999999999997, 0.7824763963863587
+0.15999999999999998, 0.6302308952153012
+0.16999999999999998, 0.5295497179503069
+0.18, 0.43790866055301697
+0.19, 0.37031731330082857
+0.2, 0.31290497150352786
+0.21000000000000002, 0.256503222592482
+0.22000000000000003, 0.22390263764244225
+0.23000000000000004, 0.19604280504809907
+0.24000000000000005, 0.16678267457932666
+0.25000000000000006, 0.14042307398859455
+0.26000000000000006, 0.12126100070749664
+0.2700000000000001, 0.10450476667127709
+0.2800000000000001, 0.09021157158143586
+0.2900000000000001, 0.07838315940451865
+0.3000000000000001, 0.06777212786047229
+0.3100000000000001, 0.05933615312084914
+0.3200000000000002, 0.05151538819558096
+0.33000000000000007, 0.04418766195169044
+0.34000000000000014, 0.03805489385783269
+0.35000000000000014, 0.03378445730968002
+0.36000000000000015, 0.029438034025831387
+0.37000000000000016, 0.02485501736142455
+0.38000000000000017, 0.020738270345017393
+0.39000000000000024, 0.01732291839500684
+0.40000000000000013, 0.01362814848600499
+0.41000000000000014, 0.011426672698220192
+0.42000000000000015, 0.009154081410446989
+0.43000000000000016, 0.0076855960419349575
+0.44000000000000017, 0.006434563981875693
+0.4500000000000002, 0.005644940250446222
+0.4600000000000002, 0.004863009001266276
+0.4700000000000002, 0.0044128079719770045
+0.4800000000000002, 0.0040647083205181825
+0.4900000000000002, 0.0038087690820460722
+0.5000000000000002, 0.003653592622672644
+0.5100000000000002, 0.0034842756403011483
+0.5200000000000002, 0.0030962855046397075
+0.5300000000000002, 0.0033245987107141644
+0.5400000000000003, 0.0031305289073558324
+0.5500000000000003, 0.0036835285807601042
+0.5600000000000003, 0.0038914796044229798
+0.5700000000000003, 0.004490470024707854
+0.5800000000000003, 0.00483802490109347
+0.5900000000000003, 0.005162452387464068
+0.6000000000000003, 0.005681180896696126
+0.6100000000000003, 0.006316692136562475
+0.6200000000000003, 0.0069002971656321275
+0.6300000000000004, 0.00749730241050716
+0.6400000000000005, 0.008446042400018092
+0.6500000000000002, 0.00937921197088767
+0.6600000000000003, 0.009941189425362455
+0.6700000000000004, 0.011270614668015926
+0.6800000000000004, 0.012539853885079654
+0.6900000000000004, 0.013915429848684687
+0.7000000000000004, 0.014740371748262274
+0.7100000000000004, 0.01637217194974703
+0.7200000000000004, 0.017627118831007826
+0.7300000000000004, 0.0189658143965737
+0.7400000000000004, 0.020864297440323015
+0.7500000000000004, 0.021816979533427455
+0.7600000000000005, 0.023671716957203253
+0.7700000000000006, 0.026018386771829938
+0.7800000000000006, 0.026821526912957055
+0.7900000000000004, 0.028929289047135164
+0.8000000000000004, 0.03019264061338722
+0.8100000000000005, 0.03213779499623537
+0.8200000000000005, 0.03407357324299317
+0.8300000000000005, 0.03573984212194802
+0.8400000000000005, 0.03779469048821385
+0.8500000000000005, 0.03939122596270858
+0.8600000000000005, 0.04112055731055077
+0.8700000000000006, 0.042787950742395775
+0.8800000000000006, 0.04482899850542682
+0.8900000000000006, 0.04631777190252346
+0.9000000000000007, 0.048438433149974015
+0.9100000000000005, 0.04858772022347478
+0.9200000000000005, 0.0499623117938213
+0.9300000000000005, 0.050506687751334996
+0.9400000000000005, 0.052638901174431846
+0.9500000000000005, 0.053684220884096974
+0.9600000000000005, 0.05487696260901973
+0.9700000000000005, 0.054775381803112505
+0.9800000000000005, 0.055973971216674946
+0.9900000000000005, 0.055986359148468154
```

## SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP12.csv

 * *Ordering differences only*

```diff
@@ -1,82 +1,82 @@
-0.020000000000000004, 0.7503864681480337
-0.03, 0.2941077361972875
-0.039999999999999994, 0.17150778747342935
-0.05, 0.10446694038292048
-0.06000000000000001, 0.06789343120180247
-0.07000000000000002, 0.046995971895215385
-0.08, 0.037669925088413006
-0.08999999999999998, 0.029789988372077438
-0.09999999999999999, 0.024788896842007992
-0.23000000000000004, 0.004864025326263113
-0.24000000000000005, 0.004654482891192198
-0.25000000000000006, 0.004304272613858848
-0.26000000000000006, 0.004117567733227475
-0.2700000000000001, 0.003803726404665622
-0.2800000000000001, 0.003578511562682663
-0.2900000000000001, 0.003405802073852069
-0.3000000000000001, 0.003210135206240982
-0.3100000000000001, 0.0030903106624928533
-0.3200000000000002, 0.003006039714568892
-0.33000000000000007, 0.0029292204064867073
-0.34000000000000014, 0.0028573870139817713
-0.35000000000000014, 0.0027393900369966947
-0.36000000000000015, 0.0027399266179037743
-0.37000000000000016, 0.0026016712705615847
-0.38000000000000017, 0.002677739376487723
-0.39000000000000024, 0.0026785107385921456
-0.40000000000000013, 0.0026791866392348097
-0.41000000000000014, 0.002678708591770809
-0.42000000000000015, 0.0027346142042399884
-0.43000000000000016, 0.002740708785071588
-0.44000000000000017, 0.002758618978311059
-0.4500000000000002, 0.0027919985245587545
-0.4600000000000002, 0.0027941459172931204
-0.4700000000000002, 0.002846997340473905
-0.4800000000000002, 0.0028402130534257975
-0.4900000000000002, 0.0028955258374581227
-0.5000000000000002, 0.0030397374776553908
-0.5100000000000002, 0.0031439148951415458
-0.5200000000000002, 0.003098133969591239
-0.5300000000000002, 0.0031781318449978493
-0.5400000000000003, 0.0033728840950854556
-0.5500000000000003, 0.00337229105980127
-0.5600000000000003, 0.0033901144163286964
-0.5800000000000003, 0.0036925406442850734
-0.5900000000000003, 0.0038628626422402825
-0.6200000000000003, 0.004400677333806665
-0.6400000000000005, 0.004790556832564931
-0.6500000000000002, 0.004997258215216738
-0.6600000000000003, 0.005158434728877573
-0.6700000000000004, 0.005331081872672487
-0.6800000000000004, 0.005644906539432887
-0.6900000000000004, 0.005856417773459223
-0.7000000000000004, 0.006040987145974082
-0.7100000000000004, 0.006391944636884679
-0.7200000000000004, 0.006596126623155487
-0.7300000000000004, 0.006708888253281812
-0.7400000000000004, 0.0069911627068080535
-0.7500000000000004, 0.007271461880796397
-0.7600000000000005, 0.007353357833727128
-0.7700000000000006, 0.007635771642759376
-0.7800000000000006, 0.00793229063250531
-0.7900000000000004, 0.008184151412921522
-0.8000000000000004, 0.008306143645904322
-0.8100000000000005, 0.008598585552772701
-0.8200000000000005, 0.00878452204690696
-0.8300000000000005, 0.008928794112979935
-0.8400000000000005, 0.00917628032914479
-0.8500000000000005, 0.009359434876010177
-0.8600000000000005, 0.009445353697759328
-0.8700000000000006, 0.009665328757267352
-0.8800000000000006, 0.009844236257471797
-0.8900000000000006, 0.009858943575259608
-0.9000000000000007, 0.009975229350254836
-0.9100000000000005, 0.010039183727079215
-0.9200000000000005, 0.010166385807174617
-0.9300000000000005, 0.010271820459236618
-0.9400000000000005, 0.01020345869267626
-0.9500000000000005, 0.010267960501538574
-0.9600000000000005, 0.010265390487504194
-0.9700000000000005, 0.010362247873111963
-0.9800000000000005, 0.009807562655562116
-0.9900000000000005, 0.009959350771341439
+0.020000000000000004, 0.7503864681480337
+0.03, 0.2941077361972875
+0.039999999999999994, 0.17150778747342935
+0.05, 0.10446694038292048
+0.06000000000000001, 0.06789343120180247
+0.07000000000000002, 0.046995971895215385
+0.08, 0.037669925088413006
+0.08999999999999998, 0.029789988372077438
+0.09999999999999999, 0.024788896842007992
+0.23000000000000004, 0.004864025326263113
+0.24000000000000005, 0.004654482891192198
+0.25000000000000006, 0.004304272613858848
+0.26000000000000006, 0.004117567733227475
+0.2700000000000001, 0.003803726404665622
+0.2800000000000001, 0.003578511562682663
+0.2900000000000001, 0.003405802073852069
+0.3000000000000001, 0.003210135206240982
+0.3100000000000001, 0.0030903106624928533
+0.3200000000000002, 0.003006039714568892
+0.33000000000000007, 0.0029292204064867073
+0.34000000000000014, 0.0028573870139817713
+0.35000000000000014, 0.0027393900369966947
+0.36000000000000015, 0.0027399266179037743
+0.37000000000000016, 0.0026016712705615847
+0.38000000000000017, 0.002677739376487723
+0.39000000000000024, 0.0026785107385921456
+0.40000000000000013, 0.0026791866392348097
+0.41000000000000014, 0.002678708591770809
+0.42000000000000015, 0.0027346142042399884
+0.43000000000000016, 0.002740708785071588
+0.44000000000000017, 0.002758618978311059
+0.4500000000000002, 0.0027919985245587545
+0.4600000000000002, 0.0027941459172931204
+0.4700000000000002, 0.002846997340473905
+0.4800000000000002, 0.0028402130534257975
+0.4900000000000002, 0.0028955258374581227
+0.5000000000000002, 0.0030397374776553908
+0.5100000000000002, 0.0031439148951415458
+0.5200000000000002, 0.003098133969591239
+0.5300000000000002, 0.0031781318449978493
+0.5400000000000003, 0.0033728840950854556
+0.5500000000000003, 0.00337229105980127
+0.5600000000000003, 0.0033901144163286964
+0.5800000000000003, 0.0036925406442850734
+0.5900000000000003, 0.0038628626422402825
+0.6200000000000003, 0.004400677333806665
+0.6400000000000005, 0.004790556832564931
+0.6500000000000002, 0.004997258215216738
+0.6600000000000003, 0.005158434728877573
+0.6700000000000004, 0.005331081872672487
+0.6800000000000004, 0.005644906539432887
+0.6900000000000004, 0.005856417773459223
+0.7000000000000004, 0.006040987145974082
+0.7100000000000004, 0.006391944636884679
+0.7200000000000004, 0.006596126623155487
+0.7300000000000004, 0.006708888253281812
+0.7400000000000004, 0.0069911627068080535
+0.7500000000000004, 0.007271461880796397
+0.7600000000000005, 0.007353357833727128
+0.7700000000000006, 0.007635771642759376
+0.7800000000000006, 0.00793229063250531
+0.7900000000000004, 0.008184151412921522
+0.8000000000000004, 0.008306143645904322
+0.8100000000000005, 0.008598585552772701
+0.8200000000000005, 0.00878452204690696
+0.8300000000000005, 0.008928794112979935
+0.8400000000000005, 0.00917628032914479
+0.8500000000000005, 0.009359434876010177
+0.8600000000000005, 0.009445353697759328
+0.8700000000000006, 0.009665328757267352
+0.8800000000000006, 0.009844236257471797
+0.8900000000000006, 0.009858943575259608
+0.9000000000000007, 0.009975229350254836
+0.9100000000000005, 0.010039183727079215
+0.9200000000000005, 0.010166385807174617
+0.9300000000000005, 0.010271820459236618
+0.9400000000000005, 0.01020345869267626
+0.9500000000000005, 0.010267960501538574
+0.9600000000000005, 0.010265390487504194
+0.9700000000000005, 0.010362247873111963
+0.9800000000000005, 0.009807562655562116
+0.9900000000000005, 0.009959350771341439
```

## SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP31.csv

 * *Ordering differences only*

```diff
@@ -1,95 +1,95 @@
-0.039999999999999994, 0.626645691271422
-0.05, 0.3918076247900129
-0.06000000000000001, 0.2672967532377689
-0.07000000000000002, 0.16843182705451093
-0.08, 0.13911272764328522
-0.08999999999999998, 0.11550673539864281
-0.09999999999999999, 0.09223696181355875
-0.11, 0.0782312277430982
-0.11999999999999998, 0.06484885313754071
-0.12999999999999995, 0.05508431315355192
-0.13999999999999996, 0.04959054995026816
-0.14999999999999997, 0.042339388698104816
-0.15999999999999998, 0.0375773184393119
-0.16999999999999998, 0.03338024866063832
-0.18, 0.030814792614864566
-0.19, 0.027408662011624667
-0.2, 0.02517901711582273
-0.21000000000000002, 0.023429850909679688
-0.22000000000000003, 0.021683453266276027
-0.23000000000000004, 0.020750573810175522
-0.24000000000000005, 0.01958048116972276
-0.25000000000000006, 0.01852224103313135
-0.26000000000000006, 0.017281468077829945
-0.2700000000000001, 0.016897194898852014
-0.2800000000000001, 0.016530860552814122
-0.2900000000000001, 0.016352343726936485
-0.3000000000000001, 0.016186886183558336
-0.3100000000000001, 0.016395927482444755
-0.3200000000000002, 0.016506262393572977
-0.33000000000000007, 0.016908908715929014
-0.34000000000000014, 0.017580828461450412
-0.35000000000000014, 0.017953412996844567
-0.36000000000000015, 0.017935384523538503
-0.37000000000000016, 0.01724874943533124
-0.38000000000000017, 0.016298294733647533
-0.39000000000000024, 0.014801627238197397
-0.40000000000000013, 0.012621040986694977
-0.41000000000000014, 0.010333258877491234
-0.42000000000000015, 0.0086344473097339
-0.43000000000000016, 0.007463922256367472
-0.44000000000000017, 0.006537046733954626
-0.4500000000000002, 0.005603423097046329
-0.4600000000000002, 0.0051401100411456865
-0.4700000000000002, 0.004601378074839988
-0.4800000000000002, 0.004317304200812954
-0.4900000000000002, 0.004304293260705103
-0.5000000000000002, 0.004260337096690113
-0.5100000000000002, 0.004314990734323268
-0.5200000000000002, 0.004509692129104204
-0.5300000000000002, 0.004855585048031174
-0.5400000000000003, 0.005197181765129207
-0.5500000000000003, 0.005727951423319159
-0.5600000000000003, 0.006389102194372355
-0.5700000000000003, 0.006944712216027417
-0.5800000000000003, 0.008170034453547333
-0.5900000000000003, 0.009569274730669219
-0.6000000000000003, 0.010678895716736438
-0.6100000000000003, 0.012911310996799642
-0.6200000000000003, 0.01576701821536972
-0.6300000000000004, 0.019223928297707176
-0.6400000000000005, 0.02354639323406487
-0.6500000000000002, 0.029393617637377047
-0.6600000000000003, 0.035976873988807334
-0.6700000000000004, 0.04644355140123588
-0.6800000000000004, 0.0639822626881289
-0.6900000000000004, 0.09395586971775112
-0.7000000000000004, 0.2062098715579228
-0.7100000000000004, 0.5045776553286359
-0.7139862542955328, 0.9498560760628543
-0.7300000000000004, 0.35447264644548626
-0.733556701030928, 0.2602321613764637
-0.7500000000000004, 0.12695208168845482
-0.7600000000000005, 0.10264441120163943
-0.7700000000000006, 0.09014635259049462
-0.7800000000000006, 0.0795836712371088
-0.7900000000000004, 0.07360160682978972
-0.8000000000000004, 0.0675030917983165
-0.8100000000000005, 0.06441589835767235
-0.8200000000000005, 0.06131599515616828
-0.8300000000000005, 0.058639594768694014
-0.8400000000000005, 0.05701984995393847
-0.8500000000000005, 0.0537152649335125
-0.8600000000000005, 0.05382115367021272
-0.8700000000000006, 0.05269737685031415
-0.8800000000000006, 0.05123870090696337
-0.8900000000000006, 0.04970243675425792
-0.9000000000000007, 0.048558569121757635
-0.9100000000000005, 0.0474733002023986
-0.9200000000000005, 0.04696711103078974
-0.9300000000000005, 0.046456949656348306
-0.9400000000000005, 0.04525228768854257
-0.9500000000000005, 0.044031094385018635
-0.9600000000000005, 0.04243410082108795
-0.9700000000000005, 0.04183482450398794
-0.9800000000000005, 0.04112636069905649
+0.039999999999999994, 0.626645691271422
+0.05, 0.3918076247900129
+0.06000000000000001, 0.2672967532377689
+0.07000000000000002, 0.16843182705451093
+0.08, 0.13911272764328522
+0.08999999999999998, 0.11550673539864281
+0.09999999999999999, 0.09223696181355875
+0.11, 0.0782312277430982
+0.11999999999999998, 0.06484885313754071
+0.12999999999999995, 0.05508431315355192
+0.13999999999999996, 0.04959054995026816
+0.14999999999999997, 0.042339388698104816
+0.15999999999999998, 0.0375773184393119
+0.16999999999999998, 0.03338024866063832
+0.18, 0.030814792614864566
+0.19, 0.027408662011624667
+0.2, 0.02517901711582273
+0.21000000000000002, 0.023429850909679688
+0.22000000000000003, 0.021683453266276027
+0.23000000000000004, 0.020750573810175522
+0.24000000000000005, 0.01958048116972276
+0.25000000000000006, 0.01852224103313135
+0.26000000000000006, 0.017281468077829945
+0.2700000000000001, 0.016897194898852014
+0.2800000000000001, 0.016530860552814122
+0.2900000000000001, 0.016352343726936485
+0.3000000000000001, 0.016186886183558336
+0.3100000000000001, 0.016395927482444755
+0.3200000000000002, 0.016506262393572977
+0.33000000000000007, 0.016908908715929014
+0.34000000000000014, 0.017580828461450412
+0.35000000000000014, 0.017953412996844567
+0.36000000000000015, 0.017935384523538503
+0.37000000000000016, 0.01724874943533124
+0.38000000000000017, 0.016298294733647533
+0.39000000000000024, 0.014801627238197397
+0.40000000000000013, 0.012621040986694977
+0.41000000000000014, 0.010333258877491234
+0.42000000000000015, 0.0086344473097339
+0.43000000000000016, 0.007463922256367472
+0.44000000000000017, 0.006537046733954626
+0.4500000000000002, 0.005603423097046329
+0.4600000000000002, 0.0051401100411456865
+0.4700000000000002, 0.004601378074839988
+0.4800000000000002, 0.004317304200812954
+0.4900000000000002, 0.004304293260705103
+0.5000000000000002, 0.004260337096690113
+0.5100000000000002, 0.004314990734323268
+0.5200000000000002, 0.004509692129104204
+0.5300000000000002, 0.004855585048031174
+0.5400000000000003, 0.005197181765129207
+0.5500000000000003, 0.005727951423319159
+0.5600000000000003, 0.006389102194372355
+0.5700000000000003, 0.006944712216027417
+0.5800000000000003, 0.008170034453547333
+0.5900000000000003, 0.009569274730669219
+0.6000000000000003, 0.010678895716736438
+0.6100000000000003, 0.012911310996799642
+0.6200000000000003, 0.01576701821536972
+0.6300000000000004, 0.019223928297707176
+0.6400000000000005, 0.02354639323406487
+0.6500000000000002, 0.029393617637377047
+0.6600000000000003, 0.035976873988807334
+0.6700000000000004, 0.04644355140123588
+0.6800000000000004, 0.0639822626881289
+0.6900000000000004, 0.09395586971775112
+0.7000000000000004, 0.2062098715579228
+0.7100000000000004, 0.5045776553286359
+0.7139862542955328, 0.9498560760628543
+0.7300000000000004, 0.35447264644548626
+0.733556701030928, 0.2602321613764637
+0.7500000000000004, 0.12695208168845482
+0.7600000000000005, 0.10264441120163943
+0.7700000000000006, 0.09014635259049462
+0.7800000000000006, 0.0795836712371088
+0.7900000000000004, 0.07360160682978972
+0.8000000000000004, 0.0675030917983165
+0.8100000000000005, 0.06441589835767235
+0.8200000000000005, 0.06131599515616828
+0.8300000000000005, 0.058639594768694014
+0.8400000000000005, 0.05701984995393847
+0.8500000000000005, 0.0537152649335125
+0.8600000000000005, 0.05382115367021272
+0.8700000000000006, 0.05269737685031415
+0.8800000000000006, 0.05123870090696337
+0.8900000000000006, 0.04970243675425792
+0.9000000000000007, 0.048558569121757635
+0.9100000000000005, 0.0474733002023986
+0.9200000000000005, 0.04696711103078974
+0.9300000000000005, 0.046456949656348306
+0.9400000000000005, 0.04525228768854257
+0.9500000000000005, 0.044031094385018635
+0.9600000000000005, 0.04243410082108795
+0.9700000000000005, 0.04183482450398794
+0.9800000000000005, 0.04112636069905649
```

## SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP51.csv

 * *Ordering differences only*

```diff
@@ -1,81 +1,81 @@
-0.16999999999999998, 0.8275934017584731
-0.18, 0.7024155913429159
-0.19, 0.5696204580625808
-0.2, 0.4638539137648573
-0.21000000000000002, 0.39132631422056763
-0.22000000000000003, 0.33069221573188706
-0.23000000000000004, 0.279428858954314
-0.24000000000000005, 0.2383017959054523
-0.25000000000000006, 0.20374484207711993
-0.26000000000000006, 0.17577450550019869
-0.2700000000000001, 0.15014086468635032
-0.2800000000000001, 0.12953558478299623
-0.2900000000000001, 0.11170983333116141
-0.3000000000000001, 0.0973773875161037
-0.3100000000000001, 0.08400312255425843
-0.3200000000000002, 0.07246308155823815
-0.33000000000000007, 0.06327710823131404
-0.34000000000000014, 0.055065087873603945
-0.35000000000000014, 0.04797702733363067
-0.36000000000000015, 0.04183984812525302
-0.37000000000000016, 0.03645288867886333
-0.38000000000000017, 0.031791354123999575
-0.39000000000000024, 0.027850204788655186
-0.40000000000000013, 0.024156161791093096
-0.41000000000000014, 0.020839791145071833
-0.42000000000000015, 0.018341588715166543
-0.43000000000000016, 0.01566609426966968
-0.44000000000000017, 0.01338125611016569
-0.4500000000000002, 0.011514148300216635
-0.4600000000000002, 0.009655835819678866
-0.4700000000000002, 0.008077106617254136
-0.4800000000000002, 0.0062839097408083685
-0.4900000000000002, 0.005474316520260445
-0.5000000000000002, 0.004578067314134588
-0.5100000000000002, 0.004015600318717578
-0.5200000000000002, 0.003463999427325292
-0.5300000000000002, 0.0034747048545863152
-0.5400000000000003, 0.003205840247509459
-0.5500000000000003, 0.0031643378776815886
-0.5600000000000003, 0.003160518638612851
-0.5700000000000003, 0.0031277721227313624
-0.5800000000000003, 0.0031587533359812912
-0.6000000000000003, 0.003335329829741892
-0.6200000000000003, 0.003514841115255888
-0.6300000000000004, 0.003647432439918026
-0.6400000000000005, 0.003871171289987252
-0.6500000000000002, 0.004098043193832771
-0.6600000000000003, 0.004102135615881383
-0.6700000000000004, 0.004279829497546178
-0.6800000000000004, 0.004469091423475117
-0.6900000000000004, 0.004678497065348811
-0.7000000000000004, 0.004877324359022345
-0.7100000000000004, 0.005138754595910349
-0.7200000000000004, 0.005358524836196248
-0.7300000000000004, 0.005581428213433727
-0.7400000000000004, 0.005822974755312521
-0.7500000000000004, 0.006038055976451219
-0.7600000000000005, 0.006306448971873539
-0.7700000000000006, 0.006515088494300156
-0.7800000000000006, 0.006723506356173216
-0.7900000000000004, 0.007003289120672657
-0.8000000000000004, 0.007254436649381947
-0.8100000000000005, 0.007447670497475426
-0.8200000000000005, 0.007688074137023973
-0.8300000000000005, 0.007928994756174383
-0.8400000000000005, 0.008172790058801201
-0.8500000000000005, 0.008353135207615396
-0.8600000000000005, 0.008537890607310094
-0.8700000000000006, 0.00872927154908551
-0.8800000000000006, 0.008880201794002127
-0.8900000000000006, 0.009061205884996695
-0.9000000000000007, 0.009157935922712128
-0.9100000000000005, 0.009358521839587587
-0.9200000000000005, 0.009456772028069998
-0.9300000000000005, 0.009561299765313684
-0.9400000000000005, 0.009554455924624014
-0.9500000000000005, 0.009653969529620247
-0.9600000000000005, 0.009654175389711426
-0.9700000000000005, 0.009654923413531288
-0.9800000000000005, 0.009554928866520514
-0.9900000000000005, 0.00945051812627089
+0.16999999999999998, 0.8275934017584731
+0.18, 0.7024155913429159
+0.19, 0.5696204580625808
+0.2, 0.4638539137648573
+0.21000000000000002, 0.39132631422056763
+0.22000000000000003, 0.33069221573188706
+0.23000000000000004, 0.279428858954314
+0.24000000000000005, 0.2383017959054523
+0.25000000000000006, 0.20374484207711993
+0.26000000000000006, 0.17577450550019869
+0.2700000000000001, 0.15014086468635032
+0.2800000000000001, 0.12953558478299623
+0.2900000000000001, 0.11170983333116141
+0.3000000000000001, 0.0973773875161037
+0.3100000000000001, 0.08400312255425843
+0.3200000000000002, 0.07246308155823815
+0.33000000000000007, 0.06327710823131404
+0.34000000000000014, 0.055065087873603945
+0.35000000000000014, 0.04797702733363067
+0.36000000000000015, 0.04183984812525302
+0.37000000000000016, 0.03645288867886333
+0.38000000000000017, 0.031791354123999575
+0.39000000000000024, 0.027850204788655186
+0.40000000000000013, 0.024156161791093096
+0.41000000000000014, 0.020839791145071833
+0.42000000000000015, 0.018341588715166543
+0.43000000000000016, 0.01566609426966968
+0.44000000000000017, 0.01338125611016569
+0.4500000000000002, 0.011514148300216635
+0.4600000000000002, 0.009655835819678866
+0.4700000000000002, 0.008077106617254136
+0.4800000000000002, 0.0062839097408083685
+0.4900000000000002, 0.005474316520260445
+0.5000000000000002, 0.004578067314134588
+0.5100000000000002, 0.004015600318717578
+0.5200000000000002, 0.003463999427325292
+0.5300000000000002, 0.0034747048545863152
+0.5400000000000003, 0.003205840247509459
+0.5500000000000003, 0.0031643378776815886
+0.5600000000000003, 0.003160518638612851
+0.5700000000000003, 0.0031277721227313624
+0.5800000000000003, 0.0031587533359812912
+0.6000000000000003, 0.003335329829741892
+0.6200000000000003, 0.003514841115255888
+0.6300000000000004, 0.003647432439918026
+0.6400000000000005, 0.003871171289987252
+0.6500000000000002, 0.004098043193832771
+0.6600000000000003, 0.004102135615881383
+0.6700000000000004, 0.004279829497546178
+0.6800000000000004, 0.004469091423475117
+0.6900000000000004, 0.004678497065348811
+0.7000000000000004, 0.004877324359022345
+0.7100000000000004, 0.005138754595910349
+0.7200000000000004, 0.005358524836196248
+0.7300000000000004, 0.005581428213433727
+0.7400000000000004, 0.005822974755312521
+0.7500000000000004, 0.006038055976451219
+0.7600000000000005, 0.006306448971873539
+0.7700000000000006, 0.006515088494300156
+0.7800000000000006, 0.006723506356173216
+0.7900000000000004, 0.007003289120672657
+0.8000000000000004, 0.007254436649381947
+0.8100000000000005, 0.007447670497475426
+0.8200000000000005, 0.007688074137023973
+0.8300000000000005, 0.007928994756174383
+0.8400000000000005, 0.008172790058801201
+0.8500000000000005, 0.008353135207615396
+0.8600000000000005, 0.008537890607310094
+0.8700000000000006, 0.00872927154908551
+0.8800000000000006, 0.008880201794002127
+0.8900000000000006, 0.009061205884996695
+0.9000000000000007, 0.009157935922712128
+0.9100000000000005, 0.009358521839587587
+0.9200000000000005, 0.009456772028069998
+0.9300000000000005, 0.009561299765313684
+0.9400000000000005, 0.009554455924624014
+0.9500000000000005, 0.009653969529620247
+0.9600000000000005, 0.009654175389711426
+0.9700000000000005, 0.009654923413531288
+0.9800000000000005, 0.009554928866520514
+0.9900000000000005, 0.00945051812627089
```

## SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP02.csv

 * *Ordering differences only*

```diff
@@ -1,285 +1,285 @@
-0.019293137995924386, 0.9225879534963551
-0.020195517033881505, 0.8502270986426581
-0.02105866220062308, 0.7903582555750823
-0.021159549298034458, 0.7432602696844071
-0.02186575897991394, 0.6954252961765095
-0.023000738825791678, 0.6513379616008309
-0.021764871882502562, 0.9611857352930676
-0.025119367871430126, 0.511344251162802
-0.02600212997377946, 0.47151228943221823
-0.02494281545096025, 0.5870090523554583
-0.02620390416860216, 0.43620720163947063
-0.02600212997377946, 0.560741032158277
-0.02794420659894803, 0.4046027095113585
-0.029533178383176872, 0.36511969930704224
-0.03059249290599611, 0.3007001374179111
-0.030239388065056355, 0.3369718463535166
-0.03191663605952014, 0.27507304586758075
-0.03271112195163456, 0.2558115401860372
-0.0342412429290401, 0.24087342993549263
-0.03571251309962234, 0.22532911423098806
-0.03694838004291143, 0.21217102469135218
-0.037693823596006426, 0.1871062101684233
-0.03730148488385118, 0.20109218353904598
-0.03924356150901975, 0.17357504103210122
-0.03962188812431233, 0.16093886204081606
-0.042068400236537684, 0.1515974849829428
-0.04464606557539777, 0.13826104798594643
-0.0461291059073447, 0.12839469002735113
-0.04762980148133861, 0.11406087459568622
-0.04718842043016394, 0.12264916651742237
-0.04910527528097966, 0.10661048569533649
-0.05054291641909148, 0.09935855720294343
-0.053230436597355046, 0.09211287034185889
-0.052838097885199775, 0.09768330882012806
-0.05601604145365746, 0.08481423813042094
-0.05813467049929591, 0.07848077054239712
-0.060135597931287754, 0.07153084956673489
-0.06175399511892826, 0.06636751802460485
-0.06390204956797835, 0.06261472049748291
-0.06625608184090992, 0.05883849365454301
-0.06890436814795803, 0.055879733559944446
-0.07079600122442092, 0.05237141021487271
-0.0730155173674707, 0.04900087485548452
-0.07578991254628298, 0.045476103693963835
-0.07861475127380091, 0.04218122649842182
-0.08138914645261314, 0.0394812664214923
-0.08373477146742714, 0.03726687204875243
-0.0869715658427081, 0.03499034815708491
-0.08991410618387258, 0.03272755470658312
-0.09273894491139051, 0.030595526771392857
-0.09556378363890844, 0.02888436603927864
-0.09850632398007297, 0.027156191064178915
-0.10191967077582381, 0.025539207752554246
-0.1054507191852212, 0.02398501777345455
-0.10886406598097204, 0.02266464446544479
-0.11251281600401603, 0.0221340316045439
-0.23442226233846164, 0.006102548511721859
-0.23821813937856384, 0.005970949546543947
-0.24245539746984074, 0.005939790400195441
-0.24669265556111764, 0.005826924914147607
-0.25092991365239453, 0.005706243449839193
-0.25516717174367143, 0.005573461817568539
-0.2594044298349483, 0.005448519099879793
-0.26364168792622517, 0.005331024011734417
-0.26787894601750206, 0.005225167618544427
-0.27211620410877896, 0.0051348286483923825
-0.27635346220005585, 0.005090246570302099
-0.28059072029133275, 0.00499352377125492
-0.28482797838260965, 0.004945853777869779
-0.28906523647388654, 0.004868827952923447
-0.29330249456516344, 0.004784649810665665
-0.29753975265644034, 0.004734843124450799
-0.30177701074771723, 0.004677390234821966
-0.30601426883899413, 0.004640824899364683
-0.31025152693027097, 0.004505250271731682
-0.3144887850215479, 0.004489562969983612
-0.31872604311282476, 0.004462241514691589
-0.3229633012041017, 0.0044583520460551905
-0.32720055929537856, 0.0044583520460551905
-0.3314378173866555, 0.004438955497063265
-0.33567507547793235, 0.004411942016025765
-0.34016455131273765, 0.00436601509968164
-0.34414959166048614, 0.004331883928512109
-0.3483868497517631, 0.004331883928512109
-0.35262410784303994, 0.004331883928512109
-0.3567008637338897, 0.004334975705194922
-0.36109862402559373, 0.004328108084775051
-0.36533588211687057, 0.004320566267962656
-0.3695731402081475, 0.004320566267962656
-0.37381039829942436, 0.004320566267962656
-0.3780476563907013, 0.0042924013119919726
-0.3820326967384498, 0.0043432312355088905
-0.3865221725732551, 0.00436601509968164
-0.3911125355054717, 0.0043489160306853574
-0.3949966887558089, 0.00436601509968164
-0.39923394684708574, 0.00436601509968164
-0.4034712049383627, 0.0043889184841926976
-0.40770846302963953, 0.004411942016025765
-0.4119457211209164, 0.004435086325453582
-0.4161829792121933, 0.004435086325453582
-0.42042023730347017, 0.00445446596763562
-0.4246574953947471, 0.004480437281501035
-0.42910661639058784, 0.004552641828475097
-0.4331320115773009, 0.004588512364270972
-0.43736926966857775, 0.004608562419950179
-0.4416065277598547, 0.0046489257475125206
-0.44584378585113155, 0.004620634482234403
-0.4500810439424085, 0.0046448735574129065
-0.4620866085343596, 0.004911470772874806
-0.4663238666256366, 0.004928632292727861
-0.4705611247169134, 0.00498047748286831
-0.47479838280819037, 0.00505485976326881
-0.4790356408994672, 0.005139308275567383
-0.48327289899074416, 0.005229726057483824
-0.487510157082021, 0.005266337025047732
-0.49174741517329795, 0.005261746674520947
-0.49573245552104644, 0.005406598972751928
-0.5002219313558518, 0.005534715753871662
-0.5044591894471286, 0.005637003526466453
-0.5088477781845224, 0.005726895421144856
-0.5129337056296823, 0.005862602066091917
-0.5171709637209592, 0.005944972276420039
-0.5214082218122362, 0.0060337590637027675
-0.5256454799035131, 0.006123871861138197
-0.5284703186310309, 0.006182896034561619
-0.5397696735411026, 0.006931120037306963
-0.5440069316323797, 0.007071537229917625
-0.5482441897236565, 0.00722109332147239
-0.5524814478149334, 0.007386683825557927
-0.5568952583266802, 0.00753304506089033
-0.5609559639974873, 0.007722606420375884
-0.5650755204751174, 0.007996730208624729
-0.5697051172785497, 0.008290217752889096
-0.5738639076273955, 0.008564550560823652
-0.5778657624913792, 0.008868560232763851
-0.5820459531336153, 0.009164936780996755
-0.5864501335133363, 0.009560332156064597
-0.5907772728368526, 0.009950989368910878
-0.5949952706640782, 0.01038424740854272
-0.5990591863788939, 0.010799321734546785
-0.6033285449102561, 0.011285071121271145
-0.607565803001533, 0.011803425108026148
-0.6118030610928098, 0.012377927591823098
-0.6160403191840869, 0.012991716662358616
-0.6202775772753637, 0.013659744312011095
-0.6245148353666405, 0.014406022784377547
-0.6287520934579174, 0.015186450108488785
-0.6329893515491942, 0.016072100859003544
-0.6372266096404713, 0.017039092385600786
-0.641303365531321, 0.017956467922396847
-0.645701125823025, 0.01896002339079217
-0.6474666500277237, 0.019987157704088467
-0.6513508032780608, 0.020633556148325308
-0.6550423538878853, 0.022126137017146677
-0.6591191097787352, 0.023619716791244694
-0.6633563678700121, 0.025381574232164944
-0.6674331237608617, 0.027160496995905607
-0.6711246743706865, 0.029062486639799167
-0.6745380211664371, 0.030843314012223882
-0.6775982631212483, 0.032899237981248455
-0.6808939083033525, 0.034848246800532834
-0.6839541502581636, 0.03734440488161144
-0.6872497954402679, 0.03964884501996563
-0.6901923357814324, 0.04245800220059076
-0.6930171745089504, 0.04523878858029312
-0.6958420132364682, 0.0482017025328616
-0.6986668519639863, 0.051661868100077835
-0.7014916906915041, 0.05526188933182427
-0.7042660858703162, 0.05924547505650981
-0.7064856020133663, 0.06336803384899212
-0.7094561665482562, 0.06709977368994023
-0.7117317310787565, 0.07161406639602844
-0.7137620839141601, 0.07668798894658098
-0.7159689891700334, 0.08152680393889364
-0.7180876182156719, 0.08721427987399213
-0.7200296948408405, 0.09343422129927723
-0.722148323886479, 0.10033808406111877
-0.7237372956707078, 0.10803432883614765
-0.7256793722958763, 0.11563823008902119
-0.7277391505346915, 0.1252066768131756
-0.7300931828076231, 0.1347614470526261
-0.7315056021713822, 0.1463369830507758
-0.7327162473403184, 0.15619835697408768
-0.7343304408989, 0.16861455112356918
-0.7355410860678364, 0.18111297425336073
-0.736978727205948, 0.19475000008904175
-0.7383659247953542, 0.20843783221409154
-0.7399094973857481, 0.22609673578666215
-0.7405854409384041, 0.24550847759422845
-0.7419418119147123, 0.26628147642369787
-0.7425224732087019, 0.29354935624692996
-0.7441389087027817, 0.3237224315140316
-0.7448226990296809, 0.35067615609760333
-0.7461790700059892, 0.3944705031900081
-0.7453943925816786, 0.3657570384232573
-0.7469413280753194, 0.42557944885606386
-0.7481407635667654, 0.4658247786109112
-0.7488077393774293, 0.5096748477558716
-0.7503806609416155, 0.5942429016761835
-0.7504555619684814, 0.5453100512861365
-0.7509656022942834, 0.6579504012041578
-0.749160844218369, 0.43620720163947063
-0.7519150619776991, 0.7287920607505032
-0.752499289987254, 0.8258689863140388
-0.7523387877868268, 0.7715631895640511
-0.7532972152122346, 0.9604675693997275
-0.7530449974687063, 0.9019058980719554
-0.7555167313552844, 0.9763918844738245
-0.7650505620606576, 0.9755408221548104
-0.7657567717425369, 0.9151761194979002
-0.7661098765834766, 0.857573955923786
-0.7662107636808881, 0.8009438682132493
-0.7671691911062959, 0.7503306131392713
-0.7671691911062959, 0.7046691998624183
-0.7669169733627674, 0.6594821709309684
-0.7676231830446469, 0.6179621104586221
-0.7682285056291152, 0.581050460836442
-0.7683293927265265, 0.5446311579814807
-0.76932705402315, 0.5021020013060761
-0.769035602408406, 0.4630861168558576
-0.7698426991876968, 0.43005619740116563
-0.7713672153263573, 0.3986200110104354
-0.7728581024325474, 0.365969731925059
-0.7743826185712077, 0.34034687904368754
-0.7756437072888498, 0.31639642143013813
-0.7770561266526086, 0.292514461861666
-0.7784685460163676, 0.27149843654018724
-0.7799201992513423, 0.2508048661450886
-0.7825645621712687, 0.23245419257924366
-0.784824433153283, 0.2158097135347959
-0.787060763812568, 0.2019121809477098
-0.7892382436650298, 0.19009389317571168
-0.7925927396539574, 0.1780127191741841
-0.7961237880633547, 0.16569934035653242
-0.799654836472752, 0.15488463974741273
-0.8033463870825768, 0.1455214078083586
-0.8070700381324867, 0.1396058331935921
-0.8091886671781252, 0.13327143310785183
-0.8127197155875225, 0.1301040708444465
-0.8153680018945706, 0.1251611922639179
-0.8190756027244379, 0.12232872819169043
-0.8216650382246626, 0.1184448163300098
-0.8254314898613533, 0.11624484889070615
-0.8283975705252471, 0.11285877385104218
-0.8321404818392084, 0.11172291288770686
-0.8363777399304853, 0.10902805651126767
-0.8406149980217621, 0.10676997601351931
-0.8448522561130389, 0.10510715987472857
-0.849089514204316, 0.10328994112274241
-0.8533267722955928, 0.10203661436383693
-0.8575640303868697, 0.1011507027548758
-0.8618012884781465, 0.09992333365129454
-0.8660385465694234, 0.09957540015323858
-0.8702758046607004, 0.09871085752300052
-0.8745130627519773, 0.09871085752300052
-0.8791034256841939, 0.09793918882798058
-0.8829371353858253, 0.09922867816119085
-0.8836937886164105, 0.0969196729513494
-0.8879310467076875, 0.09871085752300052
-0.8921683047989644, 0.09871085752300052
-0.8964055628902412, 0.09871085752300052
-0.900642820981518, 0.0993152453114635
-0.9048800790727949, 0.09974921519978601
-0.909117337164072, 0.10044751473633234
-0.9133545952553488, 0.10168132241281692
-0.9175918533466256, 0.10239314776576904
-0.9219896136383297, 0.10123092132520257
-0.9260663695291795, 0.10474117627040297
-0.9303036276204564, 0.10593530544003686
-0.9345408857117332, 0.10761122300610346
-0.9387781438030101, 0.10893302328527757
-0.9430154018942871, 0.11084952290249879
-0.947252659985564, 0.11250503491377824
-0.9515403616255464, 0.11428488690457334
-0.9555758455220007, 0.11617970210214777
-0.9599644342593945, 0.1189623751756222
-0.9642016923506715, 0.12147831298304365
-0.9684389504419484, 0.12393933567206711
-0.9728275391793424, 0.12660783873658144
-0.9769639101732079, 0.12947888293079302
-0.9814029424593074, 0.13271228520658176
-0.985299706596821, 0.1358232405106948
-0.9893730231548044, 0.13952759427132272
-0.993812055440904, 0.14269161549988543
-0.9979820554672401, 0.14496106363939804
+0.019293137995924386, 0.9225879534963551
+0.020195517033881505, 0.8502270986426581
+0.02105866220062308, 0.7903582555750823
+0.021159549298034458, 0.7432602696844071
+0.02186575897991394, 0.6954252961765095
+0.023000738825791678, 0.6513379616008309
+0.021764871882502562, 0.9611857352930676
+0.025119367871430126, 0.511344251162802
+0.02600212997377946, 0.47151228943221823
+0.02494281545096025, 0.5870090523554583
+0.02620390416860216, 0.43620720163947063
+0.02600212997377946, 0.560741032158277
+0.02794420659894803, 0.4046027095113585
+0.029533178383176872, 0.36511969930704224
+0.03059249290599611, 0.3007001374179111
+0.030239388065056355, 0.3369718463535166
+0.03191663605952014, 0.27507304586758075
+0.03271112195163456, 0.2558115401860372
+0.0342412429290401, 0.24087342993549263
+0.03571251309962234, 0.22532911423098806
+0.03694838004291143, 0.21217102469135218
+0.037693823596006426, 0.1871062101684233
+0.03730148488385118, 0.20109218353904598
+0.03924356150901975, 0.17357504103210122
+0.03962188812431233, 0.16093886204081606
+0.042068400236537684, 0.1515974849829428
+0.04464606557539777, 0.13826104798594643
+0.0461291059073447, 0.12839469002735113
+0.04762980148133861, 0.11406087459568622
+0.04718842043016394, 0.12264916651742237
+0.04910527528097966, 0.10661048569533649
+0.05054291641909148, 0.09935855720294343
+0.053230436597355046, 0.09211287034185889
+0.052838097885199775, 0.09768330882012806
+0.05601604145365746, 0.08481423813042094
+0.05813467049929591, 0.07848077054239712
+0.060135597931287754, 0.07153084956673489
+0.06175399511892826, 0.06636751802460485
+0.06390204956797835, 0.06261472049748291
+0.06625608184090992, 0.05883849365454301
+0.06890436814795803, 0.055879733559944446
+0.07079600122442092, 0.05237141021487271
+0.0730155173674707, 0.04900087485548452
+0.07578991254628298, 0.045476103693963835
+0.07861475127380091, 0.04218122649842182
+0.08138914645261314, 0.0394812664214923
+0.08373477146742714, 0.03726687204875243
+0.0869715658427081, 0.03499034815708491
+0.08991410618387258, 0.03272755470658312
+0.09273894491139051, 0.030595526771392857
+0.09556378363890844, 0.02888436603927864
+0.09850632398007297, 0.027156191064178915
+0.10191967077582381, 0.025539207752554246
+0.1054507191852212, 0.02398501777345455
+0.10886406598097204, 0.02266464446544479
+0.11251281600401603, 0.0221340316045439
+0.23442226233846164, 0.006102548511721859
+0.23821813937856384, 0.005970949546543947
+0.24245539746984074, 0.005939790400195441
+0.24669265556111764, 0.005826924914147607
+0.25092991365239453, 0.005706243449839193
+0.25516717174367143, 0.005573461817568539
+0.2594044298349483, 0.005448519099879793
+0.26364168792622517, 0.005331024011734417
+0.26787894601750206, 0.005225167618544427
+0.27211620410877896, 0.0051348286483923825
+0.27635346220005585, 0.005090246570302099
+0.28059072029133275, 0.00499352377125492
+0.28482797838260965, 0.004945853777869779
+0.28906523647388654, 0.004868827952923447
+0.29330249456516344, 0.004784649810665665
+0.29753975265644034, 0.004734843124450799
+0.30177701074771723, 0.004677390234821966
+0.30601426883899413, 0.004640824899364683
+0.31025152693027097, 0.004505250271731682
+0.3144887850215479, 0.004489562969983612
+0.31872604311282476, 0.004462241514691589
+0.3229633012041017, 0.0044583520460551905
+0.32720055929537856, 0.0044583520460551905
+0.3314378173866555, 0.004438955497063265
+0.33567507547793235, 0.004411942016025765
+0.34016455131273765, 0.00436601509968164
+0.34414959166048614, 0.004331883928512109
+0.3483868497517631, 0.004331883928512109
+0.35262410784303994, 0.004331883928512109
+0.3567008637338897, 0.004334975705194922
+0.36109862402559373, 0.004328108084775051
+0.36533588211687057, 0.004320566267962656
+0.3695731402081475, 0.004320566267962656
+0.37381039829942436, 0.004320566267962656
+0.3780476563907013, 0.0042924013119919726
+0.3820326967384498, 0.0043432312355088905
+0.3865221725732551, 0.00436601509968164
+0.3911125355054717, 0.0043489160306853574
+0.3949966887558089, 0.00436601509968164
+0.39923394684708574, 0.00436601509968164
+0.4034712049383627, 0.0043889184841926976
+0.40770846302963953, 0.004411942016025765
+0.4119457211209164, 0.004435086325453582
+0.4161829792121933, 0.004435086325453582
+0.42042023730347017, 0.00445446596763562
+0.4246574953947471, 0.004480437281501035
+0.42910661639058784, 0.004552641828475097
+0.4331320115773009, 0.004588512364270972
+0.43736926966857775, 0.004608562419950179
+0.4416065277598547, 0.0046489257475125206
+0.44584378585113155, 0.004620634482234403
+0.4500810439424085, 0.0046448735574129065
+0.4620866085343596, 0.004911470772874806
+0.4663238666256366, 0.004928632292727861
+0.4705611247169134, 0.00498047748286831
+0.47479838280819037, 0.00505485976326881
+0.4790356408994672, 0.005139308275567383
+0.48327289899074416, 0.005229726057483824
+0.487510157082021, 0.005266337025047732
+0.49174741517329795, 0.005261746674520947
+0.49573245552104644, 0.005406598972751928
+0.5002219313558518, 0.005534715753871662
+0.5044591894471286, 0.005637003526466453
+0.5088477781845224, 0.005726895421144856
+0.5129337056296823, 0.005862602066091917
+0.5171709637209592, 0.005944972276420039
+0.5214082218122362, 0.0060337590637027675
+0.5256454799035131, 0.006123871861138197
+0.5284703186310309, 0.006182896034561619
+0.5397696735411026, 0.006931120037306963
+0.5440069316323797, 0.007071537229917625
+0.5482441897236565, 0.00722109332147239
+0.5524814478149334, 0.007386683825557927
+0.5568952583266802, 0.00753304506089033
+0.5609559639974873, 0.007722606420375884
+0.5650755204751174, 0.007996730208624729
+0.5697051172785497, 0.008290217752889096
+0.5738639076273955, 0.008564550560823652
+0.5778657624913792, 0.008868560232763851
+0.5820459531336153, 0.009164936780996755
+0.5864501335133363, 0.009560332156064597
+0.5907772728368526, 0.009950989368910878
+0.5949952706640782, 0.01038424740854272
+0.5990591863788939, 0.010799321734546785
+0.6033285449102561, 0.011285071121271145
+0.607565803001533, 0.011803425108026148
+0.6118030610928098, 0.012377927591823098
+0.6160403191840869, 0.012991716662358616
+0.6202775772753637, 0.013659744312011095
+0.6245148353666405, 0.014406022784377547
+0.6287520934579174, 0.015186450108488785
+0.6329893515491942, 0.016072100859003544
+0.6372266096404713, 0.017039092385600786
+0.641303365531321, 0.017956467922396847
+0.645701125823025, 0.01896002339079217
+0.6474666500277237, 0.019987157704088467
+0.6513508032780608, 0.020633556148325308
+0.6550423538878853, 0.022126137017146677
+0.6591191097787352, 0.023619716791244694
+0.6633563678700121, 0.025381574232164944
+0.6674331237608617, 0.027160496995905607
+0.6711246743706865, 0.029062486639799167
+0.6745380211664371, 0.030843314012223882
+0.6775982631212483, 0.032899237981248455
+0.6808939083033525, 0.034848246800532834
+0.6839541502581636, 0.03734440488161144
+0.6872497954402679, 0.03964884501996563
+0.6901923357814324, 0.04245800220059076
+0.6930171745089504, 0.04523878858029312
+0.6958420132364682, 0.0482017025328616
+0.6986668519639863, 0.051661868100077835
+0.7014916906915041, 0.05526188933182427
+0.7042660858703162, 0.05924547505650981
+0.7064856020133663, 0.06336803384899212
+0.7094561665482562, 0.06709977368994023
+0.7117317310787565, 0.07161406639602844
+0.7137620839141601, 0.07668798894658098
+0.7159689891700334, 0.08152680393889364
+0.7180876182156719, 0.08721427987399213
+0.7200296948408405, 0.09343422129927723
+0.722148323886479, 0.10033808406111877
+0.7237372956707078, 0.10803432883614765
+0.7256793722958763, 0.11563823008902119
+0.7277391505346915, 0.1252066768131756
+0.7300931828076231, 0.1347614470526261
+0.7315056021713822, 0.1463369830507758
+0.7327162473403184, 0.15619835697408768
+0.7343304408989, 0.16861455112356918
+0.7355410860678364, 0.18111297425336073
+0.736978727205948, 0.19475000008904175
+0.7383659247953542, 0.20843783221409154
+0.7399094973857481, 0.22609673578666215
+0.7405854409384041, 0.24550847759422845
+0.7419418119147123, 0.26628147642369787
+0.7425224732087019, 0.29354935624692996
+0.7441389087027817, 0.3237224315140316
+0.7448226990296809, 0.35067615609760333
+0.7461790700059892, 0.3944705031900081
+0.7453943925816786, 0.3657570384232573
+0.7469413280753194, 0.42557944885606386
+0.7481407635667654, 0.4658247786109112
+0.7488077393774293, 0.5096748477558716
+0.7503806609416155, 0.5942429016761835
+0.7504555619684814, 0.5453100512861365
+0.7509656022942834, 0.6579504012041578
+0.749160844218369, 0.43620720163947063
+0.7519150619776991, 0.7287920607505032
+0.752499289987254, 0.8258689863140388
+0.7523387877868268, 0.7715631895640511
+0.7532972152122346, 0.9604675693997275
+0.7530449974687063, 0.9019058980719554
+0.7555167313552844, 0.9763918844738245
+0.7650505620606576, 0.9755408221548104
+0.7657567717425369, 0.9151761194979002
+0.7661098765834766, 0.857573955923786
+0.7662107636808881, 0.8009438682132493
+0.7671691911062959, 0.7503306131392713
+0.7671691911062959, 0.7046691998624183
+0.7669169733627674, 0.6594821709309684
+0.7676231830446469, 0.6179621104586221
+0.7682285056291152, 0.581050460836442
+0.7683293927265265, 0.5446311579814807
+0.76932705402315, 0.5021020013060761
+0.769035602408406, 0.4630861168558576
+0.7698426991876968, 0.43005619740116563
+0.7713672153263573, 0.3986200110104354
+0.7728581024325474, 0.365969731925059
+0.7743826185712077, 0.34034687904368754
+0.7756437072888498, 0.31639642143013813
+0.7770561266526086, 0.292514461861666
+0.7784685460163676, 0.27149843654018724
+0.7799201992513423, 0.2508048661450886
+0.7825645621712687, 0.23245419257924366
+0.784824433153283, 0.2158097135347959
+0.787060763812568, 0.2019121809477098
+0.7892382436650298, 0.19009389317571168
+0.7925927396539574, 0.1780127191741841
+0.7961237880633547, 0.16569934035653242
+0.799654836472752, 0.15488463974741273
+0.8033463870825768, 0.1455214078083586
+0.8070700381324867, 0.1396058331935921
+0.8091886671781252, 0.13327143310785183
+0.8127197155875225, 0.1301040708444465
+0.8153680018945706, 0.1251611922639179
+0.8190756027244379, 0.12232872819169043
+0.8216650382246626, 0.1184448163300098
+0.8254314898613533, 0.11624484889070615
+0.8283975705252471, 0.11285877385104218
+0.8321404818392084, 0.11172291288770686
+0.8363777399304853, 0.10902805651126767
+0.8406149980217621, 0.10676997601351931
+0.8448522561130389, 0.10510715987472857
+0.849089514204316, 0.10328994112274241
+0.8533267722955928, 0.10203661436383693
+0.8575640303868697, 0.1011507027548758
+0.8618012884781465, 0.09992333365129454
+0.8660385465694234, 0.09957540015323858
+0.8702758046607004, 0.09871085752300052
+0.8745130627519773, 0.09871085752300052
+0.8791034256841939, 0.09793918882798058
+0.8829371353858253, 0.09922867816119085
+0.8836937886164105, 0.0969196729513494
+0.8879310467076875, 0.09871085752300052
+0.8921683047989644, 0.09871085752300052
+0.8964055628902412, 0.09871085752300052
+0.900642820981518, 0.0993152453114635
+0.9048800790727949, 0.09974921519978601
+0.909117337164072, 0.10044751473633234
+0.9133545952553488, 0.10168132241281692
+0.9175918533466256, 0.10239314776576904
+0.9219896136383297, 0.10123092132520257
+0.9260663695291795, 0.10474117627040297
+0.9303036276204564, 0.10593530544003686
+0.9345408857117332, 0.10761122300610346
+0.9387781438030101, 0.10893302328527757
+0.9430154018942871, 0.11084952290249879
+0.947252659985564, 0.11250503491377824
+0.9515403616255464, 0.11428488690457334
+0.9555758455220007, 0.11617970210214777
+0.9599644342593945, 0.1189623751756222
+0.9642016923506715, 0.12147831298304365
+0.9684389504419484, 0.12393933567206711
+0.9728275391793424, 0.12660783873658144
+0.9769639101732079, 0.12947888293079302
+0.9814029424593074, 0.13271228520658176
+0.985299706596821, 0.1358232405106948
+0.9893730231548044, 0.13952759427132272
+0.993812055440904, 0.14269161549988543
+0.9979820554672401, 0.14496106363939804
```

## SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP21.csv

 * *Ordering differences only*

```diff
@@ -1,75 +1,75 @@
-0.029533178383176872, 0.813007053303996
-0.03204414614097059, 0.7174836955514713
-0.0323580171106948, 0.6699153098187071
-0.03862562803737521, 0.48623102851646793
-0.04153874297512808, 0.4323445144430961
-0.048600839793922906, 0.305617134061553
-0.05213188820332029, 0.268847997147885
-0.06166571890869332, 0.18601081585263837
-0.06548567127885963, 0.16625196103081752
-0.07620721826739352, 0.11742575243820037
-0.08061567870579273, 0.10492400850005858
-0.09238584007045081, 0.07607742561510655
-0.09700830344275285, 0.06785579621631302
-0.11039418695837755, 0.04922112136680365
-0.11675007409529292, 0.04389806213623985
-0.12840253384630435, 0.033037232822202806
-0.24422092167453946, 0.0048591881531993225
-0.251636123334274, 0.004509967142307495
-0.27176309926783926, 0.003649286445129134
-0.27953140576851354, 0.0034272089054170085
-0.302130115588657, 0.0029265705280861216
-0.3098984220893312, 0.002825353142782376
-0.3148418898624877, 0.002803488279369446
-0.3360281803188721, 0.002583672032540643
-0.3437964868195464, 0.0025470663197760027
-0.3483868497517631, 0.002553738322984916
-0.3706324547309667, 0.00250739877332495
-0.37840076123164107, 0.00250739877332495
-0.38299112416385767, 0.002494314019430602
-0.40382430977930234, 0.002565303883642535
-0.41159261627997673, 0.0025861310356442846
-0.4165360840531331, 0.0025783522105828002
-0.4377223745095175, 0.0026736865940620745
-0.4454906810101918, 0.002696676043940004
-0.4500810439424085, 0.0027121120573980716
-0.4723266489216122, 0.002765521517022991
-0.4800949554222865, 0.0027866484157490112
-0.48468531835450307, 0.0027986031437340648
-0.5062247136518272, 0.002825353142782376
-0.5139930201525016, 0.0028280421652509746
-0.5185833830847182, 0.0028280421652509746
-0.5408289880639219, 0.0028280421652509746
-0.5485972945645963, 0.0028280421652509746
-0.5531876574968129, 0.0028280421652509746
-0.574727052794137, 0.002814622596974489
-0.5824953592948114, 0.002809272616530959
-0.587085722227028, 0.0027986031437340648
-0.6086251175243522, 0.002785323268904902
-0.6163934240250264, 0.00277078817784657
-0.621336891798183, 0.0027454252228326526
-0.6432293919364469, 0.0027694705730892536
-0.6499383839143018, 0.002778541775308601
-0.6764212469847826, 0.0027839987522135447
-0.6848957631673362, 0.0027839987522135447
-0.7103193117149975, 0.0027986031437340648
-0.7202062472613104, 0.0028199827659239644
-0.7244435053525873, 0.0028577908612531055
-0.7449235861270922, 0.0028090817339930527
-0.7533981023096461, 0.0028132841474482946
-0.7788216508573074, 0.0028111821554515485
-0.7876492718808008, 0.0028224988578878863
-0.813425925269402, 0.0028259291465560087
-0.8219004414519557, 0.0028132841474482946
-0.8480301996814967, 0.002821473512502169
-0.8572109255459299, 0.0028226666771504257
-0.8614481836372068, 0.0028577908612531055
-0.8819282644117119, 0.0027777630808393803
-0.8916739580216486, 0.00277817835739472
-0.8960524580493014, 0.0028280421652509746
-0.9165325388238064, 0.0027243023136069673
-0.9250070550063603, 0.0027060373996754708
-0.9504306035540215, 0.0026401075012274077
-0.9589051197365754, 0.0026184897800849076
-0.9850348779661162, 0.0025299896734448813
-0.9935093941486699, 0.0025055253286681233
+0.029533178383176872, 0.813007053303996
+0.03204414614097059, 0.7174836955514713
+0.0323580171106948, 0.6699153098187071
+0.03862562803737521, 0.48623102851646793
+0.04153874297512808, 0.4323445144430961
+0.048600839793922906, 0.305617134061553
+0.05213188820332029, 0.268847997147885
+0.06166571890869332, 0.18601081585263837
+0.06548567127885963, 0.16625196103081752
+0.07620721826739352, 0.11742575243820037
+0.08061567870579273, 0.10492400850005858
+0.09238584007045081, 0.07607742561510655
+0.09700830344275285, 0.06785579621631302
+0.11039418695837755, 0.04922112136680365
+0.11675007409529292, 0.04389806213623985
+0.12840253384630435, 0.033037232822202806
+0.24422092167453946, 0.0048591881531993225
+0.251636123334274, 0.004509967142307495
+0.27176309926783926, 0.003649286445129134
+0.27953140576851354, 0.0034272089054170085
+0.302130115588657, 0.0029265705280861216
+0.3098984220893312, 0.002825353142782376
+0.3148418898624877, 0.002803488279369446
+0.3360281803188721, 0.002583672032540643
+0.3437964868195464, 0.0025470663197760027
+0.3483868497517631, 0.002553738322984916
+0.3706324547309667, 0.00250739877332495
+0.37840076123164107, 0.00250739877332495
+0.38299112416385767, 0.002494314019430602
+0.40382430977930234, 0.002565303883642535
+0.41159261627997673, 0.0025861310356442846
+0.4165360840531331, 0.0025783522105828002
+0.4377223745095175, 0.0026736865940620745
+0.4454906810101918, 0.002696676043940004
+0.4500810439424085, 0.0027121120573980716
+0.4723266489216122, 0.002765521517022991
+0.4800949554222865, 0.0027866484157490112
+0.48468531835450307, 0.0027986031437340648
+0.5062247136518272, 0.002825353142782376
+0.5139930201525016, 0.0028280421652509746
+0.5185833830847182, 0.0028280421652509746
+0.5408289880639219, 0.0028280421652509746
+0.5485972945645963, 0.0028280421652509746
+0.5531876574968129, 0.0028280421652509746
+0.574727052794137, 0.002814622596974489
+0.5824953592948114, 0.002809272616530959
+0.587085722227028, 0.0027986031437340648
+0.6086251175243522, 0.002785323268904902
+0.6163934240250264, 0.00277078817784657
+0.621336891798183, 0.0027454252228326526
+0.6432293919364469, 0.0027694705730892536
+0.6499383839143018, 0.002778541775308601
+0.6764212469847826, 0.0027839987522135447
+0.6848957631673362, 0.0027839987522135447
+0.7103193117149975, 0.0027986031437340648
+0.7202062472613104, 0.0028199827659239644
+0.7244435053525873, 0.0028577908612531055
+0.7449235861270922, 0.0028090817339930527
+0.7533981023096461, 0.0028132841474482946
+0.7788216508573074, 0.0028111821554515485
+0.7876492718808008, 0.0028224988578878863
+0.813425925269402, 0.0028259291465560087
+0.8219004414519557, 0.0028132841474482946
+0.8480301996814967, 0.002821473512502169
+0.8572109255459299, 0.0028226666771504257
+0.8614481836372068, 0.0028577908612531055
+0.8819282644117119, 0.0027777630808393803
+0.8916739580216486, 0.00277817835739472
+0.8960524580493014, 0.0028280421652509746
+0.9165325388238064, 0.0027243023136069673
+0.9250070550063603, 0.0027060373996754708
+0.9504306035540215, 0.0026401075012274077
+0.9589051197365754, 0.0026184897800849076
+0.9850348779661162, 0.0025299896734448813
+0.9935093941486699, 0.0025055253286681233
```

## SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP41.csv

 * *Ordering differences only*

```diff
@@ -1,237 +1,237 @@
-0.12169354186844927, 0.9445676024808226
-0.12463608220961381, 0.9000726434052022
-0.12699011448254538, 0.8433353071030851
-0.1294618483691236, 0.8367425626753014
-0.13169817902840864, 0.7433837347888443
-0.1346575338858083, 0.7143918684762212
-0.13798680810038305, 0.6391008140705834
-0.14087890489284188, 0.6061695010944297
-0.14429225168859272, 0.5630930431560202
-0.14711709041611065, 0.5427009454833469
-0.14999237269233423, 0.4872314926772639
-0.1527667678711465, 0.4656893954160731
-0.1552385017577247, 0.46447271588684824
-0.1571805783828933, 0.4155987462818408
-0.1605350743718208, 0.39286849587726513
-0.16406612278121824, 0.36473782903793217
-0.1665378566677964, 0.35569180413491497
-0.16918614297484447, 0.3207718887863496
-0.17242293735012543, 0.3088319769397648
-0.1750123728503502, 0.30722035039836565
-0.17713100189598863, 0.2748932027450525
-0.18042664707809286, 0.26628147642369787
-0.18187269547432228, 0.2522043143952256
-0.18525241323760266, 0.23961644218231834
-0.18772414712418084, 0.2377432489806376
-0.19054898585169877, 0.2135011347788835
-0.19418092135850756, 0.2076603060168962
-0.19372692942015646, 0.20004279252885715
-0.19902350203425256, 0.1845137711849144
-0.2026554375410613, 0.1777600943377138
-0.20361386496646922, 0.16949907483921656
-0.2071449133758666, 0.16252244171112562
-0.20996975210338453, 0.1622675406810958
-0.21314769567184222, 0.14606075833515442
-0.21677963117865096, 0.14311887092513115
-0.2166787440812396, 0.13773157212900827
-0.22296401024996698, 0.12695846362792002
-0.22656567962755236, 0.12289004598702173
-0.22868430867319084, 0.11700759934502143
-0.23221535708258823, 0.11415208581670078
-0.23398088128728695, 0.11221109956918658
-0.2390756797065603, 0.10526440120293731
-0.2428085023107805, 0.10257188136581136
-0.24563334103829843, 0.1040130276941149
-0.25092991365239453, 0.0984529614213443
-0.25516717174367143, 0.09871085752300052
-0.25958098225541815, 0.09838859274447767
-0.2622292685624662, 0.09871085752300052
-0.2703506799040803, 0.11043144021641725
-0.2738817283134777, 0.11388694641337246
-0.27882519608663403, 0.12564417038062814
-0.2827093493369712, 0.12912451440345063
-0.28710710962867525, 0.13421770606708378
-0.29118386551952496, 0.1386957691183564
-0.2978222365291921, 0.1301191988409116
-0.3014239059067775, 0.12789184484394944
-0.30177701074771723, 0.12361552659661418
-0.30636737367993383, 0.11401943904607359
-0.3096630188620381, 0.11123685011586622
-0.3109577366121505, 0.10575071100479047
-0.3140650592124202, 0.09980141885363815
-0.31660741406718634, 0.09871085752300052
-0.3194322527947043, 0.08832404407788391
-0.32220664797351656, 0.08462426903779438
-0.3266709020339689, 0.0756914187456626
-0.32990769640924994, 0.07169738003726707
-0.33296793836406097, 0.06721690051312437
-0.33560445450974435, 0.06501848894428672
-0.33955922872826955, 0.05856548443928111
-0.3431911642350783, 0.05711487316088468
-0.34273717229672723, 0.05508147391478541
-0.34866933362451485, 0.050631619977988374
-0.3523718900995115, 0.048927678574903335
-0.3535825352684478, 0.046537776756200466
-0.35731535787266794, 0.0456421117270845
-0.3575675756161963, 0.04386936152494362
-0.3635703579121719, 0.04108010631287118
-0.36710140632156935, 0.039903204464367424
-0.36780761600344875, 0.038490564430582457
-0.3741635031403641, 0.036592231362808224
-0.37769455154976156, 0.03556457175377749
-0.3805193902772795, 0.034166206371465745
-0.384207374171539, 0.03349751465258039
-0.3865221725732551, 0.032856232913303814
-0.3925249548692307, 0.03122216577074076
-0.3964483419907833, 0.030593303525730114
-0.39852773716520623, 0.03009934574924187
-0.4050601767225915, 0.02901690488689344
-0.4088383985206467, 0.0283565275982605
-0.4133189066134599, 0.0278112404293592
-0.4173431808324239, 0.027517163286578057
-0.425615922820155, 0.026567269094315525
-0.4297522938140205, 0.02623182564614052
-0.4378989269299874, 0.025509159990785017
-0.44216140679561716, 0.025307378422453793
-0.4461968906920713, 0.02496450717395945
-0.45073681007558225, 0.02483887194918688
-0.45890866496590194, 0.024240491111875054
-0.46279281821623913, 0.024288098745972
-0.46561765694375706, 0.02467234129066144
-0.4716204392397327, 0.02370741589908594
-0.4752523747465414, 0.023731793438157955
-0.47956529816087684, 0.023475977848136684
-0.48397910867262356, 0.023537472830940636
-0.4868039474001415, 0.023785067839427337
-0.4928067296961171, 0.023034918027765694
-0.49643866520292584, 0.022998360189587733
-0.4991626168330325, 0.023170904520719404
-0.5058716088108874, 0.02281004507852421
-0.5101088669021645, 0.022612001622633614
-0.5142956814447357, 0.022354328555194064
-0.5185833830847182, 0.022318155776500752
-0.5270578992672721, 0.02184639703977992
-0.5316482621994887, 0.021675613590850337
-0.5397696735411026, 0.02144062696353017
-0.5443600364733194, 0.021226689874401537
-0.548496407467185, 0.02108831708976241
-0.5522292300714049, 0.020931280942826855
-0.5549531817015116, 0.020978268603617692
-0.5616621736793665, 0.02075989148449344
-0.5656472140271152, 0.020482457850946167
-0.5746261656967258, 0.020223842399571416
-0.5786112060444741, 0.02011830513784356
-0.5828484641357512, 0.02011830513784356
-0.5869343915809109, 0.019894004715030233
-0.595383685989112, 0.019637314228503545
-0.5997974965008586, 0.01970163484275471
-0.6082720126834125, 0.01970163484275471
-0.6125092707746893, 0.01970163484275471
-0.6167465288659661, 0.01970163484275471
-0.6209837869572432, 0.01970163484275471
-0.6234555208438213, 0.01970163484275471
-0.6301645128216764, 0.01970163484275471
-0.6345783233334232, 0.019637314228503545
-0.6432293919364469, 0.01970163484275471
-0.6474666500277237, 0.019966833971324434
-0.6538225371646391, 0.019987157704088467
-0.6566473758921569, 0.020329933292111444
-0.6639112469057744, 0.020651556873406515
-0.6682998356431684, 0.020850604322797974
-0.6725370937344453, 0.021198942871847606
-0.6767743518257223, 0.021421938453317364
-0.6810116099169992, 0.02191317564262582
-0.6834833438035772, 0.022221058194825616
-0.6901923357814324, 0.021647279766348154
-0.6972544326002272, 0.022651472276113478
-0.7014916906915041, 0.02288974728170661
-0.7039634245780824, 0.023049988140609257
-0.7108237472020544, 0.02351988641701259
-0.7147331222267443, 0.023785067839427337
-0.7191469327384912, 0.02424577623741267
-0.723384190829768, 0.02439954715422744
-0.7304967311972685, 0.025212975455886834
-0.7348012473534864, 0.025400025306561082
-0.7375083844673578, 0.02552584882463031
-0.7440408240247429, 0.026339885393830444
-0.7481519732442556, 0.02670663654165218
-0.7523387877868268, 0.027073434802491574
-0.7563238281345752, 0.027394034047605573
-0.7645965701223063, 0.028415935658176232
-0.768531166921349, 0.02875780580559294
-0.771053344356633, 0.028565000900911713
-0.7771065702013145, 0.029674911667048956
-0.7812933847438857, 0.030151886027005255
-0.7854914089639469, 0.030380622408337485
-0.7897679009264393, 0.030816429742939466
-0.7977127598475835, 0.031882484019903304
-0.8015772961623129, 0.03223659693296423
-0.8042451994049686, 0.032386871247531
-0.8103993123470614, 0.03359502466632582
-0.8146617922126911, 0.03399285152598308
-0.8187224978834982, 0.03462107765743454
-0.8226772721020232, 0.03504938833917844
-0.8309046148959192, 0.03686446694607493
-0.8347691512106485, 0.037474892626609496
-0.8423099012582729, 0.0395107875629375
-0.846264675476798, 0.04050503604336413
-0.8505019335680748, 0.042254856449554026
-0.854083425526178, 0.04386936152494362
-0.85996514330526, 0.048302687028307686
-0.8632641513906112, 0.05003719540190636
-0.8670978610922426, 0.05616470590389427
-0.8703935062743471, 0.05793899255904217
-0.8716882240244592, 0.0657626164836583
-0.8753958248543265, 0.07475667511508109
-0.8745130627519773, 0.066846698594214
-0.8775144538999651, 0.07866919762840699
-0.879338828911487, 0.0906256210625599
-0.8805158450479529, 0.0989406655799369
-0.8819282644117119, 0.10649102432290718
-0.882836248288414, 0.12380045662052915
-0.8845513289444071, 0.13045029337339853
-0.8851062079801695, 0.15021576158873953
-0.8862537987132237, 0.16279903637180917
-0.886960008395103, 0.17448558664761482
-0.8879702805789029, 0.2024999397633646
-0.8893434660714463, 0.21694181517380984
-0.8902262281737958, 0.24324808190996436
-0.8889903612305066, 0.17829235381513234
-0.8918151999580246, 0.25765852683232854
-0.8904027805942656, 0.20320750922619923
-0.8928352806096282, 0.2796075638668033
-0.8944987967491667, 0.29401048379565514
-0.8955480225622447, 0.33454589490986864
-0.8974648774130605, 0.35522685263017517
-0.8984737483871739, 0.39848761216448697
-0.9002897161405783, 0.4174511558979457
-0.9012784096952098, 0.3742096540653075
-0.9020552403452771, 0.32457041771882295
-0.903013667770685, 0.304704769551326
-0.9034676597090361, 0.26767834448380823
-0.9044260871344438, 0.253337908857549
-0.9051322968163233, 0.23650259594369383
-0.9058385064982029, 0.22277527181662504
-0.9052331839137346, 0.2992874964225403
-0.9072811919911854, 0.19244561791943754
-0.9074930548957492, 0.18111297425336073
-0.9084111274821924, 0.16269259814572515
-0.9093695549076002, 0.15216509955630084
-0.9098627807171669, 0.14088996372457424
-0.9119926194402956, 0.13420858633402
-0.9175918533466256, 0.11324324626087995
-0.922535321119782, 0.10110660964015902
-0.9262268717296067, 0.09475449381190976
-0.9267725792110588, 0.10510715987472857
-0.9299505227795166, 0.09141935049381454
-0.9317160469842154, 0.08960406647150573
-0.9393330228387726, 0.08784671210940788
-0.9437216115761664, 0.08797813164074449
-0.9479588696674435, 0.08936996315181608
-0.9521961277587203, 0.0887486734761692
-0.9564333858499972, 0.08999560219794871
-0.960670643941274, 0.09157892864903118
-0.9645547971916113, 0.09328767858801561
-0.9726762085332252, 0.09704652976818058
-0.9917438699439713, 0.09974921519978601
-0.9959811280352482, 0.10239314776576904
+0.12169354186844927, 0.9445676024808226
+0.12463608220961381, 0.9000726434052022
+0.12699011448254538, 0.8433353071030851
+0.1294618483691236, 0.8367425626753014
+0.13169817902840864, 0.7433837347888443
+0.1346575338858083, 0.7143918684762212
+0.13798680810038305, 0.6391008140705834
+0.14087890489284188, 0.6061695010944297
+0.14429225168859272, 0.5630930431560202
+0.14711709041611065, 0.5427009454833469
+0.14999237269233423, 0.4872314926772639
+0.1527667678711465, 0.4656893954160731
+0.1552385017577247, 0.46447271588684824
+0.1571805783828933, 0.4155987462818408
+0.1605350743718208, 0.39286849587726513
+0.16406612278121824, 0.36473782903793217
+0.1665378566677964, 0.35569180413491497
+0.16918614297484447, 0.3207718887863496
+0.17242293735012543, 0.3088319769397648
+0.1750123728503502, 0.30722035039836565
+0.17713100189598863, 0.2748932027450525
+0.18042664707809286, 0.26628147642369787
+0.18187269547432228, 0.2522043143952256
+0.18525241323760266, 0.23961644218231834
+0.18772414712418084, 0.2377432489806376
+0.19054898585169877, 0.2135011347788835
+0.19418092135850756, 0.2076603060168962
+0.19372692942015646, 0.20004279252885715
+0.19902350203425256, 0.1845137711849144
+0.2026554375410613, 0.1777600943377138
+0.20361386496646922, 0.16949907483921656
+0.2071449133758666, 0.16252244171112562
+0.20996975210338453, 0.1622675406810958
+0.21314769567184222, 0.14606075833515442
+0.21677963117865096, 0.14311887092513115
+0.2166787440812396, 0.13773157212900827
+0.22296401024996698, 0.12695846362792002
+0.22656567962755236, 0.12289004598702173
+0.22868430867319084, 0.11700759934502143
+0.23221535708258823, 0.11415208581670078
+0.23398088128728695, 0.11221109956918658
+0.2390756797065603, 0.10526440120293731
+0.2428085023107805, 0.10257188136581136
+0.24563334103829843, 0.1040130276941149
+0.25092991365239453, 0.0984529614213443
+0.25516717174367143, 0.09871085752300052
+0.25958098225541815, 0.09838859274447767
+0.2622292685624662, 0.09871085752300052
+0.2703506799040803, 0.11043144021641725
+0.2738817283134777, 0.11388694641337246
+0.27882519608663403, 0.12564417038062814
+0.2827093493369712, 0.12912451440345063
+0.28710710962867525, 0.13421770606708378
+0.29118386551952496, 0.1386957691183564
+0.2978222365291921, 0.1301191988409116
+0.3014239059067775, 0.12789184484394944
+0.30177701074771723, 0.12361552659661418
+0.30636737367993383, 0.11401943904607359
+0.3096630188620381, 0.11123685011586622
+0.3109577366121505, 0.10575071100479047
+0.3140650592124202, 0.09980141885363815
+0.31660741406718634, 0.09871085752300052
+0.3194322527947043, 0.08832404407788391
+0.32220664797351656, 0.08462426903779438
+0.3266709020339689, 0.0756914187456626
+0.32990769640924994, 0.07169738003726707
+0.33296793836406097, 0.06721690051312437
+0.33560445450974435, 0.06501848894428672
+0.33955922872826955, 0.05856548443928111
+0.3431911642350783, 0.05711487316088468
+0.34273717229672723, 0.05508147391478541
+0.34866933362451485, 0.050631619977988374
+0.3523718900995115, 0.048927678574903335
+0.3535825352684478, 0.046537776756200466
+0.35731535787266794, 0.0456421117270845
+0.3575675756161963, 0.04386936152494362
+0.3635703579121719, 0.04108010631287118
+0.36710140632156935, 0.039903204464367424
+0.36780761600344875, 0.038490564430582457
+0.3741635031403641, 0.036592231362808224
+0.37769455154976156, 0.03556457175377749
+0.3805193902772795, 0.034166206371465745
+0.384207374171539, 0.03349751465258039
+0.3865221725732551, 0.032856232913303814
+0.3925249548692307, 0.03122216577074076
+0.3964483419907833, 0.030593303525730114
+0.39852773716520623, 0.03009934574924187
+0.4050601767225915, 0.02901690488689344
+0.4088383985206467, 0.0283565275982605
+0.4133189066134599, 0.0278112404293592
+0.4173431808324239, 0.027517163286578057
+0.425615922820155, 0.026567269094315525
+0.4297522938140205, 0.02623182564614052
+0.4378989269299874, 0.025509159990785017
+0.44216140679561716, 0.025307378422453793
+0.4461968906920713, 0.02496450717395945
+0.45073681007558225, 0.02483887194918688
+0.45890866496590194, 0.024240491111875054
+0.46279281821623913, 0.024288098745972
+0.46561765694375706, 0.02467234129066144
+0.4716204392397327, 0.02370741589908594
+0.4752523747465414, 0.023731793438157955
+0.47956529816087684, 0.023475977848136684
+0.48397910867262356, 0.023537472830940636
+0.4868039474001415, 0.023785067839427337
+0.4928067296961171, 0.023034918027765694
+0.49643866520292584, 0.022998360189587733
+0.4991626168330325, 0.023170904520719404
+0.5058716088108874, 0.02281004507852421
+0.5101088669021645, 0.022612001622633614
+0.5142956814447357, 0.022354328555194064
+0.5185833830847182, 0.022318155776500752
+0.5270578992672721, 0.02184639703977992
+0.5316482621994887, 0.021675613590850337
+0.5397696735411026, 0.02144062696353017
+0.5443600364733194, 0.021226689874401537
+0.548496407467185, 0.02108831708976241
+0.5522292300714049, 0.020931280942826855
+0.5549531817015116, 0.020978268603617692
+0.5616621736793665, 0.02075989148449344
+0.5656472140271152, 0.020482457850946167
+0.5746261656967258, 0.020223842399571416
+0.5786112060444741, 0.02011830513784356
+0.5828484641357512, 0.02011830513784356
+0.5869343915809109, 0.019894004715030233
+0.595383685989112, 0.019637314228503545
+0.5997974965008586, 0.01970163484275471
+0.6082720126834125, 0.01970163484275471
+0.6125092707746893, 0.01970163484275471
+0.6167465288659661, 0.01970163484275471
+0.6209837869572432, 0.01970163484275471
+0.6234555208438213, 0.01970163484275471
+0.6301645128216764, 0.01970163484275471
+0.6345783233334232, 0.019637314228503545
+0.6432293919364469, 0.01970163484275471
+0.6474666500277237, 0.019966833971324434
+0.6538225371646391, 0.019987157704088467
+0.6566473758921569, 0.020329933292111444
+0.6639112469057744, 0.020651556873406515
+0.6682998356431684, 0.020850604322797974
+0.6725370937344453, 0.021198942871847606
+0.6767743518257223, 0.021421938453317364
+0.6810116099169992, 0.02191317564262582
+0.6834833438035772, 0.022221058194825616
+0.6901923357814324, 0.021647279766348154
+0.6972544326002272, 0.022651472276113478
+0.7014916906915041, 0.02288974728170661
+0.7039634245780824, 0.023049988140609257
+0.7108237472020544, 0.02351988641701259
+0.7147331222267443, 0.023785067839427337
+0.7191469327384912, 0.02424577623741267
+0.723384190829768, 0.02439954715422744
+0.7304967311972685, 0.025212975455886834
+0.7348012473534864, 0.025400025306561082
+0.7375083844673578, 0.02552584882463031
+0.7440408240247429, 0.026339885393830444
+0.7481519732442556, 0.02670663654165218
+0.7523387877868268, 0.027073434802491574
+0.7563238281345752, 0.027394034047605573
+0.7645965701223063, 0.028415935658176232
+0.768531166921349, 0.02875780580559294
+0.771053344356633, 0.028565000900911713
+0.7771065702013145, 0.029674911667048956
+0.7812933847438857, 0.030151886027005255
+0.7854914089639469, 0.030380622408337485
+0.7897679009264393, 0.030816429742939466
+0.7977127598475835, 0.031882484019903304
+0.8015772961623129, 0.03223659693296423
+0.8042451994049686, 0.032386871247531
+0.8103993123470614, 0.03359502466632582
+0.8146617922126911, 0.03399285152598308
+0.8187224978834982, 0.03462107765743454
+0.8226772721020232, 0.03504938833917844
+0.8309046148959192, 0.03686446694607493
+0.8347691512106485, 0.037474892626609496
+0.8423099012582729, 0.0395107875629375
+0.846264675476798, 0.04050503604336413
+0.8505019335680748, 0.042254856449554026
+0.854083425526178, 0.04386936152494362
+0.85996514330526, 0.048302687028307686
+0.8632641513906112, 0.05003719540190636
+0.8670978610922426, 0.05616470590389427
+0.8703935062743471, 0.05793899255904217
+0.8716882240244592, 0.0657626164836583
+0.8753958248543265, 0.07475667511508109
+0.8745130627519773, 0.066846698594214
+0.8775144538999651, 0.07866919762840699
+0.879338828911487, 0.0906256210625599
+0.8805158450479529, 0.0989406655799369
+0.8819282644117119, 0.10649102432290718
+0.882836248288414, 0.12380045662052915
+0.8845513289444071, 0.13045029337339853
+0.8851062079801695, 0.15021576158873953
+0.8862537987132237, 0.16279903637180917
+0.886960008395103, 0.17448558664761482
+0.8879702805789029, 0.2024999397633646
+0.8893434660714463, 0.21694181517380984
+0.8902262281737958, 0.24324808190996436
+0.8889903612305066, 0.17829235381513234
+0.8918151999580246, 0.25765852683232854
+0.8904027805942656, 0.20320750922619923
+0.8928352806096282, 0.2796075638668033
+0.8944987967491667, 0.29401048379565514
+0.8955480225622447, 0.33454589490986864
+0.8974648774130605, 0.35522685263017517
+0.8984737483871739, 0.39848761216448697
+0.9002897161405783, 0.4174511558979457
+0.9012784096952098, 0.3742096540653075
+0.9020552403452771, 0.32457041771882295
+0.903013667770685, 0.304704769551326
+0.9034676597090361, 0.26767834448380823
+0.9044260871344438, 0.253337908857549
+0.9051322968163233, 0.23650259594369383
+0.9058385064982029, 0.22277527181662504
+0.9052331839137346, 0.2992874964225403
+0.9072811919911854, 0.19244561791943754
+0.9074930548957492, 0.18111297425336073
+0.9084111274821924, 0.16269259814572515
+0.9093695549076002, 0.15216509955630084
+0.9098627807171669, 0.14088996372457424
+0.9119926194402956, 0.13420858633402
+0.9175918533466256, 0.11324324626087995
+0.922535321119782, 0.10110660964015902
+0.9262268717296067, 0.09475449381190976
+0.9267725792110588, 0.10510715987472857
+0.9299505227795166, 0.09141935049381454
+0.9317160469842154, 0.08960406647150573
+0.9393330228387726, 0.08784671210940788
+0.9437216115761664, 0.08797813164074449
+0.9479588696674435, 0.08936996315181608
+0.9521961277587203, 0.0887486734761692
+0.9564333858499972, 0.08999560219794871
+0.960670643941274, 0.09157892864903118
+0.9645547971916113, 0.09328767858801561
+0.9726762085332252, 0.09704652976818058
+0.9917438699439713, 0.09974921519978601
+0.9959811280352482, 0.10239314776576904
```

## SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP12.csv

 * *Ordering differences only*

```diff
@@ -1,126 +1,126 @@
-0.022314146079519953, 0.6186296498650461
-0.023076404148850177, 0.5573980483041836
-0.02388350092814101, 0.526617103902779
-0.02670833965565894, 0.38634554061856974
-0.02729684772389185, 0.358807071650743
-0.028473863860357662, 0.339330835180311
-0.02882696870129739, 0.31901448728241155
-0.033064226792574286, 0.23281934763659212
-0.034123541315393524, 0.21769984702215645
-0.035182855838212734, 0.20363323708873832
-0.036242170361031945, 0.19268070444263516
-0.0414378558777167, 0.14036440827931682
-0.043092404275262924, 0.13135042643075945
-0.0446284103333508, 0.12208894897339075
-0.04506979138452549, 0.11700759934502143
-0.05243454949555437, 0.0870623072084876
-0.05401511402166562, 0.08147942236629954
-0.05613374306730404, 0.07645428859933637
-0.05731075920376982, 0.07351225438625668
-0.06615519474349857, 0.054773559623588555
-0.0683747108865484, 0.051459539471579836
-0.07079600122442092, 0.0480937391307835
-0.07261196897782529, 0.04628627141788121
-0.08290245291378345, 0.03524115293500046
-0.08567684809259568, 0.0331584530344253
-0.08850168682011361, 0.031120233677457435
-0.09114997312716167, 0.030138742365781904
-0.10344979175322933, 0.023170904520719404
-0.10721624338991992, 0.02243132063241203
-0.24245539746984074, 0.005731177565693223
-0.24669265556111764, 0.005602699265481804
-0.25092991365239453, 0.005477101119206642
-0.2548140669027317, 0.005354318561204252
-0.2756472525181764, 0.00485610745003043
-0.2798845106094533, 0.004801368196361686
-0.2841217687007302, 0.004734843124450799
-0.28800592195106733, 0.004702747147762864
-0.30954531724839157, 0.00463273816711034
-0.3137825753396684, 0.0046489257475125206
-0.31801983343094536, 0.004669239786723119
-0.3222570915222222, 0.004673313233933811
-0.34414959166048614, 0.0046489257475125206
-0.3483868497517631, 0.004640824899364683
-0.35262410784303994, 0.004624665526152259
-0.35650826109337713, 0.004624665526152259
-0.3787538660725808, 0.004600531905725726
-0.38299112416385767, 0.004600531905725726
-0.3872283822551345, 0.004600531905725726
-0.3911125355054717, 0.004600531905725726
-0.4126519308027959, 0.004624665526152259
-0.41688918889407284, 0.004665169890092364
-0.4211264469853497, 0.004673313233933811
-0.42536370507662663, 0.004665169890092364
-0.44725620521489057, 0.004738973804047336
-0.4514934633061674, 0.004755532589955297
-0.45573072139744436, 0.004813945310575232
-0.45961487464778145, 0.0048173047682804155
-0.48044806026322623, 0.004976136298981216
-0.48468531835450307, 0.00498047748286831
-0.48892257644578, 0.005002240277193135
-0.49315983453705686, 0.00500660423420436
-0.49563156842363504, 0.004950168543269757
-0.5143461249934413, 0.005161765100110363
-0.5185833830847182, 0.005202434954399209
-0.522820641175995, 0.005234288473207709
-0.5270578992672721, 0.005280132118350771
-0.548950399405536, 0.005443769952151235
-0.5531876574968129, 0.005477101119206642
-0.5574249155880897, 0.005496239048340533
-0.5613090688384268, 0.0055192928538346005
-0.5835546738176305, 0.005731177565693223
-0.5877919319089076, 0.005796517354219929
-0.5920291900001844, 0.005837096173551258
-0.5959133432505215, 0.00586464734574269
-0.6174527385478457, 0.006188289996267676
-0.6216899966391227, 0.006247935055834002
-0.6259272547303996, 0.006352315561943648
-0.6298114079807366, 0.0063834117722794854
-0.6506445935961813, 0.006900965440275646
-0.6548818516874582, 0.007010140083763337
-0.6591191097787352, 0.007139695357535807
-0.6630032630290723, 0.007214799126973526
-0.6831302389626375, 0.00796193955780476
-0.6873674970539145, 0.008123240068317496
-0.6916047551451914, 0.008295038645611104
-0.6954889083955285, 0.00844097637789562
-0.7163220940109731, 0.009495525743276514
-0.7205593521022502, 0.009747212232172647
-0.724796610193527, 0.009988134962311025
-0.7279745537619846, 0.010137305450080562
-0.7473953200136705, 0.011503658979524514
-0.7516325781049473, 0.011787995963465435
-0.7558698361962242, 0.01214272723629033
-0.7597539894465613, 0.012341283012081426
-0.7784685460163676, 0.01413228538725972
-0.7827058041076445, 0.014494228119329369
-0.7869430621989215, 0.014943422199874
-0.7908272154492586, 0.015246160196331689
-0.809541772019065, 0.017651611357552825
-0.8137790301103418, 0.01815111008598894
-0.8180162882016186, 0.018729961253019088
-0.8219004414519557, 0.019152785554585477
-0.8399087883398826, 0.022221058194825616
-0.8441460464311594, 0.022849861429158715
-0.8483833045224365, 0.0236609464741502
-0.8519143529318338, 0.024288098745972
-0.8702758046607004, 0.028292309017109843
-0.8745130627519773, 0.029245530806666132
-0.8787503208432541, 0.030204518017087238
-0.8822813692526517, 0.030937593788112016
-0.8999366112996385, 0.03640127635919204
-0.9041738693909156, 0.03749668486928718
-0.9084111274821924, 0.038929386175562415
-0.9119421758915898, 0.039874217997411976
-0.9295974179385769, 0.04712114400230953
-0.9338346760298537, 0.048793769253086414
-0.9380719341211305, 0.050658117986599374
-0.9412498776895883, 0.051864992244321395
-0.9592582245775152, 0.06169334465020701
-0.963495482668792, 0.06405056998297874
-0.9677327407600689, 0.06661393808847933
-0.9705575794875869, 0.06808210077358239
-0.9875066118526943, 0.08112493721316758
-0.9917438699439713, 0.08437163863468863
-0.9959811280352482, 0.08797813164074449
-0.9991590716037058, 0.0901526951120723
+0.022314146079519953, 0.6186296498650461
+0.023076404148850177, 0.5573980483041836
+0.02388350092814101, 0.526617103902779
+0.02670833965565894, 0.38634554061856974
+0.02729684772389185, 0.358807071650743
+0.028473863860357662, 0.339330835180311
+0.02882696870129739, 0.31901448728241155
+0.033064226792574286, 0.23281934763659212
+0.034123541315393524, 0.21769984702215645
+0.035182855838212734, 0.20363323708873832
+0.036242170361031945, 0.19268070444263516
+0.0414378558777167, 0.14036440827931682
+0.043092404275262924, 0.13135042643075945
+0.0446284103333508, 0.12208894897339075
+0.04506979138452549, 0.11700759934502143
+0.05243454949555437, 0.0870623072084876
+0.05401511402166562, 0.08147942236629954
+0.05613374306730404, 0.07645428859933637
+0.05731075920376982, 0.07351225438625668
+0.06615519474349857, 0.054773559623588555
+0.0683747108865484, 0.051459539471579836
+0.07079600122442092, 0.0480937391307835
+0.07261196897782529, 0.04628627141788121
+0.08290245291378345, 0.03524115293500046
+0.08567684809259568, 0.0331584530344253
+0.08850168682011361, 0.031120233677457435
+0.09114997312716167, 0.030138742365781904
+0.10344979175322933, 0.023170904520719404
+0.10721624338991992, 0.02243132063241203
+0.24245539746984074, 0.005731177565693223
+0.24669265556111764, 0.005602699265481804
+0.25092991365239453, 0.005477101119206642
+0.2548140669027317, 0.005354318561204252
+0.2756472525181764, 0.00485610745003043
+0.2798845106094533, 0.004801368196361686
+0.2841217687007302, 0.004734843124450799
+0.28800592195106733, 0.004702747147762864
+0.30954531724839157, 0.00463273816711034
+0.3137825753396684, 0.0046489257475125206
+0.31801983343094536, 0.004669239786723119
+0.3222570915222222, 0.004673313233933811
+0.34414959166048614, 0.0046489257475125206
+0.3483868497517631, 0.004640824899364683
+0.35262410784303994, 0.004624665526152259
+0.35650826109337713, 0.004624665526152259
+0.3787538660725808, 0.004600531905725726
+0.38299112416385767, 0.004600531905725726
+0.3872283822551345, 0.004600531905725726
+0.3911125355054717, 0.004600531905725726
+0.4126519308027959, 0.004624665526152259
+0.41688918889407284, 0.004665169890092364
+0.4211264469853497, 0.004673313233933811
+0.42536370507662663, 0.004665169890092364
+0.44725620521489057, 0.004738973804047336
+0.4514934633061674, 0.004755532589955297
+0.45573072139744436, 0.004813945310575232
+0.45961487464778145, 0.0048173047682804155
+0.48044806026322623, 0.004976136298981216
+0.48468531835450307, 0.00498047748286831
+0.48892257644578, 0.005002240277193135
+0.49315983453705686, 0.00500660423420436
+0.49563156842363504, 0.004950168543269757
+0.5143461249934413, 0.005161765100110363
+0.5185833830847182, 0.005202434954399209
+0.522820641175995, 0.005234288473207709
+0.5270578992672721, 0.005280132118350771
+0.548950399405536, 0.005443769952151235
+0.5531876574968129, 0.005477101119206642
+0.5574249155880897, 0.005496239048340533
+0.5613090688384268, 0.0055192928538346005
+0.5835546738176305, 0.005731177565693223
+0.5877919319089076, 0.005796517354219929
+0.5920291900001844, 0.005837096173551258
+0.5959133432505215, 0.00586464734574269
+0.6174527385478457, 0.006188289996267676
+0.6216899966391227, 0.006247935055834002
+0.6259272547303996, 0.006352315561943648
+0.6298114079807366, 0.0063834117722794854
+0.6506445935961813, 0.006900965440275646
+0.6548818516874582, 0.007010140083763337
+0.6591191097787352, 0.007139695357535807
+0.6630032630290723, 0.007214799126973526
+0.6831302389626375, 0.00796193955780476
+0.6873674970539145, 0.008123240068317496
+0.6916047551451914, 0.008295038645611104
+0.6954889083955285, 0.00844097637789562
+0.7163220940109731, 0.009495525743276514
+0.7205593521022502, 0.009747212232172647
+0.724796610193527, 0.009988134962311025
+0.7279745537619846, 0.010137305450080562
+0.7473953200136705, 0.011503658979524514
+0.7516325781049473, 0.011787995963465435
+0.7558698361962242, 0.01214272723629033
+0.7597539894465613, 0.012341283012081426
+0.7784685460163676, 0.01413228538725972
+0.7827058041076445, 0.014494228119329369
+0.7869430621989215, 0.014943422199874
+0.7908272154492586, 0.015246160196331689
+0.809541772019065, 0.017651611357552825
+0.8137790301103418, 0.01815111008598894
+0.8180162882016186, 0.018729961253019088
+0.8219004414519557, 0.019152785554585477
+0.8399087883398826, 0.022221058194825616
+0.8441460464311594, 0.022849861429158715
+0.8483833045224365, 0.0236609464741502
+0.8519143529318338, 0.024288098745972
+0.8702758046607004, 0.028292309017109843
+0.8745130627519773, 0.029245530806666132
+0.8787503208432541, 0.030204518017087238
+0.8822813692526517, 0.030937593788112016
+0.8999366112996385, 0.03640127635919204
+0.9041738693909156, 0.03749668486928718
+0.9084111274821924, 0.038929386175562415
+0.9119421758915898, 0.039874217997411976
+0.9295974179385769, 0.04712114400230953
+0.9338346760298537, 0.048793769253086414
+0.9380719341211305, 0.050658117986599374
+0.9412498776895883, 0.051864992244321395
+0.9592582245775152, 0.06169334465020701
+0.963495482668792, 0.06405056998297874
+0.9677327407600689, 0.06661393808847933
+0.9705575794875869, 0.06808210077358239
+0.9875066118526943, 0.08112493721316758
+0.9917438699439713, 0.08437163863468863
+0.9959811280352482, 0.08797813164074449
+0.9991590716037058, 0.0901526951120723
```

## SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP31.csv

 * *Ordering differences only*

```diff
@@ -1,156 +1,156 @@
-0.03730148488385118, 0.9452267780022501
-0.039067009088549876, 0.8302013567977528
-0.03977321877042936, 0.7331903773246035
-0.041891847816067806, 0.6475153587738023
-0.04365737202076653, 0.5750019099240278
-0.045776001066404975, 0.5071477868137063
-0.047894630112043424, 0.4449666894076218
-0.050013259157681844, 0.3941037551198636
-0.05248499304426005, 0.3504577979012359
-0.055662936612717706, 0.31045205780427626
-0.05848777534023564, 0.2746775461990602
-0.06095950922681381, 0.24532504185578577
-0.06484366247715101, 0.21773781806596565
-0.0683747108865484, 0.19345515542309827
-0.07190575929594578, 0.17278221229992732
-0.07649612222816243, 0.1539957872958411
-0.08038027547849957, 0.1375395385853209
-0.08461753356977647, 0.12361552659661418
-0.08885479166105337, 0.11098493377451038
-0.09415136427514947, 0.10001050681937684
-0.09874172720736613, 0.09012125460731485
-0.10368519498052248, 0.08116739386941867
-0.10933487243555834, 0.07356355561497667
-0.11468188859836015, 0.06657245907965305
-0.12028112250469031, 0.060626716050359845
-0.12593079995972617, 0.05517762204914054
-0.13158047741476203, 0.05017451717483877
-0.1372301548697979, 0.04602465688778523
-0.13970188875637607, 0.04574457158462823
-0.14429225168859272, 0.04221802542228778
-0.15064813882550804, 0.03869247948975522
-0.1570040259624234, 0.03583436951831214
-0.16406612278121824, 0.033071821877639546
-0.171128219600013, 0.030709126795707236
-0.17783721157786814, 0.028624845720737903
-0.18525241323760266, 0.026779930071585342
-0.193020719738277, 0.025216116540654372
-0.20078902623895128, 0.023930699281708788
-0.20891043758056532, 0.022881764545223664
-0.21738495376311912, 0.022454805595485343
-0.2258594699456729, 0.022454805595485343
-0.2343339861282267, 0.02266727982234891
-0.24210229262890098, 0.02398501777345455
-0.24775197008393685, 0.026188725977734677
-0.2523423330161535, 0.029118294921023496
-0.25622648626649064, 0.03272755470658312
-0.25905132499400857, 0.0365284686516444
-0.261169954039647, 0.04167666474025425
-0.26258237340340596, 0.046858896703048186
-0.2639947927671649, 0.05305433433253283
-0.2654072121309239, 0.06048941568200244
-0.26681963149468285, 0.06801089527523942
-0.2682320508584418, 0.07751495974670512
-0.26893826054032133, 0.0870623072084876
-0.27741277672287507, 0.09260684575627957
-0.28059072029133275, 0.08660797625985006
-0.2827093493369712, 0.06719736518749034
-0.28376866385979044, 0.05923661916115826
-0.28482797838260965, 0.05206891503211951
-0.28553418806448916, 0.04574457158462823
-0.2869466074282481, 0.04018838933306648
-0.28800592195106733, 0.035436615322555674
-0.2887121316329468, 0.03141881223778674
-0.28977144615576605, 0.027682196933282322
-0.29224318004234423, 0.024492277425414447
-0.29436180908798265, 0.021692631683606564
-0.2964804381336211, 0.019192911406660882
-0.29859906717925955, 0.01701681930662627
-0.302130115588657, 0.015134890556260461
-0.3056611639980544, 0.013475181968586119
-0.30954531724839157, 0.012037300541273586
-0.3144887850215479, 0.010841352779822677
-0.3194322527947043, 0.009815448095188826
-0.32578813993161965, 0.008980103614230123
-0.3321440270685349, 0.00825895017125613
-0.3392061238873298, 0.0076555565018549395
-0.34732753522894383, 0.007184663278023873
-0.3543896320477386, 0.006775742104805793
-0.362157938548413, 0.006416898082100911
-0.3699262450490873, 0.0060961659970373535
-0.3773414467088218, 0.005791464877258434
-0.3798131805954, 0.005821845932737567
-0.3858159628913756, 0.005534715753871662
-0.3882876967779538, 0.005583190641392089
-0.3935842693920499, 0.005298581804069411
-0.4017056807336639, 0.005076062216938902
-0.4101801969162177, 0.0048986388595725835
-0.4264230195994458, 0.004472370020592317
-0.4348975357819996, 0.0043889184841926976
-0.44266584228267386, 0.0042134099848915585
-0.45114035846522765, 0.004074657592929009
-0.45961487464778145, 0.0039487299270330066
-0.46808939083033524, 0.0038387259792935346
-0.47656390701288903, 0.0037278835384955537
-0.4843322135135633, 0.003631624434203074
-0.4928067296961171, 0.0035526902795767435
-0.5012812458786708, 0.0034645784299599156
-0.5097557620612247, 0.0033786518814619415
-0.5185833830847182, 0.0033173436396442234
-0.5274110041082118, 0.0032571478831155015
-0.5358855202907655, 0.0031963716070302906
-0.5433007219505002, 0.003140013444620781
-0.5457724558370782, 0.0031896890807806624
-0.5524814478149334, 0.00309111144776097
-0.5609559639974873, 0.0030616025740642593
-0.5690773753391012, 0.003008145235141667
-0.5775518915216549, 0.0029643973244966584
-0.5860264077042088, 0.0029489277430927133
-0.5945009238867625, 0.0029151782312896307
-0.6029754400693164, 0.00289087598975996
-0.6118030610928098, 0.0028677764718510823
-0.6206306821163035, 0.0028577908612531055
-0.6291051982988571, 0.00284287760114513
-0.637579714481411, 0.0028132841474482946
-0.6460542306639647, 0.0028132841474482946
-0.6545287468465186, 0.0027986031437340648
-0.6630032630290723, 0.0027956761492781137
-0.6721839888935055, 0.0027839987522135447
-0.6806585050760594, 0.0027839987522135447
-0.6891330212586131, 0.0027839987522135447
-0.697607537441167, 0.0027839987522135447
-0.7060820536237207, 0.0027839987522135447
-0.7145565698062746, 0.0027839987522135447
-0.7230310859888283, 0.0027839987522135447
-0.7318587070123219, 0.0027839987522135447
-0.7406863280358154, 0.0027839987522135447
-0.749160844218369, 0.0027986031437340648
-0.7576353604009229, 0.0027986031437340648
-0.7661098765834766, 0.0027986031437340648
-0.7745843927660305, 0.0027986031437340648
-0.7830589089485842, 0.0027986031437340648
-0.7915334251311381, 0.0027986031437340648
-0.8007141509955713, 0.0027986031437340648
-0.8091886671781252, 0.0027986031437340648
-0.8176631833606789, 0.0027986031437340648
-0.8261376995432328, 0.0027986031437340648
-0.8346122157257865, 0.0027986031437340648
-0.8430867319083404, 0.0027927522160981293
-0.8519143529318338, 0.002788858394976305
-0.8607419739553273, 0.0027839987522135447
-0.8692164901378812, 0.0027839987522135447
-0.8776910063204348, 0.0027839987522135447
-0.8861655225029887, 0.0027694705730892536
-0.8946400386855424, 0.002757902635383393
-0.9031145548680963, 0.002729193744115009
-0.9122952807325295, 0.0027149515625954
-0.9207697969150834, 0.002709275521973713
-0.9292443130976371, 0.002697959015934349
-0.937718829280191, 0.002669874118722506
-0.9461933454627447, 0.00264208157637845
-0.9546678616452984, 0.0026282939860025212
-0.9631423778278523, 0.00261184381841522
-0.9719699988513457, 0.00256042780340927
-0.9807976198748394, 0.002541741270115316
-0.9892721360573931, 0.002517915980292825
-0.997746652239947, 0.0024812975477681394
+0.03730148488385118, 0.9452267780022501
+0.039067009088549876, 0.8302013567977528
+0.03977321877042936, 0.7331903773246035
+0.041891847816067806, 0.6475153587738023
+0.04365737202076653, 0.5750019099240278
+0.045776001066404975, 0.5071477868137063
+0.047894630112043424, 0.4449666894076218
+0.050013259157681844, 0.3941037551198636
+0.05248499304426005, 0.3504577979012359
+0.055662936612717706, 0.31045205780427626
+0.05848777534023564, 0.2746775461990602
+0.06095950922681381, 0.24532504185578577
+0.06484366247715101, 0.21773781806596565
+0.0683747108865484, 0.19345515542309827
+0.07190575929594578, 0.17278221229992732
+0.07649612222816243, 0.1539957872958411
+0.08038027547849957, 0.1375395385853209
+0.08461753356977647, 0.12361552659661418
+0.08885479166105337, 0.11098493377451038
+0.09415136427514947, 0.10001050681937684
+0.09874172720736613, 0.09012125460731485
+0.10368519498052248, 0.08116739386941867
+0.10933487243555834, 0.07356355561497667
+0.11468188859836015, 0.06657245907965305
+0.12028112250469031, 0.060626716050359845
+0.12593079995972617, 0.05517762204914054
+0.13158047741476203, 0.05017451717483877
+0.1372301548697979, 0.04602465688778523
+0.13970188875637607, 0.04574457158462823
+0.14429225168859272, 0.04221802542228778
+0.15064813882550804, 0.03869247948975522
+0.1570040259624234, 0.03583436951831214
+0.16406612278121824, 0.033071821877639546
+0.171128219600013, 0.030709126795707236
+0.17783721157786814, 0.028624845720737903
+0.18525241323760266, 0.026779930071585342
+0.193020719738277, 0.025216116540654372
+0.20078902623895128, 0.023930699281708788
+0.20891043758056532, 0.022881764545223664
+0.21738495376311912, 0.022454805595485343
+0.2258594699456729, 0.022454805595485343
+0.2343339861282267, 0.02266727982234891
+0.24210229262890098, 0.02398501777345455
+0.24775197008393685, 0.026188725977734677
+0.2523423330161535, 0.029118294921023496
+0.25622648626649064, 0.03272755470658312
+0.25905132499400857, 0.0365284686516444
+0.261169954039647, 0.04167666474025425
+0.26258237340340596, 0.046858896703048186
+0.2639947927671649, 0.05305433433253283
+0.2654072121309239, 0.06048941568200244
+0.26681963149468285, 0.06801089527523942
+0.2682320508584418, 0.07751495974670512
+0.26893826054032133, 0.0870623072084876
+0.27741277672287507, 0.09260684575627957
+0.28059072029133275, 0.08660797625985006
+0.2827093493369712, 0.06719736518749034
+0.28376866385979044, 0.05923661916115826
+0.28482797838260965, 0.05206891503211951
+0.28553418806448916, 0.04574457158462823
+0.2869466074282481, 0.04018838933306648
+0.28800592195106733, 0.035436615322555674
+0.2887121316329468, 0.03141881223778674
+0.28977144615576605, 0.027682196933282322
+0.29224318004234423, 0.024492277425414447
+0.29436180908798265, 0.021692631683606564
+0.2964804381336211, 0.019192911406660882
+0.29859906717925955, 0.01701681930662627
+0.302130115588657, 0.015134890556260461
+0.3056611639980544, 0.013475181968586119
+0.30954531724839157, 0.012037300541273586
+0.3144887850215479, 0.010841352779822677
+0.3194322527947043, 0.009815448095188826
+0.32578813993161965, 0.008980103614230123
+0.3321440270685349, 0.00825895017125613
+0.3392061238873298, 0.0076555565018549395
+0.34732753522894383, 0.007184663278023873
+0.3543896320477386, 0.006775742104805793
+0.362157938548413, 0.006416898082100911
+0.3699262450490873, 0.0060961659970373535
+0.3773414467088218, 0.005791464877258434
+0.3798131805954, 0.005821845932737567
+0.3858159628913756, 0.005534715753871662
+0.3882876967779538, 0.005583190641392089
+0.3935842693920499, 0.005298581804069411
+0.4017056807336639, 0.005076062216938902
+0.4101801969162177, 0.0048986388595725835
+0.4264230195994458, 0.004472370020592317
+0.4348975357819996, 0.0043889184841926976
+0.44266584228267386, 0.0042134099848915585
+0.45114035846522765, 0.004074657592929009
+0.45961487464778145, 0.0039487299270330066
+0.46808939083033524, 0.0038387259792935346
+0.47656390701288903, 0.0037278835384955537
+0.4843322135135633, 0.003631624434203074
+0.4928067296961171, 0.0035526902795767435
+0.5012812458786708, 0.0034645784299599156
+0.5097557620612247, 0.0033786518814619415
+0.5185833830847182, 0.0033173436396442234
+0.5274110041082118, 0.0032571478831155015
+0.5358855202907655, 0.0031963716070302906
+0.5433007219505002, 0.003140013444620781
+0.5457724558370782, 0.0031896890807806624
+0.5524814478149334, 0.00309111144776097
+0.5609559639974873, 0.0030616025740642593
+0.5690773753391012, 0.003008145235141667
+0.5775518915216549, 0.0029643973244966584
+0.5860264077042088, 0.0029489277430927133
+0.5945009238867625, 0.0029151782312896307
+0.6029754400693164, 0.00289087598975996
+0.6118030610928098, 0.0028677764718510823
+0.6206306821163035, 0.0028577908612531055
+0.6291051982988571, 0.00284287760114513
+0.637579714481411, 0.0028132841474482946
+0.6460542306639647, 0.0028132841474482946
+0.6545287468465186, 0.0027986031437340648
+0.6630032630290723, 0.0027956761492781137
+0.6721839888935055, 0.0027839987522135447
+0.6806585050760594, 0.0027839987522135447
+0.6891330212586131, 0.0027839987522135447
+0.697607537441167, 0.0027839987522135447
+0.7060820536237207, 0.0027839987522135447
+0.7145565698062746, 0.0027839987522135447
+0.7230310859888283, 0.0027839987522135447
+0.7318587070123219, 0.0027839987522135447
+0.7406863280358154, 0.0027839987522135447
+0.749160844218369, 0.0027986031437340648
+0.7576353604009229, 0.0027986031437340648
+0.7661098765834766, 0.0027986031437340648
+0.7745843927660305, 0.0027986031437340648
+0.7830589089485842, 0.0027986031437340648
+0.7915334251311381, 0.0027986031437340648
+0.8007141509955713, 0.0027986031437340648
+0.8091886671781252, 0.0027986031437340648
+0.8176631833606789, 0.0027986031437340648
+0.8261376995432328, 0.0027986031437340648
+0.8346122157257865, 0.0027986031437340648
+0.8430867319083404, 0.0027927522160981293
+0.8519143529318338, 0.002788858394976305
+0.8607419739553273, 0.0027839987522135447
+0.8692164901378812, 0.0027839987522135447
+0.8776910063204348, 0.0027839987522135447
+0.8861655225029887, 0.0027694705730892536
+0.8946400386855424, 0.002757902635383393
+0.9031145548680963, 0.002729193744115009
+0.9122952807325295, 0.0027149515625954
+0.9207697969150834, 0.002709275521973713
+0.9292443130976371, 0.002697959015934349
+0.937718829280191, 0.002669874118722506
+0.9461933454627447, 0.00264208157637845
+0.9546678616452984, 0.0026282939860025212
+0.9631423778278523, 0.00261184381841522
+0.9719699988513457, 0.00256042780340927
+0.9807976198748394, 0.002541741270115316
+0.9892721360573931, 0.002517915980292825
+0.997746652239947, 0.0024812975477681394
```

## SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP51.csv

 * *Ordering differences only*

```diff
@@ -1,224 +1,224 @@
-0.14575511460105733, 0.9554554102239319
-0.14852950977986962, 0.8985695436183806
-0.15135434850738755, 0.8416822671042973
-0.15417918723490548, 0.7914962678823056
-0.1570040259624234, 0.7443026502469843
-0.15982886468994134, 0.699008069003934
-0.16265370341745927, 0.6590510006121979
-0.1654785421449772, 0.6205657293819906
-0.16830338087249513, 0.583182451144275
-0.171128219600013, 0.5527306693873699
-0.17395305832753094, 0.5207944680856867
-0.17677789705504887, 0.4919888978755135
-0.1796027357825668, 0.46508065778809576
-0.18242757451008473, 0.43935666423157366
-0.1853701148512492, 0.41373050381123866
-0.18866576003335356, 0.38832709149814626
-0.19172600198816458, 0.3649074998253697
-0.19513934878391542, 0.3414680414967446
-0.1987208407420185, 0.32251486440182225
-0.20096557865942116, 0.304818665995814
-0.20432007464834867, 0.28762010136207583
-0.2078511230577461, 0.2701169632986067
-0.21126446985349695, 0.2537379767684588
-0.21432471180830798, 0.23912938697866504
-0.21773805860405887, 0.22527017447916042
-0.2213195505621619, 0.21284608836894897
-0.22353906670521173, 0.20229822996278335
-0.22703648608213867, 0.19150813658084961
-0.23033213126424296, 0.18058729139453478
-0.23339237321905404, 0.17019024442966496
-0.23668801840115833, 0.16123318060786052
-0.24033676842420226, 0.15128054618566797
-0.24398551844724625, 0.14399516052544795
-0.24543156684347567, 0.13766295796107425
-0.24881128460675606, 0.1305283203273489
-0.25257773624344665, 0.12372336884610519
-0.2546122927079089, 0.11792950918085411
-0.25799201047118936, 0.1116255307168376
-0.26156229275180226, 0.10492400850005858
-0.26576031697186364, 0.09940188798296293
-0.2673240669817396, 0.0943112749094057
-0.27070378474502, 0.08974482271112444
-0.274352534768064, 0.08412674881172508
-0.27788358317746137, 0.08014056203085461
-0.2800610630299232, 0.07574093827164531
-0.28346600256755633, 0.07233133645220131
-0.285710740484959, 0.06852882726332658
-0.2891156800225922, 0.06538888327209208
-0.29136041793999484, 0.061881924732914914
-0.2947149139289224, 0.058681358231883904
-0.29812826072467324, 0.055097486961224455
-0.30133562969654254, 0.05172948760331342
-0.30460184947523516, 0.04873423678666432
-0.308015196270986, 0.04569141557218211
-0.31107543822579703, 0.04286099861859053
-0.3143710834079014, 0.040369864121812975
-0.31731362374906585, 0.037915908869773716
-0.32025616409023033, 0.035751137545065606
-0.32355180927233457, 0.0335754999821346
-0.32649434961349905, 0.03148875446167082
-0.329319188341017, 0.02963058402663415
-0.3321440270685349, 0.027936824934373022
-0.33496886579605284, 0.026253892651534775
-0.33779370452357077, 0.02467234129066144
-0.3406185432510887, 0.023231600368375713
-0.34344338197860663, 0.02184639703977992
-0.34626822070612456, 0.02050351927403326
-0.3490930594336425, 0.019318847325841507
-0.3519178981611604, 0.01820262448660881
-0.35474273688867836, 0.017106086692752192
-0.3575675756161963, 0.016212865681625582
-0.36051011595736077, 0.015219593450529357
-0.3638057611394651, 0.01437674045175807
-0.3674545111625091, 0.013425919585438376
-0.37089728336167155, 0.01268663940246895
-0.3746343095949504, 0.012079360930466401
-0.377576849936115, 0.01149363192907075
-0.3813264870565703, 0.011014237138982565
-0.3858159628913756, 0.01048799233763033
-0.39005322098265244, 0.009979428903361936
-0.3942904790739294, 0.00958704718117178
-0.39852773716520623, 0.009194044761561292
-0.4027649952564832, 0.00886340602199915
-0.40700225334776, 0.008589481647549664
-0.411239511439037, 0.008324022930967073
-0.4154767695303138, 0.008080849285387617
-0.41971402762159077, 0.007851623377088926
-0.4239512857128676, 0.007675610120855667
-0.42818854380414456, 0.007483938562041235
-0.4324258018954214, 0.0073353324516036746
-0.43666305998669835, 0.007189677163901531
-0.4409003180779752, 0.007040771732507048
-0.44513757616925204, 0.006937166750020929
-0.449374834260529, 0.006811286513890746
-0.45361209235180583, 0.006728637927226461
-0.4578493504430828, 0.006629625994857294
-0.4620866085343596, 0.006560613692031756
-0.4663238666256366, 0.006497983688525643
-0.4705611247169134, 0.006419136738404111
-0.47479838280819037, 0.006380072767459883
-0.4790356408994672, 0.006346778628977258
-0.48327289899074416, 0.006308154996851071
-0.487510157082021, 0.006258841214592924
-0.49174741517329795, 0.006231611440228437
-0.4959846732645748, 0.006231611440228437
-0.5002219313558518, 0.006231611440228437
-0.5044591894471286, 0.006231611440228437
-0.5086964475384055, 0.006247935055834002
-0.5129337056296823, 0.006302656556004025
-0.5171709637209592, 0.006341246522223663
-0.5214082218122362, 0.006368955360241889
-0.5256454799035131, 0.006413541561420845
-0.5298827379947899, 0.006458439890605593
-0.5341199960860668, 0.0065491816885621
-0.5383572541773438, 0.00660078308068653
-0.5425945122686207, 0.006693524816277147
-0.5468317703598975, 0.00678165326573089
-0.5510690284511743, 0.006888940366927238
-0.5553062865424514, 0.007010140083763337
-0.5595435446337282, 0.007145924031467276
-0.5637808027250051, 0.0072970533310730374
-0.5680180608162819, 0.007444883946841397
-0.5722553189075588, 0.00762889981961744
-0.5764925769988358, 0.007810650014314211
-0.5807298350901127, 0.008010688997957236
-0.5849670931813895, 0.00825895017125613
-0.5892043512726663, 0.008477860237614848
-0.5934416093639434, 0.00874059962622311
-0.5976788674552203, 0.009019343255136912
-0.6019161255464971, 0.009347644156694304
-0.6061533836377739, 0.009671013739605288
-0.610390641729051, 0.010005569872346288
-0.6146278998203278, 0.010387870149720407
-0.6188651579116047, 0.010784777641270742
-0.6231024160028815, 0.011226180457419445
-0.6273396740941584, 0.011685649148691829
-0.6315769321854354, 0.012163923120982138
-0.6358141902767123, 0.012706014442369767
-0.6400514483679891, 0.013272264334787584
-0.644288706459266, 0.013863749437043804
-0.648525964550543, 0.014481594368893989
-0.6528136661905255, 0.015121321628407862
-0.6570004807330967, 0.015856326831679597
-0.6612377388243735, 0.016620845832404398
-0.6654749969156506, 0.017407040504645938
-0.6697122550069274, 0.018246327771707045
-0.6739495130982043, 0.019126081602654346
-0.6781867711894811, 0.020030778247367067
-0.6824240292807582, 0.020978268603617692
-0.686661287372035, 0.02200892789452429
-0.6908985454633119, 0.023070096962213314
-0.6951358035545887, 0.02414029233175017
-0.6993730616458655, 0.02528216979147447
-0.7036103197371426, 0.02650115949762228
-0.7080997955719479, 0.027723609767752525
-0.7120848359196963, 0.028966342336967852
-0.7163220940109731, 0.030310057774844724
-0.7205593521022502, 0.03171610663255707
-0.724796610193527, 0.033042995151538315
-0.7290338682848039, 0.034515572767012115
-0.7332711263760807, 0.0360223506235193
-0.7375083844673578, 0.0375293969966072
-0.7417456425586346, 0.039031361136900374
-0.7459829006499115, 0.040558052523730015
-0.7502201587411883, 0.042034351277674104
-0.7544574168324651, 0.043640431126969886
-0.7586946749237422, 0.04522892737088183
-0.762931933015019, 0.046671308430118866
-0.7671691911062959, 0.0482017025328616
-0.7714064491975727, 0.04973888740099398
-0.7756437072888498, 0.05123565910768042
-0.7798809653801266, 0.052639583919388076
-0.7841182234714035, 0.053940681296682044
-0.7883554815626803, 0.055225759035222866
-0.7925927396539574, 0.05634457475357417
-0.7968299977452342, 0.05743594934813614
-0.8010672558365111, 0.05839549732811205
-0.8053045139277879, 0.05937107590105852
-0.809541772019065, 0.0599956111749671
-0.8137790301103418, 0.06052107275831785
-0.8180162882016186, 0.06137140055409629
-0.8222535462928955, 0.061639570257157834
-0.8264908043841726, 0.06180103421565734
-0.8307280624754494, 0.06196292112664959
-0.8349653205667262, 0.06196292112664959
-0.8392025786580031, 0.06196292112664959
-0.8434398367492801, 0.06196292112664959
-0.847677094840557, 0.06196292112664959
-0.8519143529318338, 0.06196292112664959
-0.8561516110231107, 0.06196292112664959
-0.8603888691143877, 0.06174716595606462
-0.8646261272056646, 0.061639570257157834
-0.8688633852969414, 0.061639570257157834
-0.8731006433882182, 0.06190891175993376
-0.8773379014794951, 0.06196292112664959
-0.8815751595707721, 0.06217943018274353
-0.885812417662049, 0.06299809851076665
-0.8900496757533258, 0.06332857599211182
-0.8942869338446027, 0.06377191096148331
-0.8985241919358797, 0.0645552282341397
-0.9027614500271566, 0.06540517685232854
-0.9069987081184334, 0.06626631608471431
-0.9112359662097103, 0.06743216428740698
-0.9154732243009873, 0.0684392480799332
-0.9197104823922642, 0.0697648922426948
-0.923947740483541, 0.07111621366661239
-0.9281849985748178, 0.07249370971120286
-0.9324222566660947, 0.07415609924138844
-0.9366595147573717, 0.07579049019474111
-0.9408967728486486, 0.07759611573377836
-0.9451340309399254, 0.07930632421113867
-0.9493712890312023, 0.08126654583051848
-0.9536085471224793, 0.08327521842572275
-0.9578458052137562, 0.085333539563922
-0.962083063305033, 0.08744273641266345
-0.9663203213963099, 0.08968223710555046
-0.9705575794875869, 0.09189892110644575
-0.9747948375788638, 0.0944170730685264
-0.9790320956701406, 0.09649801329655705
-0.9832693537614174, 0.09896942917974716
-0.9875066118526943, 0.10150414062995494
-0.9917438699439713, 0.10410376871340046
-0.9959811280352482, 0.10676997601351931
-0.998805966762766, 0.10789310904088673
+0.14575511460105733, 0.9554554102239319
+0.14852950977986962, 0.8985695436183806
+0.15135434850738755, 0.8416822671042973
+0.15417918723490548, 0.7914962678823056
+0.1570040259624234, 0.7443026502469843
+0.15982886468994134, 0.699008069003934
+0.16265370341745927, 0.6590510006121979
+0.1654785421449772, 0.6205657293819906
+0.16830338087249513, 0.583182451144275
+0.171128219600013, 0.5527306693873699
+0.17395305832753094, 0.5207944680856867
+0.17677789705504887, 0.4919888978755135
+0.1796027357825668, 0.46508065778809576
+0.18242757451008473, 0.43935666423157366
+0.1853701148512492, 0.41373050381123866
+0.18866576003335356, 0.38832709149814626
+0.19172600198816458, 0.3649074998253697
+0.19513934878391542, 0.3414680414967446
+0.1987208407420185, 0.32251486440182225
+0.20096557865942116, 0.304818665995814
+0.20432007464834867, 0.28762010136207583
+0.2078511230577461, 0.2701169632986067
+0.21126446985349695, 0.2537379767684588
+0.21432471180830798, 0.23912938697866504
+0.21773805860405887, 0.22527017447916042
+0.2213195505621619, 0.21284608836894897
+0.22353906670521173, 0.20229822996278335
+0.22703648608213867, 0.19150813658084961
+0.23033213126424296, 0.18058729139453478
+0.23339237321905404, 0.17019024442966496
+0.23668801840115833, 0.16123318060786052
+0.24033676842420226, 0.15128054618566797
+0.24398551844724625, 0.14399516052544795
+0.24543156684347567, 0.13766295796107425
+0.24881128460675606, 0.1305283203273489
+0.25257773624344665, 0.12372336884610519
+0.2546122927079089, 0.11792950918085411
+0.25799201047118936, 0.1116255307168376
+0.26156229275180226, 0.10492400850005858
+0.26576031697186364, 0.09940188798296293
+0.2673240669817396, 0.0943112749094057
+0.27070378474502, 0.08974482271112444
+0.274352534768064, 0.08412674881172508
+0.27788358317746137, 0.08014056203085461
+0.2800610630299232, 0.07574093827164531
+0.28346600256755633, 0.07233133645220131
+0.285710740484959, 0.06852882726332658
+0.2891156800225922, 0.06538888327209208
+0.29136041793999484, 0.061881924732914914
+0.2947149139289224, 0.058681358231883904
+0.29812826072467324, 0.055097486961224455
+0.30133562969654254, 0.05172948760331342
+0.30460184947523516, 0.04873423678666432
+0.308015196270986, 0.04569141557218211
+0.31107543822579703, 0.04286099861859053
+0.3143710834079014, 0.040369864121812975
+0.31731362374906585, 0.037915908869773716
+0.32025616409023033, 0.035751137545065606
+0.32355180927233457, 0.0335754999821346
+0.32649434961349905, 0.03148875446167082
+0.329319188341017, 0.02963058402663415
+0.3321440270685349, 0.027936824934373022
+0.33496886579605284, 0.026253892651534775
+0.33779370452357077, 0.02467234129066144
+0.3406185432510887, 0.023231600368375713
+0.34344338197860663, 0.02184639703977992
+0.34626822070612456, 0.02050351927403326
+0.3490930594336425, 0.019318847325841507
+0.3519178981611604, 0.01820262448660881
+0.35474273688867836, 0.017106086692752192
+0.3575675756161963, 0.016212865681625582
+0.36051011595736077, 0.015219593450529357
+0.3638057611394651, 0.01437674045175807
+0.3674545111625091, 0.013425919585438376
+0.37089728336167155, 0.01268663940246895
+0.3746343095949504, 0.012079360930466401
+0.377576849936115, 0.01149363192907075
+0.3813264870565703, 0.011014237138982565
+0.3858159628913756, 0.01048799233763033
+0.39005322098265244, 0.009979428903361936
+0.3942904790739294, 0.00958704718117178
+0.39852773716520623, 0.009194044761561292
+0.4027649952564832, 0.00886340602199915
+0.40700225334776, 0.008589481647549664
+0.411239511439037, 0.008324022930967073
+0.4154767695303138, 0.008080849285387617
+0.41971402762159077, 0.007851623377088926
+0.4239512857128676, 0.007675610120855667
+0.42818854380414456, 0.007483938562041235
+0.4324258018954214, 0.0073353324516036746
+0.43666305998669835, 0.007189677163901531
+0.4409003180779752, 0.007040771732507048
+0.44513757616925204, 0.006937166750020929
+0.449374834260529, 0.006811286513890746
+0.45361209235180583, 0.006728637927226461
+0.4578493504430828, 0.006629625994857294
+0.4620866085343596, 0.006560613692031756
+0.4663238666256366, 0.006497983688525643
+0.4705611247169134, 0.006419136738404111
+0.47479838280819037, 0.006380072767459883
+0.4790356408994672, 0.006346778628977258
+0.48327289899074416, 0.006308154996851071
+0.487510157082021, 0.006258841214592924
+0.49174741517329795, 0.006231611440228437
+0.4959846732645748, 0.006231611440228437
+0.5002219313558518, 0.006231611440228437
+0.5044591894471286, 0.006231611440228437
+0.5086964475384055, 0.006247935055834002
+0.5129337056296823, 0.006302656556004025
+0.5171709637209592, 0.006341246522223663
+0.5214082218122362, 0.006368955360241889
+0.5256454799035131, 0.006413541561420845
+0.5298827379947899, 0.006458439890605593
+0.5341199960860668, 0.0065491816885621
+0.5383572541773438, 0.00660078308068653
+0.5425945122686207, 0.006693524816277147
+0.5468317703598975, 0.00678165326573089
+0.5510690284511743, 0.006888940366927238
+0.5553062865424514, 0.007010140083763337
+0.5595435446337282, 0.007145924031467276
+0.5637808027250051, 0.0072970533310730374
+0.5680180608162819, 0.007444883946841397
+0.5722553189075588, 0.00762889981961744
+0.5764925769988358, 0.007810650014314211
+0.5807298350901127, 0.008010688997957236
+0.5849670931813895, 0.00825895017125613
+0.5892043512726663, 0.008477860237614848
+0.5934416093639434, 0.00874059962622311
+0.5976788674552203, 0.009019343255136912
+0.6019161255464971, 0.009347644156694304
+0.6061533836377739, 0.009671013739605288
+0.610390641729051, 0.010005569872346288
+0.6146278998203278, 0.010387870149720407
+0.6188651579116047, 0.010784777641270742
+0.6231024160028815, 0.011226180457419445
+0.6273396740941584, 0.011685649148691829
+0.6315769321854354, 0.012163923120982138
+0.6358141902767123, 0.012706014442369767
+0.6400514483679891, 0.013272264334787584
+0.644288706459266, 0.013863749437043804
+0.648525964550543, 0.014481594368893989
+0.6528136661905255, 0.015121321628407862
+0.6570004807330967, 0.015856326831679597
+0.6612377388243735, 0.016620845832404398
+0.6654749969156506, 0.017407040504645938
+0.6697122550069274, 0.018246327771707045
+0.6739495130982043, 0.019126081602654346
+0.6781867711894811, 0.020030778247367067
+0.6824240292807582, 0.020978268603617692
+0.686661287372035, 0.02200892789452429
+0.6908985454633119, 0.023070096962213314
+0.6951358035545887, 0.02414029233175017
+0.6993730616458655, 0.02528216979147447
+0.7036103197371426, 0.02650115949762228
+0.7080997955719479, 0.027723609767752525
+0.7120848359196963, 0.028966342336967852
+0.7163220940109731, 0.030310057774844724
+0.7205593521022502, 0.03171610663255707
+0.724796610193527, 0.033042995151538315
+0.7290338682848039, 0.034515572767012115
+0.7332711263760807, 0.0360223506235193
+0.7375083844673578, 0.0375293969966072
+0.7417456425586346, 0.039031361136900374
+0.7459829006499115, 0.040558052523730015
+0.7502201587411883, 0.042034351277674104
+0.7544574168324651, 0.043640431126969886
+0.7586946749237422, 0.04522892737088183
+0.762931933015019, 0.046671308430118866
+0.7671691911062959, 0.0482017025328616
+0.7714064491975727, 0.04973888740099398
+0.7756437072888498, 0.05123565910768042
+0.7798809653801266, 0.052639583919388076
+0.7841182234714035, 0.053940681296682044
+0.7883554815626803, 0.055225759035222866
+0.7925927396539574, 0.05634457475357417
+0.7968299977452342, 0.05743594934813614
+0.8010672558365111, 0.05839549732811205
+0.8053045139277879, 0.05937107590105852
+0.809541772019065, 0.0599956111749671
+0.8137790301103418, 0.06052107275831785
+0.8180162882016186, 0.06137140055409629
+0.8222535462928955, 0.061639570257157834
+0.8264908043841726, 0.06180103421565734
+0.8307280624754494, 0.06196292112664959
+0.8349653205667262, 0.06196292112664959
+0.8392025786580031, 0.06196292112664959
+0.8434398367492801, 0.06196292112664959
+0.847677094840557, 0.06196292112664959
+0.8519143529318338, 0.06196292112664959
+0.8561516110231107, 0.06196292112664959
+0.8603888691143877, 0.06174716595606462
+0.8646261272056646, 0.061639570257157834
+0.8688633852969414, 0.061639570257157834
+0.8731006433882182, 0.06190891175993376
+0.8773379014794951, 0.06196292112664959
+0.8815751595707721, 0.06217943018274353
+0.885812417662049, 0.06299809851076665
+0.8900496757533258, 0.06332857599211182
+0.8942869338446027, 0.06377191096148331
+0.8985241919358797, 0.0645552282341397
+0.9027614500271566, 0.06540517685232854
+0.9069987081184334, 0.06626631608471431
+0.9112359662097103, 0.06743216428740698
+0.9154732243009873, 0.0684392480799332
+0.9197104823922642, 0.0697648922426948
+0.923947740483541, 0.07111621366661239
+0.9281849985748178, 0.07249370971120286
+0.9324222566660947, 0.07415609924138844
+0.9366595147573717, 0.07579049019474111
+0.9408967728486486, 0.07759611573377836
+0.9451340309399254, 0.07930632421113867
+0.9493712890312023, 0.08126654583051848
+0.9536085471224793, 0.08327521842572275
+0.9578458052137562, 0.085333539563922
+0.962083063305033, 0.08744273641266345
+0.9663203213963099, 0.08968223710555046
+0.9705575794875869, 0.09189892110644575
+0.9747948375788638, 0.0944170730685264
+0.9790320956701406, 0.09649801329655705
+0.9832693537614174, 0.09896942917974716
+0.9875066118526943, 0.10150414062995494
+0.9917438699439713, 0.10410376871340046
+0.9959811280352482, 0.10676997601351931
+0.998805966762766, 0.10789310904088673
```

## developments/gradient_tests_2.py

 * *Ordering differences only*

```diff
@@ -1,46 +1,46 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-from SuPyMode.binary.Example import get_rho_gradient_5p
-from MPSTools.tools.mathematics import gradientO4
-import matplotlib.pyplot as plt
-import numpy
-
-x_vector = numpy.linspace(-10, 10, 100)
-y_vector = numpy.linspace(-10, 10, 100)
-dx = x_vector[1] - x_vector[0]
-dy = y_vector[1] - y_vector[0]
-
-x_mesh, y_mesh = numpy.meshgrid(x_vector, y_vector)
-
-rho_mesh = numpy.sqrt(numpy.square(x_mesh) + numpy.square(y_mesh))**2
-
-
-y_gradient, x_gradient = gradientO4(rho_mesh, dx, dy)
-
-theta_mesh = numpy.arctan2(y_mesh, x_mesh)
-
-gradient = (x_gradient * numpy.cos(theta_mesh) + y_gradient * numpy.sin(theta_mesh))
-
-plt.figure()
-plt.pcolormesh(gradient)
-plt.colorbar()
-plt.show()
-
-rho_gradient = get_rho_gradient_5p(
-    mesh=rho_mesh,
-    x_vector=x_vector,
-    y_vector=y_vector
-)
-
-plt.figure()
-plt.pcolormesh(rho_gradient)
-plt.colorbar()
-plt.show()
-
-condition = numpy.isclose(rho_gradient, 1, atol=0.5)
-
-assert numpy.all(condition), f"Error in constant (expected value: 1.0) gradient computation. Mean gradient value: {condition.mean()}"
-
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+from SuPyMode.binary.Example import get_rho_gradient_5p
+from MPSTools.tools.mathematics import gradientO4
+import matplotlib.pyplot as plt
+import numpy
+
+x_vector = numpy.linspace(-10, 10, 100)
+y_vector = numpy.linspace(-10, 10, 100)
+dx = x_vector[1] - x_vector[0]
+dy = y_vector[1] - y_vector[0]
+
+x_mesh, y_mesh = numpy.meshgrid(x_vector, y_vector)
+
+rho_mesh = numpy.sqrt(numpy.square(x_mesh) + numpy.square(y_mesh))**2
+
+
+y_gradient, x_gradient = gradientO4(rho_mesh, dx, dy)
+
+theta_mesh = numpy.arctan2(y_mesh, x_mesh)
+
+gradient = (x_gradient * numpy.cos(theta_mesh) + y_gradient * numpy.sin(theta_mesh))
+
+plt.figure()
+plt.pcolormesh(gradient)
+plt.colorbar()
+plt.show()
+
+rho_gradient = get_rho_gradient_5p(
+    mesh=rho_mesh,
+    x_vector=x_vector,
+    y_vector=y_vector
+)
+
+plt.figure()
+plt.pcolormesh(rho_gradient)
+plt.colorbar()
+plt.show()
+
+condition = numpy.isclose(rho_gradient, 1, atol=0.5)
+
+assert numpy.all(condition), f"Error in constant (expected value: 1.0) gradient computation. Mean gradient value: {condition.mean()}"
+
+
+# -
```

## developments/validation.py

 * *Ordering differences only*

```diff
@@ -1,125 +1,125 @@
-"""
-Propagation constant: DCFC
-==========================
-"""
-
-# %%
-# Imports
-# ~~~~~~~
-import numpy
-from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
-from PyFiberModes.__future__ import get_normalized_LP_coupling
-from PyFiberModes.fiber import load_fiber
-from MPSPlots.render2D import SceneList
-import PyFiberModes
-
-wavelength = 1550e-9
-fiber_name = 'SMF28'
-scale_factor = 4
-
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-fiber = fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength, remove_cladding=False)
-fiber.structure_list[-1].scale(scale_factor)
-fiber_list = [fiber]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(left='symmetric', top='symmetric'),
-]
-
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=150,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="right",                # Mesh x-boundary structure.
-    y_bounds="bottom",                 # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=3,                # Total computed and sorted mode.
-    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    # plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=2,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.3,                  # Final value of inverse taper ratio to simulate
-    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-    n_step=100
-)
-
-superset = workflow.get_superset()
-superset.label_supermodes('LP01', 'LP02', 'LP21')
-# superset.label_supermodes('LP01', 'LP02', 'LP21', 'LP03', 'LP22', 'LP41')
-
-superset.plot(plot_type='field').show()
-
-itr_list = superset.itr_list[::8]
-
-# %%
-# Computing the analytical values using FiberModes solver.
-pyfibermodes_fiber = load_fiber(
-    fiber_name=fiber_name,
-    wavelength=wavelength,
-    add_air_layer=False
-)
-
-pyfibermodes_fiber = pyfibermodes_fiber.scale(scale_factor)
-
-analytical = numpy.empty(itr_list.shape)
-for idx, itr in enumerate(itr_list):
-    print(idx, itr)
-    _fiber = pyfibermodes_fiber.scale(factor=itr)
-    analytical[idx] = get_normalized_LP_coupling(
-        fiber=_fiber,
-        mode_0=PyFiberModes.LP01,
-        mode_1=PyFiberModes.LP02
-    )
-
-
-# %%
-# Preparing the figure
-figure = SceneList(unit_size=(12, 4))
-
-ax = figure.append_ax(
-    x_label='Inverse taper ratio',
-    y_label='Effective index',
-    show_legend=True,
-    font_size=18,
-    tick_size=15,
-    legend_font_size=18
-)
-
-ax.add_line(
-    x=itr_list,
-    y=abs(analytical),
-    label='Analytical',
-    line_style='-',
-    line_width=2,
-    color='red',
-    layer_position=1
-)
-
-simulation = superset.LP01.normalized_coupling.get_values(superset.LP02).imag
-
-ax.add_scatter(
-    x=superset.itr_list,
-    y=abs(simulation),
-    label="SuPyMode",
-    color='black',
-    line_width=2,
-    edge_color='blue',
-    marker_size=80,
-    line_style='-',
-    layer_position=2
-)
-
-_ = figure.show()
+"""
+Propagation constant: DCFC
+==========================
+"""
+
+# %%
+# Imports
+# ~~~~~~~
+import numpy
+from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
+from PyFiberModes.__future__ import get_normalized_LP_coupling
+from PyFiberModes.fiber import load_fiber
+from MPSPlots.render2D import SceneList
+import PyFiberModes
+
+wavelength = 1550e-9
+fiber_name = 'SMF28'
+scale_factor = 4
+
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+fiber = fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength, remove_cladding=False)
+fiber.structure_list[-1].scale(scale_factor)
+fiber_list = [fiber]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(left='symmetric', top='symmetric'),
+]
+
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=150,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="right",                # Mesh x-boundary structure.
+    y_bounds="bottom",                 # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=3,                # Total computed and sorted mode.
+    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    # plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=2,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.3,                  # Final value of inverse taper ratio to simulate
+    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+    n_step=100
+)
+
+superset = workflow.get_superset()
+superset.label_supermodes('LP01', 'LP02', 'LP21')
+# superset.label_supermodes('LP01', 'LP02', 'LP21', 'LP03', 'LP22', 'LP41')
+
+superset.plot(plot_type='field').show()
+
+itr_list = superset.itr_list[::8]
+
+# %%
+# Computing the analytical values using FiberModes solver.
+pyfibermodes_fiber = load_fiber(
+    fiber_name=fiber_name,
+    wavelength=wavelength,
+    add_air_layer=False
+)
+
+pyfibermodes_fiber = pyfibermodes_fiber.scale(scale_factor)
+
+analytical = numpy.empty(itr_list.shape)
+for idx, itr in enumerate(itr_list):
+    print(idx, itr)
+    _fiber = pyfibermodes_fiber.scale(factor=itr)
+    analytical[idx] = get_normalized_LP_coupling(
+        fiber=_fiber,
+        mode_0=PyFiberModes.LP01,
+        mode_1=PyFiberModes.LP02
+    )
+
+
+# %%
+# Preparing the figure
+figure = SceneList(unit_size=(12, 4))
+
+ax = figure.append_ax(
+    x_label='Inverse taper ratio',
+    y_label='Effective index',
+    show_legend=True,
+    font_size=18,
+    tick_size=15,
+    legend_font_size=18
+)
+
+ax.add_line(
+    x=itr_list,
+    y=abs(analytical),
+    label='Analytical',
+    line_style='-',
+    line_width=2,
+    color='red',
+    layer_position=1
+)
+
+simulation = superset.LP01.normalized_coupling.get_values(superset.LP02).imag
+
+ax.add_scatter(
+    x=superset.itr_list,
+    y=abs(simulation),
+    label="SuPyMode",
+    color='black',
+    line_width=2,
+    edge_color='blue',
+    marker_size=80,
+    line_style='-',
+    layer_position=2
+)
+
+_ = figure.show()
```

## developments/validation_2.py

 * *Ordering differences only*

```diff
@@ -1,125 +1,125 @@
-"""
-Propagation constant: DCFC
-==========================
-"""
-
-# %%
-# Imports
-# ~~~~~~~
-import numpy
-from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
-from PyFiberModes.__future__ import get_normalized_LP_coupling
-from PyFiberModes.fiber import load_fiber
-from MPSPlots.render2D import SceneList
-import PyFiberModes
-
-wavelength = 1550e-9
-fiber_name = 'SMF28'
-scale_factor = 8
-
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-fiber = fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength, remove_cladding=False)
-fiber.structure_list[-1].scale(scale_factor)
-fiber_list = [fiber]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(left='symmetric', top='symmetric'),
-]
-
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=150,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="right",                # Mesh x-boundary structure.
-    y_bounds="bottom",                 # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=6,                # Total computed and sorted mode.
-    n_added_mode=10,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=2,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.3,                  # Final value of inverse taper ratio to simulate
-    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-    n_step=400
-)
-
-superset = workflow.get_superset()
-# superset.label_supermodes('LP01', 'LP02', 'LP22', 'LP04')
-superset.label_supermodes('LP01', 'LP21', 'LP02', 'LP41', 'LP03', 'LP22')
-
-superset.plot(plot_type='field').show()
-
-itr_list = superset.itr_list[::8]
-
-# %%
-# Computing the analytical values using FiberModes solver.
-pyfibermodes_fiber = load_fiber(
-    fiber_name=fiber_name,
-    wavelength=wavelength,
-    add_air_layer=False
-)
-
-pyfibermodes_fiber = pyfibermodes_fiber.scale(scale_factor)
-
-analytical = numpy.empty(itr_list.shape)
-for idx, itr in enumerate(itr_list):
-    print(idx, itr)
-    _fiber = pyfibermodes_fiber.scale(factor=itr)
-    analytical[idx] = get_normalized_LP_coupling(
-        fiber=_fiber,
-        mode_0=PyFiberModes.LP01,
-        mode_1=PyFiberModes.LP03
-    )
-
-
-# %%
-# Preparing the figure
-figure = SceneList(unit_size=(12, 4))
-
-ax = figure.append_ax(
-    x_label='Inverse taper ratio',
-    y_label='Effective index',
-    show_legend=True,
-    font_size=18,
-    tick_size=15,
-    legend_font_size=18
-)
-
-ax.add_line(
-    x=itr_list,
-    y=abs(analytical),
-    label='Analytical',
-    line_style='-',
-    line_width=2,
-    color='red',
-    layer_position=1
-)
-
-simulation = superset.LP01.normalized_coupling.get_values(superset.LP03).imag
-
-ax.add_scatter(
-    x=superset.itr_list,
-    y=abs(simulation),
-    label="SuPyMode",
-    color='black',
-    line_width=2,
-    edge_color='blue',
-    marker_size=80,
-    line_style='-',
-    layer_position=2
-)
-
-_ = figure.show()
+"""
+Propagation constant: DCFC
+==========================
+"""
+
+# %%
+# Imports
+# ~~~~~~~
+import numpy
+from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
+from PyFiberModes.__future__ import get_normalized_LP_coupling
+from PyFiberModes.fiber import load_fiber
+from MPSPlots.render2D import SceneList
+import PyFiberModes
+
+wavelength = 1550e-9
+fiber_name = 'SMF28'
+scale_factor = 8
+
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+fiber = fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength, remove_cladding=False)
+fiber.structure_list[-1].scale(scale_factor)
+fiber_list = [fiber]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(left='symmetric', top='symmetric'),
+]
+
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=150,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="right",                # Mesh x-boundary structure.
+    y_bounds="bottom",                 # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=6,                # Total computed and sorted mode.
+    n_added_mode=10,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=2,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.3,                  # Final value of inverse taper ratio to simulate
+    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+    n_step=400
+)
+
+superset = workflow.get_superset()
+# superset.label_supermodes('LP01', 'LP02', 'LP22', 'LP04')
+superset.label_supermodes('LP01', 'LP21', 'LP02', 'LP41', 'LP03', 'LP22')
+
+superset.plot(plot_type='field').show()
+
+itr_list = superset.itr_list[::8]
+
+# %%
+# Computing the analytical values using FiberModes solver.
+pyfibermodes_fiber = load_fiber(
+    fiber_name=fiber_name,
+    wavelength=wavelength,
+    add_air_layer=False
+)
+
+pyfibermodes_fiber = pyfibermodes_fiber.scale(scale_factor)
+
+analytical = numpy.empty(itr_list.shape)
+for idx, itr in enumerate(itr_list):
+    print(idx, itr)
+    _fiber = pyfibermodes_fiber.scale(factor=itr)
+    analytical[idx] = get_normalized_LP_coupling(
+        fiber=_fiber,
+        mode_0=PyFiberModes.LP01,
+        mode_1=PyFiberModes.LP03
+    )
+
+
+# %%
+# Preparing the figure
+figure = SceneList(unit_size=(12, 4))
+
+ax = figure.append_ax(
+    x_label='Inverse taper ratio',
+    y_label='Effective index',
+    show_legend=True,
+    font_size=18,
+    tick_size=15,
+    legend_font_size=18
+)
+
+ax.add_line(
+    x=itr_list,
+    y=abs(analytical),
+    label='Analytical',
+    line_style='-',
+    line_width=2,
+    color='red',
+    layer_position=1
+)
+
+simulation = superset.LP01.normalized_coupling.get_values(superset.LP03).imag
+
+ax.add_scatter(
+    x=superset.itr_list,
+    y=abs(simulation),
+    label="SuPyMode",
+    color='black',
+    line_width=2,
+    edge_color='blue',
+    marker_size=80,
+    line_style='-',
+    layer_position=2
+)
+
+_ = figure.show()
```

## docs/examples/basic/plot_alpha_profile_0.py

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-"""
-Non-symmetric coupler z-profile
-===============================
-"""
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import AlphaProfile
-
-
-profile = AlphaProfile(symmetric=False, add_end_of_taper_section=True)
-
-# %%
-# Adding a first taper segment with large initial heating length (i.e. slow reduction)
-profile.add_taper_segment(
-    alpha=0,
-    initial_heating_length=8e-3,
-    stretching_length=0.2e-3 * 20
-)
-
-# %%
-# Adding a first taper segment with small initial heating length (i.e. steep reduction)
-profile.add_taper_segment(
-    alpha=0,
-    initial_heating_length=2e-3,
-    stretching_length=0.2e-3 * 20
-)
-
-profile.initialize()
-
-profile.plot().show()
-
-# -
+"""
+Non-symmetric coupler z-profile
+===============================
+"""
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import AlphaProfile
+
+
+profile = AlphaProfile(symmetric=False, add_end_of_taper_section=True)
+
+# %%
+# Adding a first taper segment with large initial heating length (i.e. slow reduction)
+profile.add_taper_segment(
+    alpha=0,
+    initial_heating_length=8e-3,
+    stretching_length=0.2e-3 * 20
+)
+
+# %%
+# Adding a first taper segment with small initial heating length (i.e. steep reduction)
+profile.add_taper_segment(
+    alpha=0,
+    initial_heating_length=2e-3,
+    stretching_length=0.2e-3 * 20
+)
+
+profile.initialize()
+
+profile.plot().show()
+
+# -
```

## docs/examples/basic/plot_alpha_profile_1.py

 * *Ordering differences only*

```diff
@@ -1,35 +1,35 @@
-"""
-Symmetric coupler z-profile
-===========================
-"""
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import AlphaProfile
-
-
-profile = AlphaProfile(symmetric=True, add_end_of_taper_section=True)
-
-# %%
-# Adding a first taper segment with large initial heating length (i.e. slow reduction)
-profile.add_taper_segment(
-    alpha=0,
-    initial_heating_length=8e-3,
-    stretching_length=0.2e-3 * 20
-)
-
-# %%
-# Adding a first taper segment with small initial heating length (i.e. steep reduction)
-profile.add_taper_segment(
-    alpha=0,
-    initial_heating_length=2e-3,
-    stretching_length=0.2e-3 * 20
-)
-
-profile.initialize()
-
-print(profile.adiabatic)
-
-profile.plot(show_adiabatic=False).show()
-
-# -
+"""
+Symmetric coupler z-profile
+===========================
+"""
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import AlphaProfile
+
+
+profile = AlphaProfile(symmetric=True, add_end_of_taper_section=True)
+
+# %%
+# Adding a first taper segment with large initial heating length (i.e. slow reduction)
+profile.add_taper_segment(
+    alpha=0,
+    initial_heating_length=8e-3,
+    stretching_length=0.2e-3 * 20
+)
+
+# %%
+# Adding a first taper segment with small initial heating length (i.e. steep reduction)
+profile.add_taper_segment(
+    alpha=0,
+    initial_heating_length=2e-3,
+    stretching_length=0.2e-3 * 20
+)
+
+profile.initialize()
+
+print(profile.adiabatic)
+
+profile.plot(show_adiabatic=False).show()
+
+# -
```

## docs/examples/basic/plot_workflow_01.py

 * *Ordering differences only*

```diff
@@ -1,76 +1,76 @@
-"""
-1x1 Coupler
-===========
-"""
-
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-
-wavelength = 1550e-9
-
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-clad_structure = configuration.ring.FusedProfile_01x01
-
-fiber_list = [
-    fiber_catalogue.load_fiber('SMF28', wavelength=wavelength)
-]
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(right='symmetric', top='symmetric'),
-    Boundaries(right='symmetric', top='anti-symmetric')
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=80,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="left",                # Mesh x-boundary structure.
-    y_bounds="bottom",              # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=4,                # Total computed and sorted mode.
-    n_added_mode=2,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.05,                 # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=0              # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-# -
+"""
+1x1 Coupler
+===========
+"""
+
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+
+wavelength = 1550e-9
+
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+clad_structure = configuration.ring.FusedProfile_01x01
+
+fiber_list = [
+    fiber_catalogue.load_fiber('SMF28', wavelength=wavelength)
+]
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(right='symmetric', top='symmetric'),
+    Boundaries(right='symmetric', top='anti-symmetric')
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=80,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="left",                # Mesh x-boundary structure.
+    y_bounds="bottom",              # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=4,                # Total computed and sorted mode.
+    n_added_mode=2,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.05,                 # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=0              # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+# -
```

## docs/examples/basic/plot_workflow_02.py

 * *Ordering differences only*

```diff
@@ -1,77 +1,77 @@
-"""
-2x2 Coupler
-===========
-"""
-
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-
-wavelength = 1550e-9
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-clad_structure = configuration.ring.FusedProfile_02x02
-
-fiber_list = [
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-]
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(right='symmetric', top='symmetric'),
-    Boundaries(right='symmetric', top='anti-symmetric')
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
-    fusion_degree=0.9,              # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=50,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="left",                # Mesh x-boundary structure.
-    y_bounds="bottom",              # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=4,                # Total computed and sorted mode.
-    n_added_mode=2,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-
-# -
+"""
+2x2 Coupler
+===========
+"""
+
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+
+wavelength = 1550e-9
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+clad_structure = configuration.ring.FusedProfile_02x02
+
+fiber_list = [
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+]
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(right='symmetric', top='symmetric'),
+    Boundaries(right='symmetric', top='anti-symmetric')
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
+    fusion_degree=0.9,              # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=50,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="left",                # Mesh x-boundary structure.
+    y_bounds="bottom",              # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=4,                # Total computed and sorted mode.
+    n_added_mode=2,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+
+# -
```

## docs/examples/basic/plot_workflow_03.py

 * *Ordering differences only*

```diff
@@ -1,94 +1,94 @@
-"""
-3x3 Coupler
-===========
-"""
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-
-# %%
-# Creating the fiber list for mesh
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# In this example we want to simulate a single fiber at wavelength 1550 nm.
-wavelength = 1550e-9
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-clad_structure = configuration.ring.FusedProfile_03x03
-
-custom_fiber = fiber_catalogue.CustomFiber(wavelength=1.55e-6)
-custom_fiber.add_silica_pure_cladding(radius=62.5e-6, name='outer-clad')
-
-custom_fiber.create_and_add_new_structure(
-    radius=40e-6 / 2,
-    NA=0.13,
-    name='inner-clad'
-)
-custom_fiber.create_and_add_new_structure(
-    radius=9.2e-6 / 2,
-    NA=0.13,
-    name='core'
-)
-
-fiber_list = [
-    fiber_catalogue.load_fiber('DCF1300S_42', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    custom_fiber
-]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(),
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
-    fusion_degree=0.8,           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=40,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="centering",           # Mesh x-boundary structure.
-    y_bounds="centering",           # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=2,                # Total computed and sorted mode.
-    n_added_mode=5,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=3,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.05,                  # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=1e-7           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', slice_list=[], itr_list=[1.0, 0.3, 0.1]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-# -
+"""
+3x3 Coupler
+===========
+"""
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+
+# %%
+# Creating the fiber list for mesh
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# In this example we want to simulate a single fiber at wavelength 1550 nm.
+wavelength = 1550e-9
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+clad_structure = configuration.ring.FusedProfile_03x03
+
+custom_fiber = fiber_catalogue.CustomFiber(wavelength=1.55e-6)
+custom_fiber.add_silica_pure_cladding(radius=62.5e-6, name='outer-clad')
+
+custom_fiber.create_and_add_new_structure(
+    radius=40e-6 / 2,
+    NA=0.13,
+    name='inner-clad'
+)
+custom_fiber.create_and_add_new_structure(
+    radius=9.2e-6 / 2,
+    NA=0.13,
+    name='core'
+)
+
+fiber_list = [
+    fiber_catalogue.load_fiber('DCF1300S_42', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    custom_fiber
+]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(),
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
+    fusion_degree=0.8,           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=40,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="centering",           # Mesh x-boundary structure.
+    y_bounds="centering",           # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=2,                # Total computed and sorted mode.
+    n_added_mode=5,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=3,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.05,                  # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=1e-7           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', slice_list=[], itr_list=[1.0, 0.3, 0.1]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+# -
```

## docs/examples/basic/plot_workflow_04.py

 * *Ordering differences only*

```diff
@@ -1,77 +1,77 @@
-"""
-4x4 Coupler
-===========
-"""
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-
-wavelength = 1550e-9
-
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-clad_structure = configuration.ring.FusedProfile_04x04
-
-fiber_list = [
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-]
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries()
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=60,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="centering",           # Mesh x-boundary structure.
-    y_bounds="centering",           # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=6,                # Total computed and sorted mode.
-    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.05,                 # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', itr_list=[1.0, 0.05]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-# -
+"""
+4x4 Coupler
+===========
+"""
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+
+wavelength = 1550e-9
+
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+clad_structure = configuration.ring.FusedProfile_04x04
+
+fiber_list = [
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+]
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries()
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=60,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="centering",           # Mesh x-boundary structure.
+    y_bounds="centering",           # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=6,                # Total computed and sorted mode.
+    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.05,                 # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', itr_list=[1.0, 0.05]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+# -
```

## docs/examples/basic/plot_workflow_05.py

 * *Ordering differences only*

```diff
@@ -1,86 +1,86 @@
-"""
-5x5 Coupler
-===========
-"""
-
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-
-# %%
-# Creating the fiber list for mesh
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# In this example we want to simulate a single fiber at wavelength 1550 nm.
-wavelength = 1550e-9
-
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-clad_structure = configuration.ring.FusedProfile_07x07
-
-fiber_list = [
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries()
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
-    fusion_degree=0.3,              # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=60,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="centering",           # Mesh x-boundary structure.
-    y_bounds="centering",           # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=6,                # Total computed and sorted mode.
-    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=False,               # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-# -
+"""
+5x5 Coupler
+===========
+"""
+
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+
+# %%
+# Creating the fiber list for mesh
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# In this example we want to simulate a single fiber at wavelength 1550 nm.
+wavelength = 1550e-9
+
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+clad_structure = configuration.ring.FusedProfile_07x07
+
+fiber_list = [
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries()
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
+    fusion_degree=0.3,              # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=60,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="centering",           # Mesh x-boundary structure.
+    y_bounds="centering",           # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=6,                # Total computed and sorted mode.
+    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=False,               # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+# -
```

## docs/examples/basic/plot_workflow_06.py

 * *Ordering differences only*

```diff
@@ -1,91 +1,91 @@
-"""
-19x19 Coupler
-=============
-"""
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-import numpy
-
-# %%
-# Creating the fiber list for mesh
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# In this example we want to simulate a single fiber at wavelength 1550 nm.
-wavelength = 1550e-9
-
-fiber_list = []
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-clad_structure = configuration.ring.FusedProfile_19x19
-
-for radius in numpy.linspace(10e-6, 50e-6, 19):
-    fiber = fiber_catalogue.GenericFiber(wavelength=wavelength)
-    fiber.add_silica_pure_cladding()
-    fiber.create_and_add_new_structure(name='core', radius=radius / 2, NA=0.115)
-
-    fiber_list.append(fiber)
-
-capillary_tube = fiber_catalogue.CapillaryTube(
-    radius=350e-6,
-    wavelength=wavelength,
-    delta_n=-15e-3
-)
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(right='symmetric', bottom='symmetric'),
-    Boundaries(right='symmetric', bottom='anti-symmetric')
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    capillary_tube=capillary_tube,  # Adding additional capillariy tube structure
-    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=60,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="left",                # Mesh x-boundary structure.
-    y_bounds="top",                 # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=3,                # Total computed and sorted mode.
-    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-# -
+"""
+19x19 Coupler
+=============
+"""
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+import numpy
+
+# %%
+# Creating the fiber list for mesh
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# In this example we want to simulate a single fiber at wavelength 1550 nm.
+wavelength = 1550e-9
+
+fiber_list = []
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+clad_structure = configuration.ring.FusedProfile_19x19
+
+for radius in numpy.linspace(10e-6, 50e-6, 19):
+    fiber = fiber_catalogue.GenericFiber(wavelength=wavelength)
+    fiber.add_silica_pure_cladding()
+    fiber.create_and_add_new_structure(name='core', radius=radius / 2, NA=0.115)
+
+    fiber_list.append(fiber)
+
+capillary_tube = fiber_catalogue.CapillaryTube(
+    radius=350e-6,
+    wavelength=wavelength,
+    delta_n=-15e-3
+)
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(right='symmetric', bottom='symmetric'),
+    Boundaries(right='symmetric', bottom='anti-symmetric')
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    capillary_tube=capillary_tube,  # Adding additional capillariy tube structure
+    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=60,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="left",                # Mesh x-boundary structure.
+    y_bounds="top",                 # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=3,                # Total computed and sorted mode.
+    n_added_mode=3,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+# -
```

## docs/examples/basic/plot_workflow_07.py

 * *Ordering differences only*

```diff
@@ -1,79 +1,79 @@
-"""
-4x4 Coupler [linear]
-====================
-"""
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-
-wavelength = 1550e-9
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-clad_structure = configuration.line.FusedProfile_04x04
-
-fiber_list = [
-    fiber_catalogue.load_fiber('DCF1300S_42', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_26', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_20', wavelength=wavelength)
-]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(bottom='symmetric'),
-    Boundaries(bottom='anti-symmetric')
-]
-
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=80,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="centering",           # Mesh x-boundary structure.
-    y_bounds="top",                 # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=3,                # Total computed and sorted mode.
-    n_added_mode=5,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-# -
+"""
+4x4 Coupler [linear]
+====================
+"""
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+
+wavelength = 1550e-9
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+clad_structure = configuration.line.FusedProfile_04x04
+
+fiber_list = [
+    fiber_catalogue.load_fiber('DCF1300S_42', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_26', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_20', wavelength=wavelength)
+]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(bottom='symmetric'),
+    Boundaries(bottom='anti-symmetric')
+]
+
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    clad_structure=clad_structure,  # Cladding structure, if None provided then no cladding is set.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=80,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="centering",           # Mesh x-boundary structure.
+    y_bounds="top",                 # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=3,                # Total computed and sorted mode.
+    n_added_mode=5,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=1e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+# -
```

## docs/examples/basic/plot_workflow_08.py

 * *Ordering differences only*

```diff
@@ -1,76 +1,76 @@
-"""
-4x4 Coupler [linear]
-====================
-"""
-
-# %%
-# Importing the script dependencies
-from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
-
-wavelength = 1550e-9
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-fiber_list = [
-    fiber_catalogue.load_fiber('DCF1300S_20', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_26', wavelength=wavelength),
-    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength)
-]
-
-clad_profile = configuration.ring.FusedProfile_03x03
-
-capillary_tube = fiber_catalogue.CapillaryTube(
-    radius=150e-6,
-    wavelength=wavelength,
-    delta_n=-15e-3
-)
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    clad_structure=clad_profile,    # Cladding structure, if None provided then no cladding is set.
-    capillary_tube=capillary_tube,
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=80,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="centering",           # Mesh x-boundary structure.
-    y_bounds="centering",           # Mesh y-boundary structure.
-    boundaries=[Boundaries()],    # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=6,                # Total computed and sorted mode.
-    n_added_mode=6,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps. [Does not work properly on jupyter notebooks]
-    auto_label=False,               # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
-    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
-    index_scrambling=0e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-)
-
-superset = workflow.get_superset()
-
-# %%
-# Field computation: :math:`E_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
-
-# %%
-# Effective index: :math:`n^{eff}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='index').show()
-
-# %%
-# Modal normalized coupling: :math:`C_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='normalized-coupling').show()
-
-# %%
-# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-_ = superset.plot(plot_type='adiabatic').show()
-
-# -
+"""
+4x4 Coupler [linear]
+====================
+"""
+
+# %%
+# Importing the script dependencies
+from SuPyMode.workflow import Workflow, configuration, fiber_catalogue, Boundaries
+
+wavelength = 1550e-9
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+fiber_list = [
+    fiber_catalogue.load_fiber('DCF1300S_20', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_26', wavelength=wavelength),
+    fiber_catalogue.load_fiber('DCF1300S_33', wavelength=wavelength)
+]
+
+clad_profile = configuration.ring.FusedProfile_03x03
+
+capillary_tube = fiber_catalogue.CapillaryTube(
+    radius=150e-6,
+    wavelength=wavelength,
+    delta_n=-15e-3
+)
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    clad_structure=clad_profile,    # Cladding structure, if None provided then no cladding is set.
+    capillary_tube=capillary_tube,
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=80,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="centering",           # Mesh x-boundary structure.
+    y_bounds="centering",           # Mesh y-boundary structure.
+    boundaries=[Boundaries()],    # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=6,                # Total computed and sorted mode.
+    n_added_mode=6,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps. [Does not work properly on jupyter notebooks]
+    auto_label=False,               # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.1,                  # Final value of inverse taper ratio to simulate
+    clad_rotation=0,                # Rotate the geoemtry in the given angle in degree
+    index_scrambling=0e-4           # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+)
+
+superset = workflow.get_superset()
+
+# %%
+# Field computation: :math:`E_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='field', itr_list=[1.0, 0.1]).show()
+
+# %%
+# Effective index: :math:`n^{eff}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='index').show()
+
+# %%
+# Modal normalized coupling: :math:`C_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='normalized-coupling').show()
+
+# %%
+# Adiabatic criterion: :math:`\tilde{C}_{i,j}`
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+_ = superset.plot(plot_type='adiabatic').show()
+
+# -
```

## docs/examples/validation/plot_beta_DCF.py

```diff
@@ -1,113 +1,113 @@
-"""
-Propagation constant: DCFC
-==========================
-"""
-
-# %%
-# Imports
-# ~~~~~~~
-import numpy
-from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
-from PyFiberModes import LP01
-from PyFiberModes.fiber import load_fiber
-from MPSPlots.render2D import SceneList
-
-wavelength = 1550e-9
-fiber_name = 'DCF1300S_33'
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-fiber_list = [
-    fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength)
-]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(right='symmetric', bottom='symmetric'),
-    Boundaries(right='symmetric', bottom='anti-symmetric')
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=50,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="left",                # Mesh x-boundary structure.
-    y_bounds="top",                 # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=6,                # Total computed and sorted mode.
-    n_added_mode=4,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.2,                  # Final value of inverse taper ratio to simulate
-    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-    n_step=50
-)
-
-superset = workflow.get_superset()
-itr_list = superset.itr_list
-
-# %%
-# Computing the analytical values using FiberModes solver.
-dcf_fiber = load_fiber(
-    fiber_name=fiber_name,
-    wavelength=wavelength,
-    add_air_layer=True
-)
-
-# %%
-# Preparing the figure
-figure = SceneList(unit_size=(12, 4))
-
-ax = figure.append_ax(
-    x_label='Inverse taper ratio',
-    y_label='Effective index',
-    show_legend=True,
-    font_size=18,
-    tick_size=15,
-    legend_font_size=18
-)
-
-pyfibermodes_mode = LP01
-supymode_mode = superset.LP01
-
-analytical = numpy.empty(itr_list.shape)
-for idx, itr in enumerate(itr_list):
-    _fiber = dcf_fiber.scale(factor=itr)
-    analytical[idx] = _fiber.get_effective_index(mode=pyfibermodes_mode)
-
-ax.add_line(
-    x=itr_list,
-    y=analytical,
-    label=pyfibermodes_mode,
-    line_style='-',
-    line_width=2,
-    color='red',
-    layer_position=1
-)
-
-ax.add_scatter(
-    x=itr_list,
-    y=supymode_mode.index.data,
-    label=supymode_mode,
-    color='black',
-    line_width=2,
-    edge_color='blue',
-    marker_size=80,
-    line_style='-',
-    layer_position=2
-)
-
-_ = figure.show()
-
-
-# -
+"""
+Propagation constant: DCFC
+==========================
+"""
+
+# %%
+# Imports
+# ~~~~~~~
+import numpy
+from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
+from PyFiberModes import LP01
+from PyFiberModes.fiber import load_fiber
+from MPSPlots.render2D import SceneList
+
+wavelength = 1550e-9
+fiber_name = 'DCF1300S_33'
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+fiber_list = [
+    fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength)
+]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(right='symmetric', bottom='symmetric'),
+    Boundaries(right='symmetric', bottom='anti-symmetric')
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=50,                  # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="left",                # Mesh x-boundary structure.
+    y_bounds="top",                 # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=6,                # Total computed and sorted mode.
+    n_added_mode=4,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.2,                  # Final value of inverse taper ratio to simulate
+    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+    n_step=50
+)
+
+superset = workflow.get_superset()
+itr_list = superset.model_parameters.itr_list
+
+# %%
+# Computing the analytical values using FiberModes solver.
+dcf_fiber = load_fiber(
+    fiber_name=fiber_name,
+    wavelength=wavelength,
+    add_air_layer=True
+)
+
+# %%
+# Preparing the figure
+figure = SceneList(unit_size=(12, 4))
+
+ax = figure.append_ax(
+    x_label='Inverse taper ratio',
+    y_label='Effective index',
+    show_legend=True,
+    font_size=18,
+    tick_size=15,
+    legend_font_size=18
+)
+
+pyfibermodes_mode = LP01
+supymode_mode = superset.LP01
+
+analytical = numpy.empty(itr_list.shape)
+for idx, itr in enumerate(itr_list):
+    _fiber = dcf_fiber.scale(factor=itr)
+    analytical[idx] = _fiber.get_effective_index(mode=pyfibermodes_mode)
+
+ax.add_line(
+    x=itr_list,
+    y=analytical,
+    label=pyfibermodes_mode,
+    line_style='-',
+    line_width=2,
+    color='red',
+    layer_position=1
+)
+
+ax.add_scatter(
+    x=itr_list,
+    y=supymode_mode.index.data,
+    label=supymode_mode,
+    color='black',
+    line_width=2,
+    edge_color='blue',
+    marker_size=80,
+    line_style='-',
+    layer_position=2
+)
+
+_ = figure.show()
+
+
+# -
```

## docs/examples/validation/plot_beta_SMF28.py

```diff
@@ -1,113 +1,113 @@
-"""
-Propagation constant: DCFC
-==========================
-"""
-
-# %%
-# Imports
-# ~~~~~~~
-import numpy
-from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
-from PyFiberModes import LP01
-from PyFiberModes.fiber import load_fiber
-from MPSPlots.render2D import SceneList
-
-wavelength = 1550e-9
-fiber_name = 'SMF28'
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-fiber_list = [
-    fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength)
-]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(right='symmetric', bottom='symmetric'),
-    Boundaries(right='symmetric', bottom='anti-symmetric')
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=50,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="left",                # Mesh x-boundary structure.
-    y_bounds="top",                 # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=6,                # Total computed and sorted mode.
-    n_added_mode=4,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.2,                  # Final value of inverse taper ratio to simulate
-    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-    n_step=50
-)
-
-superset = workflow.get_superset()
-itr_list = superset.itr_list
-
-# %%
-# Computing the analytical values using FiberModes solver.
-dcf_fiber = load_fiber(
-    fiber_name=fiber_name,
-    wavelength=wavelength,
-    add_air_layer=True
-)
-
-# %%
-# Preparing the figure
-figure = SceneList(unit_size=(12, 4))
-
-ax = figure.append_ax(
-    x_label='Inverse taper ratio',
-    y_label='Effective index',
-    show_legend=True,
-    font_size=18,
-    tick_size=15,
-    legend_font_size=18
-)
-
-pyfibermodes_mode = LP01
-supymode_mode = superset.LP01
-
-analytical = numpy.empty(itr_list.shape)
-for idx, itr in enumerate(itr_list):
-    _fiber = dcf_fiber.scale(factor=itr)
-    analytical[idx] = _fiber.get_effective_index(mode=pyfibermodes_mode)
-
-ax.add_line(
-    x=itr_list,
-    y=analytical,
-    label=pyfibermodes_mode,
-    line_style='-',
-    line_width=2,
-    color='red',
-    layer_position=1
-)
-
-ax.add_scatter(
-    x=itr_list,
-    y=supymode_mode.index.data,
-    label=supymode_mode,
-    color='black',
-    line_width=2,
-    edge_color='blue',
-    marker_size=80,
-    line_style='-',
-    layer_position=2
-)
-
-_ = figure.show()
-
-
-# -
+"""
+Propagation constant: DCFC
+==========================
+"""
+
+# %%
+# Imports
+# ~~~~~~~
+import numpy
+from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
+from PyFiberModes import LP01
+from PyFiberModes.fiber import load_fiber
+from MPSPlots.render2D import SceneList
+
+wavelength = 1550e-9
+fiber_name = 'SMF28'
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+fiber_list = [
+    fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength)
+]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(right='symmetric', bottom='symmetric'),
+    Boundaries(right='symmetric', bottom='anti-symmetric')
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=50,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="left",                # Mesh x-boundary structure.
+    y_bounds="top",                 # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=6,                # Total computed and sorted mode.
+    n_added_mode=4,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=0,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.2,                  # Final value of inverse taper ratio to simulate
+    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+    n_step=50
+)
+
+superset = workflow.get_superset()
+itr_list = superset.model_parameters.itr_list
+
+# %%
+# Computing the analytical values using FiberModes solver.
+dcf_fiber = load_fiber(
+    fiber_name=fiber_name,
+    wavelength=wavelength,
+    add_air_layer=True
+)
+
+# %%
+# Preparing the figure
+figure = SceneList(unit_size=(12, 4))
+
+ax = figure.append_ax(
+    x_label='Inverse taper ratio',
+    y_label='Effective index',
+    show_legend=True,
+    font_size=18,
+    tick_size=15,
+    legend_font_size=18
+)
+
+pyfibermodes_mode = LP01
+supymode_mode = superset.LP01
+
+analytical = numpy.empty(itr_list.shape)
+for idx, itr in enumerate(itr_list):
+    _fiber = dcf_fiber.scale(factor=itr)
+    analytical[idx] = _fiber.get_effective_index(mode=pyfibermodes_mode)
+
+ax.add_line(
+    x=itr_list,
+    y=analytical,
+    label=pyfibermodes_mode,
+    line_style='-',
+    line_width=2,
+    color='red',
+    layer_position=1
+)
+
+ax.add_scatter(
+    x=itr_list,
+    y=supymode_mode.index.data,
+    label=supymode_mode,
+    color='black',
+    line_width=2,
+    edge_color='blue',
+    marker_size=80,
+    line_style='-',
+    layer_position=2
+)
+
+_ = figure.show()
+
+
+# -
```

## docs/examples/validation/plot_validation.py

```diff
@@ -1,199 +1,199 @@
-"""
-Propagation constant: DCFC
-==========================
-"""
-
-# %%
-# Imports
-# ~~~~~~~
-import numpy
-from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
-import PyFiberModes
-from PyFiberModes.fiber import load_fiber
-from PyFiberModes.__future__ import get_normalized_LP_coupling
-from MPSPlots.render2D import SceneList
-import itertools
-
-wavelength = 1550e-9
-fiber_name = 'test_multimode_fiber'
-scale_factor = 4
-
-# %%
-# Generating the fiber structure
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Here we define the cladding and fiber structure to model the problem
-fiber = fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength, remove_cladding=False)
-fiber_list = [fiber]
-
-
-# %%
-# Defining the boundaries of the system
-boundaries = [
-    Boundaries(right='symmetric', bottom='symmetric'),
-]
-
-# %%
-# Generating the computing workflow
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# Workflow class to define all the computation parameters before initializing the solver
-workflow = Workflow(
-    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
-    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
-    wavelength=wavelength,          # Wavelength used for the mode computation.
-    resolution=180,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
-    x_bounds="left",                # Mesh x-boundary structure.
-    y_bounds="top",                 # Mesh y-boundary structure.
-    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
-    n_sorted_mode=7,                # Total computed and sorted mode.
-    n_added_mode=6,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
-    plot_geometry=True,             # Plot the geometry mesh before computation.
-    debug_mode=1,                   # Print the iteration step for the solver plus some other important steps.
-    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
-    itr_final=0.4,                  # Final value of inverse taper ratio to simulate
-    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
-    n_step=100
-)
-
-superset = workflow.get_superset()
-
-superset.label_supermodes('LP01', 'LP21', 'LP02', 'LP03', 's')
-
-superset.plot(plot_type='field').show()
-
-itr_list = superset.itr_list
-
-# %%
-# Computing the analytical values using FiberModes solver.
-initial_fiber = load_fiber(
-    fiber_name=fiber_name,
-    wavelength=wavelength,
-    add_air_layer=False
-)
-
-
-# %%
-# Preparing the figure
-figure = SceneList(unit_size=(12, 4))
-
-ax = figure.append_ax(
-    x_label='Inverse taper ratio',
-    y_label='Effective index',
-    show_legend=True,
-    font_size=18,
-    tick_size=15,
-    legend_font_size=18
-)
-
-
-def get_index_pyfibermodes(mode, itr_list, fiber):
-    analytical = numpy.empty(itr_list.shape)
-
-    for idx, itr in enumerate(itr_list):
-        tapered_fiber = fiber.scale(factor=itr)
-        analytical[idx] = tapered_fiber.get_effective_index(mode=mode)
-
-    return analytical
-
-
-for idx, mode in enumerate(['LP01', 'LP02', 'LP03']):
-    color = f"C{idx}"
-
-    supymode_mode = getattr(superset, mode)
-    ax.add_scatter(
-        x=itr_list,
-        y=supymode_mode.index.data,
-        label=supymode_mode,
-        color='black',
-        line_width=2,
-        edge_color=color,
-        marker_size=80,
-        line_style='-',
-        layer_position=2
-    )
-
-    analytical = get_index_pyfibermodes(mode=getattr(PyFiberModes, mode), itr_list=itr_list, fiber=initial_fiber)
-
-    ax.add_line(
-        x=itr_list,
-        y=analytical,
-        label=mode,
-        line_style='-',
-        line_width=2,
-        color=color,
-        layer_position=1
-    )
-
-_ = figure.show()
-
-
-# %%
-# Preparing the figure
-figure = SceneList(unit_size=(12, 4))
-
-
-ax = figure.append_ax(
-    x_label='Inverse taper ratio',
-    y_label='Normalized coupling',
-    show_legend=True,
-    font_size=18,
-    tick_size=15,
-    legend_font_size=18
-)
-
-# %%
-# Computing the analytical values using FiberModes solver.
-initial_fiber = load_fiber(
-    fiber_name=fiber_name,
-    wavelength=wavelength,
-    add_air_layer=False
-)
-
-
-def get_normalized_coupling_pyfibermodes(mode_0, mode_1, itr_list, initial_fiber):
-    analytical = numpy.empty(itr_list.shape)
-
-    for idx, itr in enumerate(itr_list):
-        tapered_fiber = initial_fiber.scale(factor=itr)
-
-        analytical[idx] = get_normalized_LP_coupling(fiber=tapered_fiber, mode_0=mode_0, mode_1=mode_1)
-
-    return analytical
-
-
-for idx, (mode_0, mode_1) in enumerate(itertools.combinations(['LP01', 'LP02', 'LP03'], 2)):
-    color = f"C{idx}"
-
-    analytical = get_normalized_coupling_pyfibermodes(
-        mode_0=getattr(PyFiberModes, mode_0),
-        mode_1=getattr(PyFiberModes, mode_1),
-        itr_list=itr_list[::2],
-        initial_fiber=initial_fiber
-    )
-
-    ax.add_line(
-        x=itr_list[::2],
-        y=abs(analytical),
-        label='Analytical',
-        line_style='-',
-        line_width=2,
-        color=color,
-        layer_position=1
-    )
-
-    simulation = getattr(superset, mode_0).normalized_coupling.get_values(getattr(superset, mode_1))
-
-    ax.add_scatter(
-        x=superset.itr_list,
-        y=abs(simulation),
-        color='black',
-        line_width=2,
-        edge_color=color,
-        marker_size=80,
-        line_style='-',
-        layer_position=2,
-        label=mode_0 + '-' + mode_1
-    )
-
-_ = figure.show()
-
-# -
+"""
+Propagation constant: DCFC
+==========================
+"""
+
+# %%
+# Imports
+# ~~~~~~~
+import numpy
+from SuPyMode.workflow import Workflow, fiber_catalogue, Boundaries
+import PyFiberModes
+from PyFiberModes.fiber import load_fiber
+from PyFiberModes.__future__ import get_normalized_LP_coupling
+from MPSPlots.render2D import SceneList
+import itertools
+
+wavelength = 1550e-9
+fiber_name = 'test_multimode_fiber'
+scale_factor = 4
+
+# %%
+# Generating the fiber structure
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Here we define the cladding and fiber structure to model the problem
+fiber = fiber_catalogue.load_fiber(fiber_name, wavelength=wavelength, remove_cladding=False)
+fiber_list = [fiber]
+
+
+# %%
+# Defining the boundaries of the system
+boundaries = [
+    Boundaries(right='symmetric', bottom='symmetric'),
+]
+
+# %%
+# Generating the computing workflow
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# Workflow class to define all the computation parameters before initializing the solver
+workflow = Workflow(
+    fiber_list=fiber_list,          # List of fiber to be added in the mesh, the order matters.
+    fusion_degree='auto',           # Degree of fusion of the structure if applicable.
+    wavelength=wavelength,          # Wavelength used for the mode computation.
+    resolution=180,                 # Number of point in the x and y axis [is divided by half if symmetric or anti-symmetric boundaries].
+    x_bounds="left",                # Mesh x-boundary structure.
+    y_bounds="top",                 # Mesh y-boundary structure.
+    boundaries=boundaries,          # Set of symmetries to be evaluated, each symmetry add a round of simulation
+    n_sorted_mode=7,                # Total computed and sorted mode.
+    n_added_mode=6,                 # Additional computed mode that are not considered later except for field comparison [the higher the better but the slower].
+    plot_geometry=True,             # Plot the geometry mesh before computation.
+    debug_mode=1,                   # Print the iteration step for the solver plus some other important steps.
+    auto_label=True,                # Auto labeling the mode. Label are not always correct and should be verified afterwards.
+    itr_final=0.4,                  # Final value of inverse taper ratio to simulate
+    index_scrambling=0,             # Scrambling of refractive index value in order to lift mode degeneracy [useful for some analysis]
+    n_step=100
+)
+
+superset = workflow.get_superset()
+
+superset.label_supermodes('LP01', 'LP21', 'LP02', 'LP03', 's')
+
+superset.plot(plot_type='field').show()
+
+itr_list = superset.model_parameters.itr_list
+
+# %%
+# Computing the analytical values using FiberModes solver.
+initial_fiber = load_fiber(
+    fiber_name=fiber_name,
+    wavelength=wavelength,
+    add_air_layer=False
+)
+
+
+# %%
+# Preparing the figure
+figure = SceneList(unit_size=(12, 4))
+
+ax = figure.append_ax(
+    x_label='Inverse taper ratio',
+    y_label='Effective index',
+    show_legend=True,
+    font_size=18,
+    tick_size=15,
+    legend_font_size=18
+)
+
+
+def get_index_pyfibermodes(mode, itr_list, fiber):
+    analytical = numpy.empty(itr_list.shape)
+
+    for idx, itr in enumerate(itr_list):
+        tapered_fiber = fiber.scale(factor=itr)
+        analytical[idx] = tapered_fiber.get_effective_index(mode=mode)
+
+    return analytical
+
+
+for idx, mode in enumerate(['LP01', 'LP02', 'LP03']):
+    color = f"C{idx}"
+
+    supymode_mode = getattr(superset, mode)
+    ax.add_scatter(
+        x=itr_list,
+        y=supymode_mode.index.data,
+        label=supymode_mode,
+        color='black',
+        line_width=2,
+        edge_color=color,
+        marker_size=80,
+        line_style='-',
+        layer_position=2
+    )
+
+    analytical = get_index_pyfibermodes(mode=getattr(PyFiberModes, mode), itr_list=itr_list, fiber=initial_fiber)
+
+    ax.add_line(
+        x=itr_list,
+        y=analytical,
+        label=mode,
+        line_style='-',
+        line_width=2,
+        color=color,
+        layer_position=1
+    )
+
+_ = figure.show()
+
+
+# %%
+# Preparing the figure
+figure = SceneList(unit_size=(12, 4))
+
+
+ax = figure.append_ax(
+    x_label='Inverse taper ratio',
+    y_label='Normalized coupling',
+    show_legend=True,
+    font_size=18,
+    tick_size=15,
+    legend_font_size=18
+)
+
+# %%
+# Computing the analytical values using FiberModes solver.
+initial_fiber = load_fiber(
+    fiber_name=fiber_name,
+    wavelength=wavelength,
+    add_air_layer=False
+)
+
+
+def get_normalized_coupling_pyfibermodes(mode_0, mode_1, itr_list, initial_fiber):
+    analytical = numpy.empty(itr_list.shape)
+
+    for idx, itr in enumerate(itr_list):
+        tapered_fiber = initial_fiber.scale(factor=itr)
+
+        analytical[idx] = get_normalized_LP_coupling(fiber=tapered_fiber, mode_0=mode_0, mode_1=mode_1)
+
+    return analytical
+
+
+for idx, (mode_0, mode_1) in enumerate(itertools.combinations(['LP01', 'LP02', 'LP03'], 2)):
+    color = f"C{idx}"
+
+    analytical = get_normalized_coupling_pyfibermodes(
+        mode_0=getattr(PyFiberModes, mode_0),
+        mode_1=getattr(PyFiberModes, mode_1),
+        itr_list=itr_list[::2],
+        initial_fiber=initial_fiber
+    )
+
+    ax.add_line(
+        x=itr_list[::2],
+        y=abs(analytical),
+        label='Analytical',
+        line_style='-',
+        line_width=2,
+        color=color,
+        layer_position=1
+    )
+
+    simulation = getattr(superset, mode_0).normalized_coupling.get_values(getattr(superset, mode_1))
+
+    ax.add_scatter(
+        x=superset.model_parameters.itr_list,
+        y=abs(simulation),
+        color='black',
+        line_width=2,
+        edge_color=color,
+        marker_size=80,
+        line_style='-',
+        layer_position=2,
+        label=mode_0 + '-' + mode_1
+    )
+
+_ = figure.show()
+
+# -
```

## docs/legacy/__debug__.py

 * *Ordering differences only*

```diff
@@ -1,67 +1,67 @@
-
-import numpy
-from PyFiberModes.__future__ import get_normalized_LP_coupling
-
-
-def integrate_2d(mesh, x, y):
-    dx = abs(x[0] - x[1])
-    dy = abs(y[0] - y[1])
-
-    integral = numpy.trapz(mesh, dx=dx)
-
-    integral = numpy.trapz(integral, dx=dy)
-
-    return integral
-
-
-def get_theoretical_mode_coupling(fiber, mode_0, mode_1, itr_list: numpy.ndarray) -> numpy.ndarray:
-    coupling_array = numpy.empty(itr_list.shape)
-
-    for idx, itr in enumerate(itr_list):
-        _fiber = fiber.scale(itr)
-
-        coupling = get_normalized_LP_coupling(
-            fiber=_fiber,
-            mode_0=mode_0,
-            mode_1=mode_1
-        )
-
-        coupling_array[idx] = coupling
-
-    return coupling_array
-
-
-def get_mode_coupling(superset, mode_0, mode_1) -> numpy.ndarray:
-    coordinate = superset.geometry.coordinate_system
-    itr_list = superset.itr_list
-
-    gradient = superset.geometry.n2_gradient * coordinate.rho_mesh
-
-    coupling_array = numpy.empty(itr_list.shape)
-
-    for idx, itr in enumerate(itr_list):
-
-        field_01 = superset.LP01.field._data[idx]
-        field_02 = superset.LP02.field._data[idx]
-
-        beta_0 = superset.LP01.beta._data[idx]
-        beta_1 = superset.LP02.beta._data[idx]
-
-        mesh = field_01 * field_02 * gradient
-
-        integral = integrate_2d(
-            mesh=mesh,
-            x=coordinate.x_vector * itr,
-            y=coordinate.x_vector * itr
-        )
-
-        term_0 = abs(beta_0 - beta_1)
-        term_1 = numpy.sqrt(beta_0 * beta_1)
-        term_2 = 0.5 * superset.wavenumber**2
-        term_3 = term_2 / (term_0 * term_1)
-
-        coupling_array[idx] = integral * term_3
-
-    return coupling_array
-
-# -
+
+import numpy
+from PyFiberModes.__future__ import get_normalized_LP_coupling
+
+
+def integrate_2d(mesh, x, y):
+    dx = abs(x[0] - x[1])
+    dy = abs(y[0] - y[1])
+
+    integral = numpy.trapz(mesh, dx=dx)
+
+    integral = numpy.trapz(integral, dx=dy)
+
+    return integral
+
+
+def get_theoretical_mode_coupling(fiber, mode_0, mode_1, itr_list: numpy.ndarray) -> numpy.ndarray:
+    coupling_array = numpy.empty(itr_list.shape)
+
+    for idx, itr in enumerate(itr_list):
+        _fiber = fiber.scale(itr)
+
+        coupling = get_normalized_LP_coupling(
+            fiber=_fiber,
+            mode_0=mode_0,
+            mode_1=mode_1
+        )
+
+        coupling_array[idx] = coupling
+
+    return coupling_array
+
+
+def get_mode_coupling(superset, mode_0, mode_1) -> numpy.ndarray:
+    coordinate = superset.geometry.coordinate_system
+    itr_list = superset.itr_list
+
+    gradient = superset.geometry.n2_gradient * coordinate.rho_mesh
+
+    coupling_array = numpy.empty(itr_list.shape)
+
+    for idx, itr in enumerate(itr_list):
+
+        field_01 = superset.LP01.field._data[idx]
+        field_02 = superset.LP02.field._data[idx]
+
+        beta_0 = superset.LP01.beta._data[idx]
+        beta_1 = superset.LP02.beta._data[idx]
+
+        mesh = field_01 * field_02 * gradient
+
+        integral = integrate_2d(
+            mesh=mesh,
+            x=coordinate.x_vector * itr,
+            y=coordinate.x_vector * itr
+        )
+
+        term_0 = abs(beta_0 - beta_1)
+        term_1 = numpy.sqrt(beta_0 * beta_1)
+        term_2 = 0.5 * superset.wavenumber**2
+        term_3 = term_2 / (term_0 * term_1)
+
+        coupling_array[idx] = integral * term_3
+
+    return coupling_array
+
+# -
```

## docs/legacy/python_debuging/eigen_solver.py

 * *Ordering differences only*

```diff
@@ -1,322 +1,322 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-# Standard imports
-import numpy
-from dataclasses import dataclass
-
-# Scipy imports
-from scipy.sparse import linalg
-from scipy.sparse._csr import csr_matrix
-
-# Other imports
-from SuPyMode.python_debuging.mode_solver import ModeSolver
-from FiberFusing import Geometry
-from MPSPlots.render2D import Scene2D, Axis, Line
-
-
-@dataclass
-class EigenSolver:
-    laplacian: numpy.ndarray
-    """ Laplacian sparse matrix that is used to compute the eigen solutions """
-    geometry: Geometry
-    """ Geometry object that contain the mesh used connjointly with the laplacian """
-    itr_list: numpy.ndarray
-    """ Inverse taper ratio list to which evaluate the solutions """
-    wavelength: float
-    """ Wavelength used for the simulation """
-    max_iteration: int = 1000
-    """ Maximum number of time the bicgstab is called per mode per slice """
-    min_iteration: int = 5
-    """ Minimum number of time the bicgstab is called per mode per slice """
-    randomize_factor: float = 1e-15
-    """ Factor for randomization of eiven vector guess from one slice to the next """
-    n_solution: int = 1
-    """ Number of mode to compute """
-    tolerance: float = 1e-3,
-    """ Tolerance for the eigen solution to compute """
-    debug: bool = False
-    """ Debug parameter, if enabled a lot of verbose will be show """
-    debug_guess: bool = False
-    """ Debug parameter, if enabled shows the eigen_value guess and computed value """
-    debug_bicgstab: bool = False
-    """ Debug parameter, if enabled shows the bicgstab debuging """
-    fitting_max_degree: int = 5
-    """ Fitting maximim degree for eigen value extrapolation """
-
-    def __post_init__(self) -> None:
-        self.wavenumber = 2 * numpy.pi / self.wavelength
-
-        self.mode_solvers = []
-        for n in range(self.n_solution):
-            self.mode_solvers.append(
-                ModeSolver(
-                    itr_list=self.itr_list,
-                    shape=self.geometry.mesh.shape,
-                    wavelength=self.wavelength,
-                    fitting_max_degree=self.fitting_max_degree,
-                    label=f"mode_{n}"
-                )
-            )
-
-    def __getitem__(self, idx):
-        return self.mode_solvers[idx]
-
-    def index_to_eigen_value(self, index: float, itr: float) -> float:
-        """
-        Return the eigen value associated to the given effective index
-
-        :param      index:  The mode effective index
-        :type       index:  float
-
-        :returns:   The associated eigen value
-        :rtype:     float
-        """
-        return (self.wavenumber * index * itr)**2
-
-    def eigen_value_to_index(self, eigen_value: float, itr: float) -> float:
-        """
-        Return the effective index associated toe the given eigen value.
-
-        :param      eigen_value:  The eigen value
-        :type       eigen_value:  float
-        :param      itr:          The itr
-        :type       itr:          float
-
-        :returns:   The associated effective index
-        :rtype:     float
-        """
-        return numpy.sqrt(eigen_value) / self.wavenumber / itr
-
-    def get_vector_norm(self, vector: numpy.ndarray) -> float:
-        """
-        Returns the norm of the norm2 of the given vector.
-
-        :param      vector:  The vector
-        :type       vector:  float
-        """
-        return numpy.sqrt((vector**2).sum())
-
-    def normalize_vector(self, vector: numpy.ndarray) -> numpy.ndarray:
-        """
-        Returns the normalized vector given. The norm is norm2
-
-        :param      vector:  The vector to normalized
-        :type       vector:  numpy.ndarray
-
-        :returns:   The normalized vector
-        :rtype:
-        """
-        return vector / self.get_vector_norm(vector)
-
-    def generate_eigen_matrix(self, itr: float = 1) -> csr_matrix:
-        """
-        Returns a eigen matrix constitued of the laplacian with the diagonal added of the
-        mesh value times the wavenumbered squareds.
-
-        :param      itr:  The itr to which evaluate the eigen matrix
-        :type       itr:  float
-        """
-        wavenumber = self.wavenumber * itr
-        eigen_matrix = self.laplacian.copy()
-
-        eigen_matrix.setdiag(
-            eigen_matrix.diagonal() + (self.geometry.mesh.ravel() * wavenumber)**2
-        )
-
-        return eigen_matrix
-
-    def get_eigen_solution_from_scipy(self, eigen_matrix: csr_matrix, index_guess: float, itr: float) -> tuple:
-        """
-        Return eigen solution for the given eigen matrix input and index guess.
-
-        :param      eigen_matrix:  The eigen matrix
-        :type       eigen_matrix:  csr_matrix
-        :param      index_guess:   The index guess
-        :type       index_guess:   float
-
-        :returns:   The eigen solution from scipy.
-        :rtype:     tuple
-        """
-        eigen_value_guess = self.index_to_eigen_value(index=index_guess, itr=itr)
-
-        print(eigen_value_guess)
-        eigen_values, eigen_vectors = linalg.eigs(
-            eigen_matrix,
-            k=self.n_solution + 5,
-            which='LM',
-            sigma=eigen_value_guess
-        )
-
-        return eigen_values[:self.n_solution], eigen_vectors[:, :self.n_solution]
-
-    def compute_eigen_solution_with_scipy(self, number_of_iteration: int = 1, index_guess: float = None):
-        self.pre_computed_slice = 0
-
-        if index_guess is None:
-            index_guess = self.geometry.mesh.max()
-
-        for itr in self.itr_list[:number_of_iteration]:
-            eigen_matrix = self.generate_eigen_matrix(itr)
-
-            values, vectors = self.get_eigen_solution_from_scipy(
-                eigen_matrix=eigen_matrix,
-                index_guess=index_guess,
-                itr=itr
-            )
-
-            for value, vector, mode_solver in zip(values, vectors.T, self.mode_solvers):
-                mode_solver.append_next_slice(
-                    eigen_vector=vector,
-                    eigen_value=value,
-                    itr=itr
-                )
-
-            self.pre_computed_slice += 1
-
-    def shift_sparse_matrix(self, sparse_matrix: csr_matrix, shift: float) -> csr_matrix:
-        """
-        Retunrs the eigen matrix given to the same but with the diagonal shifted.
-
-        :param      sparse_matrix:  The sparse matrix
-        :type       sparse_matrix:  csr_matrix
-        :param      shift:          The shift
-        :type       shift:          float
-        """
-        shifted_sparse_matrix = sparse_matrix.copy()
-
-        shifted_sparse_matrix.setdiag(
-            shifted_sparse_matrix.diagonal() - shift
-        )
-
-        return shifted_sparse_matrix
-
-    def compute_next_slice(self):
-        itr = self.itr_list[self.pre_computed_slice]
-        eigen_matrix = self.generate_eigen_matrix(itr=itr)
-
-        for mode_solver in self.mode_solvers:
-            if self.debug:
-                print(f"Mode processed: {mode_solver.label}")
-
-            eigen_value_guess = mode_solver.extrapolate_eigen_value(itr=itr)
-            eigen_vector_guess = mode_solver.extrapolate_eigen_vector(itr=itr)
-
-            eigen_value, eigen_vector = self.power_shift_method(
-                eigen_matrix=eigen_matrix,
-                eigen_value_guess=eigen_value_guess,
-                eigen_vector_guess=eigen_vector_guess
-            )
-
-            mode_solver.append_eigen_vector(eigen_vector=eigen_vector)
-            mode_solver.append_eigen_value(eigen_value=eigen_value, itr=itr)
-
-        self.pre_computed_slice += 1
-
-    def power_shift_method(self, eigen_matrix: csr_matrix, eigen_value_guess: float = 0, eigen_vector_guess: numpy.ndarray = None) -> tuple:
-        """
-        Use the inverse power shift method to retrieve the eigen solution
-        for a given eigen matrix.
-        The method accept an initial eigen value and vector guess
-
-        :param      eigen_matrix:        The eigen matrix
-        :type       eigen_matrix:        csr_matrix
-        :param      eigen_value_guess:   The eigen value guess
-        :type       eigen_value_guess:   float
-        :param      eigen_vector_guess:  The eigen vector guess
-        :type       eigen_vector_guess:  numpy.ndarray
-
-        :returns:   Eigen value and eigen vector in a tuple
-        :rtype:     tuple
-        """
-        if eigen_vector_guess is None:
-            eigen_vector_guess = numpy.random.rand(eigen_matrix.shape[0])
-
-        eigen_vector_guess += numpy.random.rand(*eigen_vector_guess.shape) * self.randomize_factor
-
-        shifted_A = self.shift_sparse_matrix(eigen_matrix, eigen_value_guess)
-
-        solution_k = self.normalize_vector(eigen_vector_guess)
-
-        for iteration in range(self.max_iteration):
-
-            v = self.normalize_vector(solution_k)
-
-            solution_k, _ = linalg.bicgstab(shifted_A, v.real)
-
-            projection = v.dot(solution_k)
-
-            residual = self.get_vector_norm(solution_k - projection * v) / abs(projection)
-
-            eigen_value = eigen_value_guess + 1 / projection
-            eigen_vector = solution_k / projection
-
-            if iteration >= self.min_iteration and residual < self.tolerance:
-                if self.debug_bicgstab:
-                    print(f"Process suceed {residual = :.4e} in {iteration = } iteration")
-                return eigen_value, eigen_vector
-
-        print(f" ===> Process failed {residual = :.4e} in {iteration = } iteration")
-        return eigen_value, eigen_vector
-
-    def process_mode(self, mode_number: int) -> None:
-        """
-        Compute the full itr_list iteration for a given mode number.
-
-        :param      mode_number:  The mode number
-        :type       mode_number:  int
-
-        :returns:   No return
-        :rtype:     None
-        """
-        mode = self.mode_solvers[mode_number]
-
-        if self.debug:
-            print(f"Mode processed: {mode.label}")
-
-        for itr in self.itr_list[self.pre_computed_slice:]:
-            if self.debug:
-                print(f"itr: {itr}")
-
-            eigen_matrix = self.generate_eigen_matrix(itr=itr)
-
-            eigen_value_guess = mode.extrapolate_eigen_value(itr=itr)
-
-            eigen_vector_guess = mode.last_eigen_vector
-
-            eigen_value, eigen_vector = self.power_shift_method(
-                eigen_matrix=eigen_matrix,
-                eigen_value_guess=eigen_value_guess,
-                eigen_vector_guess=eigen_vector_guess
-            )
-
-            if self.debug_guess:
-                print(f'eigen value guess: {eigen_value_guess:.8e}\tcomputed eigen value: {eigen_value:.8e}\n')
-
-            mode.append_eigen_vector(eigen_vector=eigen_vector)
-            mode.append_eigen_value(eigen_value=eigen_value, itr=itr)
-
-    def render_index_on_ax(self, ax: Axis):
-        for mode in self.mode_solvers:
-            artist = Line(
-                x=mode.itr_list,
-                y=mode.effective_index,
-            )
-
-            ax.add_artist(artist)
-
-            ax.x_label = 'Inverse taper ratio'
-            ax.y_label = 'Effective index'
-
-    def plot(self):
-        figure = Scene2D(unit_size=(15, 6))
-
-        ax = Axis(row=0, col=0)
-
-        figure.add_axes(ax)
-
-        self.render_index_on_ax(ax=ax)
-
-        return figure
-
-# -
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+# Standard imports
+import numpy
+from dataclasses import dataclass
+
+# Scipy imports
+from scipy.sparse import linalg
+from scipy.sparse._csr import csr_matrix
+
+# Other imports
+from SuPyMode.python_debuging.mode_solver import ModeSolver
+from FiberFusing import Geometry
+from MPSPlots.render2D import Scene2D, Axis, Line
+
+
+@dataclass
+class EigenSolver:
+    laplacian: numpy.ndarray
+    """ Laplacian sparse matrix that is used to compute the eigen solutions """
+    geometry: Geometry
+    """ Geometry object that contain the mesh used connjointly with the laplacian """
+    itr_list: numpy.ndarray
+    """ Inverse taper ratio list to which evaluate the solutions """
+    wavelength: float
+    """ Wavelength used for the simulation """
+    max_iteration: int = 1000
+    """ Maximum number of time the bicgstab is called per mode per slice """
+    min_iteration: int = 5
+    """ Minimum number of time the bicgstab is called per mode per slice """
+    randomize_factor: float = 1e-15
+    """ Factor for randomization of eiven vector guess from one slice to the next """
+    n_solution: int = 1
+    """ Number of mode to compute """
+    tolerance: float = 1e-3,
+    """ Tolerance for the eigen solution to compute """
+    debug: bool = False
+    """ Debug parameter, if enabled a lot of verbose will be show """
+    debug_guess: bool = False
+    """ Debug parameter, if enabled shows the eigen_value guess and computed value """
+    debug_bicgstab: bool = False
+    """ Debug parameter, if enabled shows the bicgstab debuging """
+    fitting_max_degree: int = 5
+    """ Fitting maximim degree for eigen value extrapolation """
+
+    def __post_init__(self) -> None:
+        self.wavenumber = 2 * numpy.pi / self.wavelength
+
+        self.mode_solvers = []
+        for n in range(self.n_solution):
+            self.mode_solvers.append(
+                ModeSolver(
+                    itr_list=self.itr_list,
+                    shape=self.geometry.mesh.shape,
+                    wavelength=self.wavelength,
+                    fitting_max_degree=self.fitting_max_degree,
+                    label=f"mode_{n}"
+                )
+            )
+
+    def __getitem__(self, idx):
+        return self.mode_solvers[idx]
+
+    def index_to_eigen_value(self, index: float, itr: float) -> float:
+        """
+        Return the eigen value associated to the given effective index
+
+        :param      index:  The mode effective index
+        :type       index:  float
+
+        :returns:   The associated eigen value
+        :rtype:     float
+        """
+        return (self.wavenumber * index * itr)**2
+
+    def eigen_value_to_index(self, eigen_value: float, itr: float) -> float:
+        """
+        Return the effective index associated toe the given eigen value.
+
+        :param      eigen_value:  The eigen value
+        :type       eigen_value:  float
+        :param      itr:          The itr
+        :type       itr:          float
+
+        :returns:   The associated effective index
+        :rtype:     float
+        """
+        return numpy.sqrt(eigen_value) / self.wavenumber / itr
+
+    def get_vector_norm(self, vector: numpy.ndarray) -> float:
+        """
+        Returns the norm of the norm2 of the given vector.
+
+        :param      vector:  The vector
+        :type       vector:  float
+        """
+        return numpy.sqrt((vector**2).sum())
+
+    def normalize_vector(self, vector: numpy.ndarray) -> numpy.ndarray:
+        """
+        Returns the normalized vector given. The norm is norm2
+
+        :param      vector:  The vector to normalized
+        :type       vector:  numpy.ndarray
+
+        :returns:   The normalized vector
+        :rtype:
+        """
+        return vector / self.get_vector_norm(vector)
+
+    def generate_eigen_matrix(self, itr: float = 1) -> csr_matrix:
+        """
+        Returns a eigen matrix constitued of the laplacian with the diagonal added of the
+        mesh value times the wavenumbered squareds.
+
+        :param      itr:  The itr to which evaluate the eigen matrix
+        :type       itr:  float
+        """
+        wavenumber = self.wavenumber * itr
+        eigen_matrix = self.laplacian.copy()
+
+        eigen_matrix.setdiag(
+            eigen_matrix.diagonal() + (self.geometry.mesh.ravel() * wavenumber)**2
+        )
+
+        return eigen_matrix
+
+    def get_eigen_solution_from_scipy(self, eigen_matrix: csr_matrix, index_guess: float, itr: float) -> tuple:
+        """
+        Return eigen solution for the given eigen matrix input and index guess.
+
+        :param      eigen_matrix:  The eigen matrix
+        :type       eigen_matrix:  csr_matrix
+        :param      index_guess:   The index guess
+        :type       index_guess:   float
+
+        :returns:   The eigen solution from scipy.
+        :rtype:     tuple
+        """
+        eigen_value_guess = self.index_to_eigen_value(index=index_guess, itr=itr)
+
+        print(eigen_value_guess)
+        eigen_values, eigen_vectors = linalg.eigs(
+            eigen_matrix,
+            k=self.n_solution + 5,
+            which='LM',
+            sigma=eigen_value_guess
+        )
+
+        return eigen_values[:self.n_solution], eigen_vectors[:, :self.n_solution]
+
+    def compute_eigen_solution_with_scipy(self, number_of_iteration: int = 1, index_guess: float = None):
+        self.pre_computed_slice = 0
+
+        if index_guess is None:
+            index_guess = self.geometry.mesh.max()
+
+        for itr in self.itr_list[:number_of_iteration]:
+            eigen_matrix = self.generate_eigen_matrix(itr)
+
+            values, vectors = self.get_eigen_solution_from_scipy(
+                eigen_matrix=eigen_matrix,
+                index_guess=index_guess,
+                itr=itr
+            )
+
+            for value, vector, mode_solver in zip(values, vectors.T, self.mode_solvers):
+                mode_solver.append_next_slice(
+                    eigen_vector=vector,
+                    eigen_value=value,
+                    itr=itr
+                )
+
+            self.pre_computed_slice += 1
+
+    def shift_sparse_matrix(self, sparse_matrix: csr_matrix, shift: float) -> csr_matrix:
+        """
+        Retunrs the eigen matrix given to the same but with the diagonal shifted.
+
+        :param      sparse_matrix:  The sparse matrix
+        :type       sparse_matrix:  csr_matrix
+        :param      shift:          The shift
+        :type       shift:          float
+        """
+        shifted_sparse_matrix = sparse_matrix.copy()
+
+        shifted_sparse_matrix.setdiag(
+            shifted_sparse_matrix.diagonal() - shift
+        )
+
+        return shifted_sparse_matrix
+
+    def compute_next_slice(self):
+        itr = self.itr_list[self.pre_computed_slice]
+        eigen_matrix = self.generate_eigen_matrix(itr=itr)
+
+        for mode_solver in self.mode_solvers:
+            if self.debug:
+                print(f"Mode processed: {mode_solver.label}")
+
+            eigen_value_guess = mode_solver.extrapolate_eigen_value(itr=itr)
+            eigen_vector_guess = mode_solver.extrapolate_eigen_vector(itr=itr)
+
+            eigen_value, eigen_vector = self.power_shift_method(
+                eigen_matrix=eigen_matrix,
+                eigen_value_guess=eigen_value_guess,
+                eigen_vector_guess=eigen_vector_guess
+            )
+
+            mode_solver.append_eigen_vector(eigen_vector=eigen_vector)
+            mode_solver.append_eigen_value(eigen_value=eigen_value, itr=itr)
+
+        self.pre_computed_slice += 1
+
+    def power_shift_method(self, eigen_matrix: csr_matrix, eigen_value_guess: float = 0, eigen_vector_guess: numpy.ndarray = None) -> tuple:
+        """
+        Use the inverse power shift method to retrieve the eigen solution
+        for a given eigen matrix.
+        The method accept an initial eigen value and vector guess
+
+        :param      eigen_matrix:        The eigen matrix
+        :type       eigen_matrix:        csr_matrix
+        :param      eigen_value_guess:   The eigen value guess
+        :type       eigen_value_guess:   float
+        :param      eigen_vector_guess:  The eigen vector guess
+        :type       eigen_vector_guess:  numpy.ndarray
+
+        :returns:   Eigen value and eigen vector in a tuple
+        :rtype:     tuple
+        """
+        if eigen_vector_guess is None:
+            eigen_vector_guess = numpy.random.rand(eigen_matrix.shape[0])
+
+        eigen_vector_guess += numpy.random.rand(*eigen_vector_guess.shape) * self.randomize_factor
+
+        shifted_A = self.shift_sparse_matrix(eigen_matrix, eigen_value_guess)
+
+        solution_k = self.normalize_vector(eigen_vector_guess)
+
+        for iteration in range(self.max_iteration):
+
+            v = self.normalize_vector(solution_k)
+
+            solution_k, _ = linalg.bicgstab(shifted_A, v.real)
+
+            projection = v.dot(solution_k)
+
+            residual = self.get_vector_norm(solution_k - projection * v) / abs(projection)
+
+            eigen_value = eigen_value_guess + 1 / projection
+            eigen_vector = solution_k / projection
+
+            if iteration >= self.min_iteration and residual < self.tolerance:
+                if self.debug_bicgstab:
+                    print(f"Process suceed {residual = :.4e} in {iteration = } iteration")
+                return eigen_value, eigen_vector
+
+        print(f" ===> Process failed {residual = :.4e} in {iteration = } iteration")
+        return eigen_value, eigen_vector
+
+    def process_mode(self, mode_number: int) -> None:
+        """
+        Compute the full itr_list iteration for a given mode number.
+
+        :param      mode_number:  The mode number
+        :type       mode_number:  int
+
+        :returns:   No return
+        :rtype:     None
+        """
+        mode = self.mode_solvers[mode_number]
+
+        if self.debug:
+            print(f"Mode processed: {mode.label}")
+
+        for itr in self.itr_list[self.pre_computed_slice:]:
+            if self.debug:
+                print(f"itr: {itr}")
+
+            eigen_matrix = self.generate_eigen_matrix(itr=itr)
+
+            eigen_value_guess = mode.extrapolate_eigen_value(itr=itr)
+
+            eigen_vector_guess = mode.last_eigen_vector
+
+            eigen_value, eigen_vector = self.power_shift_method(
+                eigen_matrix=eigen_matrix,
+                eigen_value_guess=eigen_value_guess,
+                eigen_vector_guess=eigen_vector_guess
+            )
+
+            if self.debug_guess:
+                print(f'eigen value guess: {eigen_value_guess:.8e}\tcomputed eigen value: {eigen_value:.8e}\n')
+
+            mode.append_eigen_vector(eigen_vector=eigen_vector)
+            mode.append_eigen_value(eigen_value=eigen_value, itr=itr)
+
+    def render_index_on_ax(self, ax: Axis):
+        for mode in self.mode_solvers:
+            artist = Line(
+                x=mode.itr_list,
+                y=mode.effective_index,
+            )
+
+            ax.add_artist(artist)
+
+            ax.x_label = 'Inverse taper ratio'
+            ax.y_label = 'Effective index'
+
+    def plot(self):
+        figure = Scene2D(unit_size=(15, 6))
+
+        ax = Axis(row=0, col=0)
+
+        figure.add_axes(ax)
+
+        self.render_index_on_ax(ax=ax)
+
+        return figure
+
+# -
```

## docs/legacy/python_debuging/mode_solver.py

 * *Ordering differences only*

```diff
@@ -1,398 +1,398 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-# Standard imports
-import numpy
-from dataclasses import dataclass
-from MPSPlots.CMAP import BKR
-from MPSPlots.render2D import Scene2D, Axis, Line, Mesh, ColorBar
-
-
-@dataclass
-class ModeSolver():
-    itr_list: numpy.ndarray
-    """ List of value representing the inverse taper ratio """
-    shape: tuple
-    """ Tuple representing the shape of the mesh from which the eigen matrix is constructred """
-    wavelength: float
-    """ Value representing the wavelength of the simulation """
-    label: str = ''
-    """ Label of the mode """
-    fitting_max_degree: int = 5
-    """ Max value for the coefficient fitting algorithm for eigen value extrapolation """
-    save_fittings: bool = True
-
-    def __post_init__(self):
-        self.wavenumber = 2 * numpy.pi / self.wavelength
-        self.construct_initial_arrays()
-        self.fitting_coefficients = None
-
-    def construct_initial_arrays(self) -> None:
-        """
-        Construct the arrays where the eigen values and vectors will be stored.
-
-        :returns:   No return
-        :rtype:     None
-        """
-        eigen_vector_size = self.shape[0] * self.shape[1]
-        self.eigen_vectors = numpy.full([self.itr_list.size, eigen_vector_size], numpy.nan)
-        self.eigen_values = numpy.full(self.itr_list.size, numpy.nan)
-        self.effective_index = numpy.full(self.itr_list.size, numpy.nan)
-        self.fit_values = numpy.full(self.itr_list.size, numpy.nan)
-
-        self.eigen_values = self.eigen_values.astype(complex)
-        self.effective_index = self.effective_index
-        self.eigen_vectors = self.eigen_vectors.astype(complex)
-        self.fit_values = self.fit_values.astype(complex)
-
-    def index_to_eigen_value(self, itr: float, index: float) -> float:
-        """
-        Return the eigen value associated to the given effective index
-
-        :param      index:  The mode effective index
-        :type       index:  float
-
-        :returns:   The associated eigen value
-        :rtype:     float
-        """
-        return (self.wavenumber * index * itr)**2
-
-    def eigen_value_to_index(self, eigen_value: float, itr: float) -> float:
-        """
-        Return the effective index associated toe the given eigen value.
-
-        :param      eigen_value:  The eigen value
-        :type       eigen_value:  float
-        :param      itr:          The itr
-        :type       itr:          float
-
-        :returns:   The associated effective index
-        :rtype:     float
-        """
-        return numpy.sqrt(eigen_value) / self.wavenumber / itr
-
-    def get_next_slice_idx(self) -> int:
-        """
-        Return the index of the next slice that will be computed.
-
-        :returns:   The next slice index.
-        :rtype:     int
-        """
-        non_nan_idx = numpy.argwhere(~numpy.isnan(self.eigen_values))
-        return non_nan_idx.size
-
-    def get_last_slice_idx(self) -> int:
-        """
-        Return the index of the last slice that was computed.
-
-        :returns:   The last slice index.
-        :rtype:     int
-        """
-        next_slice_idx = self.get_next_slice_idx()
-        return next_slice_idx - 1
-
-    def append_eigen_value(self, itr: float, eigen_value: float) -> None:
-        """
-        Append eigen_value to the mode. Stored in self.eigen_values.
-
-        :param      itr:  The corresponding itr
-        :type       itr:  float
-
-        :param      eigen_value:  The eigen value
-        :type       eigen_value:  float
-
-        :returns:   No return
-        :rtype:     None
-        """
-        idx = self.get_next_slice_idx()
-
-        self.eigen_values[idx] = eigen_value
-        self.effective_index[idx] = self.eigen_value_to_index(eigen_value=eigen_value, itr=itr).real
-
-    def append_eigen_vector(self, eigen_vector: numpy.ndarray) -> None:
-        """
-        Append eigen_vector to the mode. Stored in self.eigen_values.
-
-        :param      eigen_vector:  The eigen vector
-        :type       eigen_vector:  numpy.ndarray
-
-        :returns:   No return
-        :rtype:     None
-        """
-        idx = self.get_next_slice_idx()
-        self.eigen_vectors[idx] = eigen_vector
-
-    def append_next_slice(self, eigen_value: float, eigen_vector: numpy.ndarray, itr: float) -> None:
-        """
-        Append eigen_value to the mode. Stored in self.eigen_values.
-
-        :param      itr:  The corresponding itr
-        :type       itr:  float
-
-        :param      eigen_value:  The eigen value
-        :type       eigen_value:  float
-        :param      eigen_vector:  The eigen vector
-        :type       eigen_vector:  numpy.ndarray
-
-        :returns:   No return
-        :rtype:     None
-        """
-        last_slice = self.get_last_slice_idx()
-        if last_slice > 0:
-            projection_with_previous = abs(eigen_vector.dot(self.last_eigen_vector))
-            if projection_with_previous < 0.5:
-                print(f"Error bad mode matching with {self.label} -> [{last_slice=}] [{projection_with_previous = :.3f}]")
-
-        self.append_eigen_vector(eigen_vector=eigen_vector)
-        self.append_eigen_value(eigen_value=eigen_value, itr=itr)
-
-    @property
-    def last_eigen_vector(self) -> numpy.ndarray:
-        """
-        Return the last eigen vector that was computed.
-
-        :returns:   The eigen vector
-        :rtype:     numpy.ndarray
-        """
-        idx = self.get_last_slice_idx()
-        return self.eigen_vectors[idx]
-
-    @property
-    def last_eigen_value(self) -> float:
-        """
-        Return the last eigen value that was computed.
-
-        :returns:   The eigen value
-        :rtype:     float
-        """
-        idx = self.get_last_slice_idx()
-        return self.eigen_values[idx]
-
-    def compute_fitting_coefficients(self, n_points: int = 10, max_degree: int = None):
-        """
-        Compute the fitting coefficient for the n last points:
-
-        :param      max_degree:  The maximum degree of the fitting, if None is the default one.
-        :type       max_degree:  int
-
-        :param      n_points:  The n last points to evaluate for the fitting
-        :type       n_points:  int
-        """
-        if max_degree is None:
-            max_degree = self.fitting_max_degree
-
-        idx = self.get_next_slice_idx()
-        x = self.itr_list[:idx]
-        y = self.eigen_values[:idx]
-
-        x = x[-n_points:]
-        y = y[-n_points:]
-
-        if max_degree > x.size - 2:
-            max_degree = x.size - 2
-
-        if max_degree < 1:
-            max_degree = 1
-
-        self.fitting_coefficients = numpy.polyfit(x, y, max_degree)
-
-    def evaluate_to_fitting(self, itr_list: float) -> numpy.ndarray:
-        """
-        Return the eigen values the was evaluated ovec the polynomial fitting.
-
-        :param      itr_list:  The itr list
-        :type       itr_list:  numpy.ndarray
-
-        :returns:   The evaluated eigen values
-        :rtype:     numpy.ndarray
-        """
-        assert self.fitting_coefficients is not None, "Error trying the fit the data without having computed the coefficient prior."
-
-        fit_value = numpy.polyval(
-            self.fitting_coefficients,
-            itr_list
-        )
-
-        return fit_value
-
-    def extrapolate_eigen_value(self, itr: float) -> float:
-        """
-        Extrapolate the eigen value of the mode at the given itr value.
-
-        :param      itr:  The itr
-        :type       itr:  float
-
-        :returns:   The evaluated eigen value
-        :rtype:     float
-        """
-        self.compute_fitting_coefficients()
-
-        extrapolated_value = self.evaluate_to_fitting(itr_list=itr)
-
-        if self.save_fittings:
-            slice_number = self.itr_to_slice(itr=itr)
-            self.fit_values[slice_number] = extrapolated_value
-
-        return extrapolated_value
-
-    def extrapolate_eigen_vector(self, itr: float) -> numpy.ndarray:
-        """
-        Extrapolate the eigen vector of the mode at the given itr value.
-        This function dont truly extrapolate it just return the eigen vector
-        which is the closest in term of itr.
-
-        :param      itr:  The itr
-        :type       itr:  float
-
-        :returns:   The evaluated eigen vector
-        :rtype:     numpy.ndarray
-        """
-        slice_number = self.itr_to_slice(itr=itr)
-
-        return self.eigen_vectors[slice_number]
-
-    def itr_to_slice(self, itr: float) -> int:
-        """
-        Return the slice that correspond the closest to the itr value given.
-
-        :param      itr:  The itr
-        :type       itr:  float
-
-        :returns:   The slice number
-        :rtype:     int
-        """
-        closest_idx = (numpy.abs(self.itr_list - itr)).argmin()
-        return closest_idx
-
-    @property
-    def fields(self) -> numpy.ndarray:
-        """
-        Return the fields of the mode, the first axis is the itr_slice
-
-        :returns:   The fields array
-        :rtype:     numpy.ndarray
-        """
-        return self.eigen_vectors.reshape([self.itr_list.size, *self.shape]).real
-
-    @property
-    def get_field(self, itr: float) -> numpy.ndarray:
-        """
-        Return the fields of the mode, the first axis is the itr_slice
-
-        :returns:   The fields array
-        :rtype:     numpy.ndarray
-        """
-        return self.eigen_vectors.reshape([self.itr_list.size, *self.shape]).real
-
-    def render_field(self, itr: float, slice_number, ax: Axis) -> None:
-        """
-        Render the mode field evaluated at a certain itr and on a given ax.
-
-        :param      ax:   The ax to which render the field
-        :type       ax:   { type_description }
-        :param      itr:  The itr
-        :type       itr:  float
-
-        :returns:   No return
-        :rtype:     None
-        """
-        if itr is not None:
-            slice_number = self.itr_to_slice(itr=itr)
-
-        elif slice_number is not None:
-            itr = self.itr_list[slice_number]
-
-        artist = Mesh(
-            scalar=self.fields[slice_number],
-            colormap=BKR,
-        )
-
-        ax.add_artist(artist)
-
-        ax.title = f"{itr = :.4f}, {slice_number = }"
-        ax.equal = True
-
-        ax.colorbar = ColorBar(symmetric=True, position='right')
-
-    def render_effective_index(self, ax: Axis) -> None:
-        """
-        Render the mode field evaluated at a certain itr and on a given ax.
-
-        :param      ax:   The ax to which render the field
-        :type       ax:   { type_description }
-
-        :returns:   No return
-        :rtype:     None
-        """
-        artist = Line(
-            x=self.itr_list,
-            y=self.effective_index,
-        )
-
-        ax.add_artist(artist)
-
-        ax.x_label = 'Inverse taper ratio'
-        ax.y_label = 'Effective index'
-
-    def render_eigen_value(self, ax: Axis) -> None:
-        """
-        Render the mode field evaluated at a certain itr and on a given ax.
-
-        :param      ax:   The ax to which render the field
-        :type       ax:   { type_description }
-
-        :returns:   No return
-        :rtype:     None
-        """
-
-        artist = Line(
-            x=self.itr_list,
-            y=self.eigen_values.real,
-        )
-
-        ax.add_artist(artist)
-
-        ax.x_label = 'Inverse taper ratio'
-        ax.y_label = 'Effective index'
-
-        # if ax is None:
-        #     figure, ax = plt.subplots(1, 1, figsize=(12, 8))
-
-        # ax.plot(self.itr_list, self.eigen_values.real)
-        # ax.set_xlabel('Inverse taper ratio')
-        # ax.set_ylabel('Eigen values')
-        # if self.save_fittings:
-        #     ax.plot(self.itr_list, self.fit_values.real, 'x')
-
-    def plot(self, itr: float = None, slice_number: float = None, show_field: bool = True, show_index: bool = False, show_eigen_value: bool = False) -> None:
-        """
-        Render the mode field at given itr plus the effective index associated eigen value.
-
-        :param      itr:  The itr
-        :type       itr:  float
-
-        :returns:   { description_of_the_return_value }
-        :rtype:     None
-        """
-        figure = Scene2D(unit_size=(3, 3))
-
-        plot_number = 0
-        if show_field:
-            ax = Axis(row=0, col=plot_number)
-            figure.add_axes(ax)
-            self.render_field(ax=ax, itr=itr, slice_number=slice_number)
-            plot_number += 1
-
-        if show_index:
-            ax = Axis(row=0, col=plot_number)
-            figure.add_axes(ax)
-            self.render_effective_index(ax=ax)
-            plot_number += 1
-
-        if show_eigen_value:
-            ax = Axis(row=0, col=plot_number)
-            figure.add_axes(ax)
-            self.render_eigen_value(ax=ax)
-            plot_number += 1
-
-        return figure
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+# Standard imports
+import numpy
+from dataclasses import dataclass
+from MPSPlots.CMAP import BKR
+from MPSPlots.render2D import Scene2D, Axis, Line, Mesh, ColorBar
+
+
+@dataclass
+class ModeSolver():
+    itr_list: numpy.ndarray
+    """ List of value representing the inverse taper ratio """
+    shape: tuple
+    """ Tuple representing the shape of the mesh from which the eigen matrix is constructred """
+    wavelength: float
+    """ Value representing the wavelength of the simulation """
+    label: str = ''
+    """ Label of the mode """
+    fitting_max_degree: int = 5
+    """ Max value for the coefficient fitting algorithm for eigen value extrapolation """
+    save_fittings: bool = True
+
+    def __post_init__(self):
+        self.wavenumber = 2 * numpy.pi / self.wavelength
+        self.construct_initial_arrays()
+        self.fitting_coefficients = None
+
+    def construct_initial_arrays(self) -> None:
+        """
+        Construct the arrays where the eigen values and vectors will be stored.
+
+        :returns:   No return
+        :rtype:     None
+        """
+        eigen_vector_size = self.shape[0] * self.shape[1]
+        self.eigen_vectors = numpy.full([self.itr_list.size, eigen_vector_size], numpy.nan)
+        self.eigen_values = numpy.full(self.itr_list.size, numpy.nan)
+        self.effective_index = numpy.full(self.itr_list.size, numpy.nan)
+        self.fit_values = numpy.full(self.itr_list.size, numpy.nan)
+
+        self.eigen_values = self.eigen_values.astype(complex)
+        self.effective_index = self.effective_index
+        self.eigen_vectors = self.eigen_vectors.astype(complex)
+        self.fit_values = self.fit_values.astype(complex)
+
+    def index_to_eigen_value(self, itr: float, index: float) -> float:
+        """
+        Return the eigen value associated to the given effective index
+
+        :param      index:  The mode effective index
+        :type       index:  float
+
+        :returns:   The associated eigen value
+        :rtype:     float
+        """
+        return (self.wavenumber * index * itr)**2
+
+    def eigen_value_to_index(self, eigen_value: float, itr: float) -> float:
+        """
+        Return the effective index associated toe the given eigen value.
+
+        :param      eigen_value:  The eigen value
+        :type       eigen_value:  float
+        :param      itr:          The itr
+        :type       itr:          float
+
+        :returns:   The associated effective index
+        :rtype:     float
+        """
+        return numpy.sqrt(eigen_value) / self.wavenumber / itr
+
+    def get_next_slice_idx(self) -> int:
+        """
+        Return the index of the next slice that will be computed.
+
+        :returns:   The next slice index.
+        :rtype:     int
+        """
+        non_nan_idx = numpy.argwhere(~numpy.isnan(self.eigen_values))
+        return non_nan_idx.size
+
+    def get_last_slice_idx(self) -> int:
+        """
+        Return the index of the last slice that was computed.
+
+        :returns:   The last slice index.
+        :rtype:     int
+        """
+        next_slice_idx = self.get_next_slice_idx()
+        return next_slice_idx - 1
+
+    def append_eigen_value(self, itr: float, eigen_value: float) -> None:
+        """
+        Append eigen_value to the mode. Stored in self.eigen_values.
+
+        :param      itr:  The corresponding itr
+        :type       itr:  float
+
+        :param      eigen_value:  The eigen value
+        :type       eigen_value:  float
+
+        :returns:   No return
+        :rtype:     None
+        """
+        idx = self.get_next_slice_idx()
+
+        self.eigen_values[idx] = eigen_value
+        self.effective_index[idx] = self.eigen_value_to_index(eigen_value=eigen_value, itr=itr).real
+
+    def append_eigen_vector(self, eigen_vector: numpy.ndarray) -> None:
+        """
+        Append eigen_vector to the mode. Stored in self.eigen_values.
+
+        :param      eigen_vector:  The eigen vector
+        :type       eigen_vector:  numpy.ndarray
+
+        :returns:   No return
+        :rtype:     None
+        """
+        idx = self.get_next_slice_idx()
+        self.eigen_vectors[idx] = eigen_vector
+
+    def append_next_slice(self, eigen_value: float, eigen_vector: numpy.ndarray, itr: float) -> None:
+        """
+        Append eigen_value to the mode. Stored in self.eigen_values.
+
+        :param      itr:  The corresponding itr
+        :type       itr:  float
+
+        :param      eigen_value:  The eigen value
+        :type       eigen_value:  float
+        :param      eigen_vector:  The eigen vector
+        :type       eigen_vector:  numpy.ndarray
+
+        :returns:   No return
+        :rtype:     None
+        """
+        last_slice = self.get_last_slice_idx()
+        if last_slice > 0:
+            projection_with_previous = abs(eigen_vector.dot(self.last_eigen_vector))
+            if projection_with_previous < 0.5:
+                print(f"Error bad mode matching with {self.label} -> [{last_slice=}] [{projection_with_previous = :.3f}]")
+
+        self.append_eigen_vector(eigen_vector=eigen_vector)
+        self.append_eigen_value(eigen_value=eigen_value, itr=itr)
+
+    @property
+    def last_eigen_vector(self) -> numpy.ndarray:
+        """
+        Return the last eigen vector that was computed.
+
+        :returns:   The eigen vector
+        :rtype:     numpy.ndarray
+        """
+        idx = self.get_last_slice_idx()
+        return self.eigen_vectors[idx]
+
+    @property
+    def last_eigen_value(self) -> float:
+        """
+        Return the last eigen value that was computed.
+
+        :returns:   The eigen value
+        :rtype:     float
+        """
+        idx = self.get_last_slice_idx()
+        return self.eigen_values[idx]
+
+    def compute_fitting_coefficients(self, n_points: int = 10, max_degree: int = None):
+        """
+        Compute the fitting coefficient for the n last points:
+
+        :param      max_degree:  The maximum degree of the fitting, if None is the default one.
+        :type       max_degree:  int
+
+        :param      n_points:  The n last points to evaluate for the fitting
+        :type       n_points:  int
+        """
+        if max_degree is None:
+            max_degree = self.fitting_max_degree
+
+        idx = self.get_next_slice_idx()
+        x = self.itr_list[:idx]
+        y = self.eigen_values[:idx]
+
+        x = x[-n_points:]
+        y = y[-n_points:]
+
+        if max_degree > x.size - 2:
+            max_degree = x.size - 2
+
+        if max_degree < 1:
+            max_degree = 1
+
+        self.fitting_coefficients = numpy.polyfit(x, y, max_degree)
+
+    def evaluate_to_fitting(self, itr_list: float) -> numpy.ndarray:
+        """
+        Return the eigen values the was evaluated ovec the polynomial fitting.
+
+        :param      itr_list:  The itr list
+        :type       itr_list:  numpy.ndarray
+
+        :returns:   The evaluated eigen values
+        :rtype:     numpy.ndarray
+        """
+        assert self.fitting_coefficients is not None, "Error trying the fit the data without having computed the coefficient prior."
+
+        fit_value = numpy.polyval(
+            self.fitting_coefficients,
+            itr_list
+        )
+
+        return fit_value
+
+    def extrapolate_eigen_value(self, itr: float) -> float:
+        """
+        Extrapolate the eigen value of the mode at the given itr value.
+
+        :param      itr:  The itr
+        :type       itr:  float
+
+        :returns:   The evaluated eigen value
+        :rtype:     float
+        """
+        self.compute_fitting_coefficients()
+
+        extrapolated_value = self.evaluate_to_fitting(itr_list=itr)
+
+        if self.save_fittings:
+            slice_number = self.itr_to_slice(itr=itr)
+            self.fit_values[slice_number] = extrapolated_value
+
+        return extrapolated_value
+
+    def extrapolate_eigen_vector(self, itr: float) -> numpy.ndarray:
+        """
+        Extrapolate the eigen vector of the mode at the given itr value.
+        This function dont truly extrapolate it just return the eigen vector
+        which is the closest in term of itr.
+
+        :param      itr:  The itr
+        :type       itr:  float
+
+        :returns:   The evaluated eigen vector
+        :rtype:     numpy.ndarray
+        """
+        slice_number = self.itr_to_slice(itr=itr)
+
+        return self.eigen_vectors[slice_number]
+
+    def itr_to_slice(self, itr: float) -> int:
+        """
+        Return the slice that correspond the closest to the itr value given.
+
+        :param      itr:  The itr
+        :type       itr:  float
+
+        :returns:   The slice number
+        :rtype:     int
+        """
+        closest_idx = (numpy.abs(self.itr_list - itr)).argmin()
+        return closest_idx
+
+    @property
+    def fields(self) -> numpy.ndarray:
+        """
+        Return the fields of the mode, the first axis is the itr_slice
+
+        :returns:   The fields array
+        :rtype:     numpy.ndarray
+        """
+        return self.eigen_vectors.reshape([self.itr_list.size, *self.shape]).real
+
+    @property
+    def get_field(self, itr: float) -> numpy.ndarray:
+        """
+        Return the fields of the mode, the first axis is the itr_slice
+
+        :returns:   The fields array
+        :rtype:     numpy.ndarray
+        """
+        return self.eigen_vectors.reshape([self.itr_list.size, *self.shape]).real
+
+    def render_field(self, itr: float, slice_number, ax: Axis) -> None:
+        """
+        Render the mode field evaluated at a certain itr and on a given ax.
+
+        :param      ax:   The ax to which render the field
+        :type       ax:   { type_description }
+        :param      itr:  The itr
+        :type       itr:  float
+
+        :returns:   No return
+        :rtype:     None
+        """
+        if itr is not None:
+            slice_number = self.itr_to_slice(itr=itr)
+
+        elif slice_number is not None:
+            itr = self.itr_list[slice_number]
+
+        artist = Mesh(
+            scalar=self.fields[slice_number],
+            colormap=BKR,
+        )
+
+        ax.add_artist(artist)
+
+        ax.title = f"{itr = :.4f}, {slice_number = }"
+        ax.equal = True
+
+        ax.colorbar = ColorBar(symmetric=True, position='right')
+
+    def render_effective_index(self, ax: Axis) -> None:
+        """
+        Render the mode field evaluated at a certain itr and on a given ax.
+
+        :param      ax:   The ax to which render the field
+        :type       ax:   { type_description }
+
+        :returns:   No return
+        :rtype:     None
+        """
+        artist = Line(
+            x=self.itr_list,
+            y=self.effective_index,
+        )
+
+        ax.add_artist(artist)
+
+        ax.x_label = 'Inverse taper ratio'
+        ax.y_label = 'Effective index'
+
+    def render_eigen_value(self, ax: Axis) -> None:
+        """
+        Render the mode field evaluated at a certain itr and on a given ax.
+
+        :param      ax:   The ax to which render the field
+        :type       ax:   { type_description }
+
+        :returns:   No return
+        :rtype:     None
+        """
+
+        artist = Line(
+            x=self.itr_list,
+            y=self.eigen_values.real,
+        )
+
+        ax.add_artist(artist)
+
+        ax.x_label = 'Inverse taper ratio'
+        ax.y_label = 'Effective index'
+
+        # if ax is None:
+        #     figure, ax = plt.subplots(1, 1, figsize=(12, 8))
+
+        # ax.plot(self.itr_list, self.eigen_values.real)
+        # ax.set_xlabel('Inverse taper ratio')
+        # ax.set_ylabel('Eigen values')
+        # if self.save_fittings:
+        #     ax.plot(self.itr_list, self.fit_values.real, 'x')
+
+    def plot(self, itr: float = None, slice_number: float = None, show_field: bool = True, show_index: bool = False, show_eigen_value: bool = False) -> None:
+        """
+        Render the mode field at given itr plus the effective index associated eigen value.
+
+        :param      itr:  The itr
+        :type       itr:  float
+
+        :returns:   { description_of_the_return_value }
+        :rtype:     None
+        """
+        figure = Scene2D(unit_size=(3, 3))
+
+        plot_number = 0
+        if show_field:
+            ax = Axis(row=0, col=plot_number)
+            figure.add_axes(ax)
+            self.render_field(ax=ax, itr=itr, slice_number=slice_number)
+            plot_number += 1
+
+        if show_index:
+            ax = Axis(row=0, col=plot_number)
+            figure.add_axes(ax)
+            self.render_effective_index(ax=ax)
+            plot_number += 1
+
+        if show_eigen_value:
+            ax = Axis(row=0, col=plot_number)
+            figure.add_axes(ax)
+            self.render_eigen_value(ax=ax)
+            plot_number += 1
+
+        return figure
```

## docs/source/conf.py

 * *Ordering differences only*

```diff
@@ -1,187 +1,187 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import sys
-from sphinx_gallery.sorting import FileNameSortKey
-from sphinx_gallery.sorting import ExplicitOrder
-from packaging.version import parse
-from MPSPlots.styles import use_mpsplots_style
-
-
-from SuPyMode.directories import (
-    project_path,
-    doc_css_path,
-    version_path,
-)
-
-
-sys.path.insert(0, project_path)
-sys.path.insert(0, project_path.joinpath('SuPyMode'))
-
-
-def setup(app):
-    app.add_css_file(str(doc_css_path))
-
-
-autodoc_mock_imports = [
-    'numpy',
-    'matplotlib',
-    'pyvista',
-    'PyOptik',
-    'PyFinitDiff',
-    'mayavi',
-    'scipy'
-    'numpydoc',
-    'MPSPlots',
-    'FiberFusing',
-    'SuPyMode.binary',
-    'SuPyMode.tools'
-]
-
-
-project = 'SuPyMode'
-copyright = '2021, Martin Poinsinet de Sivry-Houle'
-author = 'Martin Poinsinet de Sivry-Houle'
-
-
-with open(version_path, "r+") as f:
-    version = release = f.read()
-
-
-extensions = [
-    'sphinx.ext.mathjax',
-    'numpydoc',
-    'sphinx_gallery.gen_gallery',
-    'pyvista.ext.plot_directive',
-]
-
-
-def reset_mpl(gallery_conf, fname):
-    use_mpsplots_style()
-
-
-try:
-    import pyvista
-    if sys.platform in ["linux", "linux2"]:
-        pyvista.start_xvfb()  # Works only on linux system!
-except ImportError:
-    print('Could not load pyvista library for 3D rendering')
-
-subsection_order = ExplicitOrder(
-    ["../examples/basic", "../examples/validation"]
-)
-
-sphinx_gallery_conf = {
-    'examples_dirs': '../examples',
-    'gallery_dirs': "gallery",
-    "subsection_order": subsection_order,
-    'image_scrapers': ('matplotlib', 'pyvista'),
-    'ignore_pattern': '/__',
-    'plot_gallery': True,
-    'thumbnail_size': [600, 600],
-    'download_all_examples': False,
-    'reset_modules': reset_mpl,
-    'line_numbers': False,
-    'remove_config_comments': True,
-    'within_subsection_order': FileNameSortKey,
-    'capture_repr': ('_repr_html_', '__repr__'),
-    'nested_sections': True,
-}
-
-
-autodoc_default_options = {
-    'members': False,
-    'members-order': 'bysource',
-    'undoc-members': False,
-    'show-inheritance': True,
-}
-
-numpydoc_show_class_members = False
-
-source_suffix = '.rst'
-
-master_doc = 'index'
-
-language = 'en'
-
-highlight_language = 'python3'
-
-html_theme = "pydata_sphinx_theme"
-
-# -- Options for HTML output -------------------------------------------------
-# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output
-
-exclude_trees = []
-default_role = "autolink"
-pygments_style = "sphinx"
-
-# -- Sphinx-gallery configuration --------------------------------------------
-
-v = parse(release)
-if v.release is None:
-    raise ValueError(f"Ill-formed version: {version!r}. Version should follow PEP440")
-
-if v.is_devrelease:
-    binder_branch = "main"
-else:
-    major, minor = v.release[:2]
-    binder_branch = f"v{major}.{minor}.x"
-
-html_theme_options = {
-    # Navigation bar
-    "logo": {
-        "alt_text": "SuPyMode's logo",
-        "text": "SuPyMode",
-        "link": "https://supymodes.readthedocs.io/en/latest/",
-    },
-    "icon_links": [
-        {
-            "name": "GitHub",
-            "url": "https://github.com/MartinPdeS/SuPyMode",
-            "icon": "fa-brands fa-github",
-        },
-        {
-            "name": "PyPI",
-            "url": "https://pypi.org/project/supymode/",
-            "icon": "fa-solid fa-box",
-        },
-    ],
-    "navbar_align": "left",
-    "navbar_end": ["version-switcher", "navbar-icon-links"],
-    "show_prev_next": False,
-    "show_version_warning_banner": True,
-    # Footer
-    "footer_start": ["copyright"],
-    "footer_end": ["sphinx-version", "theme-version"],
-    # Other
-    "pygment_light_style": "default",
-    "pygment_dark_style": "github-dark",
-}
-
-htmlhelp_basename = 'SuPyModedoc'
-
-latex_elements = {}
-
-
-latex_documents = [
-    (master_doc, 'SuPyMode.tex', 'SuPyMode Documentation',
-     'Martin Poinsinet de Sivry-Houle', 'manual'),
-]
-
-man_pages = [
-    (master_doc, 'supymode', 'SuPyMode Documentation',
-     [author], 1)
-]
-
-texinfo_documents = [
-    (master_doc, 'SuPyMode', 'SuPyMode Documentation',
-     author, 'SuPyMode', 'One line description of project.',
-     'Miscellaneous'),
-]
-
-epub_title = project
-
-html_static_path = ['_static']
-templates_path = ['_templates']
-html_css_files = ['default.css']
-epub_exclude_files = ['search.html']
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+import sys
+from sphinx_gallery.sorting import FileNameSortKey
+from sphinx_gallery.sorting import ExplicitOrder
+from packaging.version import parse
+from MPSPlots.styles import use_mpsplots_style
+
+
+from SuPyMode.directories import (
+    project_path,
+    doc_css_path,
+    version_path,
+)
+
+
+sys.path.insert(0, project_path)
+sys.path.insert(0, project_path.joinpath('SuPyMode'))
+
+
+def setup(app):
+    app.add_css_file(str(doc_css_path))
+
+
+autodoc_mock_imports = [
+    'numpy',
+    'matplotlib',
+    'pyvista',
+    'PyOptik',
+    'PyFinitDiff',
+    'mayavi',
+    'scipy'
+    'numpydoc',
+    'MPSPlots',
+    'FiberFusing',
+    'SuPyMode.binary',
+    'SuPyMode.tools'
+]
+
+
+project = 'SuPyMode'
+copyright = '2021, Martin Poinsinet de Sivry-Houle'
+author = 'Martin Poinsinet de Sivry-Houle'
+
+
+with open(version_path, "r+") as f:
+    version = release = f.read()
+
+
+extensions = [
+    'sphinx.ext.mathjax',
+    'numpydoc',
+    'sphinx_gallery.gen_gallery',
+    'pyvista.ext.plot_directive',
+]
+
+
+def reset_mpl(gallery_conf, fname):
+    use_mpsplots_style()
+
+
+try:
+    import pyvista
+    if sys.platform in ["linux", "linux2"]:
+        pyvista.start_xvfb()  # Works only on linux system!
+except ImportError:
+    print('Could not load pyvista library for 3D rendering')
+
+subsection_order = ExplicitOrder(
+    ["../examples/basic", "../examples/validation"]
+)
+
+sphinx_gallery_conf = {
+    'examples_dirs': '../examples',
+    'gallery_dirs': "gallery",
+    "subsection_order": subsection_order,
+    'image_scrapers': ('matplotlib', 'pyvista'),
+    'ignore_pattern': '/__',
+    'plot_gallery': True,
+    'thumbnail_size': [600, 600],
+    'download_all_examples': False,
+    'reset_modules': reset_mpl,
+    'line_numbers': False,
+    'remove_config_comments': True,
+    'within_subsection_order': FileNameSortKey,
+    'capture_repr': ('_repr_html_', '__repr__'),
+    'nested_sections': True,
+}
+
+
+autodoc_default_options = {
+    'members': False,
+    'members-order': 'bysource',
+    'undoc-members': False,
+    'show-inheritance': True,
+}
+
+numpydoc_show_class_members = False
+
+source_suffix = '.rst'
+
+master_doc = 'index'
+
+language = 'en'
+
+highlight_language = 'python3'
+
+html_theme = "pydata_sphinx_theme"
+
+# -- Options for HTML output -------------------------------------------------
+# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output
+
+exclude_trees = []
+default_role = "autolink"
+pygments_style = "sphinx"
+
+# -- Sphinx-gallery configuration --------------------------------------------
+
+v = parse(release)
+if v.release is None:
+    raise ValueError(f"Ill-formed version: {version!r}. Version should follow PEP440")
+
+if v.is_devrelease:
+    binder_branch = "main"
+else:
+    major, minor = v.release[:2]
+    binder_branch = f"v{major}.{minor}.x"
+
+html_theme_options = {
+    # Navigation bar
+    "logo": {
+        "alt_text": "SuPyMode's logo",
+        "text": "SuPyMode",
+        "link": "https://supymodes.readthedocs.io/en/latest/",
+    },
+    "icon_links": [
+        {
+            "name": "GitHub",
+            "url": "https://github.com/MartinPdeS/SuPyMode",
+            "icon": "fa-brands fa-github",
+        },
+        {
+            "name": "PyPI",
+            "url": "https://pypi.org/project/supymode/",
+            "icon": "fa-solid fa-box",
+        },
+    ],
+    "navbar_align": "left",
+    "navbar_end": ["version-switcher", "navbar-icon-links"],
+    "show_prev_next": False,
+    "show_version_warning_banner": True,
+    # Footer
+    "footer_start": ["copyright"],
+    "footer_end": ["sphinx-version", "theme-version"],
+    # Other
+    "pygment_light_style": "default",
+    "pygment_dark_style": "github-dark",
+}
+
+htmlhelp_basename = 'SuPyModedoc'
+
+latex_elements = {}
+
+
+latex_documents = [
+    (master_doc, 'SuPyMode.tex', 'SuPyMode Documentation',
+     'Martin Poinsinet de Sivry-Houle', 'manual'),
+]
+
+man_pages = [
+    (master_doc, 'supymode', 'SuPyMode Documentation',
+     [author], 1)
+]
+
+texinfo_documents = [
+    (master_doc, 'SuPyMode', 'SuPyMode Documentation',
+     author, 'SuPyMode', 'One line description of project.',
+     'Miscellaneous'),
+]
+
+epub_title = project
+
+html_static_path = ['_static']
+templates_path = ['_templates']
+html_css_files = ['default.css']
+epub_exclude_files = ['search.html']
```

## extern/eigen/debug/gdb/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-# Intentionally empty
+# Intentionally empty
```

## extern/eigen/debug/gdb/printers.py

 * *Ordering differences only*

```diff
@@ -1,314 +1,314 @@
-# -*- coding: utf-8 -*-
-# This file is part of Eigen, a lightweight C++ template library
-# for linear algebra.
-#
-# Copyright (C) 2009 Benjamin Schindler <bschindler@inf.ethz.ch>
-#
-# This Source Code Form is subject to the terms of the Mozilla Public
-# License, v. 2.0. If a copy of the MPL was not distributed with this
-# file, You can obtain one at http://mozilla.org/MPL/2.0/.
-
-# Pretty printers for Eigen::Matrix
-# This is still pretty basic as the python extension to gdb is still pretty basic. 
-# It cannot handle complex eigen types and it doesn't support many of the other eigen types
-# This code supports fixed size as well as dynamic size matrices
-
-# To use it:
-#
-# * Create a directory and put the file as well as an empty __init__.py in 
-#   that directory.
-# * Create a ~/.gdbinit file, that contains the following:
-#      python
-#      import sys
-#      sys.path.insert(0, '/path/to/eigen/printer/directory')
-#      from printers import register_eigen_printers
-#      register_eigen_printers (None)
-#      end
-
-import gdb
-import re
-import itertools
-from bisect import bisect_left
-
-# Basic row/column iteration code for use with Sparse and Dense matrices
-class _MatrixEntryIterator(object):
-	
-	def __init__ (self, rows, cols, rowMajor):
-		self.rows = rows
-		self.cols = cols
-		self.currentRow = 0
-		self.currentCol = 0
-		self.rowMajor = rowMajor
-
-	def __iter__ (self):
-		return self
-
-	def next(self):
-                return self.__next__()  # Python 2.x compatibility
-
-	def __next__(self):
-		row = self.currentRow
-		col = self.currentCol
-		if self.rowMajor == 0:
-			if self.currentCol >= self.cols:
-				raise StopIteration
-				
-			self.currentRow = self.currentRow + 1
-			if self.currentRow >= self.rows:
-				self.currentRow = 0
-				self.currentCol = self.currentCol + 1
-		else:
-			if self.currentRow >= self.rows:
-				raise StopIteration
-				
-			self.currentCol = self.currentCol + 1
-			if self.currentCol >= self.cols:
-				self.currentCol = 0
-				self.currentRow = self.currentRow + 1
-
-		return (row, col)
-
-class EigenMatrixPrinter:
-	"Print Eigen Matrix or Array of some kind"
-
-	def __init__(self, variety, val):
-		"Extract all the necessary information"
-		
-		# Save the variety (presumably "Matrix" or "Array") for later usage
-		self.variety = variety
-		
-		# The gdb extension does not support value template arguments - need to extract them by hand
-		type = val.type
-		if type.code == gdb.TYPE_CODE_REF:
-			type = type.target()
-		self.type = type.unqualified().strip_typedefs()
-		tag = self.type.tag
-		regex = re.compile('\<.*\>')
-		m = regex.findall(tag)[0][1:-1]
-		template_params = m.split(',')
-		template_params = [x.replace(" ", "") for x in template_params]
-		
-		if template_params[1] == '-0x00000000000000001' or template_params[1] == '-0x000000001' or template_params[1] == '-1':
-			self.rows = val['m_storage']['m_rows']
-		else:
-			self.rows = int(template_params[1])
-		
-		if template_params[2] == '-0x00000000000000001' or template_params[2] == '-0x000000001' or template_params[2] == '-1':
-			self.cols = val['m_storage']['m_cols']
-		else:
-			self.cols = int(template_params[2])
-		
-		self.options = 0 # default value
-		if len(template_params) > 3:
-			self.options = template_params[3];
-		
-		self.rowMajor = (int(self.options) & 0x1)
-		
-		self.innerType = self.type.template_argument(0)
-		
-		self.val = val
-		
-		# Fixed size matrices have a struct as their storage, so we need to walk through this
-		self.data = self.val['m_storage']['m_data']
-		if self.data.type.code == gdb.TYPE_CODE_STRUCT:
-			self.data = self.data['array']
-			self.data = self.data.cast(self.innerType.pointer())
-			
-	class _iterator(_MatrixEntryIterator):
-		def __init__ (self, rows, cols, dataPtr, rowMajor):
-			super(EigenMatrixPrinter._iterator, self).__init__(rows, cols, rowMajor)
-
-			self.dataPtr = dataPtr
-
-		def __next__(self):
-			
-			row, col = super(EigenMatrixPrinter._iterator, self).__next__()
-			
-			item = self.dataPtr.dereference()
-			self.dataPtr = self.dataPtr + 1
-			if (self.cols == 1): #if it's a column vector
-				return ('[%d]' % (row,), item)
-			elif (self.rows == 1): #if it's a row vector
-				return ('[%d]' % (col,), item)
-			return ('[%d,%d]' % (row, col), item)
-			
-	def children(self):
-		
-		return self._iterator(self.rows, self.cols, self.data, self.rowMajor)
-		
-	def to_string(self):
-		return "Eigen::%s<%s,%d,%d,%s> (data ptr: %s)" % (self.variety, self.innerType, self.rows, self.cols, "RowMajor" if self.rowMajor else  "ColMajor", self.data)
-
-class EigenSparseMatrixPrinter:
-	"Print an Eigen SparseMatrix"
-
-	def __init__(self, val):
-		"Extract all the necessary information"
-
-		type = val.type
-		if type.code == gdb.TYPE_CODE_REF:
-			type = type.target()
-		self.type = type.unqualified().strip_typedefs()
-		tag = self.type.tag
-		regex = re.compile('\<.*\>')
-		m = regex.findall(tag)[0][1:-1]
-		template_params = m.split(',')
-		template_params = [x.replace(" ", "") for x in template_params]
-
-		self.options = 0
-		if len(template_params) > 1:
-			self.options = template_params[1];
-		
-		self.rowMajor = (int(self.options) & 0x1)
-		
-		self.innerType = self.type.template_argument(0)
-		
-		self.val = val
-
-		self.data = self.val['m_data']
-		self.data = self.data.cast(self.innerType.pointer())
-
-	class _iterator(_MatrixEntryIterator):
-		def __init__ (self, rows, cols, val, rowMajor):
-			super(EigenSparseMatrixPrinter._iterator, self).__init__(rows, cols, rowMajor)
-
-			self.val = val
-			
-		def __next__(self):
-			
-			row, col = super(EigenSparseMatrixPrinter._iterator, self).__next__()
-				
-			# repeat calculations from SparseMatrix.h:
-			outer = row if self.rowMajor else col
-			inner = col if self.rowMajor else row
-			start = self.val['m_outerIndex'][outer]
-			end = ((start + self.val['m_innerNonZeros'][outer]) if self.val['m_innerNonZeros'] else
-			       self.val['m_outerIndex'][outer+1])
-
-			# and from CompressedStorage.h:
-			data = self.val['m_data']
-			if start >= end:
-				item = 0
-			elif (end > start) and (inner == data['m_indices'][end-1]):
-				item = data['m_values'][end-1]
-			else:
-				# create Python index list from the target range within m_indices
-				indices = [data['m_indices'][x] for x in range(int(start), int(end)-1)]
-				# find the index with binary search
-				idx = int(start) + bisect_left(indices, inner)
-				if ((idx < end) and (data['m_indices'][idx] == inner)):
-					item = data['m_values'][idx]
-				else:
-					item = 0
-
-			return ('[%d,%d]' % (row, col), item)
-
-	def children(self):
-		if self.data:
-			return self._iterator(self.rows(), self.cols(), self.val, self.rowMajor)
-
-		return iter([])   # empty matrix, for now
-
-
-	def rows(self):
-		return self.val['m_outerSize'] if self.rowMajor else self.val['m_innerSize']
-
-	def cols(self):
-		return self.val['m_innerSize'] if self.rowMajor else self.val['m_outerSize']
-
-	def to_string(self):
-
-		if self.data:
-			status = ("not compressed" if self.val['m_innerNonZeros'] else "compressed")
-		else:
-			status = "empty"
-		dimensions  = "%d x %d" % (self.rows(), self.cols())
-		layout      = "row" if self.rowMajor else "column"
-
-		return "Eigen::SparseMatrix<%s>, %s, %s major, %s" % (
-			self.innerType, dimensions, layout, status )
-
-class EigenQuaternionPrinter:
-	"Print an Eigen Quaternion"
-	
-	def __init__(self, val):
-		"Extract all the necessary information"
-		# The gdb extension does not support value template arguments - need to extract them by hand
-		type = val.type
-		if type.code == gdb.TYPE_CODE_REF:
-			type = type.target()
-		self.type = type.unqualified().strip_typedefs()
-		self.innerType = self.type.template_argument(0)
-		self.val = val
-		
-		# Quaternions have a struct as their storage, so we need to walk through this
-		self.data = self.val['m_coeffs']['m_storage']['m_data']['array']
-		self.data = self.data.cast(self.innerType.pointer())
-			
-	class _iterator:
-		def __init__ (self, dataPtr):
-			self.dataPtr = dataPtr
-			self.currentElement = 0
-			self.elementNames = ['x', 'y', 'z', 'w']
-			
-		def __iter__ (self):
-			return self
-	
-		def next(self):
-			return self.__next__()  # Python 2.x compatibility
-
-		def __next__(self):
-			element = self.currentElement
-			
-			if self.currentElement >= 4: #there are 4 elements in a quanternion
-				raise StopIteration
-			
-			self.currentElement = self.currentElement + 1
-			
-			item = self.dataPtr.dereference()
-			self.dataPtr = self.dataPtr + 1
-			return ('[%s]' % (self.elementNames[element],), item)
-			
-	def children(self):
-		
-		return self._iterator(self.data)
-	
-	def to_string(self):
-		return "Eigen::Quaternion<%s> (data ptr: %s)" % (self.innerType, self.data)
-
-def build_eigen_dictionary ():
-	pretty_printers_dict[re.compile('^Eigen::Quaternion<.*>$')] = lambda val: EigenQuaternionPrinter(val)
-	pretty_printers_dict[re.compile('^Eigen::Matrix<.*>$')] = lambda val: EigenMatrixPrinter("Matrix", val)
-	pretty_printers_dict[re.compile('^Eigen::SparseMatrix<.*>$')] = lambda val: EigenSparseMatrixPrinter(val)
-	pretty_printers_dict[re.compile('^Eigen::Array<.*>$')]  = lambda val: EigenMatrixPrinter("Array",  val)
-
-def register_eigen_printers(obj):
-	"Register eigen pretty-printers with objfile Obj"
-
-	if obj == None:
-		obj = gdb
-	obj.pretty_printers.append(lookup_function)
-
-def lookup_function(val):
-	"Look-up and return a pretty-printer that can print va."
-	
-	type = val.type
-	
-	if type.code == gdb.TYPE_CODE_REF:
-		type = type.target()
-	
-	type = type.unqualified().strip_typedefs()
-	
-	typename = type.tag
-	if typename == None:
-		return None
-	
-	for function in pretty_printers_dict:
-		if function.search(typename):
-			return pretty_printers_dict[function](val)
-	
-	return None
-
-pretty_printers_dict = {}
-
-build_eigen_dictionary ()
+# -*- coding: utf-8 -*-
+# This file is part of Eigen, a lightweight C++ template library
+# for linear algebra.
+#
+# Copyright (C) 2009 Benjamin Schindler <bschindler@inf.ethz.ch>
+#
+# This Source Code Form is subject to the terms of the Mozilla Public
+# License, v. 2.0. If a copy of the MPL was not distributed with this
+# file, You can obtain one at http://mozilla.org/MPL/2.0/.
+
+# Pretty printers for Eigen::Matrix
+# This is still pretty basic as the python extension to gdb is still pretty basic. 
+# It cannot handle complex eigen types and it doesn't support many of the other eigen types
+# This code supports fixed size as well as dynamic size matrices
+
+# To use it:
+#
+# * Create a directory and put the file as well as an empty __init__.py in 
+#   that directory.
+# * Create a ~/.gdbinit file, that contains the following:
+#      python
+#      import sys
+#      sys.path.insert(0, '/path/to/eigen/printer/directory')
+#      from printers import register_eigen_printers
+#      register_eigen_printers (None)
+#      end
+
+import gdb
+import re
+import itertools
+from bisect import bisect_left
+
+# Basic row/column iteration code for use with Sparse and Dense matrices
+class _MatrixEntryIterator(object):
+	
+	def __init__ (self, rows, cols, rowMajor):
+		self.rows = rows
+		self.cols = cols
+		self.currentRow = 0
+		self.currentCol = 0
+		self.rowMajor = rowMajor
+
+	def __iter__ (self):
+		return self
+
+	def next(self):
+                return self.__next__()  # Python 2.x compatibility
+
+	def __next__(self):
+		row = self.currentRow
+		col = self.currentCol
+		if self.rowMajor == 0:
+			if self.currentCol >= self.cols:
+				raise StopIteration
+				
+			self.currentRow = self.currentRow + 1
+			if self.currentRow >= self.rows:
+				self.currentRow = 0
+				self.currentCol = self.currentCol + 1
+		else:
+			if self.currentRow >= self.rows:
+				raise StopIteration
+				
+			self.currentCol = self.currentCol + 1
+			if self.currentCol >= self.cols:
+				self.currentCol = 0
+				self.currentRow = self.currentRow + 1
+
+		return (row, col)
+
+class EigenMatrixPrinter:
+	"Print Eigen Matrix or Array of some kind"
+
+	def __init__(self, variety, val):
+		"Extract all the necessary information"
+		
+		# Save the variety (presumably "Matrix" or "Array") for later usage
+		self.variety = variety
+		
+		# The gdb extension does not support value template arguments - need to extract them by hand
+		type = val.type
+		if type.code == gdb.TYPE_CODE_REF:
+			type = type.target()
+		self.type = type.unqualified().strip_typedefs()
+		tag = self.type.tag
+		regex = re.compile('\<.*\>')
+		m = regex.findall(tag)[0][1:-1]
+		template_params = m.split(',')
+		template_params = [x.replace(" ", "") for x in template_params]
+		
+		if template_params[1] == '-0x00000000000000001' or template_params[1] == '-0x000000001' or template_params[1] == '-1':
+			self.rows = val['m_storage']['m_rows']
+		else:
+			self.rows = int(template_params[1])
+		
+		if template_params[2] == '-0x00000000000000001' or template_params[2] == '-0x000000001' or template_params[2] == '-1':
+			self.cols = val['m_storage']['m_cols']
+		else:
+			self.cols = int(template_params[2])
+		
+		self.options = 0 # default value
+		if len(template_params) > 3:
+			self.options = template_params[3];
+		
+		self.rowMajor = (int(self.options) & 0x1)
+		
+		self.innerType = self.type.template_argument(0)
+		
+		self.val = val
+		
+		# Fixed size matrices have a struct as their storage, so we need to walk through this
+		self.data = self.val['m_storage']['m_data']
+		if self.data.type.code == gdb.TYPE_CODE_STRUCT:
+			self.data = self.data['array']
+			self.data = self.data.cast(self.innerType.pointer())
+			
+	class _iterator(_MatrixEntryIterator):
+		def __init__ (self, rows, cols, dataPtr, rowMajor):
+			super(EigenMatrixPrinter._iterator, self).__init__(rows, cols, rowMajor)
+
+			self.dataPtr = dataPtr
+
+		def __next__(self):
+			
+			row, col = super(EigenMatrixPrinter._iterator, self).__next__()
+			
+			item = self.dataPtr.dereference()
+			self.dataPtr = self.dataPtr + 1
+			if (self.cols == 1): #if it's a column vector
+				return ('[%d]' % (row,), item)
+			elif (self.rows == 1): #if it's a row vector
+				return ('[%d]' % (col,), item)
+			return ('[%d,%d]' % (row, col), item)
+			
+	def children(self):
+		
+		return self._iterator(self.rows, self.cols, self.data, self.rowMajor)
+		
+	def to_string(self):
+		return "Eigen::%s<%s,%d,%d,%s> (data ptr: %s)" % (self.variety, self.innerType, self.rows, self.cols, "RowMajor" if self.rowMajor else  "ColMajor", self.data)
+
+class EigenSparseMatrixPrinter:
+	"Print an Eigen SparseMatrix"
+
+	def __init__(self, val):
+		"Extract all the necessary information"
+
+		type = val.type
+		if type.code == gdb.TYPE_CODE_REF:
+			type = type.target()
+		self.type = type.unqualified().strip_typedefs()
+		tag = self.type.tag
+		regex = re.compile('\<.*\>')
+		m = regex.findall(tag)[0][1:-1]
+		template_params = m.split(',')
+		template_params = [x.replace(" ", "") for x in template_params]
+
+		self.options = 0
+		if len(template_params) > 1:
+			self.options = template_params[1];
+		
+		self.rowMajor = (int(self.options) & 0x1)
+		
+		self.innerType = self.type.template_argument(0)
+		
+		self.val = val
+
+		self.data = self.val['m_data']
+		self.data = self.data.cast(self.innerType.pointer())
+
+	class _iterator(_MatrixEntryIterator):
+		def __init__ (self, rows, cols, val, rowMajor):
+			super(EigenSparseMatrixPrinter._iterator, self).__init__(rows, cols, rowMajor)
+
+			self.val = val
+			
+		def __next__(self):
+			
+			row, col = super(EigenSparseMatrixPrinter._iterator, self).__next__()
+				
+			# repeat calculations from SparseMatrix.h:
+			outer = row if self.rowMajor else col
+			inner = col if self.rowMajor else row
+			start = self.val['m_outerIndex'][outer]
+			end = ((start + self.val['m_innerNonZeros'][outer]) if self.val['m_innerNonZeros'] else
+			       self.val['m_outerIndex'][outer+1])
+
+			# and from CompressedStorage.h:
+			data = self.val['m_data']
+			if start >= end:
+				item = 0
+			elif (end > start) and (inner == data['m_indices'][end-1]):
+				item = data['m_values'][end-1]
+			else:
+				# create Python index list from the target range within m_indices
+				indices = [data['m_indices'][x] for x in range(int(start), int(end)-1)]
+				# find the index with binary search
+				idx = int(start) + bisect_left(indices, inner)
+				if ((idx < end) and (data['m_indices'][idx] == inner)):
+					item = data['m_values'][idx]
+				else:
+					item = 0
+
+			return ('[%d,%d]' % (row, col), item)
+
+	def children(self):
+		if self.data:
+			return self._iterator(self.rows(), self.cols(), self.val, self.rowMajor)
+
+		return iter([])   # empty matrix, for now
+
+
+	def rows(self):
+		return self.val['m_outerSize'] if self.rowMajor else self.val['m_innerSize']
+
+	def cols(self):
+		return self.val['m_innerSize'] if self.rowMajor else self.val['m_outerSize']
+
+	def to_string(self):
+
+		if self.data:
+			status = ("not compressed" if self.val['m_innerNonZeros'] else "compressed")
+		else:
+			status = "empty"
+		dimensions  = "%d x %d" % (self.rows(), self.cols())
+		layout      = "row" if self.rowMajor else "column"
+
+		return "Eigen::SparseMatrix<%s>, %s, %s major, %s" % (
+			self.innerType, dimensions, layout, status )
+
+class EigenQuaternionPrinter:
+	"Print an Eigen Quaternion"
+	
+	def __init__(self, val):
+		"Extract all the necessary information"
+		# The gdb extension does not support value template arguments - need to extract them by hand
+		type = val.type
+		if type.code == gdb.TYPE_CODE_REF:
+			type = type.target()
+		self.type = type.unqualified().strip_typedefs()
+		self.innerType = self.type.template_argument(0)
+		self.val = val
+		
+		# Quaternions have a struct as their storage, so we need to walk through this
+		self.data = self.val['m_coeffs']['m_storage']['m_data']['array']
+		self.data = self.data.cast(self.innerType.pointer())
+			
+	class _iterator:
+		def __init__ (self, dataPtr):
+			self.dataPtr = dataPtr
+			self.currentElement = 0
+			self.elementNames = ['x', 'y', 'z', 'w']
+			
+		def __iter__ (self):
+			return self
+	
+		def next(self):
+			return self.__next__()  # Python 2.x compatibility
+
+		def __next__(self):
+			element = self.currentElement
+			
+			if self.currentElement >= 4: #there are 4 elements in a quanternion
+				raise StopIteration
+			
+			self.currentElement = self.currentElement + 1
+			
+			item = self.dataPtr.dereference()
+			self.dataPtr = self.dataPtr + 1
+			return ('[%s]' % (self.elementNames[element],), item)
+			
+	def children(self):
+		
+		return self._iterator(self.data)
+	
+	def to_string(self):
+		return "Eigen::Quaternion<%s> (data ptr: %s)" % (self.innerType, self.data)
+
+def build_eigen_dictionary ():
+	pretty_printers_dict[re.compile('^Eigen::Quaternion<.*>$')] = lambda val: EigenQuaternionPrinter(val)
+	pretty_printers_dict[re.compile('^Eigen::Matrix<.*>$')] = lambda val: EigenMatrixPrinter("Matrix", val)
+	pretty_printers_dict[re.compile('^Eigen::SparseMatrix<.*>$')] = lambda val: EigenSparseMatrixPrinter(val)
+	pretty_printers_dict[re.compile('^Eigen::Array<.*>$')]  = lambda val: EigenMatrixPrinter("Array",  val)
+
+def register_eigen_printers(obj):
+	"Register eigen pretty-printers with objfile Obj"
+
+	if obj == None:
+		obj = gdb
+	obj.pretty_printers.append(lookup_function)
+
+def lookup_function(val):
+	"Look-up and return a pretty-printer that can print va."
+	
+	type = val.type
+	
+	if type.code == gdb.TYPE_CODE_REF:
+		type = type.target()
+	
+	type = type.unqualified().strip_typedefs()
+	
+	typename = type.tag
+	if typename == None:
+		return None
+	
+	for function in pretty_printers_dict:
+		if function.search(typename):
+			return pretty_printers_dict[function](val)
+	
+	return None
+
+pretty_printers_dict = {}
+
+build_eigen_dictionary ()
```

## extern/eigen/scripts/relicense.py

 * *Ordering differences only*

```diff
@@ -1,69 +1,69 @@
-# This file is part of Eigen, a lightweight C++ template library
-# for linear algebra.
-#
-# Copyright (C) 2012 Keir Mierle <mierle@gmail.com>
-#
-# This Source Code Form is subject to the terms of the Mozilla
-# Public License v. 2.0. If a copy of the MPL was not distributed
-# with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
-#
-# Author: mierle@gmail.com (Keir Mierle)
-#
-# Make the long-awaited conversion to MPL.
-
-lgpl3_header = '''
-// Eigen is free software; you can redistribute it and/or
-// modify it under the terms of the GNU Lesser General Public
-// License as published by the Free Software Foundation; either
-// version 3 of the License, or (at your option) any later version.
-//
-// Alternatively, you can redistribute it and/or
-// modify it under the terms of the GNU General Public License as
-// published by the Free Software Foundation; either version 2 of
-// the License, or (at your option) any later version.
-//
-// Eigen is distributed in the hope that it will be useful, but WITHOUT ANY
-// WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
-// FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License or the
-// GNU General Public License for more details.
-//
-// You should have received a copy of the GNU Lesser General Public
-// License and a copy of the GNU General Public License along with
-// Eigen. If not, see <http://www.gnu.org/licenses/>.
-'''
-
-mpl2_header = """
-// This Source Code Form is subject to the terms of the Mozilla
-// Public License v. 2.0. If a copy of the MPL was not distributed
-// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
-"""
-
-import os
-import sys
-
-exclusions = set(['relicense.py'])
-
-def update(text):
-  if text.find(lgpl3_header) == -1:
-    return text, False
-  return text.replace(lgpl3_header, mpl2_header), True
-
-rootdir = sys.argv[1]
-for root, sub_folders, files in os.walk(rootdir):
-    for basename in files:
-        if basename in exclusions:
-          print 'SKIPPED', filename
-          continue
-        filename = os.path.join(root, basename)
-        fo = file(filename)
-        text = fo.read()
-        fo.close()
-
-        text, updated = update(text)
-        if updated:
-          fo = file(filename, "w")
-          fo.write(text)
-          fo.close()
-          print 'UPDATED', filename
-        else:
-          print '       ', filename
+# This file is part of Eigen, a lightweight C++ template library
+# for linear algebra.
+#
+# Copyright (C) 2012 Keir Mierle <mierle@gmail.com>
+#
+# This Source Code Form is subject to the terms of the Mozilla
+# Public License v. 2.0. If a copy of the MPL was not distributed
+# with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
+#
+# Author: mierle@gmail.com (Keir Mierle)
+#
+# Make the long-awaited conversion to MPL.
+
+lgpl3_header = '''
+// Eigen is free software; you can redistribute it and/or
+// modify it under the terms of the GNU Lesser General Public
+// License as published by the Free Software Foundation; either
+// version 3 of the License, or (at your option) any later version.
+//
+// Alternatively, you can redistribute it and/or
+// modify it under the terms of the GNU General Public License as
+// published by the Free Software Foundation; either version 2 of
+// the License, or (at your option) any later version.
+//
+// Eigen is distributed in the hope that it will be useful, but WITHOUT ANY
+// WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
+// FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License or the
+// GNU General Public License for more details.
+//
+// You should have received a copy of the GNU Lesser General Public
+// License and a copy of the GNU General Public License along with
+// Eigen. If not, see <http://www.gnu.org/licenses/>.
+'''
+
+mpl2_header = """
+// This Source Code Form is subject to the terms of the Mozilla
+// Public License v. 2.0. If a copy of the MPL was not distributed
+// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
+"""
+
+import os
+import sys
+
+exclusions = set(['relicense.py'])
+
+def update(text):
+  if text.find(lgpl3_header) == -1:
+    return text, False
+  return text.replace(lgpl3_header, mpl2_header), True
+
+rootdir = sys.argv[1]
+for root, sub_folders, files in os.walk(rootdir):
+    for basename in files:
+        if basename in exclusions:
+          print 'SKIPPED', filename
+          continue
+        filename = os.path.join(root, basename)
+        fo = file(filename)
+        text = fo.read()
+        fo.close()
+
+        text, updated = update(text)
+        if updated:
+          fo = file(filename, "w")
+          fo.write(text)
+          fo.close()
+          print 'UPDATED', filename
+        else:
+          print '       ', filename
```

## extern/pybind11/noxfile.py

 * *Ordering differences only*

```diff
@@ -1,107 +1,107 @@
-import os
-
-import nox
-
-nox.needs_version = ">=2022.1.7"
-nox.options.sessions = ["lint", "tests", "tests_packaging"]
-
-PYTHON_VERSIONS = [
-    "3.6",
-    "3.7",
-    "3.8",
-    "3.9",
-    "3.10",
-    "3.11",
-    "pypy3.7",
-    "pypy3.8",
-    "pypy3.9",
-]
-
-if os.environ.get("CI", None):
-    nox.options.error_on_missing_interpreters = True
-
-
-@nox.session(reuse_venv=True)
-def lint(session: nox.Session) -> None:
-    """
-    Lint the codebase (except for clang-format/tidy).
-    """
-    session.install("pre-commit")
-    session.run("pre-commit", "run", "-a", *session.posargs)
-
-
-@nox.session(python=PYTHON_VERSIONS)
-def tests(session: nox.Session) -> None:
-    """
-    Run the tests (requires a compiler).
-    """
-    tmpdir = session.create_tmp()
-    session.install("cmake")
-    session.install("-r", "tests/requirements.txt")
-    session.run(
-        "cmake",
-        "-S.",
-        f"-B{tmpdir}",
-        "-DPYBIND11_WERROR=ON",
-        "-DDOWNLOAD_CATCH=ON",
-        "-DDOWNLOAD_EIGEN=ON",
-        *session.posargs,
-    )
-    session.run("cmake", "--build", tmpdir)
-    session.run("cmake", "--build", tmpdir, "--config=Release", "--target", "check")
-
-
-@nox.session
-def tests_packaging(session: nox.Session) -> None:
-    """
-    Run the packaging tests.
-    """
-
-    session.install("-r", "tests/requirements.txt")
-    session.run("pytest", "tests/extra_python_package", *session.posargs)
-
-
-@nox.session(reuse_venv=True)
-def docs(session: nox.Session) -> None:
-    """
-    Build the docs. Pass "serve" to serve.
-    """
-
-    session.install("-r", "docs/requirements.txt")
-    session.chdir("docs")
-
-    if "pdf" in session.posargs:
-        session.run("sphinx-build", "-M", "latexpdf", ".", "_build")
-        return
-
-    session.run("sphinx-build", "-M", "html", ".", "_build")
-
-    if "serve" in session.posargs:
-        session.log("Launching docs at http://localhost:8000/ - use Ctrl-C to quit")
-        session.run("python", "-m", "http.server", "8000", "-d", "_build/html")
-    elif session.posargs:
-        session.error("Unsupported argument to docs")
-
-
-@nox.session(reuse_venv=True)
-def make_changelog(session: nox.Session) -> None:
-    """
-    Inspect the closed issues and make entries for a changelog.
-    """
-    session.install("ghapi", "rich")
-    session.run("python", "tools/make_changelog.py")
-
-
-@nox.session(reuse_venv=True)
-def build(session: nox.Session) -> None:
-    """
-    Build SDists and wheels.
-    """
-
-    session.install("build")
-    session.log("Building normal files")
-    session.run("python", "-m", "build", *session.posargs)
-    session.log("Building pybind11-global files (PYBIND11_GLOBAL_SDIST=1)")
-    session.run(
-        "python", "-m", "build", *session.posargs, env={"PYBIND11_GLOBAL_SDIST": "1"}
-    )
+import os
+
+import nox
+
+nox.needs_version = ">=2022.1.7"
+nox.options.sessions = ["lint", "tests", "tests_packaging"]
+
+PYTHON_VERSIONS = [
+    "3.6",
+    "3.7",
+    "3.8",
+    "3.9",
+    "3.10",
+    "3.11",
+    "pypy3.7",
+    "pypy3.8",
+    "pypy3.9",
+]
+
+if os.environ.get("CI", None):
+    nox.options.error_on_missing_interpreters = True
+
+
+@nox.session(reuse_venv=True)
+def lint(session: nox.Session) -> None:
+    """
+    Lint the codebase (except for clang-format/tidy).
+    """
+    session.install("pre-commit")
+    session.run("pre-commit", "run", "-a", *session.posargs)
+
+
+@nox.session(python=PYTHON_VERSIONS)
+def tests(session: nox.Session) -> None:
+    """
+    Run the tests (requires a compiler).
+    """
+    tmpdir = session.create_tmp()
+    session.install("cmake")
+    session.install("-r", "tests/requirements.txt")
+    session.run(
+        "cmake",
+        "-S.",
+        f"-B{tmpdir}",
+        "-DPYBIND11_WERROR=ON",
+        "-DDOWNLOAD_CATCH=ON",
+        "-DDOWNLOAD_EIGEN=ON",
+        *session.posargs,
+    )
+    session.run("cmake", "--build", tmpdir)
+    session.run("cmake", "--build", tmpdir, "--config=Release", "--target", "check")
+
+
+@nox.session
+def tests_packaging(session: nox.Session) -> None:
+    """
+    Run the packaging tests.
+    """
+
+    session.install("-r", "tests/requirements.txt")
+    session.run("pytest", "tests/extra_python_package", *session.posargs)
+
+
+@nox.session(reuse_venv=True)
+def docs(session: nox.Session) -> None:
+    """
+    Build the docs. Pass "serve" to serve.
+    """
+
+    session.install("-r", "docs/requirements.txt")
+    session.chdir("docs")
+
+    if "pdf" in session.posargs:
+        session.run("sphinx-build", "-M", "latexpdf", ".", "_build")
+        return
+
+    session.run("sphinx-build", "-M", "html", ".", "_build")
+
+    if "serve" in session.posargs:
+        session.log("Launching docs at http://localhost:8000/ - use Ctrl-C to quit")
+        session.run("python", "-m", "http.server", "8000", "-d", "_build/html")
+    elif session.posargs:
+        session.error("Unsupported argument to docs")
+
+
+@nox.session(reuse_venv=True)
+def make_changelog(session: nox.Session) -> None:
+    """
+    Inspect the closed issues and make entries for a changelog.
+    """
+    session.install("ghapi", "rich")
+    session.run("python", "tools/make_changelog.py")
+
+
+@nox.session(reuse_venv=True)
+def build(session: nox.Session) -> None:
+    """
+    Build SDists and wheels.
+    """
+
+    session.install("build")
+    session.log("Building normal files")
+    session.run("python", "-m", "build", *session.posargs)
+    session.log("Building pybind11-global files (PYBIND11_GLOBAL_SDIST=1)")
+    session.run(
+        "python", "-m", "build", *session.posargs, env={"PYBIND11_GLOBAL_SDIST": "1"}
+    )
```

## extern/pybind11/setup.py

 * *Ordering differences only*

```diff
@@ -1,150 +1,150 @@
-#!/usr/bin/env python3
-
-# Setup script for PyPI; use CMakeFile.txt to build extension modules
-
-import contextlib
-import os
-import re
-import shutil
-import string
-import subprocess
-import sys
-from pathlib import Path
-from tempfile import TemporaryDirectory
-from typing import Dict, Iterator, List, Union
-
-import setuptools.command.sdist
-
-DIR = Path(__file__).parent.absolute()
-VERSION_REGEX = re.compile(
-    r"^\s*#\s*define\s+PYBIND11_VERSION_([A-Z]+)\s+(.*)$", re.MULTILINE
-)
-VERSION_FILE = Path("pybind11/_version.py")
-COMMON_FILE = Path("include/pybind11/detail/common.h")
-
-
-def build_expected_version_hex(matches: Dict[str, str]) -> str:
-    patch_level_serial = matches["PATCH"]
-    serial = None
-    major = int(matches["MAJOR"])
-    minor = int(matches["MINOR"])
-    flds = patch_level_serial.split(".")
-    if flds:
-        patch = int(flds[0])
-        if len(flds) == 1:
-            level = "0"
-            serial = 0
-        elif len(flds) == 2:
-            level_serial = flds[1]
-            for level in ("a", "b", "c", "dev"):
-                if level_serial.startswith(level):
-                    serial = int(level_serial[len(level) :])
-                    break
-    if serial is None:
-        msg = f'Invalid PYBIND11_VERSION_PATCH: "{patch_level_serial}"'
-        raise RuntimeError(msg)
-    version_hex_str = f"{major:02x}{minor:02x}{patch:02x}{level[:1]}{serial:x}"
-    return f"0x{version_hex_str.upper()}"
-
-
-# PYBIND11_GLOBAL_SDIST will build a different sdist, with the python-headers
-# files, and the sys.prefix files (CMake and headers).
-
-global_sdist = os.environ.get("PYBIND11_GLOBAL_SDIST", False)
-
-setup_py = Path(
-    "tools/setup_global.py.in" if global_sdist else "tools/setup_main.py.in"
-)
-extra_cmd = 'cmdclass["sdist"] = SDist\n'
-
-to_src = (
-    (Path("pyproject.toml"), Path("tools/pyproject.toml")),
-    (Path("setup.py"), setup_py),
-)
-
-
-# Read the listed version
-loc: Dict[str, str] = {}
-code = compile(VERSION_FILE.read_text(encoding="utf-8"), "pybind11/_version.py", "exec")
-exec(code, loc)
-version = loc["__version__"]
-
-# Verify that the version matches the one in C++
-matches = dict(VERSION_REGEX.findall(COMMON_FILE.read_text(encoding="utf8")))
-cpp_version = "{MAJOR}.{MINOR}.{PATCH}".format(**matches)
-if version != cpp_version:
-    msg = f"Python version {version} does not match C++ version {cpp_version}!"
-    raise RuntimeError(msg)
-
-version_hex = matches.get("HEX", "MISSING")
-exp_version_hex = build_expected_version_hex(matches)
-if version_hex != exp_version_hex:
-    msg = f"PYBIND11_VERSION_HEX {version_hex} does not match expected value {exp_version_hex}!"
-    raise RuntimeError(msg)
-
-
-# TODO: use literals & overload (typing extensions or Python 3.8)
-def get_and_replace(
-    filename: Path, binary: bool = False, **opts: str
-) -> Union[bytes, str]:
-    if binary:
-        contents = filename.read_bytes()
-        return string.Template(contents.decode()).substitute(opts).encode()
-
-    return string.Template(filename.read_text()).substitute(opts)
-
-
-# Use our input files instead when making the SDist (and anything that depends
-# on it, like a wheel)
-class SDist(setuptools.command.sdist.sdist):
-    def make_release_tree(self, base_dir: str, files: List[str]) -> None:
-        super().make_release_tree(base_dir, files)
-
-        for to, src in to_src:
-            txt = get_and_replace(src, binary=True, version=version, extra_cmd="")
-
-            dest = Path(base_dir) / to
-
-            # This is normally linked, so unlink before writing!
-            dest.unlink()
-            dest.write_bytes(txt)  # type: ignore[arg-type]
-
-
-# Remove the CMake install directory when done
-@contextlib.contextmanager
-def remove_output(*sources: str) -> Iterator[None]:
-    try:
-        yield
-    finally:
-        for src in sources:
-            shutil.rmtree(src)
-
-
-with remove_output("pybind11/include", "pybind11/share"):
-    # Generate the files if they are not present.
-    with TemporaryDirectory() as tmpdir:
-        cmd = ["cmake", "-S", ".", "-B", tmpdir] + [
-            "-DCMAKE_INSTALL_PREFIX=pybind11",
-            "-DBUILD_TESTING=OFF",
-            "-DPYBIND11_NOPYTHON=ON",
-            "-Dprefix_for_pc_file=${pcfiledir}/../../",
-        ]
-        if "CMAKE_ARGS" in os.environ:
-            fcommand = [
-                c
-                for c in os.environ["CMAKE_ARGS"].split()
-                if "DCMAKE_INSTALL_PREFIX" not in c
-            ]
-            cmd += fcommand
-        subprocess.run(cmd, check=True, cwd=DIR, stdout=sys.stdout, stderr=sys.stderr)
-        subprocess.run(
-            ["cmake", "--install", tmpdir],
-            check=True,
-            cwd=DIR,
-            stdout=sys.stdout,
-            stderr=sys.stderr,
-        )
-
-    txt = get_and_replace(setup_py, version=version, extra_cmd=extra_cmd)
-    code = compile(txt, setup_py, "exec")
-    exec(code, {"SDist": SDist})
+#!/usr/bin/env python3
+
+# Setup script for PyPI; use CMakeFile.txt to build extension modules
+
+import contextlib
+import os
+import re
+import shutil
+import string
+import subprocess
+import sys
+from pathlib import Path
+from tempfile import TemporaryDirectory
+from typing import Dict, Iterator, List, Union
+
+import setuptools.command.sdist
+
+DIR = Path(__file__).parent.absolute()
+VERSION_REGEX = re.compile(
+    r"^\s*#\s*define\s+PYBIND11_VERSION_([A-Z]+)\s+(.*)$", re.MULTILINE
+)
+VERSION_FILE = Path("pybind11/_version.py")
+COMMON_FILE = Path("include/pybind11/detail/common.h")
+
+
+def build_expected_version_hex(matches: Dict[str, str]) -> str:
+    patch_level_serial = matches["PATCH"]
+    serial = None
+    major = int(matches["MAJOR"])
+    minor = int(matches["MINOR"])
+    flds = patch_level_serial.split(".")
+    if flds:
+        patch = int(flds[0])
+        if len(flds) == 1:
+            level = "0"
+            serial = 0
+        elif len(flds) == 2:
+            level_serial = flds[1]
+            for level in ("a", "b", "c", "dev"):
+                if level_serial.startswith(level):
+                    serial = int(level_serial[len(level) :])
+                    break
+    if serial is None:
+        msg = f'Invalid PYBIND11_VERSION_PATCH: "{patch_level_serial}"'
+        raise RuntimeError(msg)
+    version_hex_str = f"{major:02x}{minor:02x}{patch:02x}{level[:1]}{serial:x}"
+    return f"0x{version_hex_str.upper()}"
+
+
+# PYBIND11_GLOBAL_SDIST will build a different sdist, with the python-headers
+# files, and the sys.prefix files (CMake and headers).
+
+global_sdist = os.environ.get("PYBIND11_GLOBAL_SDIST", False)
+
+setup_py = Path(
+    "tools/setup_global.py.in" if global_sdist else "tools/setup_main.py.in"
+)
+extra_cmd = 'cmdclass["sdist"] = SDist\n'
+
+to_src = (
+    (Path("pyproject.toml"), Path("tools/pyproject.toml")),
+    (Path("setup.py"), setup_py),
+)
+
+
+# Read the listed version
+loc: Dict[str, str] = {}
+code = compile(VERSION_FILE.read_text(encoding="utf-8"), "pybind11/_version.py", "exec")
+exec(code, loc)
+version = loc["__version__"]
+
+# Verify that the version matches the one in C++
+matches = dict(VERSION_REGEX.findall(COMMON_FILE.read_text(encoding="utf8")))
+cpp_version = "{MAJOR}.{MINOR}.{PATCH}".format(**matches)
+if version != cpp_version:
+    msg = f"Python version {version} does not match C++ version {cpp_version}!"
+    raise RuntimeError(msg)
+
+version_hex = matches.get("HEX", "MISSING")
+exp_version_hex = build_expected_version_hex(matches)
+if version_hex != exp_version_hex:
+    msg = f"PYBIND11_VERSION_HEX {version_hex} does not match expected value {exp_version_hex}!"
+    raise RuntimeError(msg)
+
+
+# TODO: use literals & overload (typing extensions or Python 3.8)
+def get_and_replace(
+    filename: Path, binary: bool = False, **opts: str
+) -> Union[bytes, str]:
+    if binary:
+        contents = filename.read_bytes()
+        return string.Template(contents.decode()).substitute(opts).encode()
+
+    return string.Template(filename.read_text()).substitute(opts)
+
+
+# Use our input files instead when making the SDist (and anything that depends
+# on it, like a wheel)
+class SDist(setuptools.command.sdist.sdist):
+    def make_release_tree(self, base_dir: str, files: List[str]) -> None:
+        super().make_release_tree(base_dir, files)
+
+        for to, src in to_src:
+            txt = get_and_replace(src, binary=True, version=version, extra_cmd="")
+
+            dest = Path(base_dir) / to
+
+            # This is normally linked, so unlink before writing!
+            dest.unlink()
+            dest.write_bytes(txt)  # type: ignore[arg-type]
+
+
+# Remove the CMake install directory when done
+@contextlib.contextmanager
+def remove_output(*sources: str) -> Iterator[None]:
+    try:
+        yield
+    finally:
+        for src in sources:
+            shutil.rmtree(src)
+
+
+with remove_output("pybind11/include", "pybind11/share"):
+    # Generate the files if they are not present.
+    with TemporaryDirectory() as tmpdir:
+        cmd = ["cmake", "-S", ".", "-B", tmpdir] + [
+            "-DCMAKE_INSTALL_PREFIX=pybind11",
+            "-DBUILD_TESTING=OFF",
+            "-DPYBIND11_NOPYTHON=ON",
+            "-Dprefix_for_pc_file=${pcfiledir}/../../",
+        ]
+        if "CMAKE_ARGS" in os.environ:
+            fcommand = [
+                c
+                for c in os.environ["CMAKE_ARGS"].split()
+                if "DCMAKE_INSTALL_PREFIX" not in c
+            ]
+            cmd += fcommand
+        subprocess.run(cmd, check=True, cwd=DIR, stdout=sys.stdout, stderr=sys.stderr)
+        subprocess.run(
+            ["cmake", "--install", tmpdir],
+            check=True,
+            cwd=DIR,
+            stdout=sys.stdout,
+            stderr=sys.stderr,
+        )
+
+    txt = get_and_replace(setup_py, version=version, extra_cmd=extra_cmd)
+    code = compile(txt, setup_py, "exec")
+    exec(code, {"SDist": SDist})
```

## extern/pybind11/docs/benchmark.py

 * *Ordering differences only*

```diff
@@ -1,87 +1,87 @@
-import datetime as dt
-import os
-import random
-
-nfns = 4  # Functions per class
-nargs = 4  # Arguments per function
-
-
-def generate_dummy_code_pybind11(nclasses=10):
-    decl = ""
-    bindings = ""
-
-    for cl in range(nclasses):
-        decl += f"class cl{cl:03};\n"
-    decl += "\n"
-
-    for cl in range(nclasses):
-        decl += f"class {cl:03} {{\n"
-        decl += "public:\n"
-        bindings += f'    py::class_<cl{cl:03}>(m, "cl{cl:03}")\n'
-        for fn in range(nfns):
-            ret = random.randint(0, nclasses - 1)
-            params = [random.randint(0, nclasses - 1) for i in range(nargs)]
-            decl += f"    cl{ret:03} *fn_{fn:03}("
-            decl += ", ".join(f"cl{p:03} *" for p in params)
-            decl += ");\n"
-            bindings += f'        .def("fn_{fn:03}", &cl{cl:03}::fn_{fn:03})\n'
-        decl += "};\n\n"
-        bindings += "        ;\n"
-
-    result = "#include <pybind11/pybind11.h>\n\n"
-    result += "namespace py = pybind11;\n\n"
-    result += decl + "\n"
-    result += "PYBIND11_MODULE(example, m) {\n"
-    result += bindings
-    result += "}"
-    return result
-
-
-def generate_dummy_code_boost(nclasses=10):
-    decl = ""
-    bindings = ""
-
-    for cl in range(nclasses):
-        decl += f"class cl{cl:03};\n"
-    decl += "\n"
-
-    for cl in range(nclasses):
-        decl += "class cl%03i {\n" % cl
-        decl += "public:\n"
-        bindings += f'    py::class_<cl{cl:03}>("cl{cl:03}")\n'
-        for fn in range(nfns):
-            ret = random.randint(0, nclasses - 1)
-            params = [random.randint(0, nclasses - 1) for i in range(nargs)]
-            decl += f"    cl{ret:03} *fn_{fn:03}("
-            decl += ", ".join(f"cl{p:03} *" for p in params)
-            decl += ");\n"
-            bindings += f'        .def("fn_{fn:03}", &cl{cl:03}::fn_{fn:03}, py::return_value_policy<py::manage_new_object>())\n'
-        decl += "};\n\n"
-        bindings += "        ;\n"
-
-    result = "#include <boost/python.hpp>\n\n"
-    result += "namespace py = boost::python;\n\n"
-    result += decl + "\n"
-    result += "BOOST_PYTHON_MODULE(example) {\n"
-    result += bindings
-    result += "}"
-    return result
-
-
-for codegen in [generate_dummy_code_pybind11, generate_dummy_code_boost]:
-    print("{")
-    for i in range(10):
-        nclasses = 2**i
-        with open("test.cpp", "w") as f:
-            f.write(codegen(nclasses))
-        n1 = dt.datetime.now()
-        os.system(
-            "g++ -Os -shared -rdynamic -undefined dynamic_lookup "
-            "-fvisibility=hidden -std=c++14 test.cpp -I include "
-            "-I /System/Library/Frameworks/Python.framework/Headers -o test.so"
-        )
-        n2 = dt.datetime.now()
-        elapsed = (n2 - n1).total_seconds()
-        size = os.stat("test.so").st_size
-        print("   {%i, %f, %i}," % (nclasses * nfns, elapsed, size))
-    print("}")
+import datetime as dt
+import os
+import random
+
+nfns = 4  # Functions per class
+nargs = 4  # Arguments per function
+
+
+def generate_dummy_code_pybind11(nclasses=10):
+    decl = ""
+    bindings = ""
+
+    for cl in range(nclasses):
+        decl += f"class cl{cl:03};\n"
+    decl += "\n"
+
+    for cl in range(nclasses):
+        decl += f"class {cl:03} {{\n"
+        decl += "public:\n"
+        bindings += f'    py::class_<cl{cl:03}>(m, "cl{cl:03}")\n'
+        for fn in range(nfns):
+            ret = random.randint(0, nclasses - 1)
+            params = [random.randint(0, nclasses - 1) for i in range(nargs)]
+            decl += f"    cl{ret:03} *fn_{fn:03}("
+            decl += ", ".join(f"cl{p:03} *" for p in params)
+            decl += ");\n"
+            bindings += f'        .def("fn_{fn:03}", &cl{cl:03}::fn_{fn:03})\n'
+        decl += "};\n\n"
+        bindings += "        ;\n"
+
+    result = "#include <pybind11/pybind11.h>\n\n"
+    result += "namespace py = pybind11;\n\n"
+    result += decl + "\n"
+    result += "PYBIND11_MODULE(example, m) {\n"
+    result += bindings
+    result += "}"
+    return result
+
+
+def generate_dummy_code_boost(nclasses=10):
+    decl = ""
+    bindings = ""
+
+    for cl in range(nclasses):
+        decl += f"class cl{cl:03};\n"
+    decl += "\n"
+
+    for cl in range(nclasses):
+        decl += "class cl%03i {\n" % cl
+        decl += "public:\n"
+        bindings += f'    py::class_<cl{cl:03}>("cl{cl:03}")\n'
+        for fn in range(nfns):
+            ret = random.randint(0, nclasses - 1)
+            params = [random.randint(0, nclasses - 1) for i in range(nargs)]
+            decl += f"    cl{ret:03} *fn_{fn:03}("
+            decl += ", ".join(f"cl{p:03} *" for p in params)
+            decl += ");\n"
+            bindings += f'        .def("fn_{fn:03}", &cl{cl:03}::fn_{fn:03}, py::return_value_policy<py::manage_new_object>())\n'
+        decl += "};\n\n"
+        bindings += "        ;\n"
+
+    result = "#include <boost/python.hpp>\n\n"
+    result += "namespace py = boost::python;\n\n"
+    result += decl + "\n"
+    result += "BOOST_PYTHON_MODULE(example) {\n"
+    result += bindings
+    result += "}"
+    return result
+
+
+for codegen in [generate_dummy_code_pybind11, generate_dummy_code_boost]:
+    print("{")
+    for i in range(10):
+        nclasses = 2**i
+        with open("test.cpp", "w") as f:
+            f.write(codegen(nclasses))
+        n1 = dt.datetime.now()
+        os.system(
+            "g++ -Os -shared -rdynamic -undefined dynamic_lookup "
+            "-fvisibility=hidden -std=c++14 test.cpp -I include "
+            "-I /System/Library/Frameworks/Python.framework/Headers -o test.so"
+        )
+        n2 = dt.datetime.now()
+        elapsed = (n2 - n1).total_seconds()
+        size = os.stat("test.so").st_size
+        print("   {%i, %f, %i}," % (nclasses * nfns, elapsed, size))
+    print("}")
```

## extern/pybind11/docs/conf.py

 * *Ordering differences only*

```diff
@@ -1,368 +1,368 @@
-#!/usr/bin/env python3
-#
-# pybind11 documentation build configuration file, created by
-# sphinx-quickstart on Sun Oct 11 19:23:48 2015.
-#
-# This file is execfile()d with the current directory set to its
-# containing dir.
-#
-# Note that not all possible configuration values are present in this
-# autogenerated file.
-#
-# All configuration values have a default; values that are commented out
-# serve to show the default.
-
-import os
-import re
-import subprocess
-import sys
-from pathlib import Path
-
-DIR = Path(__file__).parent.resolve()
-
-# If extensions (or modules to document with autodoc) are in another directory,
-# add these directories to sys.path here. If the directory is relative to the
-# documentation root, use os.path.abspath to make it absolute, like shown here.
-# sys.path.insert(0, os.path.abspath('.'))
-
-# -- General configuration ------------------------------------------------
-
-# If your documentation needs a minimal Sphinx version, state it here.
-# needs_sphinx = '1.0'
-
-# Add any Sphinx extension module names here, as strings. They can be
-# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
-# ones.
-extensions = [
-    "breathe",
-    "sphinx_copybutton",
-    "sphinxcontrib.rsvgconverter",
-    "sphinxcontrib.moderncmakedomain",
-]
-
-breathe_projects = {"pybind11": ".build/doxygenxml/"}
-breathe_default_project = "pybind11"
-breathe_domain_by_extension = {"h": "cpp"}
-
-# Add any paths that contain templates here, relative to this directory.
-templates_path = [".templates"]
-
-# The suffix(es) of source filenames.
-# You can specify multiple suffix as a list of string:
-# source_suffix = ['.rst', '.md']
-source_suffix = ".rst"
-
-# The encoding of source files.
-# source_encoding = 'utf-8-sig'
-
-# The master toctree document.
-master_doc = "index"
-
-# General information about the project.
-project = "pybind11"
-copyright = "2017, Wenzel Jakob"
-author = "Wenzel Jakob"
-
-# The version info for the project you're documenting, acts as replacement for
-# |version| and |release|, also used in various other places throughout the
-# built documents.
-
-# Read the listed version
-with open("../pybind11/_version.py") as f:
-    code = compile(f.read(), "../pybind11/_version.py", "exec")
-loc = {}
-exec(code, loc)
-
-# The full version, including alpha/beta/rc tags.
-version = loc["__version__"]
-
-# The language for content autogenerated by Sphinx. Refer to documentation
-# for a list of supported languages.
-#
-# This is also used if you do content translation via gettext catalogs.
-# Usually you set "language" from the command line for these cases.
-language = None
-
-# There are two options for replacing |today|: either, you set today to some
-# non-false value, then it is used:
-# today = ''
-# Else, today_fmt is used as the format for a strftime call.
-# today_fmt = '%B %d, %Y'
-
-# List of patterns, relative to source directory, that match files and
-# directories to ignore when looking for source files.
-exclude_patterns = [".build", "release.rst"]
-
-# The reST default role (used for this markup: `text`) to use for all
-# documents.
-default_role = "any"
-
-# If true, '()' will be appended to :func: etc. cross-reference text.
-# add_function_parentheses = True
-
-# If true, the current module name will be prepended to all description
-# unit titles (such as .. function::).
-# add_module_names = True
-
-# If true, sectionauthor and moduleauthor directives will be shown in the
-# output. They are ignored by default.
-# show_authors = False
-
-# The name of the Pygments (syntax highlighting) style to use.
-# pygments_style = 'monokai'
-
-# A list of ignored prefixes for module index sorting.
-# modindex_common_prefix = []
-
-# If true, keep warnings as "system message" paragraphs in the built documents.
-# keep_warnings = False
-
-# If true, `todo` and `todoList` produce output, else they produce nothing.
-todo_include_todos = False
-
-
-# -- Options for HTML output ----------------------------------------------
-
-# The theme to use for HTML and HTML Help pages.  See the documentation for
-# a list of builtin themes.
-
-html_theme = "furo"
-
-# Theme options are theme-specific and customize the look and feel of a theme
-# further.  For a list of options available for each theme, see the
-# documentation.
-# html_theme_options = {}
-
-# Add any paths that contain custom themes here, relative to this directory.
-# html_theme_path = []
-
-# The name for this set of Sphinx documents.  If None, it defaults to
-# "<project> v<version> documentation".
-# html_title = None
-
-# A shorter title for the navigation bar.  Default is the same as html_title.
-# html_short_title = None
-
-# The name of an image file (relative to this directory) to place at the top
-# of the sidebar.
-# html_logo = None
-
-# The name of an image file (within the static path) to use as favicon of the
-# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
-# pixels large.
-# html_favicon = None
-
-# Add any paths that contain custom static files (such as style sheets) here,
-# relative to this directory. They are copied after the builtin static files,
-# so a file named "default.css" will overwrite the builtin "default.css".
-html_static_path = ["_static"]
-
-html_css_files = [
-    "css/custom.css",
-]
-
-# Add any extra paths that contain custom files (such as robots.txt or
-# .htaccess) here, relative to this directory. These files are copied
-# directly to the root of the documentation.
-# html_extra_path = []
-
-# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
-# using the given strftime format.
-# html_last_updated_fmt = '%b %d, %Y'
-
-# If true, SmartyPants will be used to convert quotes and dashes to
-# typographically correct entities.
-# html_use_smartypants = True
-
-# Custom sidebar templates, maps document names to template names.
-# html_sidebars = {}
-
-# Additional templates that should be rendered to pages, maps page names to
-# template names.
-# html_additional_pages = {}
-
-# If false, no module index is generated.
-# html_domain_indices = True
-
-# If false, no index is generated.
-# html_use_index = True
-
-# If true, the index is split into individual pages for each letter.
-# html_split_index = False
-
-# If true, links to the reST sources are added to the pages.
-# html_show_sourcelink = True
-
-# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
-# html_show_sphinx = True
-
-# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
-# html_show_copyright = True
-
-# If true, an OpenSearch description file will be output, and all pages will
-# contain a <link> tag referring to it.  The value of this option must be the
-# base URL from which the finished HTML is served.
-# html_use_opensearch = ''
-
-# This is the file name suffix for HTML files (e.g. ".xhtml").
-# html_file_suffix = None
-
-# Language to be used for generating the HTML full-text search index.
-# Sphinx supports the following languages:
-#   'da', 'de', 'en', 'es', 'fi', 'fr', 'h', 'it', 'ja'
-#   'nl', 'no', 'pt', 'ro', 'r', 'sv', 'tr'
-# html_search_language = 'en'
-
-# A dictionary with options for the search language support, empty by default.
-# Now only 'ja' uses this config value
-# html_search_options = {'type': 'default'}
-
-# The name of a javascript file (relative to the configuration directory) that
-# implements a search results scorer. If empty, the default will be used.
-# html_search_scorer = 'scorer.js'
-
-# Output file base name for HTML help builder.
-htmlhelp_basename = "pybind11doc"
-
-# -- Options for LaTeX output ---------------------------------------------
-
-latex_engine = "pdflatex"
-
-latex_elements = {
-    # The paper size ('letterpaper' or 'a4paper').
-    # 'papersize': 'letterpaper',
-    #
-    # The font size ('10pt', '11pt' or '12pt').
-    # 'pointsize': '10pt',
-    #
-    # Additional stuff for the LaTeX preamble.
-    # remove blank pages (between the title page and the TOC, etc.)
-    "classoptions": ",openany,oneside",
-    "preamble": r"""
-\usepackage{fontawesome}
-\usepackage{textgreek}
-\DeclareUnicodeCharacter{00A0}{}
-\DeclareUnicodeCharacter{2194}{\faArrowsH}
-\DeclareUnicodeCharacter{1F382}{\faBirthdayCake}
-\DeclareUnicodeCharacter{1F355}{\faAdjust}
-\DeclareUnicodeCharacter{0301}{'}
-\DeclareUnicodeCharacter{03C0}{\textpi}
-
-""",
-    # Latex figure (float) alignment
-    # 'figure_align': 'htbp',
-}
-
-# Grouping the document tree into LaTeX files. List of tuples
-# (source start file, target name, title,
-#  author, documentclass [howto, manual, or own class]).
-latex_documents = [
-    (master_doc, "pybind11.tex", "pybind11 Documentation", "Wenzel Jakob", "manual"),
-]
-
-# The name of an image file (relative to this directory) to place at the top of
-# the title page.
-# latex_logo = 'pybind11-logo.png'
-
-# For "manual" documents, if this is true, then toplevel headings are parts,
-# not chapters.
-# latex_use_parts = False
-
-# If true, show page references after internal links.
-# latex_show_pagerefs = False
-
-# If true, show URL addresses after external links.
-# latex_show_urls = False
-
-# Documents to append as an appendix to all manuals.
-# latex_appendices = []
-
-# If false, no module index is generated.
-# latex_domain_indices = True
-
-
-# -- Options for manual page output ---------------------------------------
-
-# One entry per manual page. List of tuples
-# (source start file, name, description, authors, manual section).
-man_pages = [(master_doc, "pybind11", "pybind11 Documentation", [author], 1)]
-
-# If true, show URL addresses after external links.
-# man_show_urls = False
-
-
-# -- Options for Texinfo output -------------------------------------------
-
-# Grouping the document tree into Texinfo files. List of tuples
-# (source start file, target name, title, author,
-#  dir menu entry, description, category)
-texinfo_documents = [
-    (
-        master_doc,
-        "pybind11",
-        "pybind11 Documentation",
-        author,
-        "pybind11",
-        "One line description of project.",
-        "Miscellaneous",
-    ),
-]
-
-# Documents to append as an appendix to all manuals.
-# texinfo_appendices = []
-
-# If false, no module index is generated.
-# texinfo_domain_indices = True
-
-# How to display URL addresses: 'footnote', 'no', or 'inline'.
-# texinfo_show_urls = 'footnote'
-
-# If true, do not generate a @detailmenu in the "Top" node's menu.
-# texinfo_no_detailmenu = False
-
-primary_domain = "cpp"
-highlight_language = "cpp"
-
-
-def generate_doxygen_xml(app):
-    build_dir = os.path.join(app.confdir, ".build")
-    if not os.path.exists(build_dir):
-        os.mkdir(build_dir)
-
-    try:
-        subprocess.call(["doxygen", "--version"])
-        retcode = subprocess.call(["doxygen"], cwd=app.confdir)
-        if retcode < 0:
-            sys.stderr.write(f"doxygen error code: {-retcode}\n")
-    except OSError as e:
-        sys.stderr.write(f"doxygen execution failed: {e}\n")
-
-
-def prepare(app):
-    with open(DIR.parent / "README.rst") as f:
-        contents = f.read()
-
-    if app.builder.name == "latex":
-        # Remove badges and stuff from start
-        contents = contents[contents.find(r".. start") :]
-
-        # Filter out section titles for index.rst for LaTeX
-        contents = re.sub(r"^(.*)\n[-~]{3,}$", r"**\1**", contents, flags=re.MULTILINE)
-
-    with open(DIR / "readme.rst", "w") as f:
-        f.write(contents)
-
-
-def clean_up(app, exception):  # noqa: ARG001
-    (DIR / "readme.rst").unlink()
-
-
-def setup(app):
-    # Add hook for building doxygen xml when needed
-    app.connect("builder-inited", generate_doxygen_xml)
-
-    # Copy the readme in
-    app.connect("builder-inited", prepare)
-
-    # Clean up the generated readme
-    app.connect("build-finished", clean_up)
+#!/usr/bin/env python3
+#
+# pybind11 documentation build configuration file, created by
+# sphinx-quickstart on Sun Oct 11 19:23:48 2015.
+#
+# This file is execfile()d with the current directory set to its
+# containing dir.
+#
+# Note that not all possible configuration values are present in this
+# autogenerated file.
+#
+# All configuration values have a default; values that are commented out
+# serve to show the default.
+
+import os
+import re
+import subprocess
+import sys
+from pathlib import Path
+
+DIR = Path(__file__).parent.resolve()
+
+# If extensions (or modules to document with autodoc) are in another directory,
+# add these directories to sys.path here. If the directory is relative to the
+# documentation root, use os.path.abspath to make it absolute, like shown here.
+# sys.path.insert(0, os.path.abspath('.'))
+
+# -- General configuration ------------------------------------------------
+
+# If your documentation needs a minimal Sphinx version, state it here.
+# needs_sphinx = '1.0'
+
+# Add any Sphinx extension module names here, as strings. They can be
+# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
+# ones.
+extensions = [
+    "breathe",
+    "sphinx_copybutton",
+    "sphinxcontrib.rsvgconverter",
+    "sphinxcontrib.moderncmakedomain",
+]
+
+breathe_projects = {"pybind11": ".build/doxygenxml/"}
+breathe_default_project = "pybind11"
+breathe_domain_by_extension = {"h": "cpp"}
+
+# Add any paths that contain templates here, relative to this directory.
+templates_path = [".templates"]
+
+# The suffix(es) of source filenames.
+# You can specify multiple suffix as a list of string:
+# source_suffix = ['.rst', '.md']
+source_suffix = ".rst"
+
+# The encoding of source files.
+# source_encoding = 'utf-8-sig'
+
+# The master toctree document.
+master_doc = "index"
+
+# General information about the project.
+project = "pybind11"
+copyright = "2017, Wenzel Jakob"
+author = "Wenzel Jakob"
+
+# The version info for the project you're documenting, acts as replacement for
+# |version| and |release|, also used in various other places throughout the
+# built documents.
+
+# Read the listed version
+with open("../pybind11/_version.py") as f:
+    code = compile(f.read(), "../pybind11/_version.py", "exec")
+loc = {}
+exec(code, loc)
+
+# The full version, including alpha/beta/rc tags.
+version = loc["__version__"]
+
+# The language for content autogenerated by Sphinx. Refer to documentation
+# for a list of supported languages.
+#
+# This is also used if you do content translation via gettext catalogs.
+# Usually you set "language" from the command line for these cases.
+language = None
+
+# There are two options for replacing |today|: either, you set today to some
+# non-false value, then it is used:
+# today = ''
+# Else, today_fmt is used as the format for a strftime call.
+# today_fmt = '%B %d, %Y'
+
+# List of patterns, relative to source directory, that match files and
+# directories to ignore when looking for source files.
+exclude_patterns = [".build", "release.rst"]
+
+# The reST default role (used for this markup: `text`) to use for all
+# documents.
+default_role = "any"
+
+# If true, '()' will be appended to :func: etc. cross-reference text.
+# add_function_parentheses = True
+
+# If true, the current module name will be prepended to all description
+# unit titles (such as .. function::).
+# add_module_names = True
+
+# If true, sectionauthor and moduleauthor directives will be shown in the
+# output. They are ignored by default.
+# show_authors = False
+
+# The name of the Pygments (syntax highlighting) style to use.
+# pygments_style = 'monokai'
+
+# A list of ignored prefixes for module index sorting.
+# modindex_common_prefix = []
+
+# If true, keep warnings as "system message" paragraphs in the built documents.
+# keep_warnings = False
+
+# If true, `todo` and `todoList` produce output, else they produce nothing.
+todo_include_todos = False
+
+
+# -- Options for HTML output ----------------------------------------------
+
+# The theme to use for HTML and HTML Help pages.  See the documentation for
+# a list of builtin themes.
+
+html_theme = "furo"
+
+# Theme options are theme-specific and customize the look and feel of a theme
+# further.  For a list of options available for each theme, see the
+# documentation.
+# html_theme_options = {}
+
+# Add any paths that contain custom themes here, relative to this directory.
+# html_theme_path = []
+
+# The name for this set of Sphinx documents.  If None, it defaults to
+# "<project> v<version> documentation".
+# html_title = None
+
+# A shorter title for the navigation bar.  Default is the same as html_title.
+# html_short_title = None
+
+# The name of an image file (relative to this directory) to place at the top
+# of the sidebar.
+# html_logo = None
+
+# The name of an image file (within the static path) to use as favicon of the
+# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
+# pixels large.
+# html_favicon = None
+
+# Add any paths that contain custom static files (such as style sheets) here,
+# relative to this directory. They are copied after the builtin static files,
+# so a file named "default.css" will overwrite the builtin "default.css".
+html_static_path = ["_static"]
+
+html_css_files = [
+    "css/custom.css",
+]
+
+# Add any extra paths that contain custom files (such as robots.txt or
+# .htaccess) here, relative to this directory. These files are copied
+# directly to the root of the documentation.
+# html_extra_path = []
+
+# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
+# using the given strftime format.
+# html_last_updated_fmt = '%b %d, %Y'
+
+# If true, SmartyPants will be used to convert quotes and dashes to
+# typographically correct entities.
+# html_use_smartypants = True
+
+# Custom sidebar templates, maps document names to template names.
+# html_sidebars = {}
+
+# Additional templates that should be rendered to pages, maps page names to
+# template names.
+# html_additional_pages = {}
+
+# If false, no module index is generated.
+# html_domain_indices = True
+
+# If false, no index is generated.
+# html_use_index = True
+
+# If true, the index is split into individual pages for each letter.
+# html_split_index = False
+
+# If true, links to the reST sources are added to the pages.
+# html_show_sourcelink = True
+
+# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
+# html_show_sphinx = True
+
+# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
+# html_show_copyright = True
+
+# If true, an OpenSearch description file will be output, and all pages will
+# contain a <link> tag referring to it.  The value of this option must be the
+# base URL from which the finished HTML is served.
+# html_use_opensearch = ''
+
+# This is the file name suffix for HTML files (e.g. ".xhtml").
+# html_file_suffix = None
+
+# Language to be used for generating the HTML full-text search index.
+# Sphinx supports the following languages:
+#   'da', 'de', 'en', 'es', 'fi', 'fr', 'h', 'it', 'ja'
+#   'nl', 'no', 'pt', 'ro', 'r', 'sv', 'tr'
+# html_search_language = 'en'
+
+# A dictionary with options for the search language support, empty by default.
+# Now only 'ja' uses this config value
+# html_search_options = {'type': 'default'}
+
+# The name of a javascript file (relative to the configuration directory) that
+# implements a search results scorer. If empty, the default will be used.
+# html_search_scorer = 'scorer.js'
+
+# Output file base name for HTML help builder.
+htmlhelp_basename = "pybind11doc"
+
+# -- Options for LaTeX output ---------------------------------------------
+
+latex_engine = "pdflatex"
+
+latex_elements = {
+    # The paper size ('letterpaper' or 'a4paper').
+    # 'papersize': 'letterpaper',
+    #
+    # The font size ('10pt', '11pt' or '12pt').
+    # 'pointsize': '10pt',
+    #
+    # Additional stuff for the LaTeX preamble.
+    # remove blank pages (between the title page and the TOC, etc.)
+    "classoptions": ",openany,oneside",
+    "preamble": r"""
+\usepackage{fontawesome}
+\usepackage{textgreek}
+\DeclareUnicodeCharacter{00A0}{}
+\DeclareUnicodeCharacter{2194}{\faArrowsH}
+\DeclareUnicodeCharacter{1F382}{\faBirthdayCake}
+\DeclareUnicodeCharacter{1F355}{\faAdjust}
+\DeclareUnicodeCharacter{0301}{'}
+\DeclareUnicodeCharacter{03C0}{\textpi}
+
+""",
+    # Latex figure (float) alignment
+    # 'figure_align': 'htbp',
+}
+
+# Grouping the document tree into LaTeX files. List of tuples
+# (source start file, target name, title,
+#  author, documentclass [howto, manual, or own class]).
+latex_documents = [
+    (master_doc, "pybind11.tex", "pybind11 Documentation", "Wenzel Jakob", "manual"),
+]
+
+# The name of an image file (relative to this directory) to place at the top of
+# the title page.
+# latex_logo = 'pybind11-logo.png'
+
+# For "manual" documents, if this is true, then toplevel headings are parts,
+# not chapters.
+# latex_use_parts = False
+
+# If true, show page references after internal links.
+# latex_show_pagerefs = False
+
+# If true, show URL addresses after external links.
+# latex_show_urls = False
+
+# Documents to append as an appendix to all manuals.
+# latex_appendices = []
+
+# If false, no module index is generated.
+# latex_domain_indices = True
+
+
+# -- Options for manual page output ---------------------------------------
+
+# One entry per manual page. List of tuples
+# (source start file, name, description, authors, manual section).
+man_pages = [(master_doc, "pybind11", "pybind11 Documentation", [author], 1)]
+
+# If true, show URL addresses after external links.
+# man_show_urls = False
+
+
+# -- Options for Texinfo output -------------------------------------------
+
+# Grouping the document tree into Texinfo files. List of tuples
+# (source start file, target name, title, author,
+#  dir menu entry, description, category)
+texinfo_documents = [
+    (
+        master_doc,
+        "pybind11",
+        "pybind11 Documentation",
+        author,
+        "pybind11",
+        "One line description of project.",
+        "Miscellaneous",
+    ),
+]
+
+# Documents to append as an appendix to all manuals.
+# texinfo_appendices = []
+
+# If false, no module index is generated.
+# texinfo_domain_indices = True
+
+# How to display URL addresses: 'footnote', 'no', or 'inline'.
+# texinfo_show_urls = 'footnote'
+
+# If true, do not generate a @detailmenu in the "Top" node's menu.
+# texinfo_no_detailmenu = False
+
+primary_domain = "cpp"
+highlight_language = "cpp"
+
+
+def generate_doxygen_xml(app):
+    build_dir = os.path.join(app.confdir, ".build")
+    if not os.path.exists(build_dir):
+        os.mkdir(build_dir)
+
+    try:
+        subprocess.call(["doxygen", "--version"])
+        retcode = subprocess.call(["doxygen"], cwd=app.confdir)
+        if retcode < 0:
+            sys.stderr.write(f"doxygen error code: {-retcode}\n")
+    except OSError as e:
+        sys.stderr.write(f"doxygen execution failed: {e}\n")
+
+
+def prepare(app):
+    with open(DIR.parent / "README.rst") as f:
+        contents = f.read()
+
+    if app.builder.name == "latex":
+        # Remove badges and stuff from start
+        contents = contents[contents.find(r".. start") :]
+
+        # Filter out section titles for index.rst for LaTeX
+        contents = re.sub(r"^(.*)\n[-~]{3,}$", r"**\1**", contents, flags=re.MULTILINE)
+
+    with open(DIR / "readme.rst", "w") as f:
+        f.write(contents)
+
+
+def clean_up(app, exception):  # noqa: ARG001
+    (DIR / "readme.rst").unlink()
+
+
+def setup(app):
+    # Add hook for building doxygen xml when needed
+    app.connect("builder-inited", generate_doxygen_xml)
+
+    # Copy the readme in
+    app.connect("builder-inited", prepare)
+
+    # Clean up the generated readme
+    app.connect("build-finished", clean_up)
```

## extern/pybind11/pybind11/__init__.py

 * *Ordering differences only*

```diff
@@ -1,17 +1,17 @@
-import sys
-
-if sys.version_info < (3, 6):  # noqa: UP036
-    msg = "pybind11 does not support Python < 3.6. 2.9 was the last release supporting Python 2.7 and 3.5."
-    raise ImportError(msg)
-
-
-from ._version import __version__, version_info
-from .commands import get_cmake_dir, get_include, get_pkgconfig_dir
-
-__all__ = (
-    "version_info",
-    "__version__",
-    "get_include",
-    "get_cmake_dir",
-    "get_pkgconfig_dir",
-)
+import sys
+
+if sys.version_info < (3, 6):  # noqa: UP036
+    msg = "pybind11 does not support Python < 3.6. 2.9 was the last release supporting Python 2.7 and 3.5."
+    raise ImportError(msg)
+
+
+from ._version import __version__, version_info
+from .commands import get_cmake_dir, get_include, get_pkgconfig_dir
+
+__all__ = (
+    "version_info",
+    "__version__",
+    "get_include",
+    "get_cmake_dir",
+    "get_pkgconfig_dir",
+)
```

## extern/pybind11/pybind11/__main__.py

 * *Ordering differences only*

```diff
@@ -1,62 +1,62 @@
-# pylint: disable=missing-function-docstring
-
-import argparse
-import sys
-import sysconfig
-
-from ._version import __version__
-from .commands import get_cmake_dir, get_include, get_pkgconfig_dir
-
-
-def print_includes() -> None:
-    dirs = [
-        sysconfig.get_path("include"),
-        sysconfig.get_path("platinclude"),
-        get_include(),
-    ]
-
-    # Make unique but preserve order
-    unique_dirs = []
-    for d in dirs:
-        if d and d not in unique_dirs:
-            unique_dirs.append(d)
-
-    print(" ".join("-I" + d for d in unique_dirs))
-
-
-def main() -> None:
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--version",
-        action="version",
-        version=__version__,
-        help="Print the version and exit.",
-    )
-    parser.add_argument(
-        "--includes",
-        action="store_true",
-        help="Include flags for both pybind11 and Python headers.",
-    )
-    parser.add_argument(
-        "--cmakedir",
-        action="store_true",
-        help="Print the CMake module directory, ideal for setting -Dpybind11_ROOT in CMake.",
-    )
-    parser.add_argument(
-        "--pkgconfigdir",
-        action="store_true",
-        help="Print the pkgconfig directory, ideal for setting $PKG_CONFIG_PATH.",
-    )
-    args = parser.parse_args()
-    if not sys.argv[1:]:
-        parser.print_help()
-    if args.includes:
-        print_includes()
-    if args.cmakedir:
-        print(get_cmake_dir())
-    if args.pkgconfigdir:
-        print(get_pkgconfig_dir())
-
-
-if __name__ == "__main__":
-    main()
+# pylint: disable=missing-function-docstring
+
+import argparse
+import sys
+import sysconfig
+
+from ._version import __version__
+from .commands import get_cmake_dir, get_include, get_pkgconfig_dir
+
+
+def print_includes() -> None:
+    dirs = [
+        sysconfig.get_path("include"),
+        sysconfig.get_path("platinclude"),
+        get_include(),
+    ]
+
+    # Make unique but preserve order
+    unique_dirs = []
+    for d in dirs:
+        if d and d not in unique_dirs:
+            unique_dirs.append(d)
+
+    print(" ".join("-I" + d for d in unique_dirs))
+
+
+def main() -> None:
+    parser = argparse.ArgumentParser()
+    parser.add_argument(
+        "--version",
+        action="version",
+        version=__version__,
+        help="Print the version and exit.",
+    )
+    parser.add_argument(
+        "--includes",
+        action="store_true",
+        help="Include flags for both pybind11 and Python headers.",
+    )
+    parser.add_argument(
+        "--cmakedir",
+        action="store_true",
+        help="Print the CMake module directory, ideal for setting -Dpybind11_ROOT in CMake.",
+    )
+    parser.add_argument(
+        "--pkgconfigdir",
+        action="store_true",
+        help="Print the pkgconfig directory, ideal for setting $PKG_CONFIG_PATH.",
+    )
+    args = parser.parse_args()
+    if not sys.argv[1:]:
+        parser.print_help()
+    if args.includes:
+        print_includes()
+    if args.cmakedir:
+        print(get_cmake_dir())
+    if args.pkgconfigdir:
+        print(get_pkgconfig_dir())
+
+
+if __name__ == "__main__":
+    main()
```

## extern/pybind11/pybind11/_version.py

 * *Ordering differences only*

```diff
@@ -1,12 +1,12 @@
-from typing import Union
-
-
-def _to_int(s: str) -> Union[int, str]:
-    try:
-        return int(s)
-    except ValueError:
-        return s
-
-
-__version__ = "2.12.0.dev1"
-version_info = tuple(_to_int(s) for s in __version__.split("."))
+from typing import Union
+
+
+def _to_int(s: str) -> Union[int, str]:
+    try:
+        return int(s)
+    except ValueError:
+        return s
+
+
+__version__ = "2.12.0.dev1"
+version_info = tuple(_to_int(s) for s in __version__.split("."))
```

## extern/pybind11/pybind11/commands.py

 * *Ordering differences only*

```diff
@@ -1,37 +1,37 @@
-import os
-
-DIR = os.path.abspath(os.path.dirname(__file__))
-
-
-def get_include(user: bool = False) -> str:  # noqa: ARG001
-    """
-    Return the path to the pybind11 include directory. The historical "user"
-    argument is unused, and may be removed.
-    """
-    installed_path = os.path.join(DIR, "include")
-    source_path = os.path.join(os.path.dirname(DIR), "include")
-    return installed_path if os.path.exists(installed_path) else source_path
-
-
-def get_cmake_dir() -> str:
-    """
-    Return the path to the pybind11 CMake module directory.
-    """
-    cmake_installed_path = os.path.join(DIR, "share", "cmake", "pybind11")
-    if os.path.exists(cmake_installed_path):
-        return cmake_installed_path
-
-    msg = "pybind11 not installed, installation required to access the CMake files"
-    raise ImportError(msg)
-
-
-def get_pkgconfig_dir() -> str:
-    """
-    Return the path to the pybind11 pkgconfig directory.
-    """
-    pkgconfig_installed_path = os.path.join(DIR, "share", "pkgconfig")
-    if os.path.exists(pkgconfig_installed_path):
-        return pkgconfig_installed_path
-
-    msg = "pybind11 not installed, installation required to access the pkgconfig files"
-    raise ImportError(msg)
+import os
+
+DIR = os.path.abspath(os.path.dirname(__file__))
+
+
+def get_include(user: bool = False) -> str:  # noqa: ARG001
+    """
+    Return the path to the pybind11 include directory. The historical "user"
+    argument is unused, and may be removed.
+    """
+    installed_path = os.path.join(DIR, "include")
+    source_path = os.path.join(os.path.dirname(DIR), "include")
+    return installed_path if os.path.exists(installed_path) else source_path
+
+
+def get_cmake_dir() -> str:
+    """
+    Return the path to the pybind11 CMake module directory.
+    """
+    cmake_installed_path = os.path.join(DIR, "share", "cmake", "pybind11")
+    if os.path.exists(cmake_installed_path):
+        return cmake_installed_path
+
+    msg = "pybind11 not installed, installation required to access the CMake files"
+    raise ImportError(msg)
+
+
+def get_pkgconfig_dir() -> str:
+    """
+    Return the path to the pybind11 pkgconfig directory.
+    """
+    pkgconfig_installed_path = os.path.join(DIR, "share", "pkgconfig")
+    if os.path.exists(pkgconfig_installed_path):
+        return pkgconfig_installed_path
+
+    msg = "pybind11 not installed, installation required to access the pkgconfig files"
+    raise ImportError(msg)
```

## extern/pybind11/pybind11/setup_helpers.py

 * *Ordering differences only*

```diff
@@ -1,500 +1,500 @@
-"""
-This module provides helpers for C++11+ projects using pybind11.
-
-LICENSE:
-
-Copyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are met:
-
-1. Redistributions of source code must retain the above copyright notice, this
-   list of conditions and the following disclaimer.
-
-2. Redistributions in binary form must reproduce the above copyright notice,
-   this list of conditions and the following disclaimer in the documentation
-   and/or other materials provided with the distribution.
-
-3. Neither the name of the copyright holder nor the names of its contributors
-   may be used to endorse or promote products derived from this software
-   without specific prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
-WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-"""
-
-# IMPORTANT: If you change this file in the pybind11 repo, also review
-# setup_helpers.pyi for matching changes.
-#
-# If you copy this file in, you don't
-# need the .pyi file; it's just an interface file for static type checkers.
-
-import contextlib
-import os
-import platform
-import shlex
-import shutil
-import sys
-import sysconfig
-import tempfile
-import threading
-import warnings
-from functools import lru_cache
-from pathlib import Path
-from typing import (
-    Any,
-    Callable,
-    Dict,
-    Iterable,
-    Iterator,
-    List,
-    Optional,
-    Tuple,
-    TypeVar,
-    Union,
-)
-
-try:
-    from setuptools import Extension as _Extension
-    from setuptools.command.build_ext import build_ext as _build_ext
-except ImportError:
-    from distutils.command.build_ext import (  # type: ignore[assignment]
-        build_ext as _build_ext,
-    )
-    from distutils.extension import Extension as _Extension  # type: ignore[assignment]
-
-import distutils.ccompiler
-import distutils.errors
-
-WIN = sys.platform.startswith("win32") and "mingw" not in sysconfig.get_platform()
-MACOS = sys.platform.startswith("darwin")
-STD_TMPL = "/std:c++{}" if WIN else "-std=c++{}"
-
-
-# It is recommended to use PEP 518 builds if using this module. However, this
-# file explicitly supports being copied into a user's project directory
-# standalone, and pulling pybind11 with the deprecated setup_requires feature.
-# If you copy the file, remember to add it to your MANIFEST.in, and add the current
-# directory into your path if it sits beside your setup.py.
-
-
-class Pybind11Extension(_Extension):
-    """
-    Build a C++11+ Extension module with pybind11. This automatically adds the
-    recommended flags when you init the extension and assumes C++ sources - you
-    can further modify the options yourself.
-
-    The customizations are:
-
-    * ``/EHsc`` and ``/bigobj`` on Windows
-    * ``stdlib=libc++`` on macOS
-    * ``visibility=hidden`` and ``-g0`` on Unix
-
-    Finally, you can set ``cxx_std`` via constructor or afterwards to enable
-    flags for C++ std, and a few extra helper flags related to the C++ standard
-    level. It is _highly_ recommended you either set this, or use the provided
-    ``build_ext``, which will search for the highest supported extension for
-    you if the ``cxx_std`` property is not set. Do not set the ``cxx_std``
-    property more than once, as flags are added when you set it. Set the
-    property to None to disable the addition of C++ standard flags.
-
-    If you want to add pybind11 headers manually, for example for an exact
-    git checkout, then set ``include_pybind11=False``.
-    """
-
-    # flags are prepended, so that they can be further overridden, e.g. by
-    # ``extra_compile_args=["-g"]``.
-
-    def _add_cflags(self, flags: List[str]) -> None:
-        self.extra_compile_args[:0] = flags
-
-    def _add_ldflags(self, flags: List[str]) -> None:
-        self.extra_link_args[:0] = flags
-
-    def __init__(self, *args: Any, **kwargs: Any) -> None:
-        self._cxx_level = 0
-        cxx_std = kwargs.pop("cxx_std", 0)
-
-        if "language" not in kwargs:
-            kwargs["language"] = "c++"
-
-        include_pybind11 = kwargs.pop("include_pybind11", True)
-
-        super().__init__(*args, **kwargs)
-
-        # Include the installed package pybind11 headers
-        if include_pybind11:
-            # If using setup_requires, this fails the first time - that's okay
-            try:
-                import pybind11
-
-                pyinc = pybind11.get_include()
-
-                if pyinc not in self.include_dirs:
-                    self.include_dirs.append(pyinc)
-            except ModuleNotFoundError:
-                pass
-
-        self.cxx_std = cxx_std
-
-        cflags = []
-        if WIN:
-            cflags += ["/EHsc", "/bigobj"]
-        else:
-            cflags += ["-fvisibility=hidden"]
-            env_cflags = os.environ.get("CFLAGS", "")
-            env_cppflags = os.environ.get("CPPFLAGS", "")
-            c_cpp_flags = shlex.split(env_cflags) + shlex.split(env_cppflags)
-            if not any(opt.startswith("-g") for opt in c_cpp_flags):
-                cflags += ["-g0"]
-        self._add_cflags(cflags)
-
-    @property
-    def cxx_std(self) -> int:
-        """
-        The CXX standard level. If set, will add the required flags. If left at
-        0, it will trigger an automatic search when pybind11's build_ext is
-        used. If None, will have no effect.  Besides just the flags, this may
-        add a macos-min 10.9 or 10.14 flag if MACOSX_DEPLOYMENT_TARGET is
-        unset.
-        """
-        return self._cxx_level
-
-    @cxx_std.setter
-    def cxx_std(self, level: int) -> None:
-        if self._cxx_level:
-            warnings.warn(
-                "You cannot safely change the cxx_level after setting it!", stacklevel=2
-            )
-
-        # MSVC 2015 Update 3 and later only have 14 (and later 17) modes, so
-        # force a valid flag here.
-        if WIN and level == 11:
-            level = 14
-
-        self._cxx_level = level
-
-        if not level:
-            return
-
-        cflags = [STD_TMPL.format(level)]
-        ldflags = []
-
-        if MACOS and "MACOSX_DEPLOYMENT_TARGET" not in os.environ:
-            # C++17 requires a higher min version of macOS. An earlier version
-            # (10.12 or 10.13) can be set manually via environment variable if
-            # you are careful in your feature usage, but 10.14 is the safest
-            # setting for general use. However, never set higher than the
-            # current macOS version!
-            current_macos = tuple(int(x) for x in platform.mac_ver()[0].split(".")[:2])
-            desired_macos = (10, 9) if level < 17 else (10, 14)
-            macos_string = ".".join(str(x) for x in min(current_macos, desired_macos))
-            macosx_min = f"-mmacosx-version-min={macos_string}"
-            cflags += [macosx_min]
-            ldflags += [macosx_min]
-
-        self._add_cflags(cflags)
-        self._add_ldflags(ldflags)
-
-
-# Just in case someone clever tries to multithread
-tmp_chdir_lock = threading.Lock()
-
-
-@contextlib.contextmanager
-def tmp_chdir() -> Iterator[str]:
-    "Prepare and enter a temporary directory, cleanup when done"
-
-    # Threadsafe
-    with tmp_chdir_lock:
-        olddir = os.getcwd()
-        try:
-            tmpdir = tempfile.mkdtemp()
-            os.chdir(tmpdir)
-            yield tmpdir
-        finally:
-            os.chdir(olddir)
-            shutil.rmtree(tmpdir)
-
-
-# cf http://bugs.python.org/issue26689
-def has_flag(compiler: Any, flag: str) -> bool:
-    """
-    Return the flag if a flag name is supported on the
-    specified compiler, otherwise None (can be used as a boolean).
-    If multiple flags are passed, return the first that matches.
-    """
-
-    with tmp_chdir():
-        fname = Path("flagcheck.cpp")
-        # Don't trigger -Wunused-parameter.
-        fname.write_text("int main (int, char **) { return 0; }", encoding="utf-8")
-
-        try:
-            compiler.compile([str(fname)], extra_postargs=[flag])
-        except distutils.errors.CompileError:
-            return False
-        return True
-
-
-# Every call will cache the result
-cpp_flag_cache = None
-
-
-@lru_cache()
-def auto_cpp_level(compiler: Any) -> Union[str, int]:
-    """
-    Return the max supported C++ std level (17, 14, or 11). Returns latest on Windows.
-    """
-
-    if WIN:
-        return "latest"
-
-    levels = [17, 14, 11]
-
-    for level in levels:
-        if has_flag(compiler, STD_TMPL.format(level)):
-            return level
-
-    msg = "Unsupported compiler -- at least C++11 support is needed!"
-    raise RuntimeError(msg)
-
-
-class build_ext(_build_ext):  # noqa: N801
-    """
-    Customized build_ext that allows an auto-search for the highest supported
-    C++ level for Pybind11Extension. This is only needed for the auto-search
-    for now, and is completely optional otherwise.
-    """
-
-    def build_extensions(self) -> None:
-        """
-        Build extensions, injecting C++ std for Pybind11Extension if needed.
-        """
-
-        for ext in self.extensions:
-            if hasattr(ext, "_cxx_level") and ext._cxx_level == 0:
-                ext.cxx_std = auto_cpp_level(self.compiler)
-
-        super().build_extensions()
-
-
-def intree_extensions(
-    paths: Iterable[str], package_dir: Optional[Dict[str, str]] = None
-) -> List[Pybind11Extension]:
-    """
-    Generate Pybind11Extensions from source files directly located in a Python
-    source tree.
-
-    ``package_dir`` behaves as in ``setuptools.setup``.  If unset, the Python
-    package root parent is determined as the first parent directory that does
-    not contain an ``__init__.py`` file.
-    """
-    exts = []
-
-    if package_dir is None:
-        for path in paths:
-            parent, _ = os.path.split(path)
-            while os.path.exists(os.path.join(parent, "__init__.py")):
-                parent, _ = os.path.split(parent)
-            relname, _ = os.path.splitext(os.path.relpath(path, parent))
-            qualified_name = relname.replace(os.path.sep, ".")
-            exts.append(Pybind11Extension(qualified_name, [path]))
-        return exts
-
-    for path in paths:
-        for prefix, parent in package_dir.items():
-            if path.startswith(parent):
-                relname, _ = os.path.splitext(os.path.relpath(path, parent))
-                qualified_name = relname.replace(os.path.sep, ".")
-                if prefix:
-                    qualified_name = prefix + "." + qualified_name
-                exts.append(Pybind11Extension(qualified_name, [path]))
-                break
-        else:
-            msg = (
-                f"path {path} is not a child of any of the directories listed "
-                f"in 'package_dir' ({package_dir})"
-            )
-            raise ValueError(msg)
-
-    return exts
-
-
-def naive_recompile(obj: str, src: str) -> bool:
-    """
-    This will recompile only if the source file changes. It does not check
-    header files, so a more advanced function or Ccache is better if you have
-    editable header files in your package.
-    """
-    return os.stat(obj).st_mtime < os.stat(src).st_mtime
-
-
-def no_recompile(obg: str, src: str) -> bool:  # noqa: ARG001
-    """
-    This is the safest but slowest choice (and is the default) - will always
-    recompile sources.
-    """
-    return True
-
-
-S = TypeVar("S", bound="ParallelCompile")
-
-CCompilerMethod = Callable[
-    [
-        distutils.ccompiler.CCompiler,
-        List[str],
-        Optional[str],
-        Optional[Union[Tuple[str], Tuple[str, Optional[str]]]],
-        Optional[List[str]],
-        bool,
-        Optional[List[str]],
-        Optional[List[str]],
-        Optional[List[str]],
-    ],
-    List[str],
-]
-
-
-# Optional parallel compile utility
-# inspired by: http://stackoverflow.com/questions/11013851/speeding-up-build-process-with-distutils
-# and: https://github.com/tbenthompson/cppimport/blob/stable/cppimport/build_module.py
-# and NumPy's parallel distutils module:
-#              https://github.com/numpy/numpy/blob/master/numpy/distutils/ccompiler.py
-class ParallelCompile:
-    """
-    Make a parallel compile function. Inspired by
-    numpy.distutils.ccompiler.CCompiler.compile and cppimport.
-
-    This takes several arguments that allow you to customize the compile
-    function created:
-
-    envvar:
-        Set an environment variable to control the compilation threads, like
-        NPY_NUM_BUILD_JOBS
-    default:
-        0 will automatically multithread, or 1 will only multithread if the
-        envvar is set.
-    max:
-        The limit for automatic multithreading if non-zero
-    needs_recompile:
-        A function of (obj, src) that returns True when recompile is needed.  No
-        effect in isolated mode; use ccache instead, see
-        https://github.com/matplotlib/matplotlib/issues/1507/
-
-    To use::
-
-        ParallelCompile("NPY_NUM_BUILD_JOBS").install()
-
-    or::
-
-        with ParallelCompile("NPY_NUM_BUILD_JOBS"):
-            setup(...)
-
-    By default, this assumes all files need to be recompiled. A smarter
-    function can be provided via needs_recompile.  If the output has not yet
-    been generated, the compile will always run, and this function is not
-    called.
-    """
-
-    __slots__ = ("envvar", "default", "max", "_old", "needs_recompile")
-
-    def __init__(
-        self,
-        envvar: Optional[str] = None,
-        default: int = 0,
-        max: int = 0,  # pylint: disable=redefined-builtin
-        needs_recompile: Callable[[str, str], bool] = no_recompile,
-    ) -> None:
-        self.envvar = envvar
-        self.default = default
-        self.max = max
-        self.needs_recompile = needs_recompile
-        self._old: List[CCompilerMethod] = []
-
-    def function(self) -> CCompilerMethod:
-        """
-        Builds a function object usable as distutils.ccompiler.CCompiler.compile.
-        """
-
-        def compile_function(
-            compiler: distutils.ccompiler.CCompiler,
-            sources: List[str],
-            output_dir: Optional[str] = None,
-            macros: Optional[Union[Tuple[str], Tuple[str, Optional[str]]]] = None,
-            include_dirs: Optional[List[str]] = None,
-            debug: bool = False,
-            extra_preargs: Optional[List[str]] = None,
-            extra_postargs: Optional[List[str]] = None,
-            depends: Optional[List[str]] = None,
-        ) -> Any:
-            # These lines are directly from distutils.ccompiler.CCompiler
-            macros, objects, extra_postargs, pp_opts, build = compiler._setup_compile(  # type: ignore[attr-defined]
-                output_dir, macros, include_dirs, sources, depends, extra_postargs
-            )
-            cc_args = compiler._get_cc_args(pp_opts, debug, extra_preargs)  # type: ignore[attr-defined]
-
-            # The number of threads; start with default.
-            threads = self.default
-
-            # Determine the number of compilation threads, unless set by an environment variable.
-            if self.envvar is not None:
-                threads = int(os.environ.get(self.envvar, self.default))
-
-            def _single_compile(obj: Any) -> None:
-                try:
-                    src, ext = build[obj]
-                except KeyError:
-                    return
-
-                if not os.path.exists(obj) or self.needs_recompile(obj, src):
-                    compiler._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)  # type: ignore[attr-defined]
-
-            try:
-                # Importing .synchronize checks for platforms that have some multiprocessing
-                # capabilities but lack semaphores, such as AWS Lambda and Android Termux.
-                import multiprocessing.synchronize
-                from multiprocessing.pool import ThreadPool
-            except ImportError:
-                threads = 1
-
-            if threads == 0:
-                try:
-                    threads = multiprocessing.cpu_count()
-                    threads = self.max if self.max and self.max < threads else threads
-                except NotImplementedError:
-                    threads = 1
-
-            if threads > 1:
-                with ThreadPool(threads) as pool:
-                    for _ in pool.imap_unordered(_single_compile, objects):
-                        pass
-            else:
-                for ob in objects:
-                    _single_compile(ob)
-
-            return objects
-
-        return compile_function
-
-    def install(self: S) -> S:
-        """
-        Installs the compile function into distutils.ccompiler.CCompiler.compile.
-        """
-        distutils.ccompiler.CCompiler.compile = self.function()  # type: ignore[assignment]
-        return self
-
-    def __enter__(self: S) -> S:
-        self._old.append(distutils.ccompiler.CCompiler.compile)
-        return self.install()
-
-    def __exit__(self, *args: Any) -> None:
-        distutils.ccompiler.CCompiler.compile = self._old.pop()  # type: ignore[assignment]
+"""
+This module provides helpers for C++11+ projects using pybind11.
+
+LICENSE:
+
+Copyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this
+   list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice,
+   this list of conditions and the following disclaimer in the documentation
+   and/or other materials provided with the distribution.
+
+3. Neither the name of the copyright holder nor the names of its contributors
+   may be used to endorse or promote products derived from this software
+   without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+"""
+
+# IMPORTANT: If you change this file in the pybind11 repo, also review
+# setup_helpers.pyi for matching changes.
+#
+# If you copy this file in, you don't
+# need the .pyi file; it's just an interface file for static type checkers.
+
+import contextlib
+import os
+import platform
+import shlex
+import shutil
+import sys
+import sysconfig
+import tempfile
+import threading
+import warnings
+from functools import lru_cache
+from pathlib import Path
+from typing import (
+    Any,
+    Callable,
+    Dict,
+    Iterable,
+    Iterator,
+    List,
+    Optional,
+    Tuple,
+    TypeVar,
+    Union,
+)
+
+try:
+    from setuptools import Extension as _Extension
+    from setuptools.command.build_ext import build_ext as _build_ext
+except ImportError:
+    from distutils.command.build_ext import (  # type: ignore[assignment]
+        build_ext as _build_ext,
+    )
+    from distutils.extension import Extension as _Extension  # type: ignore[assignment]
+
+import distutils.ccompiler
+import distutils.errors
+
+WIN = sys.platform.startswith("win32") and "mingw" not in sysconfig.get_platform()
+MACOS = sys.platform.startswith("darwin")
+STD_TMPL = "/std:c++{}" if WIN else "-std=c++{}"
+
+
+# It is recommended to use PEP 518 builds if using this module. However, this
+# file explicitly supports being copied into a user's project directory
+# standalone, and pulling pybind11 with the deprecated setup_requires feature.
+# If you copy the file, remember to add it to your MANIFEST.in, and add the current
+# directory into your path if it sits beside your setup.py.
+
+
+class Pybind11Extension(_Extension):
+    """
+    Build a C++11+ Extension module with pybind11. This automatically adds the
+    recommended flags when you init the extension and assumes C++ sources - you
+    can further modify the options yourself.
+
+    The customizations are:
+
+    * ``/EHsc`` and ``/bigobj`` on Windows
+    * ``stdlib=libc++`` on macOS
+    * ``visibility=hidden`` and ``-g0`` on Unix
+
+    Finally, you can set ``cxx_std`` via constructor or afterwards to enable
+    flags for C++ std, and a few extra helper flags related to the C++ standard
+    level. It is _highly_ recommended you either set this, or use the provided
+    ``build_ext``, which will search for the highest supported extension for
+    you if the ``cxx_std`` property is not set. Do not set the ``cxx_std``
+    property more than once, as flags are added when you set it. Set the
+    property to None to disable the addition of C++ standard flags.
+
+    If you want to add pybind11 headers manually, for example for an exact
+    git checkout, then set ``include_pybind11=False``.
+    """
+
+    # flags are prepended, so that they can be further overridden, e.g. by
+    # ``extra_compile_args=["-g"]``.
+
+    def _add_cflags(self, flags: List[str]) -> None:
+        self.extra_compile_args[:0] = flags
+
+    def _add_ldflags(self, flags: List[str]) -> None:
+        self.extra_link_args[:0] = flags
+
+    def __init__(self, *args: Any, **kwargs: Any) -> None:
+        self._cxx_level = 0
+        cxx_std = kwargs.pop("cxx_std", 0)
+
+        if "language" not in kwargs:
+            kwargs["language"] = "c++"
+
+        include_pybind11 = kwargs.pop("include_pybind11", True)
+
+        super().__init__(*args, **kwargs)
+
+        # Include the installed package pybind11 headers
+        if include_pybind11:
+            # If using setup_requires, this fails the first time - that's okay
+            try:
+                import pybind11
+
+                pyinc = pybind11.get_include()
+
+                if pyinc not in self.include_dirs:
+                    self.include_dirs.append(pyinc)
+            except ModuleNotFoundError:
+                pass
+
+        self.cxx_std = cxx_std
+
+        cflags = []
+        if WIN:
+            cflags += ["/EHsc", "/bigobj"]
+        else:
+            cflags += ["-fvisibility=hidden"]
+            env_cflags = os.environ.get("CFLAGS", "")
+            env_cppflags = os.environ.get("CPPFLAGS", "")
+            c_cpp_flags = shlex.split(env_cflags) + shlex.split(env_cppflags)
+            if not any(opt.startswith("-g") for opt in c_cpp_flags):
+                cflags += ["-g0"]
+        self._add_cflags(cflags)
+
+    @property
+    def cxx_std(self) -> int:
+        """
+        The CXX standard level. If set, will add the required flags. If left at
+        0, it will trigger an automatic search when pybind11's build_ext is
+        used. If None, will have no effect.  Besides just the flags, this may
+        add a macos-min 10.9 or 10.14 flag if MACOSX_DEPLOYMENT_TARGET is
+        unset.
+        """
+        return self._cxx_level
+
+    @cxx_std.setter
+    def cxx_std(self, level: int) -> None:
+        if self._cxx_level:
+            warnings.warn(
+                "You cannot safely change the cxx_level after setting it!", stacklevel=2
+            )
+
+        # MSVC 2015 Update 3 and later only have 14 (and later 17) modes, so
+        # force a valid flag here.
+        if WIN and level == 11:
+            level = 14
+
+        self._cxx_level = level
+
+        if not level:
+            return
+
+        cflags = [STD_TMPL.format(level)]
+        ldflags = []
+
+        if MACOS and "MACOSX_DEPLOYMENT_TARGET" not in os.environ:
+            # C++17 requires a higher min version of macOS. An earlier version
+            # (10.12 or 10.13) can be set manually via environment variable if
+            # you are careful in your feature usage, but 10.14 is the safest
+            # setting for general use. However, never set higher than the
+            # current macOS version!
+            current_macos = tuple(int(x) for x in platform.mac_ver()[0].split(".")[:2])
+            desired_macos = (10, 9) if level < 17 else (10, 14)
+            macos_string = ".".join(str(x) for x in min(current_macos, desired_macos))
+            macosx_min = f"-mmacosx-version-min={macos_string}"
+            cflags += [macosx_min]
+            ldflags += [macosx_min]
+
+        self._add_cflags(cflags)
+        self._add_ldflags(ldflags)
+
+
+# Just in case someone clever tries to multithread
+tmp_chdir_lock = threading.Lock()
+
+
+@contextlib.contextmanager
+def tmp_chdir() -> Iterator[str]:
+    "Prepare and enter a temporary directory, cleanup when done"
+
+    # Threadsafe
+    with tmp_chdir_lock:
+        olddir = os.getcwd()
+        try:
+            tmpdir = tempfile.mkdtemp()
+            os.chdir(tmpdir)
+            yield tmpdir
+        finally:
+            os.chdir(olddir)
+            shutil.rmtree(tmpdir)
+
+
+# cf http://bugs.python.org/issue26689
+def has_flag(compiler: Any, flag: str) -> bool:
+    """
+    Return the flag if a flag name is supported on the
+    specified compiler, otherwise None (can be used as a boolean).
+    If multiple flags are passed, return the first that matches.
+    """
+
+    with tmp_chdir():
+        fname = Path("flagcheck.cpp")
+        # Don't trigger -Wunused-parameter.
+        fname.write_text("int main (int, char **) { return 0; }", encoding="utf-8")
+
+        try:
+            compiler.compile([str(fname)], extra_postargs=[flag])
+        except distutils.errors.CompileError:
+            return False
+        return True
+
+
+# Every call will cache the result
+cpp_flag_cache = None
+
+
+@lru_cache()
+def auto_cpp_level(compiler: Any) -> Union[str, int]:
+    """
+    Return the max supported C++ std level (17, 14, or 11). Returns latest on Windows.
+    """
+
+    if WIN:
+        return "latest"
+
+    levels = [17, 14, 11]
+
+    for level in levels:
+        if has_flag(compiler, STD_TMPL.format(level)):
+            return level
+
+    msg = "Unsupported compiler -- at least C++11 support is needed!"
+    raise RuntimeError(msg)
+
+
+class build_ext(_build_ext):  # noqa: N801
+    """
+    Customized build_ext that allows an auto-search for the highest supported
+    C++ level for Pybind11Extension. This is only needed for the auto-search
+    for now, and is completely optional otherwise.
+    """
+
+    def build_extensions(self) -> None:
+        """
+        Build extensions, injecting C++ std for Pybind11Extension if needed.
+        """
+
+        for ext in self.extensions:
+            if hasattr(ext, "_cxx_level") and ext._cxx_level == 0:
+                ext.cxx_std = auto_cpp_level(self.compiler)
+
+        super().build_extensions()
+
+
+def intree_extensions(
+    paths: Iterable[str], package_dir: Optional[Dict[str, str]] = None
+) -> List[Pybind11Extension]:
+    """
+    Generate Pybind11Extensions from source files directly located in a Python
+    source tree.
+
+    ``package_dir`` behaves as in ``setuptools.setup``.  If unset, the Python
+    package root parent is determined as the first parent directory that does
+    not contain an ``__init__.py`` file.
+    """
+    exts = []
+
+    if package_dir is None:
+        for path in paths:
+            parent, _ = os.path.split(path)
+            while os.path.exists(os.path.join(parent, "__init__.py")):
+                parent, _ = os.path.split(parent)
+            relname, _ = os.path.splitext(os.path.relpath(path, parent))
+            qualified_name = relname.replace(os.path.sep, ".")
+            exts.append(Pybind11Extension(qualified_name, [path]))
+        return exts
+
+    for path in paths:
+        for prefix, parent in package_dir.items():
+            if path.startswith(parent):
+                relname, _ = os.path.splitext(os.path.relpath(path, parent))
+                qualified_name = relname.replace(os.path.sep, ".")
+                if prefix:
+                    qualified_name = prefix + "." + qualified_name
+                exts.append(Pybind11Extension(qualified_name, [path]))
+                break
+        else:
+            msg = (
+                f"path {path} is not a child of any of the directories listed "
+                f"in 'package_dir' ({package_dir})"
+            )
+            raise ValueError(msg)
+
+    return exts
+
+
+def naive_recompile(obj: str, src: str) -> bool:
+    """
+    This will recompile only if the source file changes. It does not check
+    header files, so a more advanced function or Ccache is better if you have
+    editable header files in your package.
+    """
+    return os.stat(obj).st_mtime < os.stat(src).st_mtime
+
+
+def no_recompile(obg: str, src: str) -> bool:  # noqa: ARG001
+    """
+    This is the safest but slowest choice (and is the default) - will always
+    recompile sources.
+    """
+    return True
+
+
+S = TypeVar("S", bound="ParallelCompile")
+
+CCompilerMethod = Callable[
+    [
+        distutils.ccompiler.CCompiler,
+        List[str],
+        Optional[str],
+        Optional[Union[Tuple[str], Tuple[str, Optional[str]]]],
+        Optional[List[str]],
+        bool,
+        Optional[List[str]],
+        Optional[List[str]],
+        Optional[List[str]],
+    ],
+    List[str],
+]
+
+
+# Optional parallel compile utility
+# inspired by: http://stackoverflow.com/questions/11013851/speeding-up-build-process-with-distutils
+# and: https://github.com/tbenthompson/cppimport/blob/stable/cppimport/build_module.py
+# and NumPy's parallel distutils module:
+#              https://github.com/numpy/numpy/blob/master/numpy/distutils/ccompiler.py
+class ParallelCompile:
+    """
+    Make a parallel compile function. Inspired by
+    numpy.distutils.ccompiler.CCompiler.compile and cppimport.
+
+    This takes several arguments that allow you to customize the compile
+    function created:
+
+    envvar:
+        Set an environment variable to control the compilation threads, like
+        NPY_NUM_BUILD_JOBS
+    default:
+        0 will automatically multithread, or 1 will only multithread if the
+        envvar is set.
+    max:
+        The limit for automatic multithreading if non-zero
+    needs_recompile:
+        A function of (obj, src) that returns True when recompile is needed.  No
+        effect in isolated mode; use ccache instead, see
+        https://github.com/matplotlib/matplotlib/issues/1507/
+
+    To use::
+
+        ParallelCompile("NPY_NUM_BUILD_JOBS").install()
+
+    or::
+
+        with ParallelCompile("NPY_NUM_BUILD_JOBS"):
+            setup(...)
+
+    By default, this assumes all files need to be recompiled. A smarter
+    function can be provided via needs_recompile.  If the output has not yet
+    been generated, the compile will always run, and this function is not
+    called.
+    """
+
+    __slots__ = ("envvar", "default", "max", "_old", "needs_recompile")
+
+    def __init__(
+        self,
+        envvar: Optional[str] = None,
+        default: int = 0,
+        max: int = 0,  # pylint: disable=redefined-builtin
+        needs_recompile: Callable[[str, str], bool] = no_recompile,
+    ) -> None:
+        self.envvar = envvar
+        self.default = default
+        self.max = max
+        self.needs_recompile = needs_recompile
+        self._old: List[CCompilerMethod] = []
+
+    def function(self) -> CCompilerMethod:
+        """
+        Builds a function object usable as distutils.ccompiler.CCompiler.compile.
+        """
+
+        def compile_function(
+            compiler: distutils.ccompiler.CCompiler,
+            sources: List[str],
+            output_dir: Optional[str] = None,
+            macros: Optional[Union[Tuple[str], Tuple[str, Optional[str]]]] = None,
+            include_dirs: Optional[List[str]] = None,
+            debug: bool = False,
+            extra_preargs: Optional[List[str]] = None,
+            extra_postargs: Optional[List[str]] = None,
+            depends: Optional[List[str]] = None,
+        ) -> Any:
+            # These lines are directly from distutils.ccompiler.CCompiler
+            macros, objects, extra_postargs, pp_opts, build = compiler._setup_compile(  # type: ignore[attr-defined]
+                output_dir, macros, include_dirs, sources, depends, extra_postargs
+            )
+            cc_args = compiler._get_cc_args(pp_opts, debug, extra_preargs)  # type: ignore[attr-defined]
+
+            # The number of threads; start with default.
+            threads = self.default
+
+            # Determine the number of compilation threads, unless set by an environment variable.
+            if self.envvar is not None:
+                threads = int(os.environ.get(self.envvar, self.default))
+
+            def _single_compile(obj: Any) -> None:
+                try:
+                    src, ext = build[obj]
+                except KeyError:
+                    return
+
+                if not os.path.exists(obj) or self.needs_recompile(obj, src):
+                    compiler._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)  # type: ignore[attr-defined]
+
+            try:
+                # Importing .synchronize checks for platforms that have some multiprocessing
+                # capabilities but lack semaphores, such as AWS Lambda and Android Termux.
+                import multiprocessing.synchronize
+                from multiprocessing.pool import ThreadPool
+            except ImportError:
+                threads = 1
+
+            if threads == 0:
+                try:
+                    threads = multiprocessing.cpu_count()
+                    threads = self.max if self.max and self.max < threads else threads
+                except NotImplementedError:
+                    threads = 1
+
+            if threads > 1:
+                with ThreadPool(threads) as pool:
+                    for _ in pool.imap_unordered(_single_compile, objects):
+                        pass
+            else:
+                for ob in objects:
+                    _single_compile(ob)
+
+            return objects
+
+        return compile_function
+
+    def install(self: S) -> S:
+        """
+        Installs the compile function into distutils.ccompiler.CCompiler.compile.
+        """
+        distutils.ccompiler.CCompiler.compile = self.function()  # type: ignore[assignment]
+        return self
+
+    def __enter__(self: S) -> S:
+        self._old.append(distutils.ccompiler.CCompiler.compile)
+        return self.install()
+
+    def __exit__(self, *args: Any) -> None:
+        distutils.ccompiler.CCompiler.compile = self._old.pop()  # type: ignore[assignment]
```

## extern/pybind11/tests/conftest.py

 * *Ordering differences only*

```diff
@@ -1,221 +1,221 @@
-"""pytest configuration
-
-Extends output capture as needed by pybind11: ignore constructors, optional unordered lines.
-Adds docstring and exceptions message sanitizers.
-"""
-
-import contextlib
-import difflib
-import gc
-import multiprocessing
-import re
-import sys
-import textwrap
-import traceback
-
-import pytest
-
-# Early diagnostic for failed imports
-try:
-    import pybind11_tests
-except Exception:
-    # pytest does not show the traceback without this.
-    traceback.print_exc()
-    raise
-
-
-@pytest.fixture(scope="session", autouse=True)
-def use_multiprocessing_forkserver_on_linux():
-    if sys.platform != "linux":
-        # The default on Windows and macOS is "spawn": If it's not broken, don't fix it.
-        return
-
-    # Full background: https://github.com/pybind/pybind11/issues/4105#issuecomment-1301004592
-    # In a nutshell: fork() after starting threads == flakiness in the form of deadlocks.
-    # It is actually a well-known pitfall, unfortunately without guard rails.
-    # "forkserver" is more performant than "spawn" (~9s vs ~13s for tests/test_gil_scoped.py,
-    # visit the issuecomment link above for details).
-    multiprocessing.set_start_method("forkserver")
-
-
-_long_marker = re.compile(r"([0-9])L")
-_hexadecimal = re.compile(r"0x[0-9a-fA-F]+")
-
-# Avoid collecting Python3 only files
-collect_ignore = []
-
-
-def _strip_and_dedent(s):
-    """For triple-quote strings"""
-    return textwrap.dedent(s.lstrip("\n").rstrip())
-
-
-def _split_and_sort(s):
-    """For output which does not require specific line order"""
-    return sorted(_strip_and_dedent(s).splitlines())
-
-
-def _make_explanation(a, b):
-    """Explanation for a failed assert -- the a and b arguments are List[str]"""
-    return ["--- actual / +++ expected"] + [
-        line.strip("\n") for line in difflib.ndiff(a, b)
-    ]
-
-
-class Output:
-    """Basic output post-processing and comparison"""
-
-    def __init__(self, string):
-        self.string = string
-        self.explanation = []
-
-    def __str__(self):
-        return self.string
-
-    def __eq__(self, other):
-        # Ignore constructor/destructor output which is prefixed with "###"
-        a = [
-            line
-            for line in self.string.strip().splitlines()
-            if not line.startswith("###")
-        ]
-        b = _strip_and_dedent(other).splitlines()
-        if a == b:
-            return True
-        self.explanation = _make_explanation(a, b)
-        return False
-
-
-class Unordered(Output):
-    """Custom comparison for output without strict line ordering"""
-
-    def __eq__(self, other):
-        a = _split_and_sort(self.string)
-        b = _split_and_sort(other)
-        if a == b:
-            return True
-        self.explanation = _make_explanation(a, b)
-        return False
-
-
-class Capture:
-    def __init__(self, capfd):
-        self.capfd = capfd
-        self.out = ""
-        self.err = ""
-
-    def __enter__(self):
-        self.capfd.readouterr()
-        return self
-
-    def __exit__(self, *args):
-        self.out, self.err = self.capfd.readouterr()
-
-    def __eq__(self, other):
-        a = Output(self.out)
-        b = other
-        if a == b:
-            return True
-        self.explanation = a.explanation
-        return False
-
-    def __str__(self):
-        return self.out
-
-    def __contains__(self, item):
-        return item in self.out
-
-    @property
-    def unordered(self):
-        return Unordered(self.out)
-
-    @property
-    def stderr(self):
-        return Output(self.err)
-
-
-@pytest.fixture()
-def capture(capsys):
-    """Extended `capsys` with context manager and custom equality operators"""
-    return Capture(capsys)
-
-
-class SanitizedString:
-    def __init__(self, sanitizer):
-        self.sanitizer = sanitizer
-        self.string = ""
-        self.explanation = []
-
-    def __call__(self, thing):
-        self.string = self.sanitizer(thing)
-        return self
-
-    def __eq__(self, other):
-        a = self.string
-        b = _strip_and_dedent(other)
-        if a == b:
-            return True
-        self.explanation = _make_explanation(a.splitlines(), b.splitlines())
-        return False
-
-
-def _sanitize_general(s):
-    s = s.strip()
-    s = s.replace("pybind11_tests.", "m.")
-    return _long_marker.sub(r"\1", s)
-
-
-def _sanitize_docstring(thing):
-    s = thing.__doc__
-    return _sanitize_general(s)
-
-
-@pytest.fixture()
-def doc():
-    """Sanitize docstrings and add custom failure explanation"""
-    return SanitizedString(_sanitize_docstring)
-
-
-def _sanitize_message(thing):
-    s = str(thing)
-    s = _sanitize_general(s)
-    return _hexadecimal.sub("0", s)
-
-
-@pytest.fixture()
-def msg():
-    """Sanitize messages and add custom failure explanation"""
-    return SanitizedString(_sanitize_message)
-
-
-def pytest_assertrepr_compare(op, left, right):  # noqa: ARG001
-    """Hook to insert custom failure explanation"""
-    if hasattr(left, "explanation"):
-        return left.explanation
-    return None
-
-
-def gc_collect():
-    """Run the garbage collector twice (needed when running
-    reference counting tests with PyPy)"""
-    gc.collect()
-    gc.collect()
-
-
-def pytest_configure():
-    pytest.suppress = contextlib.suppress
-    pytest.gc_collect = gc_collect
-
-
-def pytest_report_header(config):
-    del config  # Unused.
-    assert (
-        pybind11_tests.compiler_info is not None
-    ), "Please update pybind11_tests.cpp if this assert fails."
-    return (
-        "C++ Info:"
-        f" {pybind11_tests.compiler_info}"
-        f" {pybind11_tests.cpp_std}"
-        f" {pybind11_tests.PYBIND11_INTERNALS_ID}"
-        f" PYBIND11_SIMPLE_GIL_MANAGEMENT={pybind11_tests.PYBIND11_SIMPLE_GIL_MANAGEMENT}"
-    )
+"""pytest configuration
+
+Extends output capture as needed by pybind11: ignore constructors, optional unordered lines.
+Adds docstring and exceptions message sanitizers.
+"""
+
+import contextlib
+import difflib
+import gc
+import multiprocessing
+import re
+import sys
+import textwrap
+import traceback
+
+import pytest
+
+# Early diagnostic for failed imports
+try:
+    import pybind11_tests
+except Exception:
+    # pytest does not show the traceback without this.
+    traceback.print_exc()
+    raise
+
+
+@pytest.fixture(scope="session", autouse=True)
+def use_multiprocessing_forkserver_on_linux():
+    if sys.platform != "linux":
+        # The default on Windows and macOS is "spawn": If it's not broken, don't fix it.
+        return
+
+    # Full background: https://github.com/pybind/pybind11/issues/4105#issuecomment-1301004592
+    # In a nutshell: fork() after starting threads == flakiness in the form of deadlocks.
+    # It is actually a well-known pitfall, unfortunately without guard rails.
+    # "forkserver" is more performant than "spawn" (~9s vs ~13s for tests/test_gil_scoped.py,
+    # visit the issuecomment link above for details).
+    multiprocessing.set_start_method("forkserver")
+
+
+_long_marker = re.compile(r"([0-9])L")
+_hexadecimal = re.compile(r"0x[0-9a-fA-F]+")
+
+# Avoid collecting Python3 only files
+collect_ignore = []
+
+
+def _strip_and_dedent(s):
+    """For triple-quote strings"""
+    return textwrap.dedent(s.lstrip("\n").rstrip())
+
+
+def _split_and_sort(s):
+    """For output which does not require specific line order"""
+    return sorted(_strip_and_dedent(s).splitlines())
+
+
+def _make_explanation(a, b):
+    """Explanation for a failed assert -- the a and b arguments are List[str]"""
+    return ["--- actual / +++ expected"] + [
+        line.strip("\n") for line in difflib.ndiff(a, b)
+    ]
+
+
+class Output:
+    """Basic output post-processing and comparison"""
+
+    def __init__(self, string):
+        self.string = string
+        self.explanation = []
+
+    def __str__(self):
+        return self.string
+
+    def __eq__(self, other):
+        # Ignore constructor/destructor output which is prefixed with "###"
+        a = [
+            line
+            for line in self.string.strip().splitlines()
+            if not line.startswith("###")
+        ]
+        b = _strip_and_dedent(other).splitlines()
+        if a == b:
+            return True
+        self.explanation = _make_explanation(a, b)
+        return False
+
+
+class Unordered(Output):
+    """Custom comparison for output without strict line ordering"""
+
+    def __eq__(self, other):
+        a = _split_and_sort(self.string)
+        b = _split_and_sort(other)
+        if a == b:
+            return True
+        self.explanation = _make_explanation(a, b)
+        return False
+
+
+class Capture:
+    def __init__(self, capfd):
+        self.capfd = capfd
+        self.out = ""
+        self.err = ""
+
+    def __enter__(self):
+        self.capfd.readouterr()
+        return self
+
+    def __exit__(self, *args):
+        self.out, self.err = self.capfd.readouterr()
+
+    def __eq__(self, other):
+        a = Output(self.out)
+        b = other
+        if a == b:
+            return True
+        self.explanation = a.explanation
+        return False
+
+    def __str__(self):
+        return self.out
+
+    def __contains__(self, item):
+        return item in self.out
+
+    @property
+    def unordered(self):
+        return Unordered(self.out)
+
+    @property
+    def stderr(self):
+        return Output(self.err)
+
+
+@pytest.fixture()
+def capture(capsys):
+    """Extended `capsys` with context manager and custom equality operators"""
+    return Capture(capsys)
+
+
+class SanitizedString:
+    def __init__(self, sanitizer):
+        self.sanitizer = sanitizer
+        self.string = ""
+        self.explanation = []
+
+    def __call__(self, thing):
+        self.string = self.sanitizer(thing)
+        return self
+
+    def __eq__(self, other):
+        a = self.string
+        b = _strip_and_dedent(other)
+        if a == b:
+            return True
+        self.explanation = _make_explanation(a.splitlines(), b.splitlines())
+        return False
+
+
+def _sanitize_general(s):
+    s = s.strip()
+    s = s.replace("pybind11_tests.", "m.")
+    return _long_marker.sub(r"\1", s)
+
+
+def _sanitize_docstring(thing):
+    s = thing.__doc__
+    return _sanitize_general(s)
+
+
+@pytest.fixture()
+def doc():
+    """Sanitize docstrings and add custom failure explanation"""
+    return SanitizedString(_sanitize_docstring)
+
+
+def _sanitize_message(thing):
+    s = str(thing)
+    s = _sanitize_general(s)
+    return _hexadecimal.sub("0", s)
+
+
+@pytest.fixture()
+def msg():
+    """Sanitize messages and add custom failure explanation"""
+    return SanitizedString(_sanitize_message)
+
+
+def pytest_assertrepr_compare(op, left, right):  # noqa: ARG001
+    """Hook to insert custom failure explanation"""
+    if hasattr(left, "explanation"):
+        return left.explanation
+    return None
+
+
+def gc_collect():
+    """Run the garbage collector twice (needed when running
+    reference counting tests with PyPy)"""
+    gc.collect()
+    gc.collect()
+
+
+def pytest_configure():
+    pytest.suppress = contextlib.suppress
+    pytest.gc_collect = gc_collect
+
+
+def pytest_report_header(config):
+    del config  # Unused.
+    assert (
+        pybind11_tests.compiler_info is not None
+    ), "Please update pybind11_tests.cpp if this assert fails."
+    return (
+        "C++ Info:"
+        f" {pybind11_tests.compiler_info}"
+        f" {pybind11_tests.cpp_std}"
+        f" {pybind11_tests.PYBIND11_INTERNALS_ID}"
+        f" PYBIND11_SIMPLE_GIL_MANAGEMENT={pybind11_tests.PYBIND11_SIMPLE_GIL_MANAGEMENT}"
+    )
```

## extern/pybind11/tests/env.py

 * *Ordering differences only*

```diff
@@ -1,27 +1,27 @@
-import platform
-import sys
-
-import pytest
-
-LINUX = sys.platform.startswith("linux")
-MACOS = sys.platform.startswith("darwin")
-WIN = sys.platform.startswith("win32") or sys.platform.startswith("cygwin")
-
-CPYTHON = platform.python_implementation() == "CPython"
-PYPY = platform.python_implementation() == "PyPy"
-
-
-def deprecated_call():
-    """
-    pytest.deprecated_call() seems broken in pytest<3.9.x; concretely, it
-    doesn't work on CPython 3.8.0 with pytest==3.3.2 on Ubuntu 18.04 (#2922).
-
-    This is a narrowed reimplementation of the following PR :(
-    https://github.com/pytest-dev/pytest/pull/4104
-    """
-    # TODO: Remove this when testing requires pytest>=3.9.
-    pieces = pytest.__version__.split(".")
-    pytest_major_minor = (int(pieces[0]), int(pieces[1]))
-    if pytest_major_minor < (3, 9):
-        return pytest.warns((DeprecationWarning, PendingDeprecationWarning))
-    return pytest.deprecated_call()
+import platform
+import sys
+
+import pytest
+
+LINUX = sys.platform.startswith("linux")
+MACOS = sys.platform.startswith("darwin")
+WIN = sys.platform.startswith("win32") or sys.platform.startswith("cygwin")
+
+CPYTHON = platform.python_implementation() == "CPython"
+PYPY = platform.python_implementation() == "PyPy"
+
+
+def deprecated_call():
+    """
+    pytest.deprecated_call() seems broken in pytest<3.9.x; concretely, it
+    doesn't work on CPython 3.8.0 with pytest==3.3.2 on Ubuntu 18.04 (#2922).
+
+    This is a narrowed reimplementation of the following PR :(
+    https://github.com/pytest-dev/pytest/pull/4104
+    """
+    # TODO: Remove this when testing requires pytest>=3.9.
+    pieces = pytest.__version__.split(".")
+    pytest_major_minor = (int(pieces[0]), int(pieces[1]))
+    if pytest_major_minor < (3, 9):
+        return pytest.warns((DeprecationWarning, PendingDeprecationWarning))
+    return pytest.deprecated_call()
```

## extern/pybind11/tests/test_async.py

 * *Ordering differences only*

```diff
@@ -1,24 +1,24 @@
-import pytest
-
-asyncio = pytest.importorskip("asyncio")
-m = pytest.importorskip("pybind11_tests.async_module")
-
-
-@pytest.fixture()
-def event_loop():
-    loop = asyncio.new_event_loop()
-    yield loop
-    loop.close()
-
-
-async def get_await_result(x):
-    return await x
-
-
-def test_await(event_loop):
-    assert event_loop.run_until_complete(get_await_result(m.SupportsAsync())) == 5
-
-
-def test_await_missing(event_loop):
-    with pytest.raises(TypeError):
-        event_loop.run_until_complete(get_await_result(m.DoesNotSupportAsync()))
+import pytest
+
+asyncio = pytest.importorskip("asyncio")
+m = pytest.importorskip("pybind11_tests.async_module")
+
+
+@pytest.fixture()
+def event_loop():
+    loop = asyncio.new_event_loop()
+    yield loop
+    loop.close()
+
+
+async def get_await_result(x):
+    return await x
+
+
+def test_await(event_loop):
+    assert event_loop.run_until_complete(get_await_result(m.SupportsAsync())) == 5
+
+
+def test_await_missing(event_loop):
+    with pytest.raises(TypeError):
+        event_loop.run_until_complete(get_await_result(m.DoesNotSupportAsync()))
```

## extern/pybind11/tests/test_buffers.py

 * *Ordering differences only*

```diff
@@ -1,228 +1,228 @@
-import ctypes
-import io
-import struct
-
-import pytest
-
-import env
-from pybind11_tests import ConstructorStats
-from pybind11_tests import buffers as m
-
-np = pytest.importorskip("numpy")
-
-if m.long_double_and_double_have_same_size:
-    # Determined by the compiler used to build the pybind11 tests
-    # (e.g. MSVC gets here, but MinGW might not).
-    np_float128 = None
-    np_complex256 = None
-else:
-    # Determined by the compiler used to build numpy (e.g. MinGW).
-    np_float128 = getattr(np, *["float128"] * 2)
-    np_complex256 = getattr(np, *["complex256"] * 2)
-
-CPP_NAME_FORMAT_NP_DTYPE_TABLE = [
-    ("PyObject *", "O", object),
-    ("bool", "?", np.bool_),
-    ("std::int8_t", "b", np.int8),
-    ("std::uint8_t", "B", np.uint8),
-    ("std::int16_t", "h", np.int16),
-    ("std::uint16_t", "H", np.uint16),
-    ("std::int32_t", "i", np.int32),
-    ("std::uint32_t", "I", np.uint32),
-    ("std::int64_t", "q", np.int64),
-    ("std::uint64_t", "Q", np.uint64),
-    ("float", "f", np.float32),
-    ("double", "d", np.float64),
-    ("long double", "g", np_float128),
-    ("std::complex<float>", "Zf", np.complex64),
-    ("std::complex<double>", "Zd", np.complex128),
-    ("std::complex<long double>", "Zg", np_complex256),
-]
-CPP_NAME_FORMAT_TABLE = [
-    (cpp_name, format)
-    for cpp_name, format, np_dtype in CPP_NAME_FORMAT_NP_DTYPE_TABLE
-    if np_dtype is not None
-]
-CPP_NAME_NP_DTYPE_TABLE = [
-    (cpp_name, np_dtype) for cpp_name, _, np_dtype in CPP_NAME_FORMAT_NP_DTYPE_TABLE
-]
-
-
-@pytest.mark.parametrize(("cpp_name", "np_dtype"), CPP_NAME_NP_DTYPE_TABLE)
-def test_format_descriptor_format_buffer_info_equiv(cpp_name, np_dtype):
-    if np_dtype is None:
-        pytest.skip(
-            f"cpp_name=`{cpp_name}`: `long double` and `double` have same size."
-        )
-    if isinstance(np_dtype, str):
-        pytest.skip(f"np.{np_dtype} does not exist.")
-    np_array = np.array([], dtype=np_dtype)
-    for other_cpp_name, expected_format in CPP_NAME_FORMAT_TABLE:
-        format, np_array_is_matching = m.format_descriptor_format_buffer_info_equiv(
-            other_cpp_name, np_array
-        )
-        assert format == expected_format
-        if other_cpp_name == cpp_name:
-            assert np_array_is_matching
-        else:
-            assert not np_array_is_matching
-
-
-def test_from_python():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.Matrix(np.array([1, 2, 3]))  # trying to assign a 1D array
-    assert str(excinfo.value) == "Incompatible buffer format!"
-
-    m3 = np.array([[1, 2, 3], [4, 5, 6]]).astype(np.float32)
-    m4 = m.Matrix(m3)
-
-    for i in range(m4.rows()):
-        for j in range(m4.cols()):
-            assert m3[i, j] == m4[i, j]
-
-    cstats = ConstructorStats.get(m.Matrix)
-    assert cstats.alive() == 1
-    del m3, m4
-    assert cstats.alive() == 0
-    assert cstats.values() == ["2x3 matrix"]
-    assert cstats.copy_constructions == 0
-    # assert cstats.move_constructions >= 0  # Don't invoke any
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-
-# https://foss.heptapod.net/pypy/pypy/-/issues/2444
-# TODO: fix on recent PyPy
-@pytest.mark.xfail(
-    env.PYPY, reason="PyPy 7.3.7 doesn't clear this anymore", strict=False
-)
-def test_to_python():
-    mat = m.Matrix(5, 4)
-    assert memoryview(mat).shape == (5, 4)
-
-    assert mat[2, 3] == 0
-    mat[2, 3] = 4.0
-    mat[3, 2] = 7.0
-    assert mat[2, 3] == 4
-    assert mat[3, 2] == 7
-    assert struct.unpack_from("f", mat, (3 * 4 + 2) * 4) == (7,)
-    assert struct.unpack_from("f", mat, (2 * 4 + 3) * 4) == (4,)
-
-    mat2 = np.array(mat, copy=False)
-    assert mat2.shape == (5, 4)
-    assert abs(mat2).sum() == 11
-    assert mat2[2, 3] == 4
-    assert mat2[3, 2] == 7
-    mat2[2, 3] = 5
-    assert mat2[2, 3] == 5
-
-    cstats = ConstructorStats.get(m.Matrix)
-    assert cstats.alive() == 1
-    del mat
-    pytest.gc_collect()
-    assert cstats.alive() == 1
-    del mat2  # holds a mat reference
-    pytest.gc_collect()
-    assert cstats.alive() == 0
-    assert cstats.values() == ["5x4 matrix"]
-    assert cstats.copy_constructions == 0
-    # assert cstats.move_constructions >= 0  # Don't invoke any
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-
-def test_inherited_protocol():
-    """SquareMatrix is derived from Matrix and inherits the buffer protocol"""
-
-    matrix = m.SquareMatrix(5)
-    assert memoryview(matrix).shape == (5, 5)
-    assert np.asarray(matrix).shape == (5, 5)
-
-
-def test_pointer_to_member_fn():
-    for cls in [m.Buffer, m.ConstBuffer, m.DerivedBuffer]:
-        buf = cls()
-        buf.value = 0x12345678
-        value = struct.unpack("i", bytearray(buf))[0]
-        assert value == 0x12345678
-
-
-def test_readonly_buffer():
-    buf = m.BufferReadOnly(0x64)
-    view = memoryview(buf)
-    assert view[0] == 0x64
-    assert view.readonly
-    with pytest.raises(TypeError):
-        view[0] = 0
-
-
-def test_selective_readonly_buffer():
-    buf = m.BufferReadOnlySelect()
-
-    memoryview(buf)[0] = 0x64
-    assert buf.value == 0x64
-
-    io.BytesIO(b"A").readinto(buf)
-    assert buf.value == ord(b"A")
-
-    buf.readonly = True
-    with pytest.raises(TypeError):
-        memoryview(buf)[0] = 0
-    with pytest.raises(TypeError):
-        io.BytesIO(b"1").readinto(buf)
-
-
-def test_ctypes_array_1d():
-    char1d = (ctypes.c_char * 10)()
-    int1d = (ctypes.c_int * 15)()
-    long1d = (ctypes.c_long * 7)()
-
-    for carray in (char1d, int1d, long1d):
-        info = m.get_buffer_info(carray)
-        assert info.itemsize == ctypes.sizeof(carray._type_)
-        assert info.size == len(carray)
-        assert info.ndim == 1
-        assert info.shape == [info.size]
-        assert info.strides == [info.itemsize]
-        assert not info.readonly
-
-
-def test_ctypes_array_2d():
-    char2d = ((ctypes.c_char * 10) * 4)()
-    int2d = ((ctypes.c_int * 15) * 3)()
-    long2d = ((ctypes.c_long * 7) * 2)()
-
-    for carray in (char2d, int2d, long2d):
-        info = m.get_buffer_info(carray)
-        assert info.itemsize == ctypes.sizeof(carray[0]._type_)
-        assert info.size == len(carray) * len(carray[0])
-        assert info.ndim == 2
-        assert info.shape == [len(carray), len(carray[0])]
-        assert info.strides == [info.itemsize * len(carray[0]), info.itemsize]
-        assert not info.readonly
-
-
-def test_ctypes_from_buffer():
-    test_pystr = b"0123456789"
-    for pyarray in (test_pystr, bytearray(test_pystr)):
-        pyinfo = m.get_buffer_info(pyarray)
-
-        if pyinfo.readonly:
-            cbytes = (ctypes.c_char * len(pyarray)).from_buffer_copy(pyarray)
-            cinfo = m.get_buffer_info(cbytes)
-        else:
-            cbytes = (ctypes.c_char * len(pyarray)).from_buffer(pyarray)
-            cinfo = m.get_buffer_info(cbytes)
-
-        assert cinfo.size == pyinfo.size
-        assert cinfo.ndim == pyinfo.ndim
-        assert cinfo.shape == pyinfo.shape
-        assert cinfo.strides == pyinfo.strides
-        assert not cinfo.readonly
-
-
-def test_buffer_docstring():
-    assert (
-        m.get_buffer_info.__doc__.strip()
-        == "get_buffer_info(arg0: Buffer) -> pybind11_tests.buffers.buffer_info"
-    )
+import ctypes
+import io
+import struct
+
+import pytest
+
+import env
+from pybind11_tests import ConstructorStats
+from pybind11_tests import buffers as m
+
+np = pytest.importorskip("numpy")
+
+if m.long_double_and_double_have_same_size:
+    # Determined by the compiler used to build the pybind11 tests
+    # (e.g. MSVC gets here, but MinGW might not).
+    np_float128 = None
+    np_complex256 = None
+else:
+    # Determined by the compiler used to build numpy (e.g. MinGW).
+    np_float128 = getattr(np, *["float128"] * 2)
+    np_complex256 = getattr(np, *["complex256"] * 2)
+
+CPP_NAME_FORMAT_NP_DTYPE_TABLE = [
+    ("PyObject *", "O", object),
+    ("bool", "?", np.bool_),
+    ("std::int8_t", "b", np.int8),
+    ("std::uint8_t", "B", np.uint8),
+    ("std::int16_t", "h", np.int16),
+    ("std::uint16_t", "H", np.uint16),
+    ("std::int32_t", "i", np.int32),
+    ("std::uint32_t", "I", np.uint32),
+    ("std::int64_t", "q", np.int64),
+    ("std::uint64_t", "Q", np.uint64),
+    ("float", "f", np.float32),
+    ("double", "d", np.float64),
+    ("long double", "g", np_float128),
+    ("std::complex<float>", "Zf", np.complex64),
+    ("std::complex<double>", "Zd", np.complex128),
+    ("std::complex<long double>", "Zg", np_complex256),
+]
+CPP_NAME_FORMAT_TABLE = [
+    (cpp_name, format)
+    for cpp_name, format, np_dtype in CPP_NAME_FORMAT_NP_DTYPE_TABLE
+    if np_dtype is not None
+]
+CPP_NAME_NP_DTYPE_TABLE = [
+    (cpp_name, np_dtype) for cpp_name, _, np_dtype in CPP_NAME_FORMAT_NP_DTYPE_TABLE
+]
+
+
+@pytest.mark.parametrize(("cpp_name", "np_dtype"), CPP_NAME_NP_DTYPE_TABLE)
+def test_format_descriptor_format_buffer_info_equiv(cpp_name, np_dtype):
+    if np_dtype is None:
+        pytest.skip(
+            f"cpp_name=`{cpp_name}`: `long double` and `double` have same size."
+        )
+    if isinstance(np_dtype, str):
+        pytest.skip(f"np.{np_dtype} does not exist.")
+    np_array = np.array([], dtype=np_dtype)
+    for other_cpp_name, expected_format in CPP_NAME_FORMAT_TABLE:
+        format, np_array_is_matching = m.format_descriptor_format_buffer_info_equiv(
+            other_cpp_name, np_array
+        )
+        assert format == expected_format
+        if other_cpp_name == cpp_name:
+            assert np_array_is_matching
+        else:
+            assert not np_array_is_matching
+
+
+def test_from_python():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.Matrix(np.array([1, 2, 3]))  # trying to assign a 1D array
+    assert str(excinfo.value) == "Incompatible buffer format!"
+
+    m3 = np.array([[1, 2, 3], [4, 5, 6]]).astype(np.float32)
+    m4 = m.Matrix(m3)
+
+    for i in range(m4.rows()):
+        for j in range(m4.cols()):
+            assert m3[i, j] == m4[i, j]
+
+    cstats = ConstructorStats.get(m.Matrix)
+    assert cstats.alive() == 1
+    del m3, m4
+    assert cstats.alive() == 0
+    assert cstats.values() == ["2x3 matrix"]
+    assert cstats.copy_constructions == 0
+    # assert cstats.move_constructions >= 0  # Don't invoke any
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+
+# https://foss.heptapod.net/pypy/pypy/-/issues/2444
+# TODO: fix on recent PyPy
+@pytest.mark.xfail(
+    env.PYPY, reason="PyPy 7.3.7 doesn't clear this anymore", strict=False
+)
+def test_to_python():
+    mat = m.Matrix(5, 4)
+    assert memoryview(mat).shape == (5, 4)
+
+    assert mat[2, 3] == 0
+    mat[2, 3] = 4.0
+    mat[3, 2] = 7.0
+    assert mat[2, 3] == 4
+    assert mat[3, 2] == 7
+    assert struct.unpack_from("f", mat, (3 * 4 + 2) * 4) == (7,)
+    assert struct.unpack_from("f", mat, (2 * 4 + 3) * 4) == (4,)
+
+    mat2 = np.array(mat, copy=False)
+    assert mat2.shape == (5, 4)
+    assert abs(mat2).sum() == 11
+    assert mat2[2, 3] == 4
+    assert mat2[3, 2] == 7
+    mat2[2, 3] = 5
+    assert mat2[2, 3] == 5
+
+    cstats = ConstructorStats.get(m.Matrix)
+    assert cstats.alive() == 1
+    del mat
+    pytest.gc_collect()
+    assert cstats.alive() == 1
+    del mat2  # holds a mat reference
+    pytest.gc_collect()
+    assert cstats.alive() == 0
+    assert cstats.values() == ["5x4 matrix"]
+    assert cstats.copy_constructions == 0
+    # assert cstats.move_constructions >= 0  # Don't invoke any
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+
+def test_inherited_protocol():
+    """SquareMatrix is derived from Matrix and inherits the buffer protocol"""
+
+    matrix = m.SquareMatrix(5)
+    assert memoryview(matrix).shape == (5, 5)
+    assert np.asarray(matrix).shape == (5, 5)
+
+
+def test_pointer_to_member_fn():
+    for cls in [m.Buffer, m.ConstBuffer, m.DerivedBuffer]:
+        buf = cls()
+        buf.value = 0x12345678
+        value = struct.unpack("i", bytearray(buf))[0]
+        assert value == 0x12345678
+
+
+def test_readonly_buffer():
+    buf = m.BufferReadOnly(0x64)
+    view = memoryview(buf)
+    assert view[0] == 0x64
+    assert view.readonly
+    with pytest.raises(TypeError):
+        view[0] = 0
+
+
+def test_selective_readonly_buffer():
+    buf = m.BufferReadOnlySelect()
+
+    memoryview(buf)[0] = 0x64
+    assert buf.value == 0x64
+
+    io.BytesIO(b"A").readinto(buf)
+    assert buf.value == ord(b"A")
+
+    buf.readonly = True
+    with pytest.raises(TypeError):
+        memoryview(buf)[0] = 0
+    with pytest.raises(TypeError):
+        io.BytesIO(b"1").readinto(buf)
+
+
+def test_ctypes_array_1d():
+    char1d = (ctypes.c_char * 10)()
+    int1d = (ctypes.c_int * 15)()
+    long1d = (ctypes.c_long * 7)()
+
+    for carray in (char1d, int1d, long1d):
+        info = m.get_buffer_info(carray)
+        assert info.itemsize == ctypes.sizeof(carray._type_)
+        assert info.size == len(carray)
+        assert info.ndim == 1
+        assert info.shape == [info.size]
+        assert info.strides == [info.itemsize]
+        assert not info.readonly
+
+
+def test_ctypes_array_2d():
+    char2d = ((ctypes.c_char * 10) * 4)()
+    int2d = ((ctypes.c_int * 15) * 3)()
+    long2d = ((ctypes.c_long * 7) * 2)()
+
+    for carray in (char2d, int2d, long2d):
+        info = m.get_buffer_info(carray)
+        assert info.itemsize == ctypes.sizeof(carray[0]._type_)
+        assert info.size == len(carray) * len(carray[0])
+        assert info.ndim == 2
+        assert info.shape == [len(carray), len(carray[0])]
+        assert info.strides == [info.itemsize * len(carray[0]), info.itemsize]
+        assert not info.readonly
+
+
+def test_ctypes_from_buffer():
+    test_pystr = b"0123456789"
+    for pyarray in (test_pystr, bytearray(test_pystr)):
+        pyinfo = m.get_buffer_info(pyarray)
+
+        if pyinfo.readonly:
+            cbytes = (ctypes.c_char * len(pyarray)).from_buffer_copy(pyarray)
+            cinfo = m.get_buffer_info(cbytes)
+        else:
+            cbytes = (ctypes.c_char * len(pyarray)).from_buffer(pyarray)
+            cinfo = m.get_buffer_info(cbytes)
+
+        assert cinfo.size == pyinfo.size
+        assert cinfo.ndim == pyinfo.ndim
+        assert cinfo.shape == pyinfo.shape
+        assert cinfo.strides == pyinfo.strides
+        assert not cinfo.readonly
+
+
+def test_buffer_docstring():
+    assert (
+        m.get_buffer_info.__doc__.strip()
+        == "get_buffer_info(arg0: Buffer) -> pybind11_tests.buffers.buffer_info"
+    )
```

## extern/pybind11/tests/test_builtin_casters.py

 * *Ordering differences only*

```diff
@@ -1,528 +1,528 @@
-import sys
-
-import pytest
-
-import env
-from pybind11_tests import IncType, UserType
-from pybind11_tests import builtin_casters as m
-
-
-def test_simple_string():
-    assert m.string_roundtrip("const char *") == "const char *"
-
-
-def test_unicode_conversion():
-    """Tests unicode conversion and error reporting."""
-    assert m.good_utf8_string() == "Say utf8‽ 🎂 𝐀"
-    assert m.good_utf16_string() == "b‽🎂𝐀z"
-    assert m.good_utf32_string() == "a𝐀🎂‽z"
-    assert m.good_wchar_string() == "a⸘𝐀z"
-    if hasattr(m, "has_u8string"):
-        assert m.good_utf8_u8string() == "Say utf8‽ 🎂 𝐀"
-
-    with pytest.raises(UnicodeDecodeError):
-        m.bad_utf8_string()
-
-    with pytest.raises(UnicodeDecodeError):
-        m.bad_utf16_string()
-
-    # These are provided only if they actually fail (they don't when 32-bit)
-    if hasattr(m, "bad_utf32_string"):
-        with pytest.raises(UnicodeDecodeError):
-            m.bad_utf32_string()
-    if hasattr(m, "bad_wchar_string"):
-        with pytest.raises(UnicodeDecodeError):
-            m.bad_wchar_string()
-    if hasattr(m, "has_u8string"):
-        with pytest.raises(UnicodeDecodeError):
-            m.bad_utf8_u8string()
-
-    assert m.u8_Z() == "Z"
-    assert m.u8_eacute() == "é"
-    assert m.u16_ibang() == "‽"
-    assert m.u32_mathbfA() == "𝐀"
-    assert m.wchar_heart() == "♥"
-    if hasattr(m, "has_u8string"):
-        assert m.u8_char8_Z() == "Z"
-
-
-def test_single_char_arguments():
-    """Tests failures for passing invalid inputs to char-accepting functions"""
-
-    def toobig_message(r):
-        return f"Character code point not in range({r:#x})"
-
-    toolong_message = "Expected a character, but multi-character string found"
-
-    assert m.ord_char("a") == 0x61  # simple ASCII
-    assert m.ord_char_lv("b") == 0x62
-    assert (
-        m.ord_char("é") == 0xE9
-    )  # requires 2 bytes in utf-8, but can be stuffed in a char
-    with pytest.raises(ValueError) as excinfo:
-        assert m.ord_char("Ā") == 0x100  # requires 2 bytes, doesn't fit in a char
-    assert str(excinfo.value) == toobig_message(0x100)
-    with pytest.raises(ValueError) as excinfo:
-        assert m.ord_char("ab")
-    assert str(excinfo.value) == toolong_message
-
-    assert m.ord_char16("a") == 0x61
-    assert m.ord_char16("é") == 0xE9
-    assert m.ord_char16_lv("ê") == 0xEA
-    assert m.ord_char16("Ā") == 0x100
-    assert m.ord_char16("‽") == 0x203D
-    assert m.ord_char16("♥") == 0x2665
-    assert m.ord_char16_lv("♡") == 0x2661
-    with pytest.raises(ValueError) as excinfo:
-        assert m.ord_char16("🎂") == 0x1F382  # requires surrogate pair
-    assert str(excinfo.value) == toobig_message(0x10000)
-    with pytest.raises(ValueError) as excinfo:
-        assert m.ord_char16("aa")
-    assert str(excinfo.value) == toolong_message
-
-    assert m.ord_char32("a") == 0x61
-    assert m.ord_char32("é") == 0xE9
-    assert m.ord_char32("Ā") == 0x100
-    assert m.ord_char32("‽") == 0x203D
-    assert m.ord_char32("♥") == 0x2665
-    assert m.ord_char32("🎂") == 0x1F382
-    with pytest.raises(ValueError) as excinfo:
-        assert m.ord_char32("aa")
-    assert str(excinfo.value) == toolong_message
-
-    assert m.ord_wchar("a") == 0x61
-    assert m.ord_wchar("é") == 0xE9
-    assert m.ord_wchar("Ā") == 0x100
-    assert m.ord_wchar("‽") == 0x203D
-    assert m.ord_wchar("♥") == 0x2665
-    if m.wchar_size == 2:
-        with pytest.raises(ValueError) as excinfo:
-            assert m.ord_wchar("🎂") == 0x1F382  # requires surrogate pair
-        assert str(excinfo.value) == toobig_message(0x10000)
-    else:
-        assert m.ord_wchar("🎂") == 0x1F382
-    with pytest.raises(ValueError) as excinfo:
-        assert m.ord_wchar("aa")
-    assert str(excinfo.value) == toolong_message
-
-    if hasattr(m, "has_u8string"):
-        assert m.ord_char8("a") == 0x61  # simple ASCII
-        assert m.ord_char8_lv("b") == 0x62
-        assert (
-            m.ord_char8("é") == 0xE9
-        )  # requires 2 bytes in utf-8, but can be stuffed in a char
-        with pytest.raises(ValueError) as excinfo:
-            assert m.ord_char8("Ā") == 0x100  # requires 2 bytes, doesn't fit in a char
-        assert str(excinfo.value) == toobig_message(0x100)
-        with pytest.raises(ValueError) as excinfo:
-            assert m.ord_char8("ab")
-        assert str(excinfo.value) == toolong_message
-
-
-def test_bytes_to_string():
-    """Tests the ability to pass bytes to C++ string-accepting functions.  Note that this is
-    one-way: the only way to return bytes to Python is via the pybind11::bytes class."""
-    # Issue #816
-
-    assert m.strlen(b"hi") == 2
-    assert m.string_length(b"world") == 5
-    assert m.string_length(b"a\x00b") == 3
-    assert m.strlen(b"a\x00b") == 1  # C-string limitation
-
-    # passing in a utf8 encoded string should work
-    assert m.string_length("💩".encode()) == 4
-
-
-def test_bytearray_to_string():
-    """Tests the ability to pass bytearray to C++ string-accepting functions"""
-    assert m.string_length(bytearray(b"Hi")) == 2
-    assert m.strlen(bytearray(b"bytearray")) == 9
-    assert m.string_length(bytearray()) == 0
-    assert m.string_length(bytearray("🦜", "utf-8", "strict")) == 4
-    assert m.string_length(bytearray(b"\x80")) == 1
-
-
-@pytest.mark.skipif(not hasattr(m, "has_string_view"), reason="no <string_view>")
-def test_string_view(capture):
-    """Tests support for C++17 string_view arguments and return values"""
-    assert m.string_view_chars("Hi") == [72, 105]
-    assert m.string_view_chars("Hi 🎂") == [72, 105, 32, 0xF0, 0x9F, 0x8E, 0x82]
-    assert m.string_view16_chars("Hi 🎂") == [72, 105, 32, 0xD83C, 0xDF82]
-    assert m.string_view32_chars("Hi 🎂") == [72, 105, 32, 127874]
-    if hasattr(m, "has_u8string"):
-        assert m.string_view8_chars("Hi") == [72, 105]
-        assert m.string_view8_chars("Hi 🎂") == [72, 105, 32, 0xF0, 0x9F, 0x8E, 0x82]
-
-    assert m.string_view_return() == "utf8 secret 🎂"
-    assert m.string_view16_return() == "utf16 secret 🎂"
-    assert m.string_view32_return() == "utf32 secret 🎂"
-    if hasattr(m, "has_u8string"):
-        assert m.string_view8_return() == "utf8 secret 🎂"
-
-    with capture:
-        m.string_view_print("Hi")
-        m.string_view_print("utf8 🎂")
-        m.string_view16_print("utf16 🎂")
-        m.string_view32_print("utf32 🎂")
-    assert (
-        capture
-        == """
-        Hi 2
-        utf8 🎂 9
-        utf16 🎂 8
-        utf32 🎂 7
-    """
-    )
-    if hasattr(m, "has_u8string"):
-        with capture:
-            m.string_view8_print("Hi")
-            m.string_view8_print("utf8 🎂")
-        assert (
-            capture
-            == """
-            Hi 2
-            utf8 🎂 9
-        """
-        )
-
-    with capture:
-        m.string_view_print("Hi, ascii")
-        m.string_view_print("Hi, utf8 🎂")
-        m.string_view16_print("Hi, utf16 🎂")
-        m.string_view32_print("Hi, utf32 🎂")
-    assert (
-        capture
-        == """
-        Hi, ascii 9
-        Hi, utf8 🎂 13
-        Hi, utf16 🎂 12
-        Hi, utf32 🎂 11
-    """
-    )
-    if hasattr(m, "has_u8string"):
-        with capture:
-            m.string_view8_print("Hi, ascii")
-            m.string_view8_print("Hi, utf8 🎂")
-        assert (
-            capture
-            == """
-            Hi, ascii 9
-            Hi, utf8 🎂 13
-        """
-        )
-
-    assert m.string_view_bytes() == b"abc \x80\x80 def"
-    assert m.string_view_str() == "abc ‽ def"
-    assert m.string_view_from_bytes("abc ‽ def".encode()) == "abc ‽ def"
-    if hasattr(m, "has_u8string"):
-        assert m.string_view8_str() == "abc ‽ def"
-    assert m.string_view_memoryview() == "Have some 🎂".encode()
-
-    assert m.bytes_from_type_with_both_operator_string_and_string_view() == b"success"
-    assert m.str_from_type_with_both_operator_string_and_string_view() == "success"
-
-
-def test_integer_casting():
-    """Issue #929 - out-of-range integer values shouldn't be accepted"""
-    assert m.i32_str(-1) == "-1"
-    assert m.i64_str(-1) == "-1"
-    assert m.i32_str(2000000000) == "2000000000"
-    assert m.u32_str(2000000000) == "2000000000"
-    assert m.i64_str(-999999999999) == "-999999999999"
-    assert m.u64_str(999999999999) == "999999999999"
-
-    with pytest.raises(TypeError) as excinfo:
-        m.u32_str(-1)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.u64_str(-1)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.i32_str(-3000000000)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.i32_str(3000000000)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-
-def test_int_convert():
-    class Int:
-        def __int__(self):
-            return 42
-
-    class NotInt:
-        pass
-
-    class Float:
-        def __float__(self):
-            return 41.99999
-
-    class Index:
-        def __index__(self):
-            return 42
-
-    class IntAndIndex:
-        def __int__(self):
-            return 42
-
-        def __index__(self):
-            return 0
-
-    class RaisingTypeErrorOnIndex:
-        def __index__(self):
-            raise TypeError
-
-        def __int__(self):
-            return 42
-
-    class RaisingValueErrorOnIndex:
-        def __index__(self):
-            raise ValueError
-
-        def __int__(self):
-            return 42
-
-    convert, noconvert = m.int_passthrough, m.int_passthrough_noconvert
-
-    def requires_conversion(v):
-        pytest.raises(TypeError, noconvert, v)
-
-    def cant_convert(v):
-        pytest.raises(TypeError, convert, v)
-
-    assert convert(7) == 7
-    assert noconvert(7) == 7
-    cant_convert(3.14159)
-    # TODO: Avoid DeprecationWarning in `PyLong_AsLong` (and similar)
-    # TODO: PyPy 3.8 does not behave like CPython 3.8 here yet (7.3.7)
-    if (3, 8) <= sys.version_info < (3, 10) and env.CPYTHON:
-        with env.deprecated_call():
-            assert convert(Int()) == 42
-    else:
-        assert convert(Int()) == 42
-    requires_conversion(Int())
-    cant_convert(NotInt())
-    cant_convert(Float())
-
-    # Before Python 3.8, `PyLong_AsLong` does not pick up on `obj.__index__`,
-    # but pybind11 "backports" this behavior.
-    assert convert(Index()) == 42
-    assert noconvert(Index()) == 42
-    assert convert(IntAndIndex()) == 0  # Fishy; `int(DoubleThought)` == 42
-    assert noconvert(IntAndIndex()) == 0
-    assert convert(RaisingTypeErrorOnIndex()) == 42
-    requires_conversion(RaisingTypeErrorOnIndex())
-    assert convert(RaisingValueErrorOnIndex()) == 42
-    requires_conversion(RaisingValueErrorOnIndex())
-
-
-def test_numpy_int_convert():
-    np = pytest.importorskip("numpy")
-
-    convert, noconvert = m.int_passthrough, m.int_passthrough_noconvert
-
-    def require_implicit(v):
-        pytest.raises(TypeError, noconvert, v)
-
-    # `np.intc` is an alias that corresponds to a C++ `int`
-    assert convert(np.intc(42)) == 42
-    assert noconvert(np.intc(42)) == 42
-
-    # The implicit conversion from np.float32 is undesirable but currently accepted.
-    # TODO: Avoid DeprecationWarning in `PyLong_AsLong` (and similar)
-    # TODO: PyPy 3.8 does not behave like CPython 3.8 here yet (7.3.7)
-    # https://github.com/pybind/pybind11/issues/3408
-    if (3, 8) <= sys.version_info < (3, 10) and env.CPYTHON:
-        with env.deprecated_call():
-            assert convert(np.float32(3.14159)) == 3
-    else:
-        assert convert(np.float32(3.14159)) == 3
-    require_implicit(np.float32(3.14159))
-
-
-def test_tuple(doc):
-    """std::pair <-> tuple & std::tuple <-> tuple"""
-    assert m.pair_passthrough((True, "test")) == ("test", True)
-    assert m.tuple_passthrough((True, "test", 5)) == (5, "test", True)
-    # Any sequence can be cast to a std::pair or std::tuple
-    assert m.pair_passthrough([True, "test"]) == ("test", True)
-    assert m.tuple_passthrough([True, "test", 5]) == (5, "test", True)
-    assert m.empty_tuple() == ()
-
-    assert (
-        doc(m.pair_passthrough)
-        == """
-        pair_passthrough(arg0: tuple[bool, str]) -> tuple[str, bool]
-
-        Return a pair in reversed order
-    """
-    )
-    assert (
-        doc(m.tuple_passthrough)
-        == """
-        tuple_passthrough(arg0: tuple[bool, str, int]) -> tuple[int, str, bool]
-
-        Return a triple in reversed order
-    """
-    )
-
-    assert m.rvalue_pair() == ("rvalue", "rvalue")
-    assert m.lvalue_pair() == ("lvalue", "lvalue")
-    assert m.rvalue_tuple() == ("rvalue", "rvalue", "rvalue")
-    assert m.lvalue_tuple() == ("lvalue", "lvalue", "lvalue")
-    assert m.rvalue_nested() == ("rvalue", ("rvalue", ("rvalue", "rvalue")))
-    assert m.lvalue_nested() == ("lvalue", ("lvalue", ("lvalue", "lvalue")))
-
-    assert m.int_string_pair() == (2, "items")
-
-
-def test_builtins_cast_return_none():
-    """Casters produced with PYBIND11_TYPE_CASTER() should convert nullptr to None"""
-    assert m.return_none_string() is None
-    assert m.return_none_char() is None
-    assert m.return_none_bool() is None
-    assert m.return_none_int() is None
-    assert m.return_none_float() is None
-    assert m.return_none_pair() is None
-
-
-def test_none_deferred():
-    """None passed as various argument types should defer to other overloads"""
-    assert not m.defer_none_cstring("abc")
-    assert m.defer_none_cstring(None)
-    assert not m.defer_none_custom(UserType())
-    assert m.defer_none_custom(None)
-    assert m.nodefer_none_void(None)
-
-
-def test_void_caster():
-    assert m.load_nullptr_t(None) is None
-    assert m.cast_nullptr_t() is None
-
-
-def test_reference_wrapper():
-    """std::reference_wrapper for builtin and user types"""
-    assert m.refwrap_builtin(42) == 420
-    assert m.refwrap_usertype(UserType(42)) == 42
-    assert m.refwrap_usertype_const(UserType(42)) == 42
-
-    with pytest.raises(TypeError) as excinfo:
-        m.refwrap_builtin(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.refwrap_usertype(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    assert m.refwrap_lvalue().value == 1
-    assert m.refwrap_lvalue_const().value == 1
-
-    a1 = m.refwrap_list(copy=True)
-    a2 = m.refwrap_list(copy=True)
-    assert [x.value for x in a1] == [2, 3]
-    assert [x.value for x in a2] == [2, 3]
-    assert a1[0] is not a2[0]
-    assert a1[1] is not a2[1]
-
-    b1 = m.refwrap_list(copy=False)
-    b2 = m.refwrap_list(copy=False)
-    assert [x.value for x in b1] == [1, 2]
-    assert [x.value for x in b2] == [1, 2]
-    assert b1[0] is b2[0]
-    assert b1[1] is b2[1]
-
-    assert m.refwrap_iiw(IncType(5)) == 5
-    assert m.refwrap_call_iiw(IncType(10), m.refwrap_iiw) == [10, 10, 10, 10]
-
-
-def test_complex_cast():
-    """std::complex casts"""
-    assert m.complex_cast(1) == "1.0"
-    assert m.complex_cast(2j) == "(0.0, 2.0)"
-
-
-def test_bool_caster():
-    """Test bool caster implicit conversions."""
-    convert, noconvert = m.bool_passthrough, m.bool_passthrough_noconvert
-
-    def require_implicit(v):
-        pytest.raises(TypeError, noconvert, v)
-
-    def cant_convert(v):
-        pytest.raises(TypeError, convert, v)
-
-    # straight up bool
-    assert convert(True) is True
-    assert convert(False) is False
-    assert noconvert(True) is True
-    assert noconvert(False) is False
-
-    # None requires implicit conversion
-    require_implicit(None)
-    assert convert(None) is False
-
-    class A:
-        def __init__(self, x):
-            self.x = x
-
-        def __nonzero__(self):
-            return self.x
-
-        def __bool__(self):
-            return self.x
-
-    class B:
-        pass
-
-    # Arbitrary objects are not accepted
-    cant_convert(object())
-    cant_convert(B())
-
-    # Objects with __nonzero__ / __bool__ defined can be converted
-    require_implicit(A(True))
-    assert convert(A(True)) is True
-    assert convert(A(False)) is False
-
-
-def test_numpy_bool():
-    np = pytest.importorskip("numpy")
-
-    convert, noconvert = m.bool_passthrough, m.bool_passthrough_noconvert
-
-    def cant_convert(v):
-        pytest.raises(TypeError, convert, v)
-
-    # np.bool_ is not considered implicit
-    assert convert(np.bool_(True)) is True
-    assert convert(np.bool_(False)) is False
-    assert noconvert(np.bool_(True)) is True
-    assert noconvert(np.bool_(False)) is False
-    cant_convert(np.zeros(2, dtype="int"))
-
-
-def test_int_long():
-    assert isinstance(m.int_cast(), int)
-    assert isinstance(m.long_cast(), int)
-    assert isinstance(m.longlong_cast(), int)
-
-
-def test_void_caster_2():
-    assert m.test_void_caster()
-
-
-def test_const_ref_caster():
-    """Verifies that const-ref is propagated through type_caster cast_op.
-    The returned ConstRefCasted type is a minimal type that is constructed to
-    reference the casting mode used.
-    """
-    x = False
-    assert m.takes(x) == 1
-    assert m.takes_move(x) == 1
-
-    assert m.takes_ptr(x) == 3
-    assert m.takes_ref(x) == 2
-    assert m.takes_ref_wrap(x) == 2
-
-    assert m.takes_const_ptr(x) == 5
-    assert m.takes_const_ref(x) == 4
-    assert m.takes_const_ref_wrap(x) == 4
+import sys
+
+import pytest
+
+import env
+from pybind11_tests import IncType, UserType
+from pybind11_tests import builtin_casters as m
+
+
+def test_simple_string():
+    assert m.string_roundtrip("const char *") == "const char *"
+
+
+def test_unicode_conversion():
+    """Tests unicode conversion and error reporting."""
+    assert m.good_utf8_string() == "Say utf8‽ 🎂 𝐀"
+    assert m.good_utf16_string() == "b‽🎂𝐀z"
+    assert m.good_utf32_string() == "a𝐀🎂‽z"
+    assert m.good_wchar_string() == "a⸘𝐀z"
+    if hasattr(m, "has_u8string"):
+        assert m.good_utf8_u8string() == "Say utf8‽ 🎂 𝐀"
+
+    with pytest.raises(UnicodeDecodeError):
+        m.bad_utf8_string()
+
+    with pytest.raises(UnicodeDecodeError):
+        m.bad_utf16_string()
+
+    # These are provided only if they actually fail (they don't when 32-bit)
+    if hasattr(m, "bad_utf32_string"):
+        with pytest.raises(UnicodeDecodeError):
+            m.bad_utf32_string()
+    if hasattr(m, "bad_wchar_string"):
+        with pytest.raises(UnicodeDecodeError):
+            m.bad_wchar_string()
+    if hasattr(m, "has_u8string"):
+        with pytest.raises(UnicodeDecodeError):
+            m.bad_utf8_u8string()
+
+    assert m.u8_Z() == "Z"
+    assert m.u8_eacute() == "é"
+    assert m.u16_ibang() == "‽"
+    assert m.u32_mathbfA() == "𝐀"
+    assert m.wchar_heart() == "♥"
+    if hasattr(m, "has_u8string"):
+        assert m.u8_char8_Z() == "Z"
+
+
+def test_single_char_arguments():
+    """Tests failures for passing invalid inputs to char-accepting functions"""
+
+    def toobig_message(r):
+        return f"Character code point not in range({r:#x})"
+
+    toolong_message = "Expected a character, but multi-character string found"
+
+    assert m.ord_char("a") == 0x61  # simple ASCII
+    assert m.ord_char_lv("b") == 0x62
+    assert (
+        m.ord_char("é") == 0xE9
+    )  # requires 2 bytes in utf-8, but can be stuffed in a char
+    with pytest.raises(ValueError) as excinfo:
+        assert m.ord_char("Ā") == 0x100  # requires 2 bytes, doesn't fit in a char
+    assert str(excinfo.value) == toobig_message(0x100)
+    with pytest.raises(ValueError) as excinfo:
+        assert m.ord_char("ab")
+    assert str(excinfo.value) == toolong_message
+
+    assert m.ord_char16("a") == 0x61
+    assert m.ord_char16("é") == 0xE9
+    assert m.ord_char16_lv("ê") == 0xEA
+    assert m.ord_char16("Ā") == 0x100
+    assert m.ord_char16("‽") == 0x203D
+    assert m.ord_char16("♥") == 0x2665
+    assert m.ord_char16_lv("♡") == 0x2661
+    with pytest.raises(ValueError) as excinfo:
+        assert m.ord_char16("🎂") == 0x1F382  # requires surrogate pair
+    assert str(excinfo.value) == toobig_message(0x10000)
+    with pytest.raises(ValueError) as excinfo:
+        assert m.ord_char16("aa")
+    assert str(excinfo.value) == toolong_message
+
+    assert m.ord_char32("a") == 0x61
+    assert m.ord_char32("é") == 0xE9
+    assert m.ord_char32("Ā") == 0x100
+    assert m.ord_char32("‽") == 0x203D
+    assert m.ord_char32("♥") == 0x2665
+    assert m.ord_char32("🎂") == 0x1F382
+    with pytest.raises(ValueError) as excinfo:
+        assert m.ord_char32("aa")
+    assert str(excinfo.value) == toolong_message
+
+    assert m.ord_wchar("a") == 0x61
+    assert m.ord_wchar("é") == 0xE9
+    assert m.ord_wchar("Ā") == 0x100
+    assert m.ord_wchar("‽") == 0x203D
+    assert m.ord_wchar("♥") == 0x2665
+    if m.wchar_size == 2:
+        with pytest.raises(ValueError) as excinfo:
+            assert m.ord_wchar("🎂") == 0x1F382  # requires surrogate pair
+        assert str(excinfo.value) == toobig_message(0x10000)
+    else:
+        assert m.ord_wchar("🎂") == 0x1F382
+    with pytest.raises(ValueError) as excinfo:
+        assert m.ord_wchar("aa")
+    assert str(excinfo.value) == toolong_message
+
+    if hasattr(m, "has_u8string"):
+        assert m.ord_char8("a") == 0x61  # simple ASCII
+        assert m.ord_char8_lv("b") == 0x62
+        assert (
+            m.ord_char8("é") == 0xE9
+        )  # requires 2 bytes in utf-8, but can be stuffed in a char
+        with pytest.raises(ValueError) as excinfo:
+            assert m.ord_char8("Ā") == 0x100  # requires 2 bytes, doesn't fit in a char
+        assert str(excinfo.value) == toobig_message(0x100)
+        with pytest.raises(ValueError) as excinfo:
+            assert m.ord_char8("ab")
+        assert str(excinfo.value) == toolong_message
+
+
+def test_bytes_to_string():
+    """Tests the ability to pass bytes to C++ string-accepting functions.  Note that this is
+    one-way: the only way to return bytes to Python is via the pybind11::bytes class."""
+    # Issue #816
+
+    assert m.strlen(b"hi") == 2
+    assert m.string_length(b"world") == 5
+    assert m.string_length(b"a\x00b") == 3
+    assert m.strlen(b"a\x00b") == 1  # C-string limitation
+
+    # passing in a utf8 encoded string should work
+    assert m.string_length("💩".encode()) == 4
+
+
+def test_bytearray_to_string():
+    """Tests the ability to pass bytearray to C++ string-accepting functions"""
+    assert m.string_length(bytearray(b"Hi")) == 2
+    assert m.strlen(bytearray(b"bytearray")) == 9
+    assert m.string_length(bytearray()) == 0
+    assert m.string_length(bytearray("🦜", "utf-8", "strict")) == 4
+    assert m.string_length(bytearray(b"\x80")) == 1
+
+
+@pytest.mark.skipif(not hasattr(m, "has_string_view"), reason="no <string_view>")
+def test_string_view(capture):
+    """Tests support for C++17 string_view arguments and return values"""
+    assert m.string_view_chars("Hi") == [72, 105]
+    assert m.string_view_chars("Hi 🎂") == [72, 105, 32, 0xF0, 0x9F, 0x8E, 0x82]
+    assert m.string_view16_chars("Hi 🎂") == [72, 105, 32, 0xD83C, 0xDF82]
+    assert m.string_view32_chars("Hi 🎂") == [72, 105, 32, 127874]
+    if hasattr(m, "has_u8string"):
+        assert m.string_view8_chars("Hi") == [72, 105]
+        assert m.string_view8_chars("Hi 🎂") == [72, 105, 32, 0xF0, 0x9F, 0x8E, 0x82]
+
+    assert m.string_view_return() == "utf8 secret 🎂"
+    assert m.string_view16_return() == "utf16 secret 🎂"
+    assert m.string_view32_return() == "utf32 secret 🎂"
+    if hasattr(m, "has_u8string"):
+        assert m.string_view8_return() == "utf8 secret 🎂"
+
+    with capture:
+        m.string_view_print("Hi")
+        m.string_view_print("utf8 🎂")
+        m.string_view16_print("utf16 🎂")
+        m.string_view32_print("utf32 🎂")
+    assert (
+        capture
+        == """
+        Hi 2
+        utf8 🎂 9
+        utf16 🎂 8
+        utf32 🎂 7
+    """
+    )
+    if hasattr(m, "has_u8string"):
+        with capture:
+            m.string_view8_print("Hi")
+            m.string_view8_print("utf8 🎂")
+        assert (
+            capture
+            == """
+            Hi 2
+            utf8 🎂 9
+        """
+        )
+
+    with capture:
+        m.string_view_print("Hi, ascii")
+        m.string_view_print("Hi, utf8 🎂")
+        m.string_view16_print("Hi, utf16 🎂")
+        m.string_view32_print("Hi, utf32 🎂")
+    assert (
+        capture
+        == """
+        Hi, ascii 9
+        Hi, utf8 🎂 13
+        Hi, utf16 🎂 12
+        Hi, utf32 🎂 11
+    """
+    )
+    if hasattr(m, "has_u8string"):
+        with capture:
+            m.string_view8_print("Hi, ascii")
+            m.string_view8_print("Hi, utf8 🎂")
+        assert (
+            capture
+            == """
+            Hi, ascii 9
+            Hi, utf8 🎂 13
+        """
+        )
+
+    assert m.string_view_bytes() == b"abc \x80\x80 def"
+    assert m.string_view_str() == "abc ‽ def"
+    assert m.string_view_from_bytes("abc ‽ def".encode()) == "abc ‽ def"
+    if hasattr(m, "has_u8string"):
+        assert m.string_view8_str() == "abc ‽ def"
+    assert m.string_view_memoryview() == "Have some 🎂".encode()
+
+    assert m.bytes_from_type_with_both_operator_string_and_string_view() == b"success"
+    assert m.str_from_type_with_both_operator_string_and_string_view() == "success"
+
+
+def test_integer_casting():
+    """Issue #929 - out-of-range integer values shouldn't be accepted"""
+    assert m.i32_str(-1) == "-1"
+    assert m.i64_str(-1) == "-1"
+    assert m.i32_str(2000000000) == "2000000000"
+    assert m.u32_str(2000000000) == "2000000000"
+    assert m.i64_str(-999999999999) == "-999999999999"
+    assert m.u64_str(999999999999) == "999999999999"
+
+    with pytest.raises(TypeError) as excinfo:
+        m.u32_str(-1)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.u64_str(-1)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.i32_str(-3000000000)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.i32_str(3000000000)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+
+def test_int_convert():
+    class Int:
+        def __int__(self):
+            return 42
+
+    class NotInt:
+        pass
+
+    class Float:
+        def __float__(self):
+            return 41.99999
+
+    class Index:
+        def __index__(self):
+            return 42
+
+    class IntAndIndex:
+        def __int__(self):
+            return 42
+
+        def __index__(self):
+            return 0
+
+    class RaisingTypeErrorOnIndex:
+        def __index__(self):
+            raise TypeError
+
+        def __int__(self):
+            return 42
+
+    class RaisingValueErrorOnIndex:
+        def __index__(self):
+            raise ValueError
+
+        def __int__(self):
+            return 42
+
+    convert, noconvert = m.int_passthrough, m.int_passthrough_noconvert
+
+    def requires_conversion(v):
+        pytest.raises(TypeError, noconvert, v)
+
+    def cant_convert(v):
+        pytest.raises(TypeError, convert, v)
+
+    assert convert(7) == 7
+    assert noconvert(7) == 7
+    cant_convert(3.14159)
+    # TODO: Avoid DeprecationWarning in `PyLong_AsLong` (and similar)
+    # TODO: PyPy 3.8 does not behave like CPython 3.8 here yet (7.3.7)
+    if (3, 8) <= sys.version_info < (3, 10) and env.CPYTHON:
+        with env.deprecated_call():
+            assert convert(Int()) == 42
+    else:
+        assert convert(Int()) == 42
+    requires_conversion(Int())
+    cant_convert(NotInt())
+    cant_convert(Float())
+
+    # Before Python 3.8, `PyLong_AsLong` does not pick up on `obj.__index__`,
+    # but pybind11 "backports" this behavior.
+    assert convert(Index()) == 42
+    assert noconvert(Index()) == 42
+    assert convert(IntAndIndex()) == 0  # Fishy; `int(DoubleThought)` == 42
+    assert noconvert(IntAndIndex()) == 0
+    assert convert(RaisingTypeErrorOnIndex()) == 42
+    requires_conversion(RaisingTypeErrorOnIndex())
+    assert convert(RaisingValueErrorOnIndex()) == 42
+    requires_conversion(RaisingValueErrorOnIndex())
+
+
+def test_numpy_int_convert():
+    np = pytest.importorskip("numpy")
+
+    convert, noconvert = m.int_passthrough, m.int_passthrough_noconvert
+
+    def require_implicit(v):
+        pytest.raises(TypeError, noconvert, v)
+
+    # `np.intc` is an alias that corresponds to a C++ `int`
+    assert convert(np.intc(42)) == 42
+    assert noconvert(np.intc(42)) == 42
+
+    # The implicit conversion from np.float32 is undesirable but currently accepted.
+    # TODO: Avoid DeprecationWarning in `PyLong_AsLong` (and similar)
+    # TODO: PyPy 3.8 does not behave like CPython 3.8 here yet (7.3.7)
+    # https://github.com/pybind/pybind11/issues/3408
+    if (3, 8) <= sys.version_info < (3, 10) and env.CPYTHON:
+        with env.deprecated_call():
+            assert convert(np.float32(3.14159)) == 3
+    else:
+        assert convert(np.float32(3.14159)) == 3
+    require_implicit(np.float32(3.14159))
+
+
+def test_tuple(doc):
+    """std::pair <-> tuple & std::tuple <-> tuple"""
+    assert m.pair_passthrough((True, "test")) == ("test", True)
+    assert m.tuple_passthrough((True, "test", 5)) == (5, "test", True)
+    # Any sequence can be cast to a std::pair or std::tuple
+    assert m.pair_passthrough([True, "test"]) == ("test", True)
+    assert m.tuple_passthrough([True, "test", 5]) == (5, "test", True)
+    assert m.empty_tuple() == ()
+
+    assert (
+        doc(m.pair_passthrough)
+        == """
+        pair_passthrough(arg0: tuple[bool, str]) -> tuple[str, bool]
+
+        Return a pair in reversed order
+    """
+    )
+    assert (
+        doc(m.tuple_passthrough)
+        == """
+        tuple_passthrough(arg0: tuple[bool, str, int]) -> tuple[int, str, bool]
+
+        Return a triple in reversed order
+    """
+    )
+
+    assert m.rvalue_pair() == ("rvalue", "rvalue")
+    assert m.lvalue_pair() == ("lvalue", "lvalue")
+    assert m.rvalue_tuple() == ("rvalue", "rvalue", "rvalue")
+    assert m.lvalue_tuple() == ("lvalue", "lvalue", "lvalue")
+    assert m.rvalue_nested() == ("rvalue", ("rvalue", ("rvalue", "rvalue")))
+    assert m.lvalue_nested() == ("lvalue", ("lvalue", ("lvalue", "lvalue")))
+
+    assert m.int_string_pair() == (2, "items")
+
+
+def test_builtins_cast_return_none():
+    """Casters produced with PYBIND11_TYPE_CASTER() should convert nullptr to None"""
+    assert m.return_none_string() is None
+    assert m.return_none_char() is None
+    assert m.return_none_bool() is None
+    assert m.return_none_int() is None
+    assert m.return_none_float() is None
+    assert m.return_none_pair() is None
+
+
+def test_none_deferred():
+    """None passed as various argument types should defer to other overloads"""
+    assert not m.defer_none_cstring("abc")
+    assert m.defer_none_cstring(None)
+    assert not m.defer_none_custom(UserType())
+    assert m.defer_none_custom(None)
+    assert m.nodefer_none_void(None)
+
+
+def test_void_caster():
+    assert m.load_nullptr_t(None) is None
+    assert m.cast_nullptr_t() is None
+
+
+def test_reference_wrapper():
+    """std::reference_wrapper for builtin and user types"""
+    assert m.refwrap_builtin(42) == 420
+    assert m.refwrap_usertype(UserType(42)) == 42
+    assert m.refwrap_usertype_const(UserType(42)) == 42
+
+    with pytest.raises(TypeError) as excinfo:
+        m.refwrap_builtin(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.refwrap_usertype(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.refwrap_lvalue().value == 1
+    assert m.refwrap_lvalue_const().value == 1
+
+    a1 = m.refwrap_list(copy=True)
+    a2 = m.refwrap_list(copy=True)
+    assert [x.value for x in a1] == [2, 3]
+    assert [x.value for x in a2] == [2, 3]
+    assert a1[0] is not a2[0]
+    assert a1[1] is not a2[1]
+
+    b1 = m.refwrap_list(copy=False)
+    b2 = m.refwrap_list(copy=False)
+    assert [x.value for x in b1] == [1, 2]
+    assert [x.value for x in b2] == [1, 2]
+    assert b1[0] is b2[0]
+    assert b1[1] is b2[1]
+
+    assert m.refwrap_iiw(IncType(5)) == 5
+    assert m.refwrap_call_iiw(IncType(10), m.refwrap_iiw) == [10, 10, 10, 10]
+
+
+def test_complex_cast():
+    """std::complex casts"""
+    assert m.complex_cast(1) == "1.0"
+    assert m.complex_cast(2j) == "(0.0, 2.0)"
+
+
+def test_bool_caster():
+    """Test bool caster implicit conversions."""
+    convert, noconvert = m.bool_passthrough, m.bool_passthrough_noconvert
+
+    def require_implicit(v):
+        pytest.raises(TypeError, noconvert, v)
+
+    def cant_convert(v):
+        pytest.raises(TypeError, convert, v)
+
+    # straight up bool
+    assert convert(True) is True
+    assert convert(False) is False
+    assert noconvert(True) is True
+    assert noconvert(False) is False
+
+    # None requires implicit conversion
+    require_implicit(None)
+    assert convert(None) is False
+
+    class A:
+        def __init__(self, x):
+            self.x = x
+
+        def __nonzero__(self):
+            return self.x
+
+        def __bool__(self):
+            return self.x
+
+    class B:
+        pass
+
+    # Arbitrary objects are not accepted
+    cant_convert(object())
+    cant_convert(B())
+
+    # Objects with __nonzero__ / __bool__ defined can be converted
+    require_implicit(A(True))
+    assert convert(A(True)) is True
+    assert convert(A(False)) is False
+
+
+def test_numpy_bool():
+    np = pytest.importorskip("numpy")
+
+    convert, noconvert = m.bool_passthrough, m.bool_passthrough_noconvert
+
+    def cant_convert(v):
+        pytest.raises(TypeError, convert, v)
+
+    # np.bool_ is not considered implicit
+    assert convert(np.bool_(True)) is True
+    assert convert(np.bool_(False)) is False
+    assert noconvert(np.bool_(True)) is True
+    assert noconvert(np.bool_(False)) is False
+    cant_convert(np.zeros(2, dtype="int"))
+
+
+def test_int_long():
+    assert isinstance(m.int_cast(), int)
+    assert isinstance(m.long_cast(), int)
+    assert isinstance(m.longlong_cast(), int)
+
+
+def test_void_caster_2():
+    assert m.test_void_caster()
+
+
+def test_const_ref_caster():
+    """Verifies that const-ref is propagated through type_caster cast_op.
+    The returned ConstRefCasted type is a minimal type that is constructed to
+    reference the casting mode used.
+    """
+    x = False
+    assert m.takes(x) == 1
+    assert m.takes_move(x) == 1
+
+    assert m.takes_ptr(x) == 3
+    assert m.takes_ref(x) == 2
+    assert m.takes_ref_wrap(x) == 2
+
+    assert m.takes_const_ptr(x) == 5
+    assert m.takes_const_ref(x) == 4
+    assert m.takes_const_ref_wrap(x) == 4
```

## extern/pybind11/tests/test_call_policies.py

 * *Ordering differences only*

```diff
@@ -1,247 +1,247 @@
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import ConstructorStats
-from pybind11_tests import call_policies as m
-
-
-@pytest.mark.xfail("env.PYPY", reason="sometimes comes out 1 off on PyPy", strict=False)
-def test_keep_alive_argument(capture):
-    n_inst = ConstructorStats.detail_reg_inst()
-    with capture:
-        p = m.Parent()
-    assert capture == "Allocating parent."
-    with capture:
-        p.addChild(m.Child())
-        assert ConstructorStats.detail_reg_inst() == n_inst + 1
-    assert (
-        capture
-        == """
-        Allocating child.
-        Releasing child.
-    """
-    )
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert capture == "Releasing parent."
-
-    with capture:
-        p = m.Parent()
-    assert capture == "Allocating parent."
-    with capture:
-        p.addChildKeepAlive(m.Child())
-        assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    assert capture == "Allocating child."
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert (
-        capture
-        == """
-        Releasing parent.
-        Releasing child.
-    """
-    )
-
-    p = m.Parent()
-    c = m.Child()
-    assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    m.free_function(p, c)
-    del c
-    assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    del p
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.invalid_arg_index()
-    assert str(excinfo.value) == "Could not activate keep_alive!"
-
-
-def test_keep_alive_return_value(capture):
-    n_inst = ConstructorStats.detail_reg_inst()
-    with capture:
-        p = m.Parent()
-    assert capture == "Allocating parent."
-    with capture:
-        p.returnChild()
-        assert ConstructorStats.detail_reg_inst() == n_inst + 1
-    assert (
-        capture
-        == """
-        Allocating child.
-        Releasing child.
-    """
-    )
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert capture == "Releasing parent."
-
-    with capture:
-        p = m.Parent()
-    assert capture == "Allocating parent."
-    with capture:
-        p.returnChildKeepAlive()
-        assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    assert capture == "Allocating child."
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert (
-        capture
-        == """
-        Releasing parent.
-        Releasing child.
-    """
-    )
-
-    p = m.Parent()
-    assert ConstructorStats.detail_reg_inst() == n_inst + 1
-    with capture:
-        m.Parent.staticFunction(p)
-        assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    assert capture == "Allocating child."
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert (
-        capture
-        == """
-        Releasing parent.
-        Releasing child.
-    """
-    )
-
-
-# https://foss.heptapod.net/pypy/pypy/-/issues/2447
-@pytest.mark.xfail("env.PYPY", reason="_PyObject_GetDictPtr is unimplemented")
-def test_alive_gc(capture):
-    n_inst = ConstructorStats.detail_reg_inst()
-    p = m.ParentGC()
-    p.addChildKeepAlive(m.Child())
-    assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    lst = [p]
-    lst.append(lst)  # creates a circular reference
-    with capture:
-        del p, lst
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert (
-        capture
-        == """
-        Releasing parent.
-        Releasing child.
-    """
-    )
-
-
-def test_alive_gc_derived(capture):
-    class Derived(m.Parent):
-        pass
-
-    n_inst = ConstructorStats.detail_reg_inst()
-    p = Derived()
-    p.addChildKeepAlive(m.Child())
-    assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    lst = [p]
-    lst.append(lst)  # creates a circular reference
-    with capture:
-        del p, lst
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert (
-        capture
-        == """
-        Releasing parent.
-        Releasing child.
-    """
-    )
-
-
-def test_alive_gc_multi_derived(capture):
-    class Derived(m.Parent, m.Child):
-        def __init__(self):
-            m.Parent.__init__(self)
-            m.Child.__init__(self)
-
-    n_inst = ConstructorStats.detail_reg_inst()
-    p = Derived()
-    p.addChildKeepAlive(m.Child())
-    # +3 rather than +2 because Derived corresponds to two registered instances
-    assert ConstructorStats.detail_reg_inst() == n_inst + 3
-    lst = [p]
-    lst.append(lst)  # creates a circular reference
-    with capture:
-        del p, lst
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert (
-        capture
-        == """
-        Releasing parent.
-        Releasing child.
-        Releasing child.
-    """
-    )
-
-
-def test_return_none(capture):
-    n_inst = ConstructorStats.detail_reg_inst()
-    with capture:
-        p = m.Parent()
-    assert capture == "Allocating parent."
-    with capture:
-        p.returnNullChildKeepAliveChild()
-        assert ConstructorStats.detail_reg_inst() == n_inst + 1
-    assert capture == ""
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert capture == "Releasing parent."
-
-    with capture:
-        p = m.Parent()
-    assert capture == "Allocating parent."
-    with capture:
-        p.returnNullChildKeepAliveParent()
-        assert ConstructorStats.detail_reg_inst() == n_inst + 1
-    assert capture == ""
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert capture == "Releasing parent."
-
-
-def test_keep_alive_constructor(capture):
-    n_inst = ConstructorStats.detail_reg_inst()
-
-    with capture:
-        p = m.Parent(m.Child())
-        assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    assert (
-        capture
-        == """
-        Allocating child.
-        Allocating parent.
-    """
-    )
-    with capture:
-        del p
-        assert ConstructorStats.detail_reg_inst() == n_inst
-    assert (
-        capture
-        == """
-        Releasing parent.
-        Releasing child.
-    """
-    )
-
-
-def test_call_guard():
-    assert m.unguarded_call() == "unguarded"
-    assert m.guarded_call() == "guarded"
-
-    assert m.multiple_guards_correct_order() == "guarded & guarded"
-    assert m.multiple_guards_wrong_order() == "unguarded & guarded"
-
-    if hasattr(m, "with_gil"):
-        assert m.with_gil() == "GIL held"
-        assert m.without_gil() == "GIL released"
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import ConstructorStats
+from pybind11_tests import call_policies as m
+
+
+@pytest.mark.xfail("env.PYPY", reason="sometimes comes out 1 off on PyPy", strict=False)
+def test_keep_alive_argument(capture):
+    n_inst = ConstructorStats.detail_reg_inst()
+    with capture:
+        p = m.Parent()
+    assert capture == "Allocating parent."
+    with capture:
+        p.addChild(m.Child())
+        assert ConstructorStats.detail_reg_inst() == n_inst + 1
+    assert (
+        capture
+        == """
+        Allocating child.
+        Releasing child.
+    """
+    )
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert capture == "Releasing parent."
+
+    with capture:
+        p = m.Parent()
+    assert capture == "Allocating parent."
+    with capture:
+        p.addChildKeepAlive(m.Child())
+        assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    assert capture == "Allocating child."
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert (
+        capture
+        == """
+        Releasing parent.
+        Releasing child.
+    """
+    )
+
+    p = m.Parent()
+    c = m.Child()
+    assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    m.free_function(p, c)
+    del c
+    assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    del p
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.invalid_arg_index()
+    assert str(excinfo.value) == "Could not activate keep_alive!"
+
+
+def test_keep_alive_return_value(capture):
+    n_inst = ConstructorStats.detail_reg_inst()
+    with capture:
+        p = m.Parent()
+    assert capture == "Allocating parent."
+    with capture:
+        p.returnChild()
+        assert ConstructorStats.detail_reg_inst() == n_inst + 1
+    assert (
+        capture
+        == """
+        Allocating child.
+        Releasing child.
+    """
+    )
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert capture == "Releasing parent."
+
+    with capture:
+        p = m.Parent()
+    assert capture == "Allocating parent."
+    with capture:
+        p.returnChildKeepAlive()
+        assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    assert capture == "Allocating child."
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert (
+        capture
+        == """
+        Releasing parent.
+        Releasing child.
+    """
+    )
+
+    p = m.Parent()
+    assert ConstructorStats.detail_reg_inst() == n_inst + 1
+    with capture:
+        m.Parent.staticFunction(p)
+        assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    assert capture == "Allocating child."
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert (
+        capture
+        == """
+        Releasing parent.
+        Releasing child.
+    """
+    )
+
+
+# https://foss.heptapod.net/pypy/pypy/-/issues/2447
+@pytest.mark.xfail("env.PYPY", reason="_PyObject_GetDictPtr is unimplemented")
+def test_alive_gc(capture):
+    n_inst = ConstructorStats.detail_reg_inst()
+    p = m.ParentGC()
+    p.addChildKeepAlive(m.Child())
+    assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    lst = [p]
+    lst.append(lst)  # creates a circular reference
+    with capture:
+        del p, lst
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert (
+        capture
+        == """
+        Releasing parent.
+        Releasing child.
+    """
+    )
+
+
+def test_alive_gc_derived(capture):
+    class Derived(m.Parent):
+        pass
+
+    n_inst = ConstructorStats.detail_reg_inst()
+    p = Derived()
+    p.addChildKeepAlive(m.Child())
+    assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    lst = [p]
+    lst.append(lst)  # creates a circular reference
+    with capture:
+        del p, lst
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert (
+        capture
+        == """
+        Releasing parent.
+        Releasing child.
+    """
+    )
+
+
+def test_alive_gc_multi_derived(capture):
+    class Derived(m.Parent, m.Child):
+        def __init__(self):
+            m.Parent.__init__(self)
+            m.Child.__init__(self)
+
+    n_inst = ConstructorStats.detail_reg_inst()
+    p = Derived()
+    p.addChildKeepAlive(m.Child())
+    # +3 rather than +2 because Derived corresponds to two registered instances
+    assert ConstructorStats.detail_reg_inst() == n_inst + 3
+    lst = [p]
+    lst.append(lst)  # creates a circular reference
+    with capture:
+        del p, lst
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert (
+        capture
+        == """
+        Releasing parent.
+        Releasing child.
+        Releasing child.
+    """
+    )
+
+
+def test_return_none(capture):
+    n_inst = ConstructorStats.detail_reg_inst()
+    with capture:
+        p = m.Parent()
+    assert capture == "Allocating parent."
+    with capture:
+        p.returnNullChildKeepAliveChild()
+        assert ConstructorStats.detail_reg_inst() == n_inst + 1
+    assert capture == ""
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert capture == "Releasing parent."
+
+    with capture:
+        p = m.Parent()
+    assert capture == "Allocating parent."
+    with capture:
+        p.returnNullChildKeepAliveParent()
+        assert ConstructorStats.detail_reg_inst() == n_inst + 1
+    assert capture == ""
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert capture == "Releasing parent."
+
+
+def test_keep_alive_constructor(capture):
+    n_inst = ConstructorStats.detail_reg_inst()
+
+    with capture:
+        p = m.Parent(m.Child())
+        assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    assert (
+        capture
+        == """
+        Allocating child.
+        Allocating parent.
+    """
+    )
+    with capture:
+        del p
+        assert ConstructorStats.detail_reg_inst() == n_inst
+    assert (
+        capture
+        == """
+        Releasing parent.
+        Releasing child.
+    """
+    )
+
+
+def test_call_guard():
+    assert m.unguarded_call() == "unguarded"
+    assert m.guarded_call() == "guarded"
+
+    assert m.multiple_guards_correct_order() == "guarded & guarded"
+    assert m.multiple_guards_wrong_order() == "unguarded & guarded"
+
+    if hasattr(m, "with_gil"):
+        assert m.with_gil() == "GIL held"
+        assert m.without_gil() == "GIL released"
```

## extern/pybind11/tests/test_callbacks.py

 * *Ordering differences only*

```diff
@@ -1,225 +1,225 @@
-import time
-from threading import Thread
-
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import callbacks as m
-from pybind11_tests import detailed_error_messages_enabled
-
-
-def test_callbacks():
-    from functools import partial
-
-    def func1():
-        return "func1"
-
-    def func2(a, b, c, d):
-        return "func2", a, b, c, d
-
-    def func3(a):
-        return f"func3({a})"
-
-    assert m.test_callback1(func1) == "func1"
-    assert m.test_callback2(func2) == ("func2", "Hello", "x", True, 5)
-    assert m.test_callback1(partial(func2, 1, 2, 3, 4)) == ("func2", 1, 2, 3, 4)
-    assert m.test_callback1(partial(func3, "partial")) == "func3(partial)"
-    assert m.test_callback3(lambda i: i + 1) == "func(43) = 44"
-
-    f = m.test_callback4()
-    assert f(43) == 44
-    f = m.test_callback5()
-    assert f(number=43) == 44
-
-
-def test_bound_method_callback():
-    # Bound Python method:
-    class MyClass:
-        def double(self, val):
-            return 2 * val
-
-    z = MyClass()
-    assert m.test_callback3(z.double) == "func(43) = 86"
-
-    z = m.CppBoundMethodTest()
-    assert m.test_callback3(z.triple) == "func(43) = 129"
-
-
-def test_keyword_args_and_generalized_unpacking():
-    def f(*args, **kwargs):
-        return args, kwargs
-
-    assert m.test_tuple_unpacking(f) == (("positional", 1, 2, 3, 4, 5, 6), {})
-    assert m.test_dict_unpacking(f) == (
-        ("positional", 1),
-        {"key": "value", "a": 1, "b": 2},
-    )
-    assert m.test_keyword_args(f) == ((), {"x": 10, "y": 20})
-    assert m.test_unpacking_and_keywords1(f) == ((1, 2), {"c": 3, "d": 4})
-    assert m.test_unpacking_and_keywords2(f) == (
-        ("positional", 1, 2, 3, 4, 5),
-        {"key": "value", "a": 1, "b": 2, "c": 3, "d": 4, "e": 5},
-    )
-
-    with pytest.raises(TypeError) as excinfo:
-        m.test_unpacking_error1(f)
-    assert "Got multiple values for keyword argument" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.test_unpacking_error2(f)
-    assert "Got multiple values for keyword argument" in str(excinfo.value)
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.test_arg_conversion_error1(f)
-    assert str(excinfo.value) == "Unable to convert call argument " + (
-        "'1' of type 'UnregisteredType' to Python object"
-        if detailed_error_messages_enabled
-        else "'1' to Python object (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
-    )
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.test_arg_conversion_error2(f)
-    assert str(excinfo.value) == "Unable to convert call argument " + (
-        "'expected_name' of type 'UnregisteredType' to Python object"
-        if detailed_error_messages_enabled
-        else "'expected_name' to Python object "
-        "(#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
-    )
-
-
-def test_lambda_closure_cleanup():
-    m.test_lambda_closure_cleanup()
-    cstats = m.payload_cstats()
-    assert cstats.alive() == 0
-    assert cstats.copy_constructions == 1
-    assert cstats.move_constructions >= 1
-
-
-def test_cpp_callable_cleanup():
-    alive_counts = m.test_cpp_callable_cleanup()
-    assert alive_counts == [0, 1, 2, 1, 2, 1, 0]
-
-
-def test_cpp_function_roundtrip():
-    """Test if passing a function pointer from C++ -> Python -> C++ yields the original pointer"""
-
-    assert (
-        m.test_dummy_function(m.dummy_function) == "matches dummy_function: eval(1) = 2"
-    )
-    assert (
-        m.test_dummy_function(m.roundtrip(m.dummy_function))
-        == "matches dummy_function: eval(1) = 2"
-    )
-    assert (
-        m.test_dummy_function(m.dummy_function_overloaded)
-        == "matches dummy_function: eval(1) = 2"
-    )
-    assert m.roundtrip(None, expect_none=True) is None
-    assert (
-        m.test_dummy_function(lambda x: x + 2)
-        == "can't convert to function pointer: eval(1) = 3"
-    )
-
-    with pytest.raises(TypeError) as excinfo:
-        m.test_dummy_function(m.dummy_function2)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.test_dummy_function(lambda x, y: x + y)
-    assert any(
-        s in str(excinfo.value)
-        for s in ("missing 1 required positional argument", "takes exactly 2 arguments")
-    )
-
-
-def test_function_signatures(doc):
-    assert doc(m.test_callback3) == "test_callback3(arg0: Callable[[int], int]) -> str"
-    assert doc(m.test_callback4) == "test_callback4() -> Callable[[int], int]"
-
-
-def test_movable_object():
-    assert m.callback_with_movable(lambda _: None) is True
-
-
-@pytest.mark.skipif(
-    "env.PYPY",
-    reason="PyPy segfaults on here. See discussion on #1413.",
-)
-def test_python_builtins():
-    """Test if python builtins like sum() can be used as callbacks"""
-    assert m.test_sum_builtin(sum, [1, 2, 3]) == 6
-    assert m.test_sum_builtin(sum, []) == 0
-
-
-def test_async_callbacks():
-    # serves as state for async callback
-    class Item:
-        def __init__(self, value):
-            self.value = value
-
-    res = []
-
-    # generate stateful lambda that will store result in `res`
-    def gen_f():
-        s = Item(3)
-        return lambda j: res.append(s.value + j)
-
-    # do some work async
-    work = [1, 2, 3, 4]
-    m.test_async_callback(gen_f(), work)
-    # wait until work is done
-    from time import sleep
-
-    sleep(0.5)
-    assert sum(res) == sum(x + 3 for x in work)
-
-
-def test_async_async_callbacks():
-    t = Thread(target=test_async_callbacks)
-    t.start()
-    t.join()
-
-
-def test_callback_num_times():
-    # Super-simple micro-benchmarking related to PR #2919.
-    # Example runtimes (Intel Xeon 2.2GHz, fully optimized):
-    #   num_millions  1, repeats  2:  0.1 secs
-    #   num_millions 20, repeats 10: 11.5 secs
-    one_million = 1000000
-    num_millions = 1  # Try 20 for actual micro-benchmarking.
-    repeats = 2  # Try 10.
-    rates = []
-    for rep in range(repeats):
-        t0 = time.time()
-        m.callback_num_times(lambda: None, num_millions * one_million)
-        td = time.time() - t0
-        rate = num_millions / td if td else 0
-        rates.append(rate)
-        if not rep:
-            print()
-        print(
-            f"callback_num_times: {num_millions:d} million / {td:.3f} seconds = {rate:.3f} million / second"
-        )
-    if len(rates) > 1:
-        print("Min    Mean   Max")
-        print(f"{min(rates):6.3f} {sum(rates) / len(rates):6.3f} {max(rates):6.3f}")
-
-
-def test_custom_func():
-    assert m.custom_function(4) == 36
-    assert m.roundtrip(m.custom_function)(4) == 36
-
-
-@pytest.mark.skipif(
-    m.custom_function2 is None, reason="Current PYBIND11_INTERNALS_VERSION too low"
-)
-def test_custom_func2():
-    assert m.custom_function2(3) == 27
-    assert m.roundtrip(m.custom_function2)(3) == 27
-
-
-def test_callback_docstring():
-    assert (
-        m.test_tuple_unpacking.__doc__.strip()
-        == "test_tuple_unpacking(arg0: Callable) -> object"
-    )
+import time
+from threading import Thread
+
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import callbacks as m
+from pybind11_tests import detailed_error_messages_enabled
+
+
+def test_callbacks():
+    from functools import partial
+
+    def func1():
+        return "func1"
+
+    def func2(a, b, c, d):
+        return "func2", a, b, c, d
+
+    def func3(a):
+        return f"func3({a})"
+
+    assert m.test_callback1(func1) == "func1"
+    assert m.test_callback2(func2) == ("func2", "Hello", "x", True, 5)
+    assert m.test_callback1(partial(func2, 1, 2, 3, 4)) == ("func2", 1, 2, 3, 4)
+    assert m.test_callback1(partial(func3, "partial")) == "func3(partial)"
+    assert m.test_callback3(lambda i: i + 1) == "func(43) = 44"
+
+    f = m.test_callback4()
+    assert f(43) == 44
+    f = m.test_callback5()
+    assert f(number=43) == 44
+
+
+def test_bound_method_callback():
+    # Bound Python method:
+    class MyClass:
+        def double(self, val):
+            return 2 * val
+
+    z = MyClass()
+    assert m.test_callback3(z.double) == "func(43) = 86"
+
+    z = m.CppBoundMethodTest()
+    assert m.test_callback3(z.triple) == "func(43) = 129"
+
+
+def test_keyword_args_and_generalized_unpacking():
+    def f(*args, **kwargs):
+        return args, kwargs
+
+    assert m.test_tuple_unpacking(f) == (("positional", 1, 2, 3, 4, 5, 6), {})
+    assert m.test_dict_unpacking(f) == (
+        ("positional", 1),
+        {"key": "value", "a": 1, "b": 2},
+    )
+    assert m.test_keyword_args(f) == ((), {"x": 10, "y": 20})
+    assert m.test_unpacking_and_keywords1(f) == ((1, 2), {"c": 3, "d": 4})
+    assert m.test_unpacking_and_keywords2(f) == (
+        ("positional", 1, 2, 3, 4, 5),
+        {"key": "value", "a": 1, "b": 2, "c": 3, "d": 4, "e": 5},
+    )
+
+    with pytest.raises(TypeError) as excinfo:
+        m.test_unpacking_error1(f)
+    assert "Got multiple values for keyword argument" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.test_unpacking_error2(f)
+    assert "Got multiple values for keyword argument" in str(excinfo.value)
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.test_arg_conversion_error1(f)
+    assert str(excinfo.value) == "Unable to convert call argument " + (
+        "'1' of type 'UnregisteredType' to Python object"
+        if detailed_error_messages_enabled
+        else "'1' to Python object (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
+    )
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.test_arg_conversion_error2(f)
+    assert str(excinfo.value) == "Unable to convert call argument " + (
+        "'expected_name' of type 'UnregisteredType' to Python object"
+        if detailed_error_messages_enabled
+        else "'expected_name' to Python object "
+        "(#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
+    )
+
+
+def test_lambda_closure_cleanup():
+    m.test_lambda_closure_cleanup()
+    cstats = m.payload_cstats()
+    assert cstats.alive() == 0
+    assert cstats.copy_constructions == 1
+    assert cstats.move_constructions >= 1
+
+
+def test_cpp_callable_cleanup():
+    alive_counts = m.test_cpp_callable_cleanup()
+    assert alive_counts == [0, 1, 2, 1, 2, 1, 0]
+
+
+def test_cpp_function_roundtrip():
+    """Test if passing a function pointer from C++ -> Python -> C++ yields the original pointer"""
+
+    assert (
+        m.test_dummy_function(m.dummy_function) == "matches dummy_function: eval(1) = 2"
+    )
+    assert (
+        m.test_dummy_function(m.roundtrip(m.dummy_function))
+        == "matches dummy_function: eval(1) = 2"
+    )
+    assert (
+        m.test_dummy_function(m.dummy_function_overloaded)
+        == "matches dummy_function: eval(1) = 2"
+    )
+    assert m.roundtrip(None, expect_none=True) is None
+    assert (
+        m.test_dummy_function(lambda x: x + 2)
+        == "can't convert to function pointer: eval(1) = 3"
+    )
+
+    with pytest.raises(TypeError) as excinfo:
+        m.test_dummy_function(m.dummy_function2)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.test_dummy_function(lambda x, y: x + y)
+    assert any(
+        s in str(excinfo.value)
+        for s in ("missing 1 required positional argument", "takes exactly 2 arguments")
+    )
+
+
+def test_function_signatures(doc):
+    assert doc(m.test_callback3) == "test_callback3(arg0: Callable[[int], int]) -> str"
+    assert doc(m.test_callback4) == "test_callback4() -> Callable[[int], int]"
+
+
+def test_movable_object():
+    assert m.callback_with_movable(lambda _: None) is True
+
+
+@pytest.mark.skipif(
+    "env.PYPY",
+    reason="PyPy segfaults on here. See discussion on #1413.",
+)
+def test_python_builtins():
+    """Test if python builtins like sum() can be used as callbacks"""
+    assert m.test_sum_builtin(sum, [1, 2, 3]) == 6
+    assert m.test_sum_builtin(sum, []) == 0
+
+
+def test_async_callbacks():
+    # serves as state for async callback
+    class Item:
+        def __init__(self, value):
+            self.value = value
+
+    res = []
+
+    # generate stateful lambda that will store result in `res`
+    def gen_f():
+        s = Item(3)
+        return lambda j: res.append(s.value + j)
+
+    # do some work async
+    work = [1, 2, 3, 4]
+    m.test_async_callback(gen_f(), work)
+    # wait until work is done
+    from time import sleep
+
+    sleep(0.5)
+    assert sum(res) == sum(x + 3 for x in work)
+
+
+def test_async_async_callbacks():
+    t = Thread(target=test_async_callbacks)
+    t.start()
+    t.join()
+
+
+def test_callback_num_times():
+    # Super-simple micro-benchmarking related to PR #2919.
+    # Example runtimes (Intel Xeon 2.2GHz, fully optimized):
+    #   num_millions  1, repeats  2:  0.1 secs
+    #   num_millions 20, repeats 10: 11.5 secs
+    one_million = 1000000
+    num_millions = 1  # Try 20 for actual micro-benchmarking.
+    repeats = 2  # Try 10.
+    rates = []
+    for rep in range(repeats):
+        t0 = time.time()
+        m.callback_num_times(lambda: None, num_millions * one_million)
+        td = time.time() - t0
+        rate = num_millions / td if td else 0
+        rates.append(rate)
+        if not rep:
+            print()
+        print(
+            f"callback_num_times: {num_millions:d} million / {td:.3f} seconds = {rate:.3f} million / second"
+        )
+    if len(rates) > 1:
+        print("Min    Mean   Max")
+        print(f"{min(rates):6.3f} {sum(rates) / len(rates):6.3f} {max(rates):6.3f}")
+
+
+def test_custom_func():
+    assert m.custom_function(4) == 36
+    assert m.roundtrip(m.custom_function)(4) == 36
+
+
+@pytest.mark.skipif(
+    m.custom_function2 is None, reason="Current PYBIND11_INTERNALS_VERSION too low"
+)
+def test_custom_func2():
+    assert m.custom_function2(3) == 27
+    assert m.roundtrip(m.custom_function2)(3) == 27
+
+
+def test_callback_docstring():
+    assert (
+        m.test_tuple_unpacking.__doc__.strip()
+        == "test_tuple_unpacking(arg0: Callable) -> object"
+    )
```

## extern/pybind11/tests/test_chrono.py

 * *Ordering differences only*

```diff
@@ -1,205 +1,205 @@
-import datetime
-
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import chrono as m
-
-
-def test_chrono_system_clock():
-    # Get the time from both c++ and datetime
-    date0 = datetime.datetime.today()
-    date1 = m.test_chrono1()
-    date2 = datetime.datetime.today()
-
-    # The returned value should be a datetime
-    assert isinstance(date1, datetime.datetime)
-
-    # The numbers should vary by a very small amount (time it took to execute)
-    diff_python = abs(date2 - date0)
-    diff = abs(date1 - date2)
-
-    # There should never be a days difference
-    assert diff.days == 0
-
-    # Since datetime.datetime.today() calls time.time(), and on some platforms
-    # that has 1 second accuracy, we compare this way
-    assert diff.seconds <= diff_python.seconds
-
-
-def test_chrono_system_clock_roundtrip():
-    date1 = datetime.datetime.today()
-
-    # Roundtrip the time
-    date2 = m.test_chrono2(date1)
-
-    # The returned value should be a datetime
-    assert isinstance(date2, datetime.datetime)
-
-    # They should be identical (no information lost on roundtrip)
-    diff = abs(date1 - date2)
-    assert diff == datetime.timedelta(0)
-
-
-def test_chrono_system_clock_roundtrip_date():
-    date1 = datetime.date.today()
-
-    # Roundtrip the time
-    datetime2 = m.test_chrono2(date1)
-    date2 = datetime2.date()
-    time2 = datetime2.time()
-
-    # The returned value should be a datetime
-    assert isinstance(datetime2, datetime.datetime)
-    assert isinstance(date2, datetime.date)
-    assert isinstance(time2, datetime.time)
-
-    # They should be identical (no information lost on roundtrip)
-    diff = abs(date1 - date2)
-    assert diff.days == 0
-    assert diff.seconds == 0
-    assert diff.microseconds == 0
-
-    # Year, Month & Day should be the same after the round trip
-    assert date1 == date2
-
-    # There should be no time information
-    assert time2.hour == 0
-    assert time2.minute == 0
-    assert time2.second == 0
-    assert time2.microsecond == 0
-
-
-SKIP_TZ_ENV_ON_WIN = pytest.mark.skipif(
-    "env.WIN", reason="TZ environment variable only supported on POSIX"
-)
-
-
-@pytest.mark.parametrize(
-    "time1",
-    [
-        datetime.datetime.today().time(),
-        datetime.time(0, 0, 0),
-        datetime.time(0, 0, 0, 1),
-        datetime.time(0, 28, 45, 109827),
-        datetime.time(0, 59, 59, 999999),
-        datetime.time(1, 0, 0),
-        datetime.time(5, 59, 59, 0),
-        datetime.time(5, 59, 59, 1),
-    ],
-)
-@pytest.mark.parametrize(
-    "tz",
-    [
-        None,
-        pytest.param("Europe/Brussels", marks=SKIP_TZ_ENV_ON_WIN),
-        pytest.param("Asia/Pyongyang", marks=SKIP_TZ_ENV_ON_WIN),
-        pytest.param("America/New_York", marks=SKIP_TZ_ENV_ON_WIN),
-    ],
-)
-def test_chrono_system_clock_roundtrip_time(time1, tz, monkeypatch):
-    if tz is not None:
-        monkeypatch.setenv("TZ", f"/usr/share/zoneinfo/{tz}")
-
-    # Roundtrip the time
-    datetime2 = m.test_chrono2(time1)
-    date2 = datetime2.date()
-    time2 = datetime2.time()
-
-    # The returned value should be a datetime
-    assert isinstance(datetime2, datetime.datetime)
-    assert isinstance(date2, datetime.date)
-    assert isinstance(time2, datetime.time)
-
-    # Hour, Minute, Second & Microsecond should be the same after the round trip
-    assert time1 == time2
-
-    # There should be no date information (i.e. date = python base date)
-    assert date2.year == 1970
-    assert date2.month == 1
-    assert date2.day == 1
-
-
-def test_chrono_duration_roundtrip():
-    # Get the difference between two times (a timedelta)
-    date1 = datetime.datetime.today()
-    date2 = datetime.datetime.today()
-    diff = date2 - date1
-
-    # Make sure this is a timedelta
-    assert isinstance(diff, datetime.timedelta)
-
-    cpp_diff = m.test_chrono3(diff)
-
-    assert cpp_diff == diff
-
-    # Negative timedelta roundtrip
-    diff = datetime.timedelta(microseconds=-1)
-    cpp_diff = m.test_chrono3(diff)
-
-    assert cpp_diff == diff
-
-
-def test_chrono_duration_subtraction_equivalence():
-    date1 = datetime.datetime.today()
-    date2 = datetime.datetime.today()
-
-    diff = date2 - date1
-    cpp_diff = m.test_chrono4(date2, date1)
-
-    assert cpp_diff == diff
-
-
-def test_chrono_duration_subtraction_equivalence_date():
-    date1 = datetime.date.today()
-    date2 = datetime.date.today()
-
-    diff = date2 - date1
-    cpp_diff = m.test_chrono4(date2, date1)
-
-    assert cpp_diff == diff
-
-
-def test_chrono_steady_clock():
-    time1 = m.test_chrono5()
-    assert isinstance(time1, datetime.timedelta)
-
-
-def test_chrono_steady_clock_roundtrip():
-    time1 = datetime.timedelta(days=10, seconds=10, microseconds=100)
-    time2 = m.test_chrono6(time1)
-
-    assert isinstance(time2, datetime.timedelta)
-
-    # They should be identical (no information lost on roundtrip)
-    assert time1 == time2
-
-
-def test_floating_point_duration():
-    # Test using a floating point number in seconds
-    time = m.test_chrono7(35.525123)
-
-    assert isinstance(time, datetime.timedelta)
-
-    assert time.seconds == 35
-    assert 525122 <= time.microseconds <= 525123
-
-    diff = m.test_chrono_float_diff(43.789012, 1.123456)
-    assert diff.seconds == 42
-    assert 665556 <= diff.microseconds <= 665557
-
-
-def test_nano_timepoint():
-    time = datetime.datetime.now()
-    time1 = m.test_nano_timepoint(time, datetime.timedelta(seconds=60))
-    assert time1 == time + datetime.timedelta(seconds=60)
-
-
-def test_chrono_different_resolutions():
-    resolutions = m.different_resolutions()
-    time = datetime.datetime.now()
-    resolutions.timestamp_h = time
-    resolutions.timestamp_m = time
-    resolutions.timestamp_s = time
-    resolutions.timestamp_ms = time
-    resolutions.timestamp_us = time
+import datetime
+
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import chrono as m
+
+
+def test_chrono_system_clock():
+    # Get the time from both c++ and datetime
+    date0 = datetime.datetime.today()
+    date1 = m.test_chrono1()
+    date2 = datetime.datetime.today()
+
+    # The returned value should be a datetime
+    assert isinstance(date1, datetime.datetime)
+
+    # The numbers should vary by a very small amount (time it took to execute)
+    diff_python = abs(date2 - date0)
+    diff = abs(date1 - date2)
+
+    # There should never be a days difference
+    assert diff.days == 0
+
+    # Since datetime.datetime.today() calls time.time(), and on some platforms
+    # that has 1 second accuracy, we compare this way
+    assert diff.seconds <= diff_python.seconds
+
+
+def test_chrono_system_clock_roundtrip():
+    date1 = datetime.datetime.today()
+
+    # Roundtrip the time
+    date2 = m.test_chrono2(date1)
+
+    # The returned value should be a datetime
+    assert isinstance(date2, datetime.datetime)
+
+    # They should be identical (no information lost on roundtrip)
+    diff = abs(date1 - date2)
+    assert diff == datetime.timedelta(0)
+
+
+def test_chrono_system_clock_roundtrip_date():
+    date1 = datetime.date.today()
+
+    # Roundtrip the time
+    datetime2 = m.test_chrono2(date1)
+    date2 = datetime2.date()
+    time2 = datetime2.time()
+
+    # The returned value should be a datetime
+    assert isinstance(datetime2, datetime.datetime)
+    assert isinstance(date2, datetime.date)
+    assert isinstance(time2, datetime.time)
+
+    # They should be identical (no information lost on roundtrip)
+    diff = abs(date1 - date2)
+    assert diff.days == 0
+    assert diff.seconds == 0
+    assert diff.microseconds == 0
+
+    # Year, Month & Day should be the same after the round trip
+    assert date1 == date2
+
+    # There should be no time information
+    assert time2.hour == 0
+    assert time2.minute == 0
+    assert time2.second == 0
+    assert time2.microsecond == 0
+
+
+SKIP_TZ_ENV_ON_WIN = pytest.mark.skipif(
+    "env.WIN", reason="TZ environment variable only supported on POSIX"
+)
+
+
+@pytest.mark.parametrize(
+    "time1",
+    [
+        datetime.datetime.today().time(),
+        datetime.time(0, 0, 0),
+        datetime.time(0, 0, 0, 1),
+        datetime.time(0, 28, 45, 109827),
+        datetime.time(0, 59, 59, 999999),
+        datetime.time(1, 0, 0),
+        datetime.time(5, 59, 59, 0),
+        datetime.time(5, 59, 59, 1),
+    ],
+)
+@pytest.mark.parametrize(
+    "tz",
+    [
+        None,
+        pytest.param("Europe/Brussels", marks=SKIP_TZ_ENV_ON_WIN),
+        pytest.param("Asia/Pyongyang", marks=SKIP_TZ_ENV_ON_WIN),
+        pytest.param("America/New_York", marks=SKIP_TZ_ENV_ON_WIN),
+    ],
+)
+def test_chrono_system_clock_roundtrip_time(time1, tz, monkeypatch):
+    if tz is not None:
+        monkeypatch.setenv("TZ", f"/usr/share/zoneinfo/{tz}")
+
+    # Roundtrip the time
+    datetime2 = m.test_chrono2(time1)
+    date2 = datetime2.date()
+    time2 = datetime2.time()
+
+    # The returned value should be a datetime
+    assert isinstance(datetime2, datetime.datetime)
+    assert isinstance(date2, datetime.date)
+    assert isinstance(time2, datetime.time)
+
+    # Hour, Minute, Second & Microsecond should be the same after the round trip
+    assert time1 == time2
+
+    # There should be no date information (i.e. date = python base date)
+    assert date2.year == 1970
+    assert date2.month == 1
+    assert date2.day == 1
+
+
+def test_chrono_duration_roundtrip():
+    # Get the difference between two times (a timedelta)
+    date1 = datetime.datetime.today()
+    date2 = datetime.datetime.today()
+    diff = date2 - date1
+
+    # Make sure this is a timedelta
+    assert isinstance(diff, datetime.timedelta)
+
+    cpp_diff = m.test_chrono3(diff)
+
+    assert cpp_diff == diff
+
+    # Negative timedelta roundtrip
+    diff = datetime.timedelta(microseconds=-1)
+    cpp_diff = m.test_chrono3(diff)
+
+    assert cpp_diff == diff
+
+
+def test_chrono_duration_subtraction_equivalence():
+    date1 = datetime.datetime.today()
+    date2 = datetime.datetime.today()
+
+    diff = date2 - date1
+    cpp_diff = m.test_chrono4(date2, date1)
+
+    assert cpp_diff == diff
+
+
+def test_chrono_duration_subtraction_equivalence_date():
+    date1 = datetime.date.today()
+    date2 = datetime.date.today()
+
+    diff = date2 - date1
+    cpp_diff = m.test_chrono4(date2, date1)
+
+    assert cpp_diff == diff
+
+
+def test_chrono_steady_clock():
+    time1 = m.test_chrono5()
+    assert isinstance(time1, datetime.timedelta)
+
+
+def test_chrono_steady_clock_roundtrip():
+    time1 = datetime.timedelta(days=10, seconds=10, microseconds=100)
+    time2 = m.test_chrono6(time1)
+
+    assert isinstance(time2, datetime.timedelta)
+
+    # They should be identical (no information lost on roundtrip)
+    assert time1 == time2
+
+
+def test_floating_point_duration():
+    # Test using a floating point number in seconds
+    time = m.test_chrono7(35.525123)
+
+    assert isinstance(time, datetime.timedelta)
+
+    assert time.seconds == 35
+    assert 525122 <= time.microseconds <= 525123
+
+    diff = m.test_chrono_float_diff(43.789012, 1.123456)
+    assert diff.seconds == 42
+    assert 665556 <= diff.microseconds <= 665557
+
+
+def test_nano_timepoint():
+    time = datetime.datetime.now()
+    time1 = m.test_nano_timepoint(time, datetime.timedelta(seconds=60))
+    assert time1 == time + datetime.timedelta(seconds=60)
+
+
+def test_chrono_different_resolutions():
+    resolutions = m.different_resolutions()
+    time = datetime.datetime.now()
+    resolutions.timestamp_h = time
+    resolutions.timestamp_m = time
+    resolutions.timestamp_s = time
+    resolutions.timestamp_ms = time
+    resolutions.timestamp_us = time
```

## extern/pybind11/tests/test_class.py

 * *Ordering differences only*

```diff
@@ -1,499 +1,499 @@
-from unittest import mock
-
-import pytest
-
-import env
-from pybind11_tests import ConstructorStats, UserType
-from pybind11_tests import class_ as m
-
-
-def test_obj_class_name():
-    expected_name = "UserType" if env.PYPY else "pybind11_tests.UserType"
-    assert m.obj_class_name(UserType(1)) == expected_name
-    assert m.obj_class_name(UserType) == expected_name
-
-
-def test_repr():
-    assert "pybind11_type" in repr(type(UserType))
-    assert "UserType" in repr(UserType)
-
-
-def test_instance(msg):
-    with pytest.raises(TypeError) as excinfo:
-        m.NoConstructor()
-    assert msg(excinfo.value) == "m.class_.NoConstructor: No constructor defined!"
-
-    instance = m.NoConstructor.new_instance()
-
-    cstats = ConstructorStats.get(m.NoConstructor)
-    assert cstats.alive() == 1
-    del instance
-    assert cstats.alive() == 0
-
-
-def test_instance_new():
-    instance = m.NoConstructorNew()  # .__new__(m.NoConstructor.__class__)
-    cstats = ConstructorStats.get(m.NoConstructorNew)
-    assert cstats.alive() == 1
-    del instance
-    assert cstats.alive() == 0
-
-
-def test_type():
-    assert m.check_type(1) == m.DerivedClass1
-    with pytest.raises(RuntimeError) as execinfo:
-        m.check_type(0)
-
-    assert "pybind11::detail::get_type_info: unable to find type info" in str(
-        execinfo.value
-    )
-    assert "Invalid" in str(execinfo.value)
-
-    # Currently not supported
-    # See https://github.com/pybind/pybind11/issues/2486
-    # assert m.check_type(2) == int
-
-
-def test_type_of_py():
-    assert m.get_type_of(1) == int
-    assert m.get_type_of(m.DerivedClass1()) == m.DerivedClass1
-    assert m.get_type_of(int) == type
-
-
-def test_type_of_classic():
-    assert m.get_type_classic(1) == int
-    assert m.get_type_classic(m.DerivedClass1()) == m.DerivedClass1
-    assert m.get_type_classic(int) == type
-
-
-def test_type_of_py_nodelete():
-    # If the above test deleted the class, this will segfault
-    assert m.get_type_of(m.DerivedClass1()) == m.DerivedClass1
-
-
-def test_as_type_py():
-    assert m.as_type(int) == int
-
-    with pytest.raises(TypeError):
-        assert m.as_type(1) == int
-
-    with pytest.raises(TypeError):
-        assert m.as_type(m.DerivedClass1()) == m.DerivedClass1
-
-
-def test_docstrings(doc):
-    assert doc(UserType) == "A `py::class_` type for testing"
-    assert UserType.__name__ == "UserType"
-    assert UserType.__module__ == "pybind11_tests"
-    assert UserType.get_value.__name__ == "get_value"
-    assert UserType.get_value.__module__ == "pybind11_tests"
-
-    assert (
-        doc(UserType.get_value)
-        == """
-        get_value(self: m.UserType) -> int
-
-        Get value using a method
-    """
-    )
-    assert doc(UserType.value) == "Get/set value using a property"
-
-    assert (
-        doc(m.NoConstructor.new_instance)
-        == """
-        new_instance() -> m.class_.NoConstructor
-
-        Return an instance
-    """
-    )
-
-
-def test_qualname(doc):
-    """Tests that a properly qualified name is set in __qualname__ and that
-    generated docstrings properly use it and the module name"""
-    assert m.NestBase.__qualname__ == "NestBase"
-    assert m.NestBase.Nested.__qualname__ == "NestBase.Nested"
-
-    assert (
-        doc(m.NestBase.__init__)
-        == """
-        __init__(self: m.class_.NestBase) -> None
-    """
-    )
-    assert (
-        doc(m.NestBase.g)
-        == """
-        g(self: m.class_.NestBase, arg0: m.class_.NestBase.Nested) -> None
-    """
-    )
-    assert (
-        doc(m.NestBase.Nested.__init__)
-        == """
-        __init__(self: m.class_.NestBase.Nested) -> None
-    """
-    )
-    assert (
-        doc(m.NestBase.Nested.fn)
-        == """
-        fn(self: m.class_.NestBase.Nested, arg0: int, arg1: m.class_.NestBase, arg2: m.class_.NestBase.Nested) -> None
-    """
-    )
-    assert (
-        doc(m.NestBase.Nested.fa)
-        == """
-        fa(self: m.class_.NestBase.Nested, a: int, b: m.class_.NestBase, c: m.class_.NestBase.Nested) -> None
-    """
-    )
-    assert m.NestBase.__module__ == "pybind11_tests.class_"
-    assert m.NestBase.Nested.__module__ == "pybind11_tests.class_"
-
-
-def test_inheritance(msg):
-    roger = m.Rabbit("Rabbit")
-    assert roger.name() + " is a " + roger.species() == "Rabbit is a parrot"
-    assert m.pet_name_species(roger) == "Rabbit is a parrot"
-
-    polly = m.Pet("Polly", "parrot")
-    assert polly.name() + " is a " + polly.species() == "Polly is a parrot"
-    assert m.pet_name_species(polly) == "Polly is a parrot"
-
-    molly = m.Dog("Molly")
-    assert molly.name() + " is a " + molly.species() == "Molly is a dog"
-    assert m.pet_name_species(molly) == "Molly is a dog"
-
-    fred = m.Hamster("Fred")
-    assert fred.name() + " is a " + fred.species() == "Fred is a rodent"
-
-    assert m.dog_bark(molly) == "Woof!"
-
-    with pytest.raises(TypeError) as excinfo:
-        m.dog_bark(polly)
-    assert (
-        msg(excinfo.value)
-        == """
-        dog_bark(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: m.class_.Dog) -> str
-
-        Invoked with: <m.class_.Pet object at 0>
-    """
-    )
-
-    with pytest.raises(TypeError) as excinfo:
-        m.Chimera("lion", "goat")
-    assert "No constructor defined!" in str(excinfo.value)
-
-
-def test_inheritance_init(msg):
-    # Single base
-    class Python(m.Pet):
-        def __init__(self):
-            pass
-
-    with pytest.raises(TypeError) as exc_info:
-        Python()
-    expected = "m.class_.Pet.__init__() must be called when overriding __init__"
-    assert msg(exc_info.value) == expected
-
-    # Multiple bases
-    class RabbitHamster(m.Rabbit, m.Hamster):
-        def __init__(self):
-            m.Rabbit.__init__(self, "RabbitHamster")
-
-    with pytest.raises(TypeError) as exc_info:
-        RabbitHamster()
-    expected = "m.class_.Hamster.__init__() must be called when overriding __init__"
-    assert msg(exc_info.value) == expected
-
-
-@pytest.mark.parametrize(
-    "mock_return_value", [None, (1, 2, 3), m.Pet("Polly", "parrot"), m.Dog("Molly")]
-)
-def test_mock_new(mock_return_value):
-    with mock.patch.object(
-        m.Pet, "__new__", return_value=mock_return_value
-    ) as mock_new:
-        obj = m.Pet("Noname", "Nospecies")
-    assert obj is mock_return_value
-    mock_new.assert_called_once_with(m.Pet, "Noname", "Nospecies")
-
-
-def test_automatic_upcasting():
-    assert type(m.return_class_1()).__name__ == "DerivedClass1"
-    assert type(m.return_class_2()).__name__ == "DerivedClass2"
-    assert type(m.return_none()).__name__ == "NoneType"
-    # Repeat these a few times in a random order to ensure no invalid caching is applied
-    assert type(m.return_class_n(1)).__name__ == "DerivedClass1"
-    assert type(m.return_class_n(2)).__name__ == "DerivedClass2"
-    assert type(m.return_class_n(0)).__name__ == "BaseClass"
-    assert type(m.return_class_n(2)).__name__ == "DerivedClass2"
-    assert type(m.return_class_n(2)).__name__ == "DerivedClass2"
-    assert type(m.return_class_n(0)).__name__ == "BaseClass"
-    assert type(m.return_class_n(1)).__name__ == "DerivedClass1"
-
-
-def test_isinstance():
-    objects = [(), {}, m.Pet("Polly", "parrot")] + [m.Dog("Molly")] * 4
-    expected = (True, True, True, True, True, False, False)
-    assert m.check_instances(objects) == expected
-
-
-def test_mismatched_holder():
-    import re
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.mismatched_holder_1()
-    assert re.match(
-        'generic_type: type ".*MismatchDerived1" does not have a non-default '
-        'holder type while its base ".*MismatchBase1" does',
-        str(excinfo.value),
-    )
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.mismatched_holder_2()
-    assert re.match(
-        'generic_type: type ".*MismatchDerived2" has a non-default holder type '
-        'while its base ".*MismatchBase2" does not',
-        str(excinfo.value),
-    )
-
-
-def test_override_static():
-    """#511: problem with inheritance + overwritten def_static"""
-    b = m.MyBase.make()
-    d1 = m.MyDerived.make2()
-    d2 = m.MyDerived.make()
-
-    assert isinstance(b, m.MyBase)
-    assert isinstance(d1, m.MyDerived)
-    assert isinstance(d2, m.MyDerived)
-
-
-def test_implicit_conversion_life_support():
-    """Ensure the lifetime of temporary objects created for implicit conversions"""
-    assert m.implicitly_convert_argument(UserType(5)) == 5
-    assert m.implicitly_convert_variable(UserType(5)) == 5
-
-    assert "outside a bound function" in m.implicitly_convert_variable_fail(UserType(5))
-
-
-def test_operator_new_delete(capture):
-    """Tests that class-specific operator new/delete functions are invoked"""
-
-    class SubAliased(m.AliasedHasOpNewDelSize):
-        pass
-
-    with capture:
-        a = m.HasOpNewDel()
-        b = m.HasOpNewDelSize()
-        d = m.HasOpNewDelBoth()
-    assert (
-        capture
-        == """
-        A new 8
-        B new 4
-        D new 32
-    """
-    )
-    sz_alias = str(m.AliasedHasOpNewDelSize.size_alias)
-    sz_noalias = str(m.AliasedHasOpNewDelSize.size_noalias)
-    with capture:
-        c = m.AliasedHasOpNewDelSize()
-        c2 = SubAliased()
-    assert capture == ("C new " + sz_noalias + "\n" + "C new " + sz_alias + "\n")
-
-    with capture:
-        del a
-        pytest.gc_collect()
-        del b
-        pytest.gc_collect()
-        del d
-        pytest.gc_collect()
-    assert (
-        capture
-        == """
-        A delete
-        B delete 4
-        D delete
-    """
-    )
-
-    with capture:
-        del c
-        pytest.gc_collect()
-        del c2
-        pytest.gc_collect()
-    assert capture == ("C delete " + sz_noalias + "\n" + "C delete " + sz_alias + "\n")
-
-
-def test_bind_protected_functions():
-    """Expose protected member functions to Python using a helper class"""
-    a = m.ProtectedA()
-    assert a.foo() == 42
-
-    b = m.ProtectedB()
-    assert b.foo() == 42
-    assert m.read_foo(b.void_foo()) == 42
-    assert m.pointers_equal(b.get_self(), b)
-
-    class C(m.ProtectedB):
-        def __init__(self):
-            m.ProtectedB.__init__(self)
-
-        def foo(self):
-            return 0
-
-    c = C()
-    assert c.foo() == 0
-
-
-def test_brace_initialization():
-    """Tests that simple POD classes can be constructed using C++11 brace initialization"""
-    a = m.BraceInitialization(123, "test")
-    assert a.field1 == 123
-    assert a.field2 == "test"
-
-    # Tests that a non-simple class doesn't get brace initialization (if the
-    # class defines an initializer_list constructor, in particular, it would
-    # win over the expected constructor).
-    b = m.NoBraceInitialization([123, 456])
-    assert b.vec == [123, 456]
-
-
-@pytest.mark.xfail("env.PYPY")
-def test_class_refcount():
-    """Instances must correctly increase/decrease the reference count of their types (#1029)"""
-    from sys import getrefcount
-
-    class PyDog(m.Dog):
-        pass
-
-    for cls in m.Dog, PyDog:
-        refcount_1 = getrefcount(cls)
-        molly = [cls("Molly") for _ in range(10)]
-        refcount_2 = getrefcount(cls)
-
-        del molly
-        pytest.gc_collect()
-        refcount_3 = getrefcount(cls)
-
-        assert refcount_1 == refcount_3
-        assert refcount_2 > refcount_1
-
-
-def test_reentrant_implicit_conversion_failure(msg):
-    # ensure that there is no runaway reentrant implicit conversion (#1035)
-    with pytest.raises(TypeError) as excinfo:
-        m.BogusImplicitConversion(0)
-    assert (
-        msg(excinfo.value)
-        == """
-        __init__(): incompatible constructor arguments. The following argument types are supported:
-            1. m.class_.BogusImplicitConversion(arg0: m.class_.BogusImplicitConversion)
-
-        Invoked with: 0
-    """
-    )
-
-
-def test_error_after_conversions():
-    with pytest.raises(TypeError) as exc_info:
-        m.test_error_after_conversions("hello")
-    assert str(exc_info.value).startswith(
-        "Unable to convert function return value to a Python type!"
-    )
-
-
-def test_aligned():
-    if hasattr(m, "Aligned"):
-        p = m.Aligned().ptr()
-        assert p % 1024 == 0
-
-
-# https://foss.heptapod.net/pypy/pypy/-/issues/2742
-@pytest.mark.xfail("env.PYPY")
-def test_final():
-    with pytest.raises(TypeError) as exc_info:
-
-        class PyFinalChild(m.IsFinal):
-            pass
-
-    assert str(exc_info.value).endswith("is not an acceptable base type")
-
-
-# https://foss.heptapod.net/pypy/pypy/-/issues/2742
-@pytest.mark.xfail("env.PYPY")
-def test_non_final_final():
-    with pytest.raises(TypeError) as exc_info:
-
-        class PyNonFinalFinalChild(m.IsNonFinalFinal):
-            pass
-
-    assert str(exc_info.value).endswith("is not an acceptable base type")
-
-
-# https://github.com/pybind/pybind11/issues/1878
-def test_exception_rvalue_abort():
-    with pytest.raises(RuntimeError):
-        m.PyPrintDestructor().throw_something()
-
-
-# https://github.com/pybind/pybind11/issues/1568
-def test_multiple_instances_with_same_pointer():
-    n = 100
-    instances = [m.SamePointer() for _ in range(n)]
-    for i in range(n):
-        # We need to reuse the same allocated memory for with a different type,
-        # to ensure the bug in `deregister_instance_impl` is detected. Otherwise
-        # `Py_TYPE(self) == Py_TYPE(it->second)` will still succeed, even though
-        # the `instance` is already deleted.
-        instances[i] = m.Empty()
-    # No assert: if this does not trigger the error
-    #   pybind11_fail("pybind11_object_dealloc(): Tried to deallocate unregistered instance!");
-    # and just completes without crashing, we're good.
-
-
-# https://github.com/pybind/pybind11/issues/1624
-def test_base_and_derived_nested_scope():
-    assert issubclass(m.DerivedWithNested, m.BaseWithNested)
-    assert m.BaseWithNested.Nested != m.DerivedWithNested.Nested
-    assert m.BaseWithNested.Nested.get_name() == "BaseWithNested::Nested"
-    assert m.DerivedWithNested.Nested.get_name() == "DerivedWithNested::Nested"
-
-
-def test_register_duplicate_class():
-    import types
-
-    module_scope = types.ModuleType("module_scope")
-    with pytest.raises(RuntimeError) as exc_info:
-        m.register_duplicate_class_name(module_scope)
-    expected = (
-        'generic_type: cannot initialize type "Duplicate": '
-        "an object with that name is already defined"
-    )
-    assert str(exc_info.value) == expected
-    with pytest.raises(RuntimeError) as exc_info:
-        m.register_duplicate_class_type(module_scope)
-    expected = 'generic_type: type "YetAnotherDuplicate" is already registered!'
-    assert str(exc_info.value) == expected
-
-    class ClassScope:
-        pass
-
-    with pytest.raises(RuntimeError) as exc_info:
-        m.register_duplicate_nested_class_name(ClassScope)
-    expected = (
-        'generic_type: cannot initialize type "DuplicateNested": '
-        "an object with that name is already defined"
-    )
-    assert str(exc_info.value) == expected
-    with pytest.raises(RuntimeError) as exc_info:
-        m.register_duplicate_nested_class_type(ClassScope)
-    expected = 'generic_type: type "YetAnotherDuplicateNested" is already registered!'
-    assert str(exc_info.value) == expected
-
-
-def test_pr4220_tripped_over_this():
-    assert (
-        m.Empty0().get_msg()
-        == "This is really only meant to exercise successful compilation."
-    )
+from unittest import mock
+
+import pytest
+
+import env
+from pybind11_tests import ConstructorStats, UserType
+from pybind11_tests import class_ as m
+
+
+def test_obj_class_name():
+    expected_name = "UserType" if env.PYPY else "pybind11_tests.UserType"
+    assert m.obj_class_name(UserType(1)) == expected_name
+    assert m.obj_class_name(UserType) == expected_name
+
+
+def test_repr():
+    assert "pybind11_type" in repr(type(UserType))
+    assert "UserType" in repr(UserType)
+
+
+def test_instance(msg):
+    with pytest.raises(TypeError) as excinfo:
+        m.NoConstructor()
+    assert msg(excinfo.value) == "m.class_.NoConstructor: No constructor defined!"
+
+    instance = m.NoConstructor.new_instance()
+
+    cstats = ConstructorStats.get(m.NoConstructor)
+    assert cstats.alive() == 1
+    del instance
+    assert cstats.alive() == 0
+
+
+def test_instance_new():
+    instance = m.NoConstructorNew()  # .__new__(m.NoConstructor.__class__)
+    cstats = ConstructorStats.get(m.NoConstructorNew)
+    assert cstats.alive() == 1
+    del instance
+    assert cstats.alive() == 0
+
+
+def test_type():
+    assert m.check_type(1) == m.DerivedClass1
+    with pytest.raises(RuntimeError) as execinfo:
+        m.check_type(0)
+
+    assert "pybind11::detail::get_type_info: unable to find type info" in str(
+        execinfo.value
+    )
+    assert "Invalid" in str(execinfo.value)
+
+    # Currently not supported
+    # See https://github.com/pybind/pybind11/issues/2486
+    # assert m.check_type(2) == int
+
+
+def test_type_of_py():
+    assert m.get_type_of(1) == int
+    assert m.get_type_of(m.DerivedClass1()) == m.DerivedClass1
+    assert m.get_type_of(int) == type
+
+
+def test_type_of_classic():
+    assert m.get_type_classic(1) == int
+    assert m.get_type_classic(m.DerivedClass1()) == m.DerivedClass1
+    assert m.get_type_classic(int) == type
+
+
+def test_type_of_py_nodelete():
+    # If the above test deleted the class, this will segfault
+    assert m.get_type_of(m.DerivedClass1()) == m.DerivedClass1
+
+
+def test_as_type_py():
+    assert m.as_type(int) == int
+
+    with pytest.raises(TypeError):
+        assert m.as_type(1) == int
+
+    with pytest.raises(TypeError):
+        assert m.as_type(m.DerivedClass1()) == m.DerivedClass1
+
+
+def test_docstrings(doc):
+    assert doc(UserType) == "A `py::class_` type for testing"
+    assert UserType.__name__ == "UserType"
+    assert UserType.__module__ == "pybind11_tests"
+    assert UserType.get_value.__name__ == "get_value"
+    assert UserType.get_value.__module__ == "pybind11_tests"
+
+    assert (
+        doc(UserType.get_value)
+        == """
+        get_value(self: m.UserType) -> int
+
+        Get value using a method
+    """
+    )
+    assert doc(UserType.value) == "Get/set value using a property"
+
+    assert (
+        doc(m.NoConstructor.new_instance)
+        == """
+        new_instance() -> m.class_.NoConstructor
+
+        Return an instance
+    """
+    )
+
+
+def test_qualname(doc):
+    """Tests that a properly qualified name is set in __qualname__ and that
+    generated docstrings properly use it and the module name"""
+    assert m.NestBase.__qualname__ == "NestBase"
+    assert m.NestBase.Nested.__qualname__ == "NestBase.Nested"
+
+    assert (
+        doc(m.NestBase.__init__)
+        == """
+        __init__(self: m.class_.NestBase) -> None
+    """
+    )
+    assert (
+        doc(m.NestBase.g)
+        == """
+        g(self: m.class_.NestBase, arg0: m.class_.NestBase.Nested) -> None
+    """
+    )
+    assert (
+        doc(m.NestBase.Nested.__init__)
+        == """
+        __init__(self: m.class_.NestBase.Nested) -> None
+    """
+    )
+    assert (
+        doc(m.NestBase.Nested.fn)
+        == """
+        fn(self: m.class_.NestBase.Nested, arg0: int, arg1: m.class_.NestBase, arg2: m.class_.NestBase.Nested) -> None
+    """
+    )
+    assert (
+        doc(m.NestBase.Nested.fa)
+        == """
+        fa(self: m.class_.NestBase.Nested, a: int, b: m.class_.NestBase, c: m.class_.NestBase.Nested) -> None
+    """
+    )
+    assert m.NestBase.__module__ == "pybind11_tests.class_"
+    assert m.NestBase.Nested.__module__ == "pybind11_tests.class_"
+
+
+def test_inheritance(msg):
+    roger = m.Rabbit("Rabbit")
+    assert roger.name() + " is a " + roger.species() == "Rabbit is a parrot"
+    assert m.pet_name_species(roger) == "Rabbit is a parrot"
+
+    polly = m.Pet("Polly", "parrot")
+    assert polly.name() + " is a " + polly.species() == "Polly is a parrot"
+    assert m.pet_name_species(polly) == "Polly is a parrot"
+
+    molly = m.Dog("Molly")
+    assert molly.name() + " is a " + molly.species() == "Molly is a dog"
+    assert m.pet_name_species(molly) == "Molly is a dog"
+
+    fred = m.Hamster("Fred")
+    assert fred.name() + " is a " + fred.species() == "Fred is a rodent"
+
+    assert m.dog_bark(molly) == "Woof!"
+
+    with pytest.raises(TypeError) as excinfo:
+        m.dog_bark(polly)
+    assert (
+        msg(excinfo.value)
+        == """
+        dog_bark(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: m.class_.Dog) -> str
+
+        Invoked with: <m.class_.Pet object at 0>
+    """
+    )
+
+    with pytest.raises(TypeError) as excinfo:
+        m.Chimera("lion", "goat")
+    assert "No constructor defined!" in str(excinfo.value)
+
+
+def test_inheritance_init(msg):
+    # Single base
+    class Python(m.Pet):
+        def __init__(self):
+            pass
+
+    with pytest.raises(TypeError) as exc_info:
+        Python()
+    expected = "m.class_.Pet.__init__() must be called when overriding __init__"
+    assert msg(exc_info.value) == expected
+
+    # Multiple bases
+    class RabbitHamster(m.Rabbit, m.Hamster):
+        def __init__(self):
+            m.Rabbit.__init__(self, "RabbitHamster")
+
+    with pytest.raises(TypeError) as exc_info:
+        RabbitHamster()
+    expected = "m.class_.Hamster.__init__() must be called when overriding __init__"
+    assert msg(exc_info.value) == expected
+
+
+@pytest.mark.parametrize(
+    "mock_return_value", [None, (1, 2, 3), m.Pet("Polly", "parrot"), m.Dog("Molly")]
+)
+def test_mock_new(mock_return_value):
+    with mock.patch.object(
+        m.Pet, "__new__", return_value=mock_return_value
+    ) as mock_new:
+        obj = m.Pet("Noname", "Nospecies")
+    assert obj is mock_return_value
+    mock_new.assert_called_once_with(m.Pet, "Noname", "Nospecies")
+
+
+def test_automatic_upcasting():
+    assert type(m.return_class_1()).__name__ == "DerivedClass1"
+    assert type(m.return_class_2()).__name__ == "DerivedClass2"
+    assert type(m.return_none()).__name__ == "NoneType"
+    # Repeat these a few times in a random order to ensure no invalid caching is applied
+    assert type(m.return_class_n(1)).__name__ == "DerivedClass1"
+    assert type(m.return_class_n(2)).__name__ == "DerivedClass2"
+    assert type(m.return_class_n(0)).__name__ == "BaseClass"
+    assert type(m.return_class_n(2)).__name__ == "DerivedClass2"
+    assert type(m.return_class_n(2)).__name__ == "DerivedClass2"
+    assert type(m.return_class_n(0)).__name__ == "BaseClass"
+    assert type(m.return_class_n(1)).__name__ == "DerivedClass1"
+
+
+def test_isinstance():
+    objects = [(), {}, m.Pet("Polly", "parrot")] + [m.Dog("Molly")] * 4
+    expected = (True, True, True, True, True, False, False)
+    assert m.check_instances(objects) == expected
+
+
+def test_mismatched_holder():
+    import re
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.mismatched_holder_1()
+    assert re.match(
+        'generic_type: type ".*MismatchDerived1" does not have a non-default '
+        'holder type while its base ".*MismatchBase1" does',
+        str(excinfo.value),
+    )
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.mismatched_holder_2()
+    assert re.match(
+        'generic_type: type ".*MismatchDerived2" has a non-default holder type '
+        'while its base ".*MismatchBase2" does not',
+        str(excinfo.value),
+    )
+
+
+def test_override_static():
+    """#511: problem with inheritance + overwritten def_static"""
+    b = m.MyBase.make()
+    d1 = m.MyDerived.make2()
+    d2 = m.MyDerived.make()
+
+    assert isinstance(b, m.MyBase)
+    assert isinstance(d1, m.MyDerived)
+    assert isinstance(d2, m.MyDerived)
+
+
+def test_implicit_conversion_life_support():
+    """Ensure the lifetime of temporary objects created for implicit conversions"""
+    assert m.implicitly_convert_argument(UserType(5)) == 5
+    assert m.implicitly_convert_variable(UserType(5)) == 5
+
+    assert "outside a bound function" in m.implicitly_convert_variable_fail(UserType(5))
+
+
+def test_operator_new_delete(capture):
+    """Tests that class-specific operator new/delete functions are invoked"""
+
+    class SubAliased(m.AliasedHasOpNewDelSize):
+        pass
+
+    with capture:
+        a = m.HasOpNewDel()
+        b = m.HasOpNewDelSize()
+        d = m.HasOpNewDelBoth()
+    assert (
+        capture
+        == """
+        A new 8
+        B new 4
+        D new 32
+    """
+    )
+    sz_alias = str(m.AliasedHasOpNewDelSize.size_alias)
+    sz_noalias = str(m.AliasedHasOpNewDelSize.size_noalias)
+    with capture:
+        c = m.AliasedHasOpNewDelSize()
+        c2 = SubAliased()
+    assert capture == ("C new " + sz_noalias + "\n" + "C new " + sz_alias + "\n")
+
+    with capture:
+        del a
+        pytest.gc_collect()
+        del b
+        pytest.gc_collect()
+        del d
+        pytest.gc_collect()
+    assert (
+        capture
+        == """
+        A delete
+        B delete 4
+        D delete
+    """
+    )
+
+    with capture:
+        del c
+        pytest.gc_collect()
+        del c2
+        pytest.gc_collect()
+    assert capture == ("C delete " + sz_noalias + "\n" + "C delete " + sz_alias + "\n")
+
+
+def test_bind_protected_functions():
+    """Expose protected member functions to Python using a helper class"""
+    a = m.ProtectedA()
+    assert a.foo() == 42
+
+    b = m.ProtectedB()
+    assert b.foo() == 42
+    assert m.read_foo(b.void_foo()) == 42
+    assert m.pointers_equal(b.get_self(), b)
+
+    class C(m.ProtectedB):
+        def __init__(self):
+            m.ProtectedB.__init__(self)
+
+        def foo(self):
+            return 0
+
+    c = C()
+    assert c.foo() == 0
+
+
+def test_brace_initialization():
+    """Tests that simple POD classes can be constructed using C++11 brace initialization"""
+    a = m.BraceInitialization(123, "test")
+    assert a.field1 == 123
+    assert a.field2 == "test"
+
+    # Tests that a non-simple class doesn't get brace initialization (if the
+    # class defines an initializer_list constructor, in particular, it would
+    # win over the expected constructor).
+    b = m.NoBraceInitialization([123, 456])
+    assert b.vec == [123, 456]
+
+
+@pytest.mark.xfail("env.PYPY")
+def test_class_refcount():
+    """Instances must correctly increase/decrease the reference count of their types (#1029)"""
+    from sys import getrefcount
+
+    class PyDog(m.Dog):
+        pass
+
+    for cls in m.Dog, PyDog:
+        refcount_1 = getrefcount(cls)
+        molly = [cls("Molly") for _ in range(10)]
+        refcount_2 = getrefcount(cls)
+
+        del molly
+        pytest.gc_collect()
+        refcount_3 = getrefcount(cls)
+
+        assert refcount_1 == refcount_3
+        assert refcount_2 > refcount_1
+
+
+def test_reentrant_implicit_conversion_failure(msg):
+    # ensure that there is no runaway reentrant implicit conversion (#1035)
+    with pytest.raises(TypeError) as excinfo:
+        m.BogusImplicitConversion(0)
+    assert (
+        msg(excinfo.value)
+        == """
+        __init__(): incompatible constructor arguments. The following argument types are supported:
+            1. m.class_.BogusImplicitConversion(arg0: m.class_.BogusImplicitConversion)
+
+        Invoked with: 0
+    """
+    )
+
+
+def test_error_after_conversions():
+    with pytest.raises(TypeError) as exc_info:
+        m.test_error_after_conversions("hello")
+    assert str(exc_info.value).startswith(
+        "Unable to convert function return value to a Python type!"
+    )
+
+
+def test_aligned():
+    if hasattr(m, "Aligned"):
+        p = m.Aligned().ptr()
+        assert p % 1024 == 0
+
+
+# https://foss.heptapod.net/pypy/pypy/-/issues/2742
+@pytest.mark.xfail("env.PYPY")
+def test_final():
+    with pytest.raises(TypeError) as exc_info:
+
+        class PyFinalChild(m.IsFinal):
+            pass
+
+    assert str(exc_info.value).endswith("is not an acceptable base type")
+
+
+# https://foss.heptapod.net/pypy/pypy/-/issues/2742
+@pytest.mark.xfail("env.PYPY")
+def test_non_final_final():
+    with pytest.raises(TypeError) as exc_info:
+
+        class PyNonFinalFinalChild(m.IsNonFinalFinal):
+            pass
+
+    assert str(exc_info.value).endswith("is not an acceptable base type")
+
+
+# https://github.com/pybind/pybind11/issues/1878
+def test_exception_rvalue_abort():
+    with pytest.raises(RuntimeError):
+        m.PyPrintDestructor().throw_something()
+
+
+# https://github.com/pybind/pybind11/issues/1568
+def test_multiple_instances_with_same_pointer():
+    n = 100
+    instances = [m.SamePointer() for _ in range(n)]
+    for i in range(n):
+        # We need to reuse the same allocated memory for with a different type,
+        # to ensure the bug in `deregister_instance_impl` is detected. Otherwise
+        # `Py_TYPE(self) == Py_TYPE(it->second)` will still succeed, even though
+        # the `instance` is already deleted.
+        instances[i] = m.Empty()
+    # No assert: if this does not trigger the error
+    #   pybind11_fail("pybind11_object_dealloc(): Tried to deallocate unregistered instance!");
+    # and just completes without crashing, we're good.
+
+
+# https://github.com/pybind/pybind11/issues/1624
+def test_base_and_derived_nested_scope():
+    assert issubclass(m.DerivedWithNested, m.BaseWithNested)
+    assert m.BaseWithNested.Nested != m.DerivedWithNested.Nested
+    assert m.BaseWithNested.Nested.get_name() == "BaseWithNested::Nested"
+    assert m.DerivedWithNested.Nested.get_name() == "DerivedWithNested::Nested"
+
+
+def test_register_duplicate_class():
+    import types
+
+    module_scope = types.ModuleType("module_scope")
+    with pytest.raises(RuntimeError) as exc_info:
+        m.register_duplicate_class_name(module_scope)
+    expected = (
+        'generic_type: cannot initialize type "Duplicate": '
+        "an object with that name is already defined"
+    )
+    assert str(exc_info.value) == expected
+    with pytest.raises(RuntimeError) as exc_info:
+        m.register_duplicate_class_type(module_scope)
+    expected = 'generic_type: type "YetAnotherDuplicate" is already registered!'
+    assert str(exc_info.value) == expected
+
+    class ClassScope:
+        pass
+
+    with pytest.raises(RuntimeError) as exc_info:
+        m.register_duplicate_nested_class_name(ClassScope)
+    expected = (
+        'generic_type: cannot initialize type "DuplicateNested": '
+        "an object with that name is already defined"
+    )
+    assert str(exc_info.value) == expected
+    with pytest.raises(RuntimeError) as exc_info:
+        m.register_duplicate_nested_class_type(ClassScope)
+    expected = 'generic_type: type "YetAnotherDuplicateNested" is already registered!'
+    assert str(exc_info.value) == expected
+
+
+def test_pr4220_tripped_over_this():
+    assert (
+        m.Empty0().get_msg()
+        == "This is really only meant to exercise successful compilation."
+    )
```

## extern/pybind11/tests/test_const_name.py

 * *Ordering differences only*

```diff
@@ -1,29 +1,29 @@
-import pytest
-
-from pybind11_tests import const_name as m
-
-
-@pytest.mark.parametrize("func", [m.const_name_tests, m.underscore_tests])
-@pytest.mark.parametrize(
-    ("selector", "expected"),
-    enumerate(
-        (
-            "",
-            "A",
-            "Bd",
-            "Cef",
-            "%",
-            "%",
-            "T1",
-            "U2",
-            "D1",
-            "E2",
-            "KeepAtEnd",
-        )
-    ),
-)
-def test_const_name(func, selector, expected):
-    if isinstance(func, str):
-        pytest.skip(func)
-    text = func(selector)
-    assert text == expected
+import pytest
+
+from pybind11_tests import const_name as m
+
+
+@pytest.mark.parametrize("func", [m.const_name_tests, m.underscore_tests])
+@pytest.mark.parametrize(
+    ("selector", "expected"),
+    enumerate(
+        (
+            "",
+            "A",
+            "Bd",
+            "Cef",
+            "%",
+            "%",
+            "T1",
+            "U2",
+            "D1",
+            "E2",
+            "KeepAtEnd",
+        )
+    ),
+)
+def test_const_name(func, selector, expected):
+    if isinstance(func, str):
+        pytest.skip(func)
+    text = func(selector)
+    assert text == expected
```

## extern/pybind11/tests/test_constants_and_functions.py

 * *Ordering differences only*

```diff
@@ -1,56 +1,56 @@
-import pytest
-
-m = pytest.importorskip("pybind11_tests.constants_and_functions")
-
-
-def test_constants():
-    assert m.some_constant == 14
-
-
-def test_function_overloading():
-    assert m.test_function() == "test_function()"
-    assert m.test_function(7) == "test_function(7)"
-    assert m.test_function(m.MyEnum.EFirstEntry) == "test_function(enum=1)"
-    assert m.test_function(m.MyEnum.ESecondEntry) == "test_function(enum=2)"
-
-    assert m.test_function() == "test_function()"
-    assert m.test_function("abcd") == "test_function(char *)"
-    assert m.test_function(1, 1.0) == "test_function(int, float)"
-    assert m.test_function(1, 1.0) == "test_function(int, float)"
-    assert m.test_function(2.0, 2) == "test_function(float, int)"
-
-
-def test_bytes():
-    assert m.print_bytes(m.return_bytes()) == "bytes[1 0 2 0]"
-
-
-def test_exception_specifiers():
-    c = m.C()
-    assert c.m1(2) == 1
-    assert c.m2(3) == 1
-    assert c.m3(5) == 2
-    assert c.m4(7) == 3
-    assert c.m5(10) == 5
-    assert c.m6(14) == 8
-    assert c.m7(20) == 13
-    assert c.m8(29) == 21
-
-    assert m.f1(33) == 34
-    assert m.f2(53) == 55
-    assert m.f3(86) == 89
-    assert m.f4(140) == 144
-
-
-def test_function_record_leaks():
-    class RaisingRepr:
-        def __repr__(self):
-            raise RuntimeError("Surprise!")
-
-    with pytest.raises(RuntimeError):
-        m.register_large_capture_with_invalid_arguments(m)
-    with pytest.raises(RuntimeError):
-        m.register_with_raising_repr(m, RaisingRepr())
-
-
-def test_noexcept_lambda():
-    assert m.l1() == 0
+import pytest
+
+m = pytest.importorskip("pybind11_tests.constants_and_functions")
+
+
+def test_constants():
+    assert m.some_constant == 14
+
+
+def test_function_overloading():
+    assert m.test_function() == "test_function()"
+    assert m.test_function(7) == "test_function(7)"
+    assert m.test_function(m.MyEnum.EFirstEntry) == "test_function(enum=1)"
+    assert m.test_function(m.MyEnum.ESecondEntry) == "test_function(enum=2)"
+
+    assert m.test_function() == "test_function()"
+    assert m.test_function("abcd") == "test_function(char *)"
+    assert m.test_function(1, 1.0) == "test_function(int, float)"
+    assert m.test_function(1, 1.0) == "test_function(int, float)"
+    assert m.test_function(2.0, 2) == "test_function(float, int)"
+
+
+def test_bytes():
+    assert m.print_bytes(m.return_bytes()) == "bytes[1 0 2 0]"
+
+
+def test_exception_specifiers():
+    c = m.C()
+    assert c.m1(2) == 1
+    assert c.m2(3) == 1
+    assert c.m3(5) == 2
+    assert c.m4(7) == 3
+    assert c.m5(10) == 5
+    assert c.m6(14) == 8
+    assert c.m7(20) == 13
+    assert c.m8(29) == 21
+
+    assert m.f1(33) == 34
+    assert m.f2(53) == 55
+    assert m.f3(86) == 89
+    assert m.f4(140) == 144
+
+
+def test_function_record_leaks():
+    class RaisingRepr:
+        def __repr__(self):
+            raise RuntimeError("Surprise!")
+
+    with pytest.raises(RuntimeError):
+        m.register_large_capture_with_invalid_arguments(m)
+    with pytest.raises(RuntimeError):
+        m.register_with_raising_repr(m, RaisingRepr())
+
+
+def test_noexcept_lambda():
+    assert m.l1() == 0
```

## extern/pybind11/tests/test_copy_move.py

 * *Ordering differences only*

```diff
@@ -1,132 +1,132 @@
-import pytest
-
-from pybind11_tests import copy_move_policies as m
-
-
-def test_lacking_copy_ctor():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.lacking_copy_ctor.get_one()
-    assert "is non-copyable!" in str(excinfo.value)
-
-
-def test_lacking_move_ctor():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.lacking_move_ctor.get_one()
-    assert "is neither movable nor copyable!" in str(excinfo.value)
-
-
-def test_move_and_copy_casts():
-    """Cast some values in C++ via custom type casters and count the number of moves/copies."""
-
-    cstats = m.move_and_copy_cstats()
-    c_m, c_mc, c_c = (
-        cstats["MoveOnlyInt"],
-        cstats["MoveOrCopyInt"],
-        cstats["CopyOnlyInt"],
-    )
-
-    # The type move constructions/assignments below each get incremented: the move assignment comes
-    # from the type_caster load; the move construction happens when extracting that via a cast or
-    # loading into an argument.
-    assert m.move_and_copy_casts(3) == 18
-    assert c_m.copy_assignments + c_m.copy_constructions == 0
-    assert c_m.move_assignments == 2
-    assert c_m.move_constructions >= 2
-    assert c_mc.alive() == 0
-    assert c_mc.copy_assignments + c_mc.copy_constructions == 0
-    assert c_mc.move_assignments == 2
-    assert c_mc.move_constructions >= 2
-    assert c_c.alive() == 0
-    assert c_c.copy_assignments == 2
-    assert c_c.copy_constructions >= 2
-    assert c_m.alive() + c_mc.alive() + c_c.alive() == 0
-
-
-def test_move_and_copy_loads():
-    """Call some functions that load arguments via custom type casters and count the number of
-    moves/copies."""
-
-    cstats = m.move_and_copy_cstats()
-    c_m, c_mc, c_c = (
-        cstats["MoveOnlyInt"],
-        cstats["MoveOrCopyInt"],
-        cstats["CopyOnlyInt"],
-    )
-
-    assert m.move_only(10) == 10  # 1 move, c_m
-    assert m.move_or_copy(11) == 11  # 1 move, c_mc
-    assert m.copy_only(12) == 12  # 1 copy, c_c
-    assert m.move_pair((13, 14)) == 27  # 1 c_m move, 1 c_mc move
-    assert m.move_tuple((15, 16, 17)) == 48  # 2 c_m moves, 1 c_mc move
-    assert m.copy_tuple((18, 19)) == 37  # 2 c_c copies
-    # Direct constructions: 2 c_m moves, 2 c_mc moves, 1 c_c copy
-    # Extra moves/copies when moving pairs/tuples: 3 c_m, 3 c_mc, 2 c_c
-    assert m.move_copy_nested((1, ((2, 3, (4,)), 5))) == 15
-
-    assert c_m.copy_assignments + c_m.copy_constructions == 0
-    assert c_m.move_assignments == 6
-    assert c_m.move_constructions == 9
-    assert c_mc.copy_assignments + c_mc.copy_constructions == 0
-    assert c_mc.move_assignments == 5
-    assert c_mc.move_constructions == 8
-    assert c_c.copy_assignments == 4
-    assert c_c.copy_constructions == 6
-    assert c_m.alive() + c_mc.alive() + c_c.alive() == 0
-
-
-@pytest.mark.skipif(not m.has_optional, reason="no <optional>")
-def test_move_and_copy_load_optional():
-    """Tests move/copy loads of std::optional arguments"""
-
-    cstats = m.move_and_copy_cstats()
-    c_m, c_mc, c_c = (
-        cstats["MoveOnlyInt"],
-        cstats["MoveOrCopyInt"],
-        cstats["CopyOnlyInt"],
-    )
-
-    # The extra move/copy constructions below come from the std::optional move (which has to move
-    # its arguments):
-    assert m.move_optional(10) == 10  # c_m: 1 move assign, 2 move construct
-    assert m.move_or_copy_optional(11) == 11  # c_mc: 1 move assign, 2 move construct
-    assert m.copy_optional(12) == 12  # c_c: 1 copy assign, 2 copy construct
-    # 1 move assign + move construct moves each of c_m, c_mc, 1 c_c copy
-    # +1 move/copy construct each from moving the tuple
-    # +1 move/copy construct each from moving the optional (which moves the tuple again)
-    assert m.move_optional_tuple((3, 4, 5)) == 12
-
-    assert c_m.copy_assignments + c_m.copy_constructions == 0
-    assert c_m.move_assignments == 2
-    assert c_m.move_constructions == 5
-    assert c_mc.copy_assignments + c_mc.copy_constructions == 0
-    assert c_mc.move_assignments == 2
-    assert c_mc.move_constructions == 5
-    assert c_c.copy_assignments == 2
-    assert c_c.copy_constructions == 5
-    assert c_m.alive() + c_mc.alive() + c_c.alive() == 0
-
-
-def test_private_op_new():
-    """An object with a private `operator new` cannot be returned by value"""
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.private_op_new_value()
-    assert "is neither movable nor copyable" in str(excinfo.value)
-
-    assert m.private_op_new_reference().value == 1
-
-
-def test_move_fallback():
-    """#389: rvp::move should fall-through to copy on non-movable objects"""
-
-    m1 = m.get_moveissue1(1)
-    assert m1.value == 1
-    m2 = m.get_moveissue2(2)
-    assert m2.value == 2
-
-
-def test_pytype_rvalue_cast():
-    """Make sure that cast from pytype rvalue to other pytype works"""
-
-    value = m.get_pytype_rvalue_castissue(1.0)
-    assert value == 1
+import pytest
+
+from pybind11_tests import copy_move_policies as m
+
+
+def test_lacking_copy_ctor():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.lacking_copy_ctor.get_one()
+    assert "is non-copyable!" in str(excinfo.value)
+
+
+def test_lacking_move_ctor():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.lacking_move_ctor.get_one()
+    assert "is neither movable nor copyable!" in str(excinfo.value)
+
+
+def test_move_and_copy_casts():
+    """Cast some values in C++ via custom type casters and count the number of moves/copies."""
+
+    cstats = m.move_and_copy_cstats()
+    c_m, c_mc, c_c = (
+        cstats["MoveOnlyInt"],
+        cstats["MoveOrCopyInt"],
+        cstats["CopyOnlyInt"],
+    )
+
+    # The type move constructions/assignments below each get incremented: the move assignment comes
+    # from the type_caster load; the move construction happens when extracting that via a cast or
+    # loading into an argument.
+    assert m.move_and_copy_casts(3) == 18
+    assert c_m.copy_assignments + c_m.copy_constructions == 0
+    assert c_m.move_assignments == 2
+    assert c_m.move_constructions >= 2
+    assert c_mc.alive() == 0
+    assert c_mc.copy_assignments + c_mc.copy_constructions == 0
+    assert c_mc.move_assignments == 2
+    assert c_mc.move_constructions >= 2
+    assert c_c.alive() == 0
+    assert c_c.copy_assignments == 2
+    assert c_c.copy_constructions >= 2
+    assert c_m.alive() + c_mc.alive() + c_c.alive() == 0
+
+
+def test_move_and_copy_loads():
+    """Call some functions that load arguments via custom type casters and count the number of
+    moves/copies."""
+
+    cstats = m.move_and_copy_cstats()
+    c_m, c_mc, c_c = (
+        cstats["MoveOnlyInt"],
+        cstats["MoveOrCopyInt"],
+        cstats["CopyOnlyInt"],
+    )
+
+    assert m.move_only(10) == 10  # 1 move, c_m
+    assert m.move_or_copy(11) == 11  # 1 move, c_mc
+    assert m.copy_only(12) == 12  # 1 copy, c_c
+    assert m.move_pair((13, 14)) == 27  # 1 c_m move, 1 c_mc move
+    assert m.move_tuple((15, 16, 17)) == 48  # 2 c_m moves, 1 c_mc move
+    assert m.copy_tuple((18, 19)) == 37  # 2 c_c copies
+    # Direct constructions: 2 c_m moves, 2 c_mc moves, 1 c_c copy
+    # Extra moves/copies when moving pairs/tuples: 3 c_m, 3 c_mc, 2 c_c
+    assert m.move_copy_nested((1, ((2, 3, (4,)), 5))) == 15
+
+    assert c_m.copy_assignments + c_m.copy_constructions == 0
+    assert c_m.move_assignments == 6
+    assert c_m.move_constructions == 9
+    assert c_mc.copy_assignments + c_mc.copy_constructions == 0
+    assert c_mc.move_assignments == 5
+    assert c_mc.move_constructions == 8
+    assert c_c.copy_assignments == 4
+    assert c_c.copy_constructions == 6
+    assert c_m.alive() + c_mc.alive() + c_c.alive() == 0
+
+
+@pytest.mark.skipif(not m.has_optional, reason="no <optional>")
+def test_move_and_copy_load_optional():
+    """Tests move/copy loads of std::optional arguments"""
+
+    cstats = m.move_and_copy_cstats()
+    c_m, c_mc, c_c = (
+        cstats["MoveOnlyInt"],
+        cstats["MoveOrCopyInt"],
+        cstats["CopyOnlyInt"],
+    )
+
+    # The extra move/copy constructions below come from the std::optional move (which has to move
+    # its arguments):
+    assert m.move_optional(10) == 10  # c_m: 1 move assign, 2 move construct
+    assert m.move_or_copy_optional(11) == 11  # c_mc: 1 move assign, 2 move construct
+    assert m.copy_optional(12) == 12  # c_c: 1 copy assign, 2 copy construct
+    # 1 move assign + move construct moves each of c_m, c_mc, 1 c_c copy
+    # +1 move/copy construct each from moving the tuple
+    # +1 move/copy construct each from moving the optional (which moves the tuple again)
+    assert m.move_optional_tuple((3, 4, 5)) == 12
+
+    assert c_m.copy_assignments + c_m.copy_constructions == 0
+    assert c_m.move_assignments == 2
+    assert c_m.move_constructions == 5
+    assert c_mc.copy_assignments + c_mc.copy_constructions == 0
+    assert c_mc.move_assignments == 2
+    assert c_mc.move_constructions == 5
+    assert c_c.copy_assignments == 2
+    assert c_c.copy_constructions == 5
+    assert c_m.alive() + c_mc.alive() + c_c.alive() == 0
+
+
+def test_private_op_new():
+    """An object with a private `operator new` cannot be returned by value"""
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.private_op_new_value()
+    assert "is neither movable nor copyable" in str(excinfo.value)
+
+    assert m.private_op_new_reference().value == 1
+
+
+def test_move_fallback():
+    """#389: rvp::move should fall-through to copy on non-movable objects"""
+
+    m1 = m.get_moveissue1(1)
+    assert m1.value == 1
+    m2 = m.get_moveissue2(2)
+    assert m2.value == 2
+
+
+def test_pytype_rvalue_cast():
+    """Make sure that cast from pytype rvalue to other pytype works"""
+
+    value = m.get_pytype_rvalue_castissue(1.0)
+    assert value == 1
```

## extern/pybind11/tests/test_custom_type_casters.py

 * *Ordering differences only*

```diff
@@ -1,122 +1,122 @@
-import pytest
-
-from pybind11_tests import custom_type_casters as m
-
-
-def test_noconvert_args(msg):
-    a = m.ArgInspector()
-    assert (
-        msg(a.f("hi"))
-        == """
-        loading ArgInspector1 argument WITH conversion allowed.  Argument value = hi
-    """
-    )
-    assert (
-        msg(a.g("this is a", "this is b"))
-        == """
-        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = this is a
-        loading ArgInspector1 argument WITH conversion allowed.  Argument value = this is b
-        13
-        loading ArgInspector2 argument WITH conversion allowed.  Argument value = (default arg inspector 2)
-    """
-    )
-    assert (
-        msg(a.g("this is a", "this is b", 42))
-        == """
-        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = this is a
-        loading ArgInspector1 argument WITH conversion allowed.  Argument value = this is b
-        42
-        loading ArgInspector2 argument WITH conversion allowed.  Argument value = (default arg inspector 2)
-    """
-    )
-    assert (
-        msg(a.g("this is a", "this is b", 42, "this is d"))
-        == """
-        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = this is a
-        loading ArgInspector1 argument WITH conversion allowed.  Argument value = this is b
-        42
-        loading ArgInspector2 argument WITH conversion allowed.  Argument value = this is d
-    """
-    )
-    assert (
-        a.h("arg 1")
-        == "loading ArgInspector2 argument WITHOUT conversion allowed.  Argument value = arg 1"
-    )
-    assert (
-        msg(m.arg_inspect_func("A1", "A2"))
-        == """
-        loading ArgInspector2 argument WITH conversion allowed.  Argument value = A1
-        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = A2
-    """
-    )
-
-    assert m.floats_preferred(4) == 2.0
-    assert m.floats_only(4.0) == 2.0
-    with pytest.raises(TypeError) as excinfo:
-        m.floats_only(4)
-    assert (
-        msg(excinfo.value)
-        == """
-        floats_only(): incompatible function arguments. The following argument types are supported:
-            1. (f: float) -> float
-
-        Invoked with: 4
-    """
-    )
-
-    assert m.ints_preferred(4) == 2
-    assert m.ints_preferred(True) == 0
-    with pytest.raises(TypeError) as excinfo:
-        m.ints_preferred(4.0)
-    assert (
-        msg(excinfo.value)
-        == """
-        ints_preferred(): incompatible function arguments. The following argument types are supported:
-            1. (i: int) -> int
-
-        Invoked with: 4.0
-    """
-    )
-
-    assert m.ints_only(4) == 2
-    with pytest.raises(TypeError) as excinfo:
-        m.ints_only(4.0)
-    assert (
-        msg(excinfo.value)
-        == """
-        ints_only(): incompatible function arguments. The following argument types are supported:
-            1. (i: int) -> int
-
-        Invoked with: 4.0
-    """
-    )
-
-
-def test_custom_caster_destruction():
-    """Tests that returning a pointer to a type that gets converted with a custom type caster gets
-    destroyed when the function has py::return_value_policy::take_ownership policy applied.
-    """
-
-    cstats = m.destruction_tester_cstats()
-    # This one *doesn't* have take_ownership: the pointer should be used but not destroyed:
-    z = m.custom_caster_no_destroy()
-    assert cstats.alive() == 1
-    assert cstats.default_constructions == 1
-    assert z
-
-    # take_ownership applied: this constructs a new object, casts it, then destroys it:
-    z = m.custom_caster_destroy()
-    assert z
-    assert cstats.default_constructions == 2
-
-    # Same, but with a const pointer return (which should *not* inhibit destruction):
-    z = m.custom_caster_destroy_const()
-    assert z
-    assert cstats.default_constructions == 3
-
-    # Make sure we still only have the original object (from ..._no_destroy()) alive:
-    assert cstats.alive() == 1
-
-
-def test_custom_caster_other_lib():
-    assert m.other_lib_type(True)
+import pytest
+
+from pybind11_tests import custom_type_casters as m
+
+
+def test_noconvert_args(msg):
+    a = m.ArgInspector()
+    assert (
+        msg(a.f("hi"))
+        == """
+        loading ArgInspector1 argument WITH conversion allowed.  Argument value = hi
+    """
+    )
+    assert (
+        msg(a.g("this is a", "this is b"))
+        == """
+        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = this is a
+        loading ArgInspector1 argument WITH conversion allowed.  Argument value = this is b
+        13
+        loading ArgInspector2 argument WITH conversion allowed.  Argument value = (default arg inspector 2)
+    """
+    )
+    assert (
+        msg(a.g("this is a", "this is b", 42))
+        == """
+        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = this is a
+        loading ArgInspector1 argument WITH conversion allowed.  Argument value = this is b
+        42
+        loading ArgInspector2 argument WITH conversion allowed.  Argument value = (default arg inspector 2)
+    """
+    )
+    assert (
+        msg(a.g("this is a", "this is b", 42, "this is d"))
+        == """
+        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = this is a
+        loading ArgInspector1 argument WITH conversion allowed.  Argument value = this is b
+        42
+        loading ArgInspector2 argument WITH conversion allowed.  Argument value = this is d
+    """
+    )
+    assert (
+        a.h("arg 1")
+        == "loading ArgInspector2 argument WITHOUT conversion allowed.  Argument value = arg 1"
+    )
+    assert (
+        msg(m.arg_inspect_func("A1", "A2"))
+        == """
+        loading ArgInspector2 argument WITH conversion allowed.  Argument value = A1
+        loading ArgInspector1 argument WITHOUT conversion allowed.  Argument value = A2
+    """
+    )
+
+    assert m.floats_preferred(4) == 2.0
+    assert m.floats_only(4.0) == 2.0
+    with pytest.raises(TypeError) as excinfo:
+        m.floats_only(4)
+    assert (
+        msg(excinfo.value)
+        == """
+        floats_only(): incompatible function arguments. The following argument types are supported:
+            1. (f: float) -> float
+
+        Invoked with: 4
+    """
+    )
+
+    assert m.ints_preferred(4) == 2
+    assert m.ints_preferred(True) == 0
+    with pytest.raises(TypeError) as excinfo:
+        m.ints_preferred(4.0)
+    assert (
+        msg(excinfo.value)
+        == """
+        ints_preferred(): incompatible function arguments. The following argument types are supported:
+            1. (i: int) -> int
+
+        Invoked with: 4.0
+    """
+    )
+
+    assert m.ints_only(4) == 2
+    with pytest.raises(TypeError) as excinfo:
+        m.ints_only(4.0)
+    assert (
+        msg(excinfo.value)
+        == """
+        ints_only(): incompatible function arguments. The following argument types are supported:
+            1. (i: int) -> int
+
+        Invoked with: 4.0
+    """
+    )
+
+
+def test_custom_caster_destruction():
+    """Tests that returning a pointer to a type that gets converted with a custom type caster gets
+    destroyed when the function has py::return_value_policy::take_ownership policy applied.
+    """
+
+    cstats = m.destruction_tester_cstats()
+    # This one *doesn't* have take_ownership: the pointer should be used but not destroyed:
+    z = m.custom_caster_no_destroy()
+    assert cstats.alive() == 1
+    assert cstats.default_constructions == 1
+    assert z
+
+    # take_ownership applied: this constructs a new object, casts it, then destroys it:
+    z = m.custom_caster_destroy()
+    assert z
+    assert cstats.default_constructions == 2
+
+    # Same, but with a const pointer return (which should *not* inhibit destruction):
+    z = m.custom_caster_destroy_const()
+    assert z
+    assert cstats.default_constructions == 3
+
+    # Make sure we still only have the original object (from ..._no_destroy()) alive:
+    assert cstats.alive() == 1
+
+
+def test_custom_caster_other_lib():
+    assert m.other_lib_type(True)
```

## extern/pybind11/tests/test_custom_type_setup.py

 * *Ordering differences only*

```diff
@@ -1,48 +1,48 @@
-import gc
-import weakref
-
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import custom_type_setup as m
-
-
-@pytest.fixture()
-def gc_tester():
-    """Tests that an object is garbage collected.
-
-    Assumes that any unreferenced objects are fully collected after calling
-    `gc.collect()`.  That is true on CPython, but does not appear to reliably
-    hold on PyPy.
-    """
-
-    weak_refs = []
-
-    def add_ref(obj):
-        # PyPy does not support `gc.is_tracked`.
-        if hasattr(gc, "is_tracked"):
-            assert gc.is_tracked(obj)
-        weak_refs.append(weakref.ref(obj))
-
-    yield add_ref
-
-    gc.collect()
-    for ref in weak_refs:
-        assert ref() is None
-
-
-# PyPy does not seem to reliably garbage collect.
-@pytest.mark.skipif("env.PYPY")
-def test_self_cycle(gc_tester):
-    obj = m.OwnsPythonObjects()
-    obj.value = obj
-    gc_tester(obj)
-
-
-# PyPy does not seem to reliably garbage collect.
-@pytest.mark.skipif("env.PYPY")
-def test_indirect_cycle(gc_tester):
-    obj = m.OwnsPythonObjects()
-    obj_list = [obj]
-    obj.value = obj_list
-    gc_tester(obj)
+import gc
+import weakref
+
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import custom_type_setup as m
+
+
+@pytest.fixture()
+def gc_tester():
+    """Tests that an object is garbage collected.
+
+    Assumes that any unreferenced objects are fully collected after calling
+    `gc.collect()`.  That is true on CPython, but does not appear to reliably
+    hold on PyPy.
+    """
+
+    weak_refs = []
+
+    def add_ref(obj):
+        # PyPy does not support `gc.is_tracked`.
+        if hasattr(gc, "is_tracked"):
+            assert gc.is_tracked(obj)
+        weak_refs.append(weakref.ref(obj))
+
+    yield add_ref
+
+    gc.collect()
+    for ref in weak_refs:
+        assert ref() is None
+
+
+# PyPy does not seem to reliably garbage collect.
+@pytest.mark.skipif("env.PYPY")
+def test_self_cycle(gc_tester):
+    obj = m.OwnsPythonObjects()
+    obj.value = obj
+    gc_tester(obj)
+
+
+# PyPy does not seem to reliably garbage collect.
+@pytest.mark.skipif("env.PYPY")
+def test_indirect_cycle(gc_tester):
+    obj = m.OwnsPythonObjects()
+    obj_list = [obj]
+    obj.value = obj_list
+    gc_tester(obj)
```

## extern/pybind11/tests/test_docstring_options.py

 * *Ordering differences only*

```diff
@@ -1,64 +1,64 @@
-from pybind11_tests import docstring_options as m
-
-
-def test_docstring_options():
-    # options.disable_function_signatures()
-    assert not m.test_function1.__doc__
-
-    assert m.test_function2.__doc__ == "A custom docstring"
-
-    # docstring specified on just the first overload definition:
-    assert m.test_overloaded1.__doc__ == "Overload docstring"
-
-    # docstring on both overloads:
-    assert m.test_overloaded2.__doc__ == "overload docstring 1\noverload docstring 2"
-
-    # docstring on only second overload:
-    assert m.test_overloaded3.__doc__ == "Overload docstr"
-
-    # options.enable_function_signatures()
-    assert m.test_function3.__doc__.startswith("test_function3(a: int, b: int) -> None")
-
-    assert m.test_function4.__doc__.startswith("test_function4(a: int, b: int) -> None")
-    assert m.test_function4.__doc__.endswith("A custom docstring\n")
-
-    # options.disable_function_signatures()
-    # options.disable_user_defined_docstrings()
-    assert not m.test_function5.__doc__
-
-    # nested options.enable_user_defined_docstrings()
-    assert m.test_function6.__doc__ == "A custom docstring"
-
-    # RAII destructor
-    assert m.test_function7.__doc__.startswith("test_function7(a: int, b: int) -> None")
-    assert m.test_function7.__doc__.endswith("A custom docstring\n")
-
-    # when all options are disabled, no docstring (instead of an empty one) should be generated
-    assert m.test_function8.__doc__ is None
-
-    # Suppression of user-defined docstrings for non-function objects
-    assert not m.DocstringTestFoo.__doc__
-    assert not m.DocstringTestFoo.value_prop.__doc__
-
-    # Check existig behaviour of enum docstings
-    assert (
-        m.DocstringTestEnum1.__doc__
-        == "Enum docstring\n\nMembers:\n\n  Member1\n\n  Member2"
-    )
-
-    # options.enable_enum_members_docstring()
-    assert (
-        m.DocstringTestEnum2.__doc__
-        == "Enum docstring\n\nMembers:\n\n  Member1\n\n  Member2"
-    )
-
-    # options.disable_enum_members_docstring()
-    assert m.DocstringTestEnum3.__doc__ == "Enum docstring"
-
-    # options.disable_user_defined_docstrings()
-    assert m.DocstringTestEnum4.__doc__ == "Members:\n\n  Member1\n\n  Member2"
-
-    # options.disable_user_defined_docstrings()
-    # options.disable_enum_members_docstring()
-    # When all options are disabled, no docstring (instead of an empty one) should be generated
-    assert m.DocstringTestEnum5.__doc__ is None
+from pybind11_tests import docstring_options as m
+
+
+def test_docstring_options():
+    # options.disable_function_signatures()
+    assert not m.test_function1.__doc__
+
+    assert m.test_function2.__doc__ == "A custom docstring"
+
+    # docstring specified on just the first overload definition:
+    assert m.test_overloaded1.__doc__ == "Overload docstring"
+
+    # docstring on both overloads:
+    assert m.test_overloaded2.__doc__ == "overload docstring 1\noverload docstring 2"
+
+    # docstring on only second overload:
+    assert m.test_overloaded3.__doc__ == "Overload docstr"
+
+    # options.enable_function_signatures()
+    assert m.test_function3.__doc__.startswith("test_function3(a: int, b: int) -> None")
+
+    assert m.test_function4.__doc__.startswith("test_function4(a: int, b: int) -> None")
+    assert m.test_function4.__doc__.endswith("A custom docstring\n")
+
+    # options.disable_function_signatures()
+    # options.disable_user_defined_docstrings()
+    assert not m.test_function5.__doc__
+
+    # nested options.enable_user_defined_docstrings()
+    assert m.test_function6.__doc__ == "A custom docstring"
+
+    # RAII destructor
+    assert m.test_function7.__doc__.startswith("test_function7(a: int, b: int) -> None")
+    assert m.test_function7.__doc__.endswith("A custom docstring\n")
+
+    # when all options are disabled, no docstring (instead of an empty one) should be generated
+    assert m.test_function8.__doc__ is None
+
+    # Suppression of user-defined docstrings for non-function objects
+    assert not m.DocstringTestFoo.__doc__
+    assert not m.DocstringTestFoo.value_prop.__doc__
+
+    # Check existig behaviour of enum docstings
+    assert (
+        m.DocstringTestEnum1.__doc__
+        == "Enum docstring\n\nMembers:\n\n  Member1\n\n  Member2"
+    )
+
+    # options.enable_enum_members_docstring()
+    assert (
+        m.DocstringTestEnum2.__doc__
+        == "Enum docstring\n\nMembers:\n\n  Member1\n\n  Member2"
+    )
+
+    # options.disable_enum_members_docstring()
+    assert m.DocstringTestEnum3.__doc__ == "Enum docstring"
+
+    # options.disable_user_defined_docstrings()
+    assert m.DocstringTestEnum4.__doc__ == "Members:\n\n  Member1\n\n  Member2"
+
+    # options.disable_user_defined_docstrings()
+    # options.disable_enum_members_docstring()
+    # When all options are disabled, no docstring (instead of an empty one) should be generated
+    assert m.DocstringTestEnum5.__doc__ is None
```

## extern/pybind11/tests/test_eigen_matrix.py

 * *Ordering differences only*

```diff
@@ -1,812 +1,812 @@
-import pytest
-
-from pybind11_tests import ConstructorStats
-
-np = pytest.importorskip("numpy")
-m = pytest.importorskip("pybind11_tests.eigen_matrix")
-
-
-ref = np.array(
-    [
-        [0.0, 3, 0, 0, 0, 11],
-        [22, 0, 0, 0, 17, 11],
-        [7, 5, 0, 1, 0, 11],
-        [0, 0, 0, 0, 0, 11],
-        [0, 0, 14, 0, 8, 11],
-    ]
-)
-
-
-def assert_equal_ref(mat):
-    np.testing.assert_array_equal(mat, ref)
-
-
-def assert_sparse_equal_ref(sparse_mat):
-    assert_equal_ref(sparse_mat.toarray())
-
-
-def test_fixed():
-    assert_equal_ref(m.fixed_c())
-    assert_equal_ref(m.fixed_r())
-    assert_equal_ref(m.fixed_copy_r(m.fixed_r()))
-    assert_equal_ref(m.fixed_copy_c(m.fixed_c()))
-    assert_equal_ref(m.fixed_copy_r(m.fixed_c()))
-    assert_equal_ref(m.fixed_copy_c(m.fixed_r()))
-
-
-def test_dense():
-    assert_equal_ref(m.dense_r())
-    assert_equal_ref(m.dense_c())
-    assert_equal_ref(m.dense_copy_r(m.dense_r()))
-    assert_equal_ref(m.dense_copy_c(m.dense_c()))
-    assert_equal_ref(m.dense_copy_r(m.dense_c()))
-    assert_equal_ref(m.dense_copy_c(m.dense_r()))
-
-
-def test_partially_fixed():
-    ref2 = np.array([[0.0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]])
-    np.testing.assert_array_equal(m.partial_copy_four_rm_r(ref2), ref2)
-    np.testing.assert_array_equal(m.partial_copy_four_rm_c(ref2), ref2)
-    np.testing.assert_array_equal(m.partial_copy_four_rm_r(ref2[:, 1]), ref2[:, [1]])
-    np.testing.assert_array_equal(m.partial_copy_four_rm_c(ref2[0, :]), ref2[[0], :])
-    np.testing.assert_array_equal(
-        m.partial_copy_four_rm_r(ref2[:, (0, 2)]), ref2[:, (0, 2)]
-    )
-    np.testing.assert_array_equal(
-        m.partial_copy_four_rm_c(ref2[(3, 1, 2), :]), ref2[(3, 1, 2), :]
-    )
-
-    np.testing.assert_array_equal(m.partial_copy_four_cm_r(ref2), ref2)
-    np.testing.assert_array_equal(m.partial_copy_four_cm_c(ref2), ref2)
-    np.testing.assert_array_equal(m.partial_copy_four_cm_r(ref2[:, 1]), ref2[:, [1]])
-    np.testing.assert_array_equal(m.partial_copy_four_cm_c(ref2[0, :]), ref2[[0], :])
-    np.testing.assert_array_equal(
-        m.partial_copy_four_cm_r(ref2[:, (0, 2)]), ref2[:, (0, 2)]
-    )
-    np.testing.assert_array_equal(
-        m.partial_copy_four_cm_c(ref2[(3, 1, 2), :]), ref2[(3, 1, 2), :]
-    )
-
-    # TypeError should be raise for a shape mismatch
-    functions = [
-        m.partial_copy_four_rm_r,
-        m.partial_copy_four_rm_c,
-        m.partial_copy_four_cm_r,
-        m.partial_copy_four_cm_c,
-    ]
-    matrix_with_wrong_shape = [[1, 2], [3, 4]]
-    for f in functions:
-        with pytest.raises(TypeError) as excinfo:
-            f(matrix_with_wrong_shape)
-        assert "incompatible function arguments" in str(excinfo.value)
-
-
-def test_mutator_descriptors():
-    zr = np.arange(30, dtype="float32").reshape(5, 6)  # row-major
-    zc = zr.reshape(6, 5).transpose()  # column-major
-
-    m.fixed_mutator_r(zr)
-    m.fixed_mutator_c(zc)
-    m.fixed_mutator_a(zr)
-    m.fixed_mutator_a(zc)
-    with pytest.raises(TypeError) as excinfo:
-        m.fixed_mutator_r(zc)
-    assert (
-        "(arg0: numpy.ndarray[numpy.float32[5, 6],"
-        " flags.writeable, flags.c_contiguous]) -> None" in str(excinfo.value)
-    )
-    with pytest.raises(TypeError) as excinfo:
-        m.fixed_mutator_c(zr)
-    assert (
-        "(arg0: numpy.ndarray[numpy.float32[5, 6],"
-        " flags.writeable, flags.f_contiguous]) -> None" in str(excinfo.value)
-    )
-    with pytest.raises(TypeError) as excinfo:
-        m.fixed_mutator_a(np.array([[1, 2], [3, 4]], dtype="float32"))
-    assert "(arg0: numpy.ndarray[numpy.float32[5, 6], flags.writeable]) -> None" in str(
-        excinfo.value
-    )
-    zr.flags.writeable = False
-    with pytest.raises(TypeError):
-        m.fixed_mutator_r(zr)
-    with pytest.raises(TypeError):
-        m.fixed_mutator_a(zr)
-
-
-def test_cpp_casting():
-    assert m.cpp_copy(m.fixed_r()) == 22.0
-    assert m.cpp_copy(m.fixed_c()) == 22.0
-    z = np.array([[5.0, 6], [7, 8]])
-    assert m.cpp_copy(z) == 7.0
-    assert m.cpp_copy(m.get_cm_ref()) == 21.0
-    assert m.cpp_copy(m.get_rm_ref()) == 21.0
-    assert m.cpp_ref_c(m.get_cm_ref()) == 21.0
-    assert m.cpp_ref_r(m.get_rm_ref()) == 21.0
-    with pytest.raises(RuntimeError) as excinfo:
-        # Can't reference m.fixed_c: it contains floats, m.cpp_ref_any wants doubles
-        m.cpp_ref_any(m.fixed_c())
-    assert "Unable to cast Python instance" in str(excinfo.value)
-    with pytest.raises(RuntimeError) as excinfo:
-        # Can't reference m.fixed_r: it contains floats, m.cpp_ref_any wants doubles
-        m.cpp_ref_any(m.fixed_r())
-    assert "Unable to cast Python instance" in str(excinfo.value)
-    assert m.cpp_ref_any(m.ReturnTester.create()) == 1.0
-
-    assert m.cpp_ref_any(m.get_cm_ref()) == 21.0
-    assert m.cpp_ref_any(m.get_cm_ref()) == 21.0
-
-
-def test_pass_readonly_array():
-    z = np.full((5, 6), 42.0)
-    z.flags.writeable = False
-    np.testing.assert_array_equal(z, m.fixed_copy_r(z))
-    np.testing.assert_array_equal(m.fixed_r_const(), m.fixed_r())
-    assert not m.fixed_r_const().flags.writeable
-    np.testing.assert_array_equal(m.fixed_copy_r(m.fixed_r_const()), m.fixed_r_const())
-
-
-def test_nonunit_stride_from_python():
-    counting_mat = np.arange(9.0, dtype=np.float32).reshape((3, 3))
-    second_row = counting_mat[1, :]
-    second_col = counting_mat[:, 1]
-    np.testing.assert_array_equal(m.double_row(second_row), 2.0 * second_row)
-    np.testing.assert_array_equal(m.double_col(second_row), 2.0 * second_row)
-    np.testing.assert_array_equal(m.double_complex(second_row), 2.0 * second_row)
-    np.testing.assert_array_equal(m.double_row(second_col), 2.0 * second_col)
-    np.testing.assert_array_equal(m.double_col(second_col), 2.0 * second_col)
-    np.testing.assert_array_equal(m.double_complex(second_col), 2.0 * second_col)
-
-    counting_3d = np.arange(27.0, dtype=np.float32).reshape((3, 3, 3))
-    slices = [counting_3d[0, :, :], counting_3d[:, 0, :], counting_3d[:, :, 0]]
-    for ref_mat in slices:
-        np.testing.assert_array_equal(m.double_mat_cm(ref_mat), 2.0 * ref_mat)
-        np.testing.assert_array_equal(m.double_mat_rm(ref_mat), 2.0 * ref_mat)
-
-    # Mutator:
-    m.double_threer(second_row)
-    m.double_threec(second_col)
-    np.testing.assert_array_equal(counting_mat, [[0.0, 2, 2], [6, 16, 10], [6, 14, 8]])
-
-
-def test_negative_stride_from_python(msg):
-    """Eigen doesn't support (as of yet) negative strides. When a function takes an Eigen matrix by
-    copy or const reference, we can pass a numpy array that has negative strides.  Otherwise, an
-    exception will be thrown as Eigen will not be able to map the numpy array."""
-
-    counting_mat = np.arange(9.0, dtype=np.float32).reshape((3, 3))
-    counting_mat = counting_mat[::-1, ::-1]
-    second_row = counting_mat[1, :]
-    second_col = counting_mat[:, 1]
-    np.testing.assert_array_equal(m.double_row(second_row), 2.0 * second_row)
-    np.testing.assert_array_equal(m.double_col(second_row), 2.0 * second_row)
-    np.testing.assert_array_equal(m.double_complex(second_row), 2.0 * second_row)
-    np.testing.assert_array_equal(m.double_row(second_col), 2.0 * second_col)
-    np.testing.assert_array_equal(m.double_col(second_col), 2.0 * second_col)
-    np.testing.assert_array_equal(m.double_complex(second_col), 2.0 * second_col)
-
-    counting_3d = np.arange(27.0, dtype=np.float32).reshape((3, 3, 3))
-    counting_3d = counting_3d[::-1, ::-1, ::-1]
-    slices = [counting_3d[0, :, :], counting_3d[:, 0, :], counting_3d[:, :, 0]]
-    for ref_mat in slices:
-        np.testing.assert_array_equal(m.double_mat_cm(ref_mat), 2.0 * ref_mat)
-        np.testing.assert_array_equal(m.double_mat_rm(ref_mat), 2.0 * ref_mat)
-
-    # Mutator:
-    with pytest.raises(TypeError) as excinfo:
-        m.double_threer(second_row)
-    assert (
-        msg(excinfo.value)
-        == """
-        double_threer(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: numpy.ndarray[numpy.float32[1, 3], flags.writeable]) -> None
-
-        Invoked with: """
-        + repr(np.array([5.0, 4.0, 3.0], dtype="float32"))
-    )
-
-    with pytest.raises(TypeError) as excinfo:
-        m.double_threec(second_col)
-    assert (
-        msg(excinfo.value)
-        == """
-        double_threec(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: numpy.ndarray[numpy.float32[3, 1], flags.writeable]) -> None
-
-        Invoked with: """
-        + repr(np.array([7.0, 4.0, 1.0], dtype="float32"))
-    )
-
-
-def test_block_runtime_error_type_caster_eigen_ref_made_a_copy():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.block(ref, 0, 0, 0, 0)
-    assert str(excinfo.value) == "type_caster for Eigen::Ref made a copy."
-
-
-def test_nonunit_stride_to_python():
-    assert np.all(m.diagonal(ref) == ref.diagonal())
-    assert np.all(m.diagonal_1(ref) == ref.diagonal(1))
-    for i in range(-5, 7):
-        assert np.all(m.diagonal_n(ref, i) == ref.diagonal(i)), f"m.diagonal_n({i})"
-
-    # Must be order="F", otherwise the type_caster will make a copy and
-    # m.block() will return a dangling reference (heap-use-after-free).
-    rof = np.asarray(ref, order="F")
-    assert np.all(m.block(rof, 2, 1, 3, 3) == rof[2:5, 1:4])
-    assert np.all(m.block(rof, 1, 4, 4, 2) == rof[1:, 4:])
-    assert np.all(m.block(rof, 1, 4, 3, 2) == rof[1:4, 4:])
-
-
-def test_eigen_ref_to_python():
-    chols = [m.cholesky1, m.cholesky2, m.cholesky3, m.cholesky4]
-    for i, chol in enumerate(chols, start=1):
-        mymat = chol(np.array([[1.0, 2, 4], [2, 13, 23], [4, 23, 77]]))
-        assert np.all(
-            mymat == np.array([[1, 0, 0], [2, 3, 0], [4, 5, 6]])
-        ), f"cholesky{i}"
-
-
-def assign_both(a1, a2, r, c, v):
-    a1[r, c] = v
-    a2[r, c] = v
-
-
-def array_copy_but_one(a, r, c, v):
-    z = np.array(a, copy=True)
-    z[r, c] = v
-    return z
-
-
-def test_eigen_return_references():
-    """Tests various ways of returning references and non-referencing copies"""
-
-    primary = np.ones((10, 10))
-    a = m.ReturnTester()
-    a_get1 = a.get()
-    assert not a_get1.flags.owndata
-    assert a_get1.flags.writeable
-    assign_both(a_get1, primary, 3, 3, 5)
-    a_get2 = a.get_ptr()
-    assert not a_get2.flags.owndata
-    assert a_get2.flags.writeable
-    assign_both(a_get1, primary, 2, 3, 6)
-
-    a_view1 = a.view()
-    assert not a_view1.flags.owndata
-    assert not a_view1.flags.writeable
-    with pytest.raises(ValueError):
-        a_view1[2, 3] = 4
-    a_view2 = a.view_ptr()
-    assert not a_view2.flags.owndata
-    assert not a_view2.flags.writeable
-    with pytest.raises(ValueError):
-        a_view2[2, 3] = 4
-
-    a_copy1 = a.copy_get()
-    assert a_copy1.flags.owndata
-    assert a_copy1.flags.writeable
-    np.testing.assert_array_equal(a_copy1, primary)
-    a_copy1[7, 7] = -44  # Shouldn't affect anything else
-    c1want = array_copy_but_one(primary, 7, 7, -44)
-    a_copy2 = a.copy_view()
-    assert a_copy2.flags.owndata
-    assert a_copy2.flags.writeable
-    np.testing.assert_array_equal(a_copy2, primary)
-    a_copy2[4, 4] = -22  # Shouldn't affect anything else
-    c2want = array_copy_but_one(primary, 4, 4, -22)
-
-    a_ref1 = a.ref()
-    assert not a_ref1.flags.owndata
-    assert a_ref1.flags.writeable
-    assign_both(a_ref1, primary, 1, 1, 15)
-    a_ref2 = a.ref_const()
-    assert not a_ref2.flags.owndata
-    assert not a_ref2.flags.writeable
-    with pytest.raises(ValueError):
-        a_ref2[5, 5] = 33
-    a_ref3 = a.ref_safe()
-    assert not a_ref3.flags.owndata
-    assert a_ref3.flags.writeable
-    assign_both(a_ref3, primary, 0, 7, 99)
-    a_ref4 = a.ref_const_safe()
-    assert not a_ref4.flags.owndata
-    assert not a_ref4.flags.writeable
-    with pytest.raises(ValueError):
-        a_ref4[7, 0] = 987654321
-
-    a_copy3 = a.copy_ref()
-    assert a_copy3.flags.owndata
-    assert a_copy3.flags.writeable
-    np.testing.assert_array_equal(a_copy3, primary)
-    a_copy3[8, 1] = 11
-    c3want = array_copy_but_one(primary, 8, 1, 11)
-    a_copy4 = a.copy_ref_const()
-    assert a_copy4.flags.owndata
-    assert a_copy4.flags.writeable
-    np.testing.assert_array_equal(a_copy4, primary)
-    a_copy4[8, 4] = 88
-    c4want = array_copy_but_one(primary, 8, 4, 88)
-
-    a_block1 = a.block(3, 3, 2, 2)
-    assert not a_block1.flags.owndata
-    assert a_block1.flags.writeable
-    a_block1[0, 0] = 55
-    primary[3, 3] = 55
-    a_block2 = a.block_safe(2, 2, 3, 2)
-    assert not a_block2.flags.owndata
-    assert a_block2.flags.writeable
-    a_block2[2, 1] = -123
-    primary[4, 3] = -123
-    a_block3 = a.block_const(6, 7, 4, 3)
-    assert not a_block3.flags.owndata
-    assert not a_block3.flags.writeable
-    with pytest.raises(ValueError):
-        a_block3[2, 2] = -44444
-
-    a_copy5 = a.copy_block(2, 2, 2, 3)
-    assert a_copy5.flags.owndata
-    assert a_copy5.flags.writeable
-    np.testing.assert_array_equal(a_copy5, primary[2:4, 2:5])
-    a_copy5[1, 1] = 777
-    c5want = array_copy_but_one(primary[2:4, 2:5], 1, 1, 777)
-
-    a_corn1 = a.corners()
-    assert not a_corn1.flags.owndata
-    assert a_corn1.flags.writeable
-    a_corn1 *= 50
-    a_corn1[1, 1] = 999
-    primary[0, 0] = 50
-    primary[0, 9] = 50
-    primary[9, 0] = 50
-    primary[9, 9] = 999
-    a_corn2 = a.corners_const()
-    assert not a_corn2.flags.owndata
-    assert not a_corn2.flags.writeable
-    with pytest.raises(ValueError):
-        a_corn2[1, 0] = 51
-
-    # All of the changes made all the way along should be visible everywhere
-    # now (except for the copies, of course)
-    np.testing.assert_array_equal(a_get1, primary)
-    np.testing.assert_array_equal(a_get2, primary)
-    np.testing.assert_array_equal(a_view1, primary)
-    np.testing.assert_array_equal(a_view2, primary)
-    np.testing.assert_array_equal(a_ref1, primary)
-    np.testing.assert_array_equal(a_ref2, primary)
-    np.testing.assert_array_equal(a_ref3, primary)
-    np.testing.assert_array_equal(a_ref4, primary)
-    np.testing.assert_array_equal(a_block1, primary[3:5, 3:5])
-    np.testing.assert_array_equal(a_block2, primary[2:5, 2:4])
-    np.testing.assert_array_equal(a_block3, primary[6:10, 7:10])
-    np.testing.assert_array_equal(
-        a_corn1, primary[0 :: primary.shape[0] - 1, 0 :: primary.shape[1] - 1]
-    )
-    np.testing.assert_array_equal(
-        a_corn2, primary[0 :: primary.shape[0] - 1, 0 :: primary.shape[1] - 1]
-    )
-
-    np.testing.assert_array_equal(a_copy1, c1want)
-    np.testing.assert_array_equal(a_copy2, c2want)
-    np.testing.assert_array_equal(a_copy3, c3want)
-    np.testing.assert_array_equal(a_copy4, c4want)
-    np.testing.assert_array_equal(a_copy5, c5want)
-
-
-def assert_keeps_alive(cl, method, *args):
-    cstats = ConstructorStats.get(cl)
-    start_with = cstats.alive()
-    a = cl()
-    assert cstats.alive() == start_with + 1
-    z = method(a, *args)
-    assert cstats.alive() == start_with + 1
-    del a
-    # Here's the keep alive in action:
-    assert cstats.alive() == start_with + 1
-    del z
-    # Keep alive should have expired:
-    assert cstats.alive() == start_with
-
-
-def test_eigen_keepalive():
-    a = m.ReturnTester()
-    cstats = ConstructorStats.get(m.ReturnTester)
-    assert cstats.alive() == 1
-    unsafe = [a.ref(), a.ref_const(), a.block(1, 2, 3, 4)]
-    copies = [
-        a.copy_get(),
-        a.copy_view(),
-        a.copy_ref(),
-        a.copy_ref_const(),
-        a.copy_block(4, 3, 2, 1),
-    ]
-    del a
-    assert cstats.alive() == 0
-    del unsafe
-    del copies
-
-    for meth in [
-        m.ReturnTester.get,
-        m.ReturnTester.get_ptr,
-        m.ReturnTester.view,
-        m.ReturnTester.view_ptr,
-        m.ReturnTester.ref_safe,
-        m.ReturnTester.ref_const_safe,
-        m.ReturnTester.corners,
-        m.ReturnTester.corners_const,
-    ]:
-        assert_keeps_alive(m.ReturnTester, meth)
-
-    for meth in [m.ReturnTester.block_safe, m.ReturnTester.block_const]:
-        assert_keeps_alive(m.ReturnTester, meth, 4, 3, 2, 1)
-
-
-def test_eigen_ref_mutators():
-    """Tests Eigen's ability to mutate numpy values"""
-
-    orig = np.array([[1.0, 2, 3], [4, 5, 6], [7, 8, 9]])
-    zr = np.array(orig)
-    zc = np.array(orig, order="F")
-    m.add_rm(zr, 1, 0, 100)
-    assert np.all(zr == np.array([[1.0, 2, 3], [104, 5, 6], [7, 8, 9]]))
-    m.add_cm(zc, 1, 0, 200)
-    assert np.all(zc == np.array([[1.0, 2, 3], [204, 5, 6], [7, 8, 9]]))
-
-    m.add_any(zr, 1, 0, 20)
-    assert np.all(zr == np.array([[1.0, 2, 3], [124, 5, 6], [7, 8, 9]]))
-    m.add_any(zc, 1, 0, 10)
-    assert np.all(zc == np.array([[1.0, 2, 3], [214, 5, 6], [7, 8, 9]]))
-
-    # Can't reference a col-major array with a row-major Ref, and vice versa:
-    with pytest.raises(TypeError):
-        m.add_rm(zc, 1, 0, 1)
-    with pytest.raises(TypeError):
-        m.add_cm(zr, 1, 0, 1)
-
-    # Overloads:
-    m.add1(zr, 1, 0, -100)
-    m.add2(zr, 1, 0, -20)
-    assert np.all(zr == orig)
-    m.add1(zc, 1, 0, -200)
-    m.add2(zc, 1, 0, -10)
-    assert np.all(zc == orig)
-
-    # a non-contiguous slice (this won't work on either the row- or
-    # column-contiguous refs, but should work for the any)
-    cornersr = zr[0::2, 0::2]
-    cornersc = zc[0::2, 0::2]
-
-    assert np.all(cornersr == np.array([[1.0, 3], [7, 9]]))
-    assert np.all(cornersc == np.array([[1.0, 3], [7, 9]]))
-
-    with pytest.raises(TypeError):
-        m.add_rm(cornersr, 0, 1, 25)
-    with pytest.raises(TypeError):
-        m.add_cm(cornersr, 0, 1, 25)
-    with pytest.raises(TypeError):
-        m.add_rm(cornersc, 0, 1, 25)
-    with pytest.raises(TypeError):
-        m.add_cm(cornersc, 0, 1, 25)
-    m.add_any(cornersr, 0, 1, 25)
-    m.add_any(cornersc, 0, 1, 44)
-    assert np.all(zr == np.array([[1.0, 2, 28], [4, 5, 6], [7, 8, 9]]))
-    assert np.all(zc == np.array([[1.0, 2, 47], [4, 5, 6], [7, 8, 9]]))
-
-    # You shouldn't be allowed to pass a non-writeable array to a mutating Eigen method:
-    zro = zr[0:4, 0:4]
-    zro.flags.writeable = False
-    with pytest.raises(TypeError):
-        m.add_rm(zro, 0, 0, 0)
-    with pytest.raises(TypeError):
-        m.add_any(zro, 0, 0, 0)
-    with pytest.raises(TypeError):
-        m.add1(zro, 0, 0, 0)
-    with pytest.raises(TypeError):
-        m.add2(zro, 0, 0, 0)
-
-    # integer array shouldn't be passable to a double-matrix-accepting mutating func:
-    zi = np.array([[1, 2], [3, 4]])
-    with pytest.raises(TypeError):
-        m.add_rm(zi)
-
-
-def test_numpy_ref_mutators():
-    """Tests numpy mutating Eigen matrices (for returned Eigen::Ref<...>s)"""
-
-    m.reset_refs()  # In case another test already changed it
-
-    zc = m.get_cm_ref()
-    zcro = m.get_cm_const_ref()
-    zr = m.get_rm_ref()
-    zrro = m.get_rm_const_ref()
-
-    assert [zc[1, 2], zcro[1, 2], zr[1, 2], zrro[1, 2]] == [23] * 4
-
-    assert not zc.flags.owndata
-    assert zc.flags.writeable
-    assert not zr.flags.owndata
-    assert zr.flags.writeable
-    assert not zcro.flags.owndata
-    assert not zcro.flags.writeable
-    assert not zrro.flags.owndata
-    assert not zrro.flags.writeable
-
-    zc[1, 2] = 99
-    expect = np.array([[11.0, 12, 13], [21, 22, 99], [31, 32, 33]])
-    # We should have just changed zc, of course, but also zcro and the original eigen matrix
-    assert np.all(zc == expect)
-    assert np.all(zcro == expect)
-    assert np.all(m.get_cm_ref() == expect)
-
-    zr[1, 2] = 99
-    assert np.all(zr == expect)
-    assert np.all(zrro == expect)
-    assert np.all(m.get_rm_ref() == expect)
-
-    # Make sure the readonly ones are numpy-readonly:
-    with pytest.raises(ValueError):
-        zcro[1, 2] = 6
-    with pytest.raises(ValueError):
-        zrro[1, 2] = 6
-
-    # We should be able to explicitly copy like this (and since we're copying,
-    # the const should drop away)
-    y1 = np.array(m.get_cm_const_ref())
-
-    assert y1.flags.owndata
-    assert y1.flags.writeable
-    # We should get copies of the eigen data, which was modified above:
-    assert y1[1, 2] == 99
-    y1[1, 2] += 12
-    assert y1[1, 2] == 111
-    assert zc[1, 2] == 99  # Make sure we aren't referencing the original
-
-
-def test_both_ref_mutators():
-    """Tests a complex chain of nested eigen/numpy references"""
-
-    m.reset_refs()  # In case another test already changed it
-
-    z = m.get_cm_ref()  # numpy -> eigen
-    z[0, 2] -= 3
-    z2 = m.incr_matrix(z, 1)  # numpy -> eigen -> numpy -> eigen
-    z2[1, 1] += 6
-    z3 = m.incr_matrix(z, 2)  # (numpy -> eigen)^3
-    z3[2, 2] += -5
-    z4 = m.incr_matrix(z, 3)  # (numpy -> eigen)^4
-    z4[1, 1] -= 1
-    z5 = m.incr_matrix(z, 4)  # (numpy -> eigen)^5
-    z5[0, 0] = 0
-    assert np.all(z == z2)
-    assert np.all(z == z3)
-    assert np.all(z == z4)
-    assert np.all(z == z5)
-    expect = np.array([[0.0, 22, 20], [31, 37, 33], [41, 42, 38]])
-    assert np.all(z == expect)
-
-    y = np.array(range(100), dtype="float64").reshape(10, 10)
-    y2 = m.incr_matrix_any(y, 10)  # np -> eigen -> np
-    y3 = m.incr_matrix_any(
-        y2[0::2, 0::2], -33
-    )  # np -> eigen -> np slice -> np -> eigen -> np
-    y4 = m.even_rows(y3)  # numpy -> eigen slice -> (... y3)
-    y5 = m.even_cols(y4)  # numpy -> eigen slice -> (... y4)
-    y6 = m.incr_matrix_any(y5, 1000)  # numpy -> eigen -> (... y5)
-
-    # Apply same mutations using just numpy:
-    yexpect = np.array(range(100), dtype="float64").reshape(10, 10)
-    yexpect += 10
-    yexpect[0::2, 0::2] -= 33
-    yexpect[0::4, 0::4] += 1000
-    assert np.all(y6 == yexpect[0::4, 0::4])
-    assert np.all(y5 == yexpect[0::4, 0::4])
-    assert np.all(y4 == yexpect[0::4, 0::2])
-    assert np.all(y3 == yexpect[0::2, 0::2])
-    assert np.all(y2 == yexpect)
-    assert np.all(y == yexpect)
-
-
-def test_nocopy_wrapper():
-    # get_elem requires a column-contiguous matrix reference, but should be
-    # callable with other types of matrix (via copying):
-    int_matrix_colmajor = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], order="F")
-    dbl_matrix_colmajor = np.array(
-        int_matrix_colmajor, dtype="double", order="F", copy=True
-    )
-    int_matrix_rowmajor = np.array(int_matrix_colmajor, order="C", copy=True)
-    dbl_matrix_rowmajor = np.array(
-        int_matrix_rowmajor, dtype="double", order="C", copy=True
-    )
-
-    # All should be callable via get_elem:
-    assert m.get_elem(int_matrix_colmajor) == 8
-    assert m.get_elem(dbl_matrix_colmajor) == 8
-    assert m.get_elem(int_matrix_rowmajor) == 8
-    assert m.get_elem(dbl_matrix_rowmajor) == 8
-
-    # All but the second should fail with m.get_elem_nocopy:
-    with pytest.raises(TypeError) as excinfo:
-        m.get_elem_nocopy(int_matrix_colmajor)
-    assert "get_elem_nocopy(): incompatible function arguments." in str(excinfo.value)
-    assert ", flags.f_contiguous" in str(excinfo.value)
-    assert m.get_elem_nocopy(dbl_matrix_colmajor) == 8
-    with pytest.raises(TypeError) as excinfo:
-        m.get_elem_nocopy(int_matrix_rowmajor)
-    assert "get_elem_nocopy(): incompatible function arguments." in str(excinfo.value)
-    assert ", flags.f_contiguous" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.get_elem_nocopy(dbl_matrix_rowmajor)
-    assert "get_elem_nocopy(): incompatible function arguments." in str(excinfo.value)
-    assert ", flags.f_contiguous" in str(excinfo.value)
-
-    # For the row-major test, we take a long matrix in row-major, so only the third is allowed:
-    with pytest.raises(TypeError) as excinfo:
-        m.get_elem_rm_nocopy(int_matrix_colmajor)
-    assert "get_elem_rm_nocopy(): incompatible function arguments." in str(
-        excinfo.value
-    )
-    assert ", flags.c_contiguous" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.get_elem_rm_nocopy(dbl_matrix_colmajor)
-    assert "get_elem_rm_nocopy(): incompatible function arguments." in str(
-        excinfo.value
-    )
-    assert ", flags.c_contiguous" in str(excinfo.value)
-    assert m.get_elem_rm_nocopy(int_matrix_rowmajor) == 8
-    with pytest.raises(TypeError) as excinfo:
-        m.get_elem_rm_nocopy(dbl_matrix_rowmajor)
-    assert "get_elem_rm_nocopy(): incompatible function arguments." in str(
-        excinfo.value
-    )
-    assert ", flags.c_contiguous" in str(excinfo.value)
-
-
-def test_eigen_ref_life_support():
-    """Ensure the lifetime of temporary arrays created by the `Ref` caster
-
-    The `Ref` caster sometimes creates a copy which needs to stay alive. This needs to
-    happen both for directs casts (just the array) or indirectly (e.g. list of arrays).
-    """
-
-    a = np.full(shape=10, fill_value=8, dtype=np.int8)
-    assert m.get_elem_direct(a) == 8
-
-    list_of_a = [a]
-    assert m.get_elem_indirect(list_of_a) == 8
-
-
-def test_special_matrix_objects():
-    assert np.all(m.incr_diag(7) == np.diag([1.0, 2, 3, 4, 5, 6, 7]))
-
-    asymm = np.array([[1.0, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
-    symm_lower = np.array(asymm)
-    symm_upper = np.array(asymm)
-    for i in range(4):
-        for j in range(i + 1, 4):
-            symm_lower[i, j] = symm_lower[j, i]
-            symm_upper[j, i] = symm_upper[i, j]
-
-    assert np.all(m.symmetric_lower(asymm) == symm_lower)
-    assert np.all(m.symmetric_upper(asymm) == symm_upper)
-
-
-def test_dense_signature(doc):
-    assert (
-        doc(m.double_col)
-        == """
-        double_col(arg0: numpy.ndarray[numpy.float32[m, 1]]) -> numpy.ndarray[numpy.float32[m, 1]]
-    """
-    )
-    assert (
-        doc(m.double_row)
-        == """
-        double_row(arg0: numpy.ndarray[numpy.float32[1, n]]) -> numpy.ndarray[numpy.float32[1, n]]
-    """
-    )
-    assert doc(m.double_complex) == (
-        """
-        double_complex(arg0: numpy.ndarray[numpy.complex64[m, 1]])"""
-        """ -> numpy.ndarray[numpy.complex64[m, 1]]
-    """
-    )
-    assert doc(m.double_mat_rm) == (
-        """
-        double_mat_rm(arg0: numpy.ndarray[numpy.float32[m, n]])"""
-        """ -> numpy.ndarray[numpy.float32[m, n]]
-    """
-    )
-
-
-def test_defaults(doc):
-    assert "\n" not in str(doc(m.defaults_mat))
-    assert "\n" not in str(doc(m.defaults_vec))
-
-
-def test_named_arguments():
-    a = np.array([[1.0, 2], [3, 4], [5, 6]])
-    b = np.ones((2, 1))
-
-    assert np.all(m.matrix_multiply(a, b) == np.array([[3.0], [7], [11]]))
-    assert np.all(m.matrix_multiply(A=a, B=b) == np.array([[3.0], [7], [11]]))
-    assert np.all(m.matrix_multiply(B=b, A=a) == np.array([[3.0], [7], [11]]))
-
-    with pytest.raises(ValueError) as excinfo:
-        m.matrix_multiply(b, a)
-    assert str(excinfo.value) == "Nonconformable matrices!"
-
-    with pytest.raises(ValueError) as excinfo:
-        m.matrix_multiply(A=b, B=a)
-    assert str(excinfo.value) == "Nonconformable matrices!"
-
-    with pytest.raises(ValueError) as excinfo:
-        m.matrix_multiply(B=a, A=b)
-    assert str(excinfo.value) == "Nonconformable matrices!"
-
-
-def test_sparse():
-    pytest.importorskip("scipy")
-    assert_sparse_equal_ref(m.sparse_r())
-    assert_sparse_equal_ref(m.sparse_c())
-    assert_sparse_equal_ref(m.sparse_copy_r(m.sparse_r()))
-    assert_sparse_equal_ref(m.sparse_copy_c(m.sparse_c()))
-    assert_sparse_equal_ref(m.sparse_copy_r(m.sparse_c()))
-    assert_sparse_equal_ref(m.sparse_copy_c(m.sparse_r()))
-
-
-def test_sparse_signature(doc):
-    pytest.importorskip("scipy")
-    assert (
-        doc(m.sparse_copy_r)
-        == """
-        sparse_copy_r(arg0: scipy.sparse.csr_matrix[numpy.float32]) -> scipy.sparse.csr_matrix[numpy.float32]
-    """
-    )
-    assert (
-        doc(m.sparse_copy_c)
-        == """
-        sparse_copy_c(arg0: scipy.sparse.csc_matrix[numpy.float32]) -> scipy.sparse.csc_matrix[numpy.float32]
-    """
-    )
-
-
-def test_issue738():
-    """Ignore strides on a length-1 dimension (even if they would be incompatible length > 1)"""
-    assert np.all(m.iss738_f1(np.array([[1.0, 2, 3]])) == np.array([[1.0, 102, 203]]))
-    assert np.all(
-        m.iss738_f1(np.array([[1.0], [2], [3]])) == np.array([[1.0], [12], [23]])
-    )
-
-    assert np.all(m.iss738_f2(np.array([[1.0, 2, 3]])) == np.array([[1.0, 102, 203]]))
-    assert np.all(
-        m.iss738_f2(np.array([[1.0], [2], [3]])) == np.array([[1.0], [12], [23]])
-    )
-
-
-@pytest.mark.parametrize("func", [m.iss738_f1, m.iss738_f2])
-@pytest.mark.parametrize("sizes", [(0, 2), (2, 0)])
-def test_zero_length(func, sizes):
-    """Ignore strides on a length-0 dimension (even if they would be incompatible length > 1)"""
-    assert np.all(func(np.zeros(sizes)) == np.zeros(sizes))
-
-
-def test_issue1105():
-    """Issue 1105: 1xN or Nx1 input arrays weren't accepted for eigen
-    compile-time row vectors or column vector"""
-    assert m.iss1105_row(np.ones((1, 7)))
-    assert m.iss1105_col(np.ones((7, 1)))
-
-    # These should still fail (incompatible dimensions):
-    with pytest.raises(TypeError) as excinfo:
-        m.iss1105_row(np.ones((7, 1)))
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.iss1105_col(np.ones((1, 7)))
-    assert "incompatible function arguments" in str(excinfo.value)
-
-
-def test_custom_operator_new():
-    """Using Eigen types as member variables requires a class-specific
-    operator new with proper alignment"""
-
-    o = m.CustomOperatorNew()
-    np.testing.assert_allclose(o.a, 0.0)
-    np.testing.assert_allclose(o.b.diagonal(), 1.0)
+import pytest
+
+from pybind11_tests import ConstructorStats
+
+np = pytest.importorskip("numpy")
+m = pytest.importorskip("pybind11_tests.eigen_matrix")
+
+
+ref = np.array(
+    [
+        [0.0, 3, 0, 0, 0, 11],
+        [22, 0, 0, 0, 17, 11],
+        [7, 5, 0, 1, 0, 11],
+        [0, 0, 0, 0, 0, 11],
+        [0, 0, 14, 0, 8, 11],
+    ]
+)
+
+
+def assert_equal_ref(mat):
+    np.testing.assert_array_equal(mat, ref)
+
+
+def assert_sparse_equal_ref(sparse_mat):
+    assert_equal_ref(sparse_mat.toarray())
+
+
+def test_fixed():
+    assert_equal_ref(m.fixed_c())
+    assert_equal_ref(m.fixed_r())
+    assert_equal_ref(m.fixed_copy_r(m.fixed_r()))
+    assert_equal_ref(m.fixed_copy_c(m.fixed_c()))
+    assert_equal_ref(m.fixed_copy_r(m.fixed_c()))
+    assert_equal_ref(m.fixed_copy_c(m.fixed_r()))
+
+
+def test_dense():
+    assert_equal_ref(m.dense_r())
+    assert_equal_ref(m.dense_c())
+    assert_equal_ref(m.dense_copy_r(m.dense_r()))
+    assert_equal_ref(m.dense_copy_c(m.dense_c()))
+    assert_equal_ref(m.dense_copy_r(m.dense_c()))
+    assert_equal_ref(m.dense_copy_c(m.dense_r()))
+
+
+def test_partially_fixed():
+    ref2 = np.array([[0.0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]])
+    np.testing.assert_array_equal(m.partial_copy_four_rm_r(ref2), ref2)
+    np.testing.assert_array_equal(m.partial_copy_four_rm_c(ref2), ref2)
+    np.testing.assert_array_equal(m.partial_copy_four_rm_r(ref2[:, 1]), ref2[:, [1]])
+    np.testing.assert_array_equal(m.partial_copy_four_rm_c(ref2[0, :]), ref2[[0], :])
+    np.testing.assert_array_equal(
+        m.partial_copy_four_rm_r(ref2[:, (0, 2)]), ref2[:, (0, 2)]
+    )
+    np.testing.assert_array_equal(
+        m.partial_copy_four_rm_c(ref2[(3, 1, 2), :]), ref2[(3, 1, 2), :]
+    )
+
+    np.testing.assert_array_equal(m.partial_copy_four_cm_r(ref2), ref2)
+    np.testing.assert_array_equal(m.partial_copy_four_cm_c(ref2), ref2)
+    np.testing.assert_array_equal(m.partial_copy_four_cm_r(ref2[:, 1]), ref2[:, [1]])
+    np.testing.assert_array_equal(m.partial_copy_four_cm_c(ref2[0, :]), ref2[[0], :])
+    np.testing.assert_array_equal(
+        m.partial_copy_four_cm_r(ref2[:, (0, 2)]), ref2[:, (0, 2)]
+    )
+    np.testing.assert_array_equal(
+        m.partial_copy_four_cm_c(ref2[(3, 1, 2), :]), ref2[(3, 1, 2), :]
+    )
+
+    # TypeError should be raise for a shape mismatch
+    functions = [
+        m.partial_copy_four_rm_r,
+        m.partial_copy_four_rm_c,
+        m.partial_copy_four_cm_r,
+        m.partial_copy_four_cm_c,
+    ]
+    matrix_with_wrong_shape = [[1, 2], [3, 4]]
+    for f in functions:
+        with pytest.raises(TypeError) as excinfo:
+            f(matrix_with_wrong_shape)
+        assert "incompatible function arguments" in str(excinfo.value)
+
+
+def test_mutator_descriptors():
+    zr = np.arange(30, dtype="float32").reshape(5, 6)  # row-major
+    zc = zr.reshape(6, 5).transpose()  # column-major
+
+    m.fixed_mutator_r(zr)
+    m.fixed_mutator_c(zc)
+    m.fixed_mutator_a(zr)
+    m.fixed_mutator_a(zc)
+    with pytest.raises(TypeError) as excinfo:
+        m.fixed_mutator_r(zc)
+    assert (
+        "(arg0: numpy.ndarray[numpy.float32[5, 6],"
+        " flags.writeable, flags.c_contiguous]) -> None" in str(excinfo.value)
+    )
+    with pytest.raises(TypeError) as excinfo:
+        m.fixed_mutator_c(zr)
+    assert (
+        "(arg0: numpy.ndarray[numpy.float32[5, 6],"
+        " flags.writeable, flags.f_contiguous]) -> None" in str(excinfo.value)
+    )
+    with pytest.raises(TypeError) as excinfo:
+        m.fixed_mutator_a(np.array([[1, 2], [3, 4]], dtype="float32"))
+    assert "(arg0: numpy.ndarray[numpy.float32[5, 6], flags.writeable]) -> None" in str(
+        excinfo.value
+    )
+    zr.flags.writeable = False
+    with pytest.raises(TypeError):
+        m.fixed_mutator_r(zr)
+    with pytest.raises(TypeError):
+        m.fixed_mutator_a(zr)
+
+
+def test_cpp_casting():
+    assert m.cpp_copy(m.fixed_r()) == 22.0
+    assert m.cpp_copy(m.fixed_c()) == 22.0
+    z = np.array([[5.0, 6], [7, 8]])
+    assert m.cpp_copy(z) == 7.0
+    assert m.cpp_copy(m.get_cm_ref()) == 21.0
+    assert m.cpp_copy(m.get_rm_ref()) == 21.0
+    assert m.cpp_ref_c(m.get_cm_ref()) == 21.0
+    assert m.cpp_ref_r(m.get_rm_ref()) == 21.0
+    with pytest.raises(RuntimeError) as excinfo:
+        # Can't reference m.fixed_c: it contains floats, m.cpp_ref_any wants doubles
+        m.cpp_ref_any(m.fixed_c())
+    assert "Unable to cast Python instance" in str(excinfo.value)
+    with pytest.raises(RuntimeError) as excinfo:
+        # Can't reference m.fixed_r: it contains floats, m.cpp_ref_any wants doubles
+        m.cpp_ref_any(m.fixed_r())
+    assert "Unable to cast Python instance" in str(excinfo.value)
+    assert m.cpp_ref_any(m.ReturnTester.create()) == 1.0
+
+    assert m.cpp_ref_any(m.get_cm_ref()) == 21.0
+    assert m.cpp_ref_any(m.get_cm_ref()) == 21.0
+
+
+def test_pass_readonly_array():
+    z = np.full((5, 6), 42.0)
+    z.flags.writeable = False
+    np.testing.assert_array_equal(z, m.fixed_copy_r(z))
+    np.testing.assert_array_equal(m.fixed_r_const(), m.fixed_r())
+    assert not m.fixed_r_const().flags.writeable
+    np.testing.assert_array_equal(m.fixed_copy_r(m.fixed_r_const()), m.fixed_r_const())
+
+
+def test_nonunit_stride_from_python():
+    counting_mat = np.arange(9.0, dtype=np.float32).reshape((3, 3))
+    second_row = counting_mat[1, :]
+    second_col = counting_mat[:, 1]
+    np.testing.assert_array_equal(m.double_row(second_row), 2.0 * second_row)
+    np.testing.assert_array_equal(m.double_col(second_row), 2.0 * second_row)
+    np.testing.assert_array_equal(m.double_complex(second_row), 2.0 * second_row)
+    np.testing.assert_array_equal(m.double_row(second_col), 2.0 * second_col)
+    np.testing.assert_array_equal(m.double_col(second_col), 2.0 * second_col)
+    np.testing.assert_array_equal(m.double_complex(second_col), 2.0 * second_col)
+
+    counting_3d = np.arange(27.0, dtype=np.float32).reshape((3, 3, 3))
+    slices = [counting_3d[0, :, :], counting_3d[:, 0, :], counting_3d[:, :, 0]]
+    for ref_mat in slices:
+        np.testing.assert_array_equal(m.double_mat_cm(ref_mat), 2.0 * ref_mat)
+        np.testing.assert_array_equal(m.double_mat_rm(ref_mat), 2.0 * ref_mat)
+
+    # Mutator:
+    m.double_threer(second_row)
+    m.double_threec(second_col)
+    np.testing.assert_array_equal(counting_mat, [[0.0, 2, 2], [6, 16, 10], [6, 14, 8]])
+
+
+def test_negative_stride_from_python(msg):
+    """Eigen doesn't support (as of yet) negative strides. When a function takes an Eigen matrix by
+    copy or const reference, we can pass a numpy array that has negative strides.  Otherwise, an
+    exception will be thrown as Eigen will not be able to map the numpy array."""
+
+    counting_mat = np.arange(9.0, dtype=np.float32).reshape((3, 3))
+    counting_mat = counting_mat[::-1, ::-1]
+    second_row = counting_mat[1, :]
+    second_col = counting_mat[:, 1]
+    np.testing.assert_array_equal(m.double_row(second_row), 2.0 * second_row)
+    np.testing.assert_array_equal(m.double_col(second_row), 2.0 * second_row)
+    np.testing.assert_array_equal(m.double_complex(second_row), 2.0 * second_row)
+    np.testing.assert_array_equal(m.double_row(second_col), 2.0 * second_col)
+    np.testing.assert_array_equal(m.double_col(second_col), 2.0 * second_col)
+    np.testing.assert_array_equal(m.double_complex(second_col), 2.0 * second_col)
+
+    counting_3d = np.arange(27.0, dtype=np.float32).reshape((3, 3, 3))
+    counting_3d = counting_3d[::-1, ::-1, ::-1]
+    slices = [counting_3d[0, :, :], counting_3d[:, 0, :], counting_3d[:, :, 0]]
+    for ref_mat in slices:
+        np.testing.assert_array_equal(m.double_mat_cm(ref_mat), 2.0 * ref_mat)
+        np.testing.assert_array_equal(m.double_mat_rm(ref_mat), 2.0 * ref_mat)
+
+    # Mutator:
+    with pytest.raises(TypeError) as excinfo:
+        m.double_threer(second_row)
+    assert (
+        msg(excinfo.value)
+        == """
+        double_threer(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: numpy.ndarray[numpy.float32[1, 3], flags.writeable]) -> None
+
+        Invoked with: """
+        + repr(np.array([5.0, 4.0, 3.0], dtype="float32"))
+    )
+
+    with pytest.raises(TypeError) as excinfo:
+        m.double_threec(second_col)
+    assert (
+        msg(excinfo.value)
+        == """
+        double_threec(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: numpy.ndarray[numpy.float32[3, 1], flags.writeable]) -> None
+
+        Invoked with: """
+        + repr(np.array([7.0, 4.0, 1.0], dtype="float32"))
+    )
+
+
+def test_block_runtime_error_type_caster_eigen_ref_made_a_copy():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.block(ref, 0, 0, 0, 0)
+    assert str(excinfo.value) == "type_caster for Eigen::Ref made a copy."
+
+
+def test_nonunit_stride_to_python():
+    assert np.all(m.diagonal(ref) == ref.diagonal())
+    assert np.all(m.diagonal_1(ref) == ref.diagonal(1))
+    for i in range(-5, 7):
+        assert np.all(m.diagonal_n(ref, i) == ref.diagonal(i)), f"m.diagonal_n({i})"
+
+    # Must be order="F", otherwise the type_caster will make a copy and
+    # m.block() will return a dangling reference (heap-use-after-free).
+    rof = np.asarray(ref, order="F")
+    assert np.all(m.block(rof, 2, 1, 3, 3) == rof[2:5, 1:4])
+    assert np.all(m.block(rof, 1, 4, 4, 2) == rof[1:, 4:])
+    assert np.all(m.block(rof, 1, 4, 3, 2) == rof[1:4, 4:])
+
+
+def test_eigen_ref_to_python():
+    chols = [m.cholesky1, m.cholesky2, m.cholesky3, m.cholesky4]
+    for i, chol in enumerate(chols, start=1):
+        mymat = chol(np.array([[1.0, 2, 4], [2, 13, 23], [4, 23, 77]]))
+        assert np.all(
+            mymat == np.array([[1, 0, 0], [2, 3, 0], [4, 5, 6]])
+        ), f"cholesky{i}"
+
+
+def assign_both(a1, a2, r, c, v):
+    a1[r, c] = v
+    a2[r, c] = v
+
+
+def array_copy_but_one(a, r, c, v):
+    z = np.array(a, copy=True)
+    z[r, c] = v
+    return z
+
+
+def test_eigen_return_references():
+    """Tests various ways of returning references and non-referencing copies"""
+
+    primary = np.ones((10, 10))
+    a = m.ReturnTester()
+    a_get1 = a.get()
+    assert not a_get1.flags.owndata
+    assert a_get1.flags.writeable
+    assign_both(a_get1, primary, 3, 3, 5)
+    a_get2 = a.get_ptr()
+    assert not a_get2.flags.owndata
+    assert a_get2.flags.writeable
+    assign_both(a_get1, primary, 2, 3, 6)
+
+    a_view1 = a.view()
+    assert not a_view1.flags.owndata
+    assert not a_view1.flags.writeable
+    with pytest.raises(ValueError):
+        a_view1[2, 3] = 4
+    a_view2 = a.view_ptr()
+    assert not a_view2.flags.owndata
+    assert not a_view2.flags.writeable
+    with pytest.raises(ValueError):
+        a_view2[2, 3] = 4
+
+    a_copy1 = a.copy_get()
+    assert a_copy1.flags.owndata
+    assert a_copy1.flags.writeable
+    np.testing.assert_array_equal(a_copy1, primary)
+    a_copy1[7, 7] = -44  # Shouldn't affect anything else
+    c1want = array_copy_but_one(primary, 7, 7, -44)
+    a_copy2 = a.copy_view()
+    assert a_copy2.flags.owndata
+    assert a_copy2.flags.writeable
+    np.testing.assert_array_equal(a_copy2, primary)
+    a_copy2[4, 4] = -22  # Shouldn't affect anything else
+    c2want = array_copy_but_one(primary, 4, 4, -22)
+
+    a_ref1 = a.ref()
+    assert not a_ref1.flags.owndata
+    assert a_ref1.flags.writeable
+    assign_both(a_ref1, primary, 1, 1, 15)
+    a_ref2 = a.ref_const()
+    assert not a_ref2.flags.owndata
+    assert not a_ref2.flags.writeable
+    with pytest.raises(ValueError):
+        a_ref2[5, 5] = 33
+    a_ref3 = a.ref_safe()
+    assert not a_ref3.flags.owndata
+    assert a_ref3.flags.writeable
+    assign_both(a_ref3, primary, 0, 7, 99)
+    a_ref4 = a.ref_const_safe()
+    assert not a_ref4.flags.owndata
+    assert not a_ref4.flags.writeable
+    with pytest.raises(ValueError):
+        a_ref4[7, 0] = 987654321
+
+    a_copy3 = a.copy_ref()
+    assert a_copy3.flags.owndata
+    assert a_copy3.flags.writeable
+    np.testing.assert_array_equal(a_copy3, primary)
+    a_copy3[8, 1] = 11
+    c3want = array_copy_but_one(primary, 8, 1, 11)
+    a_copy4 = a.copy_ref_const()
+    assert a_copy4.flags.owndata
+    assert a_copy4.flags.writeable
+    np.testing.assert_array_equal(a_copy4, primary)
+    a_copy4[8, 4] = 88
+    c4want = array_copy_but_one(primary, 8, 4, 88)
+
+    a_block1 = a.block(3, 3, 2, 2)
+    assert not a_block1.flags.owndata
+    assert a_block1.flags.writeable
+    a_block1[0, 0] = 55
+    primary[3, 3] = 55
+    a_block2 = a.block_safe(2, 2, 3, 2)
+    assert not a_block2.flags.owndata
+    assert a_block2.flags.writeable
+    a_block2[2, 1] = -123
+    primary[4, 3] = -123
+    a_block3 = a.block_const(6, 7, 4, 3)
+    assert not a_block3.flags.owndata
+    assert not a_block3.flags.writeable
+    with pytest.raises(ValueError):
+        a_block3[2, 2] = -44444
+
+    a_copy5 = a.copy_block(2, 2, 2, 3)
+    assert a_copy5.flags.owndata
+    assert a_copy5.flags.writeable
+    np.testing.assert_array_equal(a_copy5, primary[2:4, 2:5])
+    a_copy5[1, 1] = 777
+    c5want = array_copy_but_one(primary[2:4, 2:5], 1, 1, 777)
+
+    a_corn1 = a.corners()
+    assert not a_corn1.flags.owndata
+    assert a_corn1.flags.writeable
+    a_corn1 *= 50
+    a_corn1[1, 1] = 999
+    primary[0, 0] = 50
+    primary[0, 9] = 50
+    primary[9, 0] = 50
+    primary[9, 9] = 999
+    a_corn2 = a.corners_const()
+    assert not a_corn2.flags.owndata
+    assert not a_corn2.flags.writeable
+    with pytest.raises(ValueError):
+        a_corn2[1, 0] = 51
+
+    # All of the changes made all the way along should be visible everywhere
+    # now (except for the copies, of course)
+    np.testing.assert_array_equal(a_get1, primary)
+    np.testing.assert_array_equal(a_get2, primary)
+    np.testing.assert_array_equal(a_view1, primary)
+    np.testing.assert_array_equal(a_view2, primary)
+    np.testing.assert_array_equal(a_ref1, primary)
+    np.testing.assert_array_equal(a_ref2, primary)
+    np.testing.assert_array_equal(a_ref3, primary)
+    np.testing.assert_array_equal(a_ref4, primary)
+    np.testing.assert_array_equal(a_block1, primary[3:5, 3:5])
+    np.testing.assert_array_equal(a_block2, primary[2:5, 2:4])
+    np.testing.assert_array_equal(a_block3, primary[6:10, 7:10])
+    np.testing.assert_array_equal(
+        a_corn1, primary[0 :: primary.shape[0] - 1, 0 :: primary.shape[1] - 1]
+    )
+    np.testing.assert_array_equal(
+        a_corn2, primary[0 :: primary.shape[0] - 1, 0 :: primary.shape[1] - 1]
+    )
+
+    np.testing.assert_array_equal(a_copy1, c1want)
+    np.testing.assert_array_equal(a_copy2, c2want)
+    np.testing.assert_array_equal(a_copy3, c3want)
+    np.testing.assert_array_equal(a_copy4, c4want)
+    np.testing.assert_array_equal(a_copy5, c5want)
+
+
+def assert_keeps_alive(cl, method, *args):
+    cstats = ConstructorStats.get(cl)
+    start_with = cstats.alive()
+    a = cl()
+    assert cstats.alive() == start_with + 1
+    z = method(a, *args)
+    assert cstats.alive() == start_with + 1
+    del a
+    # Here's the keep alive in action:
+    assert cstats.alive() == start_with + 1
+    del z
+    # Keep alive should have expired:
+    assert cstats.alive() == start_with
+
+
+def test_eigen_keepalive():
+    a = m.ReturnTester()
+    cstats = ConstructorStats.get(m.ReturnTester)
+    assert cstats.alive() == 1
+    unsafe = [a.ref(), a.ref_const(), a.block(1, 2, 3, 4)]
+    copies = [
+        a.copy_get(),
+        a.copy_view(),
+        a.copy_ref(),
+        a.copy_ref_const(),
+        a.copy_block(4, 3, 2, 1),
+    ]
+    del a
+    assert cstats.alive() == 0
+    del unsafe
+    del copies
+
+    for meth in [
+        m.ReturnTester.get,
+        m.ReturnTester.get_ptr,
+        m.ReturnTester.view,
+        m.ReturnTester.view_ptr,
+        m.ReturnTester.ref_safe,
+        m.ReturnTester.ref_const_safe,
+        m.ReturnTester.corners,
+        m.ReturnTester.corners_const,
+    ]:
+        assert_keeps_alive(m.ReturnTester, meth)
+
+    for meth in [m.ReturnTester.block_safe, m.ReturnTester.block_const]:
+        assert_keeps_alive(m.ReturnTester, meth, 4, 3, 2, 1)
+
+
+def test_eigen_ref_mutators():
+    """Tests Eigen's ability to mutate numpy values"""
+
+    orig = np.array([[1.0, 2, 3], [4, 5, 6], [7, 8, 9]])
+    zr = np.array(orig)
+    zc = np.array(orig, order="F")
+    m.add_rm(zr, 1, 0, 100)
+    assert np.all(zr == np.array([[1.0, 2, 3], [104, 5, 6], [7, 8, 9]]))
+    m.add_cm(zc, 1, 0, 200)
+    assert np.all(zc == np.array([[1.0, 2, 3], [204, 5, 6], [7, 8, 9]]))
+
+    m.add_any(zr, 1, 0, 20)
+    assert np.all(zr == np.array([[1.0, 2, 3], [124, 5, 6], [7, 8, 9]]))
+    m.add_any(zc, 1, 0, 10)
+    assert np.all(zc == np.array([[1.0, 2, 3], [214, 5, 6], [7, 8, 9]]))
+
+    # Can't reference a col-major array with a row-major Ref, and vice versa:
+    with pytest.raises(TypeError):
+        m.add_rm(zc, 1, 0, 1)
+    with pytest.raises(TypeError):
+        m.add_cm(zr, 1, 0, 1)
+
+    # Overloads:
+    m.add1(zr, 1, 0, -100)
+    m.add2(zr, 1, 0, -20)
+    assert np.all(zr == orig)
+    m.add1(zc, 1, 0, -200)
+    m.add2(zc, 1, 0, -10)
+    assert np.all(zc == orig)
+
+    # a non-contiguous slice (this won't work on either the row- or
+    # column-contiguous refs, but should work for the any)
+    cornersr = zr[0::2, 0::2]
+    cornersc = zc[0::2, 0::2]
+
+    assert np.all(cornersr == np.array([[1.0, 3], [7, 9]]))
+    assert np.all(cornersc == np.array([[1.0, 3], [7, 9]]))
+
+    with pytest.raises(TypeError):
+        m.add_rm(cornersr, 0, 1, 25)
+    with pytest.raises(TypeError):
+        m.add_cm(cornersr, 0, 1, 25)
+    with pytest.raises(TypeError):
+        m.add_rm(cornersc, 0, 1, 25)
+    with pytest.raises(TypeError):
+        m.add_cm(cornersc, 0, 1, 25)
+    m.add_any(cornersr, 0, 1, 25)
+    m.add_any(cornersc, 0, 1, 44)
+    assert np.all(zr == np.array([[1.0, 2, 28], [4, 5, 6], [7, 8, 9]]))
+    assert np.all(zc == np.array([[1.0, 2, 47], [4, 5, 6], [7, 8, 9]]))
+
+    # You shouldn't be allowed to pass a non-writeable array to a mutating Eigen method:
+    zro = zr[0:4, 0:4]
+    zro.flags.writeable = False
+    with pytest.raises(TypeError):
+        m.add_rm(zro, 0, 0, 0)
+    with pytest.raises(TypeError):
+        m.add_any(zro, 0, 0, 0)
+    with pytest.raises(TypeError):
+        m.add1(zro, 0, 0, 0)
+    with pytest.raises(TypeError):
+        m.add2(zro, 0, 0, 0)
+
+    # integer array shouldn't be passable to a double-matrix-accepting mutating func:
+    zi = np.array([[1, 2], [3, 4]])
+    with pytest.raises(TypeError):
+        m.add_rm(zi)
+
+
+def test_numpy_ref_mutators():
+    """Tests numpy mutating Eigen matrices (for returned Eigen::Ref<...>s)"""
+
+    m.reset_refs()  # In case another test already changed it
+
+    zc = m.get_cm_ref()
+    zcro = m.get_cm_const_ref()
+    zr = m.get_rm_ref()
+    zrro = m.get_rm_const_ref()
+
+    assert [zc[1, 2], zcro[1, 2], zr[1, 2], zrro[1, 2]] == [23] * 4
+
+    assert not zc.flags.owndata
+    assert zc.flags.writeable
+    assert not zr.flags.owndata
+    assert zr.flags.writeable
+    assert not zcro.flags.owndata
+    assert not zcro.flags.writeable
+    assert not zrro.flags.owndata
+    assert not zrro.flags.writeable
+
+    zc[1, 2] = 99
+    expect = np.array([[11.0, 12, 13], [21, 22, 99], [31, 32, 33]])
+    # We should have just changed zc, of course, but also zcro and the original eigen matrix
+    assert np.all(zc == expect)
+    assert np.all(zcro == expect)
+    assert np.all(m.get_cm_ref() == expect)
+
+    zr[1, 2] = 99
+    assert np.all(zr == expect)
+    assert np.all(zrro == expect)
+    assert np.all(m.get_rm_ref() == expect)
+
+    # Make sure the readonly ones are numpy-readonly:
+    with pytest.raises(ValueError):
+        zcro[1, 2] = 6
+    with pytest.raises(ValueError):
+        zrro[1, 2] = 6
+
+    # We should be able to explicitly copy like this (and since we're copying,
+    # the const should drop away)
+    y1 = np.array(m.get_cm_const_ref())
+
+    assert y1.flags.owndata
+    assert y1.flags.writeable
+    # We should get copies of the eigen data, which was modified above:
+    assert y1[1, 2] == 99
+    y1[1, 2] += 12
+    assert y1[1, 2] == 111
+    assert zc[1, 2] == 99  # Make sure we aren't referencing the original
+
+
+def test_both_ref_mutators():
+    """Tests a complex chain of nested eigen/numpy references"""
+
+    m.reset_refs()  # In case another test already changed it
+
+    z = m.get_cm_ref()  # numpy -> eigen
+    z[0, 2] -= 3
+    z2 = m.incr_matrix(z, 1)  # numpy -> eigen -> numpy -> eigen
+    z2[1, 1] += 6
+    z3 = m.incr_matrix(z, 2)  # (numpy -> eigen)^3
+    z3[2, 2] += -5
+    z4 = m.incr_matrix(z, 3)  # (numpy -> eigen)^4
+    z4[1, 1] -= 1
+    z5 = m.incr_matrix(z, 4)  # (numpy -> eigen)^5
+    z5[0, 0] = 0
+    assert np.all(z == z2)
+    assert np.all(z == z3)
+    assert np.all(z == z4)
+    assert np.all(z == z5)
+    expect = np.array([[0.0, 22, 20], [31, 37, 33], [41, 42, 38]])
+    assert np.all(z == expect)
+
+    y = np.array(range(100), dtype="float64").reshape(10, 10)
+    y2 = m.incr_matrix_any(y, 10)  # np -> eigen -> np
+    y3 = m.incr_matrix_any(
+        y2[0::2, 0::2], -33
+    )  # np -> eigen -> np slice -> np -> eigen -> np
+    y4 = m.even_rows(y3)  # numpy -> eigen slice -> (... y3)
+    y5 = m.even_cols(y4)  # numpy -> eigen slice -> (... y4)
+    y6 = m.incr_matrix_any(y5, 1000)  # numpy -> eigen -> (... y5)
+
+    # Apply same mutations using just numpy:
+    yexpect = np.array(range(100), dtype="float64").reshape(10, 10)
+    yexpect += 10
+    yexpect[0::2, 0::2] -= 33
+    yexpect[0::4, 0::4] += 1000
+    assert np.all(y6 == yexpect[0::4, 0::4])
+    assert np.all(y5 == yexpect[0::4, 0::4])
+    assert np.all(y4 == yexpect[0::4, 0::2])
+    assert np.all(y3 == yexpect[0::2, 0::2])
+    assert np.all(y2 == yexpect)
+    assert np.all(y == yexpect)
+
+
+def test_nocopy_wrapper():
+    # get_elem requires a column-contiguous matrix reference, but should be
+    # callable with other types of matrix (via copying):
+    int_matrix_colmajor = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], order="F")
+    dbl_matrix_colmajor = np.array(
+        int_matrix_colmajor, dtype="double", order="F", copy=True
+    )
+    int_matrix_rowmajor = np.array(int_matrix_colmajor, order="C", copy=True)
+    dbl_matrix_rowmajor = np.array(
+        int_matrix_rowmajor, dtype="double", order="C", copy=True
+    )
+
+    # All should be callable via get_elem:
+    assert m.get_elem(int_matrix_colmajor) == 8
+    assert m.get_elem(dbl_matrix_colmajor) == 8
+    assert m.get_elem(int_matrix_rowmajor) == 8
+    assert m.get_elem(dbl_matrix_rowmajor) == 8
+
+    # All but the second should fail with m.get_elem_nocopy:
+    with pytest.raises(TypeError) as excinfo:
+        m.get_elem_nocopy(int_matrix_colmajor)
+    assert "get_elem_nocopy(): incompatible function arguments." in str(excinfo.value)
+    assert ", flags.f_contiguous" in str(excinfo.value)
+    assert m.get_elem_nocopy(dbl_matrix_colmajor) == 8
+    with pytest.raises(TypeError) as excinfo:
+        m.get_elem_nocopy(int_matrix_rowmajor)
+    assert "get_elem_nocopy(): incompatible function arguments." in str(excinfo.value)
+    assert ", flags.f_contiguous" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.get_elem_nocopy(dbl_matrix_rowmajor)
+    assert "get_elem_nocopy(): incompatible function arguments." in str(excinfo.value)
+    assert ", flags.f_contiguous" in str(excinfo.value)
+
+    # For the row-major test, we take a long matrix in row-major, so only the third is allowed:
+    with pytest.raises(TypeError) as excinfo:
+        m.get_elem_rm_nocopy(int_matrix_colmajor)
+    assert "get_elem_rm_nocopy(): incompatible function arguments." in str(
+        excinfo.value
+    )
+    assert ", flags.c_contiguous" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.get_elem_rm_nocopy(dbl_matrix_colmajor)
+    assert "get_elem_rm_nocopy(): incompatible function arguments." in str(
+        excinfo.value
+    )
+    assert ", flags.c_contiguous" in str(excinfo.value)
+    assert m.get_elem_rm_nocopy(int_matrix_rowmajor) == 8
+    with pytest.raises(TypeError) as excinfo:
+        m.get_elem_rm_nocopy(dbl_matrix_rowmajor)
+    assert "get_elem_rm_nocopy(): incompatible function arguments." in str(
+        excinfo.value
+    )
+    assert ", flags.c_contiguous" in str(excinfo.value)
+
+
+def test_eigen_ref_life_support():
+    """Ensure the lifetime of temporary arrays created by the `Ref` caster
+
+    The `Ref` caster sometimes creates a copy which needs to stay alive. This needs to
+    happen both for directs casts (just the array) or indirectly (e.g. list of arrays).
+    """
+
+    a = np.full(shape=10, fill_value=8, dtype=np.int8)
+    assert m.get_elem_direct(a) == 8
+
+    list_of_a = [a]
+    assert m.get_elem_indirect(list_of_a) == 8
+
+
+def test_special_matrix_objects():
+    assert np.all(m.incr_diag(7) == np.diag([1.0, 2, 3, 4, 5, 6, 7]))
+
+    asymm = np.array([[1.0, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
+    symm_lower = np.array(asymm)
+    symm_upper = np.array(asymm)
+    for i in range(4):
+        for j in range(i + 1, 4):
+            symm_lower[i, j] = symm_lower[j, i]
+            symm_upper[j, i] = symm_upper[i, j]
+
+    assert np.all(m.symmetric_lower(asymm) == symm_lower)
+    assert np.all(m.symmetric_upper(asymm) == symm_upper)
+
+
+def test_dense_signature(doc):
+    assert (
+        doc(m.double_col)
+        == """
+        double_col(arg0: numpy.ndarray[numpy.float32[m, 1]]) -> numpy.ndarray[numpy.float32[m, 1]]
+    """
+    )
+    assert (
+        doc(m.double_row)
+        == """
+        double_row(arg0: numpy.ndarray[numpy.float32[1, n]]) -> numpy.ndarray[numpy.float32[1, n]]
+    """
+    )
+    assert doc(m.double_complex) == (
+        """
+        double_complex(arg0: numpy.ndarray[numpy.complex64[m, 1]])"""
+        """ -> numpy.ndarray[numpy.complex64[m, 1]]
+    """
+    )
+    assert doc(m.double_mat_rm) == (
+        """
+        double_mat_rm(arg0: numpy.ndarray[numpy.float32[m, n]])"""
+        """ -> numpy.ndarray[numpy.float32[m, n]]
+    """
+    )
+
+
+def test_defaults(doc):
+    assert "\n" not in str(doc(m.defaults_mat))
+    assert "\n" not in str(doc(m.defaults_vec))
+
+
+def test_named_arguments():
+    a = np.array([[1.0, 2], [3, 4], [5, 6]])
+    b = np.ones((2, 1))
+
+    assert np.all(m.matrix_multiply(a, b) == np.array([[3.0], [7], [11]]))
+    assert np.all(m.matrix_multiply(A=a, B=b) == np.array([[3.0], [7], [11]]))
+    assert np.all(m.matrix_multiply(B=b, A=a) == np.array([[3.0], [7], [11]]))
+
+    with pytest.raises(ValueError) as excinfo:
+        m.matrix_multiply(b, a)
+    assert str(excinfo.value) == "Nonconformable matrices!"
+
+    with pytest.raises(ValueError) as excinfo:
+        m.matrix_multiply(A=b, B=a)
+    assert str(excinfo.value) == "Nonconformable matrices!"
+
+    with pytest.raises(ValueError) as excinfo:
+        m.matrix_multiply(B=a, A=b)
+    assert str(excinfo.value) == "Nonconformable matrices!"
+
+
+def test_sparse():
+    pytest.importorskip("scipy")
+    assert_sparse_equal_ref(m.sparse_r())
+    assert_sparse_equal_ref(m.sparse_c())
+    assert_sparse_equal_ref(m.sparse_copy_r(m.sparse_r()))
+    assert_sparse_equal_ref(m.sparse_copy_c(m.sparse_c()))
+    assert_sparse_equal_ref(m.sparse_copy_r(m.sparse_c()))
+    assert_sparse_equal_ref(m.sparse_copy_c(m.sparse_r()))
+
+
+def test_sparse_signature(doc):
+    pytest.importorskip("scipy")
+    assert (
+        doc(m.sparse_copy_r)
+        == """
+        sparse_copy_r(arg0: scipy.sparse.csr_matrix[numpy.float32]) -> scipy.sparse.csr_matrix[numpy.float32]
+    """
+    )
+    assert (
+        doc(m.sparse_copy_c)
+        == """
+        sparse_copy_c(arg0: scipy.sparse.csc_matrix[numpy.float32]) -> scipy.sparse.csc_matrix[numpy.float32]
+    """
+    )
+
+
+def test_issue738():
+    """Ignore strides on a length-1 dimension (even if they would be incompatible length > 1)"""
+    assert np.all(m.iss738_f1(np.array([[1.0, 2, 3]])) == np.array([[1.0, 102, 203]]))
+    assert np.all(
+        m.iss738_f1(np.array([[1.0], [2], [3]])) == np.array([[1.0], [12], [23]])
+    )
+
+    assert np.all(m.iss738_f2(np.array([[1.0, 2, 3]])) == np.array([[1.0, 102, 203]]))
+    assert np.all(
+        m.iss738_f2(np.array([[1.0], [2], [3]])) == np.array([[1.0], [12], [23]])
+    )
+
+
+@pytest.mark.parametrize("func", [m.iss738_f1, m.iss738_f2])
+@pytest.mark.parametrize("sizes", [(0, 2), (2, 0)])
+def test_zero_length(func, sizes):
+    """Ignore strides on a length-0 dimension (even if they would be incompatible length > 1)"""
+    assert np.all(func(np.zeros(sizes)) == np.zeros(sizes))
+
+
+def test_issue1105():
+    """Issue 1105: 1xN or Nx1 input arrays weren't accepted for eigen
+    compile-time row vectors or column vector"""
+    assert m.iss1105_row(np.ones((1, 7)))
+    assert m.iss1105_col(np.ones((7, 1)))
+
+    # These should still fail (incompatible dimensions):
+    with pytest.raises(TypeError) as excinfo:
+        m.iss1105_row(np.ones((7, 1)))
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.iss1105_col(np.ones((1, 7)))
+    assert "incompatible function arguments" in str(excinfo.value)
+
+
+def test_custom_operator_new():
+    """Using Eigen types as member variables requires a class-specific
+    operator new with proper alignment"""
+
+    o = m.CustomOperatorNew()
+    np.testing.assert_allclose(o.a, 0.0)
+    np.testing.assert_allclose(o.b.diagonal(), 1.0)
```

## extern/pybind11/tests/test_eigen_tensor.py

 * *Ordering differences only*

```diff
@@ -1,288 +1,288 @@
-import sys
-
-import pytest
-
-np = pytest.importorskip("numpy")
-eigen_tensor = pytest.importorskip("pybind11_tests.eigen_tensor")
-submodules = [eigen_tensor.c_style, eigen_tensor.f_style]
-try:
-    import eigen_tensor_avoid_stl_array as avoid
-
-    submodules += [avoid.c_style, avoid.f_style]
-except ImportError as e:
-    # Ensure config, build, toolchain, etc. issues are not masked here:
-    msg = (
-        "import eigen_tensor_avoid_stl_array FAILED, while "
-        "import pybind11_tests.eigen_tensor succeeded. "
-        "Please ensure that "
-        "test_eigen_tensor.cpp & "
-        "eigen_tensor_avoid_stl_array.cpp "
-        "are built together (or both are not built if Eigen is not available)."
-    )
-    raise RuntimeError(msg) from e
-
-tensor_ref = np.empty((3, 5, 2), dtype=np.int64)
-
-for i in range(tensor_ref.shape[0]):
-    for j in range(tensor_ref.shape[1]):
-        for k in range(tensor_ref.shape[2]):
-            tensor_ref[i, j, k] = i * (5 * 2) + j * 2 + k
-
-indices = (2, 3, 1)
-
-
-@pytest.fixture(autouse=True)
-def cleanup():
-    for module in submodules:
-        module.setup()
-
-    yield
-
-    for module in submodules:
-        assert module.is_ok()
-
-
-def test_import_avoid_stl_array():
-    pytest.importorskip("eigen_tensor_avoid_stl_array")
-    assert len(submodules) == 4
-
-
-def assert_equal_tensor_ref(mat, writeable=True, modified=None):
-    assert mat.flags.writeable == writeable
-
-    copy = np.array(tensor_ref)
-    if modified is not None:
-        copy[indices] = modified
-
-    np.testing.assert_array_equal(mat, copy)
-
-
-@pytest.mark.parametrize("m", submodules)
-@pytest.mark.parametrize("member_name", ["member", "member_view"])
-def test_reference_internal(m, member_name):
-    if not hasattr(sys, "getrefcount"):
-        pytest.skip("No reference counting")
-    foo = m.CustomExample()
-    counts = sys.getrefcount(foo)
-    mem = getattr(foo, member_name)
-    assert_equal_tensor_ref(mem, writeable=False)
-    new_counts = sys.getrefcount(foo)
-    assert new_counts == counts + 1
-    assert_equal_tensor_ref(mem, writeable=False)
-    del mem
-    assert sys.getrefcount(foo) == counts
-
-
-assert_equal_funcs = [
-    "copy_tensor",
-    "copy_fixed_tensor",
-    "copy_const_tensor",
-    "move_tensor_copy",
-    "move_fixed_tensor_copy",
-    "take_tensor",
-    "take_fixed_tensor",
-    "reference_tensor",
-    "reference_tensor_v2",
-    "reference_fixed_tensor",
-    "reference_view_of_tensor",
-    "reference_view_of_tensor_v3",
-    "reference_view_of_tensor_v5",
-    "reference_view_of_fixed_tensor",
-]
-
-assert_equal_const_funcs = [
-    "reference_view_of_tensor_v2",
-    "reference_view_of_tensor_v4",
-    "reference_view_of_tensor_v6",
-    "reference_const_tensor",
-    "reference_const_tensor_v2",
-]
-
-
-@pytest.mark.parametrize("m", submodules)
-@pytest.mark.parametrize("func_name", assert_equal_funcs + assert_equal_const_funcs)
-def test_convert_tensor_to_py(m, func_name):
-    writeable = func_name in assert_equal_funcs
-    assert_equal_tensor_ref(getattr(m, func_name)(), writeable=writeable)
-
-
-@pytest.mark.parametrize("m", submodules)
-def test_bad_cpp_to_python_casts(m):
-    with pytest.raises(
-        RuntimeError, match="Cannot use reference internal when there is no parent"
-    ):
-        m.reference_tensor_internal()
-
-    with pytest.raises(RuntimeError, match="Cannot move from a constant reference"):
-        m.move_const_tensor()
-
-    with pytest.raises(
-        RuntimeError, match="Cannot take ownership of a const reference"
-    ):
-        m.take_const_tensor()
-
-    with pytest.raises(
-        RuntimeError,
-        match="Invalid return_value_policy for Eigen Map type, must be either reference or reference_internal",
-    ):
-        m.take_view_tensor()
-
-
-@pytest.mark.parametrize("m", submodules)
-def test_bad_python_to_cpp_casts(m):
-    with pytest.raises(
-        TypeError, match=r"^round_trip_tensor\(\): incompatible function arguments"
-    ):
-        m.round_trip_tensor(np.zeros((2, 3)))
-
-    with pytest.raises(TypeError, match=r"^Cannot cast array data from dtype"):
-        m.round_trip_tensor(np.zeros(dtype=np.str_, shape=(2, 3, 1)))
-
-    with pytest.raises(
-        TypeError,
-        match=r"^round_trip_tensor_noconvert\(\): incompatible function arguments",
-    ):
-        m.round_trip_tensor_noconvert(tensor_ref)
-
-    assert_equal_tensor_ref(
-        m.round_trip_tensor_noconvert(tensor_ref.astype(np.float64))
-    )
-
-    bad_options = "C" if m.needed_options == "F" else "F"
-    # Shape, dtype and the order need to be correct for a TensorMap cast
-    with pytest.raises(
-        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
-    ):
-        m.round_trip_view_tensor(
-            np.zeros((3, 5, 2), dtype=np.float64, order=bad_options)
-        )
-
-    with pytest.raises(
-        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
-    ):
-        m.round_trip_view_tensor(
-            np.zeros((3, 5, 2), dtype=np.float32, order=m.needed_options)
-        )
-
-    with pytest.raises(
-        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
-    ):
-        m.round_trip_view_tensor(
-            np.zeros((3, 5), dtype=np.float64, order=m.needed_options)
-        )
-
-    temp = np.zeros((3, 5, 2), dtype=np.float64, order=m.needed_options)
-    with pytest.raises(
-        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
-    ):
-        m.round_trip_view_tensor(
-            temp[:, ::-1, :],
-        )
-
-    temp = np.zeros((3, 5, 2), dtype=np.float64, order=m.needed_options)
-    temp.setflags(write=False)
-    with pytest.raises(
-        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
-    ):
-        m.round_trip_view_tensor(temp)
-
-
-@pytest.mark.parametrize("m", submodules)
-def test_references_actually_refer(m):
-    a = m.reference_tensor()
-    temp = a[indices]
-    a[indices] = 100
-    assert_equal_tensor_ref(m.copy_const_tensor(), modified=100)
-    a[indices] = temp
-    assert_equal_tensor_ref(m.copy_const_tensor())
-
-    a = m.reference_view_of_tensor()
-    a[indices] = 100
-    assert_equal_tensor_ref(m.copy_const_tensor(), modified=100)
-    a[indices] = temp
-    assert_equal_tensor_ref(m.copy_const_tensor())
-
-
-@pytest.mark.parametrize("m", submodules)
-def test_round_trip(m):
-    assert_equal_tensor_ref(m.round_trip_tensor(tensor_ref))
-
-    with pytest.raises(TypeError, match="^Cannot cast array data from"):
-        assert_equal_tensor_ref(m.round_trip_tensor2(tensor_ref))
-
-    assert_equal_tensor_ref(m.round_trip_tensor2(np.array(tensor_ref, dtype=np.int32)))
-    assert_equal_tensor_ref(m.round_trip_fixed_tensor(tensor_ref))
-    assert_equal_tensor_ref(m.round_trip_aligned_view_tensor(m.reference_tensor()))
-
-    copy = np.array(tensor_ref, dtype=np.float64, order=m.needed_options)
-    assert_equal_tensor_ref(m.round_trip_view_tensor(copy))
-    assert_equal_tensor_ref(m.round_trip_view_tensor_ref(copy))
-    assert_equal_tensor_ref(m.round_trip_view_tensor_ptr(copy))
-    copy.setflags(write=False)
-    assert_equal_tensor_ref(m.round_trip_const_view_tensor(copy))
-
-    np.testing.assert_array_equal(
-        tensor_ref[:, ::-1, :], m.round_trip_tensor(tensor_ref[:, ::-1, :])
-    )
-
-    assert m.round_trip_rank_0(np.float64(3.5)) == 3.5
-    assert m.round_trip_rank_0(3.5) == 3.5
-
-    with pytest.raises(
-        TypeError,
-        match=r"^round_trip_rank_0_noconvert\(\): incompatible function arguments",
-    ):
-        m.round_trip_rank_0_noconvert(np.float64(3.5))
-
-    with pytest.raises(
-        TypeError,
-        match=r"^round_trip_rank_0_noconvert\(\): incompatible function arguments",
-    ):
-        m.round_trip_rank_0_noconvert(3.5)
-
-    with pytest.raises(
-        TypeError, match=r"^round_trip_rank_0_view\(\): incompatible function arguments"
-    ):
-        m.round_trip_rank_0_view(np.float64(3.5))
-
-    with pytest.raises(
-        TypeError, match=r"^round_trip_rank_0_view\(\): incompatible function arguments"
-    ):
-        m.round_trip_rank_0_view(3.5)
-
-
-@pytest.mark.parametrize("m", submodules)
-def test_round_trip_references_actually_refer(m):
-    # Need to create a copy that matches the type on the C side
-    copy = np.array(tensor_ref, dtype=np.float64, order=m.needed_options)
-    a = m.round_trip_view_tensor(copy)
-    temp = a[indices]
-    a[indices] = 100
-    assert_equal_tensor_ref(copy, modified=100)
-    a[indices] = temp
-    assert_equal_tensor_ref(copy)
-
-
-@pytest.mark.parametrize("m", submodules)
-def test_doc_string(m, doc):
-    assert (
-        doc(m.copy_tensor) == "copy_tensor() -> numpy.ndarray[numpy.float64[?, ?, ?]]"
-    )
-    assert (
-        doc(m.copy_fixed_tensor)
-        == "copy_fixed_tensor() -> numpy.ndarray[numpy.float64[3, 5, 2]]"
-    )
-    assert (
-        doc(m.reference_const_tensor)
-        == "reference_const_tensor() -> numpy.ndarray[numpy.float64[?, ?, ?]]"
-    )
-
-    order_flag = f"flags.{m.needed_options.lower()}_contiguous"
-    assert doc(m.round_trip_view_tensor) == (
-        f"round_trip_view_tensor(arg0: numpy.ndarray[numpy.float64[?, ?, ?], flags.writeable, {order_flag}])"
-        f" -> numpy.ndarray[numpy.float64[?, ?, ?], flags.writeable, {order_flag}]"
-    )
-    assert doc(m.round_trip_const_view_tensor) == (
-        f"round_trip_const_view_tensor(arg0: numpy.ndarray[numpy.float64[?, ?, ?], {order_flag}])"
-        " -> numpy.ndarray[numpy.float64[?, ?, ?]]"
-    )
+import sys
+
+import pytest
+
+np = pytest.importorskip("numpy")
+eigen_tensor = pytest.importorskip("pybind11_tests.eigen_tensor")
+submodules = [eigen_tensor.c_style, eigen_tensor.f_style]
+try:
+    import eigen_tensor_avoid_stl_array as avoid
+
+    submodules += [avoid.c_style, avoid.f_style]
+except ImportError as e:
+    # Ensure config, build, toolchain, etc. issues are not masked here:
+    msg = (
+        "import eigen_tensor_avoid_stl_array FAILED, while "
+        "import pybind11_tests.eigen_tensor succeeded. "
+        "Please ensure that "
+        "test_eigen_tensor.cpp & "
+        "eigen_tensor_avoid_stl_array.cpp "
+        "are built together (or both are not built if Eigen is not available)."
+    )
+    raise RuntimeError(msg) from e
+
+tensor_ref = np.empty((3, 5, 2), dtype=np.int64)
+
+for i in range(tensor_ref.shape[0]):
+    for j in range(tensor_ref.shape[1]):
+        for k in range(tensor_ref.shape[2]):
+            tensor_ref[i, j, k] = i * (5 * 2) + j * 2 + k
+
+indices = (2, 3, 1)
+
+
+@pytest.fixture(autouse=True)
+def cleanup():
+    for module in submodules:
+        module.setup()
+
+    yield
+
+    for module in submodules:
+        assert module.is_ok()
+
+
+def test_import_avoid_stl_array():
+    pytest.importorskip("eigen_tensor_avoid_stl_array")
+    assert len(submodules) == 4
+
+
+def assert_equal_tensor_ref(mat, writeable=True, modified=None):
+    assert mat.flags.writeable == writeable
+
+    copy = np.array(tensor_ref)
+    if modified is not None:
+        copy[indices] = modified
+
+    np.testing.assert_array_equal(mat, copy)
+
+
+@pytest.mark.parametrize("m", submodules)
+@pytest.mark.parametrize("member_name", ["member", "member_view"])
+def test_reference_internal(m, member_name):
+    if not hasattr(sys, "getrefcount"):
+        pytest.skip("No reference counting")
+    foo = m.CustomExample()
+    counts = sys.getrefcount(foo)
+    mem = getattr(foo, member_name)
+    assert_equal_tensor_ref(mem, writeable=False)
+    new_counts = sys.getrefcount(foo)
+    assert new_counts == counts + 1
+    assert_equal_tensor_ref(mem, writeable=False)
+    del mem
+    assert sys.getrefcount(foo) == counts
+
+
+assert_equal_funcs = [
+    "copy_tensor",
+    "copy_fixed_tensor",
+    "copy_const_tensor",
+    "move_tensor_copy",
+    "move_fixed_tensor_copy",
+    "take_tensor",
+    "take_fixed_tensor",
+    "reference_tensor",
+    "reference_tensor_v2",
+    "reference_fixed_tensor",
+    "reference_view_of_tensor",
+    "reference_view_of_tensor_v3",
+    "reference_view_of_tensor_v5",
+    "reference_view_of_fixed_tensor",
+]
+
+assert_equal_const_funcs = [
+    "reference_view_of_tensor_v2",
+    "reference_view_of_tensor_v4",
+    "reference_view_of_tensor_v6",
+    "reference_const_tensor",
+    "reference_const_tensor_v2",
+]
+
+
+@pytest.mark.parametrize("m", submodules)
+@pytest.mark.parametrize("func_name", assert_equal_funcs + assert_equal_const_funcs)
+def test_convert_tensor_to_py(m, func_name):
+    writeable = func_name in assert_equal_funcs
+    assert_equal_tensor_ref(getattr(m, func_name)(), writeable=writeable)
+
+
+@pytest.mark.parametrize("m", submodules)
+def test_bad_cpp_to_python_casts(m):
+    with pytest.raises(
+        RuntimeError, match="Cannot use reference internal when there is no parent"
+    ):
+        m.reference_tensor_internal()
+
+    with pytest.raises(RuntimeError, match="Cannot move from a constant reference"):
+        m.move_const_tensor()
+
+    with pytest.raises(
+        RuntimeError, match="Cannot take ownership of a const reference"
+    ):
+        m.take_const_tensor()
+
+    with pytest.raises(
+        RuntimeError,
+        match="Invalid return_value_policy for Eigen Map type, must be either reference or reference_internal",
+    ):
+        m.take_view_tensor()
+
+
+@pytest.mark.parametrize("m", submodules)
+def test_bad_python_to_cpp_casts(m):
+    with pytest.raises(
+        TypeError, match=r"^round_trip_tensor\(\): incompatible function arguments"
+    ):
+        m.round_trip_tensor(np.zeros((2, 3)))
+
+    with pytest.raises(TypeError, match=r"^Cannot cast array data from dtype"):
+        m.round_trip_tensor(np.zeros(dtype=np.str_, shape=(2, 3, 1)))
+
+    with pytest.raises(
+        TypeError,
+        match=r"^round_trip_tensor_noconvert\(\): incompatible function arguments",
+    ):
+        m.round_trip_tensor_noconvert(tensor_ref)
+
+    assert_equal_tensor_ref(
+        m.round_trip_tensor_noconvert(tensor_ref.astype(np.float64))
+    )
+
+    bad_options = "C" if m.needed_options == "F" else "F"
+    # Shape, dtype and the order need to be correct for a TensorMap cast
+    with pytest.raises(
+        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
+    ):
+        m.round_trip_view_tensor(
+            np.zeros((3, 5, 2), dtype=np.float64, order=bad_options)
+        )
+
+    with pytest.raises(
+        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
+    ):
+        m.round_trip_view_tensor(
+            np.zeros((3, 5, 2), dtype=np.float32, order=m.needed_options)
+        )
+
+    with pytest.raises(
+        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
+    ):
+        m.round_trip_view_tensor(
+            np.zeros((3, 5), dtype=np.float64, order=m.needed_options)
+        )
+
+    temp = np.zeros((3, 5, 2), dtype=np.float64, order=m.needed_options)
+    with pytest.raises(
+        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
+    ):
+        m.round_trip_view_tensor(
+            temp[:, ::-1, :],
+        )
+
+    temp = np.zeros((3, 5, 2), dtype=np.float64, order=m.needed_options)
+    temp.setflags(write=False)
+    with pytest.raises(
+        TypeError, match=r"^round_trip_view_tensor\(\): incompatible function arguments"
+    ):
+        m.round_trip_view_tensor(temp)
+
+
+@pytest.mark.parametrize("m", submodules)
+def test_references_actually_refer(m):
+    a = m.reference_tensor()
+    temp = a[indices]
+    a[indices] = 100
+    assert_equal_tensor_ref(m.copy_const_tensor(), modified=100)
+    a[indices] = temp
+    assert_equal_tensor_ref(m.copy_const_tensor())
+
+    a = m.reference_view_of_tensor()
+    a[indices] = 100
+    assert_equal_tensor_ref(m.copy_const_tensor(), modified=100)
+    a[indices] = temp
+    assert_equal_tensor_ref(m.copy_const_tensor())
+
+
+@pytest.mark.parametrize("m", submodules)
+def test_round_trip(m):
+    assert_equal_tensor_ref(m.round_trip_tensor(tensor_ref))
+
+    with pytest.raises(TypeError, match="^Cannot cast array data from"):
+        assert_equal_tensor_ref(m.round_trip_tensor2(tensor_ref))
+
+    assert_equal_tensor_ref(m.round_trip_tensor2(np.array(tensor_ref, dtype=np.int32)))
+    assert_equal_tensor_ref(m.round_trip_fixed_tensor(tensor_ref))
+    assert_equal_tensor_ref(m.round_trip_aligned_view_tensor(m.reference_tensor()))
+
+    copy = np.array(tensor_ref, dtype=np.float64, order=m.needed_options)
+    assert_equal_tensor_ref(m.round_trip_view_tensor(copy))
+    assert_equal_tensor_ref(m.round_trip_view_tensor_ref(copy))
+    assert_equal_tensor_ref(m.round_trip_view_tensor_ptr(copy))
+    copy.setflags(write=False)
+    assert_equal_tensor_ref(m.round_trip_const_view_tensor(copy))
+
+    np.testing.assert_array_equal(
+        tensor_ref[:, ::-1, :], m.round_trip_tensor(tensor_ref[:, ::-1, :])
+    )
+
+    assert m.round_trip_rank_0(np.float64(3.5)) == 3.5
+    assert m.round_trip_rank_0(3.5) == 3.5
+
+    with pytest.raises(
+        TypeError,
+        match=r"^round_trip_rank_0_noconvert\(\): incompatible function arguments",
+    ):
+        m.round_trip_rank_0_noconvert(np.float64(3.5))
+
+    with pytest.raises(
+        TypeError,
+        match=r"^round_trip_rank_0_noconvert\(\): incompatible function arguments",
+    ):
+        m.round_trip_rank_0_noconvert(3.5)
+
+    with pytest.raises(
+        TypeError, match=r"^round_trip_rank_0_view\(\): incompatible function arguments"
+    ):
+        m.round_trip_rank_0_view(np.float64(3.5))
+
+    with pytest.raises(
+        TypeError, match=r"^round_trip_rank_0_view\(\): incompatible function arguments"
+    ):
+        m.round_trip_rank_0_view(3.5)
+
+
+@pytest.mark.parametrize("m", submodules)
+def test_round_trip_references_actually_refer(m):
+    # Need to create a copy that matches the type on the C side
+    copy = np.array(tensor_ref, dtype=np.float64, order=m.needed_options)
+    a = m.round_trip_view_tensor(copy)
+    temp = a[indices]
+    a[indices] = 100
+    assert_equal_tensor_ref(copy, modified=100)
+    a[indices] = temp
+    assert_equal_tensor_ref(copy)
+
+
+@pytest.mark.parametrize("m", submodules)
+def test_doc_string(m, doc):
+    assert (
+        doc(m.copy_tensor) == "copy_tensor() -> numpy.ndarray[numpy.float64[?, ?, ?]]"
+    )
+    assert (
+        doc(m.copy_fixed_tensor)
+        == "copy_fixed_tensor() -> numpy.ndarray[numpy.float64[3, 5, 2]]"
+    )
+    assert (
+        doc(m.reference_const_tensor)
+        == "reference_const_tensor() -> numpy.ndarray[numpy.float64[?, ?, ?]]"
+    )
+
+    order_flag = f"flags.{m.needed_options.lower()}_contiguous"
+    assert doc(m.round_trip_view_tensor) == (
+        f"round_trip_view_tensor(arg0: numpy.ndarray[numpy.float64[?, ?, ?], flags.writeable, {order_flag}])"
+        f" -> numpy.ndarray[numpy.float64[?, ?, ?], flags.writeable, {order_flag}]"
+    )
+    assert doc(m.round_trip_const_view_tensor) == (
+        f"round_trip_const_view_tensor(arg0: numpy.ndarray[numpy.float64[?, ?, ?], {order_flag}])"
+        " -> numpy.ndarray[numpy.float64[?, ?, ?]]"
+    )
```

## extern/pybind11/tests/test_enum.py

 * *Ordering differences only*

```diff
@@ -1,269 +1,269 @@
-# ruff: noqa: SIM201 SIM300 SIM202
-
-import pytest
-
-from pybind11_tests import enums as m
-
-
-def test_unscoped_enum():
-    assert str(m.UnscopedEnum.EOne) == "UnscopedEnum.EOne"
-    assert str(m.UnscopedEnum.ETwo) == "UnscopedEnum.ETwo"
-    assert str(m.EOne) == "UnscopedEnum.EOne"
-    assert repr(m.UnscopedEnum.EOne) == "<UnscopedEnum.EOne: 1>"
-    assert repr(m.UnscopedEnum.ETwo) == "<UnscopedEnum.ETwo: 2>"
-    assert repr(m.EOne) == "<UnscopedEnum.EOne: 1>"
-
-    # name property
-    assert m.UnscopedEnum.EOne.name == "EOne"
-    assert m.UnscopedEnum.EOne.value == 1
-    assert m.UnscopedEnum.ETwo.name == "ETwo"
-    assert m.UnscopedEnum.ETwo.value == 2
-    assert m.EOne is m.UnscopedEnum.EOne
-    # name, value readonly
-    with pytest.raises(AttributeError):
-        m.UnscopedEnum.EOne.name = ""
-    with pytest.raises(AttributeError):
-        m.UnscopedEnum.EOne.value = 10
-    # name, value returns a copy
-    # TODO: Neither the name nor value tests actually check against aliasing.
-    # Use a mutable type that has reference semantics.
-    nonaliased_name = m.UnscopedEnum.EOne.name
-    nonaliased_name = "bar"  # noqa: F841
-    assert m.UnscopedEnum.EOne.name == "EOne"
-    nonaliased_value = m.UnscopedEnum.EOne.value
-    nonaliased_value = 10  # noqa: F841
-    assert m.UnscopedEnum.EOne.value == 1
-
-    # __members__ property
-    assert m.UnscopedEnum.__members__ == {
-        "EOne": m.UnscopedEnum.EOne,
-        "ETwo": m.UnscopedEnum.ETwo,
-        "EThree": m.UnscopedEnum.EThree,
-    }
-    # __members__ readonly
-    with pytest.raises(AttributeError):
-        m.UnscopedEnum.__members__ = {}
-    # __members__ returns a copy
-    nonaliased_members = m.UnscopedEnum.__members__
-    nonaliased_members["bar"] = "baz"
-    assert m.UnscopedEnum.__members__ == {
-        "EOne": m.UnscopedEnum.EOne,
-        "ETwo": m.UnscopedEnum.ETwo,
-        "EThree": m.UnscopedEnum.EThree,
-    }
-
-    for docstring_line in """An unscoped enumeration
-
-Members:
-
-  EOne : Docstring for EOne
-
-  ETwo : Docstring for ETwo
-
-  EThree : Docstring for EThree""".split("\n"):
-        assert docstring_line in m.UnscopedEnum.__doc__
-
-    # Unscoped enums will accept ==/!= int comparisons
-    y = m.UnscopedEnum.ETwo
-    assert y == 2
-    assert 2 == y
-    assert y != 3
-    assert 3 != y
-    # Compare with None
-    assert y != None  # noqa: E711
-    assert not (y == None)  # noqa: E711
-    # Compare with an object
-    assert y != object()
-    assert not (y == object())
-    # Compare with string
-    assert y != "2"
-    assert "2" != y
-    assert not ("2" == y)
-    assert not (y == "2")
-
-    with pytest.raises(TypeError):
-        y < object()  # noqa: B015
-
-    with pytest.raises(TypeError):
-        y <= object()  # noqa: B015
-
-    with pytest.raises(TypeError):
-        y > object()  # noqa: B015
-
-    with pytest.raises(TypeError):
-        y >= object()  # noqa: B015
-
-    with pytest.raises(TypeError):
-        y | object()
-
-    with pytest.raises(TypeError):
-        y & object()
-
-    with pytest.raises(TypeError):
-        y ^ object()
-
-    assert int(m.UnscopedEnum.ETwo) == 2
-    assert str(m.UnscopedEnum(2)) == "UnscopedEnum.ETwo"
-
-    # order
-    assert m.UnscopedEnum.EOne < m.UnscopedEnum.ETwo
-    assert m.UnscopedEnum.EOne < 2
-    assert m.UnscopedEnum.ETwo > m.UnscopedEnum.EOne
-    assert m.UnscopedEnum.ETwo > 1
-    assert m.UnscopedEnum.ETwo <= 2
-    assert m.UnscopedEnum.ETwo >= 2
-    assert m.UnscopedEnum.EOne <= m.UnscopedEnum.ETwo
-    assert m.UnscopedEnum.EOne <= 2
-    assert m.UnscopedEnum.ETwo >= m.UnscopedEnum.EOne
-    assert m.UnscopedEnum.ETwo >= 1
-    assert not (m.UnscopedEnum.ETwo < m.UnscopedEnum.EOne)
-    assert not (2 < m.UnscopedEnum.EOne)
-
-    # arithmetic
-    assert m.UnscopedEnum.EOne & m.UnscopedEnum.EThree == m.UnscopedEnum.EOne
-    assert m.UnscopedEnum.EOne | m.UnscopedEnum.ETwo == m.UnscopedEnum.EThree
-    assert m.UnscopedEnum.EOne ^ m.UnscopedEnum.EThree == m.UnscopedEnum.ETwo
-
-
-def test_scoped_enum():
-    assert m.test_scoped_enum(m.ScopedEnum.Three) == "ScopedEnum::Three"
-    z = m.ScopedEnum.Two
-    assert m.test_scoped_enum(z) == "ScopedEnum::Two"
-
-    # Scoped enums will *NOT* accept ==/!= int comparisons (Will always return False)
-    assert not z == 3
-    assert not 3 == z
-    assert z != 3
-    assert 3 != z
-    # Compare with None
-    assert z != None  # noqa: E711
-    assert not (z == None)  # noqa: E711
-    # Compare with an object
-    assert z != object()
-    assert not (z == object())
-    # Scoped enums will *NOT* accept >, <, >= and <= int comparisons (Will throw exceptions)
-    with pytest.raises(TypeError):
-        z > 3  # noqa: B015
-    with pytest.raises(TypeError):
-        z < 3  # noqa: B015
-    with pytest.raises(TypeError):
-        z >= 3  # noqa: B015
-    with pytest.raises(TypeError):
-        z <= 3  # noqa: B015
-
-    # order
-    assert m.ScopedEnum.Two < m.ScopedEnum.Three
-    assert m.ScopedEnum.Three > m.ScopedEnum.Two
-    assert m.ScopedEnum.Two <= m.ScopedEnum.Three
-    assert m.ScopedEnum.Two <= m.ScopedEnum.Two
-    assert m.ScopedEnum.Two >= m.ScopedEnum.Two
-    assert m.ScopedEnum.Three >= m.ScopedEnum.Two
-
-
-def test_implicit_conversion():
-    assert str(m.ClassWithUnscopedEnum.EMode.EFirstMode) == "EMode.EFirstMode"
-    assert str(m.ClassWithUnscopedEnum.EFirstMode) == "EMode.EFirstMode"
-    assert repr(m.ClassWithUnscopedEnum.EMode.EFirstMode) == "<EMode.EFirstMode: 1>"
-    assert repr(m.ClassWithUnscopedEnum.EFirstMode) == "<EMode.EFirstMode: 1>"
-
-    f = m.ClassWithUnscopedEnum.test_function
-    first = m.ClassWithUnscopedEnum.EFirstMode
-    second = m.ClassWithUnscopedEnum.ESecondMode
-
-    assert f(first) == 1
-
-    assert f(first) == f(first)
-    assert not f(first) != f(first)
-
-    assert f(first) != f(second)
-    assert not f(first) == f(second)
-
-    assert f(first) == int(f(first))
-    assert not f(first) != int(f(first))
-
-    assert f(first) != int(f(second))
-    assert not f(first) == int(f(second))
-
-    # noinspection PyDictCreation
-    x = {f(first): 1, f(second): 2}
-    x[f(first)] = 3
-    x[f(second)] = 4
-    # Hashing test
-    assert repr(x) == "{<EMode.EFirstMode: 1>: 3, <EMode.ESecondMode: 2>: 4}"
-
-
-def test_binary_operators():
-    assert int(m.Flags.Read) == 4
-    assert int(m.Flags.Write) == 2
-    assert int(m.Flags.Execute) == 1
-    assert int(m.Flags.Read | m.Flags.Write | m.Flags.Execute) == 7
-    assert int(m.Flags.Read | m.Flags.Write) == 6
-    assert int(m.Flags.Read | m.Flags.Execute) == 5
-    assert int(m.Flags.Write | m.Flags.Execute) == 3
-    assert int(m.Flags.Write | 1) == 3
-    assert ~m.Flags.Write == -3
-
-    state = m.Flags.Read | m.Flags.Write
-    assert (state & m.Flags.Read) != 0
-    assert (state & m.Flags.Write) != 0
-    assert (state & m.Flags.Execute) == 0
-    assert (state & 1) == 0
-
-    state2 = ~state
-    assert state2 == -7
-    assert int(state ^ state2) == -1
-
-
-def test_enum_to_int():
-    m.test_enum_to_int(m.Flags.Read)
-    m.test_enum_to_int(m.ClassWithUnscopedEnum.EMode.EFirstMode)
-    m.test_enum_to_int(m.ScopedCharEnum.Positive)
-    m.test_enum_to_int(m.ScopedBoolEnum.TRUE)
-    m.test_enum_to_uint(m.Flags.Read)
-    m.test_enum_to_uint(m.ClassWithUnscopedEnum.EMode.EFirstMode)
-    m.test_enum_to_uint(m.ScopedCharEnum.Positive)
-    m.test_enum_to_uint(m.ScopedBoolEnum.TRUE)
-    m.test_enum_to_long_long(m.Flags.Read)
-    m.test_enum_to_long_long(m.ClassWithUnscopedEnum.EMode.EFirstMode)
-    m.test_enum_to_long_long(m.ScopedCharEnum.Positive)
-    m.test_enum_to_long_long(m.ScopedBoolEnum.TRUE)
-
-
-def test_duplicate_enum_name():
-    with pytest.raises(ValueError) as excinfo:
-        m.register_bad_enum()
-    assert str(excinfo.value) == 'SimpleEnum: element "ONE" already exists!'
-
-
-def test_char_underlying_enum():  # Issue #1331/PR #1334:
-    assert type(m.ScopedCharEnum.Positive.__int__()) is int
-    assert int(m.ScopedChar16Enum.Zero) == 0
-    assert hash(m.ScopedChar32Enum.Positive) == 1
-    assert type(m.ScopedCharEnum.Positive.__getstate__()) is int
-    assert m.ScopedWCharEnum(1) == m.ScopedWCharEnum.Positive
-    with pytest.raises(TypeError):
-        # Even if the underlying type is char, only an int can be used to construct the enum:
-        m.ScopedCharEnum("0")
-
-
-def test_bool_underlying_enum():
-    assert type(m.ScopedBoolEnum.TRUE.__int__()) is int
-    assert int(m.ScopedBoolEnum.FALSE) == 0
-    assert hash(m.ScopedBoolEnum.TRUE) == 1
-    assert type(m.ScopedBoolEnum.TRUE.__getstate__()) is int
-    assert m.ScopedBoolEnum(1) == m.ScopedBoolEnum.TRUE
-    # Enum could construct with a bool
-    # (bool is a strict subclass of int, and False will be converted to 0)
-    assert m.ScopedBoolEnum(False) == m.ScopedBoolEnum.FALSE
-
-
-def test_docstring_signatures():
-    for enum_type in [m.ScopedEnum, m.UnscopedEnum]:
-        for attr in enum_type.__dict__.values():
-            # Issue #2623/PR #2637: Add argument names to enum_ methods
-            assert "arg0" not in (attr.__doc__ or "")
-
-
-def test_str_signature():
-    for enum_type in [m.ScopedEnum, m.UnscopedEnum]:
-        assert enum_type.__str__.__doc__.startswith("__str__")
+# ruff: noqa: SIM201 SIM300 SIM202
+
+import pytest
+
+from pybind11_tests import enums as m
+
+
+def test_unscoped_enum():
+    assert str(m.UnscopedEnum.EOne) == "UnscopedEnum.EOne"
+    assert str(m.UnscopedEnum.ETwo) == "UnscopedEnum.ETwo"
+    assert str(m.EOne) == "UnscopedEnum.EOne"
+    assert repr(m.UnscopedEnum.EOne) == "<UnscopedEnum.EOne: 1>"
+    assert repr(m.UnscopedEnum.ETwo) == "<UnscopedEnum.ETwo: 2>"
+    assert repr(m.EOne) == "<UnscopedEnum.EOne: 1>"
+
+    # name property
+    assert m.UnscopedEnum.EOne.name == "EOne"
+    assert m.UnscopedEnum.EOne.value == 1
+    assert m.UnscopedEnum.ETwo.name == "ETwo"
+    assert m.UnscopedEnum.ETwo.value == 2
+    assert m.EOne is m.UnscopedEnum.EOne
+    # name, value readonly
+    with pytest.raises(AttributeError):
+        m.UnscopedEnum.EOne.name = ""
+    with pytest.raises(AttributeError):
+        m.UnscopedEnum.EOne.value = 10
+    # name, value returns a copy
+    # TODO: Neither the name nor value tests actually check against aliasing.
+    # Use a mutable type that has reference semantics.
+    nonaliased_name = m.UnscopedEnum.EOne.name
+    nonaliased_name = "bar"  # noqa: F841
+    assert m.UnscopedEnum.EOne.name == "EOne"
+    nonaliased_value = m.UnscopedEnum.EOne.value
+    nonaliased_value = 10  # noqa: F841
+    assert m.UnscopedEnum.EOne.value == 1
+
+    # __members__ property
+    assert m.UnscopedEnum.__members__ == {
+        "EOne": m.UnscopedEnum.EOne,
+        "ETwo": m.UnscopedEnum.ETwo,
+        "EThree": m.UnscopedEnum.EThree,
+    }
+    # __members__ readonly
+    with pytest.raises(AttributeError):
+        m.UnscopedEnum.__members__ = {}
+    # __members__ returns a copy
+    nonaliased_members = m.UnscopedEnum.__members__
+    nonaliased_members["bar"] = "baz"
+    assert m.UnscopedEnum.__members__ == {
+        "EOne": m.UnscopedEnum.EOne,
+        "ETwo": m.UnscopedEnum.ETwo,
+        "EThree": m.UnscopedEnum.EThree,
+    }
+
+    for docstring_line in """An unscoped enumeration
+
+Members:
+
+  EOne : Docstring for EOne
+
+  ETwo : Docstring for ETwo
+
+  EThree : Docstring for EThree""".split("\n"):
+        assert docstring_line in m.UnscopedEnum.__doc__
+
+    # Unscoped enums will accept ==/!= int comparisons
+    y = m.UnscopedEnum.ETwo
+    assert y == 2
+    assert 2 == y
+    assert y != 3
+    assert 3 != y
+    # Compare with None
+    assert y != None  # noqa: E711
+    assert not (y == None)  # noqa: E711
+    # Compare with an object
+    assert y != object()
+    assert not (y == object())
+    # Compare with string
+    assert y != "2"
+    assert "2" != y
+    assert not ("2" == y)
+    assert not (y == "2")
+
+    with pytest.raises(TypeError):
+        y < object()  # noqa: B015
+
+    with pytest.raises(TypeError):
+        y <= object()  # noqa: B015
+
+    with pytest.raises(TypeError):
+        y > object()  # noqa: B015
+
+    with pytest.raises(TypeError):
+        y >= object()  # noqa: B015
+
+    with pytest.raises(TypeError):
+        y | object()
+
+    with pytest.raises(TypeError):
+        y & object()
+
+    with pytest.raises(TypeError):
+        y ^ object()
+
+    assert int(m.UnscopedEnum.ETwo) == 2
+    assert str(m.UnscopedEnum(2)) == "UnscopedEnum.ETwo"
+
+    # order
+    assert m.UnscopedEnum.EOne < m.UnscopedEnum.ETwo
+    assert m.UnscopedEnum.EOne < 2
+    assert m.UnscopedEnum.ETwo > m.UnscopedEnum.EOne
+    assert m.UnscopedEnum.ETwo > 1
+    assert m.UnscopedEnum.ETwo <= 2
+    assert m.UnscopedEnum.ETwo >= 2
+    assert m.UnscopedEnum.EOne <= m.UnscopedEnum.ETwo
+    assert m.UnscopedEnum.EOne <= 2
+    assert m.UnscopedEnum.ETwo >= m.UnscopedEnum.EOne
+    assert m.UnscopedEnum.ETwo >= 1
+    assert not (m.UnscopedEnum.ETwo < m.UnscopedEnum.EOne)
+    assert not (2 < m.UnscopedEnum.EOne)
+
+    # arithmetic
+    assert m.UnscopedEnum.EOne & m.UnscopedEnum.EThree == m.UnscopedEnum.EOne
+    assert m.UnscopedEnum.EOne | m.UnscopedEnum.ETwo == m.UnscopedEnum.EThree
+    assert m.UnscopedEnum.EOne ^ m.UnscopedEnum.EThree == m.UnscopedEnum.ETwo
+
+
+def test_scoped_enum():
+    assert m.test_scoped_enum(m.ScopedEnum.Three) == "ScopedEnum::Three"
+    z = m.ScopedEnum.Two
+    assert m.test_scoped_enum(z) == "ScopedEnum::Two"
+
+    # Scoped enums will *NOT* accept ==/!= int comparisons (Will always return False)
+    assert not z == 3
+    assert not 3 == z
+    assert z != 3
+    assert 3 != z
+    # Compare with None
+    assert z != None  # noqa: E711
+    assert not (z == None)  # noqa: E711
+    # Compare with an object
+    assert z != object()
+    assert not (z == object())
+    # Scoped enums will *NOT* accept >, <, >= and <= int comparisons (Will throw exceptions)
+    with pytest.raises(TypeError):
+        z > 3  # noqa: B015
+    with pytest.raises(TypeError):
+        z < 3  # noqa: B015
+    with pytest.raises(TypeError):
+        z >= 3  # noqa: B015
+    with pytest.raises(TypeError):
+        z <= 3  # noqa: B015
+
+    # order
+    assert m.ScopedEnum.Two < m.ScopedEnum.Three
+    assert m.ScopedEnum.Three > m.ScopedEnum.Two
+    assert m.ScopedEnum.Two <= m.ScopedEnum.Three
+    assert m.ScopedEnum.Two <= m.ScopedEnum.Two
+    assert m.ScopedEnum.Two >= m.ScopedEnum.Two
+    assert m.ScopedEnum.Three >= m.ScopedEnum.Two
+
+
+def test_implicit_conversion():
+    assert str(m.ClassWithUnscopedEnum.EMode.EFirstMode) == "EMode.EFirstMode"
+    assert str(m.ClassWithUnscopedEnum.EFirstMode) == "EMode.EFirstMode"
+    assert repr(m.ClassWithUnscopedEnum.EMode.EFirstMode) == "<EMode.EFirstMode: 1>"
+    assert repr(m.ClassWithUnscopedEnum.EFirstMode) == "<EMode.EFirstMode: 1>"
+
+    f = m.ClassWithUnscopedEnum.test_function
+    first = m.ClassWithUnscopedEnum.EFirstMode
+    second = m.ClassWithUnscopedEnum.ESecondMode
+
+    assert f(first) == 1
+
+    assert f(first) == f(first)
+    assert not f(first) != f(first)
+
+    assert f(first) != f(second)
+    assert not f(first) == f(second)
+
+    assert f(first) == int(f(first))
+    assert not f(first) != int(f(first))
+
+    assert f(first) != int(f(second))
+    assert not f(first) == int(f(second))
+
+    # noinspection PyDictCreation
+    x = {f(first): 1, f(second): 2}
+    x[f(first)] = 3
+    x[f(second)] = 4
+    # Hashing test
+    assert repr(x) == "{<EMode.EFirstMode: 1>: 3, <EMode.ESecondMode: 2>: 4}"
+
+
+def test_binary_operators():
+    assert int(m.Flags.Read) == 4
+    assert int(m.Flags.Write) == 2
+    assert int(m.Flags.Execute) == 1
+    assert int(m.Flags.Read | m.Flags.Write | m.Flags.Execute) == 7
+    assert int(m.Flags.Read | m.Flags.Write) == 6
+    assert int(m.Flags.Read | m.Flags.Execute) == 5
+    assert int(m.Flags.Write | m.Flags.Execute) == 3
+    assert int(m.Flags.Write | 1) == 3
+    assert ~m.Flags.Write == -3
+
+    state = m.Flags.Read | m.Flags.Write
+    assert (state & m.Flags.Read) != 0
+    assert (state & m.Flags.Write) != 0
+    assert (state & m.Flags.Execute) == 0
+    assert (state & 1) == 0
+
+    state2 = ~state
+    assert state2 == -7
+    assert int(state ^ state2) == -1
+
+
+def test_enum_to_int():
+    m.test_enum_to_int(m.Flags.Read)
+    m.test_enum_to_int(m.ClassWithUnscopedEnum.EMode.EFirstMode)
+    m.test_enum_to_int(m.ScopedCharEnum.Positive)
+    m.test_enum_to_int(m.ScopedBoolEnum.TRUE)
+    m.test_enum_to_uint(m.Flags.Read)
+    m.test_enum_to_uint(m.ClassWithUnscopedEnum.EMode.EFirstMode)
+    m.test_enum_to_uint(m.ScopedCharEnum.Positive)
+    m.test_enum_to_uint(m.ScopedBoolEnum.TRUE)
+    m.test_enum_to_long_long(m.Flags.Read)
+    m.test_enum_to_long_long(m.ClassWithUnscopedEnum.EMode.EFirstMode)
+    m.test_enum_to_long_long(m.ScopedCharEnum.Positive)
+    m.test_enum_to_long_long(m.ScopedBoolEnum.TRUE)
+
+
+def test_duplicate_enum_name():
+    with pytest.raises(ValueError) as excinfo:
+        m.register_bad_enum()
+    assert str(excinfo.value) == 'SimpleEnum: element "ONE" already exists!'
+
+
+def test_char_underlying_enum():  # Issue #1331/PR #1334:
+    assert type(m.ScopedCharEnum.Positive.__int__()) is int
+    assert int(m.ScopedChar16Enum.Zero) == 0
+    assert hash(m.ScopedChar32Enum.Positive) == 1
+    assert type(m.ScopedCharEnum.Positive.__getstate__()) is int
+    assert m.ScopedWCharEnum(1) == m.ScopedWCharEnum.Positive
+    with pytest.raises(TypeError):
+        # Even if the underlying type is char, only an int can be used to construct the enum:
+        m.ScopedCharEnum("0")
+
+
+def test_bool_underlying_enum():
+    assert type(m.ScopedBoolEnum.TRUE.__int__()) is int
+    assert int(m.ScopedBoolEnum.FALSE) == 0
+    assert hash(m.ScopedBoolEnum.TRUE) == 1
+    assert type(m.ScopedBoolEnum.TRUE.__getstate__()) is int
+    assert m.ScopedBoolEnum(1) == m.ScopedBoolEnum.TRUE
+    # Enum could construct with a bool
+    # (bool is a strict subclass of int, and False will be converted to 0)
+    assert m.ScopedBoolEnum(False) == m.ScopedBoolEnum.FALSE
+
+
+def test_docstring_signatures():
+    for enum_type in [m.ScopedEnum, m.UnscopedEnum]:
+        for attr in enum_type.__dict__.values():
+            # Issue #2623/PR #2637: Add argument names to enum_ methods
+            assert "arg0" not in (attr.__doc__ or "")
+
+
+def test_str_signature():
+    for enum_type in [m.ScopedEnum, m.UnscopedEnum]:
+        assert enum_type.__str__.__doc__.startswith("__str__")
```

## extern/pybind11/tests/test_eval.py

 * *Ordering differences only*

```diff
@@ -1,50 +1,50 @@
-import os
-
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import eval_ as m
-
-
-def test_evals(capture):
-    with capture:
-        assert m.test_eval_statements()
-    assert capture == "Hello World!"
-
-    assert m.test_eval()
-    assert m.test_eval_single_statement()
-
-    assert m.test_eval_failure()
-
-
-@pytest.mark.xfail("env.PYPY", raises=RuntimeError)
-def test_eval_file():
-    filename = os.path.join(os.path.dirname(__file__), "test_eval_call.py")
-    assert m.test_eval_file(filename)
-
-    assert m.test_eval_file_failure()
-
-
-def test_eval_empty_globals():
-    assert "__builtins__" in m.eval_empty_globals(None)
-
-    g = {}
-    assert "__builtins__" in m.eval_empty_globals(g)
-    assert "__builtins__" in g
-
-
-def test_eval_closure():
-    global_, local = m.test_eval_closure()
-
-    assert global_["closure_value"] == 42
-    assert local["closure_value"] == 0
-
-    assert "local_value" not in global_
-    assert local["local_value"] == 0
-
-    assert "func_global" not in global_
-    assert local["func_global"]() == 42
-
-    assert "func_local" not in global_
-    with pytest.raises(NameError):
-        local["func_local"]()
+import os
+
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import eval_ as m
+
+
+def test_evals(capture):
+    with capture:
+        assert m.test_eval_statements()
+    assert capture == "Hello World!"
+
+    assert m.test_eval()
+    assert m.test_eval_single_statement()
+
+    assert m.test_eval_failure()
+
+
+@pytest.mark.xfail("env.PYPY", raises=RuntimeError)
+def test_eval_file():
+    filename = os.path.join(os.path.dirname(__file__), "test_eval_call.py")
+    assert m.test_eval_file(filename)
+
+    assert m.test_eval_file_failure()
+
+
+def test_eval_empty_globals():
+    assert "__builtins__" in m.eval_empty_globals(None)
+
+    g = {}
+    assert "__builtins__" in m.eval_empty_globals(g)
+    assert "__builtins__" in g
+
+
+def test_eval_closure():
+    global_, local = m.test_eval_closure()
+
+    assert global_["closure_value"] == 42
+    assert local["closure_value"] == 0
+
+    assert "local_value" not in global_
+    assert local["local_value"] == 0
+
+    assert "func_global" not in global_
+    assert local["func_global"]() == 42
+
+    assert "func_local" not in global_
+    with pytest.raises(NameError):
+        local["func_local"]()
```

## extern/pybind11/tests/test_eval_call.py

 * *Ordering differences only*

```diff
@@ -1,4 +1,4 @@
-# This file is called from 'test_eval.py'
-
-if "call_test2" in locals():
-    call_test2(y)  # noqa: F821 undefined name
+# This file is called from 'test_eval.py'
+
+if "call_test2" in locals():
+    call_test2(y)  # noqa: F821 undefined name
```

## extern/pybind11/tests/test_exceptions.py

 * *Ordering differences only*

```diff
@@ -1,421 +1,421 @@
-import sys
-
-import pytest
-
-import env
-import pybind11_cross_module_tests as cm
-import pybind11_tests  # noqa: F401
-from pybind11_tests import exceptions as m
-
-
-def test_std_exception(msg):
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throw_std_exception()
-    assert msg(excinfo.value) == "This exception was intentionally thrown."
-
-
-def test_error_already_set(msg):
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throw_already_set(False)
-    assert (
-        msg(excinfo.value)
-        == "Internal error: pybind11::error_already_set called while Python error indicator not set."
-    )
-
-    with pytest.raises(ValueError) as excinfo:
-        m.throw_already_set(True)
-    assert msg(excinfo.value) == "foo"
-
-
-def test_raise_from(msg):
-    with pytest.raises(ValueError) as excinfo:
-        m.raise_from()
-    assert msg(excinfo.value) == "outer"
-    assert msg(excinfo.value.__cause__) == "inner"
-
-
-def test_raise_from_already_set(msg):
-    with pytest.raises(ValueError) as excinfo:
-        m.raise_from_already_set()
-    assert msg(excinfo.value) == "outer"
-    assert msg(excinfo.value.__cause__) == "inner"
-
-
-def test_cross_module_exceptions(msg):
-    with pytest.raises(RuntimeError) as excinfo:
-        cm.raise_runtime_error()
-    assert str(excinfo.value) == "My runtime error"
-
-    with pytest.raises(ValueError) as excinfo:
-        cm.raise_value_error()
-    assert str(excinfo.value) == "My value error"
-
-    with pytest.raises(ValueError) as excinfo:
-        cm.throw_pybind_value_error()
-    assert str(excinfo.value) == "pybind11 value error"
-
-    with pytest.raises(TypeError) as excinfo:
-        cm.throw_pybind_type_error()
-    assert str(excinfo.value) == "pybind11 type error"
-
-    with pytest.raises(StopIteration) as excinfo:
-        cm.throw_stop_iteration()
-
-    with pytest.raises(cm.LocalSimpleException) as excinfo:
-        cm.throw_local_simple_error()
-    assert msg(excinfo.value) == "external mod"
-
-    with pytest.raises(KeyError) as excinfo:
-        cm.throw_local_error()
-    # KeyError is a repr of the key, so it has an extra set of quotes
-    assert str(excinfo.value) == "'just local'"
-
-
-# TODO: FIXME
-@pytest.mark.xfail(
-    "env.MACOS and (env.PYPY or pybind11_tests.compiler_info.startswith('Homebrew Clang'))",
-    raises=RuntimeError,
-    reason="See Issue #2847, PR #2999, PR #4324",
-)
-def test_cross_module_exception_translator():
-    with pytest.raises(KeyError):
-        # translator registered in cross_module_tests
-        m.throw_should_be_translated_to_key_error()
-
-
-def test_python_call_in_catch():
-    d = {}
-    assert m.python_call_in_destructor(d) is True
-    assert d["good"] is True
-
-
-def ignore_pytest_unraisable_warning(f):
-    unraisable = "PytestUnraisableExceptionWarning"
-    if hasattr(pytest, unraisable):  # Python >= 3.8 and pytest >= 6
-        dec = pytest.mark.filterwarnings(f"ignore::pytest.{unraisable}")
-        return dec(f)
-    return f
-
-
-# TODO: find out why this fails on PyPy, https://foss.heptapod.net/pypy/pypy/-/issues/3583
-@pytest.mark.xfail(env.PYPY, reason="Failure on PyPy 3.8 (7.3.7)", strict=False)
-@ignore_pytest_unraisable_warning
-def test_python_alreadyset_in_destructor(monkeypatch, capsys):
-    hooked = False
-    triggered = False
-
-    if hasattr(sys, "unraisablehook"):  # Python 3.8+
-        hooked = True
-        # Don't take `sys.unraisablehook`, as that's overwritten by pytest
-        default_hook = sys.__unraisablehook__
-
-        def hook(unraisable_hook_args):
-            exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
-            if obj == "already_set demo":
-                nonlocal triggered
-                triggered = True
-            default_hook(unraisable_hook_args)
-            return
-
-        # Use monkeypatch so pytest can apply and remove the patch as appropriate
-        monkeypatch.setattr(sys, "unraisablehook", hook)
-
-    assert m.python_alreadyset_in_destructor("already_set demo") is True
-    if hooked:
-        assert triggered is True
-
-    _, captured_stderr = capsys.readouterr()
-    assert captured_stderr.startswith("Exception ignored in: 'already_set demo'")
-    assert captured_stderr.rstrip().endswith("KeyError: 'bar'")
-
-
-def test_exception_matches():
-    assert m.exception_matches()
-    assert m.exception_matches_base()
-    assert m.modulenotfound_exception_matches_base()
-
-
-def test_custom(msg):
-    # Can we catch a MyException?
-    with pytest.raises(m.MyException) as excinfo:
-        m.throws1()
-    assert msg(excinfo.value) == "this error should go to py::exception<MyException>"
-
-    # Can we catch a MyExceptionUseDeprecatedOperatorCall?
-    with pytest.raises(m.MyExceptionUseDeprecatedOperatorCall) as excinfo:
-        m.throws1d()
-    assert (
-        msg(excinfo.value)
-        == "this error should go to py::exception<MyExceptionUseDeprecatedOperatorCall>"
-    )
-
-    # Can we translate to standard Python exceptions?
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throws2()
-    assert msg(excinfo.value) == "this error should go to a standard Python exception"
-
-    # Can we handle unknown exceptions?
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throws3()
-    assert msg(excinfo.value) == "Caught an unknown exception!"
-
-    # Can we delegate to another handler by rethrowing?
-    with pytest.raises(m.MyException) as excinfo:
-        m.throws4()
-    assert msg(excinfo.value) == "this error is rethrown"
-
-    # Can we fall-through to the default handler?
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throws_logic_error()
-    assert (
-        msg(excinfo.value) == "this error should fall through to the standard handler"
-    )
-
-    # OverFlow error translation.
-    with pytest.raises(OverflowError) as excinfo:
-        m.throws_overflow_error()
-
-    # Can we handle a helper-declared exception?
-    with pytest.raises(m.MyException5) as excinfo:
-        m.throws5()
-    assert msg(excinfo.value) == "this is a helper-defined translated exception"
-
-    # Exception subclassing:
-    with pytest.raises(m.MyException5) as excinfo:
-        m.throws5_1()
-    assert msg(excinfo.value) == "MyException5 subclass"
-    assert isinstance(excinfo.value, m.MyException5_1)
-
-    with pytest.raises(m.MyException5_1) as excinfo:
-        m.throws5_1()
-    assert msg(excinfo.value) == "MyException5 subclass"
-
-    with pytest.raises(m.MyException5) as excinfo:  # noqa: PT012
-        try:
-            m.throws5()
-        except m.MyException5_1 as err:
-            raise RuntimeError("Exception error: caught child from parent") from err
-    assert msg(excinfo.value) == "this is a helper-defined translated exception"
-
-
-def test_nested_throws(capture):
-    """Tests nested (e.g. C++ -> Python -> C++) exception handling"""
-
-    def throw_myex():
-        raise m.MyException("nested error")
-
-    def throw_myex5():
-        raise m.MyException5("nested error 5")
-
-    # In the comments below, the exception is caught in the first step, thrown in the last step
-
-    # C++ -> Python
-    with capture:
-        m.try_catch(m.MyException5, throw_myex5)
-    assert str(capture).startswith("MyException5: nested error 5")
-
-    # Python -> C++ -> Python
-    with pytest.raises(m.MyException) as excinfo:
-        m.try_catch(m.MyException5, throw_myex)
-    assert str(excinfo.value) == "nested error"
-
-    def pycatch(exctype, f, *args):  # noqa: ARG001
-        try:
-            f(*args)
-        except m.MyException as e:
-            print(e)
-
-    # C++ -> Python -> C++ -> Python
-    with capture:
-        m.try_catch(
-            m.MyException5,
-            pycatch,
-            m.MyException,
-            m.try_catch,
-            m.MyException,
-            throw_myex5,
-        )
-    assert str(capture).startswith("MyException5: nested error 5")
-
-    # C++ -> Python -> C++
-    with capture:
-        m.try_catch(m.MyException, pycatch, m.MyException5, m.throws4)
-    assert capture == "this error is rethrown"
-
-    # Python -> C++ -> Python -> C++
-    with pytest.raises(m.MyException5) as excinfo:
-        m.try_catch(m.MyException, pycatch, m.MyException, m.throws5)
-    assert str(excinfo.value) == "this is a helper-defined translated exception"
-
-
-def test_throw_nested_exception():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throw_nested_exception()
-    assert str(excinfo.value) == "Outer Exception"
-    assert str(excinfo.value.__cause__) == "Inner Exception"
-
-
-# This can often happen if you wrap a pybind11 class in a Python wrapper
-def test_invalid_repr():
-    class MyRepr:
-        def __repr__(self):
-            raise AttributeError("Example error")
-
-    with pytest.raises(TypeError):
-        m.simple_bool_passthrough(MyRepr())
-
-
-def test_local_translator(msg):
-    """Tests that a local translator works and that the local translator from
-    the cross module is not applied"""
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throws6()
-    assert msg(excinfo.value) == "MyException6 only handled in this module"
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.throws_local_error()
-    assert not isinstance(excinfo.value, KeyError)
-    assert msg(excinfo.value) == "never caught"
-
-    with pytest.raises(Exception) as excinfo:
-        m.throws_local_simple_error()
-    assert not isinstance(excinfo.value, cm.LocalSimpleException)
-    assert msg(excinfo.value) == "this mod"
-
-
-def test_error_already_set_message_with_unicode_surrogate():  # Issue #4288
-    assert m.error_already_set_what(RuntimeError, "\ud927") == (
-        "RuntimeError: \\ud927",
-        False,
-    )
-
-
-def test_error_already_set_message_with_malformed_utf8():
-    assert m.error_already_set_what(RuntimeError, b"\x80") == (
-        "RuntimeError: b'\\x80'",
-        False,
-    )
-
-
-class FlakyException(Exception):
-    def __init__(self, failure_point):
-        if failure_point == "failure_point_init":
-            raise ValueError("triggered_failure_point_init")
-        self.failure_point = failure_point
-
-    def __str__(self):
-        if self.failure_point == "failure_point_str":
-            raise ValueError("triggered_failure_point_str")
-        return "FlakyException.__str__"
-
-
-@pytest.mark.parametrize(
-    ("exc_type", "exc_value", "expected_what"),
-    [
-        (ValueError, "plain_str", "ValueError: plain_str"),
-        (ValueError, ("tuple_elem",), "ValueError: tuple_elem"),
-        (FlakyException, ("happy",), "FlakyException: FlakyException.__str__"),
-    ],
-)
-def test_error_already_set_what_with_happy_exceptions(
-    exc_type, exc_value, expected_what
-):
-    what, py_err_set_after_what = m.error_already_set_what(exc_type, exc_value)
-    assert not py_err_set_after_what
-    assert what == expected_what
-
-
-def _test_flaky_exception_failure_point_init_before_py_3_12():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.error_already_set_what(FlakyException, ("failure_point_init",))
-    lines = str(excinfo.value).splitlines()
-    # PyErr_NormalizeException replaces the original FlakyException with ValueError:
-    assert lines[:3] == [
-        "pybind11::error_already_set: MISMATCH of original and normalized active exception types:"
-        " ORIGINAL FlakyException REPLACED BY ValueError: triggered_failure_point_init",
-        "",
-        "At:",
-    ]
-    # Checking the first two lines of the traceback as formatted in error_string():
-    assert "test_exceptions.py(" in lines[3]
-    assert lines[3].endswith("): __init__")
-    assert lines[4].endswith(
-        "): _test_flaky_exception_failure_point_init_before_py_3_12"
-    )
-
-
-def _test_flaky_exception_failure_point_init_py_3_12():
-    # Behavior change in Python 3.12: https://github.com/python/cpython/issues/102594
-    what, py_err_set_after_what = m.error_already_set_what(
-        FlakyException, ("failure_point_init",)
-    )
-    assert not py_err_set_after_what
-    lines = what.splitlines()
-    assert lines[0].endswith("ValueError[WITH __notes__]: triggered_failure_point_init")
-    assert lines[1] == "__notes__ (len=1):"
-    assert "Normalization failed:" in lines[2]
-    assert "FlakyException" in lines[2]
-
-
-@pytest.mark.skipif(
-    "env.PYPY and sys.version_info[:2] < (3, 12)",
-    reason="PyErr_NormalizeException Segmentation fault",
-)
-def test_flaky_exception_failure_point_init():
-    if sys.version_info[:2] < (3, 12):
-        _test_flaky_exception_failure_point_init_before_py_3_12()
-    else:
-        _test_flaky_exception_failure_point_init_py_3_12()
-
-
-def test_flaky_exception_failure_point_str():
-    what, py_err_set_after_what = m.error_already_set_what(
-        FlakyException, ("failure_point_str",)
-    )
-    assert not py_err_set_after_what
-    lines = what.splitlines()
-    n = 3 if env.PYPY and len(lines) == 3 else 5
-    assert (
-        lines[:n]
-        == [
-            "FlakyException: <MESSAGE UNAVAILABLE DUE TO ANOTHER EXCEPTION>",
-            "",
-            "MESSAGE UNAVAILABLE DUE TO EXCEPTION: ValueError: triggered_failure_point_str",
-            "",
-            "At:",
-        ][:n]
-    )
-
-
-def test_cross_module_interleaved_error_already_set():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.test_cross_module_interleaved_error_already_set()
-    assert str(excinfo.value) in (
-        "2nd error.",  # Almost all platforms.
-        "RuntimeError: 2nd error.",  # Some PyPy builds (seen under macOS).
-    )
-
-
-def test_error_already_set_double_restore():
-    m.test_error_already_set_double_restore(True)  # dry_run
-    with pytest.raises(RuntimeError) as excinfo:
-        m.test_error_already_set_double_restore(False)
-    assert str(excinfo.value) == (
-        "Internal error: pybind11::detail::error_fetch_and_normalize::restore()"
-        " called a second time. ORIGINAL ERROR: ValueError: Random error."
-    )
-
-
-def test_pypy_oserror_normalization():
-    # https://github.com/pybind/pybind11/issues/4075
-    what = m.test_pypy_oserror_normalization()
-    assert "this_filename_must_not_exist" in what
-
-
-def test_fn_cast_int_exception():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.test_fn_cast_int(lambda: None)
-
-    assert str(excinfo.value).startswith(
-        "Unable to cast Python instance of type <class 'NoneType'> to C++ type"
-    )
+import sys
+
+import pytest
+
+import env
+import pybind11_cross_module_tests as cm
+import pybind11_tests  # noqa: F401
+from pybind11_tests import exceptions as m
+
+
+def test_std_exception(msg):
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throw_std_exception()
+    assert msg(excinfo.value) == "This exception was intentionally thrown."
+
+
+def test_error_already_set(msg):
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throw_already_set(False)
+    assert (
+        msg(excinfo.value)
+        == "Internal error: pybind11::error_already_set called while Python error indicator not set."
+    )
+
+    with pytest.raises(ValueError) as excinfo:
+        m.throw_already_set(True)
+    assert msg(excinfo.value) == "foo"
+
+
+def test_raise_from(msg):
+    with pytest.raises(ValueError) as excinfo:
+        m.raise_from()
+    assert msg(excinfo.value) == "outer"
+    assert msg(excinfo.value.__cause__) == "inner"
+
+
+def test_raise_from_already_set(msg):
+    with pytest.raises(ValueError) as excinfo:
+        m.raise_from_already_set()
+    assert msg(excinfo.value) == "outer"
+    assert msg(excinfo.value.__cause__) == "inner"
+
+
+def test_cross_module_exceptions(msg):
+    with pytest.raises(RuntimeError) as excinfo:
+        cm.raise_runtime_error()
+    assert str(excinfo.value) == "My runtime error"
+
+    with pytest.raises(ValueError) as excinfo:
+        cm.raise_value_error()
+    assert str(excinfo.value) == "My value error"
+
+    with pytest.raises(ValueError) as excinfo:
+        cm.throw_pybind_value_error()
+    assert str(excinfo.value) == "pybind11 value error"
+
+    with pytest.raises(TypeError) as excinfo:
+        cm.throw_pybind_type_error()
+    assert str(excinfo.value) == "pybind11 type error"
+
+    with pytest.raises(StopIteration) as excinfo:
+        cm.throw_stop_iteration()
+
+    with pytest.raises(cm.LocalSimpleException) as excinfo:
+        cm.throw_local_simple_error()
+    assert msg(excinfo.value) == "external mod"
+
+    with pytest.raises(KeyError) as excinfo:
+        cm.throw_local_error()
+    # KeyError is a repr of the key, so it has an extra set of quotes
+    assert str(excinfo.value) == "'just local'"
+
+
+# TODO: FIXME
+@pytest.mark.xfail(
+    "env.MACOS and (env.PYPY or pybind11_tests.compiler_info.startswith('Homebrew Clang'))",
+    raises=RuntimeError,
+    reason="See Issue #2847, PR #2999, PR #4324",
+)
+def test_cross_module_exception_translator():
+    with pytest.raises(KeyError):
+        # translator registered in cross_module_tests
+        m.throw_should_be_translated_to_key_error()
+
+
+def test_python_call_in_catch():
+    d = {}
+    assert m.python_call_in_destructor(d) is True
+    assert d["good"] is True
+
+
+def ignore_pytest_unraisable_warning(f):
+    unraisable = "PytestUnraisableExceptionWarning"
+    if hasattr(pytest, unraisable):  # Python >= 3.8 and pytest >= 6
+        dec = pytest.mark.filterwarnings(f"ignore::pytest.{unraisable}")
+        return dec(f)
+    return f
+
+
+# TODO: find out why this fails on PyPy, https://foss.heptapod.net/pypy/pypy/-/issues/3583
+@pytest.mark.xfail(env.PYPY, reason="Failure on PyPy 3.8 (7.3.7)", strict=False)
+@ignore_pytest_unraisable_warning
+def test_python_alreadyset_in_destructor(monkeypatch, capsys):
+    hooked = False
+    triggered = False
+
+    if hasattr(sys, "unraisablehook"):  # Python 3.8+
+        hooked = True
+        # Don't take `sys.unraisablehook`, as that's overwritten by pytest
+        default_hook = sys.__unraisablehook__
+
+        def hook(unraisable_hook_args):
+            exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
+            if obj == "already_set demo":
+                nonlocal triggered
+                triggered = True
+            default_hook(unraisable_hook_args)
+            return
+
+        # Use monkeypatch so pytest can apply and remove the patch as appropriate
+        monkeypatch.setattr(sys, "unraisablehook", hook)
+
+    assert m.python_alreadyset_in_destructor("already_set demo") is True
+    if hooked:
+        assert triggered is True
+
+    _, captured_stderr = capsys.readouterr()
+    assert captured_stderr.startswith("Exception ignored in: 'already_set demo'")
+    assert captured_stderr.rstrip().endswith("KeyError: 'bar'")
+
+
+def test_exception_matches():
+    assert m.exception_matches()
+    assert m.exception_matches_base()
+    assert m.modulenotfound_exception_matches_base()
+
+
+def test_custom(msg):
+    # Can we catch a MyException?
+    with pytest.raises(m.MyException) as excinfo:
+        m.throws1()
+    assert msg(excinfo.value) == "this error should go to py::exception<MyException>"
+
+    # Can we catch a MyExceptionUseDeprecatedOperatorCall?
+    with pytest.raises(m.MyExceptionUseDeprecatedOperatorCall) as excinfo:
+        m.throws1d()
+    assert (
+        msg(excinfo.value)
+        == "this error should go to py::exception<MyExceptionUseDeprecatedOperatorCall>"
+    )
+
+    # Can we translate to standard Python exceptions?
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throws2()
+    assert msg(excinfo.value) == "this error should go to a standard Python exception"
+
+    # Can we handle unknown exceptions?
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throws3()
+    assert msg(excinfo.value) == "Caught an unknown exception!"
+
+    # Can we delegate to another handler by rethrowing?
+    with pytest.raises(m.MyException) as excinfo:
+        m.throws4()
+    assert msg(excinfo.value) == "this error is rethrown"
+
+    # Can we fall-through to the default handler?
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throws_logic_error()
+    assert (
+        msg(excinfo.value) == "this error should fall through to the standard handler"
+    )
+
+    # OverFlow error translation.
+    with pytest.raises(OverflowError) as excinfo:
+        m.throws_overflow_error()
+
+    # Can we handle a helper-declared exception?
+    with pytest.raises(m.MyException5) as excinfo:
+        m.throws5()
+    assert msg(excinfo.value) == "this is a helper-defined translated exception"
+
+    # Exception subclassing:
+    with pytest.raises(m.MyException5) as excinfo:
+        m.throws5_1()
+    assert msg(excinfo.value) == "MyException5 subclass"
+    assert isinstance(excinfo.value, m.MyException5_1)
+
+    with pytest.raises(m.MyException5_1) as excinfo:
+        m.throws5_1()
+    assert msg(excinfo.value) == "MyException5 subclass"
+
+    with pytest.raises(m.MyException5) as excinfo:  # noqa: PT012
+        try:
+            m.throws5()
+        except m.MyException5_1 as err:
+            raise RuntimeError("Exception error: caught child from parent") from err
+    assert msg(excinfo.value) == "this is a helper-defined translated exception"
+
+
+def test_nested_throws(capture):
+    """Tests nested (e.g. C++ -> Python -> C++) exception handling"""
+
+    def throw_myex():
+        raise m.MyException("nested error")
+
+    def throw_myex5():
+        raise m.MyException5("nested error 5")
+
+    # In the comments below, the exception is caught in the first step, thrown in the last step
+
+    # C++ -> Python
+    with capture:
+        m.try_catch(m.MyException5, throw_myex5)
+    assert str(capture).startswith("MyException5: nested error 5")
+
+    # Python -> C++ -> Python
+    with pytest.raises(m.MyException) as excinfo:
+        m.try_catch(m.MyException5, throw_myex)
+    assert str(excinfo.value) == "nested error"
+
+    def pycatch(exctype, f, *args):  # noqa: ARG001
+        try:
+            f(*args)
+        except m.MyException as e:
+            print(e)
+
+    # C++ -> Python -> C++ -> Python
+    with capture:
+        m.try_catch(
+            m.MyException5,
+            pycatch,
+            m.MyException,
+            m.try_catch,
+            m.MyException,
+            throw_myex5,
+        )
+    assert str(capture).startswith("MyException5: nested error 5")
+
+    # C++ -> Python -> C++
+    with capture:
+        m.try_catch(m.MyException, pycatch, m.MyException5, m.throws4)
+    assert capture == "this error is rethrown"
+
+    # Python -> C++ -> Python -> C++
+    with pytest.raises(m.MyException5) as excinfo:
+        m.try_catch(m.MyException, pycatch, m.MyException, m.throws5)
+    assert str(excinfo.value) == "this is a helper-defined translated exception"
+
+
+def test_throw_nested_exception():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throw_nested_exception()
+    assert str(excinfo.value) == "Outer Exception"
+    assert str(excinfo.value.__cause__) == "Inner Exception"
+
+
+# This can often happen if you wrap a pybind11 class in a Python wrapper
+def test_invalid_repr():
+    class MyRepr:
+        def __repr__(self):
+            raise AttributeError("Example error")
+
+    with pytest.raises(TypeError):
+        m.simple_bool_passthrough(MyRepr())
+
+
+def test_local_translator(msg):
+    """Tests that a local translator works and that the local translator from
+    the cross module is not applied"""
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throws6()
+    assert msg(excinfo.value) == "MyException6 only handled in this module"
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.throws_local_error()
+    assert not isinstance(excinfo.value, KeyError)
+    assert msg(excinfo.value) == "never caught"
+
+    with pytest.raises(Exception) as excinfo:
+        m.throws_local_simple_error()
+    assert not isinstance(excinfo.value, cm.LocalSimpleException)
+    assert msg(excinfo.value) == "this mod"
+
+
+def test_error_already_set_message_with_unicode_surrogate():  # Issue #4288
+    assert m.error_already_set_what(RuntimeError, "\ud927") == (
+        "RuntimeError: \\ud927",
+        False,
+    )
+
+
+def test_error_already_set_message_with_malformed_utf8():
+    assert m.error_already_set_what(RuntimeError, b"\x80") == (
+        "RuntimeError: b'\\x80'",
+        False,
+    )
+
+
+class FlakyException(Exception):
+    def __init__(self, failure_point):
+        if failure_point == "failure_point_init":
+            raise ValueError("triggered_failure_point_init")
+        self.failure_point = failure_point
+
+    def __str__(self):
+        if self.failure_point == "failure_point_str":
+            raise ValueError("triggered_failure_point_str")
+        return "FlakyException.__str__"
+
+
+@pytest.mark.parametrize(
+    ("exc_type", "exc_value", "expected_what"),
+    [
+        (ValueError, "plain_str", "ValueError: plain_str"),
+        (ValueError, ("tuple_elem",), "ValueError: tuple_elem"),
+        (FlakyException, ("happy",), "FlakyException: FlakyException.__str__"),
+    ],
+)
+def test_error_already_set_what_with_happy_exceptions(
+    exc_type, exc_value, expected_what
+):
+    what, py_err_set_after_what = m.error_already_set_what(exc_type, exc_value)
+    assert not py_err_set_after_what
+    assert what == expected_what
+
+
+def _test_flaky_exception_failure_point_init_before_py_3_12():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.error_already_set_what(FlakyException, ("failure_point_init",))
+    lines = str(excinfo.value).splitlines()
+    # PyErr_NormalizeException replaces the original FlakyException with ValueError:
+    assert lines[:3] == [
+        "pybind11::error_already_set: MISMATCH of original and normalized active exception types:"
+        " ORIGINAL FlakyException REPLACED BY ValueError: triggered_failure_point_init",
+        "",
+        "At:",
+    ]
+    # Checking the first two lines of the traceback as formatted in error_string():
+    assert "test_exceptions.py(" in lines[3]
+    assert lines[3].endswith("): __init__")
+    assert lines[4].endswith(
+        "): _test_flaky_exception_failure_point_init_before_py_3_12"
+    )
+
+
+def _test_flaky_exception_failure_point_init_py_3_12():
+    # Behavior change in Python 3.12: https://github.com/python/cpython/issues/102594
+    what, py_err_set_after_what = m.error_already_set_what(
+        FlakyException, ("failure_point_init",)
+    )
+    assert not py_err_set_after_what
+    lines = what.splitlines()
+    assert lines[0].endswith("ValueError[WITH __notes__]: triggered_failure_point_init")
+    assert lines[1] == "__notes__ (len=1):"
+    assert "Normalization failed:" in lines[2]
+    assert "FlakyException" in lines[2]
+
+
+@pytest.mark.skipif(
+    "env.PYPY and sys.version_info[:2] < (3, 12)",
+    reason="PyErr_NormalizeException Segmentation fault",
+)
+def test_flaky_exception_failure_point_init():
+    if sys.version_info[:2] < (3, 12):
+        _test_flaky_exception_failure_point_init_before_py_3_12()
+    else:
+        _test_flaky_exception_failure_point_init_py_3_12()
+
+
+def test_flaky_exception_failure_point_str():
+    what, py_err_set_after_what = m.error_already_set_what(
+        FlakyException, ("failure_point_str",)
+    )
+    assert not py_err_set_after_what
+    lines = what.splitlines()
+    n = 3 if env.PYPY and len(lines) == 3 else 5
+    assert (
+        lines[:n]
+        == [
+            "FlakyException: <MESSAGE UNAVAILABLE DUE TO ANOTHER EXCEPTION>",
+            "",
+            "MESSAGE UNAVAILABLE DUE TO EXCEPTION: ValueError: triggered_failure_point_str",
+            "",
+            "At:",
+        ][:n]
+    )
+
+
+def test_cross_module_interleaved_error_already_set():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.test_cross_module_interleaved_error_already_set()
+    assert str(excinfo.value) in (
+        "2nd error.",  # Almost all platforms.
+        "RuntimeError: 2nd error.",  # Some PyPy builds (seen under macOS).
+    )
+
+
+def test_error_already_set_double_restore():
+    m.test_error_already_set_double_restore(True)  # dry_run
+    with pytest.raises(RuntimeError) as excinfo:
+        m.test_error_already_set_double_restore(False)
+    assert str(excinfo.value) == (
+        "Internal error: pybind11::detail::error_fetch_and_normalize::restore()"
+        " called a second time. ORIGINAL ERROR: ValueError: Random error."
+    )
+
+
+def test_pypy_oserror_normalization():
+    # https://github.com/pybind/pybind11/issues/4075
+    what = m.test_pypy_oserror_normalization()
+    assert "this_filename_must_not_exist" in what
+
+
+def test_fn_cast_int_exception():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.test_fn_cast_int(lambda: None)
+
+    assert str(excinfo.value).startswith(
+        "Unable to cast Python instance of type <class 'NoneType'> to C++ type"
+    )
```

## extern/pybind11/tests/test_factory_constructors.py

 * *Ordering differences only*

```diff
@@ -1,516 +1,516 @@
-import re
-
-import pytest
-
-from pybind11_tests import ConstructorStats
-from pybind11_tests import factory_constructors as m
-from pybind11_tests.factory_constructors import tag
-
-
-def test_init_factory_basic():
-    """Tests py::init_factory() wrapper around various ways of returning the object"""
-
-    cstats = [
-        ConstructorStats.get(c)
-        for c in [m.TestFactory1, m.TestFactory2, m.TestFactory3]
-    ]
-    cstats[0].alive()  # force gc
-    n_inst = ConstructorStats.detail_reg_inst()
-
-    x1 = m.TestFactory1(tag.unique_ptr, 3)
-    assert x1.value == "3"
-    y1 = m.TestFactory1(tag.pointer)
-    assert y1.value == "(empty)"
-    z1 = m.TestFactory1("hi!")
-    assert z1.value == "hi!"
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 3
-
-    x2 = m.TestFactory2(tag.move)
-    assert x2.value == "(empty2)"
-    y2 = m.TestFactory2(tag.pointer, 7)
-    assert y2.value == "7"
-    z2 = m.TestFactory2(tag.unique_ptr, "hi again")
-    assert z2.value == "hi again"
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 6
-
-    x3 = m.TestFactory3(tag.shared_ptr)
-    assert x3.value == "(empty3)"
-    y3 = m.TestFactory3(tag.pointer, 42)
-    assert y3.value == "42"
-    z3 = m.TestFactory3("bye")
-    assert z3.value == "bye"
-
-    for null_ptr_kind in [tag.null_ptr, tag.null_unique_ptr, tag.null_shared_ptr]:
-        with pytest.raises(TypeError) as excinfo:
-            m.TestFactory3(null_ptr_kind)
-        assert (
-            str(excinfo.value) == "pybind11::init(): factory function returned nullptr"
-        )
-
-    assert [i.alive() for i in cstats] == [3, 3, 3]
-    assert ConstructorStats.detail_reg_inst() == n_inst + 9
-
-    del x1, y2, y3, z3
-    assert [i.alive() for i in cstats] == [2, 2, 1]
-    assert ConstructorStats.detail_reg_inst() == n_inst + 5
-    del x2, x3, y1, z1, z2
-    assert [i.alive() for i in cstats] == [0, 0, 0]
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-    assert [i.values() for i in cstats] == [
-        ["3", "hi!"],
-        ["7", "hi again"],
-        ["42", "bye"],
-    ]
-    assert [i.default_constructions for i in cstats] == [1, 1, 1]
-
-
-def test_init_factory_signature(msg):
-    with pytest.raises(TypeError) as excinfo:
-        m.TestFactory1("invalid", "constructor", "arguments")
-    assert (
-        msg(excinfo.value)
-        == """
-        __init__(): incompatible constructor arguments. The following argument types are supported:
-            1. m.factory_constructors.TestFactory1(arg0: m.factory_constructors.tag.unique_ptr_tag, arg1: int)
-            2. m.factory_constructors.TestFactory1(arg0: str)
-            3. m.factory_constructors.TestFactory1(arg0: m.factory_constructors.tag.pointer_tag)
-            4. m.factory_constructors.TestFactory1(arg0: object, arg1: int, arg2: object)
-
-        Invoked with: 'invalid', 'constructor', 'arguments'
-    """
-    )
-
-    assert (
-        msg(m.TestFactory1.__init__.__doc__)
-        == """
-        __init__(*args, **kwargs)
-        Overloaded function.
-
-        1. __init__(self: m.factory_constructors.TestFactory1, arg0: m.factory_constructors.tag.unique_ptr_tag, arg1: int) -> None
-
-        2. __init__(self: m.factory_constructors.TestFactory1, arg0: str) -> None
-
-        3. __init__(self: m.factory_constructors.TestFactory1, arg0: m.factory_constructors.tag.pointer_tag) -> None
-
-        4. __init__(self: m.factory_constructors.TestFactory1, arg0: object, arg1: int, arg2: object) -> None
-    """
-    )
-
-
-def test_init_factory_casting():
-    """Tests py::init_factory() wrapper with various upcasting and downcasting returns"""
-
-    cstats = [
-        ConstructorStats.get(c)
-        for c in [m.TestFactory3, m.TestFactory4, m.TestFactory5]
-    ]
-    cstats[0].alive()  # force gc
-    n_inst = ConstructorStats.detail_reg_inst()
-
-    # Construction from derived references:
-    a = m.TestFactory3(tag.pointer, tag.TF4, 4)
-    assert a.value == "4"
-    b = m.TestFactory3(tag.shared_ptr, tag.TF4, 5)
-    assert b.value == "5"
-    c = m.TestFactory3(tag.pointer, tag.TF5, 6)
-    assert c.value == "6"
-    d = m.TestFactory3(tag.shared_ptr, tag.TF5, 7)
-    assert d.value == "7"
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 4
-
-    # Shared a lambda with TF3:
-    e = m.TestFactory4(tag.pointer, tag.TF4, 8)
-    assert e.value == "8"
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 5
-    assert [i.alive() for i in cstats] == [5, 3, 2]
-
-    del a
-    assert [i.alive() for i in cstats] == [4, 2, 2]
-    assert ConstructorStats.detail_reg_inst() == n_inst + 4
-
-    del b, c, e
-    assert [i.alive() for i in cstats] == [1, 0, 1]
-    assert ConstructorStats.detail_reg_inst() == n_inst + 1
-
-    del d
-    assert [i.alive() for i in cstats] == [0, 0, 0]
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-    assert [i.values() for i in cstats] == [
-        ["4", "5", "6", "7", "8"],
-        ["4", "5", "8"],
-        ["6", "7"],
-    ]
-
-
-def test_init_factory_alias():
-    """Tests py::init_factory() wrapper with value conversions and alias types"""
-
-    cstats = [m.TestFactory6.get_cstats(), m.TestFactory6.get_alias_cstats()]
-    cstats[0].alive()  # force gc
-    n_inst = ConstructorStats.detail_reg_inst()
-
-    a = m.TestFactory6(tag.base, 1)
-    assert a.get() == 1
-    assert not a.has_alias()
-    b = m.TestFactory6(tag.alias, "hi there")
-    assert b.get() == 8
-    assert b.has_alias()
-    c = m.TestFactory6(tag.alias, 3)
-    assert c.get() == 3
-    assert c.has_alias()
-    d = m.TestFactory6(tag.alias, tag.pointer, 4)
-    assert d.get() == 4
-    assert d.has_alias()
-    e = m.TestFactory6(tag.base, tag.pointer, 5)
-    assert e.get() == 5
-    assert not e.has_alias()
-    f = m.TestFactory6(tag.base, tag.alias, tag.pointer, 6)
-    assert f.get() == 6
-    assert f.has_alias()
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 6
-    assert [i.alive() for i in cstats] == [6, 4]
-
-    del a, b, e
-    assert [i.alive() for i in cstats] == [3, 3]
-    assert ConstructorStats.detail_reg_inst() == n_inst + 3
-    del f, c, d
-    assert [i.alive() for i in cstats] == [0, 0]
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-    class MyTest(m.TestFactory6):
-        def __init__(self, *args):
-            m.TestFactory6.__init__(self, *args)
-
-        def get(self):
-            return -5 + m.TestFactory6.get(self)
-
-    # Return Class by value, moved into new alias:
-    z = MyTest(tag.base, 123)
-    assert z.get() == 118
-    assert z.has_alias()
-
-    # Return alias by value, moved into new alias:
-    y = MyTest(tag.alias, "why hello!")
-    assert y.get() == 5
-    assert y.has_alias()
-
-    # Return Class by pointer, moved into new alias then original destroyed:
-    x = MyTest(tag.base, tag.pointer, 47)
-    assert x.get() == 42
-    assert x.has_alias()
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 3
-    assert [i.alive() for i in cstats] == [3, 3]
-    del x, y, z
-    assert [i.alive() for i in cstats] == [0, 0]
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-    assert [i.values() for i in cstats] == [
-        ["1", "8", "3", "4", "5", "6", "123", "10", "47"],
-        ["hi there", "3", "4", "6", "move", "123", "why hello!", "move", "47"],
-    ]
-
-
-def test_init_factory_dual():
-    """Tests init factory functions with dual main/alias factory functions"""
-    from pybind11_tests.factory_constructors import TestFactory7
-
-    cstats = [TestFactory7.get_cstats(), TestFactory7.get_alias_cstats()]
-    cstats[0].alive()  # force gc
-    n_inst = ConstructorStats.detail_reg_inst()
-
-    class PythFactory7(TestFactory7):
-        def get(self):
-            return 100 + TestFactory7.get(self)
-
-    a1 = TestFactory7(1)
-    a2 = PythFactory7(2)
-    assert a1.get() == 1
-    assert a2.get() == 102
-    assert not a1.has_alias()
-    assert a2.has_alias()
-
-    b1 = TestFactory7(tag.pointer, 3)
-    b2 = PythFactory7(tag.pointer, 4)
-    assert b1.get() == 3
-    assert b2.get() == 104
-    assert not b1.has_alias()
-    assert b2.has_alias()
-
-    c1 = TestFactory7(tag.mixed, 5)
-    c2 = PythFactory7(tag.mixed, 6)
-    assert c1.get() == 5
-    assert c2.get() == 106
-    assert not c1.has_alias()
-    assert c2.has_alias()
-
-    d1 = TestFactory7(tag.base, tag.pointer, 7)
-    d2 = PythFactory7(tag.base, tag.pointer, 8)
-    assert d1.get() == 7
-    assert d2.get() == 108
-    assert not d1.has_alias()
-    assert d2.has_alias()
-
-    # Both return an alias; the second multiplies the value by 10:
-    e1 = TestFactory7(tag.alias, tag.pointer, 9)
-    e2 = PythFactory7(tag.alias, tag.pointer, 10)
-    assert e1.get() == 9
-    assert e2.get() == 200
-    assert e1.has_alias()
-    assert e2.has_alias()
-
-    f1 = TestFactory7(tag.shared_ptr, tag.base, 11)
-    f2 = PythFactory7(tag.shared_ptr, tag.base, 12)
-    assert f1.get() == 11
-    assert f2.get() == 112
-    assert not f1.has_alias()
-    assert f2.has_alias()
-
-    g1 = TestFactory7(tag.shared_ptr, tag.invalid_base, 13)
-    assert g1.get() == 13
-    assert not g1.has_alias()
-    with pytest.raises(TypeError) as excinfo:
-        PythFactory7(tag.shared_ptr, tag.invalid_base, 14)
-    assert (
-        str(excinfo.value)
-        == "pybind11::init(): construction failed: returned holder-wrapped instance is not an "
-        "alias instance"
-    )
-
-    assert [i.alive() for i in cstats] == [13, 7]
-    assert ConstructorStats.detail_reg_inst() == n_inst + 13
-
-    del a1, a2, b1, d1, e1, e2
-    assert [i.alive() for i in cstats] == [7, 4]
-    assert ConstructorStats.detail_reg_inst() == n_inst + 7
-    del b2, c1, c2, d2, f1, f2, g1
-    assert [i.alive() for i in cstats] == [0, 0]
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-    assert [i.values() for i in cstats] == [
-        ["1", "2", "3", "4", "5", "6", "7", "8", "9", "100", "11", "12", "13", "14"],
-        ["2", "4", "6", "8", "9", "100", "12"],
-    ]
-
-
-def test_no_placement_new(capture):
-    """Prior to 2.2, `py::init<...>` relied on the type supporting placement
-    new; this tests a class without placement new support."""
-    with capture:
-        a = m.NoPlacementNew(123)
-
-    found = re.search(r"^operator new called, returning (\d+)\n$", str(capture))
-    assert found
-    assert a.i == 123
-    with capture:
-        del a
-        pytest.gc_collect()
-    assert capture == "operator delete called on " + found.group(1)
-
-    with capture:
-        b = m.NoPlacementNew()
-
-    found = re.search(r"^operator new called, returning (\d+)\n$", str(capture))
-    assert found
-    assert b.i == 100
-    with capture:
-        del b
-        pytest.gc_collect()
-    assert capture == "operator delete called on " + found.group(1)
-
-
-def test_multiple_inheritance():
-    class MITest(m.TestFactory1, m.TestFactory2):
-        def __init__(self):
-            m.TestFactory1.__init__(self, tag.unique_ptr, 33)
-            m.TestFactory2.__init__(self, tag.move)
-
-    a = MITest()
-    assert m.TestFactory1.value.fget(a) == "33"
-    assert m.TestFactory2.value.fget(a) == "(empty2)"
-
-
-def create_and_destroy(*args):
-    a = m.NoisyAlloc(*args)
-    print("---")
-    del a
-    pytest.gc_collect()
-
-
-def strip_comments(s):
-    return re.sub(r"\s+#.*", "", s)
-
-
-def test_reallocation_a(capture, msg):
-    """When the constructor is overloaded, previous overloads can require a preallocated value.
-    This test makes sure that such preallocated values only happen when they might be necessary,
-    and that they are deallocated properly."""
-
-    pytest.gc_collect()
-
-    with capture:
-        create_and_destroy(1)
-    assert (
-        msg(capture)
-        == """
-        noisy new
-        noisy placement new
-        NoisyAlloc(int 1)
-        ---
-        ~NoisyAlloc()
-        noisy delete
-    """
-    )
-
-
-def test_reallocation_b(capture, msg):
-    with capture:
-        create_and_destroy(1.5)
-    assert msg(capture) == strip_comments(
-        """
-        noisy new               # allocation required to attempt first overload
-        noisy delete            # have to dealloc before considering factory init overload
-        noisy new               # pointer factory calling "new", part 1: allocation
-        NoisyAlloc(double 1.5)  # ... part two, invoking constructor
-        ---
-        ~NoisyAlloc()  # Destructor
-        noisy delete   # operator delete
-    """
-    )
-
-
-def test_reallocation_c(capture, msg):
-    with capture:
-        create_and_destroy(2, 3)
-    assert msg(capture) == strip_comments(
-        """
-        noisy new          # pointer factory calling "new", allocation
-        NoisyAlloc(int 2)  # constructor
-        ---
-        ~NoisyAlloc()  # Destructor
-        noisy delete   # operator delete
-    """
-    )
-
-
-def test_reallocation_d(capture, msg):
-    with capture:
-        create_and_destroy(2.5, 3)
-    assert msg(capture) == strip_comments(
-        """
-        NoisyAlloc(double 2.5)  # construction (local func variable: operator_new not called)
-        noisy new               # return-by-value "new" part 1: allocation
-        ~NoisyAlloc()           # moved-away local func variable destruction
-        ---
-        ~NoisyAlloc()  # Destructor
-        noisy delete   # operator delete
-    """
-    )
-
-
-def test_reallocation_e(capture, msg):
-    with capture:
-        create_and_destroy(3.5, 4.5)
-    assert msg(capture) == strip_comments(
-        """
-        noisy new               # preallocation needed before invoking placement-new overload
-        noisy placement new     # Placement new
-        NoisyAlloc(double 3.5)  # construction
-        ---
-        ~NoisyAlloc()  # Destructor
-        noisy delete   # operator delete
-    """
-    )
-
-
-def test_reallocation_f(capture, msg):
-    with capture:
-        create_and_destroy(4, 0.5)
-    assert msg(capture) == strip_comments(
-        """
-        noisy new          # preallocation needed before invoking placement-new overload
-        noisy delete       # deallocation of preallocated storage
-        noisy new          # Factory pointer allocation
-        NoisyAlloc(int 4)  # factory pointer construction
-        ---
-        ~NoisyAlloc()  # Destructor
-        noisy delete   # operator delete
-    """
-    )
-
-
-def test_reallocation_g(capture, msg):
-    with capture:
-        create_and_destroy(5, "hi")
-    assert msg(capture) == strip_comments(
-        """
-        noisy new            # preallocation needed before invoking first placement new
-        noisy delete         # delete before considering new-style constructor
-        noisy new            # preallocation for second placement new
-        noisy placement new  # Placement new in the second placement new overload
-        NoisyAlloc(int 5)    # construction
-        ---
-        ~NoisyAlloc()  # Destructor
-        noisy delete   # operator delete
-    """
-    )
-
-
-def test_invalid_self():
-    """Tests invocation of the pybind-registered base class with an invalid `self` argument."""
-
-    class NotPybindDerived:
-        pass
-
-    # Attempts to initialize with an invalid type passed as `self`:
-    class BrokenTF1(m.TestFactory1):
-        def __init__(self, bad):
-            if bad == 1:
-                a = m.TestFactory2(tag.pointer, 1)
-                m.TestFactory1.__init__(a, tag.pointer)
-            elif bad == 2:
-                a = NotPybindDerived()
-                m.TestFactory1.__init__(a, tag.pointer)
-
-    # Same as above, but for a class with an alias:
-    class BrokenTF6(m.TestFactory6):
-        def __init__(self, bad):
-            if bad == 0:
-                m.TestFactory6.__init__()
-            elif bad == 1:
-                a = m.TestFactory2(tag.pointer, 1)
-                m.TestFactory6.__init__(a, tag.base, 1)
-            elif bad == 2:
-                a = m.TestFactory2(tag.pointer, 1)
-                m.TestFactory6.__init__(a, tag.alias, 1)
-            elif bad == 3:
-                m.TestFactory6.__init__(
-                    NotPybindDerived.__new__(NotPybindDerived), tag.base, 1
-                )
-            elif bad == 4:
-                m.TestFactory6.__init__(
-                    NotPybindDerived.__new__(NotPybindDerived), tag.alias, 1
-                )
-
-    for arg in (1, 2):
-        with pytest.raises(TypeError) as excinfo:
-            BrokenTF1(arg)
-        assert (
-            str(excinfo.value)
-            == "__init__(self, ...) called with invalid or missing `self` argument"
-        )
-
-    for arg in (0, 1, 2, 3, 4):
-        with pytest.raises(TypeError) as excinfo:
-            BrokenTF6(arg)
-        assert (
-            str(excinfo.value)
-            == "__init__(self, ...) called with invalid or missing `self` argument"
-        )
+import re
+
+import pytest
+
+from pybind11_tests import ConstructorStats
+from pybind11_tests import factory_constructors as m
+from pybind11_tests.factory_constructors import tag
+
+
+def test_init_factory_basic():
+    """Tests py::init_factory() wrapper around various ways of returning the object"""
+
+    cstats = [
+        ConstructorStats.get(c)
+        for c in [m.TestFactory1, m.TestFactory2, m.TestFactory3]
+    ]
+    cstats[0].alive()  # force gc
+    n_inst = ConstructorStats.detail_reg_inst()
+
+    x1 = m.TestFactory1(tag.unique_ptr, 3)
+    assert x1.value == "3"
+    y1 = m.TestFactory1(tag.pointer)
+    assert y1.value == "(empty)"
+    z1 = m.TestFactory1("hi!")
+    assert z1.value == "hi!"
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 3
+
+    x2 = m.TestFactory2(tag.move)
+    assert x2.value == "(empty2)"
+    y2 = m.TestFactory2(tag.pointer, 7)
+    assert y2.value == "7"
+    z2 = m.TestFactory2(tag.unique_ptr, "hi again")
+    assert z2.value == "hi again"
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 6
+
+    x3 = m.TestFactory3(tag.shared_ptr)
+    assert x3.value == "(empty3)"
+    y3 = m.TestFactory3(tag.pointer, 42)
+    assert y3.value == "42"
+    z3 = m.TestFactory3("bye")
+    assert z3.value == "bye"
+
+    for null_ptr_kind in [tag.null_ptr, tag.null_unique_ptr, tag.null_shared_ptr]:
+        with pytest.raises(TypeError) as excinfo:
+            m.TestFactory3(null_ptr_kind)
+        assert (
+            str(excinfo.value) == "pybind11::init(): factory function returned nullptr"
+        )
+
+    assert [i.alive() for i in cstats] == [3, 3, 3]
+    assert ConstructorStats.detail_reg_inst() == n_inst + 9
+
+    del x1, y2, y3, z3
+    assert [i.alive() for i in cstats] == [2, 2, 1]
+    assert ConstructorStats.detail_reg_inst() == n_inst + 5
+    del x2, x3, y1, z1, z2
+    assert [i.alive() for i in cstats] == [0, 0, 0]
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+    assert [i.values() for i in cstats] == [
+        ["3", "hi!"],
+        ["7", "hi again"],
+        ["42", "bye"],
+    ]
+    assert [i.default_constructions for i in cstats] == [1, 1, 1]
+
+
+def test_init_factory_signature(msg):
+    with pytest.raises(TypeError) as excinfo:
+        m.TestFactory1("invalid", "constructor", "arguments")
+    assert (
+        msg(excinfo.value)
+        == """
+        __init__(): incompatible constructor arguments. The following argument types are supported:
+            1. m.factory_constructors.TestFactory1(arg0: m.factory_constructors.tag.unique_ptr_tag, arg1: int)
+            2. m.factory_constructors.TestFactory1(arg0: str)
+            3. m.factory_constructors.TestFactory1(arg0: m.factory_constructors.tag.pointer_tag)
+            4. m.factory_constructors.TestFactory1(arg0: object, arg1: int, arg2: object)
+
+        Invoked with: 'invalid', 'constructor', 'arguments'
+    """
+    )
+
+    assert (
+        msg(m.TestFactory1.__init__.__doc__)
+        == """
+        __init__(*args, **kwargs)
+        Overloaded function.
+
+        1. __init__(self: m.factory_constructors.TestFactory1, arg0: m.factory_constructors.tag.unique_ptr_tag, arg1: int) -> None
+
+        2. __init__(self: m.factory_constructors.TestFactory1, arg0: str) -> None
+
+        3. __init__(self: m.factory_constructors.TestFactory1, arg0: m.factory_constructors.tag.pointer_tag) -> None
+
+        4. __init__(self: m.factory_constructors.TestFactory1, arg0: object, arg1: int, arg2: object) -> None
+    """
+    )
+
+
+def test_init_factory_casting():
+    """Tests py::init_factory() wrapper with various upcasting and downcasting returns"""
+
+    cstats = [
+        ConstructorStats.get(c)
+        for c in [m.TestFactory3, m.TestFactory4, m.TestFactory5]
+    ]
+    cstats[0].alive()  # force gc
+    n_inst = ConstructorStats.detail_reg_inst()
+
+    # Construction from derived references:
+    a = m.TestFactory3(tag.pointer, tag.TF4, 4)
+    assert a.value == "4"
+    b = m.TestFactory3(tag.shared_ptr, tag.TF4, 5)
+    assert b.value == "5"
+    c = m.TestFactory3(tag.pointer, tag.TF5, 6)
+    assert c.value == "6"
+    d = m.TestFactory3(tag.shared_ptr, tag.TF5, 7)
+    assert d.value == "7"
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 4
+
+    # Shared a lambda with TF3:
+    e = m.TestFactory4(tag.pointer, tag.TF4, 8)
+    assert e.value == "8"
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 5
+    assert [i.alive() for i in cstats] == [5, 3, 2]
+
+    del a
+    assert [i.alive() for i in cstats] == [4, 2, 2]
+    assert ConstructorStats.detail_reg_inst() == n_inst + 4
+
+    del b, c, e
+    assert [i.alive() for i in cstats] == [1, 0, 1]
+    assert ConstructorStats.detail_reg_inst() == n_inst + 1
+
+    del d
+    assert [i.alive() for i in cstats] == [0, 0, 0]
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+    assert [i.values() for i in cstats] == [
+        ["4", "5", "6", "7", "8"],
+        ["4", "5", "8"],
+        ["6", "7"],
+    ]
+
+
+def test_init_factory_alias():
+    """Tests py::init_factory() wrapper with value conversions and alias types"""
+
+    cstats = [m.TestFactory6.get_cstats(), m.TestFactory6.get_alias_cstats()]
+    cstats[0].alive()  # force gc
+    n_inst = ConstructorStats.detail_reg_inst()
+
+    a = m.TestFactory6(tag.base, 1)
+    assert a.get() == 1
+    assert not a.has_alias()
+    b = m.TestFactory6(tag.alias, "hi there")
+    assert b.get() == 8
+    assert b.has_alias()
+    c = m.TestFactory6(tag.alias, 3)
+    assert c.get() == 3
+    assert c.has_alias()
+    d = m.TestFactory6(tag.alias, tag.pointer, 4)
+    assert d.get() == 4
+    assert d.has_alias()
+    e = m.TestFactory6(tag.base, tag.pointer, 5)
+    assert e.get() == 5
+    assert not e.has_alias()
+    f = m.TestFactory6(tag.base, tag.alias, tag.pointer, 6)
+    assert f.get() == 6
+    assert f.has_alias()
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 6
+    assert [i.alive() for i in cstats] == [6, 4]
+
+    del a, b, e
+    assert [i.alive() for i in cstats] == [3, 3]
+    assert ConstructorStats.detail_reg_inst() == n_inst + 3
+    del f, c, d
+    assert [i.alive() for i in cstats] == [0, 0]
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+    class MyTest(m.TestFactory6):
+        def __init__(self, *args):
+            m.TestFactory6.__init__(self, *args)
+
+        def get(self):
+            return -5 + m.TestFactory6.get(self)
+
+    # Return Class by value, moved into new alias:
+    z = MyTest(tag.base, 123)
+    assert z.get() == 118
+    assert z.has_alias()
+
+    # Return alias by value, moved into new alias:
+    y = MyTest(tag.alias, "why hello!")
+    assert y.get() == 5
+    assert y.has_alias()
+
+    # Return Class by pointer, moved into new alias then original destroyed:
+    x = MyTest(tag.base, tag.pointer, 47)
+    assert x.get() == 42
+    assert x.has_alias()
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 3
+    assert [i.alive() for i in cstats] == [3, 3]
+    del x, y, z
+    assert [i.alive() for i in cstats] == [0, 0]
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+    assert [i.values() for i in cstats] == [
+        ["1", "8", "3", "4", "5", "6", "123", "10", "47"],
+        ["hi there", "3", "4", "6", "move", "123", "why hello!", "move", "47"],
+    ]
+
+
+def test_init_factory_dual():
+    """Tests init factory functions with dual main/alias factory functions"""
+    from pybind11_tests.factory_constructors import TestFactory7
+
+    cstats = [TestFactory7.get_cstats(), TestFactory7.get_alias_cstats()]
+    cstats[0].alive()  # force gc
+    n_inst = ConstructorStats.detail_reg_inst()
+
+    class PythFactory7(TestFactory7):
+        def get(self):
+            return 100 + TestFactory7.get(self)
+
+    a1 = TestFactory7(1)
+    a2 = PythFactory7(2)
+    assert a1.get() == 1
+    assert a2.get() == 102
+    assert not a1.has_alias()
+    assert a2.has_alias()
+
+    b1 = TestFactory7(tag.pointer, 3)
+    b2 = PythFactory7(tag.pointer, 4)
+    assert b1.get() == 3
+    assert b2.get() == 104
+    assert not b1.has_alias()
+    assert b2.has_alias()
+
+    c1 = TestFactory7(tag.mixed, 5)
+    c2 = PythFactory7(tag.mixed, 6)
+    assert c1.get() == 5
+    assert c2.get() == 106
+    assert not c1.has_alias()
+    assert c2.has_alias()
+
+    d1 = TestFactory7(tag.base, tag.pointer, 7)
+    d2 = PythFactory7(tag.base, tag.pointer, 8)
+    assert d1.get() == 7
+    assert d2.get() == 108
+    assert not d1.has_alias()
+    assert d2.has_alias()
+
+    # Both return an alias; the second multiplies the value by 10:
+    e1 = TestFactory7(tag.alias, tag.pointer, 9)
+    e2 = PythFactory7(tag.alias, tag.pointer, 10)
+    assert e1.get() == 9
+    assert e2.get() == 200
+    assert e1.has_alias()
+    assert e2.has_alias()
+
+    f1 = TestFactory7(tag.shared_ptr, tag.base, 11)
+    f2 = PythFactory7(tag.shared_ptr, tag.base, 12)
+    assert f1.get() == 11
+    assert f2.get() == 112
+    assert not f1.has_alias()
+    assert f2.has_alias()
+
+    g1 = TestFactory7(tag.shared_ptr, tag.invalid_base, 13)
+    assert g1.get() == 13
+    assert not g1.has_alias()
+    with pytest.raises(TypeError) as excinfo:
+        PythFactory7(tag.shared_ptr, tag.invalid_base, 14)
+    assert (
+        str(excinfo.value)
+        == "pybind11::init(): construction failed: returned holder-wrapped instance is not an "
+        "alias instance"
+    )
+
+    assert [i.alive() for i in cstats] == [13, 7]
+    assert ConstructorStats.detail_reg_inst() == n_inst + 13
+
+    del a1, a2, b1, d1, e1, e2
+    assert [i.alive() for i in cstats] == [7, 4]
+    assert ConstructorStats.detail_reg_inst() == n_inst + 7
+    del b2, c1, c2, d2, f1, f2, g1
+    assert [i.alive() for i in cstats] == [0, 0]
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+    assert [i.values() for i in cstats] == [
+        ["1", "2", "3", "4", "5", "6", "7", "8", "9", "100", "11", "12", "13", "14"],
+        ["2", "4", "6", "8", "9", "100", "12"],
+    ]
+
+
+def test_no_placement_new(capture):
+    """Prior to 2.2, `py::init<...>` relied on the type supporting placement
+    new; this tests a class without placement new support."""
+    with capture:
+        a = m.NoPlacementNew(123)
+
+    found = re.search(r"^operator new called, returning (\d+)\n$", str(capture))
+    assert found
+    assert a.i == 123
+    with capture:
+        del a
+        pytest.gc_collect()
+    assert capture == "operator delete called on " + found.group(1)
+
+    with capture:
+        b = m.NoPlacementNew()
+
+    found = re.search(r"^operator new called, returning (\d+)\n$", str(capture))
+    assert found
+    assert b.i == 100
+    with capture:
+        del b
+        pytest.gc_collect()
+    assert capture == "operator delete called on " + found.group(1)
+
+
+def test_multiple_inheritance():
+    class MITest(m.TestFactory1, m.TestFactory2):
+        def __init__(self):
+            m.TestFactory1.__init__(self, tag.unique_ptr, 33)
+            m.TestFactory2.__init__(self, tag.move)
+
+    a = MITest()
+    assert m.TestFactory1.value.fget(a) == "33"
+    assert m.TestFactory2.value.fget(a) == "(empty2)"
+
+
+def create_and_destroy(*args):
+    a = m.NoisyAlloc(*args)
+    print("---")
+    del a
+    pytest.gc_collect()
+
+
+def strip_comments(s):
+    return re.sub(r"\s+#.*", "", s)
+
+
+def test_reallocation_a(capture, msg):
+    """When the constructor is overloaded, previous overloads can require a preallocated value.
+    This test makes sure that such preallocated values only happen when they might be necessary,
+    and that they are deallocated properly."""
+
+    pytest.gc_collect()
+
+    with capture:
+        create_and_destroy(1)
+    assert (
+        msg(capture)
+        == """
+        noisy new
+        noisy placement new
+        NoisyAlloc(int 1)
+        ---
+        ~NoisyAlloc()
+        noisy delete
+    """
+    )
+
+
+def test_reallocation_b(capture, msg):
+    with capture:
+        create_and_destroy(1.5)
+    assert msg(capture) == strip_comments(
+        """
+        noisy new               # allocation required to attempt first overload
+        noisy delete            # have to dealloc before considering factory init overload
+        noisy new               # pointer factory calling "new", part 1: allocation
+        NoisyAlloc(double 1.5)  # ... part two, invoking constructor
+        ---
+        ~NoisyAlloc()  # Destructor
+        noisy delete   # operator delete
+    """
+    )
+
+
+def test_reallocation_c(capture, msg):
+    with capture:
+        create_and_destroy(2, 3)
+    assert msg(capture) == strip_comments(
+        """
+        noisy new          # pointer factory calling "new", allocation
+        NoisyAlloc(int 2)  # constructor
+        ---
+        ~NoisyAlloc()  # Destructor
+        noisy delete   # operator delete
+    """
+    )
+
+
+def test_reallocation_d(capture, msg):
+    with capture:
+        create_and_destroy(2.5, 3)
+    assert msg(capture) == strip_comments(
+        """
+        NoisyAlloc(double 2.5)  # construction (local func variable: operator_new not called)
+        noisy new               # return-by-value "new" part 1: allocation
+        ~NoisyAlloc()           # moved-away local func variable destruction
+        ---
+        ~NoisyAlloc()  # Destructor
+        noisy delete   # operator delete
+    """
+    )
+
+
+def test_reallocation_e(capture, msg):
+    with capture:
+        create_and_destroy(3.5, 4.5)
+    assert msg(capture) == strip_comments(
+        """
+        noisy new               # preallocation needed before invoking placement-new overload
+        noisy placement new     # Placement new
+        NoisyAlloc(double 3.5)  # construction
+        ---
+        ~NoisyAlloc()  # Destructor
+        noisy delete   # operator delete
+    """
+    )
+
+
+def test_reallocation_f(capture, msg):
+    with capture:
+        create_and_destroy(4, 0.5)
+    assert msg(capture) == strip_comments(
+        """
+        noisy new          # preallocation needed before invoking placement-new overload
+        noisy delete       # deallocation of preallocated storage
+        noisy new          # Factory pointer allocation
+        NoisyAlloc(int 4)  # factory pointer construction
+        ---
+        ~NoisyAlloc()  # Destructor
+        noisy delete   # operator delete
+    """
+    )
+
+
+def test_reallocation_g(capture, msg):
+    with capture:
+        create_and_destroy(5, "hi")
+    assert msg(capture) == strip_comments(
+        """
+        noisy new            # preallocation needed before invoking first placement new
+        noisy delete         # delete before considering new-style constructor
+        noisy new            # preallocation for second placement new
+        noisy placement new  # Placement new in the second placement new overload
+        NoisyAlloc(int 5)    # construction
+        ---
+        ~NoisyAlloc()  # Destructor
+        noisy delete   # operator delete
+    """
+    )
+
+
+def test_invalid_self():
+    """Tests invocation of the pybind-registered base class with an invalid `self` argument."""
+
+    class NotPybindDerived:
+        pass
+
+    # Attempts to initialize with an invalid type passed as `self`:
+    class BrokenTF1(m.TestFactory1):
+        def __init__(self, bad):
+            if bad == 1:
+                a = m.TestFactory2(tag.pointer, 1)
+                m.TestFactory1.__init__(a, tag.pointer)
+            elif bad == 2:
+                a = NotPybindDerived()
+                m.TestFactory1.__init__(a, tag.pointer)
+
+    # Same as above, but for a class with an alias:
+    class BrokenTF6(m.TestFactory6):
+        def __init__(self, bad):
+            if bad == 0:
+                m.TestFactory6.__init__()
+            elif bad == 1:
+                a = m.TestFactory2(tag.pointer, 1)
+                m.TestFactory6.__init__(a, tag.base, 1)
+            elif bad == 2:
+                a = m.TestFactory2(tag.pointer, 1)
+                m.TestFactory6.__init__(a, tag.alias, 1)
+            elif bad == 3:
+                m.TestFactory6.__init__(
+                    NotPybindDerived.__new__(NotPybindDerived), tag.base, 1
+                )
+            elif bad == 4:
+                m.TestFactory6.__init__(
+                    NotPybindDerived.__new__(NotPybindDerived), tag.alias, 1
+                )
+
+    for arg in (1, 2):
+        with pytest.raises(TypeError) as excinfo:
+            BrokenTF1(arg)
+        assert (
+            str(excinfo.value)
+            == "__init__(self, ...) called with invalid or missing `self` argument"
+        )
+
+    for arg in (0, 1, 2, 3, 4):
+        with pytest.raises(TypeError) as excinfo:
+            BrokenTF6(arg)
+        assert (
+            str(excinfo.value)
+            == "__init__(self, ...) called with invalid or missing `self` argument"
+        )
```

## extern/pybind11/tests/test_gil_scoped.py

 * *Ordering differences only*

```diff
@@ -1,242 +1,242 @@
-import multiprocessing
-import sys
-import threading
-import time
-
-import pytest
-
-import env
-from pybind11_tests import gil_scoped as m
-
-
-class ExtendedVirtClass(m.VirtClass):
-    def virtual_func(self):
-        pass
-
-    def pure_virtual_func(self):
-        pass
-
-
-def test_callback_py_obj():
-    m.test_callback_py_obj(lambda: None)
-
-
-def test_callback_std_func():
-    m.test_callback_std_func(lambda: None)
-
-
-def test_callback_virtual_func():
-    extended = ExtendedVirtClass()
-    m.test_callback_virtual_func(extended)
-
-
-def test_callback_pure_virtual_func():
-    extended = ExtendedVirtClass()
-    m.test_callback_pure_virtual_func(extended)
-
-
-def test_cross_module_gil_released():
-    """Makes sure that the GIL can be acquired by another module from a GIL-released state."""
-    m.test_cross_module_gil_released()  # Should not raise a SIGSEGV
-
-
-def test_cross_module_gil_acquired():
-    """Makes sure that the GIL can be acquired by another module from a GIL-acquired state."""
-    m.test_cross_module_gil_acquired()  # Should not raise a SIGSEGV
-
-
-def test_cross_module_gil_inner_custom_released():
-    """Makes sure that the GIL can be acquired/released by another module
-    from a GIL-released state using custom locking logic."""
-    m.test_cross_module_gil_inner_custom_released()
-
-
-def test_cross_module_gil_inner_custom_acquired():
-    """Makes sure that the GIL can be acquired/acquired by another module
-    from a GIL-acquired state using custom locking logic."""
-    m.test_cross_module_gil_inner_custom_acquired()
-
-
-def test_cross_module_gil_inner_pybind11_released():
-    """Makes sure that the GIL can be acquired/released by another module
-    from a GIL-released state using pybind11 locking logic."""
-    m.test_cross_module_gil_inner_pybind11_released()
-
-
-def test_cross_module_gil_inner_pybind11_acquired():
-    """Makes sure that the GIL can be acquired/acquired by another module
-    from a GIL-acquired state using pybind11 locking logic."""
-    m.test_cross_module_gil_inner_pybind11_acquired()
-
-
-def test_cross_module_gil_nested_custom_released():
-    """Makes sure that the GIL can be nested acquired/released by another module
-    from a GIL-released state using custom locking logic."""
-    m.test_cross_module_gil_nested_custom_released()
-
-
-def test_cross_module_gil_nested_custom_acquired():
-    """Makes sure that the GIL can be nested acquired/acquired by another module
-    from a GIL-acquired state using custom locking logic."""
-    m.test_cross_module_gil_nested_custom_acquired()
-
-
-def test_cross_module_gil_nested_pybind11_released():
-    """Makes sure that the GIL can be nested acquired/released by another module
-    from a GIL-released state using pybind11 locking logic."""
-    m.test_cross_module_gil_nested_pybind11_released()
-
-
-def test_cross_module_gil_nested_pybind11_acquired():
-    """Makes sure that the GIL can be nested acquired/acquired by another module
-    from a GIL-acquired state using pybind11 locking logic."""
-    m.test_cross_module_gil_nested_pybind11_acquired()
-
-
-def test_release_acquire():
-    assert m.test_release_acquire(0xAB) == "171"
-
-
-def test_nested_acquire():
-    assert m.test_nested_acquire(0xAB) == "171"
-
-
-def test_multi_acquire_release_cross_module():
-    for bits in range(16 * 8):
-        internals_ids = m.test_multi_acquire_release_cross_module(bits)
-        assert len(internals_ids) == 2 if bits % 8 else 1
-
-
-# Intentionally putting human review in the loop here, to guard against accidents.
-VARS_BEFORE_ALL_BASIC_TESTS = dict(vars())  # Make a copy of the dict (critical).
-ALL_BASIC_TESTS = (
-    test_callback_py_obj,
-    test_callback_std_func,
-    test_callback_virtual_func,
-    test_callback_pure_virtual_func,
-    test_cross_module_gil_released,
-    test_cross_module_gil_acquired,
-    test_cross_module_gil_inner_custom_released,
-    test_cross_module_gil_inner_custom_acquired,
-    test_cross_module_gil_inner_pybind11_released,
-    test_cross_module_gil_inner_pybind11_acquired,
-    test_cross_module_gil_nested_custom_released,
-    test_cross_module_gil_nested_custom_acquired,
-    test_cross_module_gil_nested_pybind11_released,
-    test_cross_module_gil_nested_pybind11_acquired,
-    test_release_acquire,
-    test_nested_acquire,
-    test_multi_acquire_release_cross_module,
-)
-
-
-def test_all_basic_tests_completeness():
-    num_found = 0
-    for key, value in VARS_BEFORE_ALL_BASIC_TESTS.items():
-        if not key.startswith("test_"):
-            continue
-        assert value in ALL_BASIC_TESTS
-        num_found += 1
-    assert len(ALL_BASIC_TESTS) == num_found
-
-
-def _intentional_deadlock():
-    m.intentional_deadlock()
-
-
-ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK = ALL_BASIC_TESTS + (_intentional_deadlock,)
-
-
-def _run_in_process(target, *args, **kwargs):
-    test_fn = target if len(args) == 0 else args[0]
-    # Do not need to wait much, 10s should be more than enough.
-    timeout = 0.1 if test_fn is _intentional_deadlock else 10
-    process = multiprocessing.Process(target=target, args=args, kwargs=kwargs)
-    process.daemon = True
-    try:
-        t_start = time.time()
-        process.start()
-        if timeout >= 100:  # For debugging.
-            print(
-                "\nprocess.pid STARTED", process.pid, (sys.argv, target, args, kwargs)
-            )
-            print(f"COPY-PASTE-THIS: gdb {sys.argv[0]} -p {process.pid}", flush=True)
-        process.join(timeout=timeout)
-        if timeout >= 100:
-            print("\nprocess.pid JOINED", process.pid, flush=True)
-        t_delta = time.time() - t_start
-        if process.exitcode == 66 and m.defined_THREAD_SANITIZER:  # Issue #2754
-            # WOULD-BE-NICE-TO-HAVE: Check that the message below is actually in the output.
-            # Maybe this could work:
-            # https://gist.github.com/alexeygrigorev/01ce847f2e721b513b42ea4a6c96905e
-            pytest.skip(
-                "ThreadSanitizer: starting new threads after multi-threaded fork is not supported."
-            )
-        elif test_fn is _intentional_deadlock:
-            assert process.exitcode is None
-            return 0
-
-        if process.exitcode is None:
-            assert t_delta > 0.9 * timeout
-            msg = "DEADLOCK, most likely, exactly what this test is meant to detect."
-            if env.PYPY and env.WIN:
-                pytest.skip(msg)
-            raise RuntimeError(msg)
-        return process.exitcode
-    finally:
-        if process.is_alive():
-            process.terminate()
-
-
-def _run_in_threads(test_fn, num_threads, parallel):
-    threads = []
-    for _ in range(num_threads):
-        thread = threading.Thread(target=test_fn)
-        thread.daemon = True
-        thread.start()
-        if parallel:
-            threads.append(thread)
-        else:
-            thread.join()
-    for thread in threads:
-        thread.join()
-
-
-# TODO: FIXME, sometimes returns -11 (segfault) instead of 0 on macOS Python 3.9
-@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
-def test_run_in_process_one_thread(test_fn):
-    """Makes sure there is no GIL deadlock when running in a thread.
-
-    It runs in a separate process to be able to stop and assert if it deadlocks.
-    """
-    assert _run_in_process(_run_in_threads, test_fn, num_threads=1, parallel=False) == 0
-
-
-# TODO: FIXME on macOS Python 3.9
-@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
-def test_run_in_process_multiple_threads_parallel(test_fn):
-    """Makes sure there is no GIL deadlock when running in a thread multiple times in parallel.
-
-    It runs in a separate process to be able to stop and assert if it deadlocks.
-    """
-    assert _run_in_process(_run_in_threads, test_fn, num_threads=8, parallel=True) == 0
-
-
-# TODO: FIXME on macOS Python 3.9
-@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
-def test_run_in_process_multiple_threads_sequential(test_fn):
-    """Makes sure there is no GIL deadlock when running in a thread multiple times sequentially.
-
-    It runs in a separate process to be able to stop and assert if it deadlocks.
-    """
-    assert _run_in_process(_run_in_threads, test_fn, num_threads=8, parallel=False) == 0
-
-
-# TODO: FIXME on macOS Python 3.9
-@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
-def test_run_in_process_direct(test_fn):
-    """Makes sure there is no GIL deadlock when using processes.
-
-    This test is for completion, but it was never an issue.
-    """
-    assert _run_in_process(test_fn) == 0
+import multiprocessing
+import sys
+import threading
+import time
+
+import pytest
+
+import env
+from pybind11_tests import gil_scoped as m
+
+
+class ExtendedVirtClass(m.VirtClass):
+    def virtual_func(self):
+        pass
+
+    def pure_virtual_func(self):
+        pass
+
+
+def test_callback_py_obj():
+    m.test_callback_py_obj(lambda: None)
+
+
+def test_callback_std_func():
+    m.test_callback_std_func(lambda: None)
+
+
+def test_callback_virtual_func():
+    extended = ExtendedVirtClass()
+    m.test_callback_virtual_func(extended)
+
+
+def test_callback_pure_virtual_func():
+    extended = ExtendedVirtClass()
+    m.test_callback_pure_virtual_func(extended)
+
+
+def test_cross_module_gil_released():
+    """Makes sure that the GIL can be acquired by another module from a GIL-released state."""
+    m.test_cross_module_gil_released()  # Should not raise a SIGSEGV
+
+
+def test_cross_module_gil_acquired():
+    """Makes sure that the GIL can be acquired by another module from a GIL-acquired state."""
+    m.test_cross_module_gil_acquired()  # Should not raise a SIGSEGV
+
+
+def test_cross_module_gil_inner_custom_released():
+    """Makes sure that the GIL can be acquired/released by another module
+    from a GIL-released state using custom locking logic."""
+    m.test_cross_module_gil_inner_custom_released()
+
+
+def test_cross_module_gil_inner_custom_acquired():
+    """Makes sure that the GIL can be acquired/acquired by another module
+    from a GIL-acquired state using custom locking logic."""
+    m.test_cross_module_gil_inner_custom_acquired()
+
+
+def test_cross_module_gil_inner_pybind11_released():
+    """Makes sure that the GIL can be acquired/released by another module
+    from a GIL-released state using pybind11 locking logic."""
+    m.test_cross_module_gil_inner_pybind11_released()
+
+
+def test_cross_module_gil_inner_pybind11_acquired():
+    """Makes sure that the GIL can be acquired/acquired by another module
+    from a GIL-acquired state using pybind11 locking logic."""
+    m.test_cross_module_gil_inner_pybind11_acquired()
+
+
+def test_cross_module_gil_nested_custom_released():
+    """Makes sure that the GIL can be nested acquired/released by another module
+    from a GIL-released state using custom locking logic."""
+    m.test_cross_module_gil_nested_custom_released()
+
+
+def test_cross_module_gil_nested_custom_acquired():
+    """Makes sure that the GIL can be nested acquired/acquired by another module
+    from a GIL-acquired state using custom locking logic."""
+    m.test_cross_module_gil_nested_custom_acquired()
+
+
+def test_cross_module_gil_nested_pybind11_released():
+    """Makes sure that the GIL can be nested acquired/released by another module
+    from a GIL-released state using pybind11 locking logic."""
+    m.test_cross_module_gil_nested_pybind11_released()
+
+
+def test_cross_module_gil_nested_pybind11_acquired():
+    """Makes sure that the GIL can be nested acquired/acquired by another module
+    from a GIL-acquired state using pybind11 locking logic."""
+    m.test_cross_module_gil_nested_pybind11_acquired()
+
+
+def test_release_acquire():
+    assert m.test_release_acquire(0xAB) == "171"
+
+
+def test_nested_acquire():
+    assert m.test_nested_acquire(0xAB) == "171"
+
+
+def test_multi_acquire_release_cross_module():
+    for bits in range(16 * 8):
+        internals_ids = m.test_multi_acquire_release_cross_module(bits)
+        assert len(internals_ids) == 2 if bits % 8 else 1
+
+
+# Intentionally putting human review in the loop here, to guard against accidents.
+VARS_BEFORE_ALL_BASIC_TESTS = dict(vars())  # Make a copy of the dict (critical).
+ALL_BASIC_TESTS = (
+    test_callback_py_obj,
+    test_callback_std_func,
+    test_callback_virtual_func,
+    test_callback_pure_virtual_func,
+    test_cross_module_gil_released,
+    test_cross_module_gil_acquired,
+    test_cross_module_gil_inner_custom_released,
+    test_cross_module_gil_inner_custom_acquired,
+    test_cross_module_gil_inner_pybind11_released,
+    test_cross_module_gil_inner_pybind11_acquired,
+    test_cross_module_gil_nested_custom_released,
+    test_cross_module_gil_nested_custom_acquired,
+    test_cross_module_gil_nested_pybind11_released,
+    test_cross_module_gil_nested_pybind11_acquired,
+    test_release_acquire,
+    test_nested_acquire,
+    test_multi_acquire_release_cross_module,
+)
+
+
+def test_all_basic_tests_completeness():
+    num_found = 0
+    for key, value in VARS_BEFORE_ALL_BASIC_TESTS.items():
+        if not key.startswith("test_"):
+            continue
+        assert value in ALL_BASIC_TESTS
+        num_found += 1
+    assert len(ALL_BASIC_TESTS) == num_found
+
+
+def _intentional_deadlock():
+    m.intentional_deadlock()
+
+
+ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK = ALL_BASIC_TESTS + (_intentional_deadlock,)
+
+
+def _run_in_process(target, *args, **kwargs):
+    test_fn = target if len(args) == 0 else args[0]
+    # Do not need to wait much, 10s should be more than enough.
+    timeout = 0.1 if test_fn is _intentional_deadlock else 10
+    process = multiprocessing.Process(target=target, args=args, kwargs=kwargs)
+    process.daemon = True
+    try:
+        t_start = time.time()
+        process.start()
+        if timeout >= 100:  # For debugging.
+            print(
+                "\nprocess.pid STARTED", process.pid, (sys.argv, target, args, kwargs)
+            )
+            print(f"COPY-PASTE-THIS: gdb {sys.argv[0]} -p {process.pid}", flush=True)
+        process.join(timeout=timeout)
+        if timeout >= 100:
+            print("\nprocess.pid JOINED", process.pid, flush=True)
+        t_delta = time.time() - t_start
+        if process.exitcode == 66 and m.defined_THREAD_SANITIZER:  # Issue #2754
+            # WOULD-BE-NICE-TO-HAVE: Check that the message below is actually in the output.
+            # Maybe this could work:
+            # https://gist.github.com/alexeygrigorev/01ce847f2e721b513b42ea4a6c96905e
+            pytest.skip(
+                "ThreadSanitizer: starting new threads after multi-threaded fork is not supported."
+            )
+        elif test_fn is _intentional_deadlock:
+            assert process.exitcode is None
+            return 0
+
+        if process.exitcode is None:
+            assert t_delta > 0.9 * timeout
+            msg = "DEADLOCK, most likely, exactly what this test is meant to detect."
+            if env.PYPY and env.WIN:
+                pytest.skip(msg)
+            raise RuntimeError(msg)
+        return process.exitcode
+    finally:
+        if process.is_alive():
+            process.terminate()
+
+
+def _run_in_threads(test_fn, num_threads, parallel):
+    threads = []
+    for _ in range(num_threads):
+        thread = threading.Thread(target=test_fn)
+        thread.daemon = True
+        thread.start()
+        if parallel:
+            threads.append(thread)
+        else:
+            thread.join()
+    for thread in threads:
+        thread.join()
+
+
+# TODO: FIXME, sometimes returns -11 (segfault) instead of 0 on macOS Python 3.9
+@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
+def test_run_in_process_one_thread(test_fn):
+    """Makes sure there is no GIL deadlock when running in a thread.
+
+    It runs in a separate process to be able to stop and assert if it deadlocks.
+    """
+    assert _run_in_process(_run_in_threads, test_fn, num_threads=1, parallel=False) == 0
+
+
+# TODO: FIXME on macOS Python 3.9
+@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
+def test_run_in_process_multiple_threads_parallel(test_fn):
+    """Makes sure there is no GIL deadlock when running in a thread multiple times in parallel.
+
+    It runs in a separate process to be able to stop and assert if it deadlocks.
+    """
+    assert _run_in_process(_run_in_threads, test_fn, num_threads=8, parallel=True) == 0
+
+
+# TODO: FIXME on macOS Python 3.9
+@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
+def test_run_in_process_multiple_threads_sequential(test_fn):
+    """Makes sure there is no GIL deadlock when running in a thread multiple times sequentially.
+
+    It runs in a separate process to be able to stop and assert if it deadlocks.
+    """
+    assert _run_in_process(_run_in_threads, test_fn, num_threads=8, parallel=False) == 0
+
+
+# TODO: FIXME on macOS Python 3.9
+@pytest.mark.parametrize("test_fn", ALL_BASIC_TESTS_PLUS_INTENTIONAL_DEADLOCK)
+def test_run_in_process_direct(test_fn):
+    """Makes sure there is no GIL deadlock when using processes.
+
+    This test is for completion, but it was never an issue.
+    """
+    assert _run_in_process(test_fn) == 0
```

## extern/pybind11/tests/test_iostream.py

 * *Ordering differences only*

```diff
@@ -1,291 +1,291 @@
-from contextlib import redirect_stderr, redirect_stdout
-from io import StringIO
-
-from pybind11_tests import iostream as m
-
-
-def test_captured(capsys):
-    msg = "I've been redirected to Python, I hope!"
-    m.captured_output(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-    m.captured_err(msg)
-    stdout, stderr = capsys.readouterr()
-    assert not stdout
-    assert stderr == msg
-
-
-def test_captured_large_string(capsys):
-    # Make this bigger than the buffer used on the C++ side: 1024 chars
-    msg = "I've been redirected to Python, I hope!"
-    msg = msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_2byte_offset0(capsys):
-    msg = "\u07FF"
-    msg = "" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_2byte_offset1(capsys):
-    msg = "\u07FF"
-    msg = "1" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_3byte_offset0(capsys):
-    msg = "\uFFFF"
-    msg = "" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_3byte_offset1(capsys):
-    msg = "\uFFFF"
-    msg = "1" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_3byte_offset2(capsys):
-    msg = "\uFFFF"
-    msg = "12" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_4byte_offset0(capsys):
-    msg = "\U0010FFFF"
-    msg = "" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_4byte_offset1(capsys):
-    msg = "\U0010FFFF"
-    msg = "1" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_4byte_offset2(capsys):
-    msg = "\U0010FFFF"
-    msg = "12" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_captured_utf8_4byte_offset3(capsys):
-    msg = "\U0010FFFF"
-    msg = "123" + msg * (1024 // len(msg) + 1)
-
-    m.captured_output_default(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_guard_capture(capsys):
-    msg = "I've been redirected to Python, I hope!"
-    m.guard_output(msg)
-    stdout, stderr = capsys.readouterr()
-    assert stdout == msg
-    assert not stderr
-
-
-def test_series_captured(capture):
-    with capture:
-        m.captured_output("a")
-        m.captured_output("b")
-    assert capture == "ab"
-
-
-def test_flush(capfd):
-    msg = "(not flushed)"
-    msg2 = "(flushed)"
-
-    with m.ostream_redirect():
-        m.noisy_function(msg, flush=False)
-        stdout, stderr = capfd.readouterr()
-        assert not stdout
-
-        m.noisy_function(msg2, flush=True)
-        stdout, stderr = capfd.readouterr()
-        assert stdout == msg + msg2
-
-        m.noisy_function(msg, flush=False)
-
-    stdout, stderr = capfd.readouterr()
-    assert stdout == msg
-
-
-def test_not_captured(capfd):
-    msg = "Something that should not show up in log"
-    stream = StringIO()
-    with redirect_stdout(stream):
-        m.raw_output(msg)
-    stdout, stderr = capfd.readouterr()
-    assert stdout == msg
-    assert not stderr
-    assert not stream.getvalue()
-
-    stream = StringIO()
-    with redirect_stdout(stream):
-        m.captured_output(msg)
-    stdout, stderr = capfd.readouterr()
-    assert not stdout
-    assert not stderr
-    assert stream.getvalue() == msg
-
-
-def test_err(capfd):
-    msg = "Something that should not show up in log"
-    stream = StringIO()
-    with redirect_stderr(stream):
-        m.raw_err(msg)
-    stdout, stderr = capfd.readouterr()
-    assert not stdout
-    assert stderr == msg
-    assert not stream.getvalue()
-
-    stream = StringIO()
-    with redirect_stderr(stream):
-        m.captured_err(msg)
-    stdout, stderr = capfd.readouterr()
-    assert not stdout
-    assert not stderr
-    assert stream.getvalue() == msg
-
-
-def test_multi_captured(capfd):
-    stream = StringIO()
-    with redirect_stdout(stream):
-        m.captured_output("a")
-        m.raw_output("b")
-        m.captured_output("c")
-        m.raw_output("d")
-    stdout, stderr = capfd.readouterr()
-    assert stdout == "bd"
-    assert stream.getvalue() == "ac"
-
-
-def test_dual(capsys):
-    m.captured_dual("a", "b")
-    stdout, stderr = capsys.readouterr()
-    assert stdout == "a"
-    assert stderr == "b"
-
-
-def test_redirect(capfd):
-    msg = "Should not be in log!"
-    stream = StringIO()
-    with redirect_stdout(stream):
-        m.raw_output(msg)
-    stdout, stderr = capfd.readouterr()
-    assert stdout == msg
-    assert not stream.getvalue()
-
-    stream = StringIO()
-    with redirect_stdout(stream), m.ostream_redirect():
-        m.raw_output(msg)
-    stdout, stderr = capfd.readouterr()
-    assert not stdout
-    assert stream.getvalue() == msg
-
-    stream = StringIO()
-    with redirect_stdout(stream):
-        m.raw_output(msg)
-    stdout, stderr = capfd.readouterr()
-    assert stdout == msg
-    assert not stream.getvalue()
-
-
-def test_redirect_err(capfd):
-    msg = "StdOut"
-    msg2 = "StdErr"
-
-    stream = StringIO()
-    with redirect_stderr(stream), m.ostream_redirect(stdout=False):
-        m.raw_output(msg)
-        m.raw_err(msg2)
-    stdout, stderr = capfd.readouterr()
-    assert stdout == msg
-    assert not stderr
-    assert stream.getvalue() == msg2
-
-
-def test_redirect_both(capfd):
-    msg = "StdOut"
-    msg2 = "StdErr"
-
-    stream = StringIO()
-    stream2 = StringIO()
-    with redirect_stdout(stream), redirect_stderr(stream2), m.ostream_redirect():
-        m.raw_output(msg)
-        m.raw_err(msg2)
-    stdout, stderr = capfd.readouterr()
-    assert not stdout
-    assert not stderr
-    assert stream.getvalue() == msg
-    assert stream2.getvalue() == msg2
-
-
-def test_threading():
-    with m.ostream_redirect(stdout=True, stderr=False):
-        # start some threads
-        threads = []
-
-        # start some threads
-        for _j in range(20):
-            threads.append(m.TestThread())
-
-        # give the threads some time to fail
-        threads[0].sleep()
-
-        # stop all the threads
-        for t in threads:
-            t.stop()
-
-        for t in threads:
-            t.join()
-
-        # if a thread segfaults, we don't get here
-        assert True
+from contextlib import redirect_stderr, redirect_stdout
+from io import StringIO
+
+from pybind11_tests import iostream as m
+
+
+def test_captured(capsys):
+    msg = "I've been redirected to Python, I hope!"
+    m.captured_output(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+    m.captured_err(msg)
+    stdout, stderr = capsys.readouterr()
+    assert not stdout
+    assert stderr == msg
+
+
+def test_captured_large_string(capsys):
+    # Make this bigger than the buffer used on the C++ side: 1024 chars
+    msg = "I've been redirected to Python, I hope!"
+    msg = msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_2byte_offset0(capsys):
+    msg = "\u07FF"
+    msg = "" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_2byte_offset1(capsys):
+    msg = "\u07FF"
+    msg = "1" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_3byte_offset0(capsys):
+    msg = "\uFFFF"
+    msg = "" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_3byte_offset1(capsys):
+    msg = "\uFFFF"
+    msg = "1" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_3byte_offset2(capsys):
+    msg = "\uFFFF"
+    msg = "12" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_4byte_offset0(capsys):
+    msg = "\U0010FFFF"
+    msg = "" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_4byte_offset1(capsys):
+    msg = "\U0010FFFF"
+    msg = "1" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_4byte_offset2(capsys):
+    msg = "\U0010FFFF"
+    msg = "12" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_captured_utf8_4byte_offset3(capsys):
+    msg = "\U0010FFFF"
+    msg = "123" + msg * (1024 // len(msg) + 1)
+
+    m.captured_output_default(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_guard_capture(capsys):
+    msg = "I've been redirected to Python, I hope!"
+    m.guard_output(msg)
+    stdout, stderr = capsys.readouterr()
+    assert stdout == msg
+    assert not stderr
+
+
+def test_series_captured(capture):
+    with capture:
+        m.captured_output("a")
+        m.captured_output("b")
+    assert capture == "ab"
+
+
+def test_flush(capfd):
+    msg = "(not flushed)"
+    msg2 = "(flushed)"
+
+    with m.ostream_redirect():
+        m.noisy_function(msg, flush=False)
+        stdout, stderr = capfd.readouterr()
+        assert not stdout
+
+        m.noisy_function(msg2, flush=True)
+        stdout, stderr = capfd.readouterr()
+        assert stdout == msg + msg2
+
+        m.noisy_function(msg, flush=False)
+
+    stdout, stderr = capfd.readouterr()
+    assert stdout == msg
+
+
+def test_not_captured(capfd):
+    msg = "Something that should not show up in log"
+    stream = StringIO()
+    with redirect_stdout(stream):
+        m.raw_output(msg)
+    stdout, stderr = capfd.readouterr()
+    assert stdout == msg
+    assert not stderr
+    assert not stream.getvalue()
+
+    stream = StringIO()
+    with redirect_stdout(stream):
+        m.captured_output(msg)
+    stdout, stderr = capfd.readouterr()
+    assert not stdout
+    assert not stderr
+    assert stream.getvalue() == msg
+
+
+def test_err(capfd):
+    msg = "Something that should not show up in log"
+    stream = StringIO()
+    with redirect_stderr(stream):
+        m.raw_err(msg)
+    stdout, stderr = capfd.readouterr()
+    assert not stdout
+    assert stderr == msg
+    assert not stream.getvalue()
+
+    stream = StringIO()
+    with redirect_stderr(stream):
+        m.captured_err(msg)
+    stdout, stderr = capfd.readouterr()
+    assert not stdout
+    assert not stderr
+    assert stream.getvalue() == msg
+
+
+def test_multi_captured(capfd):
+    stream = StringIO()
+    with redirect_stdout(stream):
+        m.captured_output("a")
+        m.raw_output("b")
+        m.captured_output("c")
+        m.raw_output("d")
+    stdout, stderr = capfd.readouterr()
+    assert stdout == "bd"
+    assert stream.getvalue() == "ac"
+
+
+def test_dual(capsys):
+    m.captured_dual("a", "b")
+    stdout, stderr = capsys.readouterr()
+    assert stdout == "a"
+    assert stderr == "b"
+
+
+def test_redirect(capfd):
+    msg = "Should not be in log!"
+    stream = StringIO()
+    with redirect_stdout(stream):
+        m.raw_output(msg)
+    stdout, stderr = capfd.readouterr()
+    assert stdout == msg
+    assert not stream.getvalue()
+
+    stream = StringIO()
+    with redirect_stdout(stream), m.ostream_redirect():
+        m.raw_output(msg)
+    stdout, stderr = capfd.readouterr()
+    assert not stdout
+    assert stream.getvalue() == msg
+
+    stream = StringIO()
+    with redirect_stdout(stream):
+        m.raw_output(msg)
+    stdout, stderr = capfd.readouterr()
+    assert stdout == msg
+    assert not stream.getvalue()
+
+
+def test_redirect_err(capfd):
+    msg = "StdOut"
+    msg2 = "StdErr"
+
+    stream = StringIO()
+    with redirect_stderr(stream), m.ostream_redirect(stdout=False):
+        m.raw_output(msg)
+        m.raw_err(msg2)
+    stdout, stderr = capfd.readouterr()
+    assert stdout == msg
+    assert not stderr
+    assert stream.getvalue() == msg2
+
+
+def test_redirect_both(capfd):
+    msg = "StdOut"
+    msg2 = "StdErr"
+
+    stream = StringIO()
+    stream2 = StringIO()
+    with redirect_stdout(stream), redirect_stderr(stream2), m.ostream_redirect():
+        m.raw_output(msg)
+        m.raw_err(msg2)
+    stdout, stderr = capfd.readouterr()
+    assert not stdout
+    assert not stderr
+    assert stream.getvalue() == msg
+    assert stream2.getvalue() == msg2
+
+
+def test_threading():
+    with m.ostream_redirect(stdout=True, stderr=False):
+        # start some threads
+        threads = []
+
+        # start some threads
+        for _j in range(20):
+            threads.append(m.TestThread())
+
+        # give the threads some time to fail
+        threads[0].sleep()
+
+        # stop all the threads
+        for t in threads:
+            t.stop()
+
+        for t in threads:
+            t.join()
+
+        # if a thread segfaults, we don't get here
+        assert True
```

## extern/pybind11/tests/test_kwargs_and_defaults.py

 * *Ordering differences only*

```diff
@@ -1,425 +1,425 @@
-import pytest
-
-from pybind11_tests import kwargs_and_defaults as m
-
-
-def test_function_signatures(doc):
-    assert doc(m.kw_func0) == "kw_func0(arg0: int, arg1: int) -> str"
-    assert doc(m.kw_func1) == "kw_func1(x: int, y: int) -> str"
-    assert doc(m.kw_func2) == "kw_func2(x: int = 100, y: int = 200) -> str"
-    assert doc(m.kw_func3) == "kw_func3(data: str = 'Hello world!') -> None"
-    assert doc(m.kw_func4) == "kw_func4(myList: list[int] = [13, 17]) -> str"
-    assert doc(m.kw_func_udl) == "kw_func_udl(x: int, y: int = 300) -> str"
-    assert doc(m.kw_func_udl_z) == "kw_func_udl_z(x: int, y: int = 0) -> str"
-    assert doc(m.args_function) == "args_function(*args) -> tuple"
-    assert (
-        doc(m.args_kwargs_function) == "args_kwargs_function(*args, **kwargs) -> tuple"
-    )
-    assert (
-        doc(m.KWClass.foo0)
-        == "foo0(self: m.kwargs_and_defaults.KWClass, arg0: int, arg1: float) -> None"
-    )
-    assert (
-        doc(m.KWClass.foo1)
-        == "foo1(self: m.kwargs_and_defaults.KWClass, x: int, y: float) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func0)
-        == "kw_lb_func0(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func1)
-        == "kw_lb_func1(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func2)
-        == "kw_lb_func2(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func3)
-        == "kw_lb_func3(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func4)
-        == "kw_lb_func4(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func5)
-        == "kw_lb_func5(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func6)
-        == "kw_lb_func6(custom: m.kwargs_and_defaults.CustomRepr = ) -> None"
-    )
-    assert (
-        doc(m.kw_lb_func7)
-        == "kw_lb_func7(str_arg: str = 'First line.\\n  Second line.') -> None"
-    )
-    assert (
-        doc(m.kw_lb_func8)
-        == "kw_lb_func8(custom: m.kwargs_and_defaults.CustomRepr = ) -> None"
-    )
-
-
-def test_named_arguments():
-    assert m.kw_func0(5, 10) == "x=5, y=10"
-
-    assert m.kw_func1(5, 10) == "x=5, y=10"
-    assert m.kw_func1(5, y=10) == "x=5, y=10"
-    assert m.kw_func1(y=10, x=5) == "x=5, y=10"
-
-    assert m.kw_func2() == "x=100, y=200"
-    assert m.kw_func2(5) == "x=5, y=200"
-    assert m.kw_func2(x=5) == "x=5, y=200"
-    assert m.kw_func2(y=10) == "x=100, y=10"
-    assert m.kw_func2(5, 10) == "x=5, y=10"
-    assert m.kw_func2(x=5, y=10) == "x=5, y=10"
-
-    with pytest.raises(TypeError) as excinfo:
-        # noinspection PyArgumentList
-        m.kw_func2(x=5, y=10, z=12)
-    assert excinfo.match(
-        r"(?s)^kw_func2\(\): incompatible.*Invoked with: kwargs: ((x=5|y=10|z=12)(, |$)){3}$"
-    )
-
-    assert m.kw_func4() == "{13 17}"
-    assert m.kw_func4(myList=[1, 2, 3]) == "{1 2 3}"
-
-    assert m.kw_func_udl(x=5, y=10) == "x=5, y=10"
-    assert m.kw_func_udl_z(x=5) == "x=5, y=0"
-
-
-def test_arg_and_kwargs():
-    args = "arg1_value", "arg2_value", 3
-    assert m.args_function(*args) == args
-
-    args = "a1", "a2"
-    kwargs = {"arg3": "a3", "arg4": 4}
-    assert m.args_kwargs_function(*args, **kwargs) == (args, kwargs)
-
-
-def test_mixed_args_and_kwargs(msg):
-    mpa = m.mixed_plus_args
-    mpk = m.mixed_plus_kwargs
-    mpak = m.mixed_plus_args_kwargs
-    mpakd = m.mixed_plus_args_kwargs_defaults
-
-    assert mpa(1, 2.5, 4, 99.5, None) == (1, 2.5, (4, 99.5, None))
-    assert mpa(1, 2.5) == (1, 2.5, ())
-    with pytest.raises(TypeError) as excinfo:
-        assert mpa(1)
-    assert (
-        msg(excinfo.value)
-        == """
-        mixed_plus_args(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: int, arg1: float, *args) -> tuple
-
-        Invoked with: 1
-    """
-    )
-    with pytest.raises(TypeError) as excinfo:
-        assert mpa()
-    assert (
-        msg(excinfo.value)
-        == """
-        mixed_plus_args(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: int, arg1: float, *args) -> tuple
-
-        Invoked with:
-    """
-    )
-
-    assert mpk(-2, 3.5, pi=3.14159, e=2.71828) == (
-        -2,
-        3.5,
-        {"e": 2.71828, "pi": 3.14159},
-    )
-    assert mpak(7, 7.7, 7.77, 7.777, 7.7777, minusseven=-7) == (
-        7,
-        7.7,
-        (7.77, 7.777, 7.7777),
-        {"minusseven": -7},
-    )
-    assert mpakd() == (1, 3.14159, (), {})
-    assert mpakd(3) == (3, 3.14159, (), {})
-    assert mpakd(j=2.71828) == (1, 2.71828, (), {})
-    assert mpakd(k=42) == (1, 3.14159, (), {"k": 42})
-    assert mpakd(1, 1, 2, 3, 5, 8, then=13, followedby=21) == (
-        1,
-        1,
-        (2, 3, 5, 8),
-        {"then": 13, "followedby": 21},
-    )
-    # Arguments specified both positionally and via kwargs should fail:
-    with pytest.raises(TypeError) as excinfo:
-        assert mpakd(1, i=1)
-    assert (
-        msg(excinfo.value)
-        == """
-        mixed_plus_args_kwargs_defaults(): incompatible function arguments. The following argument types are supported:
-            1. (i: int = 1, j: float = 3.14159, *args, **kwargs) -> tuple
-
-        Invoked with: 1; kwargs: i=1
-    """
-    )
-    with pytest.raises(TypeError) as excinfo:
-        assert mpakd(1, 2, j=1)
-    assert (
-        msg(excinfo.value)
-        == """
-        mixed_plus_args_kwargs_defaults(): incompatible function arguments. The following argument types are supported:
-            1. (i: int = 1, j: float = 3.14159, *args, **kwargs) -> tuple
-
-        Invoked with: 1, 2; kwargs: j=1
-    """
-    )
-
-    # Arguments after a py::args are automatically keyword-only (pybind 2.9+)
-    assert m.args_kwonly(2, 2.5, z=22) == (2, 2.5, (), 22)
-    assert m.args_kwonly(2, 2.5, "a", "b", "c", z=22) == (2, 2.5, ("a", "b", "c"), 22)
-    assert m.args_kwonly(z=22, i=4, j=16) == (4, 16, (), 22)
-
-    with pytest.raises(TypeError) as excinfo:
-        assert m.args_kwonly(2, 2.5, 22)  # missing z= keyword
-    assert (
-        msg(excinfo.value)
-        == """
-        args_kwonly(): incompatible function arguments. The following argument types are supported:
-            1. (i: int, j: float, *args, z: int) -> tuple
-
-        Invoked with: 2, 2.5, 22
-    """
-    )
-
-    assert m.args_kwonly_kwargs(i=1, k=4, j=10, z=-1, y=9) == (
-        1,
-        10,
-        (),
-        -1,
-        {"k": 4, "y": 9},
-    )
-    assert m.args_kwonly_kwargs(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, z=11, y=12) == (
-        1,
-        2,
-        (3, 4, 5, 6, 7, 8, 9, 10),
-        11,
-        {"y": 12},
-    )
-    assert (
-        m.args_kwonly_kwargs.__doc__
-        == "args_kwonly_kwargs(i: int, j: float, *args, z: int, **kwargs) -> tuple\n"
-    )
-
-    assert (
-        m.args_kwonly_kwargs_defaults.__doc__
-        == "args_kwonly_kwargs_defaults(i: int = 1, j: float = 3.14159, *args, z: int = 42, **kwargs) -> tuple\n"
-    )
-    assert m.args_kwonly_kwargs_defaults() == (1, 3.14159, (), 42, {})
-    assert m.args_kwonly_kwargs_defaults(2) == (2, 3.14159, (), 42, {})
-    assert m.args_kwonly_kwargs_defaults(z=-99) == (1, 3.14159, (), -99, {})
-    assert m.args_kwonly_kwargs_defaults(5, 6, 7, 8) == (5, 6, (7, 8), 42, {})
-    assert m.args_kwonly_kwargs_defaults(5, 6, 7, m=8) == (5, 6, (7,), 42, {"m": 8})
-    assert m.args_kwonly_kwargs_defaults(5, 6, 7, m=8, z=9) == (5, 6, (7,), 9, {"m": 8})
-
-
-def test_keyword_only_args(msg):
-    assert m.kw_only_all(i=1, j=2) == (1, 2)
-    assert m.kw_only_all(j=1, i=2) == (2, 1)
-
-    with pytest.raises(TypeError) as excinfo:
-        assert m.kw_only_all(i=1) == (1,)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        assert m.kw_only_all(1, 2) == (1, 2)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    assert m.kw_only_some(1, k=3, j=2) == (1, 2, 3)
-
-    assert m.kw_only_with_defaults(z=8) == (3, 4, 5, 8)
-    assert m.kw_only_with_defaults(2, z=8) == (2, 4, 5, 8)
-    assert m.kw_only_with_defaults(2, j=7, k=8, z=9) == (2, 7, 8, 9)
-    assert m.kw_only_with_defaults(2, 7, z=9, k=8) == (2, 7, 8, 9)
-
-    assert m.kw_only_mixed(1, j=2) == (1, 2)
-    assert m.kw_only_mixed(j=2, i=3) == (3, 2)
-    assert m.kw_only_mixed(i=2, j=3) == (2, 3)
-
-    assert m.kw_only_plus_more(4, 5, k=6, extra=7) == (4, 5, 6, {"extra": 7})
-    assert m.kw_only_plus_more(3, k=5, j=4, extra=6) == (3, 4, 5, {"extra": 6})
-    assert m.kw_only_plus_more(2, k=3, extra=4) == (2, -1, 3, {"extra": 4})
-
-    with pytest.raises(TypeError) as excinfo:
-        assert m.kw_only_mixed(i=1) == (1,)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.register_invalid_kw_only(m)
-    assert (
-        msg(excinfo.value)
-        == """
-        arg(): cannot specify an unnamed argument after a kw_only() annotation or args() argument
-    """
-    )
-
-    # https://github.com/pybind/pybind11/pull/3402#issuecomment-963341987
-    x = m.first_arg_kw_only(i=1)
-    x.method()
-    x.method(i=1, j=2)
-    assert (
-        m.first_arg_kw_only.__init__.__doc__
-        == "__init__(self: pybind11_tests.kwargs_and_defaults.first_arg_kw_only, *, i: int = 0) -> None\n"
-    )
-    assert (
-        m.first_arg_kw_only.method.__doc__
-        == "method(self: pybind11_tests.kwargs_and_defaults.first_arg_kw_only, *, i: int = 1, j: int = 2) -> None\n"
-    )
-
-
-def test_positional_only_args():
-    assert m.pos_only_all(1, 2) == (1, 2)
-    assert m.pos_only_all(2, 1) == (2, 1)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.pos_only_all(i=1, j=2)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    assert m.pos_only_mix(1, 2) == (1, 2)
-    assert m.pos_only_mix(2, j=1) == (2, 1)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.pos_only_mix(i=1, j=2)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    assert m.pos_kw_only_mix(1, 2, k=3) == (1, 2, 3)
-    assert m.pos_kw_only_mix(1, j=2, k=3) == (1, 2, 3)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.pos_kw_only_mix(i=1, j=2, k=3)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.pos_kw_only_mix(1, 2, 3)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.pos_only_def_mix()
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    assert m.pos_only_def_mix(1) == (1, 2, 3)
-    assert m.pos_only_def_mix(1, 4) == (1, 4, 3)
-    assert m.pos_only_def_mix(1, 4, 7) == (1, 4, 7)
-    assert m.pos_only_def_mix(1, 4, k=7) == (1, 4, 7)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.pos_only_def_mix(1, j=4)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    # Mix it with args and kwargs:
-    assert (
-        m.args_kwonly_full_monty.__doc__
-        == "args_kwonly_full_monty(arg0: int = 1, arg1: int = 2, /, j: float = 3.14159, *args, z: int = 42, **kwargs) -> tuple\n"
-    )
-    assert m.args_kwonly_full_monty() == (1, 2, 3.14159, (), 42, {})
-    assert m.args_kwonly_full_monty(8) == (8, 2, 3.14159, (), 42, {})
-    assert m.args_kwonly_full_monty(8, 9) == (8, 9, 3.14159, (), 42, {})
-    assert m.args_kwonly_full_monty(8, 9, 10) == (8, 9, 10.0, (), 42, {})
-    assert m.args_kwonly_full_monty(3, 4, 5, 6, 7, m=8, z=9) == (
-        3,
-        4,
-        5.0,
-        (
-            6,
-            7,
-        ),
-        9,
-        {"m": 8},
-    )
-    assert m.args_kwonly_full_monty(3, 4, 5, 6, 7, m=8, z=9) == (
-        3,
-        4,
-        5.0,
-        (
-            6,
-            7,
-        ),
-        9,
-        {"m": 8},
-    )
-    assert m.args_kwonly_full_monty(5, j=7, m=8, z=9) == (5, 2, 7.0, (), 9, {"m": 8})
-    assert m.args_kwonly_full_monty(i=5, j=7, m=8, z=9) == (
-        1,
-        2,
-        7.0,
-        (),
-        9,
-        {"i": 5, "m": 8},
-    )
-
-    # pos_only at the beginning of the argument list was "broken" in how it was displayed (though
-    # this is fairly useless in practice).  Related to:
-    # https://github.com/pybind/pybind11/pull/3402#issuecomment-963341987
-    assert (
-        m.first_arg_kw_only.pos_only.__doc__
-        == "pos_only(self: pybind11_tests.kwargs_and_defaults.first_arg_kw_only, /, i: int, j: int) -> None\n"
-    )
-
-
-def test_signatures():
-    assert m.kw_only_all.__doc__ == "kw_only_all(*, i: int, j: int) -> tuple\n"
-    assert m.kw_only_mixed.__doc__ == "kw_only_mixed(i: int, *, j: int) -> tuple\n"
-    assert m.pos_only_all.__doc__ == "pos_only_all(i: int, j: int, /) -> tuple\n"
-    assert m.pos_only_mix.__doc__ == "pos_only_mix(i: int, /, j: int) -> tuple\n"
-    assert (
-        m.pos_kw_only_mix.__doc__
-        == "pos_kw_only_mix(i: int, /, j: int, *, k: int) -> tuple\n"
-    )
-
-
-def test_args_refcount():
-    """Issue/PR #1216 - py::args elements get double-inc_ref()ed when combined with regular
-    arguments"""
-    refcount = m.arg_refcount_h
-
-    myval = 54321
-    expected = refcount(myval)
-    assert m.arg_refcount_h(myval) == expected
-    assert m.arg_refcount_o(myval) == expected + 1
-    assert m.arg_refcount_h(myval) == expected
-    assert refcount(myval) == expected
-
-    assert m.mixed_plus_args(1, 2.0, "a", myval) == (1, 2.0, ("a", myval))
-    assert refcount(myval) == expected
-
-    assert m.mixed_plus_kwargs(3, 4.0, a=1, b=myval) == (3, 4.0, {"a": 1, "b": myval})
-    assert refcount(myval) == expected
-
-    assert m.args_function(-1, myval) == (-1, myval)
-    assert refcount(myval) == expected
-
-    assert m.mixed_plus_args_kwargs(5, 6.0, myval, a=myval) == (
-        5,
-        6.0,
-        (myval,),
-        {"a": myval},
-    )
-    assert refcount(myval) == expected
-
-    assert m.args_kwargs_function(7, 8, myval, a=1, b=myval) == (
-        (7, 8, myval),
-        {"a": 1, "b": myval},
-    )
-    assert refcount(myval) == expected
-
-    exp3 = refcount(myval, myval, myval)
-    assert m.args_refcount(myval, myval, myval) == (exp3, exp3, exp3)
-    assert refcount(myval) == expected
-
-    # This function takes the first arg as a `py::object` and the rest as a `py::args`.  Unlike the
-    # previous case, when we have both positional and `py::args` we need to construct a new tuple
-    # for the `py::args`; in the previous case, we could simply inc_ref and pass on Python's input
-    # tuple without having to inc_ref the individual elements, but here we can't, hence the extra
-    # refs.
-    assert m.mixed_args_refcount(myval, myval, myval) == (exp3 + 3, exp3 + 3, exp3 + 3)
-
-    assert m.class_default_argument() == "<class 'decimal.Decimal'>"
+import pytest
+
+from pybind11_tests import kwargs_and_defaults as m
+
+
+def test_function_signatures(doc):
+    assert doc(m.kw_func0) == "kw_func0(arg0: int, arg1: int) -> str"
+    assert doc(m.kw_func1) == "kw_func1(x: int, y: int) -> str"
+    assert doc(m.kw_func2) == "kw_func2(x: int = 100, y: int = 200) -> str"
+    assert doc(m.kw_func3) == "kw_func3(data: str = 'Hello world!') -> None"
+    assert doc(m.kw_func4) == "kw_func4(myList: list[int] = [13, 17]) -> str"
+    assert doc(m.kw_func_udl) == "kw_func_udl(x: int, y: int = 300) -> str"
+    assert doc(m.kw_func_udl_z) == "kw_func_udl_z(x: int, y: int = 0) -> str"
+    assert doc(m.args_function) == "args_function(*args) -> tuple"
+    assert (
+        doc(m.args_kwargs_function) == "args_kwargs_function(*args, **kwargs) -> tuple"
+    )
+    assert (
+        doc(m.KWClass.foo0)
+        == "foo0(self: m.kwargs_and_defaults.KWClass, arg0: int, arg1: float) -> None"
+    )
+    assert (
+        doc(m.KWClass.foo1)
+        == "foo1(self: m.kwargs_and_defaults.KWClass, x: int, y: float) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func0)
+        == "kw_lb_func0(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func1)
+        == "kw_lb_func1(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func2)
+        == "kw_lb_func2(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func3)
+        == "kw_lb_func3(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func4)
+        == "kw_lb_func4(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func5)
+        == "kw_lb_func5(custom: m.kwargs_and_defaults.CustomRepr = array([[A, B], [C, D]])) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func6)
+        == "kw_lb_func6(custom: m.kwargs_and_defaults.CustomRepr = ) -> None"
+    )
+    assert (
+        doc(m.kw_lb_func7)
+        == "kw_lb_func7(str_arg: str = 'First line.\\n  Second line.') -> None"
+    )
+    assert (
+        doc(m.kw_lb_func8)
+        == "kw_lb_func8(custom: m.kwargs_and_defaults.CustomRepr = ) -> None"
+    )
+
+
+def test_named_arguments():
+    assert m.kw_func0(5, 10) == "x=5, y=10"
+
+    assert m.kw_func1(5, 10) == "x=5, y=10"
+    assert m.kw_func1(5, y=10) == "x=5, y=10"
+    assert m.kw_func1(y=10, x=5) == "x=5, y=10"
+
+    assert m.kw_func2() == "x=100, y=200"
+    assert m.kw_func2(5) == "x=5, y=200"
+    assert m.kw_func2(x=5) == "x=5, y=200"
+    assert m.kw_func2(y=10) == "x=100, y=10"
+    assert m.kw_func2(5, 10) == "x=5, y=10"
+    assert m.kw_func2(x=5, y=10) == "x=5, y=10"
+
+    with pytest.raises(TypeError) as excinfo:
+        # noinspection PyArgumentList
+        m.kw_func2(x=5, y=10, z=12)
+    assert excinfo.match(
+        r"(?s)^kw_func2\(\): incompatible.*Invoked with: kwargs: ((x=5|y=10|z=12)(, |$)){3}$"
+    )
+
+    assert m.kw_func4() == "{13 17}"
+    assert m.kw_func4(myList=[1, 2, 3]) == "{1 2 3}"
+
+    assert m.kw_func_udl(x=5, y=10) == "x=5, y=10"
+    assert m.kw_func_udl_z(x=5) == "x=5, y=0"
+
+
+def test_arg_and_kwargs():
+    args = "arg1_value", "arg2_value", 3
+    assert m.args_function(*args) == args
+
+    args = "a1", "a2"
+    kwargs = {"arg3": "a3", "arg4": 4}
+    assert m.args_kwargs_function(*args, **kwargs) == (args, kwargs)
+
+
+def test_mixed_args_and_kwargs(msg):
+    mpa = m.mixed_plus_args
+    mpk = m.mixed_plus_kwargs
+    mpak = m.mixed_plus_args_kwargs
+    mpakd = m.mixed_plus_args_kwargs_defaults
+
+    assert mpa(1, 2.5, 4, 99.5, None) == (1, 2.5, (4, 99.5, None))
+    assert mpa(1, 2.5) == (1, 2.5, ())
+    with pytest.raises(TypeError) as excinfo:
+        assert mpa(1)
+    assert (
+        msg(excinfo.value)
+        == """
+        mixed_plus_args(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: int, arg1: float, *args) -> tuple
+
+        Invoked with: 1
+    """
+    )
+    with pytest.raises(TypeError) as excinfo:
+        assert mpa()
+    assert (
+        msg(excinfo.value)
+        == """
+        mixed_plus_args(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: int, arg1: float, *args) -> tuple
+
+        Invoked with:
+    """
+    )
+
+    assert mpk(-2, 3.5, pi=3.14159, e=2.71828) == (
+        -2,
+        3.5,
+        {"e": 2.71828, "pi": 3.14159},
+    )
+    assert mpak(7, 7.7, 7.77, 7.777, 7.7777, minusseven=-7) == (
+        7,
+        7.7,
+        (7.77, 7.777, 7.7777),
+        {"minusseven": -7},
+    )
+    assert mpakd() == (1, 3.14159, (), {})
+    assert mpakd(3) == (3, 3.14159, (), {})
+    assert mpakd(j=2.71828) == (1, 2.71828, (), {})
+    assert mpakd(k=42) == (1, 3.14159, (), {"k": 42})
+    assert mpakd(1, 1, 2, 3, 5, 8, then=13, followedby=21) == (
+        1,
+        1,
+        (2, 3, 5, 8),
+        {"then": 13, "followedby": 21},
+    )
+    # Arguments specified both positionally and via kwargs should fail:
+    with pytest.raises(TypeError) as excinfo:
+        assert mpakd(1, i=1)
+    assert (
+        msg(excinfo.value)
+        == """
+        mixed_plus_args_kwargs_defaults(): incompatible function arguments. The following argument types are supported:
+            1. (i: int = 1, j: float = 3.14159, *args, **kwargs) -> tuple
+
+        Invoked with: 1; kwargs: i=1
+    """
+    )
+    with pytest.raises(TypeError) as excinfo:
+        assert mpakd(1, 2, j=1)
+    assert (
+        msg(excinfo.value)
+        == """
+        mixed_plus_args_kwargs_defaults(): incompatible function arguments. The following argument types are supported:
+            1. (i: int = 1, j: float = 3.14159, *args, **kwargs) -> tuple
+
+        Invoked with: 1, 2; kwargs: j=1
+    """
+    )
+
+    # Arguments after a py::args are automatically keyword-only (pybind 2.9+)
+    assert m.args_kwonly(2, 2.5, z=22) == (2, 2.5, (), 22)
+    assert m.args_kwonly(2, 2.5, "a", "b", "c", z=22) == (2, 2.5, ("a", "b", "c"), 22)
+    assert m.args_kwonly(z=22, i=4, j=16) == (4, 16, (), 22)
+
+    with pytest.raises(TypeError) as excinfo:
+        assert m.args_kwonly(2, 2.5, 22)  # missing z= keyword
+    assert (
+        msg(excinfo.value)
+        == """
+        args_kwonly(): incompatible function arguments. The following argument types are supported:
+            1. (i: int, j: float, *args, z: int) -> tuple
+
+        Invoked with: 2, 2.5, 22
+    """
+    )
+
+    assert m.args_kwonly_kwargs(i=1, k=4, j=10, z=-1, y=9) == (
+        1,
+        10,
+        (),
+        -1,
+        {"k": 4, "y": 9},
+    )
+    assert m.args_kwonly_kwargs(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, z=11, y=12) == (
+        1,
+        2,
+        (3, 4, 5, 6, 7, 8, 9, 10),
+        11,
+        {"y": 12},
+    )
+    assert (
+        m.args_kwonly_kwargs.__doc__
+        == "args_kwonly_kwargs(i: int, j: float, *args, z: int, **kwargs) -> tuple\n"
+    )
+
+    assert (
+        m.args_kwonly_kwargs_defaults.__doc__
+        == "args_kwonly_kwargs_defaults(i: int = 1, j: float = 3.14159, *args, z: int = 42, **kwargs) -> tuple\n"
+    )
+    assert m.args_kwonly_kwargs_defaults() == (1, 3.14159, (), 42, {})
+    assert m.args_kwonly_kwargs_defaults(2) == (2, 3.14159, (), 42, {})
+    assert m.args_kwonly_kwargs_defaults(z=-99) == (1, 3.14159, (), -99, {})
+    assert m.args_kwonly_kwargs_defaults(5, 6, 7, 8) == (5, 6, (7, 8), 42, {})
+    assert m.args_kwonly_kwargs_defaults(5, 6, 7, m=8) == (5, 6, (7,), 42, {"m": 8})
+    assert m.args_kwonly_kwargs_defaults(5, 6, 7, m=8, z=9) == (5, 6, (7,), 9, {"m": 8})
+
+
+def test_keyword_only_args(msg):
+    assert m.kw_only_all(i=1, j=2) == (1, 2)
+    assert m.kw_only_all(j=1, i=2) == (2, 1)
+
+    with pytest.raises(TypeError) as excinfo:
+        assert m.kw_only_all(i=1) == (1,)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        assert m.kw_only_all(1, 2) == (1, 2)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.kw_only_some(1, k=3, j=2) == (1, 2, 3)
+
+    assert m.kw_only_with_defaults(z=8) == (3, 4, 5, 8)
+    assert m.kw_only_with_defaults(2, z=8) == (2, 4, 5, 8)
+    assert m.kw_only_with_defaults(2, j=7, k=8, z=9) == (2, 7, 8, 9)
+    assert m.kw_only_with_defaults(2, 7, z=9, k=8) == (2, 7, 8, 9)
+
+    assert m.kw_only_mixed(1, j=2) == (1, 2)
+    assert m.kw_only_mixed(j=2, i=3) == (3, 2)
+    assert m.kw_only_mixed(i=2, j=3) == (2, 3)
+
+    assert m.kw_only_plus_more(4, 5, k=6, extra=7) == (4, 5, 6, {"extra": 7})
+    assert m.kw_only_plus_more(3, k=5, j=4, extra=6) == (3, 4, 5, {"extra": 6})
+    assert m.kw_only_plus_more(2, k=3, extra=4) == (2, -1, 3, {"extra": 4})
+
+    with pytest.raises(TypeError) as excinfo:
+        assert m.kw_only_mixed(i=1) == (1,)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.register_invalid_kw_only(m)
+    assert (
+        msg(excinfo.value)
+        == """
+        arg(): cannot specify an unnamed argument after a kw_only() annotation or args() argument
+    """
+    )
+
+    # https://github.com/pybind/pybind11/pull/3402#issuecomment-963341987
+    x = m.first_arg_kw_only(i=1)
+    x.method()
+    x.method(i=1, j=2)
+    assert (
+        m.first_arg_kw_only.__init__.__doc__
+        == "__init__(self: pybind11_tests.kwargs_and_defaults.first_arg_kw_only, *, i: int = 0) -> None\n"
+    )
+    assert (
+        m.first_arg_kw_only.method.__doc__
+        == "method(self: pybind11_tests.kwargs_and_defaults.first_arg_kw_only, *, i: int = 1, j: int = 2) -> None\n"
+    )
+
+
+def test_positional_only_args():
+    assert m.pos_only_all(1, 2) == (1, 2)
+    assert m.pos_only_all(2, 1) == (2, 1)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_all(i=1, j=2)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.pos_only_mix(1, 2) == (1, 2)
+    assert m.pos_only_mix(2, j=1) == (2, 1)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_mix(i=1, j=2)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.pos_kw_only_mix(1, 2, k=3) == (1, 2, 3)
+    assert m.pos_kw_only_mix(1, j=2, k=3) == (1, 2, 3)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_kw_only_mix(i=1, j=2, k=3)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_kw_only_mix(1, 2, 3)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_def_mix()
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    assert m.pos_only_def_mix(1) == (1, 2, 3)
+    assert m.pos_only_def_mix(1, 4) == (1, 4, 3)
+    assert m.pos_only_def_mix(1, 4, 7) == (1, 4, 7)
+    assert m.pos_only_def_mix(1, 4, k=7) == (1, 4, 7)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.pos_only_def_mix(1, j=4)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    # Mix it with args and kwargs:
+    assert (
+        m.args_kwonly_full_monty.__doc__
+        == "args_kwonly_full_monty(arg0: int = 1, arg1: int = 2, /, j: float = 3.14159, *args, z: int = 42, **kwargs) -> tuple\n"
+    )
+    assert m.args_kwonly_full_monty() == (1, 2, 3.14159, (), 42, {})
+    assert m.args_kwonly_full_monty(8) == (8, 2, 3.14159, (), 42, {})
+    assert m.args_kwonly_full_monty(8, 9) == (8, 9, 3.14159, (), 42, {})
+    assert m.args_kwonly_full_monty(8, 9, 10) == (8, 9, 10.0, (), 42, {})
+    assert m.args_kwonly_full_monty(3, 4, 5, 6, 7, m=8, z=9) == (
+        3,
+        4,
+        5.0,
+        (
+            6,
+            7,
+        ),
+        9,
+        {"m": 8},
+    )
+    assert m.args_kwonly_full_monty(3, 4, 5, 6, 7, m=8, z=9) == (
+        3,
+        4,
+        5.0,
+        (
+            6,
+            7,
+        ),
+        9,
+        {"m": 8},
+    )
+    assert m.args_kwonly_full_monty(5, j=7, m=8, z=9) == (5, 2, 7.0, (), 9, {"m": 8})
+    assert m.args_kwonly_full_monty(i=5, j=7, m=8, z=9) == (
+        1,
+        2,
+        7.0,
+        (),
+        9,
+        {"i": 5, "m": 8},
+    )
+
+    # pos_only at the beginning of the argument list was "broken" in how it was displayed (though
+    # this is fairly useless in practice).  Related to:
+    # https://github.com/pybind/pybind11/pull/3402#issuecomment-963341987
+    assert (
+        m.first_arg_kw_only.pos_only.__doc__
+        == "pos_only(self: pybind11_tests.kwargs_and_defaults.first_arg_kw_only, /, i: int, j: int) -> None\n"
+    )
+
+
+def test_signatures():
+    assert m.kw_only_all.__doc__ == "kw_only_all(*, i: int, j: int) -> tuple\n"
+    assert m.kw_only_mixed.__doc__ == "kw_only_mixed(i: int, *, j: int) -> tuple\n"
+    assert m.pos_only_all.__doc__ == "pos_only_all(i: int, j: int, /) -> tuple\n"
+    assert m.pos_only_mix.__doc__ == "pos_only_mix(i: int, /, j: int) -> tuple\n"
+    assert (
+        m.pos_kw_only_mix.__doc__
+        == "pos_kw_only_mix(i: int, /, j: int, *, k: int) -> tuple\n"
+    )
+
+
+def test_args_refcount():
+    """Issue/PR #1216 - py::args elements get double-inc_ref()ed when combined with regular
+    arguments"""
+    refcount = m.arg_refcount_h
+
+    myval = 54321
+    expected = refcount(myval)
+    assert m.arg_refcount_h(myval) == expected
+    assert m.arg_refcount_o(myval) == expected + 1
+    assert m.arg_refcount_h(myval) == expected
+    assert refcount(myval) == expected
+
+    assert m.mixed_plus_args(1, 2.0, "a", myval) == (1, 2.0, ("a", myval))
+    assert refcount(myval) == expected
+
+    assert m.mixed_plus_kwargs(3, 4.0, a=1, b=myval) == (3, 4.0, {"a": 1, "b": myval})
+    assert refcount(myval) == expected
+
+    assert m.args_function(-1, myval) == (-1, myval)
+    assert refcount(myval) == expected
+
+    assert m.mixed_plus_args_kwargs(5, 6.0, myval, a=myval) == (
+        5,
+        6.0,
+        (myval,),
+        {"a": myval},
+    )
+    assert refcount(myval) == expected
+
+    assert m.args_kwargs_function(7, 8, myval, a=1, b=myval) == (
+        (7, 8, myval),
+        {"a": 1, "b": myval},
+    )
+    assert refcount(myval) == expected
+
+    exp3 = refcount(myval, myval, myval)
+    assert m.args_refcount(myval, myval, myval) == (exp3, exp3, exp3)
+    assert refcount(myval) == expected
+
+    # This function takes the first arg as a `py::object` and the rest as a `py::args`.  Unlike the
+    # previous case, when we have both positional and `py::args` we need to construct a new tuple
+    # for the `py::args`; in the previous case, we could simply inc_ref and pass on Python's input
+    # tuple without having to inc_ref the individual elements, but here we can't, hence the extra
+    # refs.
+    assert m.mixed_args_refcount(myval, myval, myval) == (exp3 + 3, exp3 + 3, exp3 + 3)
+
+    assert m.class_default_argument() == "<class 'decimal.Decimal'>"
```

## extern/pybind11/tests/test_local_bindings.py

 * *Ordering differences only*

```diff
@@ -1,257 +1,257 @@
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import local_bindings as m
-
-
-def test_load_external():
-    """Load a `py::module_local` type that's only registered in an external module"""
-    import pybind11_cross_module_tests as cm
-
-    assert m.load_external1(cm.ExternalType1(11)) == 11
-    assert m.load_external2(cm.ExternalType2(22)) == 22
-
-    with pytest.raises(TypeError) as excinfo:
-        assert m.load_external2(cm.ExternalType1(21)) == 21
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        assert m.load_external1(cm.ExternalType2(12)) == 12
-    assert "incompatible function arguments" in str(excinfo.value)
-
-
-def test_local_bindings():
-    """Tests that duplicate `py::module_local` class bindings work across modules"""
-
-    # Make sure we can load the second module with the conflicting (but local) definition:
-    import pybind11_cross_module_tests as cm
-
-    i1 = m.LocalType(5)
-    assert i1.get() == 4
-    assert i1.get3() == 8
-
-    i2 = cm.LocalType(10)
-    assert i2.get() == 11
-    assert i2.get2() == 12
-
-    assert not hasattr(i1, "get2")
-    assert not hasattr(i2, "get3")
-
-    # Loading within the local module
-    assert m.local_value(i1) == 5
-    assert cm.local_value(i2) == 10
-
-    # Cross-module loading works as well (on failure, the type loader looks for
-    # external module-local converters):
-    assert m.local_value(i2) == 10
-    assert cm.local_value(i1) == 5
-
-
-def test_nonlocal_failure():
-    """Tests that attempting to register a non-local type in multiple modules fails"""
-    import pybind11_cross_module_tests as cm
-
-    with pytest.raises(RuntimeError) as excinfo:
-        cm.register_nonlocal()
-    assert (
-        str(excinfo.value) == 'generic_type: type "NonLocalType" is already registered!'
-    )
-
-
-def test_duplicate_local():
-    """Tests expected failure when registering a class twice with py::local in the same module"""
-    with pytest.raises(RuntimeError) as excinfo:
-        m.register_local_external()
-    import pybind11_tests
-
-    assert str(excinfo.value) == (
-        'generic_type: type "LocalExternal" is already registered!'
-        if hasattr(pybind11_tests, "class_")
-        else "test_class not enabled"
-    )
-
-
-def test_stl_bind_local():
-    import pybind11_cross_module_tests as cm
-
-    v1, v2 = m.LocalVec(), cm.LocalVec()
-    v1.append(m.LocalType(1))
-    v1.append(m.LocalType(2))
-    v2.append(cm.LocalType(1))
-    v2.append(cm.LocalType(2))
-
-    # Cross module value loading:
-    v1.append(cm.LocalType(3))
-    v2.append(m.LocalType(3))
-
-    assert [i.get() for i in v1] == [0, 1, 2]
-    assert [i.get() for i in v2] == [2, 3, 4]
-
-    v3, v4 = m.NonLocalVec(), cm.NonLocalVec2()
-    v3.append(m.NonLocalType(1))
-    v3.append(m.NonLocalType(2))
-    v4.append(m.NonLocal2(3))
-    v4.append(m.NonLocal2(4))
-
-    assert [i.get() for i in v3] == [1, 2]
-    assert [i.get() for i in v4] == [13, 14]
-
-    d1, d2 = m.LocalMap(), cm.LocalMap()
-    d1["a"] = v1[0]
-    d1["b"] = v1[1]
-    d2["c"] = v2[0]
-    d2["d"] = v2[1]
-    assert {i: d1[i].get() for i in d1} == {"a": 0, "b": 1}
-    assert {i: d2[i].get() for i in d2} == {"c": 2, "d": 3}
-
-
-def test_stl_bind_global():
-    import pybind11_cross_module_tests as cm
-
-    with pytest.raises(RuntimeError) as excinfo:
-        cm.register_nonlocal_map()
-    assert (
-        str(excinfo.value) == 'generic_type: type "NonLocalMap" is already registered!'
-    )
-
-    with pytest.raises(RuntimeError) as excinfo:
-        cm.register_nonlocal_vec()
-    assert (
-        str(excinfo.value) == 'generic_type: type "NonLocalVec" is already registered!'
-    )
-
-    with pytest.raises(RuntimeError) as excinfo:
-        cm.register_nonlocal_map2()
-    assert (
-        str(excinfo.value) == 'generic_type: type "NonLocalMap2" is already registered!'
-    )
-
-
-def test_mixed_local_global():
-    """Local types take precedence over globally registered types: a module with a `module_local`
-    type can be registered even if the type is already registered globally.  With the module,
-    casting will go to the local type; outside the module casting goes to the global type.
-    """
-    import pybind11_cross_module_tests as cm
-
-    m.register_mixed_global()
-    m.register_mixed_local()
-
-    a = []
-    a.append(m.MixedGlobalLocal(1))
-    a.append(m.MixedLocalGlobal(2))
-    a.append(m.get_mixed_gl(3))
-    a.append(m.get_mixed_lg(4))
-
-    assert [x.get() for x in a] == [101, 1002, 103, 1004]
-
-    cm.register_mixed_global_local()
-    cm.register_mixed_local_global()
-    a.append(m.MixedGlobalLocal(5))
-    a.append(m.MixedLocalGlobal(6))
-    a.append(cm.MixedGlobalLocal(7))
-    a.append(cm.MixedLocalGlobal(8))
-    a.append(m.get_mixed_gl(9))
-    a.append(m.get_mixed_lg(10))
-    a.append(cm.get_mixed_gl(11))
-    a.append(cm.get_mixed_lg(12))
-
-    assert [x.get() for x in a] == [
-        101,
-        1002,
-        103,
-        1004,
-        105,
-        1006,
-        207,
-        2008,
-        109,
-        1010,
-        211,
-        2012,
-    ]
-
-
-def test_internal_locals_differ():
-    """Makes sure the internal local type map differs across the two modules"""
-    import pybind11_cross_module_tests as cm
-
-    assert m.local_cpp_types_addr() != cm.local_cpp_types_addr()
-
-
-@pytest.mark.xfail("env.PYPY and sys.pypy_version_info < (7, 3, 2)")
-def test_stl_caster_vs_stl_bind(msg):
-    """One module uses a generic vector caster from `<pybind11/stl.h>` while the other
-    exports `std::vector<int>` via `py:bind_vector` and `py::module_local`"""
-    import pybind11_cross_module_tests as cm
-
-    v1 = cm.VectorInt([1, 2, 3])
-    assert m.load_vector_via_caster(v1) == 6
-    assert cm.load_vector_via_binding(v1) == 6
-
-    v2 = [1, 2, 3]
-    assert m.load_vector_via_caster(v2) == 6
-    with pytest.raises(TypeError) as excinfo:
-        cm.load_vector_via_binding(v2)
-    assert (
-        msg(excinfo.value)
-        == """
-    load_vector_via_binding(): incompatible function arguments. The following argument types are supported:
-        1. (arg0: pybind11_cross_module_tests.VectorInt) -> int
-
-    Invoked with: [1, 2, 3]
-    """
-    )
-
-
-def test_cross_module_calls():
-    import pybind11_cross_module_tests as cm
-
-    v1 = m.LocalVec()
-    v1.append(m.LocalType(1))
-    v2 = cm.LocalVec()
-    v2.append(cm.LocalType(2))
-
-    # Returning the self pointer should get picked up as returning an existing
-    # instance (even when that instance is of a foreign, non-local type).
-    assert m.return_self(v1) is v1
-    assert cm.return_self(v2) is v2
-    assert m.return_self(v2) is v2
-    assert cm.return_self(v1) is v1
-
-    assert m.LocalVec is not cm.LocalVec
-    # Returning a copy, on the other hand, always goes to the local type,
-    # regardless of where the source type came from.
-    assert type(m.return_copy(v1)) is m.LocalVec
-    assert type(m.return_copy(v2)) is m.LocalVec
-    assert type(cm.return_copy(v1)) is cm.LocalVec
-    assert type(cm.return_copy(v2)) is cm.LocalVec
-
-    # Test the example given in the documentation (which also tests inheritance casting):
-    mycat = m.Cat("Fluffy")
-    mydog = cm.Dog("Rover")
-    assert mycat.get_name() == "Fluffy"
-    assert mydog.name() == "Rover"
-    assert m.Cat.__base__.__name__ == "Pet"
-    assert cm.Dog.__base__.__name__ == "Pet"
-    assert m.Cat.__base__ is not cm.Dog.__base__
-    assert m.pet_name(mycat) == "Fluffy"
-    assert m.pet_name(mydog) == "Rover"
-    assert cm.pet_name(mycat) == "Fluffy"
-    assert cm.pet_name(mydog) == "Rover"
-
-    assert m.MixGL is not cm.MixGL
-    a = m.MixGL(1)
-    b = cm.MixGL(2)
-    assert m.get_gl_value(a) == 11
-    assert m.get_gl_value(b) == 12
-    assert cm.get_gl_value(a) == 101
-    assert cm.get_gl_value(b) == 102
-
-    c, d = m.MixGL2(3), cm.MixGL2(4)
-    with pytest.raises(TypeError) as excinfo:
-        m.get_gl_value(c)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.get_gl_value(d)
-    assert "incompatible function arguments" in str(excinfo.value)
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import local_bindings as m
+
+
+def test_load_external():
+    """Load a `py::module_local` type that's only registered in an external module"""
+    import pybind11_cross_module_tests as cm
+
+    assert m.load_external1(cm.ExternalType1(11)) == 11
+    assert m.load_external2(cm.ExternalType2(22)) == 22
+
+    with pytest.raises(TypeError) as excinfo:
+        assert m.load_external2(cm.ExternalType1(21)) == 21
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        assert m.load_external1(cm.ExternalType2(12)) == 12
+    assert "incompatible function arguments" in str(excinfo.value)
+
+
+def test_local_bindings():
+    """Tests that duplicate `py::module_local` class bindings work across modules"""
+
+    # Make sure we can load the second module with the conflicting (but local) definition:
+    import pybind11_cross_module_tests as cm
+
+    i1 = m.LocalType(5)
+    assert i1.get() == 4
+    assert i1.get3() == 8
+
+    i2 = cm.LocalType(10)
+    assert i2.get() == 11
+    assert i2.get2() == 12
+
+    assert not hasattr(i1, "get2")
+    assert not hasattr(i2, "get3")
+
+    # Loading within the local module
+    assert m.local_value(i1) == 5
+    assert cm.local_value(i2) == 10
+
+    # Cross-module loading works as well (on failure, the type loader looks for
+    # external module-local converters):
+    assert m.local_value(i2) == 10
+    assert cm.local_value(i1) == 5
+
+
+def test_nonlocal_failure():
+    """Tests that attempting to register a non-local type in multiple modules fails"""
+    import pybind11_cross_module_tests as cm
+
+    with pytest.raises(RuntimeError) as excinfo:
+        cm.register_nonlocal()
+    assert (
+        str(excinfo.value) == 'generic_type: type "NonLocalType" is already registered!'
+    )
+
+
+def test_duplicate_local():
+    """Tests expected failure when registering a class twice with py::local in the same module"""
+    with pytest.raises(RuntimeError) as excinfo:
+        m.register_local_external()
+    import pybind11_tests
+
+    assert str(excinfo.value) == (
+        'generic_type: type "LocalExternal" is already registered!'
+        if hasattr(pybind11_tests, "class_")
+        else "test_class not enabled"
+    )
+
+
+def test_stl_bind_local():
+    import pybind11_cross_module_tests as cm
+
+    v1, v2 = m.LocalVec(), cm.LocalVec()
+    v1.append(m.LocalType(1))
+    v1.append(m.LocalType(2))
+    v2.append(cm.LocalType(1))
+    v2.append(cm.LocalType(2))
+
+    # Cross module value loading:
+    v1.append(cm.LocalType(3))
+    v2.append(m.LocalType(3))
+
+    assert [i.get() for i in v1] == [0, 1, 2]
+    assert [i.get() for i in v2] == [2, 3, 4]
+
+    v3, v4 = m.NonLocalVec(), cm.NonLocalVec2()
+    v3.append(m.NonLocalType(1))
+    v3.append(m.NonLocalType(2))
+    v4.append(m.NonLocal2(3))
+    v4.append(m.NonLocal2(4))
+
+    assert [i.get() for i in v3] == [1, 2]
+    assert [i.get() for i in v4] == [13, 14]
+
+    d1, d2 = m.LocalMap(), cm.LocalMap()
+    d1["a"] = v1[0]
+    d1["b"] = v1[1]
+    d2["c"] = v2[0]
+    d2["d"] = v2[1]
+    assert {i: d1[i].get() for i in d1} == {"a": 0, "b": 1}
+    assert {i: d2[i].get() for i in d2} == {"c": 2, "d": 3}
+
+
+def test_stl_bind_global():
+    import pybind11_cross_module_tests as cm
+
+    with pytest.raises(RuntimeError) as excinfo:
+        cm.register_nonlocal_map()
+    assert (
+        str(excinfo.value) == 'generic_type: type "NonLocalMap" is already registered!'
+    )
+
+    with pytest.raises(RuntimeError) as excinfo:
+        cm.register_nonlocal_vec()
+    assert (
+        str(excinfo.value) == 'generic_type: type "NonLocalVec" is already registered!'
+    )
+
+    with pytest.raises(RuntimeError) as excinfo:
+        cm.register_nonlocal_map2()
+    assert (
+        str(excinfo.value) == 'generic_type: type "NonLocalMap2" is already registered!'
+    )
+
+
+def test_mixed_local_global():
+    """Local types take precedence over globally registered types: a module with a `module_local`
+    type can be registered even if the type is already registered globally.  With the module,
+    casting will go to the local type; outside the module casting goes to the global type.
+    """
+    import pybind11_cross_module_tests as cm
+
+    m.register_mixed_global()
+    m.register_mixed_local()
+
+    a = []
+    a.append(m.MixedGlobalLocal(1))
+    a.append(m.MixedLocalGlobal(2))
+    a.append(m.get_mixed_gl(3))
+    a.append(m.get_mixed_lg(4))
+
+    assert [x.get() for x in a] == [101, 1002, 103, 1004]
+
+    cm.register_mixed_global_local()
+    cm.register_mixed_local_global()
+    a.append(m.MixedGlobalLocal(5))
+    a.append(m.MixedLocalGlobal(6))
+    a.append(cm.MixedGlobalLocal(7))
+    a.append(cm.MixedLocalGlobal(8))
+    a.append(m.get_mixed_gl(9))
+    a.append(m.get_mixed_lg(10))
+    a.append(cm.get_mixed_gl(11))
+    a.append(cm.get_mixed_lg(12))
+
+    assert [x.get() for x in a] == [
+        101,
+        1002,
+        103,
+        1004,
+        105,
+        1006,
+        207,
+        2008,
+        109,
+        1010,
+        211,
+        2012,
+    ]
+
+
+def test_internal_locals_differ():
+    """Makes sure the internal local type map differs across the two modules"""
+    import pybind11_cross_module_tests as cm
+
+    assert m.local_cpp_types_addr() != cm.local_cpp_types_addr()
+
+
+@pytest.mark.xfail("env.PYPY and sys.pypy_version_info < (7, 3, 2)")
+def test_stl_caster_vs_stl_bind(msg):
+    """One module uses a generic vector caster from `<pybind11/stl.h>` while the other
+    exports `std::vector<int>` via `py:bind_vector` and `py::module_local`"""
+    import pybind11_cross_module_tests as cm
+
+    v1 = cm.VectorInt([1, 2, 3])
+    assert m.load_vector_via_caster(v1) == 6
+    assert cm.load_vector_via_binding(v1) == 6
+
+    v2 = [1, 2, 3]
+    assert m.load_vector_via_caster(v2) == 6
+    with pytest.raises(TypeError) as excinfo:
+        cm.load_vector_via_binding(v2)
+    assert (
+        msg(excinfo.value)
+        == """
+    load_vector_via_binding(): incompatible function arguments. The following argument types are supported:
+        1. (arg0: pybind11_cross_module_tests.VectorInt) -> int
+
+    Invoked with: [1, 2, 3]
+    """
+    )
+
+
+def test_cross_module_calls():
+    import pybind11_cross_module_tests as cm
+
+    v1 = m.LocalVec()
+    v1.append(m.LocalType(1))
+    v2 = cm.LocalVec()
+    v2.append(cm.LocalType(2))
+
+    # Returning the self pointer should get picked up as returning an existing
+    # instance (even when that instance is of a foreign, non-local type).
+    assert m.return_self(v1) is v1
+    assert cm.return_self(v2) is v2
+    assert m.return_self(v2) is v2
+    assert cm.return_self(v1) is v1
+
+    assert m.LocalVec is not cm.LocalVec
+    # Returning a copy, on the other hand, always goes to the local type,
+    # regardless of where the source type came from.
+    assert type(m.return_copy(v1)) is m.LocalVec
+    assert type(m.return_copy(v2)) is m.LocalVec
+    assert type(cm.return_copy(v1)) is cm.LocalVec
+    assert type(cm.return_copy(v2)) is cm.LocalVec
+
+    # Test the example given in the documentation (which also tests inheritance casting):
+    mycat = m.Cat("Fluffy")
+    mydog = cm.Dog("Rover")
+    assert mycat.get_name() == "Fluffy"
+    assert mydog.name() == "Rover"
+    assert m.Cat.__base__.__name__ == "Pet"
+    assert cm.Dog.__base__.__name__ == "Pet"
+    assert m.Cat.__base__ is not cm.Dog.__base__
+    assert m.pet_name(mycat) == "Fluffy"
+    assert m.pet_name(mydog) == "Rover"
+    assert cm.pet_name(mycat) == "Fluffy"
+    assert cm.pet_name(mydog) == "Rover"
+
+    assert m.MixGL is not cm.MixGL
+    a = m.MixGL(1)
+    b = cm.MixGL(2)
+    assert m.get_gl_value(a) == 11
+    assert m.get_gl_value(b) == 12
+    assert cm.get_gl_value(a) == 101
+    assert cm.get_gl_value(b) == 102
+
+    c, d = m.MixGL2(3), cm.MixGL2(4)
+    with pytest.raises(TypeError) as excinfo:
+        m.get_gl_value(c)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.get_gl_value(d)
+    assert "incompatible function arguments" in str(excinfo.value)
```

## extern/pybind11/tests/test_methods_and_attributes.py

 * *Ordering differences only*

```diff
@@ -1,537 +1,537 @@
-import sys
-
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import ConstructorStats
-from pybind11_tests import methods_and_attributes as m
-
-NO_GETTER_MSG = (
-    "unreadable attribute" if sys.version_info < (3, 11) else "object has no getter"
-)
-NO_SETTER_MSG = (
-    "can't set attribute" if sys.version_info < (3, 11) else "object has no setter"
-)
-NO_DELETER_MSG = (
-    "can't delete attribute" if sys.version_info < (3, 11) else "object has no deleter"
-)
-
-
-def test_methods_and_attributes():
-    instance1 = m.ExampleMandA()
-    instance2 = m.ExampleMandA(32)
-
-    instance1.add1(instance2)
-    instance1.add2(instance2)
-    instance1.add3(instance2)
-    instance1.add4(instance2)
-    instance1.add5(instance2)
-    instance1.add6(32)
-    instance1.add7(32)
-    instance1.add8(32)
-    instance1.add9(32)
-    instance1.add10(32)
-
-    assert str(instance1) == "ExampleMandA[value=320]"
-    assert str(instance2) == "ExampleMandA[value=32]"
-    assert str(instance1.self1()) == "ExampleMandA[value=320]"
-    assert str(instance1.self2()) == "ExampleMandA[value=320]"
-    assert str(instance1.self3()) == "ExampleMandA[value=320]"
-    assert str(instance1.self4()) == "ExampleMandA[value=320]"
-    assert str(instance1.self5()) == "ExampleMandA[value=320]"
-
-    assert instance1.internal1() == 320
-    assert instance1.internal2() == 320
-    assert instance1.internal3() == 320
-    assert instance1.internal4() == 320
-    assert instance1.internal5() == 320
-
-    assert instance1.overloaded() == "()"
-    assert instance1.overloaded(0) == "(int)"
-    assert instance1.overloaded(1, 1.0) == "(int, float)"
-    assert instance1.overloaded(2.0, 2) == "(float, int)"
-    assert instance1.overloaded(3, 3) == "(int, int)"
-    assert instance1.overloaded(4.0, 4.0) == "(float, float)"
-    assert instance1.overloaded_const(-3) == "(int) const"
-    assert instance1.overloaded_const(5, 5.0) == "(int, float) const"
-    assert instance1.overloaded_const(6.0, 6) == "(float, int) const"
-    assert instance1.overloaded_const(7, 7) == "(int, int) const"
-    assert instance1.overloaded_const(8.0, 8.0) == "(float, float) const"
-    assert instance1.overloaded_float(1, 1) == "(float, float)"
-    assert instance1.overloaded_float(1, 1.0) == "(float, float)"
-    assert instance1.overloaded_float(1.0, 1) == "(float, float)"
-    assert instance1.overloaded_float(1.0, 1.0) == "(float, float)"
-
-    assert instance1.value == 320
-    instance1.value = 100
-    assert str(instance1) == "ExampleMandA[value=100]"
-
-    cstats = ConstructorStats.get(m.ExampleMandA)
-    assert cstats.alive() == 2
-    del instance1, instance2
-    assert cstats.alive() == 0
-    assert cstats.values() == ["32"]
-    assert cstats.default_constructions == 1
-    assert cstats.copy_constructions == 2
-    assert cstats.move_constructions >= 2
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-
-def test_copy_method():
-    """Issue #443: calling copied methods fails in Python 3"""
-
-    m.ExampleMandA.add2c = m.ExampleMandA.add2
-    m.ExampleMandA.add2d = m.ExampleMandA.add2b
-    a = m.ExampleMandA(123)
-    assert a.value == 123
-    a.add2(m.ExampleMandA(-100))
-    assert a.value == 23
-    a.add2b(m.ExampleMandA(20))
-    assert a.value == 43
-    a.add2c(m.ExampleMandA(6))
-    assert a.value == 49
-    a.add2d(m.ExampleMandA(-7))
-    assert a.value == 42
-
-
-def test_properties():
-    instance = m.TestProperties()
-
-    assert instance.def_readonly == 1
-    with pytest.raises(AttributeError):
-        instance.def_readonly = 2
-
-    instance.def_readwrite = 2
-    assert instance.def_readwrite == 2
-
-    assert instance.def_property_readonly == 2
-    with pytest.raises(AttributeError):
-        instance.def_property_readonly = 3
-
-    instance.def_property = 3
-    assert instance.def_property == 3
-
-    with pytest.raises(AttributeError) as excinfo:
-        dummy = instance.def_property_writeonly  # unused var
-    assert NO_GETTER_MSG in str(excinfo.value)
-
-    instance.def_property_writeonly = 4
-    assert instance.def_property_readonly == 4
-
-    with pytest.raises(AttributeError) as excinfo:
-        dummy = instance.def_property_impossible  # noqa: F841 unused var
-    assert NO_GETTER_MSG in str(excinfo.value)
-
-    with pytest.raises(AttributeError) as excinfo:
-        instance.def_property_impossible = 5
-    assert NO_SETTER_MSG in str(excinfo.value)
-
-
-def test_static_properties():
-    assert m.TestProperties.def_readonly_static == 1
-    with pytest.raises(AttributeError) as excinfo:
-        m.TestProperties.def_readonly_static = 2
-    assert NO_SETTER_MSG in str(excinfo.value)
-
-    m.TestProperties.def_readwrite_static = 2
-    assert m.TestProperties.def_readwrite_static == 2
-
-    with pytest.raises(AttributeError) as excinfo:
-        dummy = m.TestProperties.def_writeonly_static  # unused var
-    assert NO_GETTER_MSG in str(excinfo.value)
-
-    m.TestProperties.def_writeonly_static = 3
-    assert m.TestProperties.def_readonly_static == 3
-
-    assert m.TestProperties.def_property_readonly_static == 3
-    with pytest.raises(AttributeError) as excinfo:
-        m.TestProperties.def_property_readonly_static = 99
-    assert NO_SETTER_MSG in str(excinfo.value)
-
-    m.TestProperties.def_property_static = 4
-    assert m.TestProperties.def_property_static == 4
-
-    with pytest.raises(AttributeError) as excinfo:
-        dummy = m.TestProperties.def_property_writeonly_static
-    assert NO_GETTER_MSG in str(excinfo.value)
-
-    m.TestProperties.def_property_writeonly_static = 5
-    assert m.TestProperties.def_property_static == 5
-
-    # Static property read and write via instance
-    instance = m.TestProperties()
-
-    m.TestProperties.def_readwrite_static = 0
-    assert m.TestProperties.def_readwrite_static == 0
-    assert instance.def_readwrite_static == 0
-
-    instance.def_readwrite_static = 2
-    assert m.TestProperties.def_readwrite_static == 2
-    assert instance.def_readwrite_static == 2
-
-    with pytest.raises(AttributeError) as excinfo:
-        dummy = instance.def_property_writeonly_static  # noqa: F841 unused var
-    assert NO_GETTER_MSG in str(excinfo.value)
-
-    instance.def_property_writeonly_static = 4
-    assert instance.def_property_static == 4
-
-    # It should be possible to override properties in derived classes
-    assert m.TestPropertiesOverride().def_readonly == 99
-    assert m.TestPropertiesOverride.def_readonly_static == 99
-
-    # Only static attributes can be deleted
-    del m.TestPropertiesOverride.def_readonly_static
-    assert hasattr(m.TestPropertiesOverride, "def_readonly_static")
-    assert (
-        m.TestPropertiesOverride.def_readonly_static
-        is m.TestProperties.def_readonly_static
-    )
-    assert "def_readonly_static" not in m.TestPropertiesOverride.__dict__
-    properties_override = m.TestPropertiesOverride()
-    with pytest.raises(AttributeError) as excinfo:
-        del properties_override.def_readonly
-    assert NO_DELETER_MSG in str(excinfo.value)
-
-
-def test_static_cls():
-    """Static property getter and setters expect the type object as the their only argument"""
-
-    instance = m.TestProperties()
-    assert m.TestProperties.static_cls is m.TestProperties
-    assert instance.static_cls is m.TestProperties
-
-    def check_self(self):
-        assert self is m.TestProperties
-
-    m.TestProperties.static_cls = check_self
-    instance.static_cls = check_self
-
-
-def test_metaclass_override():
-    """Overriding pybind11's default metaclass changes the behavior of `static_property`"""
-
-    assert type(m.ExampleMandA).__name__ == "pybind11_type"
-    assert type(m.MetaclassOverride).__name__ == "type"
-
-    assert m.MetaclassOverride.readonly == 1
-    assert (
-        type(m.MetaclassOverride.__dict__["readonly"]).__name__
-        == "pybind11_static_property"
-    )
-
-    # Regular `type` replaces the property instead of calling `__set__()`
-    m.MetaclassOverride.readonly = 2
-    assert m.MetaclassOverride.readonly == 2
-    assert isinstance(m.MetaclassOverride.__dict__["readonly"], int)
-
-
-def test_no_mixed_overloads():
-    from pybind11_tests import detailed_error_messages_enabled
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.ExampleMandA.add_mixed_overloads1()
-    assert (
-        str(excinfo.value)
-        == "overloading a method with both static and instance methods is not supported; "
-        + (
-            "#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more details"
-            if not detailed_error_messages_enabled
-            else "error while attempting to bind static method ExampleMandA.overload_mixed1"
-            "(arg0: float) -> str"
-        )
-    )
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.ExampleMandA.add_mixed_overloads2()
-    assert (
-        str(excinfo.value)
-        == "overloading a method with both static and instance methods is not supported; "
-        + (
-            "#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more details"
-            if not detailed_error_messages_enabled
-            else "error while attempting to bind instance method ExampleMandA.overload_mixed2"
-            "(self: pybind11_tests.methods_and_attributes.ExampleMandA, arg0: int, arg1: int)"
-            " -> str"
-        )
-    )
-
-
-@pytest.mark.parametrize("access", ["ro", "rw", "static_ro", "static_rw"])
-def test_property_return_value_policies(access):
-    obj = m.TestPropRVP() if not access.startswith("static") else m.TestPropRVP
-
-    ref = getattr(obj, access + "_ref")
-    assert ref.value == 1
-    ref.value = 2
-    assert getattr(obj, access + "_ref").value == 2
-    ref.value = 1  # restore original value for static properties
-
-    copy = getattr(obj, access + "_copy")
-    assert copy.value == 1
-    copy.value = 2
-    assert getattr(obj, access + "_copy").value == 1
-
-    copy = getattr(obj, access + "_func")
-    assert copy.value == 1
-    copy.value = 2
-    assert getattr(obj, access + "_func").value == 1
-
-
-def test_property_rvalue_policy():
-    """When returning an rvalue, the return value policy is automatically changed from
-    `reference(_internal)` to `move`. The following would not work otherwise."""
-
-    instance = m.TestPropRVP()
-    o = instance.rvalue
-    assert o.value == 1
-
-    os = m.TestPropRVP.static_rvalue
-    assert os.value == 1
-
-
-# https://foss.heptapod.net/pypy/pypy/-/issues/2447
-@pytest.mark.xfail("env.PYPY")
-def test_dynamic_attributes():
-    instance = m.DynamicClass()
-    assert not hasattr(instance, "foo")
-    assert "foo" not in dir(instance)
-
-    # Dynamically add attribute
-    instance.foo = 42
-    assert hasattr(instance, "foo")
-    assert instance.foo == 42
-    assert "foo" in dir(instance)
-
-    # __dict__ should be accessible and replaceable
-    assert "foo" in instance.__dict__
-    instance.__dict__ = {"bar": True}
-    assert not hasattr(instance, "foo")
-    assert hasattr(instance, "bar")
-
-    with pytest.raises(TypeError) as excinfo:
-        instance.__dict__ = []
-    assert str(excinfo.value) == "__dict__ must be set to a dictionary, not a 'list'"
-
-    cstats = ConstructorStats.get(m.DynamicClass)
-    assert cstats.alive() == 1
-    del instance
-    assert cstats.alive() == 0
-
-    # Derived classes should work as well
-    class PythonDerivedDynamicClass(m.DynamicClass):
-        pass
-
-    for cls in m.CppDerivedDynamicClass, PythonDerivedDynamicClass:
-        derived = cls()
-        derived.foobar = 100
-        assert derived.foobar == 100
-
-        assert cstats.alive() == 1
-        del derived
-        assert cstats.alive() == 0
-
-
-# https://foss.heptapod.net/pypy/pypy/-/issues/2447
-@pytest.mark.xfail("env.PYPY")
-def test_cyclic_gc():
-    # One object references itself
-    instance = m.DynamicClass()
-    instance.circular_reference = instance
-
-    cstats = ConstructorStats.get(m.DynamicClass)
-    assert cstats.alive() == 1
-    del instance
-    assert cstats.alive() == 0
-
-    # Two object reference each other
-    i1 = m.DynamicClass()
-    i2 = m.DynamicClass()
-    i1.cycle = i2
-    i2.cycle = i1
-
-    assert cstats.alive() == 2
-    del i1, i2
-    assert cstats.alive() == 0
-
-
-def test_bad_arg_default(msg):
-    from pybind11_tests import detailed_error_messages_enabled
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.bad_arg_def_named()
-    assert msg(excinfo.value) == (
-        "arg(): could not convert default argument 'a: UnregisteredType' in function "
-        "'should_fail' into a Python object (type not registered yet?)"
-        if detailed_error_messages_enabled
-        else "arg(): could not convert default argument into a Python object (type not registered "
-        "yet?). #define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more information."
-    )
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.bad_arg_def_unnamed()
-    assert msg(excinfo.value) == (
-        "arg(): could not convert default argument 'UnregisteredType' in function "
-        "'should_fail' into a Python object (type not registered yet?)"
-        if detailed_error_messages_enabled
-        else "arg(): could not convert default argument into a Python object (type not registered "
-        "yet?). #define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more information."
-    )
-
-
-def test_accepts_none(msg):
-    a = m.NoneTester()
-    assert m.no_none1(a) == 42
-    assert m.no_none2(a) == 42
-    assert m.no_none3(a) == 42
-    assert m.no_none4(a) == 42
-    assert m.no_none5(a) == 42
-    assert m.ok_none1(a) == 42
-    assert m.ok_none2(a) == 42
-    assert m.ok_none3(a) == 42
-    assert m.ok_none4(a) == 42
-    assert m.ok_none5(a) == 42
-
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none1(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none2(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none3(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none4(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none5(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    # The first one still raises because you can't pass None as a lvalue reference arg:
-    with pytest.raises(TypeError) as excinfo:
-        assert m.ok_none1(None) == -1
-    assert (
-        msg(excinfo.value)
-        == """
-        ok_none1(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: m.methods_and_attributes.NoneTester) -> int
-
-        Invoked with: None
-    """
-    )
-
-    # The rest take the argument as pointer or holder, and accept None:
-    assert m.ok_none2(None) == -1
-    assert m.ok_none3(None) == -1
-    assert m.ok_none4(None) == -1
-    assert m.ok_none5(None) == -1
-
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none_kwarg(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none_kwarg(a=None)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none_kwarg_kw_only(None)
-    assert "incompatible function arguments" in str(excinfo.value)
-    with pytest.raises(TypeError) as excinfo:
-        m.no_none_kwarg_kw_only(a=None)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-
-def test_casts_none():
-    """#2778: implicit casting from None to object (not pointer)"""
-    a = m.NoneCastTester()
-    assert m.ok_obj_or_none(a) == -1
-    a = m.NoneCastTester(4)
-    assert m.ok_obj_or_none(a) == 4
-    a = m.NoneCastTester(None)
-    assert m.ok_obj_or_none(a) == -1
-    assert m.ok_obj_or_none(None) == -1
-
-
-def test_str_issue(msg):
-    """#283: __str__ called on uninitialized instance when constructor arguments invalid"""
-
-    assert str(m.StrIssue(3)) == "StrIssue[3]"
-
-    with pytest.raises(TypeError) as excinfo:
-        str(m.StrIssue("no", "such", "constructor"))
-    assert (
-        msg(excinfo.value)
-        == """
-        __init__(): incompatible constructor arguments. The following argument types are supported:
-            1. m.methods_and_attributes.StrIssue(arg0: int)
-            2. m.methods_and_attributes.StrIssue()
-
-        Invoked with: 'no', 'such', 'constructor'
-    """
-    )
-
-
-def test_unregistered_base_implementations():
-    a = m.RegisteredDerived()
-    a.do_nothing()
-    assert a.rw_value == 42
-    assert a.ro_value == 1.25
-    a.rw_value += 5
-    assert a.sum() == 48.25
-    a.increase_value()
-    assert a.rw_value == 48
-    assert a.ro_value == 1.5
-    assert a.sum() == 49.5
-    assert a.rw_value_prop == 48
-    a.rw_value_prop += 1
-    assert a.rw_value_prop == 49
-    a.increase_value()
-    assert a.ro_value_prop == 1.75
-
-
-def test_ref_qualified():
-    """Tests that explicit lvalue ref-qualified methods can be called just like their
-    non ref-qualified counterparts."""
-
-    r = m.RefQualified()
-    assert r.value == 0
-    r.refQualified(17)
-    assert r.value == 17
-    assert r.constRefQualified(23) == 40
-
-
-def test_overload_ordering():
-    "Check to see if the normal overload order (first defined) and prepend overload order works"
-    assert m.overload_order("string") == 1
-    assert m.overload_order(0) == 4
-
-    assert "1. overload_order(arg0: int) -> int" in m.overload_order.__doc__
-    assert "2. overload_order(arg0: str) -> int" in m.overload_order.__doc__
-    assert "3. overload_order(arg0: str) -> int" in m.overload_order.__doc__
-    assert "4. overload_order(arg0: int) -> int" in m.overload_order.__doc__
-
-    with pytest.raises(TypeError) as err:
-        m.overload_order(1.1)
-
-    assert "1. (arg0: int) -> int" in str(err.value)
-    assert "2. (arg0: str) -> int" in str(err.value)
-    assert "3. (arg0: str) -> int" in str(err.value)
-    assert "4. (arg0: int) -> int" in str(err.value)
-
-
-def test_rvalue_ref_param():
-    r = m.RValueRefParam()
-    assert r.func1("123") == 3
-    assert r.func2("1234") == 4
-    assert r.func3("12345") == 5
-    assert r.func4("123456") == 6
-
-
-def test_is_setter():
-    fld = m.exercise_is_setter.Field()
-    assert fld.int_value == -99
-    setter_return = fld.int_value = 100
-    assert isinstance(setter_return, int)
-    assert setter_return == 100
-    assert fld.int_value == 100
+import sys
+
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import ConstructorStats
+from pybind11_tests import methods_and_attributes as m
+
+NO_GETTER_MSG = (
+    "unreadable attribute" if sys.version_info < (3, 11) else "object has no getter"
+)
+NO_SETTER_MSG = (
+    "can't set attribute" if sys.version_info < (3, 11) else "object has no setter"
+)
+NO_DELETER_MSG = (
+    "can't delete attribute" if sys.version_info < (3, 11) else "object has no deleter"
+)
+
+
+def test_methods_and_attributes():
+    instance1 = m.ExampleMandA()
+    instance2 = m.ExampleMandA(32)
+
+    instance1.add1(instance2)
+    instance1.add2(instance2)
+    instance1.add3(instance2)
+    instance1.add4(instance2)
+    instance1.add5(instance2)
+    instance1.add6(32)
+    instance1.add7(32)
+    instance1.add8(32)
+    instance1.add9(32)
+    instance1.add10(32)
+
+    assert str(instance1) == "ExampleMandA[value=320]"
+    assert str(instance2) == "ExampleMandA[value=32]"
+    assert str(instance1.self1()) == "ExampleMandA[value=320]"
+    assert str(instance1.self2()) == "ExampleMandA[value=320]"
+    assert str(instance1.self3()) == "ExampleMandA[value=320]"
+    assert str(instance1.self4()) == "ExampleMandA[value=320]"
+    assert str(instance1.self5()) == "ExampleMandA[value=320]"
+
+    assert instance1.internal1() == 320
+    assert instance1.internal2() == 320
+    assert instance1.internal3() == 320
+    assert instance1.internal4() == 320
+    assert instance1.internal5() == 320
+
+    assert instance1.overloaded() == "()"
+    assert instance1.overloaded(0) == "(int)"
+    assert instance1.overloaded(1, 1.0) == "(int, float)"
+    assert instance1.overloaded(2.0, 2) == "(float, int)"
+    assert instance1.overloaded(3, 3) == "(int, int)"
+    assert instance1.overloaded(4.0, 4.0) == "(float, float)"
+    assert instance1.overloaded_const(-3) == "(int) const"
+    assert instance1.overloaded_const(5, 5.0) == "(int, float) const"
+    assert instance1.overloaded_const(6.0, 6) == "(float, int) const"
+    assert instance1.overloaded_const(7, 7) == "(int, int) const"
+    assert instance1.overloaded_const(8.0, 8.0) == "(float, float) const"
+    assert instance1.overloaded_float(1, 1) == "(float, float)"
+    assert instance1.overloaded_float(1, 1.0) == "(float, float)"
+    assert instance1.overloaded_float(1.0, 1) == "(float, float)"
+    assert instance1.overloaded_float(1.0, 1.0) == "(float, float)"
+
+    assert instance1.value == 320
+    instance1.value = 100
+    assert str(instance1) == "ExampleMandA[value=100]"
+
+    cstats = ConstructorStats.get(m.ExampleMandA)
+    assert cstats.alive() == 2
+    del instance1, instance2
+    assert cstats.alive() == 0
+    assert cstats.values() == ["32"]
+    assert cstats.default_constructions == 1
+    assert cstats.copy_constructions == 2
+    assert cstats.move_constructions >= 2
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+
+def test_copy_method():
+    """Issue #443: calling copied methods fails in Python 3"""
+
+    m.ExampleMandA.add2c = m.ExampleMandA.add2
+    m.ExampleMandA.add2d = m.ExampleMandA.add2b
+    a = m.ExampleMandA(123)
+    assert a.value == 123
+    a.add2(m.ExampleMandA(-100))
+    assert a.value == 23
+    a.add2b(m.ExampleMandA(20))
+    assert a.value == 43
+    a.add2c(m.ExampleMandA(6))
+    assert a.value == 49
+    a.add2d(m.ExampleMandA(-7))
+    assert a.value == 42
+
+
+def test_properties():
+    instance = m.TestProperties()
+
+    assert instance.def_readonly == 1
+    with pytest.raises(AttributeError):
+        instance.def_readonly = 2
+
+    instance.def_readwrite = 2
+    assert instance.def_readwrite == 2
+
+    assert instance.def_property_readonly == 2
+    with pytest.raises(AttributeError):
+        instance.def_property_readonly = 3
+
+    instance.def_property = 3
+    assert instance.def_property == 3
+
+    with pytest.raises(AttributeError) as excinfo:
+        dummy = instance.def_property_writeonly  # unused var
+    assert NO_GETTER_MSG in str(excinfo.value)
+
+    instance.def_property_writeonly = 4
+    assert instance.def_property_readonly == 4
+
+    with pytest.raises(AttributeError) as excinfo:
+        dummy = instance.def_property_impossible  # noqa: F841 unused var
+    assert NO_GETTER_MSG in str(excinfo.value)
+
+    with pytest.raises(AttributeError) as excinfo:
+        instance.def_property_impossible = 5
+    assert NO_SETTER_MSG in str(excinfo.value)
+
+
+def test_static_properties():
+    assert m.TestProperties.def_readonly_static == 1
+    with pytest.raises(AttributeError) as excinfo:
+        m.TestProperties.def_readonly_static = 2
+    assert NO_SETTER_MSG in str(excinfo.value)
+
+    m.TestProperties.def_readwrite_static = 2
+    assert m.TestProperties.def_readwrite_static == 2
+
+    with pytest.raises(AttributeError) as excinfo:
+        dummy = m.TestProperties.def_writeonly_static  # unused var
+    assert NO_GETTER_MSG in str(excinfo.value)
+
+    m.TestProperties.def_writeonly_static = 3
+    assert m.TestProperties.def_readonly_static == 3
+
+    assert m.TestProperties.def_property_readonly_static == 3
+    with pytest.raises(AttributeError) as excinfo:
+        m.TestProperties.def_property_readonly_static = 99
+    assert NO_SETTER_MSG in str(excinfo.value)
+
+    m.TestProperties.def_property_static = 4
+    assert m.TestProperties.def_property_static == 4
+
+    with pytest.raises(AttributeError) as excinfo:
+        dummy = m.TestProperties.def_property_writeonly_static
+    assert NO_GETTER_MSG in str(excinfo.value)
+
+    m.TestProperties.def_property_writeonly_static = 5
+    assert m.TestProperties.def_property_static == 5
+
+    # Static property read and write via instance
+    instance = m.TestProperties()
+
+    m.TestProperties.def_readwrite_static = 0
+    assert m.TestProperties.def_readwrite_static == 0
+    assert instance.def_readwrite_static == 0
+
+    instance.def_readwrite_static = 2
+    assert m.TestProperties.def_readwrite_static == 2
+    assert instance.def_readwrite_static == 2
+
+    with pytest.raises(AttributeError) as excinfo:
+        dummy = instance.def_property_writeonly_static  # noqa: F841 unused var
+    assert NO_GETTER_MSG in str(excinfo.value)
+
+    instance.def_property_writeonly_static = 4
+    assert instance.def_property_static == 4
+
+    # It should be possible to override properties in derived classes
+    assert m.TestPropertiesOverride().def_readonly == 99
+    assert m.TestPropertiesOverride.def_readonly_static == 99
+
+    # Only static attributes can be deleted
+    del m.TestPropertiesOverride.def_readonly_static
+    assert hasattr(m.TestPropertiesOverride, "def_readonly_static")
+    assert (
+        m.TestPropertiesOverride.def_readonly_static
+        is m.TestProperties.def_readonly_static
+    )
+    assert "def_readonly_static" not in m.TestPropertiesOverride.__dict__
+    properties_override = m.TestPropertiesOverride()
+    with pytest.raises(AttributeError) as excinfo:
+        del properties_override.def_readonly
+    assert NO_DELETER_MSG in str(excinfo.value)
+
+
+def test_static_cls():
+    """Static property getter and setters expect the type object as the their only argument"""
+
+    instance = m.TestProperties()
+    assert m.TestProperties.static_cls is m.TestProperties
+    assert instance.static_cls is m.TestProperties
+
+    def check_self(self):
+        assert self is m.TestProperties
+
+    m.TestProperties.static_cls = check_self
+    instance.static_cls = check_self
+
+
+def test_metaclass_override():
+    """Overriding pybind11's default metaclass changes the behavior of `static_property`"""
+
+    assert type(m.ExampleMandA).__name__ == "pybind11_type"
+    assert type(m.MetaclassOverride).__name__ == "type"
+
+    assert m.MetaclassOverride.readonly == 1
+    assert (
+        type(m.MetaclassOverride.__dict__["readonly"]).__name__
+        == "pybind11_static_property"
+    )
+
+    # Regular `type` replaces the property instead of calling `__set__()`
+    m.MetaclassOverride.readonly = 2
+    assert m.MetaclassOverride.readonly == 2
+    assert isinstance(m.MetaclassOverride.__dict__["readonly"], int)
+
+
+def test_no_mixed_overloads():
+    from pybind11_tests import detailed_error_messages_enabled
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.ExampleMandA.add_mixed_overloads1()
+    assert (
+        str(excinfo.value)
+        == "overloading a method with both static and instance methods is not supported; "
+        + (
+            "#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more details"
+            if not detailed_error_messages_enabled
+            else "error while attempting to bind static method ExampleMandA.overload_mixed1"
+            "(arg0: float) -> str"
+        )
+    )
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.ExampleMandA.add_mixed_overloads2()
+    assert (
+        str(excinfo.value)
+        == "overloading a method with both static and instance methods is not supported; "
+        + (
+            "#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more details"
+            if not detailed_error_messages_enabled
+            else "error while attempting to bind instance method ExampleMandA.overload_mixed2"
+            "(self: pybind11_tests.methods_and_attributes.ExampleMandA, arg0: int, arg1: int)"
+            " -> str"
+        )
+    )
+
+
+@pytest.mark.parametrize("access", ["ro", "rw", "static_ro", "static_rw"])
+def test_property_return_value_policies(access):
+    obj = m.TestPropRVP() if not access.startswith("static") else m.TestPropRVP
+
+    ref = getattr(obj, access + "_ref")
+    assert ref.value == 1
+    ref.value = 2
+    assert getattr(obj, access + "_ref").value == 2
+    ref.value = 1  # restore original value for static properties
+
+    copy = getattr(obj, access + "_copy")
+    assert copy.value == 1
+    copy.value = 2
+    assert getattr(obj, access + "_copy").value == 1
+
+    copy = getattr(obj, access + "_func")
+    assert copy.value == 1
+    copy.value = 2
+    assert getattr(obj, access + "_func").value == 1
+
+
+def test_property_rvalue_policy():
+    """When returning an rvalue, the return value policy is automatically changed from
+    `reference(_internal)` to `move`. The following would not work otherwise."""
+
+    instance = m.TestPropRVP()
+    o = instance.rvalue
+    assert o.value == 1
+
+    os = m.TestPropRVP.static_rvalue
+    assert os.value == 1
+
+
+# https://foss.heptapod.net/pypy/pypy/-/issues/2447
+@pytest.mark.xfail("env.PYPY")
+def test_dynamic_attributes():
+    instance = m.DynamicClass()
+    assert not hasattr(instance, "foo")
+    assert "foo" not in dir(instance)
+
+    # Dynamically add attribute
+    instance.foo = 42
+    assert hasattr(instance, "foo")
+    assert instance.foo == 42
+    assert "foo" in dir(instance)
+
+    # __dict__ should be accessible and replaceable
+    assert "foo" in instance.__dict__
+    instance.__dict__ = {"bar": True}
+    assert not hasattr(instance, "foo")
+    assert hasattr(instance, "bar")
+
+    with pytest.raises(TypeError) as excinfo:
+        instance.__dict__ = []
+    assert str(excinfo.value) == "__dict__ must be set to a dictionary, not a 'list'"
+
+    cstats = ConstructorStats.get(m.DynamicClass)
+    assert cstats.alive() == 1
+    del instance
+    assert cstats.alive() == 0
+
+    # Derived classes should work as well
+    class PythonDerivedDynamicClass(m.DynamicClass):
+        pass
+
+    for cls in m.CppDerivedDynamicClass, PythonDerivedDynamicClass:
+        derived = cls()
+        derived.foobar = 100
+        assert derived.foobar == 100
+
+        assert cstats.alive() == 1
+        del derived
+        assert cstats.alive() == 0
+
+
+# https://foss.heptapod.net/pypy/pypy/-/issues/2447
+@pytest.mark.xfail("env.PYPY")
+def test_cyclic_gc():
+    # One object references itself
+    instance = m.DynamicClass()
+    instance.circular_reference = instance
+
+    cstats = ConstructorStats.get(m.DynamicClass)
+    assert cstats.alive() == 1
+    del instance
+    assert cstats.alive() == 0
+
+    # Two object reference each other
+    i1 = m.DynamicClass()
+    i2 = m.DynamicClass()
+    i1.cycle = i2
+    i2.cycle = i1
+
+    assert cstats.alive() == 2
+    del i1, i2
+    assert cstats.alive() == 0
+
+
+def test_bad_arg_default(msg):
+    from pybind11_tests import detailed_error_messages_enabled
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.bad_arg_def_named()
+    assert msg(excinfo.value) == (
+        "arg(): could not convert default argument 'a: UnregisteredType' in function "
+        "'should_fail' into a Python object (type not registered yet?)"
+        if detailed_error_messages_enabled
+        else "arg(): could not convert default argument into a Python object (type not registered "
+        "yet?). #define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more information."
+    )
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.bad_arg_def_unnamed()
+    assert msg(excinfo.value) == (
+        "arg(): could not convert default argument 'UnregisteredType' in function "
+        "'should_fail' into a Python object (type not registered yet?)"
+        if detailed_error_messages_enabled
+        else "arg(): could not convert default argument into a Python object (type not registered "
+        "yet?). #define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more information."
+    )
+
+
+def test_accepts_none(msg):
+    a = m.NoneTester()
+    assert m.no_none1(a) == 42
+    assert m.no_none2(a) == 42
+    assert m.no_none3(a) == 42
+    assert m.no_none4(a) == 42
+    assert m.no_none5(a) == 42
+    assert m.ok_none1(a) == 42
+    assert m.ok_none2(a) == 42
+    assert m.ok_none3(a) == 42
+    assert m.ok_none4(a) == 42
+    assert m.ok_none5(a) == 42
+
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none1(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none2(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none3(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none4(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none5(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    # The first one still raises because you can't pass None as a lvalue reference arg:
+    with pytest.raises(TypeError) as excinfo:
+        assert m.ok_none1(None) == -1
+    assert (
+        msg(excinfo.value)
+        == """
+        ok_none1(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: m.methods_and_attributes.NoneTester) -> int
+
+        Invoked with: None
+    """
+    )
+
+    # The rest take the argument as pointer or holder, and accept None:
+    assert m.ok_none2(None) == -1
+    assert m.ok_none3(None) == -1
+    assert m.ok_none4(None) == -1
+    assert m.ok_none5(None) == -1
+
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none_kwarg(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none_kwarg(a=None)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none_kwarg_kw_only(None)
+    assert "incompatible function arguments" in str(excinfo.value)
+    with pytest.raises(TypeError) as excinfo:
+        m.no_none_kwarg_kw_only(a=None)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+
+def test_casts_none():
+    """#2778: implicit casting from None to object (not pointer)"""
+    a = m.NoneCastTester()
+    assert m.ok_obj_or_none(a) == -1
+    a = m.NoneCastTester(4)
+    assert m.ok_obj_or_none(a) == 4
+    a = m.NoneCastTester(None)
+    assert m.ok_obj_or_none(a) == -1
+    assert m.ok_obj_or_none(None) == -1
+
+
+def test_str_issue(msg):
+    """#283: __str__ called on uninitialized instance when constructor arguments invalid"""
+
+    assert str(m.StrIssue(3)) == "StrIssue[3]"
+
+    with pytest.raises(TypeError) as excinfo:
+        str(m.StrIssue("no", "such", "constructor"))
+    assert (
+        msg(excinfo.value)
+        == """
+        __init__(): incompatible constructor arguments. The following argument types are supported:
+            1. m.methods_and_attributes.StrIssue(arg0: int)
+            2. m.methods_and_attributes.StrIssue()
+
+        Invoked with: 'no', 'such', 'constructor'
+    """
+    )
+
+
+def test_unregistered_base_implementations():
+    a = m.RegisteredDerived()
+    a.do_nothing()
+    assert a.rw_value == 42
+    assert a.ro_value == 1.25
+    a.rw_value += 5
+    assert a.sum() == 48.25
+    a.increase_value()
+    assert a.rw_value == 48
+    assert a.ro_value == 1.5
+    assert a.sum() == 49.5
+    assert a.rw_value_prop == 48
+    a.rw_value_prop += 1
+    assert a.rw_value_prop == 49
+    a.increase_value()
+    assert a.ro_value_prop == 1.75
+
+
+def test_ref_qualified():
+    """Tests that explicit lvalue ref-qualified methods can be called just like their
+    non ref-qualified counterparts."""
+
+    r = m.RefQualified()
+    assert r.value == 0
+    r.refQualified(17)
+    assert r.value == 17
+    assert r.constRefQualified(23) == 40
+
+
+def test_overload_ordering():
+    "Check to see if the normal overload order (first defined) and prepend overload order works"
+    assert m.overload_order("string") == 1
+    assert m.overload_order(0) == 4
+
+    assert "1. overload_order(arg0: int) -> int" in m.overload_order.__doc__
+    assert "2. overload_order(arg0: str) -> int" in m.overload_order.__doc__
+    assert "3. overload_order(arg0: str) -> int" in m.overload_order.__doc__
+    assert "4. overload_order(arg0: int) -> int" in m.overload_order.__doc__
+
+    with pytest.raises(TypeError) as err:
+        m.overload_order(1.1)
+
+    assert "1. (arg0: int) -> int" in str(err.value)
+    assert "2. (arg0: str) -> int" in str(err.value)
+    assert "3. (arg0: str) -> int" in str(err.value)
+    assert "4. (arg0: int) -> int" in str(err.value)
+
+
+def test_rvalue_ref_param():
+    r = m.RValueRefParam()
+    assert r.func1("123") == 3
+    assert r.func2("1234") == 4
+    assert r.func3("12345") == 5
+    assert r.func4("123456") == 6
+
+
+def test_is_setter():
+    fld = m.exercise_is_setter.Field()
+    assert fld.int_value == -99
+    setter_return = fld.int_value = 100
+    assert isinstance(setter_return, int)
+    assert setter_return == 100
+    assert fld.int_value == 100
```

## extern/pybind11/tests/test_modules.py

 * *Ordering differences only*

```diff
@@ -1,116 +1,116 @@
-import builtins
-
-import pytest
-
-import env
-from pybind11_tests import ConstructorStats
-from pybind11_tests import modules as m
-from pybind11_tests.modules import subsubmodule as ms
-
-
-def test_nested_modules():
-    import pybind11_tests
-
-    assert pybind11_tests.__name__ == "pybind11_tests"
-    assert pybind11_tests.modules.__name__ == "pybind11_tests.modules"
-    assert (
-        pybind11_tests.modules.subsubmodule.__name__
-        == "pybind11_tests.modules.subsubmodule"
-    )
-    assert m.__name__ == "pybind11_tests.modules"
-    assert ms.__name__ == "pybind11_tests.modules.subsubmodule"
-
-    assert ms.submodule_func() == "submodule_func()"
-
-
-def test_reference_internal():
-    b = ms.B()
-    assert str(b.get_a1()) == "A[1]"
-    assert str(b.a1) == "A[1]"
-    assert str(b.get_a2()) == "A[2]"
-    assert str(b.a2) == "A[2]"
-
-    b.a1 = ms.A(42)
-    b.a2 = ms.A(43)
-    assert str(b.get_a1()) == "A[42]"
-    assert str(b.a1) == "A[42]"
-    assert str(b.get_a2()) == "A[43]"
-    assert str(b.a2) == "A[43]"
-
-    astats, bstats = ConstructorStats.get(ms.A), ConstructorStats.get(ms.B)
-    assert astats.alive() == 2
-    assert bstats.alive() == 1
-    del b
-    assert astats.alive() == 0
-    assert bstats.alive() == 0
-    assert astats.values() == ["1", "2", "42", "43"]
-    assert bstats.values() == []
-    assert astats.default_constructions == 0
-    assert bstats.default_constructions == 1
-    assert astats.copy_constructions == 0
-    assert bstats.copy_constructions == 0
-    # assert astats.move_constructions >= 0  # Don't invoke any
-    # assert bstats.move_constructions >= 0  # Don't invoke any
-    assert astats.copy_assignments == 2
-    assert bstats.copy_assignments == 0
-    assert astats.move_assignments == 0
-    assert bstats.move_assignments == 0
-
-
-def test_importing():
-    from collections import OrderedDict
-
-    from pybind11_tests.modules import OD
-
-    assert OD is OrderedDict
-
-
-def test_pydoc():
-    """Pydoc needs to be able to provide help() for everything inside a pybind11 module"""
-    import pydoc
-
-    import pybind11_tests
-
-    assert pybind11_tests.__name__ == "pybind11_tests"
-    assert pybind11_tests.__doc__ == "pybind11 test module"
-    assert pydoc.text.docmodule(pybind11_tests)
-
-
-def test_duplicate_registration():
-    """Registering two things with the same name"""
-
-    assert m.duplicate_registration() == []
-
-
-def test_builtin_key_type():
-    """Test that all the keys in the builtin modules have type str.
-
-    Previous versions of pybind11 would add a unicode key in python 2.
-    """
-    assert all(type(k) == str for k in dir(builtins))
-
-
-@pytest.mark.xfail("env.PYPY", reason="PyModule_GetName()")
-def test_def_submodule_failures():
-    sm = m.def_submodule(m, b"ScratchSubModuleName")  # Using bytes to show it works.
-    assert sm.__name__ == m.__name__ + "." + "ScratchSubModuleName"
-    malformed_utf8 = b"\x80"
-    if env.PYPY:
-        # It is not worth the effort finding a trigger for a failure when running with PyPy.
-        pytest.skip("Sufficiently exercised on platforms other than PyPy.")
-    else:
-        # Meant to trigger PyModule_GetName() failure:
-        sm_name_orig = sm.__name__
-        sm.__name__ = malformed_utf8
-        try:
-            # We want to assert that a bad __name__ causes some kind of failure, although we do not want to exercise
-            # the internals of PyModule_GetName(). Currently all supported Python versions raise SystemError. If that
-            # changes in future Python versions, simply add the new expected exception types here.
-            with pytest.raises(SystemError):
-                m.def_submodule(sm, b"SubSubModuleName")
-        finally:
-            # Clean up to ensure nothing gets upset by a module with an invalid __name__.
-            sm.__name__ = sm_name_orig  # Purely precautionary.
-    # Meant to trigger PyImport_AddModule() failure:
-    with pytest.raises(UnicodeDecodeError):
-        m.def_submodule(sm, malformed_utf8)
+import builtins
+
+import pytest
+
+import env
+from pybind11_tests import ConstructorStats
+from pybind11_tests import modules as m
+from pybind11_tests.modules import subsubmodule as ms
+
+
+def test_nested_modules():
+    import pybind11_tests
+
+    assert pybind11_tests.__name__ == "pybind11_tests"
+    assert pybind11_tests.modules.__name__ == "pybind11_tests.modules"
+    assert (
+        pybind11_tests.modules.subsubmodule.__name__
+        == "pybind11_tests.modules.subsubmodule"
+    )
+    assert m.__name__ == "pybind11_tests.modules"
+    assert ms.__name__ == "pybind11_tests.modules.subsubmodule"
+
+    assert ms.submodule_func() == "submodule_func()"
+
+
+def test_reference_internal():
+    b = ms.B()
+    assert str(b.get_a1()) == "A[1]"
+    assert str(b.a1) == "A[1]"
+    assert str(b.get_a2()) == "A[2]"
+    assert str(b.a2) == "A[2]"
+
+    b.a1 = ms.A(42)
+    b.a2 = ms.A(43)
+    assert str(b.get_a1()) == "A[42]"
+    assert str(b.a1) == "A[42]"
+    assert str(b.get_a2()) == "A[43]"
+    assert str(b.a2) == "A[43]"
+
+    astats, bstats = ConstructorStats.get(ms.A), ConstructorStats.get(ms.B)
+    assert astats.alive() == 2
+    assert bstats.alive() == 1
+    del b
+    assert astats.alive() == 0
+    assert bstats.alive() == 0
+    assert astats.values() == ["1", "2", "42", "43"]
+    assert bstats.values() == []
+    assert astats.default_constructions == 0
+    assert bstats.default_constructions == 1
+    assert astats.copy_constructions == 0
+    assert bstats.copy_constructions == 0
+    # assert astats.move_constructions >= 0  # Don't invoke any
+    # assert bstats.move_constructions >= 0  # Don't invoke any
+    assert astats.copy_assignments == 2
+    assert bstats.copy_assignments == 0
+    assert astats.move_assignments == 0
+    assert bstats.move_assignments == 0
+
+
+def test_importing():
+    from collections import OrderedDict
+
+    from pybind11_tests.modules import OD
+
+    assert OD is OrderedDict
+
+
+def test_pydoc():
+    """Pydoc needs to be able to provide help() for everything inside a pybind11 module"""
+    import pydoc
+
+    import pybind11_tests
+
+    assert pybind11_tests.__name__ == "pybind11_tests"
+    assert pybind11_tests.__doc__ == "pybind11 test module"
+    assert pydoc.text.docmodule(pybind11_tests)
+
+
+def test_duplicate_registration():
+    """Registering two things with the same name"""
+
+    assert m.duplicate_registration() == []
+
+
+def test_builtin_key_type():
+    """Test that all the keys in the builtin modules have type str.
+
+    Previous versions of pybind11 would add a unicode key in python 2.
+    """
+    assert all(type(k) == str for k in dir(builtins))
+
+
+@pytest.mark.xfail("env.PYPY", reason="PyModule_GetName()")
+def test_def_submodule_failures():
+    sm = m.def_submodule(m, b"ScratchSubModuleName")  # Using bytes to show it works.
+    assert sm.__name__ == m.__name__ + "." + "ScratchSubModuleName"
+    malformed_utf8 = b"\x80"
+    if env.PYPY:
+        # It is not worth the effort finding a trigger for a failure when running with PyPy.
+        pytest.skip("Sufficiently exercised on platforms other than PyPy.")
+    else:
+        # Meant to trigger PyModule_GetName() failure:
+        sm_name_orig = sm.__name__
+        sm.__name__ = malformed_utf8
+        try:
+            # We want to assert that a bad __name__ causes some kind of failure, although we do not want to exercise
+            # the internals of PyModule_GetName(). Currently all supported Python versions raise SystemError. If that
+            # changes in future Python versions, simply add the new expected exception types here.
+            with pytest.raises(SystemError):
+                m.def_submodule(sm, b"SubSubModuleName")
+        finally:
+            # Clean up to ensure nothing gets upset by a module with an invalid __name__.
+            sm.__name__ = sm_name_orig  # Purely precautionary.
+    # Meant to trigger PyImport_AddModule() failure:
+    with pytest.raises(UnicodeDecodeError):
+        m.def_submodule(sm, malformed_utf8)
```

## extern/pybind11/tests/test_multiple_inheritance.py

 * *Ordering differences only*

```diff
@@ -1,493 +1,493 @@
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import ConstructorStats
-from pybind11_tests import multiple_inheritance as m
-
-
-def test_multiple_inheritance_cpp():
-    mt = m.MIType(3, 4)
-
-    assert mt.foo() == 3
-    assert mt.bar() == 4
-
-
-@pytest.mark.xfail("env.PYPY")
-def test_multiple_inheritance_mix1():
-    class Base1:
-        def __init__(self, i):
-            self.i = i
-
-        def foo(self):
-            return self.i
-
-    class MITypePy(Base1, m.Base2):
-        def __init__(self, i, j):
-            Base1.__init__(self, i)
-            m.Base2.__init__(self, j)
-
-    mt = MITypePy(3, 4)
-
-    assert mt.foo() == 3
-    assert mt.bar() == 4
-
-
-def test_multiple_inheritance_mix2():
-    class Base2:
-        def __init__(self, i):
-            self.i = i
-
-        def bar(self):
-            return self.i
-
-    class MITypePy(m.Base1, Base2):
-        def __init__(self, i, j):
-            m.Base1.__init__(self, i)
-            Base2.__init__(self, j)
-
-    mt = MITypePy(3, 4)
-
-    assert mt.foo() == 3
-    assert mt.bar() == 4
-
-
-@pytest.mark.xfail("env.PYPY")
-def test_multiple_inheritance_python():
-    class MI1(m.Base1, m.Base2):
-        def __init__(self, i, j):
-            m.Base1.__init__(self, i)
-            m.Base2.__init__(self, j)
-
-    class B1:
-        def v(self):
-            return 1
-
-    class MI2(B1, m.Base1, m.Base2):
-        def __init__(self, i, j):
-            B1.__init__(self)
-            m.Base1.__init__(self, i)
-            m.Base2.__init__(self, j)
-
-    class MI3(MI2):
-        def __init__(self, i, j):
-            MI2.__init__(self, i, j)
-
-    class MI4(MI3, m.Base2):
-        def __init__(self, i, j):
-            MI3.__init__(self, i, j)
-            # This should be ignored (Base2 is already initialized via MI2):
-            m.Base2.__init__(self, i + 100)
-
-    class MI5(m.Base2, B1, m.Base1):
-        def __init__(self, i, j):
-            B1.__init__(self)
-            m.Base1.__init__(self, i)
-            m.Base2.__init__(self, j)
-
-    class MI6(m.Base2, B1):
-        def __init__(self, i):
-            m.Base2.__init__(self, i)
-            B1.__init__(self)
-
-    class B2(B1):
-        def v(self):
-            return 2
-
-    class B3:
-        def v(self):
-            return 3
-
-    class B4(B3, B2):
-        def v(self):
-            return 4
-
-    class MI7(B4, MI6):
-        def __init__(self, i):
-            B4.__init__(self)
-            MI6.__init__(self, i)
-
-    class MI8(MI6, B3):
-        def __init__(self, i):
-            MI6.__init__(self, i)
-            B3.__init__(self)
-
-    class MI8b(B3, MI6):
-        def __init__(self, i):
-            B3.__init__(self)
-            MI6.__init__(self, i)
-
-    mi1 = MI1(1, 2)
-    assert mi1.foo() == 1
-    assert mi1.bar() == 2
-
-    mi2 = MI2(3, 4)
-    assert mi2.v() == 1
-    assert mi2.foo() == 3
-    assert mi2.bar() == 4
-
-    mi3 = MI3(5, 6)
-    assert mi3.v() == 1
-    assert mi3.foo() == 5
-    assert mi3.bar() == 6
-
-    mi4 = MI4(7, 8)
-    assert mi4.v() == 1
-    assert mi4.foo() == 7
-    assert mi4.bar() == 8
-
-    mi5 = MI5(10, 11)
-    assert mi5.v() == 1
-    assert mi5.foo() == 10
-    assert mi5.bar() == 11
-
-    mi6 = MI6(12)
-    assert mi6.v() == 1
-    assert mi6.bar() == 12
-
-    mi7 = MI7(13)
-    assert mi7.v() == 4
-    assert mi7.bar() == 13
-
-    mi8 = MI8(14)
-    assert mi8.v() == 1
-    assert mi8.bar() == 14
-
-    mi8b = MI8b(15)
-    assert mi8b.v() == 3
-    assert mi8b.bar() == 15
-
-
-def test_multiple_inheritance_python_many_bases():
-    class MIMany14(m.BaseN1, m.BaseN2, m.BaseN3, m.BaseN4):
-        def __init__(self):
-            m.BaseN1.__init__(self, 1)
-            m.BaseN2.__init__(self, 2)
-            m.BaseN3.__init__(self, 3)
-            m.BaseN4.__init__(self, 4)
-
-    class MIMany58(m.BaseN5, m.BaseN6, m.BaseN7, m.BaseN8):
-        def __init__(self):
-            m.BaseN5.__init__(self, 5)
-            m.BaseN6.__init__(self, 6)
-            m.BaseN7.__init__(self, 7)
-            m.BaseN8.__init__(self, 8)
-
-    class MIMany916(
-        m.BaseN9,
-        m.BaseN10,
-        m.BaseN11,
-        m.BaseN12,
-        m.BaseN13,
-        m.BaseN14,
-        m.BaseN15,
-        m.BaseN16,
-    ):
-        def __init__(self):
-            m.BaseN9.__init__(self, 9)
-            m.BaseN10.__init__(self, 10)
-            m.BaseN11.__init__(self, 11)
-            m.BaseN12.__init__(self, 12)
-            m.BaseN13.__init__(self, 13)
-            m.BaseN14.__init__(self, 14)
-            m.BaseN15.__init__(self, 15)
-            m.BaseN16.__init__(self, 16)
-
-    class MIMany19(MIMany14, MIMany58, m.BaseN9):
-        def __init__(self):
-            MIMany14.__init__(self)
-            MIMany58.__init__(self)
-            m.BaseN9.__init__(self, 9)
-
-    class MIMany117(MIMany14, MIMany58, MIMany916, m.BaseN17):
-        def __init__(self):
-            MIMany14.__init__(self)
-            MIMany58.__init__(self)
-            MIMany916.__init__(self)
-            m.BaseN17.__init__(self, 17)
-
-    # Inherits from 4 registered C++ classes: can fit in one pointer on any modern arch:
-    a = MIMany14()
-    for i in range(1, 4):
-        assert getattr(a, "f" + str(i))() == 2 * i
-
-    # Inherits from 8: requires 1/2 pointers worth of holder flags on 32/64-bit arch:
-    b = MIMany916()
-    for i in range(9, 16):
-        assert getattr(b, "f" + str(i))() == 2 * i
-
-    # Inherits from 9: requires >= 2 pointers worth of holder flags
-    c = MIMany19()
-    for i in range(1, 9):
-        assert getattr(c, "f" + str(i))() == 2 * i
-
-    # Inherits from 17: requires >= 3 pointers worth of holder flags
-    d = MIMany117()
-    for i in range(1, 17):
-        assert getattr(d, "f" + str(i))() == 2 * i
-
-
-def test_multiple_inheritance_virtbase():
-    class MITypePy(m.Base12a):
-        def __init__(self, i, j):
-            m.Base12a.__init__(self, i, j)
-
-    mt = MITypePy(3, 4)
-    assert mt.bar() == 4
-    assert m.bar_base2a(mt) == 4
-    assert m.bar_base2a_sharedptr(mt) == 4
-
-
-def test_mi_static_properties():
-    """Mixing bases with and without static properties should be possible
-    and the result should be independent of base definition order"""
-
-    for d in (m.VanillaStaticMix1(), m.VanillaStaticMix2()):
-        assert d.vanilla() == "Vanilla"
-        assert d.static_func1() == "WithStatic1"
-        assert d.static_func2() == "WithStatic2"
-        assert d.static_func() == d.__class__.__name__
-
-        m.WithStatic1.static_value1 = 1
-        m.WithStatic2.static_value2 = 2
-        assert d.static_value1 == 1
-        assert d.static_value2 == 2
-        assert d.static_value == 12
-
-        d.static_value1 = 0
-        assert d.static_value1 == 0
-        d.static_value2 = 0
-        assert d.static_value2 == 0
-        d.static_value = 0
-        assert d.static_value == 0
-
-
-# Requires PyPy 6+
-def test_mi_dynamic_attributes():
-    """Mixing bases with and without dynamic attribute support"""
-
-    for d in (m.VanillaDictMix1(), m.VanillaDictMix2()):
-        d.dynamic = 1
-        assert d.dynamic == 1
-
-
-def test_mi_unaligned_base():
-    """Returning an offset (non-first MI) base class pointer should recognize the instance"""
-
-    n_inst = ConstructorStats.detail_reg_inst()
-
-    c = m.I801C()
-    d = m.I801D()
-    # + 4 below because we have the two instances, and each instance has offset base I801B2
-    assert ConstructorStats.detail_reg_inst() == n_inst + 4
-    b1c = m.i801b1_c(c)
-    assert b1c is c
-    b2c = m.i801b2_c(c)
-    assert b2c is c
-    b1d = m.i801b1_d(d)
-    assert b1d is d
-    b2d = m.i801b2_d(d)
-    assert b2d is d
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 4  # no extra instances
-    del c, b1c, b2c
-    assert ConstructorStats.detail_reg_inst() == n_inst + 2
-    del d, b1d, b2d
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-
-def test_mi_base_return():
-    """Tests returning an offset (non-first MI) base class pointer to a derived instance"""
-
-    n_inst = ConstructorStats.detail_reg_inst()
-
-    c1 = m.i801c_b1()
-    assert type(c1) is m.I801C
-    assert c1.a == 1
-    assert c1.b == 2
-
-    d1 = m.i801d_b1()
-    assert type(d1) is m.I801D
-    assert d1.a == 1
-    assert d1.b == 2
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 4
-
-    c2 = m.i801c_b2()
-    assert type(c2) is m.I801C
-    assert c2.a == 1
-    assert c2.b == 2
-
-    d2 = m.i801d_b2()
-    assert type(d2) is m.I801D
-    assert d2.a == 1
-    assert d2.b == 2
-
-    assert ConstructorStats.detail_reg_inst() == n_inst + 8
-
-    del c2
-    assert ConstructorStats.detail_reg_inst() == n_inst + 6
-    del c1, d1, d2
-    assert ConstructorStats.detail_reg_inst() == n_inst
-
-    # Returning an unregistered derived type with a registered base; we won't
-    # pick up the derived type, obviously, but should still work (as an object
-    # of whatever type was returned).
-    e1 = m.i801e_c()
-    assert type(e1) is m.I801C
-    assert e1.a == 1
-    assert e1.b == 2
-
-    e2 = m.i801e_b2()
-    assert type(e2) is m.I801B2
-    assert e2.b == 2
-
-
-def test_diamond_inheritance():
-    """Tests that diamond inheritance works as expected (issue #959)"""
-
-    # Issue #959: this shouldn't segfault:
-    d = m.D()
-
-    # Make sure all the various distinct pointers are all recognized as registered instances:
-    assert d is d.c0()
-    assert d is d.c1()
-    assert d is d.b()
-    assert d is d.c0().b()
-    assert d is d.c1().b()
-    assert d is d.c0().c1().b().c0().b()
-
-
-def test_pr3635_diamond_b():
-    o = m.MVB()
-    assert o.b == 1
-
-    assert o.get_b_b() == 1
-
-
-def test_pr3635_diamond_c():
-    o = m.MVC()
-    assert o.b == 1
-    assert o.c == 2
-
-    assert o.get_b_b() == 1
-    assert o.get_c_b() == 1
-
-    assert o.get_c_c() == 2
-
-
-def test_pr3635_diamond_d0():
-    o = m.MVD0()
-    assert o.b == 1
-    assert o.c == 2
-    assert o.d0 == 3
-
-    assert o.get_b_b() == 1
-    assert o.get_c_b() == 1
-    assert o.get_d0_b() == 1
-
-    assert o.get_c_c() == 2
-    assert o.get_d0_c() == 2
-
-    assert o.get_d0_d0() == 3
-
-
-def test_pr3635_diamond_d1():
-    o = m.MVD1()
-    assert o.b == 1
-    assert o.c == 2
-    assert o.d1 == 4
-
-    assert o.get_b_b() == 1
-    assert o.get_c_b() == 1
-    assert o.get_d1_b() == 1
-
-    assert o.get_c_c() == 2
-    assert o.get_d1_c() == 2
-
-    assert o.get_d1_d1() == 4
-
-
-def test_pr3635_diamond_e():
-    o = m.MVE()
-    assert o.b == 1
-    assert o.c == 2
-    assert o.d0 == 3
-    assert o.d1 == 4
-    assert o.e == 5
-
-    assert o.get_b_b() == 1
-    assert o.get_c_b() == 1
-    assert o.get_d0_b() == 1
-    assert o.get_d1_b() == 1
-    assert o.get_e_b() == 1
-
-    assert o.get_c_c() == 2
-    assert o.get_d0_c() == 2
-    assert o.get_d1_c() == 2
-    assert o.get_e_c() == 2
-
-    assert o.get_d0_d0() == 3
-    assert o.get_e_d0() == 3
-
-    assert o.get_d1_d1() == 4
-    assert o.get_e_d1() == 4
-
-    assert o.get_e_e() == 5
-
-
-def test_pr3635_diamond_f():
-    o = m.MVF()
-    assert o.b == 1
-    assert o.c == 2
-    assert o.d0 == 3
-    assert o.d1 == 4
-    assert o.e == 5
-    assert o.f == 6
-
-    assert o.get_b_b() == 1
-    assert o.get_c_b() == 1
-    assert o.get_d0_b() == 1
-    assert o.get_d1_b() == 1
-    assert o.get_e_b() == 1
-    assert o.get_f_b() == 1
-
-    assert o.get_c_c() == 2
-    assert o.get_d0_c() == 2
-    assert o.get_d1_c() == 2
-    assert o.get_e_c() == 2
-    assert o.get_f_c() == 2
-
-    assert o.get_d0_d0() == 3
-    assert o.get_e_d0() == 3
-    assert o.get_f_d0() == 3
-
-    assert o.get_d1_d1() == 4
-    assert o.get_e_d1() == 4
-    assert o.get_f_d1() == 4
-
-    assert o.get_e_e() == 5
-    assert o.get_f_e() == 5
-
-    assert o.get_f_f() == 6
-
-
-def test_python_inherit_from_mi():
-    """Tests extending a Python class from a single inheritor of a MI class"""
-
-    class PyMVF(m.MVF):
-        g = 7
-
-        def get_g_g(self):
-            return self.g
-
-    o = PyMVF()
-
-    assert o.b == 1
-    assert o.c == 2
-    assert o.d0 == 3
-    assert o.d1 == 4
-    assert o.e == 5
-    assert o.f == 6
-    assert o.g == 7
-
-    assert o.get_g_g() == 7
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import ConstructorStats
+from pybind11_tests import multiple_inheritance as m
+
+
+def test_multiple_inheritance_cpp():
+    mt = m.MIType(3, 4)
+
+    assert mt.foo() == 3
+    assert mt.bar() == 4
+
+
+@pytest.mark.xfail("env.PYPY")
+def test_multiple_inheritance_mix1():
+    class Base1:
+        def __init__(self, i):
+            self.i = i
+
+        def foo(self):
+            return self.i
+
+    class MITypePy(Base1, m.Base2):
+        def __init__(self, i, j):
+            Base1.__init__(self, i)
+            m.Base2.__init__(self, j)
+
+    mt = MITypePy(3, 4)
+
+    assert mt.foo() == 3
+    assert mt.bar() == 4
+
+
+def test_multiple_inheritance_mix2():
+    class Base2:
+        def __init__(self, i):
+            self.i = i
+
+        def bar(self):
+            return self.i
+
+    class MITypePy(m.Base1, Base2):
+        def __init__(self, i, j):
+            m.Base1.__init__(self, i)
+            Base2.__init__(self, j)
+
+    mt = MITypePy(3, 4)
+
+    assert mt.foo() == 3
+    assert mt.bar() == 4
+
+
+@pytest.mark.xfail("env.PYPY")
+def test_multiple_inheritance_python():
+    class MI1(m.Base1, m.Base2):
+        def __init__(self, i, j):
+            m.Base1.__init__(self, i)
+            m.Base2.__init__(self, j)
+
+    class B1:
+        def v(self):
+            return 1
+
+    class MI2(B1, m.Base1, m.Base2):
+        def __init__(self, i, j):
+            B1.__init__(self)
+            m.Base1.__init__(self, i)
+            m.Base2.__init__(self, j)
+
+    class MI3(MI2):
+        def __init__(self, i, j):
+            MI2.__init__(self, i, j)
+
+    class MI4(MI3, m.Base2):
+        def __init__(self, i, j):
+            MI3.__init__(self, i, j)
+            # This should be ignored (Base2 is already initialized via MI2):
+            m.Base2.__init__(self, i + 100)
+
+    class MI5(m.Base2, B1, m.Base1):
+        def __init__(self, i, j):
+            B1.__init__(self)
+            m.Base1.__init__(self, i)
+            m.Base2.__init__(self, j)
+
+    class MI6(m.Base2, B1):
+        def __init__(self, i):
+            m.Base2.__init__(self, i)
+            B1.__init__(self)
+
+    class B2(B1):
+        def v(self):
+            return 2
+
+    class B3:
+        def v(self):
+            return 3
+
+    class B4(B3, B2):
+        def v(self):
+            return 4
+
+    class MI7(B4, MI6):
+        def __init__(self, i):
+            B4.__init__(self)
+            MI6.__init__(self, i)
+
+    class MI8(MI6, B3):
+        def __init__(self, i):
+            MI6.__init__(self, i)
+            B3.__init__(self)
+
+    class MI8b(B3, MI6):
+        def __init__(self, i):
+            B3.__init__(self)
+            MI6.__init__(self, i)
+
+    mi1 = MI1(1, 2)
+    assert mi1.foo() == 1
+    assert mi1.bar() == 2
+
+    mi2 = MI2(3, 4)
+    assert mi2.v() == 1
+    assert mi2.foo() == 3
+    assert mi2.bar() == 4
+
+    mi3 = MI3(5, 6)
+    assert mi3.v() == 1
+    assert mi3.foo() == 5
+    assert mi3.bar() == 6
+
+    mi4 = MI4(7, 8)
+    assert mi4.v() == 1
+    assert mi4.foo() == 7
+    assert mi4.bar() == 8
+
+    mi5 = MI5(10, 11)
+    assert mi5.v() == 1
+    assert mi5.foo() == 10
+    assert mi5.bar() == 11
+
+    mi6 = MI6(12)
+    assert mi6.v() == 1
+    assert mi6.bar() == 12
+
+    mi7 = MI7(13)
+    assert mi7.v() == 4
+    assert mi7.bar() == 13
+
+    mi8 = MI8(14)
+    assert mi8.v() == 1
+    assert mi8.bar() == 14
+
+    mi8b = MI8b(15)
+    assert mi8b.v() == 3
+    assert mi8b.bar() == 15
+
+
+def test_multiple_inheritance_python_many_bases():
+    class MIMany14(m.BaseN1, m.BaseN2, m.BaseN3, m.BaseN4):
+        def __init__(self):
+            m.BaseN1.__init__(self, 1)
+            m.BaseN2.__init__(self, 2)
+            m.BaseN3.__init__(self, 3)
+            m.BaseN4.__init__(self, 4)
+
+    class MIMany58(m.BaseN5, m.BaseN6, m.BaseN7, m.BaseN8):
+        def __init__(self):
+            m.BaseN5.__init__(self, 5)
+            m.BaseN6.__init__(self, 6)
+            m.BaseN7.__init__(self, 7)
+            m.BaseN8.__init__(self, 8)
+
+    class MIMany916(
+        m.BaseN9,
+        m.BaseN10,
+        m.BaseN11,
+        m.BaseN12,
+        m.BaseN13,
+        m.BaseN14,
+        m.BaseN15,
+        m.BaseN16,
+    ):
+        def __init__(self):
+            m.BaseN9.__init__(self, 9)
+            m.BaseN10.__init__(self, 10)
+            m.BaseN11.__init__(self, 11)
+            m.BaseN12.__init__(self, 12)
+            m.BaseN13.__init__(self, 13)
+            m.BaseN14.__init__(self, 14)
+            m.BaseN15.__init__(self, 15)
+            m.BaseN16.__init__(self, 16)
+
+    class MIMany19(MIMany14, MIMany58, m.BaseN9):
+        def __init__(self):
+            MIMany14.__init__(self)
+            MIMany58.__init__(self)
+            m.BaseN9.__init__(self, 9)
+
+    class MIMany117(MIMany14, MIMany58, MIMany916, m.BaseN17):
+        def __init__(self):
+            MIMany14.__init__(self)
+            MIMany58.__init__(self)
+            MIMany916.__init__(self)
+            m.BaseN17.__init__(self, 17)
+
+    # Inherits from 4 registered C++ classes: can fit in one pointer on any modern arch:
+    a = MIMany14()
+    for i in range(1, 4):
+        assert getattr(a, "f" + str(i))() == 2 * i
+
+    # Inherits from 8: requires 1/2 pointers worth of holder flags on 32/64-bit arch:
+    b = MIMany916()
+    for i in range(9, 16):
+        assert getattr(b, "f" + str(i))() == 2 * i
+
+    # Inherits from 9: requires >= 2 pointers worth of holder flags
+    c = MIMany19()
+    for i in range(1, 9):
+        assert getattr(c, "f" + str(i))() == 2 * i
+
+    # Inherits from 17: requires >= 3 pointers worth of holder flags
+    d = MIMany117()
+    for i in range(1, 17):
+        assert getattr(d, "f" + str(i))() == 2 * i
+
+
+def test_multiple_inheritance_virtbase():
+    class MITypePy(m.Base12a):
+        def __init__(self, i, j):
+            m.Base12a.__init__(self, i, j)
+
+    mt = MITypePy(3, 4)
+    assert mt.bar() == 4
+    assert m.bar_base2a(mt) == 4
+    assert m.bar_base2a_sharedptr(mt) == 4
+
+
+def test_mi_static_properties():
+    """Mixing bases with and without static properties should be possible
+    and the result should be independent of base definition order"""
+
+    for d in (m.VanillaStaticMix1(), m.VanillaStaticMix2()):
+        assert d.vanilla() == "Vanilla"
+        assert d.static_func1() == "WithStatic1"
+        assert d.static_func2() == "WithStatic2"
+        assert d.static_func() == d.__class__.__name__
+
+        m.WithStatic1.static_value1 = 1
+        m.WithStatic2.static_value2 = 2
+        assert d.static_value1 == 1
+        assert d.static_value2 == 2
+        assert d.static_value == 12
+
+        d.static_value1 = 0
+        assert d.static_value1 == 0
+        d.static_value2 = 0
+        assert d.static_value2 == 0
+        d.static_value = 0
+        assert d.static_value == 0
+
+
+# Requires PyPy 6+
+def test_mi_dynamic_attributes():
+    """Mixing bases with and without dynamic attribute support"""
+
+    for d in (m.VanillaDictMix1(), m.VanillaDictMix2()):
+        d.dynamic = 1
+        assert d.dynamic == 1
+
+
+def test_mi_unaligned_base():
+    """Returning an offset (non-first MI) base class pointer should recognize the instance"""
+
+    n_inst = ConstructorStats.detail_reg_inst()
+
+    c = m.I801C()
+    d = m.I801D()
+    # + 4 below because we have the two instances, and each instance has offset base I801B2
+    assert ConstructorStats.detail_reg_inst() == n_inst + 4
+    b1c = m.i801b1_c(c)
+    assert b1c is c
+    b2c = m.i801b2_c(c)
+    assert b2c is c
+    b1d = m.i801b1_d(d)
+    assert b1d is d
+    b2d = m.i801b2_d(d)
+    assert b2d is d
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 4  # no extra instances
+    del c, b1c, b2c
+    assert ConstructorStats.detail_reg_inst() == n_inst + 2
+    del d, b1d, b2d
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+
+def test_mi_base_return():
+    """Tests returning an offset (non-first MI) base class pointer to a derived instance"""
+
+    n_inst = ConstructorStats.detail_reg_inst()
+
+    c1 = m.i801c_b1()
+    assert type(c1) is m.I801C
+    assert c1.a == 1
+    assert c1.b == 2
+
+    d1 = m.i801d_b1()
+    assert type(d1) is m.I801D
+    assert d1.a == 1
+    assert d1.b == 2
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 4
+
+    c2 = m.i801c_b2()
+    assert type(c2) is m.I801C
+    assert c2.a == 1
+    assert c2.b == 2
+
+    d2 = m.i801d_b2()
+    assert type(d2) is m.I801D
+    assert d2.a == 1
+    assert d2.b == 2
+
+    assert ConstructorStats.detail_reg_inst() == n_inst + 8
+
+    del c2
+    assert ConstructorStats.detail_reg_inst() == n_inst + 6
+    del c1, d1, d2
+    assert ConstructorStats.detail_reg_inst() == n_inst
+
+    # Returning an unregistered derived type with a registered base; we won't
+    # pick up the derived type, obviously, but should still work (as an object
+    # of whatever type was returned).
+    e1 = m.i801e_c()
+    assert type(e1) is m.I801C
+    assert e1.a == 1
+    assert e1.b == 2
+
+    e2 = m.i801e_b2()
+    assert type(e2) is m.I801B2
+    assert e2.b == 2
+
+
+def test_diamond_inheritance():
+    """Tests that diamond inheritance works as expected (issue #959)"""
+
+    # Issue #959: this shouldn't segfault:
+    d = m.D()
+
+    # Make sure all the various distinct pointers are all recognized as registered instances:
+    assert d is d.c0()
+    assert d is d.c1()
+    assert d is d.b()
+    assert d is d.c0().b()
+    assert d is d.c1().b()
+    assert d is d.c0().c1().b().c0().b()
+
+
+def test_pr3635_diamond_b():
+    o = m.MVB()
+    assert o.b == 1
+
+    assert o.get_b_b() == 1
+
+
+def test_pr3635_diamond_c():
+    o = m.MVC()
+    assert o.b == 1
+    assert o.c == 2
+
+    assert o.get_b_b() == 1
+    assert o.get_c_b() == 1
+
+    assert o.get_c_c() == 2
+
+
+def test_pr3635_diamond_d0():
+    o = m.MVD0()
+    assert o.b == 1
+    assert o.c == 2
+    assert o.d0 == 3
+
+    assert o.get_b_b() == 1
+    assert o.get_c_b() == 1
+    assert o.get_d0_b() == 1
+
+    assert o.get_c_c() == 2
+    assert o.get_d0_c() == 2
+
+    assert o.get_d0_d0() == 3
+
+
+def test_pr3635_diamond_d1():
+    o = m.MVD1()
+    assert o.b == 1
+    assert o.c == 2
+    assert o.d1 == 4
+
+    assert o.get_b_b() == 1
+    assert o.get_c_b() == 1
+    assert o.get_d1_b() == 1
+
+    assert o.get_c_c() == 2
+    assert o.get_d1_c() == 2
+
+    assert o.get_d1_d1() == 4
+
+
+def test_pr3635_diamond_e():
+    o = m.MVE()
+    assert o.b == 1
+    assert o.c == 2
+    assert o.d0 == 3
+    assert o.d1 == 4
+    assert o.e == 5
+
+    assert o.get_b_b() == 1
+    assert o.get_c_b() == 1
+    assert o.get_d0_b() == 1
+    assert o.get_d1_b() == 1
+    assert o.get_e_b() == 1
+
+    assert o.get_c_c() == 2
+    assert o.get_d0_c() == 2
+    assert o.get_d1_c() == 2
+    assert o.get_e_c() == 2
+
+    assert o.get_d0_d0() == 3
+    assert o.get_e_d0() == 3
+
+    assert o.get_d1_d1() == 4
+    assert o.get_e_d1() == 4
+
+    assert o.get_e_e() == 5
+
+
+def test_pr3635_diamond_f():
+    o = m.MVF()
+    assert o.b == 1
+    assert o.c == 2
+    assert o.d0 == 3
+    assert o.d1 == 4
+    assert o.e == 5
+    assert o.f == 6
+
+    assert o.get_b_b() == 1
+    assert o.get_c_b() == 1
+    assert o.get_d0_b() == 1
+    assert o.get_d1_b() == 1
+    assert o.get_e_b() == 1
+    assert o.get_f_b() == 1
+
+    assert o.get_c_c() == 2
+    assert o.get_d0_c() == 2
+    assert o.get_d1_c() == 2
+    assert o.get_e_c() == 2
+    assert o.get_f_c() == 2
+
+    assert o.get_d0_d0() == 3
+    assert o.get_e_d0() == 3
+    assert o.get_f_d0() == 3
+
+    assert o.get_d1_d1() == 4
+    assert o.get_e_d1() == 4
+    assert o.get_f_d1() == 4
+
+    assert o.get_e_e() == 5
+    assert o.get_f_e() == 5
+
+    assert o.get_f_f() == 6
+
+
+def test_python_inherit_from_mi():
+    """Tests extending a Python class from a single inheritor of a MI class"""
+
+    class PyMVF(m.MVF):
+        g = 7
+
+        def get_g_g(self):
+            return self.g
+
+    o = PyMVF()
+
+    assert o.b == 1
+    assert o.c == 2
+    assert o.d0 == 3
+    assert o.d1 == 4
+    assert o.e == 5
+    assert o.f == 6
+    assert o.g == 7
+
+    assert o.get_g_g() == 7
```

## extern/pybind11/tests/test_numpy_array.py

 * *Ordering differences only*

```diff
@@ -1,668 +1,668 @@
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import numpy_array as m
-
-np = pytest.importorskip("numpy")
-
-
-def test_dtypes():
-    # See issue #1328.
-    # - Platform-dependent sizes.
-    for size_check in m.get_platform_dtype_size_checks():
-        print(size_check)
-        assert size_check.size_cpp == size_check.size_numpy, size_check
-    # - Concrete sizes.
-    for check in m.get_concrete_dtype_checks():
-        print(check)
-        assert check.numpy == check.pybind11, check
-        if check.numpy.num != check.pybind11.num:
-            print(
-                f"NOTE: typenum mismatch for {check}: {check.numpy.num} != {check.pybind11.num}"
-            )
-
-
-@pytest.fixture()
-def arr():
-    return np.array([[1, 2, 3], [4, 5, 6]], "=u2")
-
-
-def test_array_attributes():
-    a = np.array(0, "f8")
-    assert m.ndim(a) == 0
-    assert all(m.shape(a) == [])
-    assert all(m.strides(a) == [])
-    with pytest.raises(IndexError) as excinfo:
-        m.shape(a, 0)
-    assert str(excinfo.value) == "invalid axis: 0 (ndim = 0)"
-    with pytest.raises(IndexError) as excinfo:
-        m.strides(a, 0)
-    assert str(excinfo.value) == "invalid axis: 0 (ndim = 0)"
-    assert m.writeable(a)
-    assert m.size(a) == 1
-    assert m.itemsize(a) == 8
-    assert m.nbytes(a) == 8
-    assert m.owndata(a)
-
-    a = np.array([[1, 2, 3], [4, 5, 6]], "u2").view()
-    a.flags.writeable = False
-    assert m.ndim(a) == 2
-    assert all(m.shape(a) == [2, 3])
-    assert m.shape(a, 0) == 2
-    assert m.shape(a, 1) == 3
-    assert all(m.strides(a) == [6, 2])
-    assert m.strides(a, 0) == 6
-    assert m.strides(a, 1) == 2
-    with pytest.raises(IndexError) as excinfo:
-        m.shape(a, 2)
-    assert str(excinfo.value) == "invalid axis: 2 (ndim = 2)"
-    with pytest.raises(IndexError) as excinfo:
-        m.strides(a, 2)
-    assert str(excinfo.value) == "invalid axis: 2 (ndim = 2)"
-    assert not m.writeable(a)
-    assert m.size(a) == 6
-    assert m.itemsize(a) == 2
-    assert m.nbytes(a) == 12
-    assert not m.owndata(a)
-
-
-@pytest.mark.parametrize(
-    ("args", "ret"), [([], 0), ([0], 0), ([1], 3), ([0, 1], 1), ([1, 2], 5)]
-)
-def test_index_offset(arr, args, ret):
-    assert m.index_at(arr, *args) == ret
-    assert m.index_at_t(arr, *args) == ret
-    assert m.offset_at(arr, *args) == ret * arr.dtype.itemsize
-    assert m.offset_at_t(arr, *args) == ret * arr.dtype.itemsize
-
-
-def test_dim_check_fail(arr):
-    for func in (
-        m.index_at,
-        m.index_at_t,
-        m.offset_at,
-        m.offset_at_t,
-        m.data,
-        m.data_t,
-        m.mutate_data,
-        m.mutate_data_t,
-    ):
-        with pytest.raises(IndexError) as excinfo:
-            func(arr, 1, 2, 3)
-        assert str(excinfo.value) == "too many indices for an array: 3 (ndim = 2)"
-
-
-@pytest.mark.parametrize(
-    ("args", "ret"),
-    [
-        ([], [1, 2, 3, 4, 5, 6]),
-        ([1], [4, 5, 6]),
-        ([0, 1], [2, 3, 4, 5, 6]),
-        ([1, 2], [6]),
-    ],
-)
-def test_data(arr, args, ret):
-    from sys import byteorder
-
-    assert all(m.data_t(arr, *args) == ret)
-    assert all(m.data(arr, *args)[(0 if byteorder == "little" else 1) :: 2] == ret)
-    assert all(m.data(arr, *args)[(1 if byteorder == "little" else 0) :: 2] == 0)
-
-
-@pytest.mark.parametrize("dim", [0, 1, 3])
-def test_at_fail(arr, dim):
-    for func in m.at_t, m.mutate_at_t:
-        with pytest.raises(IndexError) as excinfo:
-            func(arr, *([0] * dim))
-        assert str(excinfo.value) == f"index dimension mismatch: {dim} (ndim = 2)"
-
-
-def test_at(arr):
-    assert m.at_t(arr, 0, 2) == 3
-    assert m.at_t(arr, 1, 0) == 4
-
-    assert all(m.mutate_at_t(arr, 0, 2).ravel() == [1, 2, 4, 4, 5, 6])
-    assert all(m.mutate_at_t(arr, 1, 0).ravel() == [1, 2, 4, 5, 5, 6])
-
-
-def test_mutate_readonly(arr):
-    arr.flags.writeable = False
-    for func, args in (
-        (m.mutate_data, ()),
-        (m.mutate_data_t, ()),
-        (m.mutate_at_t, (0, 0)),
-    ):
-        with pytest.raises(ValueError) as excinfo:
-            func(arr, *args)
-        assert str(excinfo.value) == "array is not writeable"
-
-
-def test_mutate_data(arr):
-    assert all(m.mutate_data(arr).ravel() == [2, 4, 6, 8, 10, 12])
-    assert all(m.mutate_data(arr).ravel() == [4, 8, 12, 16, 20, 24])
-    assert all(m.mutate_data(arr, 1).ravel() == [4, 8, 12, 32, 40, 48])
-    assert all(m.mutate_data(arr, 0, 1).ravel() == [4, 16, 24, 64, 80, 96])
-    assert all(m.mutate_data(arr, 1, 2).ravel() == [4, 16, 24, 64, 80, 192])
-
-    assert all(m.mutate_data_t(arr).ravel() == [5, 17, 25, 65, 81, 193])
-    assert all(m.mutate_data_t(arr).ravel() == [6, 18, 26, 66, 82, 194])
-    assert all(m.mutate_data_t(arr, 1).ravel() == [6, 18, 26, 67, 83, 195])
-    assert all(m.mutate_data_t(arr, 0, 1).ravel() == [6, 19, 27, 68, 84, 196])
-    assert all(m.mutate_data_t(arr, 1, 2).ravel() == [6, 19, 27, 68, 84, 197])
-
-
-def test_bounds_check(arr):
-    for func in (
-        m.index_at,
-        m.index_at_t,
-        m.data,
-        m.data_t,
-        m.mutate_data,
-        m.mutate_data_t,
-        m.at_t,
-        m.mutate_at_t,
-    ):
-        with pytest.raises(IndexError) as excinfo:
-            func(arr, 2, 0)
-        assert str(excinfo.value) == "index 2 is out of bounds for axis 0 with size 2"
-        with pytest.raises(IndexError) as excinfo:
-            func(arr, 0, 4)
-        assert str(excinfo.value) == "index 4 is out of bounds for axis 1 with size 3"
-
-
-def test_make_c_f_array():
-    assert m.make_c_array().flags.c_contiguous
-    assert not m.make_c_array().flags.f_contiguous
-    assert m.make_f_array().flags.f_contiguous
-    assert not m.make_f_array().flags.c_contiguous
-
-
-def test_make_empty_shaped_array():
-    m.make_empty_shaped_array()
-
-    # empty shape means numpy scalar, PEP 3118
-    assert m.scalar_int().ndim == 0
-    assert m.scalar_int().shape == ()
-    assert m.scalar_int() == 42
-
-
-def test_wrap():
-    def assert_references(a, b, base=None):
-        if base is None:
-            base = a
-        assert a is not b
-        assert a.__array_interface__["data"][0] == b.__array_interface__["data"][0]
-        assert a.shape == b.shape
-        assert a.strides == b.strides
-        assert a.flags.c_contiguous == b.flags.c_contiguous
-        assert a.flags.f_contiguous == b.flags.f_contiguous
-        assert a.flags.writeable == b.flags.writeable
-        assert a.flags.aligned == b.flags.aligned
-        # 1.13 supported Python 3.6
-        if tuple(int(x) for x in np.__version__.split(".")[:2]) >= (1, 14):
-            assert a.flags.writebackifcopy == b.flags.writebackifcopy
-        else:
-            assert a.flags.updateifcopy == b.flags.updateifcopy
-        assert np.all(a == b)
-        assert not b.flags.owndata
-        assert b.base is base
-        if a.flags.writeable and a.ndim == 2:
-            a[0, 0] = 1234
-            assert b[0, 0] == 1234
-
-    a1 = np.array([1, 2], dtype=np.int16)
-    assert a1.flags.owndata
-    assert a1.base is None
-    a2 = m.wrap(a1)
-    assert_references(a1, a2)
-
-    a1 = np.array([[1, 2], [3, 4]], dtype=np.float32, order="F")
-    assert a1.flags.owndata
-    assert a1.base is None
-    a2 = m.wrap(a1)
-    assert_references(a1, a2)
-
-    a1 = np.array([[1, 2], [3, 4]], dtype=np.float32, order="C")
-    a1.flags.writeable = False
-    a2 = m.wrap(a1)
-    assert_references(a1, a2)
-
-    a1 = np.random.random((4, 4, 4))
-    a2 = m.wrap(a1)
-    assert_references(a1, a2)
-
-    a1t = a1.transpose()
-    a2 = m.wrap(a1t)
-    assert_references(a1t, a2, a1)
-
-    a1d = a1.diagonal()
-    a2 = m.wrap(a1d)
-    assert_references(a1d, a2, a1)
-
-    a1m = a1[::-1, ::-1, ::-1]
-    a2 = m.wrap(a1m)
-    assert_references(a1m, a2, a1)
-
-
-def test_numpy_view(capture):
-    with capture:
-        ac = m.ArrayClass()
-        ac_view_1 = ac.numpy_view()
-        ac_view_2 = ac.numpy_view()
-        assert np.all(ac_view_1 == np.array([1, 2], dtype=np.int32))
-        del ac
-        pytest.gc_collect()
-    assert (
-        capture
-        == """
-        ArrayClass()
-        ArrayClass::numpy_view()
-        ArrayClass::numpy_view()
-    """
-    )
-    ac_view_1[0] = 4
-    ac_view_1[1] = 3
-    assert ac_view_2[0] == 4
-    assert ac_view_2[1] == 3
-    with capture:
-        del ac_view_1
-        del ac_view_2
-        pytest.gc_collect()
-        pytest.gc_collect()
-    assert (
-        capture
-        == """
-        ~ArrayClass()
-    """
-    )
-
-
-def test_cast_numpy_int64_to_uint64():
-    m.function_taking_uint64(123)
-    m.function_taking_uint64(np.uint64(123))
-
-
-def test_isinstance():
-    assert m.isinstance_untyped(np.array([1, 2, 3]), "not an array")
-    assert m.isinstance_typed(np.array([1.0, 2.0, 3.0]))
-
-
-def test_constructors():
-    defaults = m.default_constructors()
-    for a in defaults.values():
-        assert a.size == 0
-    assert defaults["array"].dtype == np.array([]).dtype
-    assert defaults["array_t<int32>"].dtype == np.int32
-    assert defaults["array_t<double>"].dtype == np.float64
-
-    results = m.converting_constructors([1, 2, 3])
-    for a in results.values():
-        np.testing.assert_array_equal(a, [1, 2, 3])
-    assert results["array"].dtype == np.dtype(int)
-    assert results["array_t<int32>"].dtype == np.int32
-    assert results["array_t<double>"].dtype == np.float64
-
-
-def test_overload_resolution(msg):
-    # Exact overload matches:
-    assert m.overloaded(np.array([1], dtype="float64")) == "double"
-    assert m.overloaded(np.array([1], dtype="float32")) == "float"
-    assert m.overloaded(np.array([1], dtype="ushort")) == "unsigned short"
-    assert m.overloaded(np.array([1], dtype="intc")) == "int"
-    assert m.overloaded(np.array([1], dtype="longlong")) == "long long"
-    assert m.overloaded(np.array([1], dtype="complex")) == "double complex"
-    assert m.overloaded(np.array([1], dtype="csingle")) == "float complex"
-
-    # No exact match, should call first convertible version:
-    assert m.overloaded(np.array([1], dtype="uint8")) == "double"
-
-    with pytest.raises(TypeError) as excinfo:
-        m.overloaded("not an array")
-    assert (
-        msg(excinfo.value)
-        == """
-        overloaded(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: numpy.ndarray[numpy.float64]) -> str
-            2. (arg0: numpy.ndarray[numpy.float32]) -> str
-            3. (arg0: numpy.ndarray[numpy.int32]) -> str
-            4. (arg0: numpy.ndarray[numpy.uint16]) -> str
-            5. (arg0: numpy.ndarray[numpy.int64]) -> str
-            6. (arg0: numpy.ndarray[numpy.complex128]) -> str
-            7. (arg0: numpy.ndarray[numpy.complex64]) -> str
-
-        Invoked with: 'not an array'
-    """
-    )
-
-    assert m.overloaded2(np.array([1], dtype="float64")) == "double"
-    assert m.overloaded2(np.array([1], dtype="float32")) == "float"
-    assert m.overloaded2(np.array([1], dtype="complex64")) == "float complex"
-    assert m.overloaded2(np.array([1], dtype="complex128")) == "double complex"
-    assert m.overloaded2(np.array([1], dtype="float32")) == "float"
-
-    assert m.overloaded3(np.array([1], dtype="float64")) == "double"
-    assert m.overloaded3(np.array([1], dtype="intc")) == "int"
-    expected_exc = """
-        overloaded3(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: numpy.ndarray[numpy.int32]) -> str
-            2. (arg0: numpy.ndarray[numpy.float64]) -> str
-
-        Invoked with: """
-
-    with pytest.raises(TypeError) as excinfo:
-        m.overloaded3(np.array([1], dtype="uintc"))
-    assert msg(excinfo.value) == expected_exc + repr(np.array([1], dtype="uint32"))
-    with pytest.raises(TypeError) as excinfo:
-        m.overloaded3(np.array([1], dtype="float32"))
-    assert msg(excinfo.value) == expected_exc + repr(np.array([1.0], dtype="float32"))
-    with pytest.raises(TypeError) as excinfo:
-        m.overloaded3(np.array([1], dtype="complex"))
-    assert msg(excinfo.value) == expected_exc + repr(np.array([1.0 + 0.0j]))
-
-    # Exact matches:
-    assert m.overloaded4(np.array([1], dtype="double")) == "double"
-    assert m.overloaded4(np.array([1], dtype="longlong")) == "long long"
-    # Non-exact matches requiring conversion.  Since float to integer isn't a
-    # save conversion, it should go to the double overload, but short can go to
-    # either (and so should end up on the first-registered, the long long).
-    assert m.overloaded4(np.array([1], dtype="float32")) == "double"
-    assert m.overloaded4(np.array([1], dtype="short")) == "long long"
-
-    assert m.overloaded5(np.array([1], dtype="double")) == "double"
-    assert m.overloaded5(np.array([1], dtype="uintc")) == "unsigned int"
-    assert m.overloaded5(np.array([1], dtype="float32")) == "unsigned int"
-
-
-def test_greedy_string_overload():
-    """Tests fix for #685 - ndarray shouldn't go to std::string overload"""
-
-    assert m.issue685("abc") == "string"
-    assert m.issue685(np.array([97, 98, 99], dtype="b")) == "array"
-    assert m.issue685(123) == "other"
-
-
-def test_array_unchecked_fixed_dims(msg):
-    z1 = np.array([[1, 2], [3, 4]], dtype="float64")
-    m.proxy_add2(z1, 10)
-    assert np.all(z1 == [[11, 12], [13, 14]])
-
-    with pytest.raises(ValueError) as excinfo:
-        m.proxy_add2(np.array([1.0, 2, 3]), 5.0)
-    assert (
-        msg(excinfo.value) == "array has incorrect number of dimensions: 1; expected 2"
-    )
-
-    expect_c = np.ndarray(shape=(3, 3, 3), buffer=np.array(range(3, 30)), dtype="int")
-    assert np.all(m.proxy_init3(3.0) == expect_c)
-    expect_f = np.transpose(expect_c)
-    assert np.all(m.proxy_init3F(3.0) == expect_f)
-
-    assert m.proxy_squared_L2_norm(np.array(range(6))) == 55
-    assert m.proxy_squared_L2_norm(np.array(range(6), dtype="float64")) == 55
-
-    assert m.proxy_auxiliaries2(z1) == [11, 11, True, 2, 8, 2, 2, 4, 32]
-    assert m.proxy_auxiliaries2(z1) == m.array_auxiliaries2(z1)
-
-    assert m.proxy_auxiliaries1_const_ref(z1[0, :])
-    assert m.proxy_auxiliaries2_const_ref(z1)
-
-
-def test_array_unchecked_dyn_dims():
-    z1 = np.array([[1, 2], [3, 4]], dtype="float64")
-    m.proxy_add2_dyn(z1, 10)
-    assert np.all(z1 == [[11, 12], [13, 14]])
-
-    expect_c = np.ndarray(shape=(3, 3, 3), buffer=np.array(range(3, 30)), dtype="int")
-    assert np.all(m.proxy_init3_dyn(3.0) == expect_c)
-
-    assert m.proxy_auxiliaries2_dyn(z1) == [11, 11, True, 2, 8, 2, 2, 4, 32]
-    assert m.proxy_auxiliaries2_dyn(z1) == m.array_auxiliaries2(z1)
-
-
-def test_array_failure():
-    with pytest.raises(ValueError) as excinfo:
-        m.array_fail_test()
-    assert str(excinfo.value) == "cannot create a pybind11::array from a nullptr"
-
-    with pytest.raises(ValueError) as excinfo:
-        m.array_t_fail_test()
-    assert str(excinfo.value) == "cannot create a pybind11::array_t from a nullptr"
-
-    with pytest.raises(ValueError) as excinfo:
-        m.array_fail_test_negative_size()
-    assert str(excinfo.value) == "negative dimensions are not allowed"
-
-
-def test_initializer_list():
-    assert m.array_initializer_list1().shape == (1,)
-    assert m.array_initializer_list2().shape == (1, 2)
-    assert m.array_initializer_list3().shape == (1, 2, 3)
-    assert m.array_initializer_list4().shape == (1, 2, 3, 4)
-
-
-def test_array_resize():
-    a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype="float64")
-    m.array_reshape2(a)
-    assert a.size == 9
-    assert np.all(a == [[1, 2, 3], [4, 5, 6], [7, 8, 9]])
-
-    # total size change should succced with refcheck off
-    m.array_resize3(a, 4, False)
-    assert a.size == 64
-    # ... and fail with refcheck on
-    try:
-        m.array_resize3(a, 3, True)
-    except ValueError as e:
-        assert str(e).startswith("cannot resize an array")  # noqa: PT017
-    # transposed array doesn't own data
-    b = a.transpose()
-    try:
-        m.array_resize3(b, 3, False)
-    except ValueError as e:
-        assert str(e).startswith(  # noqa: PT017
-            "cannot resize this array: it does not own its data"
-        )
-    # ... but reshape should be fine
-    m.array_reshape2(b)
-    assert b.shape == (8, 8)
-
-
-@pytest.mark.xfail("env.PYPY")
-def test_array_create_and_resize():
-    a = m.create_and_resize(2)
-    assert a.size == 4
-    assert np.all(a == 42.0)
-
-
-def test_array_view():
-    a = np.ones(100 * 4).astype("uint8")
-    a_float_view = m.array_view(a, "float32")
-    assert a_float_view.shape == (100 * 1,)  # 1 / 4 bytes = 8 / 32
-
-    a_int16_view = m.array_view(a, "int16")  # 1 / 2 bytes = 16 / 32
-    assert a_int16_view.shape == (100 * 2,)
-
-
-def test_array_view_invalid():
-    a = np.ones(100 * 4).astype("uint8")
-    with pytest.raises(TypeError):
-        m.array_view(a, "deadly_dtype")
-
-
-def test_reshape_initializer_list():
-    a = np.arange(2 * 7 * 3) + 1
-    x = m.reshape_initializer_list(a, 2, 7, 3)
-    assert x.shape == (2, 7, 3)
-    assert list(x[1][4]) == [34, 35, 36]
-    with pytest.raises(ValueError) as excinfo:
-        m.reshape_initializer_list(a, 1, 7, 3)
-    assert str(excinfo.value) == "cannot reshape array of size 42 into shape (1,7,3)"
-
-
-def test_reshape_tuple():
-    a = np.arange(3 * 7 * 2) + 1
-    x = m.reshape_tuple(a, (3, 7, 2))
-    assert x.shape == (3, 7, 2)
-    assert list(x[1][4]) == [23, 24]
-    y = m.reshape_tuple(x, (x.size,))
-    assert y.shape == (42,)
-    with pytest.raises(ValueError) as excinfo:
-        m.reshape_tuple(a, (3, 7, 1))
-    assert str(excinfo.value) == "cannot reshape array of size 42 into shape (3,7,1)"
-    with pytest.raises(ValueError) as excinfo:
-        m.reshape_tuple(a, ())
-    assert str(excinfo.value) == "cannot reshape array of size 42 into shape ()"
-
-
-def test_index_using_ellipsis():
-    a = m.index_using_ellipsis(np.zeros((5, 6, 7)))
-    assert a.shape == (6,)
-
-
-@pytest.mark.parametrize(
-    "test_func",
-    [
-        m.test_fmt_desc_float,
-        m.test_fmt_desc_double,
-        m.test_fmt_desc_const_float,
-        m.test_fmt_desc_const_double,
-    ],
-)
-def test_format_descriptors_for_floating_point_types(test_func):
-    assert "numpy.ndarray[numpy.float" in test_func.__doc__
-
-
-@pytest.mark.parametrize("forcecast", [False, True])
-@pytest.mark.parametrize("contiguity", [None, "C", "F"])
-@pytest.mark.parametrize("noconvert", [False, True])
-@pytest.mark.filterwarnings(
-    "ignore:Casting complex values to real discards the imaginary part:numpy.ComplexWarning"
-)
-def test_argument_conversions(forcecast, contiguity, noconvert):
-    function_name = "accept_double"
-    if contiguity == "C":
-        function_name += "_c_style"
-    elif contiguity == "F":
-        function_name += "_f_style"
-    if forcecast:
-        function_name += "_forcecast"
-    if noconvert:
-        function_name += "_noconvert"
-    function = getattr(m, function_name)
-
-    for dtype in [np.dtype("float32"), np.dtype("float64"), np.dtype("complex128")]:
-        for order in ["C", "F"]:
-            for shape in [(2, 2), (1, 3, 1, 1), (1, 1, 1), (0,)]:
-                if not noconvert:
-                    # If noconvert is not passed, only complex128 needs to be truncated and
-                    # "cannot be safely obtained". So without `forcecast`, the argument shouldn't
-                    # be accepted.
-                    should_raise = dtype.name == "complex128" and not forcecast
-                else:
-                    # If noconvert is passed, only float64 and the matching order is accepted.
-                    # If at most one dimension has a size greater than 1, the array is also
-                    # trivially contiguous.
-                    trivially_contiguous = sum(1 for d in shape if d > 1) <= 1
-                    should_raise = dtype.name != "float64" or (
-                        contiguity is not None
-                        and contiguity != order
-                        and not trivially_contiguous
-                    )
-
-                array = np.zeros(shape, dtype=dtype, order=order)
-                if not should_raise:
-                    function(array)
-                else:
-                    with pytest.raises(
-                        TypeError, match="incompatible function arguments"
-                    ):
-                        function(array)
-
-
-@pytest.mark.xfail("env.PYPY")
-def test_dtype_refcount_leak():
-    from sys import getrefcount
-
-    dtype = np.dtype(np.float_)
-    a = np.array([1], dtype=dtype)
-    before = getrefcount(dtype)
-    m.ndim(a)
-    after = getrefcount(dtype)
-    assert after == before
-
-
-def test_round_trip_float():
-    arr = np.zeros((), np.float64)
-    arr[()] = 37.2
-    assert m.round_trip_float(arr) == 37.2
-
-
-# HINT: An easy and robust way (although only manual unfortunately) to check for
-#       ref-count leaks in the test_.*pyobject_ptr.* functions below is to
-#           * temporarily insert `while True:` (one-by-one),
-#           * run this test, and
-#           * run the Linux `top` command in another shell to visually monitor
-#             `RES` for a minute or two.
-#       If there is a leak, it is usually evident in seconds because the `RES`
-#       value increases without bounds. (Don't forget to Ctrl-C the test!)
-
-
-# For use as a temporary user-defined object, to maximize sensitivity of the tests below:
-#     * Ref-count leaks will be immediately evident.
-#     * Sanitizers are much more likely to detect heap-use-after-free due to
-#       other ref-count bugs.
-class PyValueHolder:
-    def __init__(self, value):
-        self.value = value
-
-
-def WrapWithPyValueHolder(*values):
-    return [PyValueHolder(v) for v in values]
-
-
-def UnwrapPyValueHolder(vhs):
-    return [vh.value for vh in vhs]
-
-
-def test_pass_array_pyobject_ptr_return_sum_str_values_ndarray():
-    # Intentionally all temporaries, do not change.
-    assert (
-        m.pass_array_pyobject_ptr_return_sum_str_values(
-            np.array(WrapWithPyValueHolder(-3, "four", 5.0), dtype=object)
-        )
-        == "-3four5.0"
-    )
-
-
-def test_pass_array_pyobject_ptr_return_sum_str_values_list():
-    # Intentionally all temporaries, do not change.
-    assert (
-        m.pass_array_pyobject_ptr_return_sum_str_values(
-            WrapWithPyValueHolder(2, "three", -4.0)
-        )
-        == "2three-4.0"
-    )
-
-
-def test_pass_array_pyobject_ptr_return_as_list():
-    # Intentionally all temporaries, do not change.
-    assert UnwrapPyValueHolder(
-        m.pass_array_pyobject_ptr_return_as_list(
-            np.array(WrapWithPyValueHolder(-1, "two", 3.0), dtype=object)
-        )
-    ) == [-1, "two", 3.0]
-
-
-@pytest.mark.parametrize(
-    ("return_array_pyobject_ptr", "unwrap"),
-    [
-        (m.return_array_pyobject_ptr_cpp_loop, list),
-        (m.return_array_pyobject_ptr_from_list, UnwrapPyValueHolder),
-    ],
-)
-def test_return_array_pyobject_ptr_cpp_loop(return_array_pyobject_ptr, unwrap):
-    # Intentionally all temporaries, do not change.
-    arr_from_list = return_array_pyobject_ptr(WrapWithPyValueHolder(6, "seven", -8.0))
-    assert isinstance(arr_from_list, np.ndarray)
-    assert arr_from_list.dtype == np.dtype("O")
-    assert unwrap(arr_from_list) == [6, "seven", -8.0]
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import numpy_array as m
+
+np = pytest.importorskip("numpy")
+
+
+def test_dtypes():
+    # See issue #1328.
+    # - Platform-dependent sizes.
+    for size_check in m.get_platform_dtype_size_checks():
+        print(size_check)
+        assert size_check.size_cpp == size_check.size_numpy, size_check
+    # - Concrete sizes.
+    for check in m.get_concrete_dtype_checks():
+        print(check)
+        assert check.numpy == check.pybind11, check
+        if check.numpy.num != check.pybind11.num:
+            print(
+                f"NOTE: typenum mismatch for {check}: {check.numpy.num} != {check.pybind11.num}"
+            )
+
+
+@pytest.fixture()
+def arr():
+    return np.array([[1, 2, 3], [4, 5, 6]], "=u2")
+
+
+def test_array_attributes():
+    a = np.array(0, "f8")
+    assert m.ndim(a) == 0
+    assert all(m.shape(a) == [])
+    assert all(m.strides(a) == [])
+    with pytest.raises(IndexError) as excinfo:
+        m.shape(a, 0)
+    assert str(excinfo.value) == "invalid axis: 0 (ndim = 0)"
+    with pytest.raises(IndexError) as excinfo:
+        m.strides(a, 0)
+    assert str(excinfo.value) == "invalid axis: 0 (ndim = 0)"
+    assert m.writeable(a)
+    assert m.size(a) == 1
+    assert m.itemsize(a) == 8
+    assert m.nbytes(a) == 8
+    assert m.owndata(a)
+
+    a = np.array([[1, 2, 3], [4, 5, 6]], "u2").view()
+    a.flags.writeable = False
+    assert m.ndim(a) == 2
+    assert all(m.shape(a) == [2, 3])
+    assert m.shape(a, 0) == 2
+    assert m.shape(a, 1) == 3
+    assert all(m.strides(a) == [6, 2])
+    assert m.strides(a, 0) == 6
+    assert m.strides(a, 1) == 2
+    with pytest.raises(IndexError) as excinfo:
+        m.shape(a, 2)
+    assert str(excinfo.value) == "invalid axis: 2 (ndim = 2)"
+    with pytest.raises(IndexError) as excinfo:
+        m.strides(a, 2)
+    assert str(excinfo.value) == "invalid axis: 2 (ndim = 2)"
+    assert not m.writeable(a)
+    assert m.size(a) == 6
+    assert m.itemsize(a) == 2
+    assert m.nbytes(a) == 12
+    assert not m.owndata(a)
+
+
+@pytest.mark.parametrize(
+    ("args", "ret"), [([], 0), ([0], 0), ([1], 3), ([0, 1], 1), ([1, 2], 5)]
+)
+def test_index_offset(arr, args, ret):
+    assert m.index_at(arr, *args) == ret
+    assert m.index_at_t(arr, *args) == ret
+    assert m.offset_at(arr, *args) == ret * arr.dtype.itemsize
+    assert m.offset_at_t(arr, *args) == ret * arr.dtype.itemsize
+
+
+def test_dim_check_fail(arr):
+    for func in (
+        m.index_at,
+        m.index_at_t,
+        m.offset_at,
+        m.offset_at_t,
+        m.data,
+        m.data_t,
+        m.mutate_data,
+        m.mutate_data_t,
+    ):
+        with pytest.raises(IndexError) as excinfo:
+            func(arr, 1, 2, 3)
+        assert str(excinfo.value) == "too many indices for an array: 3 (ndim = 2)"
+
+
+@pytest.mark.parametrize(
+    ("args", "ret"),
+    [
+        ([], [1, 2, 3, 4, 5, 6]),
+        ([1], [4, 5, 6]),
+        ([0, 1], [2, 3, 4, 5, 6]),
+        ([1, 2], [6]),
+    ],
+)
+def test_data(arr, args, ret):
+    from sys import byteorder
+
+    assert all(m.data_t(arr, *args) == ret)
+    assert all(m.data(arr, *args)[(0 if byteorder == "little" else 1) :: 2] == ret)
+    assert all(m.data(arr, *args)[(1 if byteorder == "little" else 0) :: 2] == 0)
+
+
+@pytest.mark.parametrize("dim", [0, 1, 3])
+def test_at_fail(arr, dim):
+    for func in m.at_t, m.mutate_at_t:
+        with pytest.raises(IndexError) as excinfo:
+            func(arr, *([0] * dim))
+        assert str(excinfo.value) == f"index dimension mismatch: {dim} (ndim = 2)"
+
+
+def test_at(arr):
+    assert m.at_t(arr, 0, 2) == 3
+    assert m.at_t(arr, 1, 0) == 4
+
+    assert all(m.mutate_at_t(arr, 0, 2).ravel() == [1, 2, 4, 4, 5, 6])
+    assert all(m.mutate_at_t(arr, 1, 0).ravel() == [1, 2, 4, 5, 5, 6])
+
+
+def test_mutate_readonly(arr):
+    arr.flags.writeable = False
+    for func, args in (
+        (m.mutate_data, ()),
+        (m.mutate_data_t, ()),
+        (m.mutate_at_t, (0, 0)),
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            func(arr, *args)
+        assert str(excinfo.value) == "array is not writeable"
+
+
+def test_mutate_data(arr):
+    assert all(m.mutate_data(arr).ravel() == [2, 4, 6, 8, 10, 12])
+    assert all(m.mutate_data(arr).ravel() == [4, 8, 12, 16, 20, 24])
+    assert all(m.mutate_data(arr, 1).ravel() == [4, 8, 12, 32, 40, 48])
+    assert all(m.mutate_data(arr, 0, 1).ravel() == [4, 16, 24, 64, 80, 96])
+    assert all(m.mutate_data(arr, 1, 2).ravel() == [4, 16, 24, 64, 80, 192])
+
+    assert all(m.mutate_data_t(arr).ravel() == [5, 17, 25, 65, 81, 193])
+    assert all(m.mutate_data_t(arr).ravel() == [6, 18, 26, 66, 82, 194])
+    assert all(m.mutate_data_t(arr, 1).ravel() == [6, 18, 26, 67, 83, 195])
+    assert all(m.mutate_data_t(arr, 0, 1).ravel() == [6, 19, 27, 68, 84, 196])
+    assert all(m.mutate_data_t(arr, 1, 2).ravel() == [6, 19, 27, 68, 84, 197])
+
+
+def test_bounds_check(arr):
+    for func in (
+        m.index_at,
+        m.index_at_t,
+        m.data,
+        m.data_t,
+        m.mutate_data,
+        m.mutate_data_t,
+        m.at_t,
+        m.mutate_at_t,
+    ):
+        with pytest.raises(IndexError) as excinfo:
+            func(arr, 2, 0)
+        assert str(excinfo.value) == "index 2 is out of bounds for axis 0 with size 2"
+        with pytest.raises(IndexError) as excinfo:
+            func(arr, 0, 4)
+        assert str(excinfo.value) == "index 4 is out of bounds for axis 1 with size 3"
+
+
+def test_make_c_f_array():
+    assert m.make_c_array().flags.c_contiguous
+    assert not m.make_c_array().flags.f_contiguous
+    assert m.make_f_array().flags.f_contiguous
+    assert not m.make_f_array().flags.c_contiguous
+
+
+def test_make_empty_shaped_array():
+    m.make_empty_shaped_array()
+
+    # empty shape means numpy scalar, PEP 3118
+    assert m.scalar_int().ndim == 0
+    assert m.scalar_int().shape == ()
+    assert m.scalar_int() == 42
+
+
+def test_wrap():
+    def assert_references(a, b, base=None):
+        if base is None:
+            base = a
+        assert a is not b
+        assert a.__array_interface__["data"][0] == b.__array_interface__["data"][0]
+        assert a.shape == b.shape
+        assert a.strides == b.strides
+        assert a.flags.c_contiguous == b.flags.c_contiguous
+        assert a.flags.f_contiguous == b.flags.f_contiguous
+        assert a.flags.writeable == b.flags.writeable
+        assert a.flags.aligned == b.flags.aligned
+        # 1.13 supported Python 3.6
+        if tuple(int(x) for x in np.__version__.split(".")[:2]) >= (1, 14):
+            assert a.flags.writebackifcopy == b.flags.writebackifcopy
+        else:
+            assert a.flags.updateifcopy == b.flags.updateifcopy
+        assert np.all(a == b)
+        assert not b.flags.owndata
+        assert b.base is base
+        if a.flags.writeable and a.ndim == 2:
+            a[0, 0] = 1234
+            assert b[0, 0] == 1234
+
+    a1 = np.array([1, 2], dtype=np.int16)
+    assert a1.flags.owndata
+    assert a1.base is None
+    a2 = m.wrap(a1)
+    assert_references(a1, a2)
+
+    a1 = np.array([[1, 2], [3, 4]], dtype=np.float32, order="F")
+    assert a1.flags.owndata
+    assert a1.base is None
+    a2 = m.wrap(a1)
+    assert_references(a1, a2)
+
+    a1 = np.array([[1, 2], [3, 4]], dtype=np.float32, order="C")
+    a1.flags.writeable = False
+    a2 = m.wrap(a1)
+    assert_references(a1, a2)
+
+    a1 = np.random.random((4, 4, 4))
+    a2 = m.wrap(a1)
+    assert_references(a1, a2)
+
+    a1t = a1.transpose()
+    a2 = m.wrap(a1t)
+    assert_references(a1t, a2, a1)
+
+    a1d = a1.diagonal()
+    a2 = m.wrap(a1d)
+    assert_references(a1d, a2, a1)
+
+    a1m = a1[::-1, ::-1, ::-1]
+    a2 = m.wrap(a1m)
+    assert_references(a1m, a2, a1)
+
+
+def test_numpy_view(capture):
+    with capture:
+        ac = m.ArrayClass()
+        ac_view_1 = ac.numpy_view()
+        ac_view_2 = ac.numpy_view()
+        assert np.all(ac_view_1 == np.array([1, 2], dtype=np.int32))
+        del ac
+        pytest.gc_collect()
+    assert (
+        capture
+        == """
+        ArrayClass()
+        ArrayClass::numpy_view()
+        ArrayClass::numpy_view()
+    """
+    )
+    ac_view_1[0] = 4
+    ac_view_1[1] = 3
+    assert ac_view_2[0] == 4
+    assert ac_view_2[1] == 3
+    with capture:
+        del ac_view_1
+        del ac_view_2
+        pytest.gc_collect()
+        pytest.gc_collect()
+    assert (
+        capture
+        == """
+        ~ArrayClass()
+    """
+    )
+
+
+def test_cast_numpy_int64_to_uint64():
+    m.function_taking_uint64(123)
+    m.function_taking_uint64(np.uint64(123))
+
+
+def test_isinstance():
+    assert m.isinstance_untyped(np.array([1, 2, 3]), "not an array")
+    assert m.isinstance_typed(np.array([1.0, 2.0, 3.0]))
+
+
+def test_constructors():
+    defaults = m.default_constructors()
+    for a in defaults.values():
+        assert a.size == 0
+    assert defaults["array"].dtype == np.array([]).dtype
+    assert defaults["array_t<int32>"].dtype == np.int32
+    assert defaults["array_t<double>"].dtype == np.float64
+
+    results = m.converting_constructors([1, 2, 3])
+    for a in results.values():
+        np.testing.assert_array_equal(a, [1, 2, 3])
+    assert results["array"].dtype == np.dtype(int)
+    assert results["array_t<int32>"].dtype == np.int32
+    assert results["array_t<double>"].dtype == np.float64
+
+
+def test_overload_resolution(msg):
+    # Exact overload matches:
+    assert m.overloaded(np.array([1], dtype="float64")) == "double"
+    assert m.overloaded(np.array([1], dtype="float32")) == "float"
+    assert m.overloaded(np.array([1], dtype="ushort")) == "unsigned short"
+    assert m.overloaded(np.array([1], dtype="intc")) == "int"
+    assert m.overloaded(np.array([1], dtype="longlong")) == "long long"
+    assert m.overloaded(np.array([1], dtype="complex")) == "double complex"
+    assert m.overloaded(np.array([1], dtype="csingle")) == "float complex"
+
+    # No exact match, should call first convertible version:
+    assert m.overloaded(np.array([1], dtype="uint8")) == "double"
+
+    with pytest.raises(TypeError) as excinfo:
+        m.overloaded("not an array")
+    assert (
+        msg(excinfo.value)
+        == """
+        overloaded(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: numpy.ndarray[numpy.float64]) -> str
+            2. (arg0: numpy.ndarray[numpy.float32]) -> str
+            3. (arg0: numpy.ndarray[numpy.int32]) -> str
+            4. (arg0: numpy.ndarray[numpy.uint16]) -> str
+            5. (arg0: numpy.ndarray[numpy.int64]) -> str
+            6. (arg0: numpy.ndarray[numpy.complex128]) -> str
+            7. (arg0: numpy.ndarray[numpy.complex64]) -> str
+
+        Invoked with: 'not an array'
+    """
+    )
+
+    assert m.overloaded2(np.array([1], dtype="float64")) == "double"
+    assert m.overloaded2(np.array([1], dtype="float32")) == "float"
+    assert m.overloaded2(np.array([1], dtype="complex64")) == "float complex"
+    assert m.overloaded2(np.array([1], dtype="complex128")) == "double complex"
+    assert m.overloaded2(np.array([1], dtype="float32")) == "float"
+
+    assert m.overloaded3(np.array([1], dtype="float64")) == "double"
+    assert m.overloaded3(np.array([1], dtype="intc")) == "int"
+    expected_exc = """
+        overloaded3(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: numpy.ndarray[numpy.int32]) -> str
+            2. (arg0: numpy.ndarray[numpy.float64]) -> str
+
+        Invoked with: """
+
+    with pytest.raises(TypeError) as excinfo:
+        m.overloaded3(np.array([1], dtype="uintc"))
+    assert msg(excinfo.value) == expected_exc + repr(np.array([1], dtype="uint32"))
+    with pytest.raises(TypeError) as excinfo:
+        m.overloaded3(np.array([1], dtype="float32"))
+    assert msg(excinfo.value) == expected_exc + repr(np.array([1.0], dtype="float32"))
+    with pytest.raises(TypeError) as excinfo:
+        m.overloaded3(np.array([1], dtype="complex"))
+    assert msg(excinfo.value) == expected_exc + repr(np.array([1.0 + 0.0j]))
+
+    # Exact matches:
+    assert m.overloaded4(np.array([1], dtype="double")) == "double"
+    assert m.overloaded4(np.array([1], dtype="longlong")) == "long long"
+    # Non-exact matches requiring conversion.  Since float to integer isn't a
+    # save conversion, it should go to the double overload, but short can go to
+    # either (and so should end up on the first-registered, the long long).
+    assert m.overloaded4(np.array([1], dtype="float32")) == "double"
+    assert m.overloaded4(np.array([1], dtype="short")) == "long long"
+
+    assert m.overloaded5(np.array([1], dtype="double")) == "double"
+    assert m.overloaded5(np.array([1], dtype="uintc")) == "unsigned int"
+    assert m.overloaded5(np.array([1], dtype="float32")) == "unsigned int"
+
+
+def test_greedy_string_overload():
+    """Tests fix for #685 - ndarray shouldn't go to std::string overload"""
+
+    assert m.issue685("abc") == "string"
+    assert m.issue685(np.array([97, 98, 99], dtype="b")) == "array"
+    assert m.issue685(123) == "other"
+
+
+def test_array_unchecked_fixed_dims(msg):
+    z1 = np.array([[1, 2], [3, 4]], dtype="float64")
+    m.proxy_add2(z1, 10)
+    assert np.all(z1 == [[11, 12], [13, 14]])
+
+    with pytest.raises(ValueError) as excinfo:
+        m.proxy_add2(np.array([1.0, 2, 3]), 5.0)
+    assert (
+        msg(excinfo.value) == "array has incorrect number of dimensions: 1; expected 2"
+    )
+
+    expect_c = np.ndarray(shape=(3, 3, 3), buffer=np.array(range(3, 30)), dtype="int")
+    assert np.all(m.proxy_init3(3.0) == expect_c)
+    expect_f = np.transpose(expect_c)
+    assert np.all(m.proxy_init3F(3.0) == expect_f)
+
+    assert m.proxy_squared_L2_norm(np.array(range(6))) == 55
+    assert m.proxy_squared_L2_norm(np.array(range(6), dtype="float64")) == 55
+
+    assert m.proxy_auxiliaries2(z1) == [11, 11, True, 2, 8, 2, 2, 4, 32]
+    assert m.proxy_auxiliaries2(z1) == m.array_auxiliaries2(z1)
+
+    assert m.proxy_auxiliaries1_const_ref(z1[0, :])
+    assert m.proxy_auxiliaries2_const_ref(z1)
+
+
+def test_array_unchecked_dyn_dims():
+    z1 = np.array([[1, 2], [3, 4]], dtype="float64")
+    m.proxy_add2_dyn(z1, 10)
+    assert np.all(z1 == [[11, 12], [13, 14]])
+
+    expect_c = np.ndarray(shape=(3, 3, 3), buffer=np.array(range(3, 30)), dtype="int")
+    assert np.all(m.proxy_init3_dyn(3.0) == expect_c)
+
+    assert m.proxy_auxiliaries2_dyn(z1) == [11, 11, True, 2, 8, 2, 2, 4, 32]
+    assert m.proxy_auxiliaries2_dyn(z1) == m.array_auxiliaries2(z1)
+
+
+def test_array_failure():
+    with pytest.raises(ValueError) as excinfo:
+        m.array_fail_test()
+    assert str(excinfo.value) == "cannot create a pybind11::array from a nullptr"
+
+    with pytest.raises(ValueError) as excinfo:
+        m.array_t_fail_test()
+    assert str(excinfo.value) == "cannot create a pybind11::array_t from a nullptr"
+
+    with pytest.raises(ValueError) as excinfo:
+        m.array_fail_test_negative_size()
+    assert str(excinfo.value) == "negative dimensions are not allowed"
+
+
+def test_initializer_list():
+    assert m.array_initializer_list1().shape == (1,)
+    assert m.array_initializer_list2().shape == (1, 2)
+    assert m.array_initializer_list3().shape == (1, 2, 3)
+    assert m.array_initializer_list4().shape == (1, 2, 3, 4)
+
+
+def test_array_resize():
+    a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype="float64")
+    m.array_reshape2(a)
+    assert a.size == 9
+    assert np.all(a == [[1, 2, 3], [4, 5, 6], [7, 8, 9]])
+
+    # total size change should succced with refcheck off
+    m.array_resize3(a, 4, False)
+    assert a.size == 64
+    # ... and fail with refcheck on
+    try:
+        m.array_resize3(a, 3, True)
+    except ValueError as e:
+        assert str(e).startswith("cannot resize an array")  # noqa: PT017
+    # transposed array doesn't own data
+    b = a.transpose()
+    try:
+        m.array_resize3(b, 3, False)
+    except ValueError as e:
+        assert str(e).startswith(  # noqa: PT017
+            "cannot resize this array: it does not own its data"
+        )
+    # ... but reshape should be fine
+    m.array_reshape2(b)
+    assert b.shape == (8, 8)
+
+
+@pytest.mark.xfail("env.PYPY")
+def test_array_create_and_resize():
+    a = m.create_and_resize(2)
+    assert a.size == 4
+    assert np.all(a == 42.0)
+
+
+def test_array_view():
+    a = np.ones(100 * 4).astype("uint8")
+    a_float_view = m.array_view(a, "float32")
+    assert a_float_view.shape == (100 * 1,)  # 1 / 4 bytes = 8 / 32
+
+    a_int16_view = m.array_view(a, "int16")  # 1 / 2 bytes = 16 / 32
+    assert a_int16_view.shape == (100 * 2,)
+
+
+def test_array_view_invalid():
+    a = np.ones(100 * 4).astype("uint8")
+    with pytest.raises(TypeError):
+        m.array_view(a, "deadly_dtype")
+
+
+def test_reshape_initializer_list():
+    a = np.arange(2 * 7 * 3) + 1
+    x = m.reshape_initializer_list(a, 2, 7, 3)
+    assert x.shape == (2, 7, 3)
+    assert list(x[1][4]) == [34, 35, 36]
+    with pytest.raises(ValueError) as excinfo:
+        m.reshape_initializer_list(a, 1, 7, 3)
+    assert str(excinfo.value) == "cannot reshape array of size 42 into shape (1,7,3)"
+
+
+def test_reshape_tuple():
+    a = np.arange(3 * 7 * 2) + 1
+    x = m.reshape_tuple(a, (3, 7, 2))
+    assert x.shape == (3, 7, 2)
+    assert list(x[1][4]) == [23, 24]
+    y = m.reshape_tuple(x, (x.size,))
+    assert y.shape == (42,)
+    with pytest.raises(ValueError) as excinfo:
+        m.reshape_tuple(a, (3, 7, 1))
+    assert str(excinfo.value) == "cannot reshape array of size 42 into shape (3,7,1)"
+    with pytest.raises(ValueError) as excinfo:
+        m.reshape_tuple(a, ())
+    assert str(excinfo.value) == "cannot reshape array of size 42 into shape ()"
+
+
+def test_index_using_ellipsis():
+    a = m.index_using_ellipsis(np.zeros((5, 6, 7)))
+    assert a.shape == (6,)
+
+
+@pytest.mark.parametrize(
+    "test_func",
+    [
+        m.test_fmt_desc_float,
+        m.test_fmt_desc_double,
+        m.test_fmt_desc_const_float,
+        m.test_fmt_desc_const_double,
+    ],
+)
+def test_format_descriptors_for_floating_point_types(test_func):
+    assert "numpy.ndarray[numpy.float" in test_func.__doc__
+
+
+@pytest.mark.parametrize("forcecast", [False, True])
+@pytest.mark.parametrize("contiguity", [None, "C", "F"])
+@pytest.mark.parametrize("noconvert", [False, True])
+@pytest.mark.filterwarnings(
+    "ignore:Casting complex values to real discards the imaginary part:numpy.ComplexWarning"
+)
+def test_argument_conversions(forcecast, contiguity, noconvert):
+    function_name = "accept_double"
+    if contiguity == "C":
+        function_name += "_c_style"
+    elif contiguity == "F":
+        function_name += "_f_style"
+    if forcecast:
+        function_name += "_forcecast"
+    if noconvert:
+        function_name += "_noconvert"
+    function = getattr(m, function_name)
+
+    for dtype in [np.dtype("float32"), np.dtype("float64"), np.dtype("complex128")]:
+        for order in ["C", "F"]:
+            for shape in [(2, 2), (1, 3, 1, 1), (1, 1, 1), (0,)]:
+                if not noconvert:
+                    # If noconvert is not passed, only complex128 needs to be truncated and
+                    # "cannot be safely obtained". So without `forcecast`, the argument shouldn't
+                    # be accepted.
+                    should_raise = dtype.name == "complex128" and not forcecast
+                else:
+                    # If noconvert is passed, only float64 and the matching order is accepted.
+                    # If at most one dimension has a size greater than 1, the array is also
+                    # trivially contiguous.
+                    trivially_contiguous = sum(1 for d in shape if d > 1) <= 1
+                    should_raise = dtype.name != "float64" or (
+                        contiguity is not None
+                        and contiguity != order
+                        and not trivially_contiguous
+                    )
+
+                array = np.zeros(shape, dtype=dtype, order=order)
+                if not should_raise:
+                    function(array)
+                else:
+                    with pytest.raises(
+                        TypeError, match="incompatible function arguments"
+                    ):
+                        function(array)
+
+
+@pytest.mark.xfail("env.PYPY")
+def test_dtype_refcount_leak():
+    from sys import getrefcount
+
+    dtype = np.dtype(np.float_)
+    a = np.array([1], dtype=dtype)
+    before = getrefcount(dtype)
+    m.ndim(a)
+    after = getrefcount(dtype)
+    assert after == before
+
+
+def test_round_trip_float():
+    arr = np.zeros((), np.float64)
+    arr[()] = 37.2
+    assert m.round_trip_float(arr) == 37.2
+
+
+# HINT: An easy and robust way (although only manual unfortunately) to check for
+#       ref-count leaks in the test_.*pyobject_ptr.* functions below is to
+#           * temporarily insert `while True:` (one-by-one),
+#           * run this test, and
+#           * run the Linux `top` command in another shell to visually monitor
+#             `RES` for a minute or two.
+#       If there is a leak, it is usually evident in seconds because the `RES`
+#       value increases without bounds. (Don't forget to Ctrl-C the test!)
+
+
+# For use as a temporary user-defined object, to maximize sensitivity of the tests below:
+#     * Ref-count leaks will be immediately evident.
+#     * Sanitizers are much more likely to detect heap-use-after-free due to
+#       other ref-count bugs.
+class PyValueHolder:
+    def __init__(self, value):
+        self.value = value
+
+
+def WrapWithPyValueHolder(*values):
+    return [PyValueHolder(v) for v in values]
+
+
+def UnwrapPyValueHolder(vhs):
+    return [vh.value for vh in vhs]
+
+
+def test_pass_array_pyobject_ptr_return_sum_str_values_ndarray():
+    # Intentionally all temporaries, do not change.
+    assert (
+        m.pass_array_pyobject_ptr_return_sum_str_values(
+            np.array(WrapWithPyValueHolder(-3, "four", 5.0), dtype=object)
+        )
+        == "-3four5.0"
+    )
+
+
+def test_pass_array_pyobject_ptr_return_sum_str_values_list():
+    # Intentionally all temporaries, do not change.
+    assert (
+        m.pass_array_pyobject_ptr_return_sum_str_values(
+            WrapWithPyValueHolder(2, "three", -4.0)
+        )
+        == "2three-4.0"
+    )
+
+
+def test_pass_array_pyobject_ptr_return_as_list():
+    # Intentionally all temporaries, do not change.
+    assert UnwrapPyValueHolder(
+        m.pass_array_pyobject_ptr_return_as_list(
+            np.array(WrapWithPyValueHolder(-1, "two", 3.0), dtype=object)
+        )
+    ) == [-1, "two", 3.0]
+
+
+@pytest.mark.parametrize(
+    ("return_array_pyobject_ptr", "unwrap"),
+    [
+        (m.return_array_pyobject_ptr_cpp_loop, list),
+        (m.return_array_pyobject_ptr_from_list, UnwrapPyValueHolder),
+    ],
+)
+def test_return_array_pyobject_ptr_cpp_loop(return_array_pyobject_ptr, unwrap):
+    # Intentionally all temporaries, do not change.
+    arr_from_list = return_array_pyobject_ptr(WrapWithPyValueHolder(6, "seven", -8.0))
+    assert isinstance(arr_from_list, np.ndarray)
+    assert arr_from_list.dtype == np.dtype("O")
+    assert unwrap(arr_from_list) == [6, "seven", -8.0]
```

## extern/pybind11/tests/test_numpy_dtypes.py

 * *Ordering differences only*

```diff
@@ -1,440 +1,440 @@
-import re
-
-import pytest
-
-import env  # noqa: F401
-from pybind11_tests import numpy_dtypes as m
-
-np = pytest.importorskip("numpy")
-
-
-@pytest.fixture(scope="module")
-def simple_dtype():
-    ld = np.dtype("longdouble")
-    return np.dtype(
-        {
-            "names": ["bool_", "uint_", "float_", "ldbl_"],
-            "formats": ["?", "u4", "f4", f"f{ld.itemsize}"],
-            "offsets": [0, 4, 8, (16 if ld.alignment > 4 else 12)],
-        }
-    )
-
-
-@pytest.fixture(scope="module")
-def packed_dtype():
-    return np.dtype([("bool_", "?"), ("uint_", "u4"), ("float_", "f4"), ("ldbl_", "g")])
-
-
-def dt_fmt():
-    from sys import byteorder
-
-    e = "<" if byteorder == "little" else ">"
-    return (
-        "{{'names':['bool_','uint_','float_','ldbl_'],"
-        "'formats':['?','" + e + "u4','" + e + "f4','" + e + "f{}'],"
-        "'offsets':[0,4,8,{}],'itemsize':{}}}"
-    )
-
-
-def simple_dtype_fmt():
-    ld = np.dtype("longdouble")
-    simple_ld_off = 12 + 4 * (ld.alignment > 4)
-    return dt_fmt().format(ld.itemsize, simple_ld_off, simple_ld_off + ld.itemsize)
-
-
-def packed_dtype_fmt():
-    from sys import byteorder
-
-    return "[('bool_','?'),('uint_','{e}u4'),('float_','{e}f4'),('ldbl_','{e}f{}')]".format(
-        np.dtype("longdouble").itemsize, e="<" if byteorder == "little" else ">"
-    )
-
-
-def partial_ld_offset():
-    return (
-        12
-        + 4 * (np.dtype("uint64").alignment > 4)
-        + 8
-        + 8 * (np.dtype("longdouble").alignment > 8)
-    )
-
-
-def partial_dtype_fmt():
-    ld = np.dtype("longdouble")
-    partial_ld_off = partial_ld_offset()
-    partial_size = partial_ld_off + ld.itemsize
-    partial_end_padding = partial_size % np.dtype("uint64").alignment
-    return dt_fmt().format(
-        ld.itemsize, partial_ld_off, partial_size + partial_end_padding
-    )
-
-
-def partial_nested_fmt():
-    ld = np.dtype("longdouble")
-    partial_nested_off = 8 + 8 * (ld.alignment > 8)
-    partial_ld_off = partial_ld_offset()
-    partial_size = partial_ld_off + ld.itemsize
-    partial_end_padding = partial_size % np.dtype("uint64").alignment
-    partial_nested_size = partial_nested_off * 2 + partial_size + partial_end_padding
-    return "{{'names':['a'],'formats':[{}],'offsets':[{}],'itemsize':{}}}".format(
-        partial_dtype_fmt(), partial_nested_off, partial_nested_size
-    )
-
-
-def assert_equal(actual, expected_data, expected_dtype):
-    np.testing.assert_equal(actual, np.array(expected_data, dtype=expected_dtype))
-
-
-def test_format_descriptors():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.get_format_unbound()
-    assert re.match(
-        "^NumPy type info missing for .*UnboundStruct.*$", str(excinfo.value)
-    )
-
-    ld = np.dtype("longdouble")
-    ldbl_fmt = ("4x" if ld.alignment > 4 else "") + ld.char
-    ss_fmt = "^T{?:bool_:3xI:uint_:f:float_:" + ldbl_fmt + ":ldbl_:}"
-    dbl = np.dtype("double")
-    end_padding = ld.itemsize % np.dtype("uint64").alignment
-    partial_fmt = (
-        "^T{?:bool_:3xI:uint_:f:float_:"
-        + str(4 * (dbl.alignment > 4) + dbl.itemsize + 8 * (ld.alignment > 8))
-        + "xg:ldbl_:"
-        + (str(end_padding) + "x}" if end_padding > 0 else "}")
-    )
-    nested_extra = str(max(8, ld.alignment))
-    assert m.print_format_descriptors() == [
-        ss_fmt,
-        "^T{?:bool_:I:uint_:f:float_:g:ldbl_:}",
-        "^T{" + ss_fmt + ":a:^T{?:bool_:I:uint_:f:float_:g:ldbl_:}:b:}",
-        partial_fmt,
-        "^T{" + nested_extra + "x" + partial_fmt + ":a:" + nested_extra + "x}",
-        "^T{3s:a:3s:b:}",
-        "^T{(3)4s:a:(2)i:b:(3)B:c:1x(4, 2)f:d:}",
-        "^T{q:e1:B:e2:}",
-        "^T{Zf:cflt:Zd:cdbl:}",
-    ]
-
-
-def test_dtype(simple_dtype):
-    from sys import byteorder
-
-    e = "<" if byteorder == "little" else ">"
-
-    assert [x.replace(" ", "") for x in m.print_dtypes()] == [
-        simple_dtype_fmt(),
-        packed_dtype_fmt(),
-        f"[('a',{simple_dtype_fmt()}),('b',{packed_dtype_fmt()})]",
-        partial_dtype_fmt(),
-        partial_nested_fmt(),
-        "[('a','S3'),('b','S3')]",
-        (
-            "{'names':['a','b','c','d'],"
-            f"'formats':[('S4',(3,)),('{e}i4',(2,)),('u1',(3,)),('{e}f4',(4,2))],"
-            "'offsets':[0,12,20,24],'itemsize':56}"
-        ),
-        "[('e1','" + e + "i8'),('e2','u1')]",
-        "[('x','i1'),('y','" + e + "u8')]",
-        "[('cflt','" + e + "c8'),('cdbl','" + e + "c16')]",
-    ]
-
-    d1 = np.dtype(
-        {
-            "names": ["a", "b"],
-            "formats": ["int32", "float64"],
-            "offsets": [1, 10],
-            "itemsize": 20,
-        }
-    )
-    d2 = np.dtype([("a", "i4"), ("b", "f4")])
-    assert m.test_dtype_ctors() == [
-        np.dtype("int32"),
-        np.dtype("float64"),
-        np.dtype("bool"),
-        d1,
-        d1,
-        np.dtype("uint32"),
-        d2,
-        np.dtype("d"),
-    ]
-
-    assert m.test_dtype_methods() == [
-        np.dtype("int32"),
-        simple_dtype,
-        False,
-        True,
-        np.dtype("int32").itemsize,
-        simple_dtype.itemsize,
-    ]
-
-    assert m.trailing_padding_dtype() == m.buffer_to_dtype(
-        np.zeros(1, m.trailing_padding_dtype())
-    )
-
-    expected_chars = "bhilqBHILQefdgFDG?MmO"
-    assert m.test_dtype_kind() == list("iiiiiuuuuuffffcccbMmO")
-    assert m.test_dtype_char_() == list(expected_chars)
-    assert m.test_dtype_num() == [np.dtype(ch).num for ch in expected_chars]
-    assert m.test_dtype_byteorder() == [np.dtype(ch).byteorder for ch in expected_chars]
-    assert m.test_dtype_alignment() == [np.dtype(ch).alignment for ch in expected_chars]
-    assert m.test_dtype_flags() == [chr(np.dtype(ch).flags) for ch in expected_chars]
-
-
-def test_recarray(simple_dtype, packed_dtype):
-    elements = [(False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)]
-
-    for func, dtype in [
-        (m.create_rec_simple, simple_dtype),
-        (m.create_rec_packed, packed_dtype),
-    ]:
-        arr = func(0)
-        assert arr.dtype == dtype
-        assert_equal(arr, [], simple_dtype)
-        assert_equal(arr, [], packed_dtype)
-
-        arr = func(3)
-        assert arr.dtype == dtype
-        assert_equal(arr, elements, simple_dtype)
-        assert_equal(arr, elements, packed_dtype)
-
-        # Show what recarray's look like in NumPy.
-        assert type(arr[0]) == np.void
-        assert type(arr[0].item()) == tuple
-
-        if dtype == simple_dtype:
-            assert m.print_rec_simple(arr) == [
-                "s:0,0,0,-0",
-                "s:1,1,1.5,-2.5",
-                "s:0,2,3,-5",
-            ]
-        else:
-            assert m.print_rec_packed(arr) == [
-                "p:0,0,0,-0",
-                "p:1,1,1.5,-2.5",
-                "p:0,2,3,-5",
-            ]
-
-    nested_dtype = np.dtype([("a", simple_dtype), ("b", packed_dtype)])
-
-    arr = m.create_rec_nested(0)
-    assert arr.dtype == nested_dtype
-    assert_equal(arr, [], nested_dtype)
-
-    arr = m.create_rec_nested(3)
-    assert arr.dtype == nested_dtype
-    assert_equal(
-        arr,
-        [
-            ((False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5)),
-            ((True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)),
-            ((False, 2, 3.0, -5.0), (True, 3, 4.5, -7.5)),
-        ],
-        nested_dtype,
-    )
-    assert m.print_rec_nested(arr) == [
-        "n:a=s:0,0,0,-0;b=p:1,1,1.5,-2.5",
-        "n:a=s:1,1,1.5,-2.5;b=p:0,2,3,-5",
-        "n:a=s:0,2,3,-5;b=p:1,3,4.5,-7.5",
-    ]
-
-    arr = m.create_rec_partial(3)
-    assert str(arr.dtype).replace(" ", "") == partial_dtype_fmt()
-    partial_dtype = arr.dtype
-    assert "" not in arr.dtype.fields
-    assert partial_dtype.itemsize > simple_dtype.itemsize
-    assert_equal(arr, elements, simple_dtype)
-    assert_equal(arr, elements, packed_dtype)
-
-    arr = m.create_rec_partial_nested(3)
-    assert str(arr.dtype).replace(" ", "") == partial_nested_fmt()
-    assert "" not in arr.dtype.fields
-    assert "" not in arr.dtype.fields["a"][0].fields
-    assert arr.dtype.itemsize > partial_dtype.itemsize
-    np.testing.assert_equal(arr["a"], m.create_rec_partial(3))
-
-
-def test_array_constructors():
-    data = np.arange(1, 7, dtype="int32")
-    for i in range(8):
-        np.testing.assert_array_equal(m.test_array_ctors(10 + i), data.reshape((3, 2)))
-        np.testing.assert_array_equal(m.test_array_ctors(20 + i), data.reshape((3, 2)))
-    for i in range(5):
-        np.testing.assert_array_equal(m.test_array_ctors(30 + i), data)
-        np.testing.assert_array_equal(m.test_array_ctors(40 + i), data)
-
-
-def test_string_array():
-    arr = m.create_string_array(True)
-    assert str(arr.dtype) == "[('a', 'S3'), ('b', 'S3')]"
-    assert m.print_string_array(arr) == [
-        "a='',b=''",
-        "a='a',b='a'",
-        "a='ab',b='ab'",
-        "a='abc',b='abc'",
-    ]
-    dtype = arr.dtype
-    assert arr["a"].tolist() == [b"", b"a", b"ab", b"abc"]
-    assert arr["b"].tolist() == [b"", b"a", b"ab", b"abc"]
-    arr = m.create_string_array(False)
-    assert dtype == arr.dtype
-
-
-def test_array_array():
-    from sys import byteorder
-
-    e = "<" if byteorder == "little" else ">"
-
-    arr = m.create_array_array(3)
-    assert str(arr.dtype).replace(" ", "") == (
-        "{'names':['a','b','c','d'],"
-        f"'formats':[('S4',(3,)),('{e}i4',(2,)),('u1',(3,)),('{e}f4',(4,2))],"
-        "'offsets':[0,12,20,24],'itemsize':56}"
-    )
-    assert m.print_array_array(arr) == [
-        "a={{A,B,C,D},{K,L,M,N},{U,V,W,X}},b={0,1},"
-        "c={0,1,2},d={{0,1},{10,11},{20,21},{30,31}}",
-        "a={{W,X,Y,Z},{G,H,I,J},{Q,R,S,T}},b={1000,1001},"
-        "c={10,11,12},d={{100,101},{110,111},{120,121},{130,131}}",
-        "a={{S,T,U,V},{C,D,E,F},{M,N,O,P}},b={2000,2001},"
-        "c={20,21,22},d={{200,201},{210,211},{220,221},{230,231}}",
-    ]
-    assert arr["a"].tolist() == [
-        [b"ABCD", b"KLMN", b"UVWX"],
-        [b"WXYZ", b"GHIJ", b"QRST"],
-        [b"STUV", b"CDEF", b"MNOP"],
-    ]
-    assert arr["b"].tolist() == [[0, 1], [1000, 1001], [2000, 2001]]
-    assert m.create_array_array(0).dtype == arr.dtype
-
-
-def test_enum_array():
-    from sys import byteorder
-
-    e = "<" if byteorder == "little" else ">"
-
-    arr = m.create_enum_array(3)
-    dtype = arr.dtype
-    assert dtype == np.dtype([("e1", e + "i8"), ("e2", "u1")])
-    assert m.print_enum_array(arr) == ["e1=A,e2=X", "e1=B,e2=Y", "e1=A,e2=X"]
-    assert arr["e1"].tolist() == [-1, 1, -1]
-    assert arr["e2"].tolist() == [1, 2, 1]
-    assert m.create_enum_array(0).dtype == dtype
-
-
-def test_complex_array():
-    from sys import byteorder
-
-    e = "<" if byteorder == "little" else ">"
-
-    arr = m.create_complex_array(3)
-    dtype = arr.dtype
-    assert dtype == np.dtype([("cflt", e + "c8"), ("cdbl", e + "c16")])
-    assert m.print_complex_array(arr) == [
-        "c:(0,0.25),(0.5,0.75)",
-        "c:(1,1.25),(1.5,1.75)",
-        "c:(2,2.25),(2.5,2.75)",
-    ]
-    assert arr["cflt"].tolist() == [0.0 + 0.25j, 1.0 + 1.25j, 2.0 + 2.25j]
-    assert arr["cdbl"].tolist() == [0.5 + 0.75j, 1.5 + 1.75j, 2.5 + 2.75j]
-    assert m.create_complex_array(0).dtype == dtype
-
-
-def test_signature(doc):
-    assert (
-        doc(m.create_rec_nested)
-        == "create_rec_nested(arg0: int) -> numpy.ndarray[NestedStruct]"
-    )
-
-
-def test_scalar_conversion():
-    n = 3
-    arrays = [
-        m.create_rec_simple(n),
-        m.create_rec_packed(n),
-        m.create_rec_nested(n),
-        m.create_enum_array(n),
-    ]
-    funcs = [m.f_simple, m.f_packed, m.f_nested]
-
-    for i, func in enumerate(funcs):
-        for j, arr in enumerate(arrays):
-            if i == j and i < 2:
-                assert [func(arr[k]) for k in range(n)] == [k * 10 for k in range(n)]
-            else:
-                with pytest.raises(TypeError) as excinfo:
-                    func(arr[0])
-                assert "incompatible function arguments" in str(excinfo.value)
-
-
-def test_vectorize():
-    n = 3
-    array = m.create_rec_simple(n)
-    values = m.f_simple_vectorized(array)
-    np.testing.assert_array_equal(values, [0, 10, 20])
-    array_2 = m.f_simple_pass_thru_vectorized(array)
-    np.testing.assert_array_equal(array, array_2)
-
-
-def test_cls_and_dtype_conversion(simple_dtype):
-    s = m.SimpleStruct()
-    assert s.astuple() == (False, 0, 0.0, 0.0)
-    assert m.SimpleStruct.fromtuple(s.astuple()).astuple() == s.astuple()
-
-    s.uint_ = 2
-    assert m.f_simple(s) == 20
-
-    # Try as recarray of shape==(1,).
-    s_recarray = np.array([(False, 2, 0.0, 0.0)], dtype=simple_dtype)
-    # Show that this will work for vectorized case.
-    np.testing.assert_array_equal(m.f_simple_vectorized(s_recarray), [20])
-
-    # Show as a scalar that inherits from np.generic.
-    s_scalar = s_recarray[0]
-    assert isinstance(s_scalar, np.void)
-    assert m.f_simple(s_scalar) == 20
-
-    # Show that an *array* scalar (np.ndarray.shape == ()) does not convert.
-    # More specifically, conversion to SimpleStruct is not implicit.
-    s_recarray_scalar = s_recarray.reshape(())
-    assert isinstance(s_recarray_scalar, np.ndarray)
-    assert s_recarray_scalar.dtype == simple_dtype
-    with pytest.raises(TypeError) as excinfo:
-        m.f_simple(s_recarray_scalar)
-    assert "incompatible function arguments" in str(excinfo.value)
-    # Explicitly convert to m.SimpleStruct.
-    assert m.f_simple(m.SimpleStruct.fromtuple(s_recarray_scalar.item())) == 20
-
-    # Show that an array of dtype=object does *not* convert.
-    s_array_object = np.array([s])
-    assert s_array_object.dtype == object
-    with pytest.raises(TypeError) as excinfo:
-        m.f_simple_vectorized(s_array_object)
-    assert "incompatible function arguments" in str(excinfo.value)
-    # Explicitly convert to `np.array(..., dtype=simple_dtype)`
-    s_array = np.array([s.astuple()], dtype=simple_dtype)
-    np.testing.assert_array_equal(m.f_simple_vectorized(s_array), [20])
-
-
-def test_register_dtype():
-    with pytest.raises(RuntimeError) as excinfo:
-        m.register_dtype()
-    assert "dtype is already registered" in str(excinfo.value)
-
-
-@pytest.mark.xfail("env.PYPY")
-def test_str_leak():
-    from sys import getrefcount
-
-    fmt = "f4"
-    pytest.gc_collect()
-    start = getrefcount(fmt)
-    d = m.dtype_wrapper(fmt)
-    assert d is np.dtype("f4")
-    del d
-    pytest.gc_collect()
-    assert getrefcount(fmt) == start
-
-
-def test_compare_buffer_info():
-    assert all(m.compare_buffer_info())
+import re
+
+import pytest
+
+import env  # noqa: F401
+from pybind11_tests import numpy_dtypes as m
+
+np = pytest.importorskip("numpy")
+
+
+@pytest.fixture(scope="module")
+def simple_dtype():
+    ld = np.dtype("longdouble")
+    return np.dtype(
+        {
+            "names": ["bool_", "uint_", "float_", "ldbl_"],
+            "formats": ["?", "u4", "f4", f"f{ld.itemsize}"],
+            "offsets": [0, 4, 8, (16 if ld.alignment > 4 else 12)],
+        }
+    )
+
+
+@pytest.fixture(scope="module")
+def packed_dtype():
+    return np.dtype([("bool_", "?"), ("uint_", "u4"), ("float_", "f4"), ("ldbl_", "g")])
+
+
+def dt_fmt():
+    from sys import byteorder
+
+    e = "<" if byteorder == "little" else ">"
+    return (
+        "{{'names':['bool_','uint_','float_','ldbl_'],"
+        "'formats':['?','" + e + "u4','" + e + "f4','" + e + "f{}'],"
+        "'offsets':[0,4,8,{}],'itemsize':{}}}"
+    )
+
+
+def simple_dtype_fmt():
+    ld = np.dtype("longdouble")
+    simple_ld_off = 12 + 4 * (ld.alignment > 4)
+    return dt_fmt().format(ld.itemsize, simple_ld_off, simple_ld_off + ld.itemsize)
+
+
+def packed_dtype_fmt():
+    from sys import byteorder
+
+    return "[('bool_','?'),('uint_','{e}u4'),('float_','{e}f4'),('ldbl_','{e}f{}')]".format(
+        np.dtype("longdouble").itemsize, e="<" if byteorder == "little" else ">"
+    )
+
+
+def partial_ld_offset():
+    return (
+        12
+        + 4 * (np.dtype("uint64").alignment > 4)
+        + 8
+        + 8 * (np.dtype("longdouble").alignment > 8)
+    )
+
+
+def partial_dtype_fmt():
+    ld = np.dtype("longdouble")
+    partial_ld_off = partial_ld_offset()
+    partial_size = partial_ld_off + ld.itemsize
+    partial_end_padding = partial_size % np.dtype("uint64").alignment
+    return dt_fmt().format(
+        ld.itemsize, partial_ld_off, partial_size + partial_end_padding
+    )
+
+
+def partial_nested_fmt():
+    ld = np.dtype("longdouble")
+    partial_nested_off = 8 + 8 * (ld.alignment > 8)
+    partial_ld_off = partial_ld_offset()
+    partial_size = partial_ld_off + ld.itemsize
+    partial_end_padding = partial_size % np.dtype("uint64").alignment
+    partial_nested_size = partial_nested_off * 2 + partial_size + partial_end_padding
+    return "{{'names':['a'],'formats':[{}],'offsets':[{}],'itemsize':{}}}".format(
+        partial_dtype_fmt(), partial_nested_off, partial_nested_size
+    )
+
+
+def assert_equal(actual, expected_data, expected_dtype):
+    np.testing.assert_equal(actual, np.array(expected_data, dtype=expected_dtype))
+
+
+def test_format_descriptors():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.get_format_unbound()
+    assert re.match(
+        "^NumPy type info missing for .*UnboundStruct.*$", str(excinfo.value)
+    )
+
+    ld = np.dtype("longdouble")
+    ldbl_fmt = ("4x" if ld.alignment > 4 else "") + ld.char
+    ss_fmt = "^T{?:bool_:3xI:uint_:f:float_:" + ldbl_fmt + ":ldbl_:}"
+    dbl = np.dtype("double")
+    end_padding = ld.itemsize % np.dtype("uint64").alignment
+    partial_fmt = (
+        "^T{?:bool_:3xI:uint_:f:float_:"
+        + str(4 * (dbl.alignment > 4) + dbl.itemsize + 8 * (ld.alignment > 8))
+        + "xg:ldbl_:"
+        + (str(end_padding) + "x}" if end_padding > 0 else "}")
+    )
+    nested_extra = str(max(8, ld.alignment))
+    assert m.print_format_descriptors() == [
+        ss_fmt,
+        "^T{?:bool_:I:uint_:f:float_:g:ldbl_:}",
+        "^T{" + ss_fmt + ":a:^T{?:bool_:I:uint_:f:float_:g:ldbl_:}:b:}",
+        partial_fmt,
+        "^T{" + nested_extra + "x" + partial_fmt + ":a:" + nested_extra + "x}",
+        "^T{3s:a:3s:b:}",
+        "^T{(3)4s:a:(2)i:b:(3)B:c:1x(4, 2)f:d:}",
+        "^T{q:e1:B:e2:}",
+        "^T{Zf:cflt:Zd:cdbl:}",
+    ]
+
+
+def test_dtype(simple_dtype):
+    from sys import byteorder
+
+    e = "<" if byteorder == "little" else ">"
+
+    assert [x.replace(" ", "") for x in m.print_dtypes()] == [
+        simple_dtype_fmt(),
+        packed_dtype_fmt(),
+        f"[('a',{simple_dtype_fmt()}),('b',{packed_dtype_fmt()})]",
+        partial_dtype_fmt(),
+        partial_nested_fmt(),
+        "[('a','S3'),('b','S3')]",
+        (
+            "{'names':['a','b','c','d'],"
+            f"'formats':[('S4',(3,)),('{e}i4',(2,)),('u1',(3,)),('{e}f4',(4,2))],"
+            "'offsets':[0,12,20,24],'itemsize':56}"
+        ),
+        "[('e1','" + e + "i8'),('e2','u1')]",
+        "[('x','i1'),('y','" + e + "u8')]",
+        "[('cflt','" + e + "c8'),('cdbl','" + e + "c16')]",
+    ]
+
+    d1 = np.dtype(
+        {
+            "names": ["a", "b"],
+            "formats": ["int32", "float64"],
+            "offsets": [1, 10],
+            "itemsize": 20,
+        }
+    )
+    d2 = np.dtype([("a", "i4"), ("b", "f4")])
+    assert m.test_dtype_ctors() == [
+        np.dtype("int32"),
+        np.dtype("float64"),
+        np.dtype("bool"),
+        d1,
+        d1,
+        np.dtype("uint32"),
+        d2,
+        np.dtype("d"),
+    ]
+
+    assert m.test_dtype_methods() == [
+        np.dtype("int32"),
+        simple_dtype,
+        False,
+        True,
+        np.dtype("int32").itemsize,
+        simple_dtype.itemsize,
+    ]
+
+    assert m.trailing_padding_dtype() == m.buffer_to_dtype(
+        np.zeros(1, m.trailing_padding_dtype())
+    )
+
+    expected_chars = "bhilqBHILQefdgFDG?MmO"
+    assert m.test_dtype_kind() == list("iiiiiuuuuuffffcccbMmO")
+    assert m.test_dtype_char_() == list(expected_chars)
+    assert m.test_dtype_num() == [np.dtype(ch).num for ch in expected_chars]
+    assert m.test_dtype_byteorder() == [np.dtype(ch).byteorder for ch in expected_chars]
+    assert m.test_dtype_alignment() == [np.dtype(ch).alignment for ch in expected_chars]
+    assert m.test_dtype_flags() == [chr(np.dtype(ch).flags) for ch in expected_chars]
+
+
+def test_recarray(simple_dtype, packed_dtype):
+    elements = [(False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)]
+
+    for func, dtype in [
+        (m.create_rec_simple, simple_dtype),
+        (m.create_rec_packed, packed_dtype),
+    ]:
+        arr = func(0)
+        assert arr.dtype == dtype
+        assert_equal(arr, [], simple_dtype)
+        assert_equal(arr, [], packed_dtype)
+
+        arr = func(3)
+        assert arr.dtype == dtype
+        assert_equal(arr, elements, simple_dtype)
+        assert_equal(arr, elements, packed_dtype)
+
+        # Show what recarray's look like in NumPy.
+        assert type(arr[0]) == np.void
+        assert type(arr[0].item()) == tuple
+
+        if dtype == simple_dtype:
+            assert m.print_rec_simple(arr) == [
+                "s:0,0,0,-0",
+                "s:1,1,1.5,-2.5",
+                "s:0,2,3,-5",
+            ]
+        else:
+            assert m.print_rec_packed(arr) == [
+                "p:0,0,0,-0",
+                "p:1,1,1.5,-2.5",
+                "p:0,2,3,-5",
+            ]
+
+    nested_dtype = np.dtype([("a", simple_dtype), ("b", packed_dtype)])
+
+    arr = m.create_rec_nested(0)
+    assert arr.dtype == nested_dtype
+    assert_equal(arr, [], nested_dtype)
+
+    arr = m.create_rec_nested(3)
+    assert arr.dtype == nested_dtype
+    assert_equal(
+        arr,
+        [
+            ((False, 0, 0.0, -0.0), (True, 1, 1.5, -2.5)),
+            ((True, 1, 1.5, -2.5), (False, 2, 3.0, -5.0)),
+            ((False, 2, 3.0, -5.0), (True, 3, 4.5, -7.5)),
+        ],
+        nested_dtype,
+    )
+    assert m.print_rec_nested(arr) == [
+        "n:a=s:0,0,0,-0;b=p:1,1,1.5,-2.5",
+        "n:a=s:1,1,1.5,-2.5;b=p:0,2,3,-5",
+        "n:a=s:0,2,3,-5;b=p:1,3,4.5,-7.5",
+    ]
+
+    arr = m.create_rec_partial(3)
+    assert str(arr.dtype).replace(" ", "") == partial_dtype_fmt()
+    partial_dtype = arr.dtype
+    assert "" not in arr.dtype.fields
+    assert partial_dtype.itemsize > simple_dtype.itemsize
+    assert_equal(arr, elements, simple_dtype)
+    assert_equal(arr, elements, packed_dtype)
+
+    arr = m.create_rec_partial_nested(3)
+    assert str(arr.dtype).replace(" ", "") == partial_nested_fmt()
+    assert "" not in arr.dtype.fields
+    assert "" not in arr.dtype.fields["a"][0].fields
+    assert arr.dtype.itemsize > partial_dtype.itemsize
+    np.testing.assert_equal(arr["a"], m.create_rec_partial(3))
+
+
+def test_array_constructors():
+    data = np.arange(1, 7, dtype="int32")
+    for i in range(8):
+        np.testing.assert_array_equal(m.test_array_ctors(10 + i), data.reshape((3, 2)))
+        np.testing.assert_array_equal(m.test_array_ctors(20 + i), data.reshape((3, 2)))
+    for i in range(5):
+        np.testing.assert_array_equal(m.test_array_ctors(30 + i), data)
+        np.testing.assert_array_equal(m.test_array_ctors(40 + i), data)
+
+
+def test_string_array():
+    arr = m.create_string_array(True)
+    assert str(arr.dtype) == "[('a', 'S3'), ('b', 'S3')]"
+    assert m.print_string_array(arr) == [
+        "a='',b=''",
+        "a='a',b='a'",
+        "a='ab',b='ab'",
+        "a='abc',b='abc'",
+    ]
+    dtype = arr.dtype
+    assert arr["a"].tolist() == [b"", b"a", b"ab", b"abc"]
+    assert arr["b"].tolist() == [b"", b"a", b"ab", b"abc"]
+    arr = m.create_string_array(False)
+    assert dtype == arr.dtype
+
+
+def test_array_array():
+    from sys import byteorder
+
+    e = "<" if byteorder == "little" else ">"
+
+    arr = m.create_array_array(3)
+    assert str(arr.dtype).replace(" ", "") == (
+        "{'names':['a','b','c','d'],"
+        f"'formats':[('S4',(3,)),('{e}i4',(2,)),('u1',(3,)),('{e}f4',(4,2))],"
+        "'offsets':[0,12,20,24],'itemsize':56}"
+    )
+    assert m.print_array_array(arr) == [
+        "a={{A,B,C,D},{K,L,M,N},{U,V,W,X}},b={0,1},"
+        "c={0,1,2},d={{0,1},{10,11},{20,21},{30,31}}",
+        "a={{W,X,Y,Z},{G,H,I,J},{Q,R,S,T}},b={1000,1001},"
+        "c={10,11,12},d={{100,101},{110,111},{120,121},{130,131}}",
+        "a={{S,T,U,V},{C,D,E,F},{M,N,O,P}},b={2000,2001},"
+        "c={20,21,22},d={{200,201},{210,211},{220,221},{230,231}}",
+    ]
+    assert arr["a"].tolist() == [
+        [b"ABCD", b"KLMN", b"UVWX"],
+        [b"WXYZ", b"GHIJ", b"QRST"],
+        [b"STUV", b"CDEF", b"MNOP"],
+    ]
+    assert arr["b"].tolist() == [[0, 1], [1000, 1001], [2000, 2001]]
+    assert m.create_array_array(0).dtype == arr.dtype
+
+
+def test_enum_array():
+    from sys import byteorder
+
+    e = "<" if byteorder == "little" else ">"
+
+    arr = m.create_enum_array(3)
+    dtype = arr.dtype
+    assert dtype == np.dtype([("e1", e + "i8"), ("e2", "u1")])
+    assert m.print_enum_array(arr) == ["e1=A,e2=X", "e1=B,e2=Y", "e1=A,e2=X"]
+    assert arr["e1"].tolist() == [-1, 1, -1]
+    assert arr["e2"].tolist() == [1, 2, 1]
+    assert m.create_enum_array(0).dtype == dtype
+
+
+def test_complex_array():
+    from sys import byteorder
+
+    e = "<" if byteorder == "little" else ">"
+
+    arr = m.create_complex_array(3)
+    dtype = arr.dtype
+    assert dtype == np.dtype([("cflt", e + "c8"), ("cdbl", e + "c16")])
+    assert m.print_complex_array(arr) == [
+        "c:(0,0.25),(0.5,0.75)",
+        "c:(1,1.25),(1.5,1.75)",
+        "c:(2,2.25),(2.5,2.75)",
+    ]
+    assert arr["cflt"].tolist() == [0.0 + 0.25j, 1.0 + 1.25j, 2.0 + 2.25j]
+    assert arr["cdbl"].tolist() == [0.5 + 0.75j, 1.5 + 1.75j, 2.5 + 2.75j]
+    assert m.create_complex_array(0).dtype == dtype
+
+
+def test_signature(doc):
+    assert (
+        doc(m.create_rec_nested)
+        == "create_rec_nested(arg0: int) -> numpy.ndarray[NestedStruct]"
+    )
+
+
+def test_scalar_conversion():
+    n = 3
+    arrays = [
+        m.create_rec_simple(n),
+        m.create_rec_packed(n),
+        m.create_rec_nested(n),
+        m.create_enum_array(n),
+    ]
+    funcs = [m.f_simple, m.f_packed, m.f_nested]
+
+    for i, func in enumerate(funcs):
+        for j, arr in enumerate(arrays):
+            if i == j and i < 2:
+                assert [func(arr[k]) for k in range(n)] == [k * 10 for k in range(n)]
+            else:
+                with pytest.raises(TypeError) as excinfo:
+                    func(arr[0])
+                assert "incompatible function arguments" in str(excinfo.value)
+
+
+def test_vectorize():
+    n = 3
+    array = m.create_rec_simple(n)
+    values = m.f_simple_vectorized(array)
+    np.testing.assert_array_equal(values, [0, 10, 20])
+    array_2 = m.f_simple_pass_thru_vectorized(array)
+    np.testing.assert_array_equal(array, array_2)
+
+
+def test_cls_and_dtype_conversion(simple_dtype):
+    s = m.SimpleStruct()
+    assert s.astuple() == (False, 0, 0.0, 0.0)
+    assert m.SimpleStruct.fromtuple(s.astuple()).astuple() == s.astuple()
+
+    s.uint_ = 2
+    assert m.f_simple(s) == 20
+
+    # Try as recarray of shape==(1,).
+    s_recarray = np.array([(False, 2, 0.0, 0.0)], dtype=simple_dtype)
+    # Show that this will work for vectorized case.
+    np.testing.assert_array_equal(m.f_simple_vectorized(s_recarray), [20])
+
+    # Show as a scalar that inherits from np.generic.
+    s_scalar = s_recarray[0]
+    assert isinstance(s_scalar, np.void)
+    assert m.f_simple(s_scalar) == 20
+
+    # Show that an *array* scalar (np.ndarray.shape == ()) does not convert.
+    # More specifically, conversion to SimpleStruct is not implicit.
+    s_recarray_scalar = s_recarray.reshape(())
+    assert isinstance(s_recarray_scalar, np.ndarray)
+    assert s_recarray_scalar.dtype == simple_dtype
+    with pytest.raises(TypeError) as excinfo:
+        m.f_simple(s_recarray_scalar)
+    assert "incompatible function arguments" in str(excinfo.value)
+    # Explicitly convert to m.SimpleStruct.
+    assert m.f_simple(m.SimpleStruct.fromtuple(s_recarray_scalar.item())) == 20
+
+    # Show that an array of dtype=object does *not* convert.
+    s_array_object = np.array([s])
+    assert s_array_object.dtype == object
+    with pytest.raises(TypeError) as excinfo:
+        m.f_simple_vectorized(s_array_object)
+    assert "incompatible function arguments" in str(excinfo.value)
+    # Explicitly convert to `np.array(..., dtype=simple_dtype)`
+    s_array = np.array([s.astuple()], dtype=simple_dtype)
+    np.testing.assert_array_equal(m.f_simple_vectorized(s_array), [20])
+
+
+def test_register_dtype():
+    with pytest.raises(RuntimeError) as excinfo:
+        m.register_dtype()
+    assert "dtype is already registered" in str(excinfo.value)
+
+
+@pytest.mark.xfail("env.PYPY")
+def test_str_leak():
+    from sys import getrefcount
+
+    fmt = "f4"
+    pytest.gc_collect()
+    start = getrefcount(fmt)
+    d = m.dtype_wrapper(fmt)
+    assert d is np.dtype("f4")
+    del d
+    pytest.gc_collect()
+    assert getrefcount(fmt) == start
+
+
+def test_compare_buffer_info():
+    assert all(m.compare_buffer_info())
```

## extern/pybind11/tests/test_numpy_vectorize.py

 * *Ordering differences only*

```diff
@@ -1,266 +1,266 @@
-import pytest
-
-from pybind11_tests import numpy_vectorize as m
-
-np = pytest.importorskip("numpy")
-
-
-def test_vectorize(capture):
-    assert np.isclose(m.vectorized_func3(np.array(3 + 7j)), [6 + 14j])
-
-    for f in [m.vectorized_func, m.vectorized_func2]:
-        with capture:
-            assert np.isclose(f(1, 2, 3), 6)
-        assert capture == "my_func(x:int=1, y:float=2, z:float=3)"
-        with capture:
-            assert np.isclose(f(np.array(1), np.array(2), 3), 6)
-        assert capture == "my_func(x:int=1, y:float=2, z:float=3)"
-        with capture:
-            assert np.allclose(f(np.array([1, 3]), np.array([2, 4]), 3), [6, 36])
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=2, z:float=3)
-            my_func(x:int=3, y:float=4, z:float=3)
-        """
-        )
-        with capture:
-            a = np.array([[1, 2], [3, 4]], order="F")
-            b = np.array([[10, 20], [30, 40]], order="F")
-            c = 3
-            result = f(a, b, c)
-            assert np.allclose(result, a * b * c)
-            assert result.flags.f_contiguous
-        # All inputs are F order and full or singletons, so we the result is in col-major order:
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=10, z:float=3)
-            my_func(x:int=3, y:float=30, z:float=3)
-            my_func(x:int=2, y:float=20, z:float=3)
-            my_func(x:int=4, y:float=40, z:float=3)
-        """
-        )
-        with capture:
-            a, b, c = (
-                np.array([[1, 3, 5], [7, 9, 11]]),
-                np.array([[2, 4, 6], [8, 10, 12]]),
-                3,
-            )
-            assert np.allclose(f(a, b, c), a * b * c)
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=2, z:float=3)
-            my_func(x:int=3, y:float=4, z:float=3)
-            my_func(x:int=5, y:float=6, z:float=3)
-            my_func(x:int=7, y:float=8, z:float=3)
-            my_func(x:int=9, y:float=10, z:float=3)
-            my_func(x:int=11, y:float=12, z:float=3)
-        """
-        )
-        with capture:
-            a, b, c = np.array([[1, 2, 3], [4, 5, 6]]), np.array([2, 3, 4]), 2
-            assert np.allclose(f(a, b, c), a * b * c)
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=2, z:float=2)
-            my_func(x:int=2, y:float=3, z:float=2)
-            my_func(x:int=3, y:float=4, z:float=2)
-            my_func(x:int=4, y:float=2, z:float=2)
-            my_func(x:int=5, y:float=3, z:float=2)
-            my_func(x:int=6, y:float=4, z:float=2)
-        """
-        )
-        with capture:
-            a, b, c = np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), 2
-            assert np.allclose(f(a, b, c), a * b * c)
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=2, z:float=2)
-            my_func(x:int=2, y:float=2, z:float=2)
-            my_func(x:int=3, y:float=2, z:float=2)
-            my_func(x:int=4, y:float=3, z:float=2)
-            my_func(x:int=5, y:float=3, z:float=2)
-            my_func(x:int=6, y:float=3, z:float=2)
-        """
-        )
-        with capture:
-            a, b, c = (
-                np.array([[1, 2, 3], [4, 5, 6]], order="F"),
-                np.array([[2], [3]]),
-                2,
-            )
-            assert np.allclose(f(a, b, c), a * b * c)
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=2, z:float=2)
-            my_func(x:int=2, y:float=2, z:float=2)
-            my_func(x:int=3, y:float=2, z:float=2)
-            my_func(x:int=4, y:float=3, z:float=2)
-            my_func(x:int=5, y:float=3, z:float=2)
-            my_func(x:int=6, y:float=3, z:float=2)
-        """
-        )
-        with capture:
-            a, b, c = np.array([[1, 2, 3], [4, 5, 6]])[::, ::2], np.array([[2], [3]]), 2
-            assert np.allclose(f(a, b, c), a * b * c)
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=2, z:float=2)
-            my_func(x:int=3, y:float=2, z:float=2)
-            my_func(x:int=4, y:float=3, z:float=2)
-            my_func(x:int=6, y:float=3, z:float=2)
-        """
-        )
-        with capture:
-            a, b, c = (
-                np.array([[1, 2, 3], [4, 5, 6]], order="F")[::, ::2],
-                np.array([[2], [3]]),
-                2,
-            )
-            assert np.allclose(f(a, b, c), a * b * c)
-        assert (
-            capture
-            == """
-            my_func(x:int=1, y:float=2, z:float=2)
-            my_func(x:int=3, y:float=2, z:float=2)
-            my_func(x:int=4, y:float=3, z:float=2)
-            my_func(x:int=6, y:float=3, z:float=2)
-        """
-        )
-
-
-def test_type_selection():
-    assert m.selective_func(np.array([1], dtype=np.int32)) == "Int branch taken."
-    assert m.selective_func(np.array([1.0], dtype=np.float32)) == "Float branch taken."
-    assert (
-        m.selective_func(np.array([1.0j], dtype=np.complex64))
-        == "Complex float branch taken."
-    )
-
-
-def test_docs(doc):
-    assert (
-        doc(m.vectorized_func)
-        == """
-        vectorized_func(arg0: numpy.ndarray[numpy.int32], arg1: numpy.ndarray[numpy.float32], arg2: numpy.ndarray[numpy.float64]) -> object
-    """
-    )
-
-
-def test_trivial_broadcasting():
-    trivial, vectorized_is_trivial = m.trivial, m.vectorized_is_trivial
-
-    assert vectorized_is_trivial(1, 2, 3) == trivial.c_trivial
-    assert vectorized_is_trivial(np.array(1), np.array(2), 3) == trivial.c_trivial
-    assert (
-        vectorized_is_trivial(np.array([1, 3]), np.array([2, 4]), 3)
-        == trivial.c_trivial
-    )
-    assert trivial.c_trivial == vectorized_is_trivial(
-        np.array([[1, 3, 5], [7, 9, 11]]), np.array([[2, 4, 6], [8, 10, 12]]), 3
-    )
-    assert (
-        vectorized_is_trivial(np.array([[1, 2, 3], [4, 5, 6]]), np.array([2, 3, 4]), 2)
-        == trivial.non_trivial
-    )
-    assert (
-        vectorized_is_trivial(np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), 2)
-        == trivial.non_trivial
-    )
-    z1 = np.array([[1, 2, 3, 4], [5, 6, 7, 8]], dtype="int32")
-    z2 = np.array(z1, dtype="float32")
-    z3 = np.array(z1, dtype="float64")
-    assert vectorized_is_trivial(z1, z2, z3) == trivial.c_trivial
-    assert vectorized_is_trivial(1, z2, z3) == trivial.c_trivial
-    assert vectorized_is_trivial(z1, 1, z3) == trivial.c_trivial
-    assert vectorized_is_trivial(z1, z2, 1) == trivial.c_trivial
-    assert vectorized_is_trivial(z1[::2, ::2], 1, 1) == trivial.non_trivial
-    assert vectorized_is_trivial(1, 1, z1[::2, ::2]) == trivial.c_trivial
-    assert vectorized_is_trivial(1, 1, z3[::2, ::2]) == trivial.non_trivial
-    assert vectorized_is_trivial(z1, 1, z3[1::4, 1::4]) == trivial.c_trivial
-
-    y1 = np.array(z1, order="F")
-    y2 = np.array(y1)
-    y3 = np.array(y1)
-    assert vectorized_is_trivial(y1, y2, y3) == trivial.f_trivial
-    assert vectorized_is_trivial(y1, 1, 1) == trivial.f_trivial
-    assert vectorized_is_trivial(1, y2, 1) == trivial.f_trivial
-    assert vectorized_is_trivial(1, 1, y3) == trivial.f_trivial
-    assert vectorized_is_trivial(y1, z2, 1) == trivial.non_trivial
-    assert vectorized_is_trivial(z1[1::4, 1::4], y2, 1) == trivial.f_trivial
-    assert vectorized_is_trivial(y1[1::4, 1::4], z2, 1) == trivial.c_trivial
-
-    assert m.vectorized_func(z1, z2, z3).flags.c_contiguous
-    assert m.vectorized_func(y1, y2, y3).flags.f_contiguous
-    assert m.vectorized_func(z1, 1, 1).flags.c_contiguous
-    assert m.vectorized_func(1, y2, 1).flags.f_contiguous
-    assert m.vectorized_func(z1[1::4, 1::4], y2, 1).flags.f_contiguous
-    assert m.vectorized_func(y1[1::4, 1::4], z2, 1).flags.c_contiguous
-
-
-def test_passthrough_arguments(doc):
-    assert doc(m.vec_passthrough) == (
-        "vec_passthrough("
-        + ", ".join(
-            [
-                "arg0: float",
-                "arg1: numpy.ndarray[numpy.float64]",
-                "arg2: numpy.ndarray[numpy.float64]",
-                "arg3: numpy.ndarray[numpy.int32]",
-                "arg4: int",
-                "arg5: m.numpy_vectorize.NonPODClass",
-                "arg6: numpy.ndarray[numpy.float64]",
-            ]
-        )
-        + ") -> object"
-    )
-
-    b = np.array([[10, 20, 30]], dtype="float64")
-    c = np.array([100, 200])  # NOT a vectorized argument
-    d = np.array([[1000], [2000], [3000]], dtype="int")
-    g = np.array([[1000000, 2000000, 3000000]], dtype="int")  # requires casting
-    assert np.all(
-        m.vec_passthrough(1, b, c, d, 10000, m.NonPODClass(100000), g)
-        == np.array(
-            [
-                [1111111, 2111121, 3111131],
-                [1112111, 2112121, 3112131],
-                [1113111, 2113121, 3113131],
-            ]
-        )
-    )
-
-
-def test_method_vectorization():
-    o = m.VectorizeTestClass(3)
-    x = np.array([1, 2], dtype="int")
-    y = np.array([[10], [20]], dtype="float32")
-    assert np.all(o.method(x, y) == [[14, 15], [24, 25]])
-
-
-def test_array_collapse():
-    assert not isinstance(m.vectorized_func(1, 2, 3), np.ndarray)
-    assert not isinstance(m.vectorized_func(np.array(1), 2, 3), np.ndarray)
-    z = m.vectorized_func([1], 2, 3)
-    assert isinstance(z, np.ndarray)
-    assert z.shape == (1,)
-    z = m.vectorized_func(1, [[[2]]], 3)
-    assert isinstance(z, np.ndarray)
-    assert z.shape == (1, 1, 1)
-
-
-def test_vectorized_noreturn():
-    x = m.NonPODClass(0)
-    assert x.value == 0
-    m.add_to(x, [1, 2, 3, 4])
-    assert x.value == 10
-    m.add_to(x, 1)
-    assert x.value == 11
-    m.add_to(x, [[1, 1], [2, 3]])
-    assert x.value == 18
+import pytest
+
+from pybind11_tests import numpy_vectorize as m
+
+np = pytest.importorskip("numpy")
+
+
+def test_vectorize(capture):
+    assert np.isclose(m.vectorized_func3(np.array(3 + 7j)), [6 + 14j])
+
+    for f in [m.vectorized_func, m.vectorized_func2]:
+        with capture:
+            assert np.isclose(f(1, 2, 3), 6)
+        assert capture == "my_func(x:int=1, y:float=2, z:float=3)"
+        with capture:
+            assert np.isclose(f(np.array(1), np.array(2), 3), 6)
+        assert capture == "my_func(x:int=1, y:float=2, z:float=3)"
+        with capture:
+            assert np.allclose(f(np.array([1, 3]), np.array([2, 4]), 3), [6, 36])
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=2, z:float=3)
+            my_func(x:int=3, y:float=4, z:float=3)
+        """
+        )
+        with capture:
+            a = np.array([[1, 2], [3, 4]], order="F")
+            b = np.array([[10, 20], [30, 40]], order="F")
+            c = 3
+            result = f(a, b, c)
+            assert np.allclose(result, a * b * c)
+            assert result.flags.f_contiguous
+        # All inputs are F order and full or singletons, so we the result is in col-major order:
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=10, z:float=3)
+            my_func(x:int=3, y:float=30, z:float=3)
+            my_func(x:int=2, y:float=20, z:float=3)
+            my_func(x:int=4, y:float=40, z:float=3)
+        """
+        )
+        with capture:
+            a, b, c = (
+                np.array([[1, 3, 5], [7, 9, 11]]),
+                np.array([[2, 4, 6], [8, 10, 12]]),
+                3,
+            )
+            assert np.allclose(f(a, b, c), a * b * c)
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=2, z:float=3)
+            my_func(x:int=3, y:float=4, z:float=3)
+            my_func(x:int=5, y:float=6, z:float=3)
+            my_func(x:int=7, y:float=8, z:float=3)
+            my_func(x:int=9, y:float=10, z:float=3)
+            my_func(x:int=11, y:float=12, z:float=3)
+        """
+        )
+        with capture:
+            a, b, c = np.array([[1, 2, 3], [4, 5, 6]]), np.array([2, 3, 4]), 2
+            assert np.allclose(f(a, b, c), a * b * c)
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=2, z:float=2)
+            my_func(x:int=2, y:float=3, z:float=2)
+            my_func(x:int=3, y:float=4, z:float=2)
+            my_func(x:int=4, y:float=2, z:float=2)
+            my_func(x:int=5, y:float=3, z:float=2)
+            my_func(x:int=6, y:float=4, z:float=2)
+        """
+        )
+        with capture:
+            a, b, c = np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), 2
+            assert np.allclose(f(a, b, c), a * b * c)
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=2, z:float=2)
+            my_func(x:int=2, y:float=2, z:float=2)
+            my_func(x:int=3, y:float=2, z:float=2)
+            my_func(x:int=4, y:float=3, z:float=2)
+            my_func(x:int=5, y:float=3, z:float=2)
+            my_func(x:int=6, y:float=3, z:float=2)
+        """
+        )
+        with capture:
+            a, b, c = (
+                np.array([[1, 2, 3], [4, 5, 6]], order="F"),
+                np.array([[2], [3]]),
+                2,
+            )
+            assert np.allclose(f(a, b, c), a * b * c)
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=2, z:float=2)
+            my_func(x:int=2, y:float=2, z:float=2)
+            my_func(x:int=3, y:float=2, z:float=2)
+            my_func(x:int=4, y:float=3, z:float=2)
+            my_func(x:int=5, y:float=3, z:float=2)
+            my_func(x:int=6, y:float=3, z:float=2)
+        """
+        )
+        with capture:
+            a, b, c = np.array([[1, 2, 3], [4, 5, 6]])[::, ::2], np.array([[2], [3]]), 2
+            assert np.allclose(f(a, b, c), a * b * c)
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=2, z:float=2)
+            my_func(x:int=3, y:float=2, z:float=2)
+            my_func(x:int=4, y:float=3, z:float=2)
+            my_func(x:int=6, y:float=3, z:float=2)
+        """
+        )
+        with capture:
+            a, b, c = (
+                np.array([[1, 2, 3], [4, 5, 6]], order="F")[::, ::2],
+                np.array([[2], [3]]),
+                2,
+            )
+            assert np.allclose(f(a, b, c), a * b * c)
+        assert (
+            capture
+            == """
+            my_func(x:int=1, y:float=2, z:float=2)
+            my_func(x:int=3, y:float=2, z:float=2)
+            my_func(x:int=4, y:float=3, z:float=2)
+            my_func(x:int=6, y:float=3, z:float=2)
+        """
+        )
+
+
+def test_type_selection():
+    assert m.selective_func(np.array([1], dtype=np.int32)) == "Int branch taken."
+    assert m.selective_func(np.array([1.0], dtype=np.float32)) == "Float branch taken."
+    assert (
+        m.selective_func(np.array([1.0j], dtype=np.complex64))
+        == "Complex float branch taken."
+    )
+
+
+def test_docs(doc):
+    assert (
+        doc(m.vectorized_func)
+        == """
+        vectorized_func(arg0: numpy.ndarray[numpy.int32], arg1: numpy.ndarray[numpy.float32], arg2: numpy.ndarray[numpy.float64]) -> object
+    """
+    )
+
+
+def test_trivial_broadcasting():
+    trivial, vectorized_is_trivial = m.trivial, m.vectorized_is_trivial
+
+    assert vectorized_is_trivial(1, 2, 3) == trivial.c_trivial
+    assert vectorized_is_trivial(np.array(1), np.array(2), 3) == trivial.c_trivial
+    assert (
+        vectorized_is_trivial(np.array([1, 3]), np.array([2, 4]), 3)
+        == trivial.c_trivial
+    )
+    assert trivial.c_trivial == vectorized_is_trivial(
+        np.array([[1, 3, 5], [7, 9, 11]]), np.array([[2, 4, 6], [8, 10, 12]]), 3
+    )
+    assert (
+        vectorized_is_trivial(np.array([[1, 2, 3], [4, 5, 6]]), np.array([2, 3, 4]), 2)
+        == trivial.non_trivial
+    )
+    assert (
+        vectorized_is_trivial(np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), 2)
+        == trivial.non_trivial
+    )
+    z1 = np.array([[1, 2, 3, 4], [5, 6, 7, 8]], dtype="int32")
+    z2 = np.array(z1, dtype="float32")
+    z3 = np.array(z1, dtype="float64")
+    assert vectorized_is_trivial(z1, z2, z3) == trivial.c_trivial
+    assert vectorized_is_trivial(1, z2, z3) == trivial.c_trivial
+    assert vectorized_is_trivial(z1, 1, z3) == trivial.c_trivial
+    assert vectorized_is_trivial(z1, z2, 1) == trivial.c_trivial
+    assert vectorized_is_trivial(z1[::2, ::2], 1, 1) == trivial.non_trivial
+    assert vectorized_is_trivial(1, 1, z1[::2, ::2]) == trivial.c_trivial
+    assert vectorized_is_trivial(1, 1, z3[::2, ::2]) == trivial.non_trivial
+    assert vectorized_is_trivial(z1, 1, z3[1::4, 1::4]) == trivial.c_trivial
+
+    y1 = np.array(z1, order="F")
+    y2 = np.array(y1)
+    y3 = np.array(y1)
+    assert vectorized_is_trivial(y1, y2, y3) == trivial.f_trivial
+    assert vectorized_is_trivial(y1, 1, 1) == trivial.f_trivial
+    assert vectorized_is_trivial(1, y2, 1) == trivial.f_trivial
+    assert vectorized_is_trivial(1, 1, y3) == trivial.f_trivial
+    assert vectorized_is_trivial(y1, z2, 1) == trivial.non_trivial
+    assert vectorized_is_trivial(z1[1::4, 1::4], y2, 1) == trivial.f_trivial
+    assert vectorized_is_trivial(y1[1::4, 1::4], z2, 1) == trivial.c_trivial
+
+    assert m.vectorized_func(z1, z2, z3).flags.c_contiguous
+    assert m.vectorized_func(y1, y2, y3).flags.f_contiguous
+    assert m.vectorized_func(z1, 1, 1).flags.c_contiguous
+    assert m.vectorized_func(1, y2, 1).flags.f_contiguous
+    assert m.vectorized_func(z1[1::4, 1::4], y2, 1).flags.f_contiguous
+    assert m.vectorized_func(y1[1::4, 1::4], z2, 1).flags.c_contiguous
+
+
+def test_passthrough_arguments(doc):
+    assert doc(m.vec_passthrough) == (
+        "vec_passthrough("
+        + ", ".join(
+            [
+                "arg0: float",
+                "arg1: numpy.ndarray[numpy.float64]",
+                "arg2: numpy.ndarray[numpy.float64]",
+                "arg3: numpy.ndarray[numpy.int32]",
+                "arg4: int",
+                "arg5: m.numpy_vectorize.NonPODClass",
+                "arg6: numpy.ndarray[numpy.float64]",
+            ]
+        )
+        + ") -> object"
+    )
+
+    b = np.array([[10, 20, 30]], dtype="float64")
+    c = np.array([100, 200])  # NOT a vectorized argument
+    d = np.array([[1000], [2000], [3000]], dtype="int")
+    g = np.array([[1000000, 2000000, 3000000]], dtype="int")  # requires casting
+    assert np.all(
+        m.vec_passthrough(1, b, c, d, 10000, m.NonPODClass(100000), g)
+        == np.array(
+            [
+                [1111111, 2111121, 3111131],
+                [1112111, 2112121, 3112131],
+                [1113111, 2113121, 3113131],
+            ]
+        )
+    )
+
+
+def test_method_vectorization():
+    o = m.VectorizeTestClass(3)
+    x = np.array([1, 2], dtype="int")
+    y = np.array([[10], [20]], dtype="float32")
+    assert np.all(o.method(x, y) == [[14, 15], [24, 25]])
+
+
+def test_array_collapse():
+    assert not isinstance(m.vectorized_func(1, 2, 3), np.ndarray)
+    assert not isinstance(m.vectorized_func(np.array(1), 2, 3), np.ndarray)
+    z = m.vectorized_func([1], 2, 3)
+    assert isinstance(z, np.ndarray)
+    assert z.shape == (1,)
+    z = m.vectorized_func(1, [[[2]]], 3)
+    assert isinstance(z, np.ndarray)
+    assert z.shape == (1, 1, 1)
+
+
+def test_vectorized_noreturn():
+    x = m.NonPODClass(0)
+    assert x.value == 0
+    m.add_to(x, [1, 2, 3, 4])
+    assert x.value == 10
+    m.add_to(x, 1)
+    assert x.value == 11
+    m.add_to(x, [[1, 1], [2, 3]])
+    assert x.value == 18
```

## extern/pybind11/tests/test_opaque_types.py

 * *Ordering differences only*

```diff
@@ -1,58 +1,58 @@
-import pytest
-
-from pybind11_tests import ConstructorStats, UserType
-from pybind11_tests import opaque_types as m
-
-
-def test_string_list():
-    lst = m.StringList()
-    lst.push_back("Element 1")
-    lst.push_back("Element 2")
-    assert m.print_opaque_list(lst) == "Opaque list: [Element 1, Element 2]"
-    assert lst.back() == "Element 2"
-
-    for i, k in enumerate(lst, start=1):
-        assert k == f"Element {i}"
-    lst.pop_back()
-    assert m.print_opaque_list(lst) == "Opaque list: [Element 1]"
-
-    cvp = m.ClassWithSTLVecProperty()
-    assert m.print_opaque_list(cvp.stringList) == "Opaque list: []"
-
-    cvp.stringList = lst
-    cvp.stringList.push_back("Element 3")
-    assert m.print_opaque_list(cvp.stringList) == "Opaque list: [Element 1, Element 3]"
-
-
-def test_pointers(msg):
-    living_before = ConstructorStats.get(UserType).alive()
-    assert m.get_void_ptr_value(m.return_void_ptr()) == 0x1234
-    assert m.get_void_ptr_value(UserType())  # Should also work for other C++ types
-    assert ConstructorStats.get(UserType).alive() == living_before
-
-    with pytest.raises(TypeError) as excinfo:
-        m.get_void_ptr_value([1, 2, 3])  # This should not work
-    assert (
-        msg(excinfo.value)
-        == """
-        get_void_ptr_value(): incompatible function arguments. The following argument types are supported:
-            1. (arg0: capsule) -> int
-
-        Invoked with: [1, 2, 3]
-    """
-    )
-
-    assert m.return_null_str() is None
-    assert m.get_null_str_value(m.return_null_str()) is not None
-
-    ptr = m.return_unique_ptr()
-    assert "StringList" in repr(ptr)
-    assert m.print_opaque_list(ptr) == "Opaque list: [some value]"
-
-
-def test_unions():
-    int_float_union = m.IntFloat()
-    int_float_union.i = 42
-    assert int_float_union.i == 42
-    int_float_union.f = 3.0
-    assert int_float_union.f == 3.0
+import pytest
+
+from pybind11_tests import ConstructorStats, UserType
+from pybind11_tests import opaque_types as m
+
+
+def test_string_list():
+    lst = m.StringList()
+    lst.push_back("Element 1")
+    lst.push_back("Element 2")
+    assert m.print_opaque_list(lst) == "Opaque list: [Element 1, Element 2]"
+    assert lst.back() == "Element 2"
+
+    for i, k in enumerate(lst, start=1):
+        assert k == f"Element {i}"
+    lst.pop_back()
+    assert m.print_opaque_list(lst) == "Opaque list: [Element 1]"
+
+    cvp = m.ClassWithSTLVecProperty()
+    assert m.print_opaque_list(cvp.stringList) == "Opaque list: []"
+
+    cvp.stringList = lst
+    cvp.stringList.push_back("Element 3")
+    assert m.print_opaque_list(cvp.stringList) == "Opaque list: [Element 1, Element 3]"
+
+
+def test_pointers(msg):
+    living_before = ConstructorStats.get(UserType).alive()
+    assert m.get_void_ptr_value(m.return_void_ptr()) == 0x1234
+    assert m.get_void_ptr_value(UserType())  # Should also work for other C++ types
+    assert ConstructorStats.get(UserType).alive() == living_before
+
+    with pytest.raises(TypeError) as excinfo:
+        m.get_void_ptr_value([1, 2, 3])  # This should not work
+    assert (
+        msg(excinfo.value)
+        == """
+        get_void_ptr_value(): incompatible function arguments. The following argument types are supported:
+            1. (arg0: capsule) -> int
+
+        Invoked with: [1, 2, 3]
+    """
+    )
+
+    assert m.return_null_str() is None
+    assert m.get_null_str_value(m.return_null_str()) is not None
+
+    ptr = m.return_unique_ptr()
+    assert "StringList" in repr(ptr)
+    assert m.print_opaque_list(ptr) == "Opaque list: [some value]"
+
+
+def test_unions():
+    int_float_union = m.IntFloat()
+    int_float_union.i = 42
+    assert int_float_union.i == 42
+    int_float_union.f = 3.0
+    assert int_float_union.f == 3.0
```

## extern/pybind11/tests/test_operator_overloading.py

 * *Ordering differences only*

```diff
@@ -1,151 +1,151 @@
-import pytest
-
-from pybind11_tests import ConstructorStats
-from pybind11_tests import operators as m
-
-
-def test_operator_overloading():
-    v1 = m.Vector2(1, 2)
-    v2 = m.Vector(3, -1)
-    v3 = m.Vector2(1, 2)  # Same value as v1, but different instance.
-    assert v1 is not v3
-
-    assert str(v1) == "[1.000000, 2.000000]"
-    assert str(v2) == "[3.000000, -1.000000]"
-
-    assert str(-v2) == "[-3.000000, 1.000000]"
-
-    assert str(v1 + v2) == "[4.000000, 1.000000]"
-    assert str(v1 - v2) == "[-2.000000, 3.000000]"
-    assert str(v1 - 8) == "[-7.000000, -6.000000]"
-    assert str(v1 + 8) == "[9.000000, 10.000000]"
-    assert str(v1 * 8) == "[8.000000, 16.000000]"
-    assert str(v1 / 8) == "[0.125000, 0.250000]"
-    assert str(8 - v1) == "[7.000000, 6.000000]"
-    assert str(8 + v1) == "[9.000000, 10.000000]"
-    assert str(8 * v1) == "[8.000000, 16.000000]"
-    assert str(8 / v1) == "[8.000000, 4.000000]"
-    assert str(v1 * v2) == "[3.000000, -2.000000]"
-    assert str(v2 / v1) == "[3.000000, -0.500000]"
-
-    assert v1 == v3
-    assert v1 != v2
-    assert hash(v1) == 4
-    # TODO(eric.cousineau): Make this work.
-    # assert abs(v1) == "abs(Vector2)"
-
-    v1 += 2 * v2
-    assert str(v1) == "[7.000000, 0.000000]"
-    v1 -= v2
-    assert str(v1) == "[4.000000, 1.000000]"
-    v1 *= 2
-    assert str(v1) == "[8.000000, 2.000000]"
-    v1 /= 16
-    assert str(v1) == "[0.500000, 0.125000]"
-    v1 *= v2
-    assert str(v1) == "[1.500000, -0.125000]"
-    v2 /= v1
-    assert str(v2) == "[2.000000, 8.000000]"
-
-    cstats = ConstructorStats.get(m.Vector2)
-    assert cstats.alive() == 3
-    del v1
-    assert cstats.alive() == 2
-    del v2
-    assert cstats.alive() == 1
-    del v3
-    assert cstats.alive() == 0
-    assert cstats.values() == [
-        "[1.000000, 2.000000]",
-        "[3.000000, -1.000000]",
-        "[1.000000, 2.000000]",
-        "[-3.000000, 1.000000]",
-        "[4.000000, 1.000000]",
-        "[-2.000000, 3.000000]",
-        "[-7.000000, -6.000000]",
-        "[9.000000, 10.000000]",
-        "[8.000000, 16.000000]",
-        "[0.125000, 0.250000]",
-        "[7.000000, 6.000000]",
-        "[9.000000, 10.000000]",
-        "[8.000000, 16.000000]",
-        "[8.000000, 4.000000]",
-        "[3.000000, -2.000000]",
-        "[3.000000, -0.500000]",
-        "[6.000000, -2.000000]",
-    ]
-    assert cstats.default_constructions == 0
-    assert cstats.copy_constructions == 0
-    assert cstats.move_constructions >= 10
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-
-def test_operators_notimplemented():
-    """#393: need to return NotSupported to ensure correct arithmetic operator behavior"""
-
-    c1, c2 = m.C1(), m.C2()
-    assert c1 + c1 == 11
-    assert c2 + c2 == 22
-    assert c2 + c1 == 21
-    assert c1 + c2 == 12
-
-
-def test_nested():
-    """#328: first member in a class can't be used in operators"""
-
-    a = m.NestA()
-    b = m.NestB()
-    c = m.NestC()
-
-    a += 10
-    assert m.get_NestA(a) == 13
-    b.a += 100
-    assert m.get_NestA(b.a) == 103
-    c.b.a += 1000
-    assert m.get_NestA(c.b.a) == 1003
-    b -= 1
-    assert m.get_NestB(b) == 3
-    c.b -= 3
-    assert m.get_NestB(c.b) == 1
-    c *= 7
-    assert m.get_NestC(c) == 35
-
-    abase = a.as_base()
-    assert abase.value == -2
-    a.as_base().value += 44
-    assert abase.value == 42
-    assert c.b.a.as_base().value == -2
-    c.b.a.as_base().value += 44
-    assert c.b.a.as_base().value == 42
-
-    del c
-    pytest.gc_collect()
-    del a  # Shouldn't delete while abase is still alive
-    pytest.gc_collect()
-
-    assert abase.value == 42
-    del abase, b
-    pytest.gc_collect()
-
-
-def test_overriding_eq_reset_hash():
-    assert m.Comparable(15) is not m.Comparable(15)
-    assert m.Comparable(15) == m.Comparable(15)
-
-    with pytest.raises(TypeError) as excinfo:
-        hash(m.Comparable(15))
-    assert str(excinfo.value).startswith("unhashable type:")
-
-    for hashable in (m.Hashable, m.Hashable2):
-        assert hashable(15) is not hashable(15)
-        assert hashable(15) == hashable(15)
-
-        assert hash(hashable(15)) == 15
-        assert hash(hashable(15)) == hash(hashable(15))
-
-
-def test_return_set_of_unhashable():
-    with pytest.raises(TypeError) as excinfo:
-        m.get_unhashable_HashMe_set()
-    assert str(excinfo.value.__cause__).startswith("unhashable type:")
+import pytest
+
+from pybind11_tests import ConstructorStats
+from pybind11_tests import operators as m
+
+
+def test_operator_overloading():
+    v1 = m.Vector2(1, 2)
+    v2 = m.Vector(3, -1)
+    v3 = m.Vector2(1, 2)  # Same value as v1, but different instance.
+    assert v1 is not v3
+
+    assert str(v1) == "[1.000000, 2.000000]"
+    assert str(v2) == "[3.000000, -1.000000]"
+
+    assert str(-v2) == "[-3.000000, 1.000000]"
+
+    assert str(v1 + v2) == "[4.000000, 1.000000]"
+    assert str(v1 - v2) == "[-2.000000, 3.000000]"
+    assert str(v1 - 8) == "[-7.000000, -6.000000]"
+    assert str(v1 + 8) == "[9.000000, 10.000000]"
+    assert str(v1 * 8) == "[8.000000, 16.000000]"
+    assert str(v1 / 8) == "[0.125000, 0.250000]"
+    assert str(8 - v1) == "[7.000000, 6.000000]"
+    assert str(8 + v1) == "[9.000000, 10.000000]"
+    assert str(8 * v1) == "[8.000000, 16.000000]"
+    assert str(8 / v1) == "[8.000000, 4.000000]"
+    assert str(v1 * v2) == "[3.000000, -2.000000]"
+    assert str(v2 / v1) == "[3.000000, -0.500000]"
+
+    assert v1 == v3
+    assert v1 != v2
+    assert hash(v1) == 4
+    # TODO(eric.cousineau): Make this work.
+    # assert abs(v1) == "abs(Vector2)"
+
+    v1 += 2 * v2
+    assert str(v1) == "[7.000000, 0.000000]"
+    v1 -= v2
+    assert str(v1) == "[4.000000, 1.000000]"
+    v1 *= 2
+    assert str(v1) == "[8.000000, 2.000000]"
+    v1 /= 16
+    assert str(v1) == "[0.500000, 0.125000]"
+    v1 *= v2
+    assert str(v1) == "[1.500000, -0.125000]"
+    v2 /= v1
+    assert str(v2) == "[2.000000, 8.000000]"
+
+    cstats = ConstructorStats.get(m.Vector2)
+    assert cstats.alive() == 3
+    del v1
+    assert cstats.alive() == 2
+    del v2
+    assert cstats.alive() == 1
+    del v3
+    assert cstats.alive() == 0
+    assert cstats.values() == [
+        "[1.000000, 2.000000]",
+        "[3.000000, -1.000000]",
+        "[1.000000, 2.000000]",
+        "[-3.000000, 1.000000]",
+        "[4.000000, 1.000000]",
+        "[-2.000000, 3.000000]",
+        "[-7.000000, -6.000000]",
+        "[9.000000, 10.000000]",
+        "[8.000000, 16.000000]",
+        "[0.125000, 0.250000]",
+        "[7.000000, 6.000000]",
+        "[9.000000, 10.000000]",
+        "[8.000000, 16.000000]",
+        "[8.000000, 4.000000]",
+        "[3.000000, -2.000000]",
+        "[3.000000, -0.500000]",
+        "[6.000000, -2.000000]",
+    ]
+    assert cstats.default_constructions == 0
+    assert cstats.copy_constructions == 0
+    assert cstats.move_constructions >= 10
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+
+def test_operators_notimplemented():
+    """#393: need to return NotSupported to ensure correct arithmetic operator behavior"""
+
+    c1, c2 = m.C1(), m.C2()
+    assert c1 + c1 == 11
+    assert c2 + c2 == 22
+    assert c2 + c1 == 21
+    assert c1 + c2 == 12
+
+
+def test_nested():
+    """#328: first member in a class can't be used in operators"""
+
+    a = m.NestA()
+    b = m.NestB()
+    c = m.NestC()
+
+    a += 10
+    assert m.get_NestA(a) == 13
+    b.a += 100
+    assert m.get_NestA(b.a) == 103
+    c.b.a += 1000
+    assert m.get_NestA(c.b.a) == 1003
+    b -= 1
+    assert m.get_NestB(b) == 3
+    c.b -= 3
+    assert m.get_NestB(c.b) == 1
+    c *= 7
+    assert m.get_NestC(c) == 35
+
+    abase = a.as_base()
+    assert abase.value == -2
+    a.as_base().value += 44
+    assert abase.value == 42
+    assert c.b.a.as_base().value == -2
+    c.b.a.as_base().value += 44
+    assert c.b.a.as_base().value == 42
+
+    del c
+    pytest.gc_collect()
+    del a  # Shouldn't delete while abase is still alive
+    pytest.gc_collect()
+
+    assert abase.value == 42
+    del abase, b
+    pytest.gc_collect()
+
+
+def test_overriding_eq_reset_hash():
+    assert m.Comparable(15) is not m.Comparable(15)
+    assert m.Comparable(15) == m.Comparable(15)
+
+    with pytest.raises(TypeError) as excinfo:
+        hash(m.Comparable(15))
+    assert str(excinfo.value).startswith("unhashable type:")
+
+    for hashable in (m.Hashable, m.Hashable2):
+        assert hashable(15) is not hashable(15)
+        assert hashable(15) == hashable(15)
+
+        assert hash(hashable(15)) == 15
+        assert hash(hashable(15)) == hash(hashable(15))
+
+
+def test_return_set_of_unhashable():
+    with pytest.raises(TypeError) as excinfo:
+        m.get_unhashable_HashMe_set()
+    assert str(excinfo.value.__cause__).startswith("unhashable type:")
```

## extern/pybind11/tests/test_pickling.py

 * *Ordering differences only*

```diff
@@ -1,93 +1,93 @@
-import pickle
-import re
-
-import pytest
-
-import env
-from pybind11_tests import pickling as m
-
-
-def test_pickle_simple_callable():
-    assert m.simple_callable() == 20220426
-    if env.PYPY:
-        serialized = pickle.dumps(m.simple_callable)
-        deserialized = pickle.loads(serialized)
-        assert deserialized() == 20220426
-    else:
-        # To document broken behavior: currently it fails universally with
-        # all C Python versions.
-        with pytest.raises(TypeError) as excinfo:
-            pickle.dumps(m.simple_callable)
-        assert re.search("can.*t pickle .*PyCapsule.* object", str(excinfo.value))
-
-
-@pytest.mark.parametrize("cls_name", ["Pickleable", "PickleableNew"])
-def test_roundtrip(cls_name):
-    cls = getattr(m, cls_name)
-    p = cls("test_value")
-    p.setExtra1(15)
-    p.setExtra2(48)
-
-    data = pickle.dumps(p, 2)  # Must use pickle protocol >= 2
-    p2 = pickle.loads(data)
-    assert p2.value() == p.value()
-    assert p2.extra1() == p.extra1()
-    assert p2.extra2() == p.extra2()
-
-
-@pytest.mark.xfail("env.PYPY")
-@pytest.mark.parametrize("cls_name", ["PickleableWithDict", "PickleableWithDictNew"])
-def test_roundtrip_with_dict(cls_name):
-    cls = getattr(m, cls_name)
-    p = cls("test_value")
-    p.extra = 15
-    p.dynamic = "Attribute"
-
-    data = pickle.dumps(p, pickle.HIGHEST_PROTOCOL)
-    p2 = pickle.loads(data)
-    assert p2.value == p.value
-    assert p2.extra == p.extra
-    assert p2.dynamic == p.dynamic
-
-
-def test_enum_pickle():
-    from pybind11_tests import enums as e
-
-    data = pickle.dumps(e.EOne, 2)
-    assert e.EOne == pickle.loads(data)
-
-
-#
-# exercise_trampoline
-#
-class SimplePyDerived(m.SimpleBase):
-    pass
-
-
-def test_roundtrip_simple_py_derived():
-    p = SimplePyDerived()
-    p.num = 202
-    p.stored_in_dict = 303
-    data = pickle.dumps(p, pickle.HIGHEST_PROTOCOL)
-    p2 = pickle.loads(data)
-    assert isinstance(p2, SimplePyDerived)
-    assert p2.num == 202
-    assert p2.stored_in_dict == 303
-
-
-def test_roundtrip_simple_cpp_derived():
-    p = m.make_SimpleCppDerivedAsBase()
-    assert m.check_dynamic_cast_SimpleCppDerived(p)
-    p.num = 404
-    if not env.PYPY:
-        # To ensure that this unit test is not accidentally invalidated.
-        with pytest.raises(AttributeError):
-            # Mimics the `setstate` C++ implementation.
-            setattr(p, "__dict__", {})  # noqa: B010
-    data = pickle.dumps(p, pickle.HIGHEST_PROTOCOL)
-    p2 = pickle.loads(data)
-    assert isinstance(p2, m.SimpleBase)
-    assert p2.num == 404
-    # Issue #3062: pickleable base C++ classes can incur object slicing
-    #              if derived typeid is not registered with pybind11
-    assert not m.check_dynamic_cast_SimpleCppDerived(p2)
+import pickle
+import re
+
+import pytest
+
+import env
+from pybind11_tests import pickling as m
+
+
+def test_pickle_simple_callable():
+    assert m.simple_callable() == 20220426
+    if env.PYPY:
+        serialized = pickle.dumps(m.simple_callable)
+        deserialized = pickle.loads(serialized)
+        assert deserialized() == 20220426
+    else:
+        # To document broken behavior: currently it fails universally with
+        # all C Python versions.
+        with pytest.raises(TypeError) as excinfo:
+            pickle.dumps(m.simple_callable)
+        assert re.search("can.*t pickle .*PyCapsule.* object", str(excinfo.value))
+
+
+@pytest.mark.parametrize("cls_name", ["Pickleable", "PickleableNew"])
+def test_roundtrip(cls_name):
+    cls = getattr(m, cls_name)
+    p = cls("test_value")
+    p.setExtra1(15)
+    p.setExtra2(48)
+
+    data = pickle.dumps(p, 2)  # Must use pickle protocol >= 2
+    p2 = pickle.loads(data)
+    assert p2.value() == p.value()
+    assert p2.extra1() == p.extra1()
+    assert p2.extra2() == p.extra2()
+
+
+@pytest.mark.xfail("env.PYPY")
+@pytest.mark.parametrize("cls_name", ["PickleableWithDict", "PickleableWithDictNew"])
+def test_roundtrip_with_dict(cls_name):
+    cls = getattr(m, cls_name)
+    p = cls("test_value")
+    p.extra = 15
+    p.dynamic = "Attribute"
+
+    data = pickle.dumps(p, pickle.HIGHEST_PROTOCOL)
+    p2 = pickle.loads(data)
+    assert p2.value == p.value
+    assert p2.extra == p.extra
+    assert p2.dynamic == p.dynamic
+
+
+def test_enum_pickle():
+    from pybind11_tests import enums as e
+
+    data = pickle.dumps(e.EOne, 2)
+    assert e.EOne == pickle.loads(data)
+
+
+#
+# exercise_trampoline
+#
+class SimplePyDerived(m.SimpleBase):
+    pass
+
+
+def test_roundtrip_simple_py_derived():
+    p = SimplePyDerived()
+    p.num = 202
+    p.stored_in_dict = 303
+    data = pickle.dumps(p, pickle.HIGHEST_PROTOCOL)
+    p2 = pickle.loads(data)
+    assert isinstance(p2, SimplePyDerived)
+    assert p2.num == 202
+    assert p2.stored_in_dict == 303
+
+
+def test_roundtrip_simple_cpp_derived():
+    p = m.make_SimpleCppDerivedAsBase()
+    assert m.check_dynamic_cast_SimpleCppDerived(p)
+    p.num = 404
+    if not env.PYPY:
+        # To ensure that this unit test is not accidentally invalidated.
+        with pytest.raises(AttributeError):
+            # Mimics the `setstate` C++ implementation.
+            setattr(p, "__dict__", {})  # noqa: B010
+    data = pickle.dumps(p, pickle.HIGHEST_PROTOCOL)
+    p2 = pickle.loads(data)
+    assert isinstance(p2, m.SimpleBase)
+    assert p2.num == 404
+    # Issue #3062: pickleable base C++ classes can incur object slicing
+    #              if derived typeid is not registered with pybind11
+    assert not m.check_dynamic_cast_SimpleCppDerived(p2)
```

## extern/pybind11/tests/test_python_multiple_inheritance.py

 * *Ordering differences only*

```diff
@@ -1,35 +1,35 @@
-# Adapted from:
-# https://github.com/google/clif/blob/5718e4d0807fd3b6a8187dde140069120b81ecef/clif/testing/python/python_multiple_inheritance_test.py
-
-from pybind11_tests import python_multiple_inheritance as m
-
-
-class PC(m.CppBase):
-    pass
-
-
-class PPCC(PC, m.CppDrvd):
-    pass
-
-
-def test_PC():
-    d = PC(11)
-    assert d.get_base_value() == 11
-    d.reset_base_value(13)
-    assert d.get_base_value() == 13
-
-
-def test_PPCC():
-    d = PPCC(11)
-    assert d.get_drvd_value() == 33
-    d.reset_drvd_value(55)
-    assert d.get_drvd_value() == 55
-
-    assert d.get_base_value() == 11
-    assert d.get_base_value_from_drvd() == 11
-    d.reset_base_value(20)
-    assert d.get_base_value() == 20
-    assert d.get_base_value_from_drvd() == 20
-    d.reset_base_value_from_drvd(30)
-    assert d.get_base_value() == 30
-    assert d.get_base_value_from_drvd() == 30
+# Adapted from:
+# https://github.com/google/clif/blob/5718e4d0807fd3b6a8187dde140069120b81ecef/clif/testing/python/python_multiple_inheritance_test.py
+
+from pybind11_tests import python_multiple_inheritance as m
+
+
+class PC(m.CppBase):
+    pass
+
+
+class PPCC(PC, m.CppDrvd):
+    pass
+
+
+def test_PC():
+    d = PC(11)
+    assert d.get_base_value() == 11
+    d.reset_base_value(13)
+    assert d.get_base_value() == 13
+
+
+def test_PPCC():
+    d = PPCC(11)
+    assert d.get_drvd_value() == 33
+    d.reset_drvd_value(55)
+    assert d.get_drvd_value() == 55
+
+    assert d.get_base_value() == 11
+    assert d.get_base_value_from_drvd() == 11
+    d.reset_base_value(20)
+    assert d.get_base_value() == 20
+    assert d.get_base_value_from_drvd() == 20
+    d.reset_base_value_from_drvd(30)
+    assert d.get_base_value() == 30
+    assert d.get_base_value_from_drvd() == 30
```

## extern/pybind11/tests/test_pytypes.py

 * *Ordering differences only*

```diff
@@ -1,947 +1,947 @@
-import contextlib
-import sys
-import types
-
-import pytest
-
-import env
-from pybind11_tests import detailed_error_messages_enabled
-from pybind11_tests import pytypes as m
-
-
-def test_obj_class_name():
-    assert m.obj_class_name(None) == "NoneType"
-    assert m.obj_class_name(list) == "list"
-    assert m.obj_class_name([]) == "list"
-
-
-def test_handle_from_move_only_type_with_operator_PyObject():
-    assert m.handle_from_move_only_type_with_operator_PyObject_ncnst()
-    assert m.handle_from_move_only_type_with_operator_PyObject_const()
-
-
-def test_bool(doc):
-    assert doc(m.get_bool) == "get_bool() -> bool"
-
-
-def test_int(doc):
-    assert doc(m.get_int) == "get_int() -> int"
-
-
-def test_iterator(doc):
-    assert doc(m.get_iterator) == "get_iterator() -> Iterator"
-
-
-@pytest.mark.parametrize(
-    ("pytype", "from_iter_func"),
-    [
-        (frozenset, m.get_frozenset_from_iterable),
-        (list, m.get_list_from_iterable),
-        (set, m.get_set_from_iterable),
-        (tuple, m.get_tuple_from_iterable),
-    ],
-)
-def test_from_iterable(pytype, from_iter_func):
-    my_iter = iter(range(10))
-    s = from_iter_func(my_iter)
-    assert type(s) == pytype
-    assert s == pytype(range(10))
-
-
-def test_iterable(doc):
-    assert doc(m.get_iterable) == "get_iterable() -> Iterable"
-
-
-def test_float(doc):
-    assert doc(m.get_float) == "get_float() -> float"
-
-
-def test_list(capture, doc):
-    assert m.list_no_args() == []
-    assert m.list_ssize_t() == []
-    assert m.list_size_t() == []
-    lins = [1, 2]
-    m.list_insert_ssize_t(lins)
-    assert lins == [1, 83, 2]
-    m.list_insert_size_t(lins)
-    assert lins == [1, 83, 2, 57]
-
-    with capture:
-        lst = m.get_list()
-        assert lst == ["inserted-0", "overwritten", "inserted-2"]
-
-        lst.append("value2")
-        m.print_list(lst)
-    assert (
-        capture.unordered
-        == """
-        Entry at position 0: value
-        list item 0: inserted-0
-        list item 1: overwritten
-        list item 2: inserted-2
-        list item 3: value2
-    """
-    )
-
-    assert doc(m.get_list) == "get_list() -> list"
-    assert doc(m.print_list) == "print_list(arg0: list) -> None"
-
-
-def test_none(doc):
-    assert doc(m.get_none) == "get_none() -> None"
-    assert doc(m.print_none) == "print_none(arg0: None) -> None"
-
-
-def test_set(capture, doc):
-    s = m.get_set()
-    assert isinstance(s, set)
-    assert s == {"key1", "key2", "key3"}
-
-    s.add("key4")
-    with capture:
-        m.print_anyset(s)
-    assert (
-        capture.unordered
-        == """
-        key: key1
-        key: key2
-        key: key3
-        key: key4
-    """
-    )
-
-    m.set_add(s, "key5")
-    assert m.anyset_size(s) == 5
-
-    m.set_clear(s)
-    assert m.anyset_empty(s)
-
-    assert not m.anyset_contains(set(), 42)
-    assert m.anyset_contains({42}, 42)
-    assert m.anyset_contains({"foo"}, "foo")
-
-    assert doc(m.get_set) == "get_set() -> set"
-    assert doc(m.print_anyset) == "print_anyset(arg0: anyset) -> None"
-
-
-def test_frozenset(capture, doc):
-    s = m.get_frozenset()
-    assert isinstance(s, frozenset)
-    assert s == frozenset({"key1", "key2", "key3"})
-
-    with capture:
-        m.print_anyset(s)
-    assert (
-        capture.unordered
-        == """
-        key: key1
-        key: key2
-        key: key3
-    """
-    )
-    assert m.anyset_size(s) == 3
-    assert not m.anyset_empty(s)
-
-    assert not m.anyset_contains(frozenset(), 42)
-    assert m.anyset_contains(frozenset({42}), 42)
-    assert m.anyset_contains(frozenset({"foo"}), "foo")
-
-    assert doc(m.get_frozenset) == "get_frozenset() -> frozenset"
-
-
-def test_dict(capture, doc):
-    d = m.get_dict()
-    assert d == {"key": "value"}
-
-    with capture:
-        d["key2"] = "value2"
-        m.print_dict(d)
-    assert (
-        capture.unordered
-        == """
-        key: key, value=value
-        key: key2, value=value2
-    """
-    )
-
-    assert not m.dict_contains({}, 42)
-    assert m.dict_contains({42: None}, 42)
-    assert m.dict_contains({"foo": None}, "foo")
-
-    assert doc(m.get_dict) == "get_dict() -> dict"
-    assert doc(m.print_dict) == "print_dict(arg0: dict) -> None"
-
-    assert m.dict_keyword_constructor() == {"x": 1, "y": 2, "z": 3}
-
-
-class CustomContains:
-    d = {"key": None}
-
-    def __contains__(self, m):
-        return m in self.d
-
-
-@pytest.mark.parametrize(
-    ("arg", "func"),
-    [
-        (set(), m.anyset_contains),
-        ({}, m.dict_contains),
-        (CustomContains(), m.obj_contains),
-    ],
-)
-@pytest.mark.xfail("env.PYPY and sys.pypy_version_info < (7, 3, 10)", strict=False)
-def test_unhashable_exceptions(arg, func):
-    class Unhashable:
-        __hash__ = None
-
-    with pytest.raises(TypeError) as exc_info:
-        func(arg, Unhashable())
-    assert "unhashable type:" in str(exc_info.value)
-
-
-def test_tuple():
-    assert m.tuple_no_args() == ()
-    assert m.tuple_ssize_t() == ()
-    assert m.tuple_size_t() == ()
-    assert m.get_tuple() == (42, None, "spam")
-
-
-def test_simple_namespace():
-    ns = m.get_simple_namespace()
-    assert ns.attr == 42
-    assert ns.x == "foo"
-    assert ns.right == 2
-    assert not hasattr(ns, "wrong")
-
-
-def test_str(doc):
-    assert m.str_from_char_ssize_t().encode().decode() == "red"
-    assert m.str_from_char_size_t().encode().decode() == "blue"
-    assert m.str_from_string().encode().decode() == "baz"
-    assert m.str_from_bytes().encode().decode() == "boo"
-
-    assert doc(m.str_from_bytes) == "str_from_bytes() -> str"
-
-    class A:
-        def __str__(self):
-            return "this is a str"
-
-        def __repr__(self):
-            return "this is a repr"
-
-    assert m.str_from_object(A()) == "this is a str"
-    assert m.repr_from_object(A()) == "this is a repr"
-    assert m.str_from_handle(A()) == "this is a str"
-
-    s1, s2 = m.str_format()
-    assert s1 == "1 + 2 = 3"
-    assert s1 == s2
-
-    malformed_utf8 = b"\x80"
-    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
-        assert m.str_from_object(malformed_utf8) is malformed_utf8
-    else:
-        assert m.str_from_object(malformed_utf8) == "b'\\x80'"
-    assert m.str_from_handle(malformed_utf8) == "b'\\x80'"
-
-    assert m.str_from_string_from_str("this is a str") == "this is a str"
-    ucs_surrogates_str = "\udcc3"
-    with pytest.raises(UnicodeEncodeError):
-        m.str_from_string_from_str(ucs_surrogates_str)
-
-
-@pytest.mark.parametrize(
-    "func",
-    [
-        m.str_from_bytes_input,
-        m.str_from_cstr_input,
-        m.str_from_std_string_input,
-    ],
-)
-def test_surrogate_pairs_unicode_error(func):
-    input_str = "\ud83d\ude4f".encode("utf-8", "surrogatepass")
-    with pytest.raises(UnicodeDecodeError):
-        func(input_str)
-
-
-def test_bytes(doc):
-    assert m.bytes_from_char_ssize_t().decode() == "green"
-    assert m.bytes_from_char_size_t().decode() == "purple"
-    assert m.bytes_from_string().decode() == "foo"
-    assert m.bytes_from_str().decode() == "bar"
-
-    assert doc(m.bytes_from_str) == "bytes_from_str() -> bytes"
-
-
-def test_bytearray():
-    assert m.bytearray_from_char_ssize_t().decode() == "$%"
-    assert m.bytearray_from_char_size_t().decode() == "@$!"
-    assert m.bytearray_from_string().decode() == "foo"
-    assert m.bytearray_size() == len("foo")
-
-
-def test_capsule(capture):
-    pytest.gc_collect()
-    with capture:
-        a = m.return_capsule_with_destructor()
-        del a
-        pytest.gc_collect()
-    assert (
-        capture.unordered
-        == """
-        creating capsule
-        destructing capsule
-    """
-    )
-
-    with capture:
-        a = m.return_renamed_capsule_with_destructor()
-        del a
-        pytest.gc_collect()
-    assert (
-        capture.unordered
-        == """
-        creating capsule
-        renaming capsule
-        destructing capsule
-    """
-    )
-
-    with capture:
-        a = m.return_capsule_with_destructor_2()
-        del a
-        pytest.gc_collect()
-    assert (
-        capture.unordered
-        == """
-        creating capsule
-        destructing capsule: 1234
-    """
-    )
-
-    with capture:
-        a = m.return_capsule_with_destructor_3()
-        del a
-        pytest.gc_collect()
-    assert (
-        capture.unordered
-        == """
-        creating capsule
-        destructing capsule: 1233
-        original name: oname
-    """
-    )
-
-    with capture:
-        a = m.return_renamed_capsule_with_destructor_2()
-        del a
-        pytest.gc_collect()
-    assert (
-        capture.unordered
-        == """
-        creating capsule
-        renaming capsule
-        destructing capsule: 1234
-    """
-    )
-
-    with capture:
-        a = m.return_capsule_with_name_and_destructor()
-        del a
-        pytest.gc_collect()
-    assert (
-        capture.unordered
-        == """
-        created capsule (1234, 'pointer type description')
-        destructing capsule (1234, 'pointer type description')
-    """
-    )
-
-    with capture:
-        a = m.return_capsule_with_explicit_nullptr_dtor()
-        del a
-        pytest.gc_collect()
-    assert (
-        capture.unordered
-        == """
-        creating capsule with explicit nullptr dtor
-    """
-    )
-
-
-def test_accessors():
-    class SubTestObject:
-        attr_obj = 1
-        attr_char = 2
-
-    class TestObject:
-        basic_attr = 1
-        begin_end = [1, 2, 3]
-        d = {"operator[object]": 1, "operator[char *]": 2}
-        sub = SubTestObject()
-
-        def func(self, x, *args):
-            return self.basic_attr + x + sum(args)
-
-    d = m.accessor_api(TestObject())
-    assert d["basic_attr"] == 1
-    assert d["begin_end"] == [1, 2, 3]
-    assert d["operator[object]"] == 1
-    assert d["operator[char *]"] == 2
-    assert d["attr(object)"] == 1
-    assert d["attr(char *)"] == 2
-    assert d["missing_attr_ptr"] == "raised"
-    assert d["missing_attr_chain"] == "raised"
-    assert d["is_none"] is False
-    assert d["operator()"] == 2
-    assert d["operator*"] == 7
-    assert d["implicit_list"] == [1, 2, 3]
-    assert all(x in TestObject.__dict__ for x in d["implicit_dict"])
-
-    assert m.tuple_accessor(()) == (0, 1, 2)
-
-    d = m.accessor_assignment()
-    assert d["get"] == 0
-    assert d["deferred_get"] == 0
-    assert d["set"] == 1
-    assert d["deferred_set"] == 1
-    assert d["var"] == 99
-
-
-def test_accessor_moves():
-    inc_refs = m.accessor_moves()
-    if inc_refs:
-        assert inc_refs == [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]
-    else:
-        pytest.skip("Not defined: PYBIND11_HANDLE_REF_DEBUG")
-
-
-def test_constructors():
-    """C++ default and converting constructors are equivalent to type calls in Python"""
-    types = [bytes, bytearray, str, bool, int, float, tuple, list, dict, set]
-    expected = {t.__name__: t() for t in types}
-    assert m.default_constructors() == expected
-
-    data = {
-        bytes: b"41",  # Currently no supported or working conversions.
-        bytearray: bytearray(b"41"),
-        str: 42,
-        bool: "Not empty",
-        int: "42",
-        float: "+1e3",
-        tuple: range(3),
-        list: range(3),
-        dict: [("two", 2), ("one", 1), ("three", 3)],
-        set: [4, 4, 5, 6, 6, 6],
-        frozenset: [4, 4, 5, 6, 6, 6],
-        memoryview: b"abc",
-    }
-    inputs = {k.__name__: v for k, v in data.items()}
-    expected = {k.__name__: k(v) for k, v in data.items()}
-
-    assert m.converting_constructors(inputs) == expected
-    assert m.cast_functions(inputs) == expected
-
-    # Converting constructors and cast functions should just reference rather
-    # than copy when no conversion is needed:
-    noconv1 = m.converting_constructors(expected)
-    for k in noconv1:
-        assert noconv1[k] is expected[k]
-
-    noconv2 = m.cast_functions(expected)
-    for k in noconv2:
-        assert noconv2[k] is expected[k]
-
-
-def test_non_converting_constructors():
-    non_converting_test_cases = [
-        ("bytes", range(10)),
-        ("none", 42),
-        ("ellipsis", 42),
-        ("type", 42),
-    ]
-    for t, v in non_converting_test_cases:
-        for move in [True, False]:
-            with pytest.raises(TypeError) as excinfo:
-                m.nonconverting_constructor(t, v, move)
-            expected_error = (
-                f"Object of type '{type(v).__name__}' is not an instance of '{t}'"
-            )
-            assert str(excinfo.value) == expected_error
-
-
-def test_pybind11_str_raw_str():
-    # specifically to exercise pybind11::str::raw_str
-    cvt = m.convert_to_pybind11_str
-    assert cvt("Str") == "Str"
-    assert cvt(b"Bytes") == "b'Bytes'"
-    assert cvt(None) == "None"
-    assert cvt(False) == "False"
-    assert cvt(True) == "True"
-    assert cvt(42) == "42"
-    assert cvt(2**65) == "36893488147419103232"
-    assert cvt(-1.50) == "-1.5"
-    assert cvt(()) == "()"
-    assert cvt((18,)) == "(18,)"
-    assert cvt([]) == "[]"
-    assert cvt([28]) == "[28]"
-    assert cvt({}) == "{}"
-    assert cvt({3: 4}) == "{3: 4}"
-    assert cvt(set()) == "set()"
-    assert cvt({3}) == "{3}"
-
-    valid_orig = "Ǳ"
-    valid_utf8 = valid_orig.encode("utf-8")
-    valid_cvt = cvt(valid_utf8)
-    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
-        assert valid_cvt is valid_utf8
-    else:
-        assert type(valid_cvt) is str
-        assert valid_cvt == "b'\\xc7\\xb1'"
-
-    malformed_utf8 = b"\x80"
-    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
-        assert cvt(malformed_utf8) is malformed_utf8
-    else:
-        malformed_cvt = cvt(malformed_utf8)
-        assert type(malformed_cvt) is str
-        assert malformed_cvt == "b'\\x80'"
-
-
-def test_implicit_casting():
-    """Tests implicit casting when assigning or appending to dicts and lists."""
-    z = m.get_implicit_casting()
-    assert z["d"] == {
-        "char*_i1": "abc",
-        "char*_i2": "abc",
-        "char*_e": "abc",
-        "char*_p": "abc",
-        "str_i1": "str",
-        "str_i2": "str1",
-        "str_e": "str2",
-        "str_p": "str3",
-        "int_i1": 42,
-        "int_i2": 42,
-        "int_e": 43,
-        "int_p": 44,
-    }
-    assert z["l"] == [3, 6, 9, 12, 15]
-
-
-def test_print(capture):
-    with capture:
-        m.print_function()
-    assert (
-        capture
-        == """
-        Hello, World!
-        1 2.0 three True -- multiple args
-        *args-and-a-custom-separator
-        no new line here -- next print
-        flush
-        py::print + str.format = this
-    """
-    )
-    assert capture.stderr == "this goes to stderr"
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.print_failure()
-    assert str(excinfo.value) == "Unable to convert call argument " + (
-        "'1' of type 'UnregisteredType' to Python object"
-        if detailed_error_messages_enabled
-        else "'1' to Python object (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
-    )
-
-
-def test_hash():
-    class Hashable:
-        def __init__(self, value):
-            self.value = value
-
-        def __hash__(self):
-            return self.value
-
-    class Unhashable:
-        __hash__ = None
-
-    assert m.hash_function(Hashable(42)) == 42
-    with pytest.raises(TypeError):
-        m.hash_function(Unhashable())
-
-
-def test_number_protocol():
-    for a, b in [(1, 1), (3, 5)]:
-        li = [
-            a == b,
-            a != b,
-            a < b,
-            a <= b,
-            a > b,
-            a >= b,
-            a + b,
-            a - b,
-            a * b,
-            a / b,
-            a | b,
-            a & b,
-            a ^ b,
-            a >> b,
-            a << b,
-        ]
-        assert m.test_number_protocol(a, b) == li
-
-
-def test_list_slicing():
-    li = list(range(100))
-    assert li[::2] == m.test_list_slicing(li)
-
-
-def test_issue2361():
-    # See issue #2361
-    assert m.issue2361_str_implicit_copy_none() == "None"
-    with pytest.raises(TypeError) as excinfo:
-        assert m.issue2361_dict_implicit_copy_none()
-    assert "NoneType" in str(excinfo.value)
-    assert "iterable" in str(excinfo.value)
-
-
-@pytest.mark.parametrize(
-    ("method", "args", "fmt", "expected_view"),
-    [
-        (m.test_memoryview_object, (b"red",), "B", b"red"),
-        (m.test_memoryview_buffer_info, (b"green",), "B", b"green"),
-        (m.test_memoryview_from_buffer, (False,), "h", [3, 1, 4, 1, 5]),
-        (m.test_memoryview_from_buffer, (True,), "H", [2, 7, 1, 8]),
-        (m.test_memoryview_from_buffer_nativeformat, (), "@i", [4, 7, 5]),
-    ],
-)
-def test_memoryview(method, args, fmt, expected_view):
-    view = method(*args)
-    assert isinstance(view, memoryview)
-    assert view.format == fmt
-    assert list(view) == list(expected_view)
-
-
-@pytest.mark.xfail("env.PYPY", reason="getrefcount is not available")
-@pytest.mark.parametrize(
-    "method",
-    [
-        m.test_memoryview_object,
-        m.test_memoryview_buffer_info,
-    ],
-)
-def test_memoryview_refcount(method):
-    buf = b"\x0a\x0b\x0c\x0d"
-    ref_before = sys.getrefcount(buf)
-    view = method(buf)
-    ref_after = sys.getrefcount(buf)
-    assert ref_before < ref_after
-    assert list(view) == list(buf)
-
-
-def test_memoryview_from_buffer_empty_shape():
-    view = m.test_memoryview_from_buffer_empty_shape()
-    assert isinstance(view, memoryview)
-    assert view.format == "B"
-    assert bytes(view) == b""
-
-
-def test_test_memoryview_from_buffer_invalid_strides():
-    with pytest.raises(RuntimeError):
-        m.test_memoryview_from_buffer_invalid_strides()
-
-
-def test_test_memoryview_from_buffer_nullptr():
-    with pytest.raises(ValueError):
-        m.test_memoryview_from_buffer_nullptr()
-
-
-def test_memoryview_from_memory():
-    view = m.test_memoryview_from_memory()
-    assert isinstance(view, memoryview)
-    assert view.format == "B"
-    assert bytes(view) == b"\xff\xe1\xab\x37"
-
-
-def test_builtin_functions():
-    assert m.get_len(list(range(42))) == 42
-    with pytest.raises(TypeError) as exc_info:
-        m.get_len(i for i in range(42))
-    assert str(exc_info.value) in [
-        "object of type 'generator' has no len()",
-        "'generator' has no length",
-    ]  # PyPy
-
-
-def test_isinstance_string_types():
-    assert m.isinstance_pybind11_bytes(b"")
-    assert not m.isinstance_pybind11_bytes("")
-
-    assert m.isinstance_pybind11_str("")
-    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
-        assert m.isinstance_pybind11_str(b"")
-    else:
-        assert not m.isinstance_pybind11_str(b"")
-
-
-def test_pass_bytes_or_unicode_to_string_types():
-    assert m.pass_to_pybind11_bytes(b"Bytes") == 5
-    with pytest.raises(TypeError):
-        m.pass_to_pybind11_bytes("Str")
-
-    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
-        assert m.pass_to_pybind11_str(b"Bytes") == 5
-    else:
-        with pytest.raises(TypeError):
-            m.pass_to_pybind11_str(b"Bytes")
-    assert m.pass_to_pybind11_str("Str") == 3
-
-    assert m.pass_to_std_string(b"Bytes") == 5
-    assert m.pass_to_std_string("Str") == 3
-
-    malformed_utf8 = b"\x80"
-    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
-        assert m.pass_to_pybind11_str(malformed_utf8) == 1
-    else:
-        with pytest.raises(TypeError):
-            m.pass_to_pybind11_str(malformed_utf8)
-
-
-@pytest.mark.parametrize(
-    ("create_weakref", "create_weakref_with_callback"),
-    [
-        (m.weakref_from_handle, m.weakref_from_handle_and_function),
-        (m.weakref_from_object, m.weakref_from_object_and_function),
-    ],
-)
-def test_weakref(create_weakref, create_weakref_with_callback):
-    from weakref import getweakrefcount
-
-    # Apparently, you cannot weakly reference an object()
-    class WeaklyReferenced:
-        pass
-
-    callback_called = False
-
-    def callback(_):
-        nonlocal callback_called
-        callback_called = True
-
-    obj = WeaklyReferenced()
-    assert getweakrefcount(obj) == 0
-    wr = create_weakref(obj)
-    assert getweakrefcount(obj) == 1
-
-    obj = WeaklyReferenced()
-    assert getweakrefcount(obj) == 0
-    wr = create_weakref_with_callback(obj, callback)  # noqa: F841
-    assert getweakrefcount(obj) == 1
-    assert not callback_called
-    del obj
-    pytest.gc_collect()
-    assert callback_called
-
-
-@pytest.mark.parametrize(
-    ("create_weakref", "has_callback"),
-    [
-        (m.weakref_from_handle, False),
-        (m.weakref_from_object, False),
-        (m.weakref_from_handle_and_function, True),
-        (m.weakref_from_object_and_function, True),
-    ],
-)
-def test_weakref_err(create_weakref, has_callback):
-    class C:
-        __slots__ = []
-
-    def callback(_):
-        pass
-
-    ob = C()
-    # Should raise TypeError on CPython
-    with pytest.raises(TypeError) if not env.PYPY else contextlib.nullcontext():
-        _ = create_weakref(ob, callback) if has_callback else create_weakref(ob)
-
-
-def test_cpp_iterators():
-    assert m.tuple_iterator() == 12
-    assert m.dict_iterator() == 305 + 711
-    assert m.passed_iterator(iter((-7, 3))) == -4
-
-
-def test_implementation_details():
-    lst = [39, 43, 92, 49, 22, 29, 93, 98, 26, 57, 8]
-    tup = tuple(lst)
-    assert m.sequence_item_get_ssize_t(lst) == 43
-    assert m.sequence_item_set_ssize_t(lst) is None
-    assert lst[1] == "peppa"
-    assert m.sequence_item_get_size_t(lst) == 92
-    assert m.sequence_item_set_size_t(lst) is None
-    assert lst[2] == "george"
-    assert m.list_item_get_ssize_t(lst) == 49
-    assert m.list_item_set_ssize_t(lst) is None
-    assert lst[3] == "rebecca"
-    assert m.list_item_get_size_t(lst) == 22
-    assert m.list_item_set_size_t(lst) is None
-    assert lst[4] == "richard"
-    assert m.tuple_item_get_ssize_t(tup) == 29
-    assert m.tuple_item_set_ssize_t() == ("emely", "edmond")
-    assert m.tuple_item_get_size_t(tup) == 93
-    assert m.tuple_item_set_size_t() == ("candy", "cat")
-
-
-def test_external_float_():
-    r1 = m.square_float_(2.0)
-    assert r1 == 4.0
-
-
-def test_tuple_rvalue_getter():
-    pop = 1000
-    tup = tuple(range(pop))
-    m.tuple_rvalue_getter(tup)
-
-
-def test_list_rvalue_getter():
-    pop = 1000
-    my_list = list(range(pop))
-    m.list_rvalue_getter(my_list)
-
-
-def test_populate_dict_rvalue():
-    pop = 1000
-    my_dict = {i: i for i in range(pop)}
-    assert m.populate_dict_rvalue(pop) == my_dict
-
-
-def test_populate_obj_str_attrs():
-    pop = 1000
-    o = types.SimpleNamespace(**{str(i): i for i in range(pop)})
-    new_o = m.populate_obj_str_attrs(o, pop)
-    new_attrs = {k: v for k, v in new_o.__dict__.items() if not k.startswith("_")}
-    assert all(isinstance(v, str) for v in new_attrs.values())
-    assert len(new_attrs) == pop
-
-
-@pytest.mark.parametrize(
-    ("a", "b"),
-    [("foo", "bar"), (1, 2), (1.0, 2.0), (list(range(3)), list(range(3, 6)))],
-)
-def test_inplace_append(a, b):
-    expected = a + b
-    assert m.inplace_append(a, b) == expected
-
-
-@pytest.mark.parametrize(
-    ("a", "b"), [(3, 2), (3.0, 2.0), (set(range(3)), set(range(2)))]
-)
-def test_inplace_subtract(a, b):
-    expected = a - b
-    assert m.inplace_subtract(a, b) == expected
-
-
-@pytest.mark.parametrize(("a", "b"), [(3, 2), (3.0, 2.0), ([1], 3)])
-def test_inplace_multiply(a, b):
-    expected = a * b
-    assert m.inplace_multiply(a, b) == expected
-
-
-@pytest.mark.parametrize(("a", "b"), [(6, 3), (6.0, 3.0)])
-def test_inplace_divide(a, b):
-    expected = a / b
-    assert m.inplace_divide(a, b) == expected
-
-
-@pytest.mark.parametrize(
-    ("a", "b"),
-    [
-        (False, True),
-        (
-            set(),
-            {
-                1,
-            },
-        ),
-    ],
-)
-def test_inplace_or(a, b):
-    expected = a | b
-    assert m.inplace_or(a, b) == expected
-
-
-@pytest.mark.parametrize(
-    ("a", "b"),
-    [
-        (True, False),
-        (
-            {1, 2, 3},
-            {
-                1,
-            },
-        ),
-    ],
-)
-def test_inplace_and(a, b):
-    expected = a & b
-    assert m.inplace_and(a, b) == expected
-
-
-@pytest.mark.parametrize(("a", "b"), [(8, 1), (-3, 2)])
-def test_inplace_lshift(a, b):
-    expected = a << b
-    assert m.inplace_lshift(a, b) == expected
-
-
-@pytest.mark.parametrize(("a", "b"), [(8, 1), (-2, 2)])
-def test_inplace_rshift(a, b):
-    expected = a >> b
-    assert m.inplace_rshift(a, b) == expected
-
-
-def test_tuple_nonempty_annotations(doc):
-    assert (
-        doc(m.annotate_tuple_float_str)
-        == "annotate_tuple_float_str(arg0: tuple[float, str]) -> None"
-    )
-
-
-def test_tuple_empty_annotations(doc):
-    assert (
-        doc(m.annotate_tuple_empty) == "annotate_tuple_empty(arg0: tuple[()]) -> None"
-    )
-
-
-def test_dict_annotations(doc):
-    assert (
-        doc(m.annotate_dict_str_int)
-        == "annotate_dict_str_int(arg0: dict[str, int]) -> None"
-    )
-
-
-def test_list_annotations(doc):
-    assert doc(m.annotate_list_int) == "annotate_list_int(arg0: list[int]) -> None"
-
-
-def test_set_annotations(doc):
-    assert doc(m.annotate_set_str) == "annotate_set_str(arg0: set[str]) -> None"
-
-
-def test_iterable_annotations(doc):
-    assert (
-        doc(m.annotate_iterable_str)
-        == "annotate_iterable_str(arg0: Iterable[str]) -> None"
-    )
-
-
-def test_iterator_annotations(doc):
-    assert (
-        doc(m.annotate_iterator_int)
-        == "annotate_iterator_int(arg0: Iterator[int]) -> None"
-    )
-
-
-def test_fn_annotations(doc):
-    assert (
-        doc(m.annotate_fn)
-        == "annotate_fn(arg0: Callable[[list[str], str], int]) -> None"
-    )
+import contextlib
+import sys
+import types
+
+import pytest
+
+import env
+from pybind11_tests import detailed_error_messages_enabled
+from pybind11_tests import pytypes as m
+
+
+def test_obj_class_name():
+    assert m.obj_class_name(None) == "NoneType"
+    assert m.obj_class_name(list) == "list"
+    assert m.obj_class_name([]) == "list"
+
+
+def test_handle_from_move_only_type_with_operator_PyObject():
+    assert m.handle_from_move_only_type_with_operator_PyObject_ncnst()
+    assert m.handle_from_move_only_type_with_operator_PyObject_const()
+
+
+def test_bool(doc):
+    assert doc(m.get_bool) == "get_bool() -> bool"
+
+
+def test_int(doc):
+    assert doc(m.get_int) == "get_int() -> int"
+
+
+def test_iterator(doc):
+    assert doc(m.get_iterator) == "get_iterator() -> Iterator"
+
+
+@pytest.mark.parametrize(
+    ("pytype", "from_iter_func"),
+    [
+        (frozenset, m.get_frozenset_from_iterable),
+        (list, m.get_list_from_iterable),
+        (set, m.get_set_from_iterable),
+        (tuple, m.get_tuple_from_iterable),
+    ],
+)
+def test_from_iterable(pytype, from_iter_func):
+    my_iter = iter(range(10))
+    s = from_iter_func(my_iter)
+    assert type(s) == pytype
+    assert s == pytype(range(10))
+
+
+def test_iterable(doc):
+    assert doc(m.get_iterable) == "get_iterable() -> Iterable"
+
+
+def test_float(doc):
+    assert doc(m.get_float) == "get_float() -> float"
+
+
+def test_list(capture, doc):
+    assert m.list_no_args() == []
+    assert m.list_ssize_t() == []
+    assert m.list_size_t() == []
+    lins = [1, 2]
+    m.list_insert_ssize_t(lins)
+    assert lins == [1, 83, 2]
+    m.list_insert_size_t(lins)
+    assert lins == [1, 83, 2, 57]
+
+    with capture:
+        lst = m.get_list()
+        assert lst == ["inserted-0", "overwritten", "inserted-2"]
+
+        lst.append("value2")
+        m.print_list(lst)
+    assert (
+        capture.unordered
+        == """
+        Entry at position 0: value
+        list item 0: inserted-0
+        list item 1: overwritten
+        list item 2: inserted-2
+        list item 3: value2
+    """
+    )
+
+    assert doc(m.get_list) == "get_list() -> list"
+    assert doc(m.print_list) == "print_list(arg0: list) -> None"
+
+
+def test_none(doc):
+    assert doc(m.get_none) == "get_none() -> None"
+    assert doc(m.print_none) == "print_none(arg0: None) -> None"
+
+
+def test_set(capture, doc):
+    s = m.get_set()
+    assert isinstance(s, set)
+    assert s == {"key1", "key2", "key3"}
+
+    s.add("key4")
+    with capture:
+        m.print_anyset(s)
+    assert (
+        capture.unordered
+        == """
+        key: key1
+        key: key2
+        key: key3
+        key: key4
+    """
+    )
+
+    m.set_add(s, "key5")
+    assert m.anyset_size(s) == 5
+
+    m.set_clear(s)
+    assert m.anyset_empty(s)
+
+    assert not m.anyset_contains(set(), 42)
+    assert m.anyset_contains({42}, 42)
+    assert m.anyset_contains({"foo"}, "foo")
+
+    assert doc(m.get_set) == "get_set() -> set"
+    assert doc(m.print_anyset) == "print_anyset(arg0: anyset) -> None"
+
+
+def test_frozenset(capture, doc):
+    s = m.get_frozenset()
+    assert isinstance(s, frozenset)
+    assert s == frozenset({"key1", "key2", "key3"})
+
+    with capture:
+        m.print_anyset(s)
+    assert (
+        capture.unordered
+        == """
+        key: key1
+        key: key2
+        key: key3
+    """
+    )
+    assert m.anyset_size(s) == 3
+    assert not m.anyset_empty(s)
+
+    assert not m.anyset_contains(frozenset(), 42)
+    assert m.anyset_contains(frozenset({42}), 42)
+    assert m.anyset_contains(frozenset({"foo"}), "foo")
+
+    assert doc(m.get_frozenset) == "get_frozenset() -> frozenset"
+
+
+def test_dict(capture, doc):
+    d = m.get_dict()
+    assert d == {"key": "value"}
+
+    with capture:
+        d["key2"] = "value2"
+        m.print_dict(d)
+    assert (
+        capture.unordered
+        == """
+        key: key, value=value
+        key: key2, value=value2
+    """
+    )
+
+    assert not m.dict_contains({}, 42)
+    assert m.dict_contains({42: None}, 42)
+    assert m.dict_contains({"foo": None}, "foo")
+
+    assert doc(m.get_dict) == "get_dict() -> dict"
+    assert doc(m.print_dict) == "print_dict(arg0: dict) -> None"
+
+    assert m.dict_keyword_constructor() == {"x": 1, "y": 2, "z": 3}
+
+
+class CustomContains:
+    d = {"key": None}
+
+    def __contains__(self, m):
+        return m in self.d
+
+
+@pytest.mark.parametrize(
+    ("arg", "func"),
+    [
+        (set(), m.anyset_contains),
+        ({}, m.dict_contains),
+        (CustomContains(), m.obj_contains),
+    ],
+)
+@pytest.mark.xfail("env.PYPY and sys.pypy_version_info < (7, 3, 10)", strict=False)
+def test_unhashable_exceptions(arg, func):
+    class Unhashable:
+        __hash__ = None
+
+    with pytest.raises(TypeError) as exc_info:
+        func(arg, Unhashable())
+    assert "unhashable type:" in str(exc_info.value)
+
+
+def test_tuple():
+    assert m.tuple_no_args() == ()
+    assert m.tuple_ssize_t() == ()
+    assert m.tuple_size_t() == ()
+    assert m.get_tuple() == (42, None, "spam")
+
+
+def test_simple_namespace():
+    ns = m.get_simple_namespace()
+    assert ns.attr == 42
+    assert ns.x == "foo"
+    assert ns.right == 2
+    assert not hasattr(ns, "wrong")
+
+
+def test_str(doc):
+    assert m.str_from_char_ssize_t().encode().decode() == "red"
+    assert m.str_from_char_size_t().encode().decode() == "blue"
+    assert m.str_from_string().encode().decode() == "baz"
+    assert m.str_from_bytes().encode().decode() == "boo"
+
+    assert doc(m.str_from_bytes) == "str_from_bytes() -> str"
+
+    class A:
+        def __str__(self):
+            return "this is a str"
+
+        def __repr__(self):
+            return "this is a repr"
+
+    assert m.str_from_object(A()) == "this is a str"
+    assert m.repr_from_object(A()) == "this is a repr"
+    assert m.str_from_handle(A()) == "this is a str"
+
+    s1, s2 = m.str_format()
+    assert s1 == "1 + 2 = 3"
+    assert s1 == s2
+
+    malformed_utf8 = b"\x80"
+    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
+        assert m.str_from_object(malformed_utf8) is malformed_utf8
+    else:
+        assert m.str_from_object(malformed_utf8) == "b'\\x80'"
+    assert m.str_from_handle(malformed_utf8) == "b'\\x80'"
+
+    assert m.str_from_string_from_str("this is a str") == "this is a str"
+    ucs_surrogates_str = "\udcc3"
+    with pytest.raises(UnicodeEncodeError):
+        m.str_from_string_from_str(ucs_surrogates_str)
+
+
+@pytest.mark.parametrize(
+    "func",
+    [
+        m.str_from_bytes_input,
+        m.str_from_cstr_input,
+        m.str_from_std_string_input,
+    ],
+)
+def test_surrogate_pairs_unicode_error(func):
+    input_str = "\ud83d\ude4f".encode("utf-8", "surrogatepass")
+    with pytest.raises(UnicodeDecodeError):
+        func(input_str)
+
+
+def test_bytes(doc):
+    assert m.bytes_from_char_ssize_t().decode() == "green"
+    assert m.bytes_from_char_size_t().decode() == "purple"
+    assert m.bytes_from_string().decode() == "foo"
+    assert m.bytes_from_str().decode() == "bar"
+
+    assert doc(m.bytes_from_str) == "bytes_from_str() -> bytes"
+
+
+def test_bytearray():
+    assert m.bytearray_from_char_ssize_t().decode() == "$%"
+    assert m.bytearray_from_char_size_t().decode() == "@$!"
+    assert m.bytearray_from_string().decode() == "foo"
+    assert m.bytearray_size() == len("foo")
+
+
+def test_capsule(capture):
+    pytest.gc_collect()
+    with capture:
+        a = m.return_capsule_with_destructor()
+        del a
+        pytest.gc_collect()
+    assert (
+        capture.unordered
+        == """
+        creating capsule
+        destructing capsule
+    """
+    )
+
+    with capture:
+        a = m.return_renamed_capsule_with_destructor()
+        del a
+        pytest.gc_collect()
+    assert (
+        capture.unordered
+        == """
+        creating capsule
+        renaming capsule
+        destructing capsule
+    """
+    )
+
+    with capture:
+        a = m.return_capsule_with_destructor_2()
+        del a
+        pytest.gc_collect()
+    assert (
+        capture.unordered
+        == """
+        creating capsule
+        destructing capsule: 1234
+    """
+    )
+
+    with capture:
+        a = m.return_capsule_with_destructor_3()
+        del a
+        pytest.gc_collect()
+    assert (
+        capture.unordered
+        == """
+        creating capsule
+        destructing capsule: 1233
+        original name: oname
+    """
+    )
+
+    with capture:
+        a = m.return_renamed_capsule_with_destructor_2()
+        del a
+        pytest.gc_collect()
+    assert (
+        capture.unordered
+        == """
+        creating capsule
+        renaming capsule
+        destructing capsule: 1234
+    """
+    )
+
+    with capture:
+        a = m.return_capsule_with_name_and_destructor()
+        del a
+        pytest.gc_collect()
+    assert (
+        capture.unordered
+        == """
+        created capsule (1234, 'pointer type description')
+        destructing capsule (1234, 'pointer type description')
+    """
+    )
+
+    with capture:
+        a = m.return_capsule_with_explicit_nullptr_dtor()
+        del a
+        pytest.gc_collect()
+    assert (
+        capture.unordered
+        == """
+        creating capsule with explicit nullptr dtor
+    """
+    )
+
+
+def test_accessors():
+    class SubTestObject:
+        attr_obj = 1
+        attr_char = 2
+
+    class TestObject:
+        basic_attr = 1
+        begin_end = [1, 2, 3]
+        d = {"operator[object]": 1, "operator[char *]": 2}
+        sub = SubTestObject()
+
+        def func(self, x, *args):
+            return self.basic_attr + x + sum(args)
+
+    d = m.accessor_api(TestObject())
+    assert d["basic_attr"] == 1
+    assert d["begin_end"] == [1, 2, 3]
+    assert d["operator[object]"] == 1
+    assert d["operator[char *]"] == 2
+    assert d["attr(object)"] == 1
+    assert d["attr(char *)"] == 2
+    assert d["missing_attr_ptr"] == "raised"
+    assert d["missing_attr_chain"] == "raised"
+    assert d["is_none"] is False
+    assert d["operator()"] == 2
+    assert d["operator*"] == 7
+    assert d["implicit_list"] == [1, 2, 3]
+    assert all(x in TestObject.__dict__ for x in d["implicit_dict"])
+
+    assert m.tuple_accessor(()) == (0, 1, 2)
+
+    d = m.accessor_assignment()
+    assert d["get"] == 0
+    assert d["deferred_get"] == 0
+    assert d["set"] == 1
+    assert d["deferred_set"] == 1
+    assert d["var"] == 99
+
+
+def test_accessor_moves():
+    inc_refs = m.accessor_moves()
+    if inc_refs:
+        assert inc_refs == [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]
+    else:
+        pytest.skip("Not defined: PYBIND11_HANDLE_REF_DEBUG")
+
+
+def test_constructors():
+    """C++ default and converting constructors are equivalent to type calls in Python"""
+    types = [bytes, bytearray, str, bool, int, float, tuple, list, dict, set]
+    expected = {t.__name__: t() for t in types}
+    assert m.default_constructors() == expected
+
+    data = {
+        bytes: b"41",  # Currently no supported or working conversions.
+        bytearray: bytearray(b"41"),
+        str: 42,
+        bool: "Not empty",
+        int: "42",
+        float: "+1e3",
+        tuple: range(3),
+        list: range(3),
+        dict: [("two", 2), ("one", 1), ("three", 3)],
+        set: [4, 4, 5, 6, 6, 6],
+        frozenset: [4, 4, 5, 6, 6, 6],
+        memoryview: b"abc",
+    }
+    inputs = {k.__name__: v for k, v in data.items()}
+    expected = {k.__name__: k(v) for k, v in data.items()}
+
+    assert m.converting_constructors(inputs) == expected
+    assert m.cast_functions(inputs) == expected
+
+    # Converting constructors and cast functions should just reference rather
+    # than copy when no conversion is needed:
+    noconv1 = m.converting_constructors(expected)
+    for k in noconv1:
+        assert noconv1[k] is expected[k]
+
+    noconv2 = m.cast_functions(expected)
+    for k in noconv2:
+        assert noconv2[k] is expected[k]
+
+
+def test_non_converting_constructors():
+    non_converting_test_cases = [
+        ("bytes", range(10)),
+        ("none", 42),
+        ("ellipsis", 42),
+        ("type", 42),
+    ]
+    for t, v in non_converting_test_cases:
+        for move in [True, False]:
+            with pytest.raises(TypeError) as excinfo:
+                m.nonconverting_constructor(t, v, move)
+            expected_error = (
+                f"Object of type '{type(v).__name__}' is not an instance of '{t}'"
+            )
+            assert str(excinfo.value) == expected_error
+
+
+def test_pybind11_str_raw_str():
+    # specifically to exercise pybind11::str::raw_str
+    cvt = m.convert_to_pybind11_str
+    assert cvt("Str") == "Str"
+    assert cvt(b"Bytes") == "b'Bytes'"
+    assert cvt(None) == "None"
+    assert cvt(False) == "False"
+    assert cvt(True) == "True"
+    assert cvt(42) == "42"
+    assert cvt(2**65) == "36893488147419103232"
+    assert cvt(-1.50) == "-1.5"
+    assert cvt(()) == "()"
+    assert cvt((18,)) == "(18,)"
+    assert cvt([]) == "[]"
+    assert cvt([28]) == "[28]"
+    assert cvt({}) == "{}"
+    assert cvt({3: 4}) == "{3: 4}"
+    assert cvt(set()) == "set()"
+    assert cvt({3}) == "{3}"
+
+    valid_orig = "Ǳ"
+    valid_utf8 = valid_orig.encode("utf-8")
+    valid_cvt = cvt(valid_utf8)
+    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
+        assert valid_cvt is valid_utf8
+    else:
+        assert type(valid_cvt) is str
+        assert valid_cvt == "b'\\xc7\\xb1'"
+
+    malformed_utf8 = b"\x80"
+    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
+        assert cvt(malformed_utf8) is malformed_utf8
+    else:
+        malformed_cvt = cvt(malformed_utf8)
+        assert type(malformed_cvt) is str
+        assert malformed_cvt == "b'\\x80'"
+
+
+def test_implicit_casting():
+    """Tests implicit casting when assigning or appending to dicts and lists."""
+    z = m.get_implicit_casting()
+    assert z["d"] == {
+        "char*_i1": "abc",
+        "char*_i2": "abc",
+        "char*_e": "abc",
+        "char*_p": "abc",
+        "str_i1": "str",
+        "str_i2": "str1",
+        "str_e": "str2",
+        "str_p": "str3",
+        "int_i1": 42,
+        "int_i2": 42,
+        "int_e": 43,
+        "int_p": 44,
+    }
+    assert z["l"] == [3, 6, 9, 12, 15]
+
+
+def test_print(capture):
+    with capture:
+        m.print_function()
+    assert (
+        capture
+        == """
+        Hello, World!
+        1 2.0 three True -- multiple args
+        *args-and-a-custom-separator
+        no new line here -- next print
+        flush
+        py::print + str.format = this
+    """
+    )
+    assert capture.stderr == "this goes to stderr"
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.print_failure()
+    assert str(excinfo.value) == "Unable to convert call argument " + (
+        "'1' of type 'UnregisteredType' to Python object"
+        if detailed_error_messages_enabled
+        else "'1' to Python object (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
+    )
+
+
+def test_hash():
+    class Hashable:
+        def __init__(self, value):
+            self.value = value
+
+        def __hash__(self):
+            return self.value
+
+    class Unhashable:
+        __hash__ = None
+
+    assert m.hash_function(Hashable(42)) == 42
+    with pytest.raises(TypeError):
+        m.hash_function(Unhashable())
+
+
+def test_number_protocol():
+    for a, b in [(1, 1), (3, 5)]:
+        li = [
+            a == b,
+            a != b,
+            a < b,
+            a <= b,
+            a > b,
+            a >= b,
+            a + b,
+            a - b,
+            a * b,
+            a / b,
+            a | b,
+            a & b,
+            a ^ b,
+            a >> b,
+            a << b,
+        ]
+        assert m.test_number_protocol(a, b) == li
+
+
+def test_list_slicing():
+    li = list(range(100))
+    assert li[::2] == m.test_list_slicing(li)
+
+
+def test_issue2361():
+    # See issue #2361
+    assert m.issue2361_str_implicit_copy_none() == "None"
+    with pytest.raises(TypeError) as excinfo:
+        assert m.issue2361_dict_implicit_copy_none()
+    assert "NoneType" in str(excinfo.value)
+    assert "iterable" in str(excinfo.value)
+
+
+@pytest.mark.parametrize(
+    ("method", "args", "fmt", "expected_view"),
+    [
+        (m.test_memoryview_object, (b"red",), "B", b"red"),
+        (m.test_memoryview_buffer_info, (b"green",), "B", b"green"),
+        (m.test_memoryview_from_buffer, (False,), "h", [3, 1, 4, 1, 5]),
+        (m.test_memoryview_from_buffer, (True,), "H", [2, 7, 1, 8]),
+        (m.test_memoryview_from_buffer_nativeformat, (), "@i", [4, 7, 5]),
+    ],
+)
+def test_memoryview(method, args, fmt, expected_view):
+    view = method(*args)
+    assert isinstance(view, memoryview)
+    assert view.format == fmt
+    assert list(view) == list(expected_view)
+
+
+@pytest.mark.xfail("env.PYPY", reason="getrefcount is not available")
+@pytest.mark.parametrize(
+    "method",
+    [
+        m.test_memoryview_object,
+        m.test_memoryview_buffer_info,
+    ],
+)
+def test_memoryview_refcount(method):
+    buf = b"\x0a\x0b\x0c\x0d"
+    ref_before = sys.getrefcount(buf)
+    view = method(buf)
+    ref_after = sys.getrefcount(buf)
+    assert ref_before < ref_after
+    assert list(view) == list(buf)
+
+
+def test_memoryview_from_buffer_empty_shape():
+    view = m.test_memoryview_from_buffer_empty_shape()
+    assert isinstance(view, memoryview)
+    assert view.format == "B"
+    assert bytes(view) == b""
+
+
+def test_test_memoryview_from_buffer_invalid_strides():
+    with pytest.raises(RuntimeError):
+        m.test_memoryview_from_buffer_invalid_strides()
+
+
+def test_test_memoryview_from_buffer_nullptr():
+    with pytest.raises(ValueError):
+        m.test_memoryview_from_buffer_nullptr()
+
+
+def test_memoryview_from_memory():
+    view = m.test_memoryview_from_memory()
+    assert isinstance(view, memoryview)
+    assert view.format == "B"
+    assert bytes(view) == b"\xff\xe1\xab\x37"
+
+
+def test_builtin_functions():
+    assert m.get_len(list(range(42))) == 42
+    with pytest.raises(TypeError) as exc_info:
+        m.get_len(i for i in range(42))
+    assert str(exc_info.value) in [
+        "object of type 'generator' has no len()",
+        "'generator' has no length",
+    ]  # PyPy
+
+
+def test_isinstance_string_types():
+    assert m.isinstance_pybind11_bytes(b"")
+    assert not m.isinstance_pybind11_bytes("")
+
+    assert m.isinstance_pybind11_str("")
+    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
+        assert m.isinstance_pybind11_str(b"")
+    else:
+        assert not m.isinstance_pybind11_str(b"")
+
+
+def test_pass_bytes_or_unicode_to_string_types():
+    assert m.pass_to_pybind11_bytes(b"Bytes") == 5
+    with pytest.raises(TypeError):
+        m.pass_to_pybind11_bytes("Str")
+
+    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
+        assert m.pass_to_pybind11_str(b"Bytes") == 5
+    else:
+        with pytest.raises(TypeError):
+            m.pass_to_pybind11_str(b"Bytes")
+    assert m.pass_to_pybind11_str("Str") == 3
+
+    assert m.pass_to_std_string(b"Bytes") == 5
+    assert m.pass_to_std_string("Str") == 3
+
+    malformed_utf8 = b"\x80"
+    if hasattr(m, "PYBIND11_STR_LEGACY_PERMISSIVE"):
+        assert m.pass_to_pybind11_str(malformed_utf8) == 1
+    else:
+        with pytest.raises(TypeError):
+            m.pass_to_pybind11_str(malformed_utf8)
+
+
+@pytest.mark.parametrize(
+    ("create_weakref", "create_weakref_with_callback"),
+    [
+        (m.weakref_from_handle, m.weakref_from_handle_and_function),
+        (m.weakref_from_object, m.weakref_from_object_and_function),
+    ],
+)
+def test_weakref(create_weakref, create_weakref_with_callback):
+    from weakref import getweakrefcount
+
+    # Apparently, you cannot weakly reference an object()
+    class WeaklyReferenced:
+        pass
+
+    callback_called = False
+
+    def callback(_):
+        nonlocal callback_called
+        callback_called = True
+
+    obj = WeaklyReferenced()
+    assert getweakrefcount(obj) == 0
+    wr = create_weakref(obj)
+    assert getweakrefcount(obj) == 1
+
+    obj = WeaklyReferenced()
+    assert getweakrefcount(obj) == 0
+    wr = create_weakref_with_callback(obj, callback)  # noqa: F841
+    assert getweakrefcount(obj) == 1
+    assert not callback_called
+    del obj
+    pytest.gc_collect()
+    assert callback_called
+
+
+@pytest.mark.parametrize(
+    ("create_weakref", "has_callback"),
+    [
+        (m.weakref_from_handle, False),
+        (m.weakref_from_object, False),
+        (m.weakref_from_handle_and_function, True),
+        (m.weakref_from_object_and_function, True),
+    ],
+)
+def test_weakref_err(create_weakref, has_callback):
+    class C:
+        __slots__ = []
+
+    def callback(_):
+        pass
+
+    ob = C()
+    # Should raise TypeError on CPython
+    with pytest.raises(TypeError) if not env.PYPY else contextlib.nullcontext():
+        _ = create_weakref(ob, callback) if has_callback else create_weakref(ob)
+
+
+def test_cpp_iterators():
+    assert m.tuple_iterator() == 12
+    assert m.dict_iterator() == 305 + 711
+    assert m.passed_iterator(iter((-7, 3))) == -4
+
+
+def test_implementation_details():
+    lst = [39, 43, 92, 49, 22, 29, 93, 98, 26, 57, 8]
+    tup = tuple(lst)
+    assert m.sequence_item_get_ssize_t(lst) == 43
+    assert m.sequence_item_set_ssize_t(lst) is None
+    assert lst[1] == "peppa"
+    assert m.sequence_item_get_size_t(lst) == 92
+    assert m.sequence_item_set_size_t(lst) is None
+    assert lst[2] == "george"
+    assert m.list_item_get_ssize_t(lst) == 49
+    assert m.list_item_set_ssize_t(lst) is None
+    assert lst[3] == "rebecca"
+    assert m.list_item_get_size_t(lst) == 22
+    assert m.list_item_set_size_t(lst) is None
+    assert lst[4] == "richard"
+    assert m.tuple_item_get_ssize_t(tup) == 29
+    assert m.tuple_item_set_ssize_t() == ("emely", "edmond")
+    assert m.tuple_item_get_size_t(tup) == 93
+    assert m.tuple_item_set_size_t() == ("candy", "cat")
+
+
+def test_external_float_():
+    r1 = m.square_float_(2.0)
+    assert r1 == 4.0
+
+
+def test_tuple_rvalue_getter():
+    pop = 1000
+    tup = tuple(range(pop))
+    m.tuple_rvalue_getter(tup)
+
+
+def test_list_rvalue_getter():
+    pop = 1000
+    my_list = list(range(pop))
+    m.list_rvalue_getter(my_list)
+
+
+def test_populate_dict_rvalue():
+    pop = 1000
+    my_dict = {i: i for i in range(pop)}
+    assert m.populate_dict_rvalue(pop) == my_dict
+
+
+def test_populate_obj_str_attrs():
+    pop = 1000
+    o = types.SimpleNamespace(**{str(i): i for i in range(pop)})
+    new_o = m.populate_obj_str_attrs(o, pop)
+    new_attrs = {k: v for k, v in new_o.__dict__.items() if not k.startswith("_")}
+    assert all(isinstance(v, str) for v in new_attrs.values())
+    assert len(new_attrs) == pop
+
+
+@pytest.mark.parametrize(
+    ("a", "b"),
+    [("foo", "bar"), (1, 2), (1.0, 2.0), (list(range(3)), list(range(3, 6)))],
+)
+def test_inplace_append(a, b):
+    expected = a + b
+    assert m.inplace_append(a, b) == expected
+
+
+@pytest.mark.parametrize(
+    ("a", "b"), [(3, 2), (3.0, 2.0), (set(range(3)), set(range(2)))]
+)
+def test_inplace_subtract(a, b):
+    expected = a - b
+    assert m.inplace_subtract(a, b) == expected
+
+
+@pytest.mark.parametrize(("a", "b"), [(3, 2), (3.0, 2.0), ([1], 3)])
+def test_inplace_multiply(a, b):
+    expected = a * b
+    assert m.inplace_multiply(a, b) == expected
+
+
+@pytest.mark.parametrize(("a", "b"), [(6, 3), (6.0, 3.0)])
+def test_inplace_divide(a, b):
+    expected = a / b
+    assert m.inplace_divide(a, b) == expected
+
+
+@pytest.mark.parametrize(
+    ("a", "b"),
+    [
+        (False, True),
+        (
+            set(),
+            {
+                1,
+            },
+        ),
+    ],
+)
+def test_inplace_or(a, b):
+    expected = a | b
+    assert m.inplace_or(a, b) == expected
+
+
+@pytest.mark.parametrize(
+    ("a", "b"),
+    [
+        (True, False),
+        (
+            {1, 2, 3},
+            {
+                1,
+            },
+        ),
+    ],
+)
+def test_inplace_and(a, b):
+    expected = a & b
+    assert m.inplace_and(a, b) == expected
+
+
+@pytest.mark.parametrize(("a", "b"), [(8, 1), (-3, 2)])
+def test_inplace_lshift(a, b):
+    expected = a << b
+    assert m.inplace_lshift(a, b) == expected
+
+
+@pytest.mark.parametrize(("a", "b"), [(8, 1), (-2, 2)])
+def test_inplace_rshift(a, b):
+    expected = a >> b
+    assert m.inplace_rshift(a, b) == expected
+
+
+def test_tuple_nonempty_annotations(doc):
+    assert (
+        doc(m.annotate_tuple_float_str)
+        == "annotate_tuple_float_str(arg0: tuple[float, str]) -> None"
+    )
+
+
+def test_tuple_empty_annotations(doc):
+    assert (
+        doc(m.annotate_tuple_empty) == "annotate_tuple_empty(arg0: tuple[()]) -> None"
+    )
+
+
+def test_dict_annotations(doc):
+    assert (
+        doc(m.annotate_dict_str_int)
+        == "annotate_dict_str_int(arg0: dict[str, int]) -> None"
+    )
+
+
+def test_list_annotations(doc):
+    assert doc(m.annotate_list_int) == "annotate_list_int(arg0: list[int]) -> None"
+
+
+def test_set_annotations(doc):
+    assert doc(m.annotate_set_str) == "annotate_set_str(arg0: set[str]) -> None"
+
+
+def test_iterable_annotations(doc):
+    assert (
+        doc(m.annotate_iterable_str)
+        == "annotate_iterable_str(arg0: Iterable[str]) -> None"
+    )
+
+
+def test_iterator_annotations(doc):
+    assert (
+        doc(m.annotate_iterator_int)
+        == "annotate_iterator_int(arg0: Iterator[int]) -> None"
+    )
+
+
+def test_fn_annotations(doc):
+    assert (
+        doc(m.annotate_fn)
+        == "annotate_fn(arg0: Callable[[list[str], str], int]) -> None"
+    )
```

## extern/pybind11/tests/test_sequences_and_iterators.py

 * *Ordering differences only*

```diff
@@ -1,265 +1,265 @@
-import pytest
-from pytest import approx  # noqa: PT013
-
-from pybind11_tests import ConstructorStats
-from pybind11_tests import sequences_and_iterators as m
-
-
-def test_slice_constructors():
-    assert m.make_forward_slice_size_t() == slice(0, -1, 1)
-    assert m.make_reversed_slice_object() == slice(None, None, -1)
-
-
-@pytest.mark.skipif(not m.has_optional, reason="no <optional>")
-def test_slice_constructors_explicit_optional():
-    assert m.make_reversed_slice_size_t_optional() == slice(None, None, -1)
-    assert m.make_reversed_slice_size_t_optional_verbose() == slice(None, None, -1)
-
-
-def test_generalized_iterators():
-    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).nonzero()) == [(1, 2), (3, 4)]
-    assert list(m.IntPairs([(1, 2), (2, 0), (0, 3), (4, 5)]).nonzero()) == [(1, 2)]
-    assert list(m.IntPairs([(0, 3), (1, 2), (3, 4)]).nonzero()) == []
-
-    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).nonzero_keys()) == [1, 3]
-    assert list(m.IntPairs([(1, 2), (2, 0), (0, 3), (4, 5)]).nonzero_keys()) == [1]
-    assert list(m.IntPairs([(0, 3), (1, 2), (3, 4)]).nonzero_keys()) == []
-
-    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).nonzero_values()) == [2, 4]
-    assert list(m.IntPairs([(1, 2), (2, 0), (0, 3), (4, 5)]).nonzero_values()) == [2]
-    assert list(m.IntPairs([(0, 3), (1, 2), (3, 4)]).nonzero_values()) == []
-
-    # __next__ must continue to raise StopIteration
-    it = m.IntPairs([(0, 0)]).nonzero()
-    for _ in range(3):
-        with pytest.raises(StopIteration):
-            next(it)
-
-    it = m.IntPairs([(0, 0)]).nonzero_keys()
-    for _ in range(3):
-        with pytest.raises(StopIteration):
-            next(it)
-
-
-def test_nonref_iterators():
-    pairs = m.IntPairs([(1, 2), (3, 4), (0, 5)])
-    assert list(pairs.nonref()) == [(1, 2), (3, 4), (0, 5)]
-    assert list(pairs.nonref_keys()) == [1, 3, 0]
-    assert list(pairs.nonref_values()) == [2, 4, 5]
-
-
-def test_generalized_iterators_simple():
-    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).simple_iterator()) == [
-        (1, 2),
-        (3, 4),
-        (0, 5),
-    ]
-    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).simple_keys()) == [1, 3, 0]
-    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).simple_values()) == [2, 4, 5]
-
-
-def test_iterator_doc_annotations():
-    assert m.IntPairs.nonref.__doc__.endswith("-> Iterator[tuple[int, int]]\n")
-    assert m.IntPairs.nonref_keys.__doc__.endswith("-> Iterator[int]\n")
-    assert m.IntPairs.nonref_values.__doc__.endswith("-> Iterator[int]\n")
-    assert m.IntPairs.simple_iterator.__doc__.endswith("-> Iterator[tuple[int, int]]\n")
-    assert m.IntPairs.simple_keys.__doc__.endswith("-> Iterator[int]\n")
-    assert m.IntPairs.simple_values.__doc__.endswith("-> Iterator[int]\n")
-
-
-def test_iterator_referencing():
-    """Test that iterators reference rather than copy their referents."""
-    vec = m.VectorNonCopyableInt()
-    vec.append(3)
-    vec.append(5)
-    assert [int(x) for x in vec] == [3, 5]
-    # Increment everything to make sure the referents can be mutated
-    for x in vec:
-        x.set(int(x) + 1)
-    assert [int(x) for x in vec] == [4, 6]
-
-    vec = m.VectorNonCopyableIntPair()
-    vec.append([3, 4])
-    vec.append([5, 7])
-    assert [int(x) for x in vec.keys()] == [3, 5]
-    assert [int(x) for x in vec.values()] == [4, 7]
-    for x in vec.keys():
-        x.set(int(x) + 1)
-    for x in vec.values():
-        x.set(int(x) + 10)
-    assert [int(x) for x in vec.keys()] == [4, 6]
-    assert [int(x) for x in vec.values()] == [14, 17]
-
-
-def test_sliceable():
-    sliceable = m.Sliceable(100)
-    assert sliceable[::] == (0, 100, 1)
-    assert sliceable[10::] == (10, 100, 1)
-    assert sliceable[:10:] == (0, 10, 1)
-    assert sliceable[::10] == (0, 100, 10)
-    assert sliceable[-10::] == (90, 100, 1)
-    assert sliceable[:-10:] == (0, 90, 1)
-    assert sliceable[::-10] == (99, -1, -10)
-    assert sliceable[50:60:1] == (50, 60, 1)
-    assert sliceable[50:60:-1] == (50, 60, -1)
-
-
-def test_sequence():
-    cstats = ConstructorStats.get(m.Sequence)
-
-    s = m.Sequence(5)
-    assert cstats.values() == ["of size", "5"]
-
-    assert "Sequence" in repr(s)
-    assert len(s) == 5
-    assert s[0] == 0
-    assert s[3] == 0
-    assert 12.34 not in s
-    s[0], s[3] = 12.34, 56.78
-    assert 12.34 in s
-    assert s[0] == approx(12.34, rel=1e-05)
-    assert s[3] == approx(56.78, rel=1e-05)
-
-    rev = reversed(s)
-    assert cstats.values() == ["of size", "5"]
-
-    rev2 = s[::-1]
-    assert cstats.values() == ["of size", "5"]
-
-    it = iter(m.Sequence(0))
-    for _ in range(3):  # __next__ must continue to raise StopIteration
-        with pytest.raises(StopIteration):
-            next(it)
-    assert cstats.values() == ["of size", "0"]
-
-    expected = [0, 56.78, 0, 0, 12.34]
-    assert rev == approx(expected, rel=1e-05)
-    assert rev2 == approx(expected, rel=1e-05)
-    assert rev == rev2
-
-    rev[0::2] = m.Sequence([2.0, 2.0, 2.0])
-    assert cstats.values() == ["of size", "3", "from std::vector"]
-
-    assert rev == approx([2, 56.78, 2, 0, 2], rel=1e-05)
-
-    assert cstats.alive() == 4
-    del it
-    assert cstats.alive() == 3
-    del s
-    assert cstats.alive() == 2
-    del rev
-    assert cstats.alive() == 1
-    del rev2
-    assert cstats.alive() == 0
-
-    assert cstats.values() == []
-    assert cstats.default_constructions == 0
-    assert cstats.copy_constructions == 0
-    assert cstats.move_constructions >= 1
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-
-def test_sequence_length():
-    """#2076: Exception raised by len(arg) should be propagated"""
-
-    class BadLen(RuntimeError):
-        pass
-
-    class SequenceLike:
-        def __getitem__(self, i):
-            return None
-
-        def __len__(self):
-            raise BadLen()
-
-    with pytest.raises(BadLen):
-        m.sequence_length(SequenceLike())
-
-    assert m.sequence_length([1, 2, 3]) == 3
-    assert m.sequence_length("hello") == 5
-
-
-def test_sequence_doc():
-    assert m.sequence_length.__doc__.strip() == "sequence_length(arg0: Sequence) -> int"
-
-
-def test_map_iterator():
-    sm = m.StringMap({"hi": "bye", "black": "white"})
-    assert sm["hi"] == "bye"
-    assert len(sm) == 2
-    assert sm["black"] == "white"
-
-    with pytest.raises(KeyError):
-        assert sm["orange"]
-    sm["orange"] = "banana"
-    assert sm["orange"] == "banana"
-
-    expected = {"hi": "bye", "black": "white", "orange": "banana"}
-    for k in sm:
-        assert sm[k] == expected[k]
-    for k, v in sm.items():
-        assert v == expected[k]
-    assert list(sm.values()) == [expected[k] for k in sm]
-
-    it = iter(m.StringMap({}))
-    for _ in range(3):  # __next__ must continue to raise StopIteration
-        with pytest.raises(StopIteration):
-            next(it)
-
-
-def test_python_iterator_in_cpp():
-    t = (1, 2, 3)
-    assert m.object_to_list(t) == [1, 2, 3]
-    assert m.object_to_list(iter(t)) == [1, 2, 3]
-    assert m.iterator_to_list(iter(t)) == [1, 2, 3]
-
-    with pytest.raises(TypeError) as excinfo:
-        m.object_to_list(1)
-    assert "object is not iterable" in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        m.iterator_to_list(1)
-    assert "incompatible function arguments" in str(excinfo.value)
-
-    def bad_next_call():
-        raise RuntimeError("py::iterator::advance() should propagate errors")
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.iterator_to_list(iter(bad_next_call, None))
-    assert str(excinfo.value) == "py::iterator::advance() should propagate errors"
-
-    lst = [1, None, 0, None]
-    assert m.count_none(lst) == 2
-    assert m.find_none(lst) is True
-    assert m.count_nonzeros({"a": 0, "b": 1, "c": 2}) == 2
-
-    r = range(5)
-    assert all(m.tuple_iterator(tuple(r)))
-    assert all(m.list_iterator(list(r)))
-    assert all(m.sequence_iterator(r))
-
-
-def test_iterator_passthrough():
-    """#181: iterator passthrough did not compile"""
-    from pybind11_tests.sequences_and_iterators import iterator_passthrough
-
-    values = [3, 5, 7, 9, 11, 13, 15]
-    assert list(iterator_passthrough(iter(values))) == values
-
-
-def test_iterator_rvp():
-    """#388: Can't make iterators via make_iterator() with different r/v policies"""
-    import pybind11_tests.sequences_and_iterators as m
-
-    assert list(m.make_iterator_1()) == [1, 2, 3]
-    assert list(m.make_iterator_2()) == [1, 2, 3]
-    assert not isinstance(m.make_iterator_1(), type(m.make_iterator_2()))
-
-
-def test_carray_iterator():
-    """#4100: Check for proper iterator overload with C-Arrays"""
-    args_gt = [float(i) for i in range(3)]
-    arr_h = m.CArrayHolder(*args_gt)
-    args = list(arr_h)
-    assert args_gt == args
+import pytest
+from pytest import approx  # noqa: PT013
+
+from pybind11_tests import ConstructorStats
+from pybind11_tests import sequences_and_iterators as m
+
+
+def test_slice_constructors():
+    assert m.make_forward_slice_size_t() == slice(0, -1, 1)
+    assert m.make_reversed_slice_object() == slice(None, None, -1)
+
+
+@pytest.mark.skipif(not m.has_optional, reason="no <optional>")
+def test_slice_constructors_explicit_optional():
+    assert m.make_reversed_slice_size_t_optional() == slice(None, None, -1)
+    assert m.make_reversed_slice_size_t_optional_verbose() == slice(None, None, -1)
+
+
+def test_generalized_iterators():
+    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).nonzero()) == [(1, 2), (3, 4)]
+    assert list(m.IntPairs([(1, 2), (2, 0), (0, 3), (4, 5)]).nonzero()) == [(1, 2)]
+    assert list(m.IntPairs([(0, 3), (1, 2), (3, 4)]).nonzero()) == []
+
+    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).nonzero_keys()) == [1, 3]
+    assert list(m.IntPairs([(1, 2), (2, 0), (0, 3), (4, 5)]).nonzero_keys()) == [1]
+    assert list(m.IntPairs([(0, 3), (1, 2), (3, 4)]).nonzero_keys()) == []
+
+    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).nonzero_values()) == [2, 4]
+    assert list(m.IntPairs([(1, 2), (2, 0), (0, 3), (4, 5)]).nonzero_values()) == [2]
+    assert list(m.IntPairs([(0, 3), (1, 2), (3, 4)]).nonzero_values()) == []
+
+    # __next__ must continue to raise StopIteration
+    it = m.IntPairs([(0, 0)]).nonzero()
+    for _ in range(3):
+        with pytest.raises(StopIteration):
+            next(it)
+
+    it = m.IntPairs([(0, 0)]).nonzero_keys()
+    for _ in range(3):
+        with pytest.raises(StopIteration):
+            next(it)
+
+
+def test_nonref_iterators():
+    pairs = m.IntPairs([(1, 2), (3, 4), (0, 5)])
+    assert list(pairs.nonref()) == [(1, 2), (3, 4), (0, 5)]
+    assert list(pairs.nonref_keys()) == [1, 3, 0]
+    assert list(pairs.nonref_values()) == [2, 4, 5]
+
+
+def test_generalized_iterators_simple():
+    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).simple_iterator()) == [
+        (1, 2),
+        (3, 4),
+        (0, 5),
+    ]
+    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).simple_keys()) == [1, 3, 0]
+    assert list(m.IntPairs([(1, 2), (3, 4), (0, 5)]).simple_values()) == [2, 4, 5]
+
+
+def test_iterator_doc_annotations():
+    assert m.IntPairs.nonref.__doc__.endswith("-> Iterator[tuple[int, int]]\n")
+    assert m.IntPairs.nonref_keys.__doc__.endswith("-> Iterator[int]\n")
+    assert m.IntPairs.nonref_values.__doc__.endswith("-> Iterator[int]\n")
+    assert m.IntPairs.simple_iterator.__doc__.endswith("-> Iterator[tuple[int, int]]\n")
+    assert m.IntPairs.simple_keys.__doc__.endswith("-> Iterator[int]\n")
+    assert m.IntPairs.simple_values.__doc__.endswith("-> Iterator[int]\n")
+
+
+def test_iterator_referencing():
+    """Test that iterators reference rather than copy their referents."""
+    vec = m.VectorNonCopyableInt()
+    vec.append(3)
+    vec.append(5)
+    assert [int(x) for x in vec] == [3, 5]
+    # Increment everything to make sure the referents can be mutated
+    for x in vec:
+        x.set(int(x) + 1)
+    assert [int(x) for x in vec] == [4, 6]
+
+    vec = m.VectorNonCopyableIntPair()
+    vec.append([3, 4])
+    vec.append([5, 7])
+    assert [int(x) for x in vec.keys()] == [3, 5]
+    assert [int(x) for x in vec.values()] == [4, 7]
+    for x in vec.keys():
+        x.set(int(x) + 1)
+    for x in vec.values():
+        x.set(int(x) + 10)
+    assert [int(x) for x in vec.keys()] == [4, 6]
+    assert [int(x) for x in vec.values()] == [14, 17]
+
+
+def test_sliceable():
+    sliceable = m.Sliceable(100)
+    assert sliceable[::] == (0, 100, 1)
+    assert sliceable[10::] == (10, 100, 1)
+    assert sliceable[:10:] == (0, 10, 1)
+    assert sliceable[::10] == (0, 100, 10)
+    assert sliceable[-10::] == (90, 100, 1)
+    assert sliceable[:-10:] == (0, 90, 1)
+    assert sliceable[::-10] == (99, -1, -10)
+    assert sliceable[50:60:1] == (50, 60, 1)
+    assert sliceable[50:60:-1] == (50, 60, -1)
+
+
+def test_sequence():
+    cstats = ConstructorStats.get(m.Sequence)
+
+    s = m.Sequence(5)
+    assert cstats.values() == ["of size", "5"]
+
+    assert "Sequence" in repr(s)
+    assert len(s) == 5
+    assert s[0] == 0
+    assert s[3] == 0
+    assert 12.34 not in s
+    s[0], s[3] = 12.34, 56.78
+    assert 12.34 in s
+    assert s[0] == approx(12.34, rel=1e-05)
+    assert s[3] == approx(56.78, rel=1e-05)
+
+    rev = reversed(s)
+    assert cstats.values() == ["of size", "5"]
+
+    rev2 = s[::-1]
+    assert cstats.values() == ["of size", "5"]
+
+    it = iter(m.Sequence(0))
+    for _ in range(3):  # __next__ must continue to raise StopIteration
+        with pytest.raises(StopIteration):
+            next(it)
+    assert cstats.values() == ["of size", "0"]
+
+    expected = [0, 56.78, 0, 0, 12.34]
+    assert rev == approx(expected, rel=1e-05)
+    assert rev2 == approx(expected, rel=1e-05)
+    assert rev == rev2
+
+    rev[0::2] = m.Sequence([2.0, 2.0, 2.0])
+    assert cstats.values() == ["of size", "3", "from std::vector"]
+
+    assert rev == approx([2, 56.78, 2, 0, 2], rel=1e-05)
+
+    assert cstats.alive() == 4
+    del it
+    assert cstats.alive() == 3
+    del s
+    assert cstats.alive() == 2
+    del rev
+    assert cstats.alive() == 1
+    del rev2
+    assert cstats.alive() == 0
+
+    assert cstats.values() == []
+    assert cstats.default_constructions == 0
+    assert cstats.copy_constructions == 0
+    assert cstats.move_constructions >= 1
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+
+def test_sequence_length():
+    """#2076: Exception raised by len(arg) should be propagated"""
+
+    class BadLen(RuntimeError):
+        pass
+
+    class SequenceLike:
+        def __getitem__(self, i):
+            return None
+
+        def __len__(self):
+            raise BadLen()
+
+    with pytest.raises(BadLen):
+        m.sequence_length(SequenceLike())
+
+    assert m.sequence_length([1, 2, 3]) == 3
+    assert m.sequence_length("hello") == 5
+
+
+def test_sequence_doc():
+    assert m.sequence_length.__doc__.strip() == "sequence_length(arg0: Sequence) -> int"
+
+
+def test_map_iterator():
+    sm = m.StringMap({"hi": "bye", "black": "white"})
+    assert sm["hi"] == "bye"
+    assert len(sm) == 2
+    assert sm["black"] == "white"
+
+    with pytest.raises(KeyError):
+        assert sm["orange"]
+    sm["orange"] = "banana"
+    assert sm["orange"] == "banana"
+
+    expected = {"hi": "bye", "black": "white", "orange": "banana"}
+    for k in sm:
+        assert sm[k] == expected[k]
+    for k, v in sm.items():
+        assert v == expected[k]
+    assert list(sm.values()) == [expected[k] for k in sm]
+
+    it = iter(m.StringMap({}))
+    for _ in range(3):  # __next__ must continue to raise StopIteration
+        with pytest.raises(StopIteration):
+            next(it)
+
+
+def test_python_iterator_in_cpp():
+    t = (1, 2, 3)
+    assert m.object_to_list(t) == [1, 2, 3]
+    assert m.object_to_list(iter(t)) == [1, 2, 3]
+    assert m.iterator_to_list(iter(t)) == [1, 2, 3]
+
+    with pytest.raises(TypeError) as excinfo:
+        m.object_to_list(1)
+    assert "object is not iterable" in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        m.iterator_to_list(1)
+    assert "incompatible function arguments" in str(excinfo.value)
+
+    def bad_next_call():
+        raise RuntimeError("py::iterator::advance() should propagate errors")
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.iterator_to_list(iter(bad_next_call, None))
+    assert str(excinfo.value) == "py::iterator::advance() should propagate errors"
+
+    lst = [1, None, 0, None]
+    assert m.count_none(lst) == 2
+    assert m.find_none(lst) is True
+    assert m.count_nonzeros({"a": 0, "b": 1, "c": 2}) == 2
+
+    r = range(5)
+    assert all(m.tuple_iterator(tuple(r)))
+    assert all(m.list_iterator(list(r)))
+    assert all(m.sequence_iterator(r))
+
+
+def test_iterator_passthrough():
+    """#181: iterator passthrough did not compile"""
+    from pybind11_tests.sequences_and_iterators import iterator_passthrough
+
+    values = [3, 5, 7, 9, 11, 13, 15]
+    assert list(iterator_passthrough(iter(values))) == values
+
+
+def test_iterator_rvp():
+    """#388: Can't make iterators via make_iterator() with different r/v policies"""
+    import pybind11_tests.sequences_and_iterators as m
+
+    assert list(m.make_iterator_1()) == [1, 2, 3]
+    assert list(m.make_iterator_2()) == [1, 2, 3]
+    assert not isinstance(m.make_iterator_1(), type(m.make_iterator_2()))
+
+
+def test_carray_iterator():
+    """#4100: Check for proper iterator overload with C-Arrays"""
+    args_gt = [float(i) for i in range(3)]
+    arr_h = m.CArrayHolder(*args_gt)
+    args = list(arr_h)
+    assert args_gt == args
```

## extern/pybind11/tests/test_smart_ptr.py

 * *Ordering differences only*

```diff
@@ -1,315 +1,315 @@
-import pytest
-
-m = pytest.importorskip("pybind11_tests.smart_ptr")
-from pybind11_tests import ConstructorStats  # noqa: E402
-
-
-def test_smart_ptr(capture):
-    # Object1
-    for i, o in enumerate(
-        [m.make_object_1(), m.make_object_2(), m.MyObject1(3)], start=1
-    ):
-        assert o.getRefCount() == 1
-        with capture:
-            m.print_object_1(o)
-            m.print_object_2(o)
-            m.print_object_3(o)
-            m.print_object_4(o)
-        assert capture == f"MyObject1[{i}]\n" * 4
-
-    for i, o in enumerate(
-        [m.make_myobject1_1(), m.make_myobject1_2(), m.MyObject1(6), 7], start=4
-    ):
-        print(o)
-        with capture:
-            if not isinstance(o, int):
-                m.print_object_1(o)
-                m.print_object_2(o)
-                m.print_object_3(o)
-                m.print_object_4(o)
-            m.print_myobject1_1(o)
-            m.print_myobject1_2(o)
-            m.print_myobject1_3(o)
-            m.print_myobject1_4(o)
-
-        times = 4 if isinstance(o, int) else 8
-        assert capture == f"MyObject1[{i}]\n" * times
-
-    cstats = ConstructorStats.get(m.MyObject1)
-    assert cstats.alive() == 0
-    expected_values = [f"MyObject1[{i}]" for i in range(1, 7)] + ["MyObject1[7]"] * 4
-    assert cstats.values() == expected_values
-    assert cstats.default_constructions == 0
-    assert cstats.copy_constructions == 0
-    # assert cstats.move_constructions >= 0 # Doesn't invoke any
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-    # Object2
-    for i, o in zip(
-        [8, 6, 7], [m.MyObject2(8), m.make_myobject2_1(), m.make_myobject2_2()]
-    ):
-        print(o)
-        with capture:
-            m.print_myobject2_1(o)
-            m.print_myobject2_2(o)
-            m.print_myobject2_3(o)
-            m.print_myobject2_4(o)
-        assert capture == f"MyObject2[{i}]\n" * 4
-
-    cstats = ConstructorStats.get(m.MyObject2)
-    assert cstats.alive() == 1
-    o = None
-    assert cstats.alive() == 0
-    assert cstats.values() == ["MyObject2[8]", "MyObject2[6]", "MyObject2[7]"]
-    assert cstats.default_constructions == 0
-    assert cstats.copy_constructions == 0
-    # assert cstats.move_constructions >= 0 # Doesn't invoke any
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-    # Object3
-    for i, o in zip(
-        [9, 8, 9], [m.MyObject3(9), m.make_myobject3_1(), m.make_myobject3_2()]
-    ):
-        print(o)
-        with capture:
-            m.print_myobject3_1(o)
-            m.print_myobject3_2(o)
-            m.print_myobject3_3(o)
-            m.print_myobject3_4(o)
-        assert capture == f"MyObject3[{i}]\n" * 4
-
-    cstats = ConstructorStats.get(m.MyObject3)
-    assert cstats.alive() == 1
-    o = None
-    assert cstats.alive() == 0
-    assert cstats.values() == ["MyObject3[9]", "MyObject3[8]", "MyObject3[9]"]
-    assert cstats.default_constructions == 0
-    assert cstats.copy_constructions == 0
-    # assert cstats.move_constructions >= 0 # Doesn't invoke any
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-    # Object
-    cstats = ConstructorStats.get(m.Object)
-    assert cstats.alive() == 0
-    assert cstats.values() == []
-    assert cstats.default_constructions == 10
-    assert cstats.copy_constructions == 0
-    # assert cstats.move_constructions >= 0 # Doesn't invoke any
-    assert cstats.copy_assignments == 0
-    assert cstats.move_assignments == 0
-
-    # ref<>
-    cstats = m.cstats_ref()
-    assert cstats.alive() == 0
-    assert cstats.values() == ["from pointer"] * 10
-    assert cstats.default_constructions == 30
-    assert cstats.copy_constructions == 12
-    # assert cstats.move_constructions >= 0 # Doesn't invoke any
-    assert cstats.copy_assignments == 30
-    assert cstats.move_assignments == 0
-
-
-def test_smart_ptr_refcounting():
-    assert m.test_object1_refcounting()
-
-
-def test_unique_nodelete():
-    o = m.MyObject4(23)
-    assert o.value == 23
-    cstats = ConstructorStats.get(m.MyObject4)
-    assert cstats.alive() == 1
-    del o
-    assert cstats.alive() == 1
-    m.MyObject4.cleanup_all_instances()
-    assert cstats.alive() == 0
-
-
-def test_unique_nodelete4a():
-    o = m.MyObject4a(23)
-    assert o.value == 23
-    cstats = ConstructorStats.get(m.MyObject4a)
-    assert cstats.alive() == 1
-    del o
-    assert cstats.alive() == 1
-    m.MyObject4a.cleanup_all_instances()
-    assert cstats.alive() == 0
-
-
-def test_unique_deleter():
-    m.MyObject4a(0)
-    o = m.MyObject4b(23)
-    assert o.value == 23
-    cstats4a = ConstructorStats.get(m.MyObject4a)
-    assert cstats4a.alive() == 2
-    cstats4b = ConstructorStats.get(m.MyObject4b)
-    assert cstats4b.alive() == 1
-    del o
-    assert cstats4a.alive() == 1  # Should now only be one leftover
-    assert cstats4b.alive() == 0  # Should be deleted
-    m.MyObject4a.cleanup_all_instances()
-    assert cstats4a.alive() == 0
-    assert cstats4b.alive() == 0
-
-
-def test_large_holder():
-    o = m.MyObject5(5)
-    assert o.value == 5
-    cstats = ConstructorStats.get(m.MyObject5)
-    assert cstats.alive() == 1
-    del o
-    assert cstats.alive() == 0
-
-
-def test_shared_ptr_and_references():
-    s = m.SharedPtrRef()
-    stats = ConstructorStats.get(m.A)
-    assert stats.alive() == 2
-
-    ref = s.ref  # init_holder_helper(holder_ptr=false, owned=false)
-    assert stats.alive() == 2
-    assert s.set_ref(ref)
-    with pytest.raises(RuntimeError) as excinfo:
-        assert s.set_holder(ref)
-    assert "Unable to cast from non-held to held instance" in str(excinfo.value)
-
-    copy = s.copy  # init_holder_helper(holder_ptr=false, owned=true)
-    assert stats.alive() == 3
-    assert s.set_ref(copy)
-    assert s.set_holder(copy)
-
-    holder_ref = s.holder_ref  # init_holder_helper(holder_ptr=true, owned=false)
-    assert stats.alive() == 3
-    assert s.set_ref(holder_ref)
-    assert s.set_holder(holder_ref)
-
-    holder_copy = s.holder_copy  # init_holder_helper(holder_ptr=true, owned=true)
-    assert stats.alive() == 3
-    assert s.set_ref(holder_copy)
-    assert s.set_holder(holder_copy)
-
-    del ref, copy, holder_ref, holder_copy, s
-    assert stats.alive() == 0
-
-
-def test_shared_ptr_from_this_and_references():
-    s = m.SharedFromThisRef()
-    stats = ConstructorStats.get(m.B)
-    assert stats.alive() == 2
-
-    ref = s.ref  # init_holder_helper(holder_ptr=false, owned=false, bad_wp=false)
-    assert stats.alive() == 2
-    assert s.set_ref(ref)
-    assert s.set_holder(
-        ref
-    )  # std::enable_shared_from_this can create a holder from a reference
-
-    bad_wp = s.bad_wp  # init_holder_helper(holder_ptr=false, owned=false, bad_wp=true)
-    assert stats.alive() == 2
-    assert s.set_ref(bad_wp)
-    with pytest.raises(RuntimeError) as excinfo:
-        assert s.set_holder(bad_wp)
-    assert "Unable to cast from non-held to held instance" in str(excinfo.value)
-
-    copy = s.copy  # init_holder_helper(holder_ptr=false, owned=true, bad_wp=false)
-    assert stats.alive() == 3
-    assert s.set_ref(copy)
-    assert s.set_holder(copy)
-
-    holder_ref = (
-        s.holder_ref
-    )  # init_holder_helper(holder_ptr=true, owned=false, bad_wp=false)
-    assert stats.alive() == 3
-    assert s.set_ref(holder_ref)
-    assert s.set_holder(holder_ref)
-
-    holder_copy = (
-        s.holder_copy
-    )  # init_holder_helper(holder_ptr=true, owned=true, bad_wp=false)
-    assert stats.alive() == 3
-    assert s.set_ref(holder_copy)
-    assert s.set_holder(holder_copy)
-
-    del ref, bad_wp, copy, holder_ref, holder_copy, s
-    assert stats.alive() == 0
-
-    z = m.SharedFromThisVirt.get()
-    y = m.SharedFromThisVirt.get()
-    assert y is z
-
-
-def test_move_only_holder():
-    a = m.TypeWithMoveOnlyHolder.make()
-    b = m.TypeWithMoveOnlyHolder.make_as_object()
-    stats = ConstructorStats.get(m.TypeWithMoveOnlyHolder)
-    assert stats.alive() == 2
-    del b
-    assert stats.alive() == 1
-    del a
-    assert stats.alive() == 0
-
-
-def test_holder_with_addressof_operator():
-    # this test must not throw exception from c++
-    a = m.TypeForHolderWithAddressOf.make()
-    a.print_object_1()
-    a.print_object_2()
-    a.print_object_3()
-    a.print_object_4()
-
-    stats = ConstructorStats.get(m.TypeForHolderWithAddressOf)
-    assert stats.alive() == 1
-
-    np = m.TypeForHolderWithAddressOf.make()
-    assert stats.alive() == 2
-    del a
-    assert stats.alive() == 1
-    del np
-    assert stats.alive() == 0
-
-    b = m.TypeForHolderWithAddressOf.make()
-    c = b
-    assert b.get() is c.get()
-    assert stats.alive() == 1
-
-    del b
-    assert stats.alive() == 1
-
-    del c
-    assert stats.alive() == 0
-
-
-def test_move_only_holder_with_addressof_operator():
-    a = m.TypeForMoveOnlyHolderWithAddressOf.make()
-    a.print_object()
-
-    stats = ConstructorStats.get(m.TypeForMoveOnlyHolderWithAddressOf)
-    assert stats.alive() == 1
-
-    a.value = 42
-    assert a.value == 42
-
-    del a
-    assert stats.alive() == 0
-
-
-def test_smart_ptr_from_default():
-    instance = m.HeldByDefaultHolder()
-    with pytest.raises(RuntimeError) as excinfo:
-        m.HeldByDefaultHolder.load_shared_ptr(instance)
-    assert (
-        "Unable to load a custom holder type from a "
-        "default-holder instance" in str(excinfo.value)
-    )
-
-
-def test_shared_ptr_gc():
-    """#187: issue involving std::shared_ptr<> return value policy & garbage collection"""
-    el = m.ElementList()
-    for i in range(10):
-        el.add(m.ElementA(i))
-    pytest.gc_collect()
-    for i, v in enumerate(el.get()):
-        assert i == v.value()
+import pytest
+
+m = pytest.importorskip("pybind11_tests.smart_ptr")
+from pybind11_tests import ConstructorStats  # noqa: E402
+
+
+def test_smart_ptr(capture):
+    # Object1
+    for i, o in enumerate(
+        [m.make_object_1(), m.make_object_2(), m.MyObject1(3)], start=1
+    ):
+        assert o.getRefCount() == 1
+        with capture:
+            m.print_object_1(o)
+            m.print_object_2(o)
+            m.print_object_3(o)
+            m.print_object_4(o)
+        assert capture == f"MyObject1[{i}]\n" * 4
+
+    for i, o in enumerate(
+        [m.make_myobject1_1(), m.make_myobject1_2(), m.MyObject1(6), 7], start=4
+    ):
+        print(o)
+        with capture:
+            if not isinstance(o, int):
+                m.print_object_1(o)
+                m.print_object_2(o)
+                m.print_object_3(o)
+                m.print_object_4(o)
+            m.print_myobject1_1(o)
+            m.print_myobject1_2(o)
+            m.print_myobject1_3(o)
+            m.print_myobject1_4(o)
+
+        times = 4 if isinstance(o, int) else 8
+        assert capture == f"MyObject1[{i}]\n" * times
+
+    cstats = ConstructorStats.get(m.MyObject1)
+    assert cstats.alive() == 0
+    expected_values = [f"MyObject1[{i}]" for i in range(1, 7)] + ["MyObject1[7]"] * 4
+    assert cstats.values() == expected_values
+    assert cstats.default_constructions == 0
+    assert cstats.copy_constructions == 0
+    # assert cstats.move_constructions >= 0 # Doesn't invoke any
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+    # Object2
+    for i, o in zip(
+        [8, 6, 7], [m.MyObject2(8), m.make_myobject2_1(), m.make_myobject2_2()]
+    ):
+        print(o)
+        with capture:
+            m.print_myobject2_1(o)
+            m.print_myobject2_2(o)
+            m.print_myobject2_3(o)
+            m.print_myobject2_4(o)
+        assert capture == f"MyObject2[{i}]\n" * 4
+
+    cstats = ConstructorStats.get(m.MyObject2)
+    assert cstats.alive() == 1
+    o = None
+    assert cstats.alive() == 0
+    assert cstats.values() == ["MyObject2[8]", "MyObject2[6]", "MyObject2[7]"]
+    assert cstats.default_constructions == 0
+    assert cstats.copy_constructions == 0
+    # assert cstats.move_constructions >= 0 # Doesn't invoke any
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+    # Object3
+    for i, o in zip(
+        [9, 8, 9], [m.MyObject3(9), m.make_myobject3_1(), m.make_myobject3_2()]
+    ):
+        print(o)
+        with capture:
+            m.print_myobject3_1(o)
+            m.print_myobject3_2(o)
+            m.print_myobject3_3(o)
+            m.print_myobject3_4(o)
+        assert capture == f"MyObject3[{i}]\n" * 4
+
+    cstats = ConstructorStats.get(m.MyObject3)
+    assert cstats.alive() == 1
+    o = None
+    assert cstats.alive() == 0
+    assert cstats.values() == ["MyObject3[9]", "MyObject3[8]", "MyObject3[9]"]
+    assert cstats.default_constructions == 0
+    assert cstats.copy_constructions == 0
+    # assert cstats.move_constructions >= 0 # Doesn't invoke any
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+    # Object
+    cstats = ConstructorStats.get(m.Object)
+    assert cstats.alive() == 0
+    assert cstats.values() == []
+    assert cstats.default_constructions == 10
+    assert cstats.copy_constructions == 0
+    # assert cstats.move_constructions >= 0 # Doesn't invoke any
+    assert cstats.copy_assignments == 0
+    assert cstats.move_assignments == 0
+
+    # ref<>
+    cstats = m.cstats_ref()
+    assert cstats.alive() == 0
+    assert cstats.values() == ["from pointer"] * 10
+    assert cstats.default_constructions == 30
+    assert cstats.copy_constructions == 12
+    # assert cstats.move_constructions >= 0 # Doesn't invoke any
+    assert cstats.copy_assignments == 30
+    assert cstats.move_assignments == 0
+
+
+def test_smart_ptr_refcounting():
+    assert m.test_object1_refcounting()
+
+
+def test_unique_nodelete():
+    o = m.MyObject4(23)
+    assert o.value == 23
+    cstats = ConstructorStats.get(m.MyObject4)
+    assert cstats.alive() == 1
+    del o
+    assert cstats.alive() == 1
+    m.MyObject4.cleanup_all_instances()
+    assert cstats.alive() == 0
+
+
+def test_unique_nodelete4a():
+    o = m.MyObject4a(23)
+    assert o.value == 23
+    cstats = ConstructorStats.get(m.MyObject4a)
+    assert cstats.alive() == 1
+    del o
+    assert cstats.alive() == 1
+    m.MyObject4a.cleanup_all_instances()
+    assert cstats.alive() == 0
+
+
+def test_unique_deleter():
+    m.MyObject4a(0)
+    o = m.MyObject4b(23)
+    assert o.value == 23
+    cstats4a = ConstructorStats.get(m.MyObject4a)
+    assert cstats4a.alive() == 2
+    cstats4b = ConstructorStats.get(m.MyObject4b)
+    assert cstats4b.alive() == 1
+    del o
+    assert cstats4a.alive() == 1  # Should now only be one leftover
+    assert cstats4b.alive() == 0  # Should be deleted
+    m.MyObject4a.cleanup_all_instances()
+    assert cstats4a.alive() == 0
+    assert cstats4b.alive() == 0
+
+
+def test_large_holder():
+    o = m.MyObject5(5)
+    assert o.value == 5
+    cstats = ConstructorStats.get(m.MyObject5)
+    assert cstats.alive() == 1
+    del o
+    assert cstats.alive() == 0
+
+
+def test_shared_ptr_and_references():
+    s = m.SharedPtrRef()
+    stats = ConstructorStats.get(m.A)
+    assert stats.alive() == 2
+
+    ref = s.ref  # init_holder_helper(holder_ptr=false, owned=false)
+    assert stats.alive() == 2
+    assert s.set_ref(ref)
+    with pytest.raises(RuntimeError) as excinfo:
+        assert s.set_holder(ref)
+    assert "Unable to cast from non-held to held instance" in str(excinfo.value)
+
+    copy = s.copy  # init_holder_helper(holder_ptr=false, owned=true)
+    assert stats.alive() == 3
+    assert s.set_ref(copy)
+    assert s.set_holder(copy)
+
+    holder_ref = s.holder_ref  # init_holder_helper(holder_ptr=true, owned=false)
+    assert stats.alive() == 3
+    assert s.set_ref(holder_ref)
+    assert s.set_holder(holder_ref)
+
+    holder_copy = s.holder_copy  # init_holder_helper(holder_ptr=true, owned=true)
+    assert stats.alive() == 3
+    assert s.set_ref(holder_copy)
+    assert s.set_holder(holder_copy)
+
+    del ref, copy, holder_ref, holder_copy, s
+    assert stats.alive() == 0
+
+
+def test_shared_ptr_from_this_and_references():
+    s = m.SharedFromThisRef()
+    stats = ConstructorStats.get(m.B)
+    assert stats.alive() == 2
+
+    ref = s.ref  # init_holder_helper(holder_ptr=false, owned=false, bad_wp=false)
+    assert stats.alive() == 2
+    assert s.set_ref(ref)
+    assert s.set_holder(
+        ref
+    )  # std::enable_shared_from_this can create a holder from a reference
+
+    bad_wp = s.bad_wp  # init_holder_helper(holder_ptr=false, owned=false, bad_wp=true)
+    assert stats.alive() == 2
+    assert s.set_ref(bad_wp)
+    with pytest.raises(RuntimeError) as excinfo:
+        assert s.set_holder(bad_wp)
+    assert "Unable to cast from non-held to held instance" in str(excinfo.value)
+
+    copy = s.copy  # init_holder_helper(holder_ptr=false, owned=true, bad_wp=false)
+    assert stats.alive() == 3
+    assert s.set_ref(copy)
+    assert s.set_holder(copy)
+
+    holder_ref = (
+        s.holder_ref
+    )  # init_holder_helper(holder_ptr=true, owned=false, bad_wp=false)
+    assert stats.alive() == 3
+    assert s.set_ref(holder_ref)
+    assert s.set_holder(holder_ref)
+
+    holder_copy = (
+        s.holder_copy
+    )  # init_holder_helper(holder_ptr=true, owned=true, bad_wp=false)
+    assert stats.alive() == 3
+    assert s.set_ref(holder_copy)
+    assert s.set_holder(holder_copy)
+
+    del ref, bad_wp, copy, holder_ref, holder_copy, s
+    assert stats.alive() == 0
+
+    z = m.SharedFromThisVirt.get()
+    y = m.SharedFromThisVirt.get()
+    assert y is z
+
+
+def test_move_only_holder():
+    a = m.TypeWithMoveOnlyHolder.make()
+    b = m.TypeWithMoveOnlyHolder.make_as_object()
+    stats = ConstructorStats.get(m.TypeWithMoveOnlyHolder)
+    assert stats.alive() == 2
+    del b
+    assert stats.alive() == 1
+    del a
+    assert stats.alive() == 0
+
+
+def test_holder_with_addressof_operator():
+    # this test must not throw exception from c++
+    a = m.TypeForHolderWithAddressOf.make()
+    a.print_object_1()
+    a.print_object_2()
+    a.print_object_3()
+    a.print_object_4()
+
+    stats = ConstructorStats.get(m.TypeForHolderWithAddressOf)
+    assert stats.alive() == 1
+
+    np = m.TypeForHolderWithAddressOf.make()
+    assert stats.alive() == 2
+    del a
+    assert stats.alive() == 1
+    del np
+    assert stats.alive() == 0
+
+    b = m.TypeForHolderWithAddressOf.make()
+    c = b
+    assert b.get() is c.get()
+    assert stats.alive() == 1
+
+    del b
+    assert stats.alive() == 1
+
+    del c
+    assert stats.alive() == 0
+
+
+def test_move_only_holder_with_addressof_operator():
+    a = m.TypeForMoveOnlyHolderWithAddressOf.make()
+    a.print_object()
+
+    stats = ConstructorStats.get(m.TypeForMoveOnlyHolderWithAddressOf)
+    assert stats.alive() == 1
+
+    a.value = 42
+    assert a.value == 42
+
+    del a
+    assert stats.alive() == 0
+
+
+def test_smart_ptr_from_default():
+    instance = m.HeldByDefaultHolder()
+    with pytest.raises(RuntimeError) as excinfo:
+        m.HeldByDefaultHolder.load_shared_ptr(instance)
+    assert (
+        "Unable to load a custom holder type from a "
+        "default-holder instance" in str(excinfo.value)
+    )
+
+
+def test_shared_ptr_gc():
+    """#187: issue involving std::shared_ptr<> return value policy & garbage collection"""
+    el = m.ElementList()
+    for i in range(10):
+        el.add(m.ElementA(i))
+    pytest.gc_collect()
+    for i, v in enumerate(el.get()):
+        assert i == v.value()
```

## extern/pybind11/tests/test_stl.py

 * *Ordering differences only*

```diff
@@ -1,381 +1,381 @@
-import pytest
-
-from pybind11_tests import ConstructorStats, UserType
-from pybind11_tests import stl as m
-
-
-def test_vector(doc):
-    """std::vector <-> list"""
-    lst = m.cast_vector()
-    assert lst == [1]
-    lst.append(2)
-    assert m.load_vector(lst)
-    assert m.load_vector(tuple(lst))
-
-    assert m.cast_bool_vector() == [True, False]
-    assert m.load_bool_vector([True, False])
-    assert m.load_bool_vector((True, False))
-
-    assert doc(m.cast_vector) == "cast_vector() -> list[int]"
-    assert doc(m.load_vector) == "load_vector(arg0: list[int]) -> bool"
-
-    # Test regression caused by 936: pointers to stl containers weren't castable
-    assert m.cast_ptr_vector() == ["lvalue", "lvalue"]
-
-
-def test_deque():
-    """std::deque <-> list"""
-    lst = m.cast_deque()
-    assert lst == [1]
-    lst.append(2)
-    assert m.load_deque(lst)
-    assert m.load_deque(tuple(lst))
-
-
-def test_array(doc):
-    """std::array <-> list"""
-    lst = m.cast_array()
-    assert lst == [1, 2]
-    assert m.load_array(lst)
-    assert m.load_array(tuple(lst))
-
-    assert doc(m.cast_array) == "cast_array() -> Annotated[list[int], FixedSize(2)]"
-    assert (
-        doc(m.load_array)
-        == "load_array(arg0: Annotated[list[int], FixedSize(2)]) -> bool"
-    )
-
-
-def test_valarray(doc):
-    """std::valarray <-> list"""
-    lst = m.cast_valarray()
-    assert lst == [1, 4, 9]
-    assert m.load_valarray(lst)
-    assert m.load_valarray(tuple(lst))
-
-    assert doc(m.cast_valarray) == "cast_valarray() -> list[int]"
-    assert doc(m.load_valarray) == "load_valarray(arg0: list[int]) -> bool"
-
-
-def test_map(doc):
-    """std::map <-> dict"""
-    d = m.cast_map()
-    assert d == {"key": "value"}
-    assert "key" in d
-    d["key2"] = "value2"
-    assert "key2" in d
-    assert m.load_map(d)
-
-    assert doc(m.cast_map) == "cast_map() -> dict[str, str]"
-    assert doc(m.load_map) == "load_map(arg0: dict[str, str]) -> bool"
-
-
-def test_set(doc):
-    """std::set <-> set"""
-    s = m.cast_set()
-    assert s == {"key1", "key2"}
-    s.add("key3")
-    assert m.load_set(s)
-    assert m.load_set(frozenset(s))
-
-    assert doc(m.cast_set) == "cast_set() -> set[str]"
-    assert doc(m.load_set) == "load_set(arg0: set[str]) -> bool"
-
-
-def test_recursive_casting():
-    """Tests that stl casters preserve lvalue/rvalue context for container values"""
-    assert m.cast_rv_vector() == ["rvalue", "rvalue"]
-    assert m.cast_lv_vector() == ["lvalue", "lvalue"]
-    assert m.cast_rv_array() == ["rvalue", "rvalue", "rvalue"]
-    assert m.cast_lv_array() == ["lvalue", "lvalue"]
-    assert m.cast_rv_map() == {"a": "rvalue"}
-    assert m.cast_lv_map() == {"a": "lvalue", "b": "lvalue"}
-    assert m.cast_rv_nested() == [[[{"b": "rvalue", "c": "rvalue"}], [{"a": "rvalue"}]]]
-    assert m.cast_lv_nested() == {
-        "a": [[["lvalue", "lvalue"]], [["lvalue", "lvalue"]]],
-        "b": [[["lvalue", "lvalue"], ["lvalue", "lvalue"]]],
-    }
-
-    # Issue #853 test case:
-    z = m.cast_unique_ptr_vector()
-    assert z[0].value == 7
-    assert z[1].value == 42
-
-
-def test_move_out_container():
-    """Properties use the `reference_internal` policy by default. If the underlying function
-    returns an rvalue, the policy is automatically changed to `move` to avoid referencing
-    a temporary. In case the return value is a container of user-defined types, the policy
-    also needs to be applied to the elements, not just the container."""
-    c = m.MoveOutContainer()
-    moved_out_list = c.move_list
-    assert [x.value for x in moved_out_list] == [0, 1, 2]
-
-
-@pytest.mark.skipif(not hasattr(m, "has_optional"), reason="no <optional>")
-def test_optional():
-    assert m.double_or_zero(None) == 0
-    assert m.double_or_zero(42) == 84
-    pytest.raises(TypeError, m.double_or_zero, "foo")
-
-    assert m.half_or_none(0) is None
-    assert m.half_or_none(42) == 21
-    pytest.raises(TypeError, m.half_or_none, "foo")
-
-    assert m.test_nullopt() == 42
-    assert m.test_nullopt(None) == 42
-    assert m.test_nullopt(42) == 42
-    assert m.test_nullopt(43) == 43
-
-    assert m.test_no_assign() == 42
-    assert m.test_no_assign(None) == 42
-    assert m.test_no_assign(m.NoAssign(43)) == 43
-    pytest.raises(TypeError, m.test_no_assign, 43)
-
-    assert m.nodefer_none_optional(None)
-
-    holder = m.OptionalHolder()
-    mvalue = holder.member
-    assert mvalue.initialized
-    assert holder.member_initialized()
-
-    props = m.OptionalProperties()
-    assert int(props.access_by_ref) == 42
-    assert int(props.access_by_copy) == 42
-
-
-@pytest.mark.skipif(
-    not hasattr(m, "has_exp_optional"), reason="no <experimental/optional>"
-)
-def test_exp_optional():
-    assert m.double_or_zero_exp(None) == 0
-    assert m.double_or_zero_exp(42) == 84
-    pytest.raises(TypeError, m.double_or_zero_exp, "foo")
-
-    assert m.half_or_none_exp(0) is None
-    assert m.half_or_none_exp(42) == 21
-    pytest.raises(TypeError, m.half_or_none_exp, "foo")
-
-    assert m.test_nullopt_exp() == 42
-    assert m.test_nullopt_exp(None) == 42
-    assert m.test_nullopt_exp(42) == 42
-    assert m.test_nullopt_exp(43) == 43
-
-    assert m.test_no_assign_exp() == 42
-    assert m.test_no_assign_exp(None) == 42
-    assert m.test_no_assign_exp(m.NoAssign(43)) == 43
-    pytest.raises(TypeError, m.test_no_assign_exp, 43)
-
-    holder = m.OptionalExpHolder()
-    mvalue = holder.member
-    assert mvalue.initialized
-    assert holder.member_initialized()
-
-    props = m.OptionalExpProperties()
-    assert int(props.access_by_ref) == 42
-    assert int(props.access_by_copy) == 42
-
-
-@pytest.mark.skipif(not hasattr(m, "has_boost_optional"), reason="no <boost/optional>")
-def test_boost_optional():
-    assert m.double_or_zero_boost(None) == 0
-    assert m.double_or_zero_boost(42) == 84
-    pytest.raises(TypeError, m.double_or_zero_boost, "foo")
-
-    assert m.half_or_none_boost(0) is None
-    assert m.half_or_none_boost(42) == 21
-    pytest.raises(TypeError, m.half_or_none_boost, "foo")
-
-    assert m.test_nullopt_boost() == 42
-    assert m.test_nullopt_boost(None) == 42
-    assert m.test_nullopt_boost(42) == 42
-    assert m.test_nullopt_boost(43) == 43
-
-    assert m.test_no_assign_boost() == 42
-    assert m.test_no_assign_boost(None) == 42
-    assert m.test_no_assign_boost(m.NoAssign(43)) == 43
-    pytest.raises(TypeError, m.test_no_assign_boost, 43)
-
-    holder = m.OptionalBoostHolder()
-    mvalue = holder.member
-    assert mvalue.initialized
-    assert holder.member_initialized()
-
-    props = m.OptionalBoostProperties()
-    assert int(props.access_by_ref) == 42
-    assert int(props.access_by_copy) == 42
-
-
-def test_reference_sensitive_optional():
-    assert m.double_or_zero_refsensitive(None) == 0
-    assert m.double_or_zero_refsensitive(42) == 84
-    pytest.raises(TypeError, m.double_or_zero_refsensitive, "foo")
-
-    assert m.half_or_none_refsensitive(0) is None
-    assert m.half_or_none_refsensitive(42) == 21
-    pytest.raises(TypeError, m.half_or_none_refsensitive, "foo")
-
-    assert m.test_nullopt_refsensitive() == 42
-    assert m.test_nullopt_refsensitive(None) == 42
-    assert m.test_nullopt_refsensitive(42) == 42
-    assert m.test_nullopt_refsensitive(43) == 43
-
-    assert m.test_no_assign_refsensitive() == 42
-    assert m.test_no_assign_refsensitive(None) == 42
-    assert m.test_no_assign_refsensitive(m.NoAssign(43)) == 43
-    pytest.raises(TypeError, m.test_no_assign_refsensitive, 43)
-
-    holder = m.OptionalRefSensitiveHolder()
-    mvalue = holder.member
-    assert mvalue.initialized
-    assert holder.member_initialized()
-
-    props = m.OptionalRefSensitiveProperties()
-    assert int(props.access_by_ref) == 42
-    assert int(props.access_by_copy) == 42
-
-
-@pytest.mark.skipif(not hasattr(m, "has_filesystem"), reason="no <filesystem>")
-def test_fs_path():
-    from pathlib import Path
-
-    class PseudoStrPath:
-        def __fspath__(self):
-            return "foo/bar"
-
-    class PseudoBytesPath:
-        def __fspath__(self):
-            return b"foo/bar"
-
-    assert m.parent_path(Path("foo/bar")) == Path("foo")
-    assert m.parent_path("foo/bar") == Path("foo")
-    assert m.parent_path(b"foo/bar") == Path("foo")
-    assert m.parent_path(PseudoStrPath()) == Path("foo")
-    assert m.parent_path(PseudoBytesPath()) == Path("foo")
-
-
-@pytest.mark.skipif(not hasattr(m, "load_variant"), reason="no <variant>")
-def test_variant(doc):
-    assert m.load_variant(1) == "int"
-    assert m.load_variant("1") == "std::string"
-    assert m.load_variant(1.0) == "double"
-    assert m.load_variant(None) == "std::nullptr_t"
-
-    assert m.load_variant_2pass(1) == "int"
-    assert m.load_variant_2pass(1.0) == "double"
-
-    assert m.cast_variant() == (5, "Hello")
-
-    assert (
-        doc(m.load_variant) == "load_variant(arg0: Union[int, str, float, None]) -> str"
-    )
-
-
-@pytest.mark.skipif(
-    not hasattr(m, "load_monostate_variant"), reason="no std::monostate"
-)
-def test_variant_monostate(doc):
-    assert m.load_monostate_variant(None) == "std::monostate"
-    assert m.load_monostate_variant(1) == "int"
-    assert m.load_monostate_variant("1") == "std::string"
-
-    assert m.cast_monostate_variant() == (None, 5, "Hello")
-
-    assert (
-        doc(m.load_monostate_variant)
-        == "load_monostate_variant(arg0: Union[None, int, str]) -> str"
-    )
-
-
-def test_vec_of_reference_wrapper():
-    """#171: Can't return reference wrappers (or STL structures containing them)"""
-    assert (
-        str(m.return_vec_of_reference_wrapper(UserType(4)))
-        == "[UserType(1), UserType(2), UserType(3), UserType(4)]"
-    )
-
-
-def test_stl_pass_by_pointer(msg):
-    """Passing nullptr or None to an STL container pointer is not expected to work"""
-    with pytest.raises(TypeError) as excinfo:
-        m.stl_pass_by_pointer()  # default value is `nullptr`
-    assert (
-        msg(excinfo.value)
-        == """
-        stl_pass_by_pointer(): incompatible function arguments. The following argument types are supported:
-            1. (v: list[int] = None) -> list[int]
-
-        Invoked with:
-    """
-    )
-
-    with pytest.raises(TypeError) as excinfo:
-        m.stl_pass_by_pointer(None)
-    assert (
-        msg(excinfo.value)
-        == """
-        stl_pass_by_pointer(): incompatible function arguments. The following argument types are supported:
-            1. (v: list[int] = None) -> list[int]
-
-        Invoked with: None
-    """
-    )
-
-    assert m.stl_pass_by_pointer([1, 2, 3]) == [1, 2, 3]
-
-
-def test_missing_header_message():
-    """Trying convert `list` to a `std::vector`, or vice versa, without including
-    <pybind11/stl.h> should result in a helpful suggestion in the error message"""
-    import pybind11_cross_module_tests as cm
-
-    expected_message = (
-        "Did you forget to `#include <pybind11/stl.h>`? Or <pybind11/complex.h>,\n"
-        "<pybind11/functional.h>, <pybind11/chrono.h>, etc. Some automatic\n"
-        "conversions are optional and require extra headers to be included\n"
-        "when compiling your pybind11 module."
-    )
-
-    with pytest.raises(TypeError) as excinfo:
-        cm.missing_header_arg([1.0, 2.0, 3.0])
-    assert expected_message in str(excinfo.value)
-
-    with pytest.raises(TypeError) as excinfo:
-        cm.missing_header_return()
-    assert expected_message in str(excinfo.value)
-
-
-def test_function_with_string_and_vector_string_arg():
-    """Check if a string is NOT implicitly converted to a list, which was the
-    behavior before fix of issue #1258"""
-    assert m.func_with_string_or_vector_string_arg_overload(("A", "B")) == 2
-    assert m.func_with_string_or_vector_string_arg_overload(["A", "B"]) == 2
-    assert m.func_with_string_or_vector_string_arg_overload("A") == 3
-
-
-def test_stl_ownership():
-    cstats = ConstructorStats.get(m.Placeholder)
-    assert cstats.alive() == 0
-    r = m.test_stl_ownership()
-    assert len(r) == 1
-    del r
-    assert cstats.alive() == 0
-
-
-def test_array_cast_sequence():
-    assert m.array_cast_sequence((1, 2, 3)) == [1, 2, 3]
-
-
-def test_issue_1561():
-    """check fix for issue #1561"""
-    bar = m.Issue1561Outer()
-    bar.list = [m.Issue1561Inner("bar")]
-    assert bar.list
-    assert bar.list[0].data == "bar"
-
-
-def test_return_vector_bool_raw_ptr():
-    # Add `while True:` for manual leak checking.
-    v = m.return_vector_bool_raw_ptr()
-    assert isinstance(v, list)
-    assert len(v) == 4513
+import pytest
+
+from pybind11_tests import ConstructorStats, UserType
+from pybind11_tests import stl as m
+
+
+def test_vector(doc):
+    """std::vector <-> list"""
+    lst = m.cast_vector()
+    assert lst == [1]
+    lst.append(2)
+    assert m.load_vector(lst)
+    assert m.load_vector(tuple(lst))
+
+    assert m.cast_bool_vector() == [True, False]
+    assert m.load_bool_vector([True, False])
+    assert m.load_bool_vector((True, False))
+
+    assert doc(m.cast_vector) == "cast_vector() -> list[int]"
+    assert doc(m.load_vector) == "load_vector(arg0: list[int]) -> bool"
+
+    # Test regression caused by 936: pointers to stl containers weren't castable
+    assert m.cast_ptr_vector() == ["lvalue", "lvalue"]
+
+
+def test_deque():
+    """std::deque <-> list"""
+    lst = m.cast_deque()
+    assert lst == [1]
+    lst.append(2)
+    assert m.load_deque(lst)
+    assert m.load_deque(tuple(lst))
+
+
+def test_array(doc):
+    """std::array <-> list"""
+    lst = m.cast_array()
+    assert lst == [1, 2]
+    assert m.load_array(lst)
+    assert m.load_array(tuple(lst))
+
+    assert doc(m.cast_array) == "cast_array() -> Annotated[list[int], FixedSize(2)]"
+    assert (
+        doc(m.load_array)
+        == "load_array(arg0: Annotated[list[int], FixedSize(2)]) -> bool"
+    )
+
+
+def test_valarray(doc):
+    """std::valarray <-> list"""
+    lst = m.cast_valarray()
+    assert lst == [1, 4, 9]
+    assert m.load_valarray(lst)
+    assert m.load_valarray(tuple(lst))
+
+    assert doc(m.cast_valarray) == "cast_valarray() -> list[int]"
+    assert doc(m.load_valarray) == "load_valarray(arg0: list[int]) -> bool"
+
+
+def test_map(doc):
+    """std::map <-> dict"""
+    d = m.cast_map()
+    assert d == {"key": "value"}
+    assert "key" in d
+    d["key2"] = "value2"
+    assert "key2" in d
+    assert m.load_map(d)
+
+    assert doc(m.cast_map) == "cast_map() -> dict[str, str]"
+    assert doc(m.load_map) == "load_map(arg0: dict[str, str]) -> bool"
+
+
+def test_set(doc):
+    """std::set <-> set"""
+    s = m.cast_set()
+    assert s == {"key1", "key2"}
+    s.add("key3")
+    assert m.load_set(s)
+    assert m.load_set(frozenset(s))
+
+    assert doc(m.cast_set) == "cast_set() -> set[str]"
+    assert doc(m.load_set) == "load_set(arg0: set[str]) -> bool"
+
+
+def test_recursive_casting():
+    """Tests that stl casters preserve lvalue/rvalue context for container values"""
+    assert m.cast_rv_vector() == ["rvalue", "rvalue"]
+    assert m.cast_lv_vector() == ["lvalue", "lvalue"]
+    assert m.cast_rv_array() == ["rvalue", "rvalue", "rvalue"]
+    assert m.cast_lv_array() == ["lvalue", "lvalue"]
+    assert m.cast_rv_map() == {"a": "rvalue"}
+    assert m.cast_lv_map() == {"a": "lvalue", "b": "lvalue"}
+    assert m.cast_rv_nested() == [[[{"b": "rvalue", "c": "rvalue"}], [{"a": "rvalue"}]]]
+    assert m.cast_lv_nested() == {
+        "a": [[["lvalue", "lvalue"]], [["lvalue", "lvalue"]]],
+        "b": [[["lvalue", "lvalue"], ["lvalue", "lvalue"]]],
+    }
+
+    # Issue #853 test case:
+    z = m.cast_unique_ptr_vector()
+    assert z[0].value == 7
+    assert z[1].value == 42
+
+
+def test_move_out_container():
+    """Properties use the `reference_internal` policy by default. If the underlying function
+    returns an rvalue, the policy is automatically changed to `move` to avoid referencing
+    a temporary. In case the return value is a container of user-defined types, the policy
+    also needs to be applied to the elements, not just the container."""
+    c = m.MoveOutContainer()
+    moved_out_list = c.move_list
+    assert [x.value for x in moved_out_list] == [0, 1, 2]
+
+
+@pytest.mark.skipif(not hasattr(m, "has_optional"), reason="no <optional>")
+def test_optional():
+    assert m.double_or_zero(None) == 0
+    assert m.double_or_zero(42) == 84
+    pytest.raises(TypeError, m.double_or_zero, "foo")
+
+    assert m.half_or_none(0) is None
+    assert m.half_or_none(42) == 21
+    pytest.raises(TypeError, m.half_or_none, "foo")
+
+    assert m.test_nullopt() == 42
+    assert m.test_nullopt(None) == 42
+    assert m.test_nullopt(42) == 42
+    assert m.test_nullopt(43) == 43
+
+    assert m.test_no_assign() == 42
+    assert m.test_no_assign(None) == 42
+    assert m.test_no_assign(m.NoAssign(43)) == 43
+    pytest.raises(TypeError, m.test_no_assign, 43)
+
+    assert m.nodefer_none_optional(None)
+
+    holder = m.OptionalHolder()
+    mvalue = holder.member
+    assert mvalue.initialized
+    assert holder.member_initialized()
+
+    props = m.OptionalProperties()
+    assert int(props.access_by_ref) == 42
+    assert int(props.access_by_copy) == 42
+
+
+@pytest.mark.skipif(
+    not hasattr(m, "has_exp_optional"), reason="no <experimental/optional>"
+)
+def test_exp_optional():
+    assert m.double_or_zero_exp(None) == 0
+    assert m.double_or_zero_exp(42) == 84
+    pytest.raises(TypeError, m.double_or_zero_exp, "foo")
+
+    assert m.half_or_none_exp(0) is None
+    assert m.half_or_none_exp(42) == 21
+    pytest.raises(TypeError, m.half_or_none_exp, "foo")
+
+    assert m.test_nullopt_exp() == 42
+    assert m.test_nullopt_exp(None) == 42
+    assert m.test_nullopt_exp(42) == 42
+    assert m.test_nullopt_exp(43) == 43
+
+    assert m.test_no_assign_exp() == 42
+    assert m.test_no_assign_exp(None) == 42
+    assert m.test_no_assign_exp(m.NoAssign(43)) == 43
+    pytest.raises(TypeError, m.test_no_assign_exp, 43)
+
+    holder = m.OptionalExpHolder()
+    mvalue = holder.member
+    assert mvalue.initialized
+    assert holder.member_initialized()
+
+    props = m.OptionalExpProperties()
+    assert int(props.access_by_ref) == 42
+    assert int(props.access_by_copy) == 42
+
+
+@pytest.mark.skipif(not hasattr(m, "has_boost_optional"), reason="no <boost/optional>")
+def test_boost_optional():
+    assert m.double_or_zero_boost(None) == 0
+    assert m.double_or_zero_boost(42) == 84
+    pytest.raises(TypeError, m.double_or_zero_boost, "foo")
+
+    assert m.half_or_none_boost(0) is None
+    assert m.half_or_none_boost(42) == 21
+    pytest.raises(TypeError, m.half_or_none_boost, "foo")
+
+    assert m.test_nullopt_boost() == 42
+    assert m.test_nullopt_boost(None) == 42
+    assert m.test_nullopt_boost(42) == 42
+    assert m.test_nullopt_boost(43) == 43
+
+    assert m.test_no_assign_boost() == 42
+    assert m.test_no_assign_boost(None) == 42
+    assert m.test_no_assign_boost(m.NoAssign(43)) == 43
+    pytest.raises(TypeError, m.test_no_assign_boost, 43)
+
+    holder = m.OptionalBoostHolder()
+    mvalue = holder.member
+    assert mvalue.initialized
+    assert holder.member_initialized()
+
+    props = m.OptionalBoostProperties()
+    assert int(props.access_by_ref) == 42
+    assert int(props.access_by_copy) == 42
+
+
+def test_reference_sensitive_optional():
+    assert m.double_or_zero_refsensitive(None) == 0
+    assert m.double_or_zero_refsensitive(42) == 84
+    pytest.raises(TypeError, m.double_or_zero_refsensitive, "foo")
+
+    assert m.half_or_none_refsensitive(0) is None
+    assert m.half_or_none_refsensitive(42) == 21
+    pytest.raises(TypeError, m.half_or_none_refsensitive, "foo")
+
+    assert m.test_nullopt_refsensitive() == 42
+    assert m.test_nullopt_refsensitive(None) == 42
+    assert m.test_nullopt_refsensitive(42) == 42
+    assert m.test_nullopt_refsensitive(43) == 43
+
+    assert m.test_no_assign_refsensitive() == 42
+    assert m.test_no_assign_refsensitive(None) == 42
+    assert m.test_no_assign_refsensitive(m.NoAssign(43)) == 43
+    pytest.raises(TypeError, m.test_no_assign_refsensitive, 43)
+
+    holder = m.OptionalRefSensitiveHolder()
+    mvalue = holder.member
+    assert mvalue.initialized
+    assert holder.member_initialized()
+
+    props = m.OptionalRefSensitiveProperties()
+    assert int(props.access_by_ref) == 42
+    assert int(props.access_by_copy) == 42
+
+
+@pytest.mark.skipif(not hasattr(m, "has_filesystem"), reason="no <filesystem>")
+def test_fs_path():
+    from pathlib import Path
+
+    class PseudoStrPath:
+        def __fspath__(self):
+            return "foo/bar"
+
+    class PseudoBytesPath:
+        def __fspath__(self):
+            return b"foo/bar"
+
+    assert m.parent_path(Path("foo/bar")) == Path("foo")
+    assert m.parent_path("foo/bar") == Path("foo")
+    assert m.parent_path(b"foo/bar") == Path("foo")
+    assert m.parent_path(PseudoStrPath()) == Path("foo")
+    assert m.parent_path(PseudoBytesPath()) == Path("foo")
+
+
+@pytest.mark.skipif(not hasattr(m, "load_variant"), reason="no <variant>")
+def test_variant(doc):
+    assert m.load_variant(1) == "int"
+    assert m.load_variant("1") == "std::string"
+    assert m.load_variant(1.0) == "double"
+    assert m.load_variant(None) == "std::nullptr_t"
+
+    assert m.load_variant_2pass(1) == "int"
+    assert m.load_variant_2pass(1.0) == "double"
+
+    assert m.cast_variant() == (5, "Hello")
+
+    assert (
+        doc(m.load_variant) == "load_variant(arg0: Union[int, str, float, None]) -> str"
+    )
+
+
+@pytest.mark.skipif(
+    not hasattr(m, "load_monostate_variant"), reason="no std::monostate"
+)
+def test_variant_monostate(doc):
+    assert m.load_monostate_variant(None) == "std::monostate"
+    assert m.load_monostate_variant(1) == "int"
+    assert m.load_monostate_variant("1") == "std::string"
+
+    assert m.cast_monostate_variant() == (None, 5, "Hello")
+
+    assert (
+        doc(m.load_monostate_variant)
+        == "load_monostate_variant(arg0: Union[None, int, str]) -> str"
+    )
+
+
+def test_vec_of_reference_wrapper():
+    """#171: Can't return reference wrappers (or STL structures containing them)"""
+    assert (
+        str(m.return_vec_of_reference_wrapper(UserType(4)))
+        == "[UserType(1), UserType(2), UserType(3), UserType(4)]"
+    )
+
+
+def test_stl_pass_by_pointer(msg):
+    """Passing nullptr or None to an STL container pointer is not expected to work"""
+    with pytest.raises(TypeError) as excinfo:
+        m.stl_pass_by_pointer()  # default value is `nullptr`
+    assert (
+        msg(excinfo.value)
+        == """
+        stl_pass_by_pointer(): incompatible function arguments. The following argument types are supported:
+            1. (v: list[int] = None) -> list[int]
+
+        Invoked with:
+    """
+    )
+
+    with pytest.raises(TypeError) as excinfo:
+        m.stl_pass_by_pointer(None)
+    assert (
+        msg(excinfo.value)
+        == """
+        stl_pass_by_pointer(): incompatible function arguments. The following argument types are supported:
+            1. (v: list[int] = None) -> list[int]
+
+        Invoked with: None
+    """
+    )
+
+    assert m.stl_pass_by_pointer([1, 2, 3]) == [1, 2, 3]
+
+
+def test_missing_header_message():
+    """Trying convert `list` to a `std::vector`, or vice versa, without including
+    <pybind11/stl.h> should result in a helpful suggestion in the error message"""
+    import pybind11_cross_module_tests as cm
+
+    expected_message = (
+        "Did you forget to `#include <pybind11/stl.h>`? Or <pybind11/complex.h>,\n"
+        "<pybind11/functional.h>, <pybind11/chrono.h>, etc. Some automatic\n"
+        "conversions are optional and require extra headers to be included\n"
+        "when compiling your pybind11 module."
+    )
+
+    with pytest.raises(TypeError) as excinfo:
+        cm.missing_header_arg([1.0, 2.0, 3.0])
+    assert expected_message in str(excinfo.value)
+
+    with pytest.raises(TypeError) as excinfo:
+        cm.missing_header_return()
+    assert expected_message in str(excinfo.value)
+
+
+def test_function_with_string_and_vector_string_arg():
+    """Check if a string is NOT implicitly converted to a list, which was the
+    behavior before fix of issue #1258"""
+    assert m.func_with_string_or_vector_string_arg_overload(("A", "B")) == 2
+    assert m.func_with_string_or_vector_string_arg_overload(["A", "B"]) == 2
+    assert m.func_with_string_or_vector_string_arg_overload("A") == 3
+
+
+def test_stl_ownership():
+    cstats = ConstructorStats.get(m.Placeholder)
+    assert cstats.alive() == 0
+    r = m.test_stl_ownership()
+    assert len(r) == 1
+    del r
+    assert cstats.alive() == 0
+
+
+def test_array_cast_sequence():
+    assert m.array_cast_sequence((1, 2, 3)) == [1, 2, 3]
+
+
+def test_issue_1561():
+    """check fix for issue #1561"""
+    bar = m.Issue1561Outer()
+    bar.list = [m.Issue1561Inner("bar")]
+    assert bar.list
+    assert bar.list[0].data == "bar"
+
+
+def test_return_vector_bool_raw_ptr():
+    # Add `while True:` for manual leak checking.
+    v = m.return_vector_bool_raw_ptr()
+    assert isinstance(v, list)
+    assert len(v) == 4513
```

## extern/pybind11/tests/test_stl_binders.py

 * *Ordering differences only*

```diff
@@ -1,355 +1,355 @@
-import pytest
-
-from pybind11_tests import stl_binders as m
-
-
-def test_vector_int():
-    v_int = m.VectorInt([0, 0])
-    assert len(v_int) == 2
-    assert bool(v_int) is True
-
-    # test construction from a generator
-    v_int1 = m.VectorInt(x for x in range(5))
-    assert v_int1 == m.VectorInt([0, 1, 2, 3, 4])
-
-    v_int2 = m.VectorInt([0, 0])
-    assert v_int == v_int2
-    v_int2[1] = 1
-    assert v_int != v_int2
-
-    v_int2.append(2)
-    v_int2.insert(0, 1)
-    v_int2.insert(0, 2)
-    v_int2.insert(0, 3)
-    v_int2.insert(6, 3)
-    assert str(v_int2) == "VectorInt[3, 2, 1, 0, 1, 2, 3]"
-    with pytest.raises(IndexError):
-        v_int2.insert(8, 4)
-
-    v_int.append(99)
-    v_int2[2:-2] = v_int
-    assert v_int2 == m.VectorInt([3, 2, 0, 0, 99, 2, 3])
-    del v_int2[1:3]
-    assert v_int2 == m.VectorInt([3, 0, 99, 2, 3])
-    del v_int2[0]
-    assert v_int2 == m.VectorInt([0, 99, 2, 3])
-
-    v_int2.extend(m.VectorInt([4, 5]))
-    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5])
-
-    v_int2.extend([6, 7])
-    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7])
-
-    # test error handling, and that the vector is unchanged
-    with pytest.raises(RuntimeError):
-        v_int2.extend([8, "a"])
-
-    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7])
-
-    # test extending from a generator
-    v_int2.extend(x for x in range(5))
-    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4])
-
-    # test negative indexing
-    assert v_int2[-1] == 4
-
-    # insert with negative index
-    v_int2.insert(-1, 88)
-    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 88, 4])
-
-    # delete negative index
-    del v_int2[-1]
-    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 88])
-
-    v_int2.clear()
-    assert len(v_int2) == 0
-
-
-# Older PyPy's failed here, related to the PyPy's buffer protocol.
-def test_vector_buffer():
-    b = bytearray([1, 2, 3, 4])
-    v = m.VectorUChar(b)
-    assert v[1] == 2
-    v[2] = 5
-    mv = memoryview(v)  # We expose the buffer interface
-    assert mv[2] == 5
-    mv[2] = 6
-    assert v[2] == 6
-
-    mv = memoryview(b)
-    v = m.VectorUChar(mv[::2])
-    assert v[1] == 3
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.create_undeclstruct()  # Undeclared struct contents, no buffer interface
-    assert "NumPy type info missing for " in str(excinfo.value)
-
-
-def test_vector_buffer_numpy():
-    np = pytest.importorskip("numpy")
-    a = np.array([1, 2, 3, 4], dtype=np.int32)
-    with pytest.raises(TypeError):
-        m.VectorInt(a)
-
-    a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], dtype=np.uintc)
-    v = m.VectorInt(a[0, :])
-    assert len(v) == 4
-    assert v[2] == 3
-    ma = np.asarray(v)
-    ma[2] = 5
-    assert v[2] == 5
-
-    v = m.VectorInt(a[:, 1])
-    assert len(v) == 3
-    assert v[2] == 10
-
-    v = m.get_vectorstruct()
-    assert v[0].x == 5
-    ma = np.asarray(v)
-    ma[1]["x"] = 99
-    assert v[1].x == 99
-
-    v = m.VectorStruct(
-        np.zeros(
-            3,
-            dtype=np.dtype(
-                [("w", "bool"), ("x", "I"), ("y", "float64"), ("z", "bool")], align=True
-            ),
-        )
-    )
-    assert len(v) == 3
-
-    b = np.array([1, 2, 3, 4], dtype=np.uint8)
-    v = m.VectorUChar(b[::2])
-    assert v[1] == 3
-
-
-def test_vector_bool():
-    import pybind11_cross_module_tests as cm
-
-    vv_c = cm.VectorBool()
-    for i in range(10):
-        vv_c.append(i % 2 == 0)
-    for i in range(10):
-        assert vv_c[i] == (i % 2 == 0)
-    assert str(vv_c) == "VectorBool[1, 0, 1, 0, 1, 0, 1, 0, 1, 0]"
-
-
-def test_vector_custom():
-    v_a = m.VectorEl()
-    v_a.append(m.El(1))
-    v_a.append(m.El(2))
-    assert str(v_a) == "VectorEl[El{1}, El{2}]"
-
-    vv_a = m.VectorVectorEl()
-    vv_a.append(v_a)
-    vv_b = vv_a[0]
-    assert str(vv_b) == "VectorEl[El{1}, El{2}]"
-
-
-def test_map_string_double():
-    mm = m.MapStringDouble()
-    mm["a"] = 1
-    mm["b"] = 2.5
-
-    assert list(mm) == ["a", "b"]
-    assert str(mm) == "MapStringDouble{a: 1, b: 2.5}"
-    assert "b" in mm
-    assert "c" not in mm
-    assert 123 not in mm
-
-    # Check that keys, values, items are views, not merely iterable
-    keys = mm.keys()
-    values = mm.values()
-    items = mm.items()
-    assert list(keys) == ["a", "b"]
-    assert len(keys) == 2
-    assert "a" in keys
-    assert "c" not in keys
-    assert 123 not in keys
-    assert list(items) == [("a", 1), ("b", 2.5)]
-    assert len(items) == 2
-    assert ("b", 2.5) in items
-    assert "hello" not in items
-    assert ("b", 2.5, None) not in items
-    assert list(values) == [1, 2.5]
-    assert len(values) == 2
-    assert 1 in values
-    assert 2 not in values
-    # Check that views update when the map is updated
-    mm["c"] = -1
-    assert list(keys) == ["a", "b", "c"]
-    assert list(values) == [1, 2.5, -1]
-    assert list(items) == [("a", 1), ("b", 2.5), ("c", -1)]
-
-    um = m.UnorderedMapStringDouble()
-    um["ua"] = 1.1
-    um["ub"] = 2.6
-
-    assert sorted(um) == ["ua", "ub"]
-    assert list(um.keys()) == list(um)
-    assert sorted(um.items()) == [("ua", 1.1), ("ub", 2.6)]
-    assert list(zip(um.keys(), um.values())) == list(um.items())
-    assert "UnorderedMapStringDouble" in str(um)
-
-
-def test_map_string_double_const():
-    mc = m.MapStringDoubleConst()
-    mc["a"] = 10
-    mc["b"] = 20.5
-    assert str(mc) == "MapStringDoubleConst{a: 10, b: 20.5}"
-
-    umc = m.UnorderedMapStringDoubleConst()
-    umc["a"] = 11
-    umc["b"] = 21.5
-
-    str(umc)
-
-
-def test_noncopyable_containers():
-    # std::vector
-    vnc = m.get_vnc(5)
-    for i in range(5):
-        assert vnc[i].value == i + 1
-
-    for i, j in enumerate(vnc, start=1):
-        assert j.value == i
-
-    # std::deque
-    dnc = m.get_dnc(5)
-    for i in range(5):
-        assert dnc[i].value == i + 1
-
-    i = 1
-    for j in dnc:
-        assert j.value == i
-        i += 1
-
-    # std::map
-    mnc = m.get_mnc(5)
-    for i in range(1, 6):
-        assert mnc[i].value == 10 * i
-
-    vsum = 0
-    for k, v in mnc.items():
-        assert v.value == 10 * k
-        vsum += v.value
-
-    assert vsum == 150
-
-    # std::unordered_map
-    mnc = m.get_umnc(5)
-    for i in range(1, 6):
-        assert mnc[i].value == 10 * i
-
-    vsum = 0
-    for k, v in mnc.items():
-        assert v.value == 10 * k
-        vsum += v.value
-
-    assert vsum == 150
-
-    # nested std::map<std::vector>
-    nvnc = m.get_nvnc(5)
-    for i in range(1, 6):
-        for j in range(5):
-            assert nvnc[i][j].value == j + 1
-
-    # Note: maps do not have .values()
-    for _, v in nvnc.items():
-        for i, j in enumerate(v, start=1):
-            assert j.value == i
-
-    # nested std::map<std::map>
-    nmnc = m.get_nmnc(5)
-    for i in range(1, 6):
-        for j in range(10, 60, 10):
-            assert nmnc[i][j].value == 10 * j
-
-    vsum = 0
-    for _, v_o in nmnc.items():
-        for k_i, v_i in v_o.items():
-            assert v_i.value == 10 * k_i
-            vsum += v_i.value
-
-    assert vsum == 7500
-
-    # nested std::unordered_map<std::unordered_map>
-    numnc = m.get_numnc(5)
-    for i in range(1, 6):
-        for j in range(10, 60, 10):
-            assert numnc[i][j].value == 10 * j
-
-    vsum = 0
-    for _, v_o in numnc.items():
-        for k_i, v_i in v_o.items():
-            assert v_i.value == 10 * k_i
-            vsum += v_i.value
-
-    assert vsum == 7500
-
-
-def test_map_delitem():
-    mm = m.MapStringDouble()
-    mm["a"] = 1
-    mm["b"] = 2.5
-
-    assert list(mm) == ["a", "b"]
-    assert list(mm.items()) == [("a", 1), ("b", 2.5)]
-    del mm["a"]
-    assert list(mm) == ["b"]
-    assert list(mm.items()) == [("b", 2.5)]
-
-    um = m.UnorderedMapStringDouble()
-    um["ua"] = 1.1
-    um["ub"] = 2.6
-
-    assert sorted(um) == ["ua", "ub"]
-    assert sorted(um.items()) == [("ua", 1.1), ("ub", 2.6)]
-    del um["ua"]
-    assert sorted(um) == ["ub"]
-    assert sorted(um.items()) == [("ub", 2.6)]
-
-
-def test_map_view_types():
-    map_string_double = m.MapStringDouble()
-    unordered_map_string_double = m.UnorderedMapStringDouble()
-    map_string_double_const = m.MapStringDoubleConst()
-    unordered_map_string_double_const = m.UnorderedMapStringDoubleConst()
-
-    assert map_string_double.keys().__class__.__name__ == "KeysView[str]"
-    assert map_string_double.values().__class__.__name__ == "ValuesView[float]"
-    assert map_string_double.items().__class__.__name__ == "ItemsView[str, float]"
-
-    keys_type = type(map_string_double.keys())
-    assert type(unordered_map_string_double.keys()) is keys_type
-    assert type(map_string_double_const.keys()) is keys_type
-    assert type(unordered_map_string_double_const.keys()) is keys_type
-
-    values_type = type(map_string_double.values())
-    assert type(unordered_map_string_double.values()) is values_type
-    assert type(map_string_double_const.values()) is values_type
-    assert type(unordered_map_string_double_const.values()) is values_type
-
-    items_type = type(map_string_double.items())
-    assert type(unordered_map_string_double.items()) is items_type
-    assert type(map_string_double_const.items()) is items_type
-    assert type(unordered_map_string_double_const.items()) is items_type
-
-
-def test_recursive_vector():
-    recursive_vector = m.RecursiveVector()
-    recursive_vector.append(m.RecursiveVector())
-    recursive_vector[0].append(m.RecursiveVector())
-    recursive_vector[0].append(m.RecursiveVector())
-    # Can't use len() since test_stl_binders.cpp does not include stl.h,
-    # so the necessary conversion is missing
-    assert recursive_vector[0].count(m.RecursiveVector()) == 2
-
-
-def test_recursive_map():
-    recursive_map = m.RecursiveMap()
-    recursive_map[100] = m.RecursiveMap()
-    recursive_map[100][101] = m.RecursiveMap()
-    recursive_map[100][102] = m.RecursiveMap()
-    assert list(recursive_map[100].keys()) == [101, 102]
+import pytest
+
+from pybind11_tests import stl_binders as m
+
+
+def test_vector_int():
+    v_int = m.VectorInt([0, 0])
+    assert len(v_int) == 2
+    assert bool(v_int) is True
+
+    # test construction from a generator
+    v_int1 = m.VectorInt(x for x in range(5))
+    assert v_int1 == m.VectorInt([0, 1, 2, 3, 4])
+
+    v_int2 = m.VectorInt([0, 0])
+    assert v_int == v_int2
+    v_int2[1] = 1
+    assert v_int != v_int2
+
+    v_int2.append(2)
+    v_int2.insert(0, 1)
+    v_int2.insert(0, 2)
+    v_int2.insert(0, 3)
+    v_int2.insert(6, 3)
+    assert str(v_int2) == "VectorInt[3, 2, 1, 0, 1, 2, 3]"
+    with pytest.raises(IndexError):
+        v_int2.insert(8, 4)
+
+    v_int.append(99)
+    v_int2[2:-2] = v_int
+    assert v_int2 == m.VectorInt([3, 2, 0, 0, 99, 2, 3])
+    del v_int2[1:3]
+    assert v_int2 == m.VectorInt([3, 0, 99, 2, 3])
+    del v_int2[0]
+    assert v_int2 == m.VectorInt([0, 99, 2, 3])
+
+    v_int2.extend(m.VectorInt([4, 5]))
+    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5])
+
+    v_int2.extend([6, 7])
+    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7])
+
+    # test error handling, and that the vector is unchanged
+    with pytest.raises(RuntimeError):
+        v_int2.extend([8, "a"])
+
+    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7])
+
+    # test extending from a generator
+    v_int2.extend(x for x in range(5))
+    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4])
+
+    # test negative indexing
+    assert v_int2[-1] == 4
+
+    # insert with negative index
+    v_int2.insert(-1, 88)
+    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 88, 4])
+
+    # delete negative index
+    del v_int2[-1]
+    assert v_int2 == m.VectorInt([0, 99, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 88])
+
+    v_int2.clear()
+    assert len(v_int2) == 0
+
+
+# Older PyPy's failed here, related to the PyPy's buffer protocol.
+def test_vector_buffer():
+    b = bytearray([1, 2, 3, 4])
+    v = m.VectorUChar(b)
+    assert v[1] == 2
+    v[2] = 5
+    mv = memoryview(v)  # We expose the buffer interface
+    assert mv[2] == 5
+    mv[2] = 6
+    assert v[2] == 6
+
+    mv = memoryview(b)
+    v = m.VectorUChar(mv[::2])
+    assert v[1] == 3
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.create_undeclstruct()  # Undeclared struct contents, no buffer interface
+    assert "NumPy type info missing for " in str(excinfo.value)
+
+
+def test_vector_buffer_numpy():
+    np = pytest.importorskip("numpy")
+    a = np.array([1, 2, 3, 4], dtype=np.int32)
+    with pytest.raises(TypeError):
+        m.VectorInt(a)
+
+    a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], dtype=np.uintc)
+    v = m.VectorInt(a[0, :])
+    assert len(v) == 4
+    assert v[2] == 3
+    ma = np.asarray(v)
+    ma[2] = 5
+    assert v[2] == 5
+
+    v = m.VectorInt(a[:, 1])
+    assert len(v) == 3
+    assert v[2] == 10
+
+    v = m.get_vectorstruct()
+    assert v[0].x == 5
+    ma = np.asarray(v)
+    ma[1]["x"] = 99
+    assert v[1].x == 99
+
+    v = m.VectorStruct(
+        np.zeros(
+            3,
+            dtype=np.dtype(
+                [("w", "bool"), ("x", "I"), ("y", "float64"), ("z", "bool")], align=True
+            ),
+        )
+    )
+    assert len(v) == 3
+
+    b = np.array([1, 2, 3, 4], dtype=np.uint8)
+    v = m.VectorUChar(b[::2])
+    assert v[1] == 3
+
+
+def test_vector_bool():
+    import pybind11_cross_module_tests as cm
+
+    vv_c = cm.VectorBool()
+    for i in range(10):
+        vv_c.append(i % 2 == 0)
+    for i in range(10):
+        assert vv_c[i] == (i % 2 == 0)
+    assert str(vv_c) == "VectorBool[1, 0, 1, 0, 1, 0, 1, 0, 1, 0]"
+
+
+def test_vector_custom():
+    v_a = m.VectorEl()
+    v_a.append(m.El(1))
+    v_a.append(m.El(2))
+    assert str(v_a) == "VectorEl[El{1}, El{2}]"
+
+    vv_a = m.VectorVectorEl()
+    vv_a.append(v_a)
+    vv_b = vv_a[0]
+    assert str(vv_b) == "VectorEl[El{1}, El{2}]"
+
+
+def test_map_string_double():
+    mm = m.MapStringDouble()
+    mm["a"] = 1
+    mm["b"] = 2.5
+
+    assert list(mm) == ["a", "b"]
+    assert str(mm) == "MapStringDouble{a: 1, b: 2.5}"
+    assert "b" in mm
+    assert "c" not in mm
+    assert 123 not in mm
+
+    # Check that keys, values, items are views, not merely iterable
+    keys = mm.keys()
+    values = mm.values()
+    items = mm.items()
+    assert list(keys) == ["a", "b"]
+    assert len(keys) == 2
+    assert "a" in keys
+    assert "c" not in keys
+    assert 123 not in keys
+    assert list(items) == [("a", 1), ("b", 2.5)]
+    assert len(items) == 2
+    assert ("b", 2.5) in items
+    assert "hello" not in items
+    assert ("b", 2.5, None) not in items
+    assert list(values) == [1, 2.5]
+    assert len(values) == 2
+    assert 1 in values
+    assert 2 not in values
+    # Check that views update when the map is updated
+    mm["c"] = -1
+    assert list(keys) == ["a", "b", "c"]
+    assert list(values) == [1, 2.5, -1]
+    assert list(items) == [("a", 1), ("b", 2.5), ("c", -1)]
+
+    um = m.UnorderedMapStringDouble()
+    um["ua"] = 1.1
+    um["ub"] = 2.6
+
+    assert sorted(um) == ["ua", "ub"]
+    assert list(um.keys()) == list(um)
+    assert sorted(um.items()) == [("ua", 1.1), ("ub", 2.6)]
+    assert list(zip(um.keys(), um.values())) == list(um.items())
+    assert "UnorderedMapStringDouble" in str(um)
+
+
+def test_map_string_double_const():
+    mc = m.MapStringDoubleConst()
+    mc["a"] = 10
+    mc["b"] = 20.5
+    assert str(mc) == "MapStringDoubleConst{a: 10, b: 20.5}"
+
+    umc = m.UnorderedMapStringDoubleConst()
+    umc["a"] = 11
+    umc["b"] = 21.5
+
+    str(umc)
+
+
+def test_noncopyable_containers():
+    # std::vector
+    vnc = m.get_vnc(5)
+    for i in range(5):
+        assert vnc[i].value == i + 1
+
+    for i, j in enumerate(vnc, start=1):
+        assert j.value == i
+
+    # std::deque
+    dnc = m.get_dnc(5)
+    for i in range(5):
+        assert dnc[i].value == i + 1
+
+    i = 1
+    for j in dnc:
+        assert j.value == i
+        i += 1
+
+    # std::map
+    mnc = m.get_mnc(5)
+    for i in range(1, 6):
+        assert mnc[i].value == 10 * i
+
+    vsum = 0
+    for k, v in mnc.items():
+        assert v.value == 10 * k
+        vsum += v.value
+
+    assert vsum == 150
+
+    # std::unordered_map
+    mnc = m.get_umnc(5)
+    for i in range(1, 6):
+        assert mnc[i].value == 10 * i
+
+    vsum = 0
+    for k, v in mnc.items():
+        assert v.value == 10 * k
+        vsum += v.value
+
+    assert vsum == 150
+
+    # nested std::map<std::vector>
+    nvnc = m.get_nvnc(5)
+    for i in range(1, 6):
+        for j in range(5):
+            assert nvnc[i][j].value == j + 1
+
+    # Note: maps do not have .values()
+    for _, v in nvnc.items():
+        for i, j in enumerate(v, start=1):
+            assert j.value == i
+
+    # nested std::map<std::map>
+    nmnc = m.get_nmnc(5)
+    for i in range(1, 6):
+        for j in range(10, 60, 10):
+            assert nmnc[i][j].value == 10 * j
+
+    vsum = 0
+    for _, v_o in nmnc.items():
+        for k_i, v_i in v_o.items():
+            assert v_i.value == 10 * k_i
+            vsum += v_i.value
+
+    assert vsum == 7500
+
+    # nested std::unordered_map<std::unordered_map>
+    numnc = m.get_numnc(5)
+    for i in range(1, 6):
+        for j in range(10, 60, 10):
+            assert numnc[i][j].value == 10 * j
+
+    vsum = 0
+    for _, v_o in numnc.items():
+        for k_i, v_i in v_o.items():
+            assert v_i.value == 10 * k_i
+            vsum += v_i.value
+
+    assert vsum == 7500
+
+
+def test_map_delitem():
+    mm = m.MapStringDouble()
+    mm["a"] = 1
+    mm["b"] = 2.5
+
+    assert list(mm) == ["a", "b"]
+    assert list(mm.items()) == [("a", 1), ("b", 2.5)]
+    del mm["a"]
+    assert list(mm) == ["b"]
+    assert list(mm.items()) == [("b", 2.5)]
+
+    um = m.UnorderedMapStringDouble()
+    um["ua"] = 1.1
+    um["ub"] = 2.6
+
+    assert sorted(um) == ["ua", "ub"]
+    assert sorted(um.items()) == [("ua", 1.1), ("ub", 2.6)]
+    del um["ua"]
+    assert sorted(um) == ["ub"]
+    assert sorted(um.items()) == [("ub", 2.6)]
+
+
+def test_map_view_types():
+    map_string_double = m.MapStringDouble()
+    unordered_map_string_double = m.UnorderedMapStringDouble()
+    map_string_double_const = m.MapStringDoubleConst()
+    unordered_map_string_double_const = m.UnorderedMapStringDoubleConst()
+
+    assert map_string_double.keys().__class__.__name__ == "KeysView[str]"
+    assert map_string_double.values().__class__.__name__ == "ValuesView[float]"
+    assert map_string_double.items().__class__.__name__ == "ItemsView[str, float]"
+
+    keys_type = type(map_string_double.keys())
+    assert type(unordered_map_string_double.keys()) is keys_type
+    assert type(map_string_double_const.keys()) is keys_type
+    assert type(unordered_map_string_double_const.keys()) is keys_type
+
+    values_type = type(map_string_double.values())
+    assert type(unordered_map_string_double.values()) is values_type
+    assert type(map_string_double_const.values()) is values_type
+    assert type(unordered_map_string_double_const.values()) is values_type
+
+    items_type = type(map_string_double.items())
+    assert type(unordered_map_string_double.items()) is items_type
+    assert type(map_string_double_const.items()) is items_type
+    assert type(unordered_map_string_double_const.items()) is items_type
+
+
+def test_recursive_vector():
+    recursive_vector = m.RecursiveVector()
+    recursive_vector.append(m.RecursiveVector())
+    recursive_vector[0].append(m.RecursiveVector())
+    recursive_vector[0].append(m.RecursiveVector())
+    # Can't use len() since test_stl_binders.cpp does not include stl.h,
+    # so the necessary conversion is missing
+    assert recursive_vector[0].count(m.RecursiveVector()) == 2
+
+
+def test_recursive_map():
+    recursive_map = m.RecursiveMap()
+    recursive_map[100] = m.RecursiveMap()
+    recursive_map[100][101] = m.RecursiveMap()
+    recursive_map[100][102] = m.RecursiveMap()
+    assert list(recursive_map[100].keys()) == [101, 102]
```

## extern/pybind11/tests/test_tagbased_polymorphic.py

 * *Ordering differences only*

```diff
@@ -1,28 +1,28 @@
-from pybind11_tests import tagbased_polymorphic as m
-
-
-def test_downcast():
-    zoo = m.create_zoo()
-    assert [type(animal) for animal in zoo] == [
-        m.Labrador,
-        m.Dog,
-        m.Chihuahua,
-        m.Cat,
-        m.Panther,
-    ]
-    assert [animal.name for animal in zoo] == [
-        "Fido",
-        "Ginger",
-        "Hertzl",
-        "Tiger",
-        "Leo",
-    ]
-    zoo[1].sound = "woooooo"
-    assert [dog.bark() for dog in zoo[:3]] == [
-        "Labrador Fido goes WOOF!",
-        "Dog Ginger goes woooooo",
-        "Chihuahua Hertzl goes iyiyiyiyiyi and runs in circles",
-    ]
-    assert [cat.purr() for cat in zoo[3:]] == ["mrowr", "mrrrRRRRRR"]
-    zoo[0].excitement -= 1000
-    assert zoo[0].excitement == 14000
+from pybind11_tests import tagbased_polymorphic as m
+
+
+def test_downcast():
+    zoo = m.create_zoo()
+    assert [type(animal) for animal in zoo] == [
+        m.Labrador,
+        m.Dog,
+        m.Chihuahua,
+        m.Cat,
+        m.Panther,
+    ]
+    assert [animal.name for animal in zoo] == [
+        "Fido",
+        "Ginger",
+        "Hertzl",
+        "Tiger",
+        "Leo",
+    ]
+    zoo[1].sound = "woooooo"
+    assert [dog.bark() for dog in zoo[:3]] == [
+        "Labrador Fido goes WOOF!",
+        "Dog Ginger goes woooooo",
+        "Chihuahua Hertzl goes iyiyiyiyiyi and runs in circles",
+    ]
+    assert [cat.purr() for cat in zoo[3:]] == ["mrowr", "mrrrRRRRRR"]
+    zoo[0].excitement -= 1000
+    assert zoo[0].excitement == 14000
```

## extern/pybind11/tests/test_thread.py

 * *Ordering differences only*

```diff
@@ -1,42 +1,42 @@
-import threading
-
-from pybind11_tests import thread as m
-
-
-class Thread(threading.Thread):
-    def __init__(self, fn):
-        super().__init__()
-        self.fn = fn
-        self.e = None
-
-    def run(self):
-        try:
-            for i in range(10):
-                self.fn(i, i)
-        except Exception as e:
-            self.e = e
-
-    def join(self):
-        super().join()
-        if self.e:
-            raise self.e
-
-
-def test_implicit_conversion():
-    a = Thread(m.test)
-    b = Thread(m.test)
-    c = Thread(m.test)
-    for x in [a, b, c]:
-        x.start()
-    for x in [c, b, a]:
-        x.join()
-
-
-def test_implicit_conversion_no_gil():
-    a = Thread(m.test_no_gil)
-    b = Thread(m.test_no_gil)
-    c = Thread(m.test_no_gil)
-    for x in [a, b, c]:
-        x.start()
-    for x in [c, b, a]:
-        x.join()
+import threading
+
+from pybind11_tests import thread as m
+
+
+class Thread(threading.Thread):
+    def __init__(self, fn):
+        super().__init__()
+        self.fn = fn
+        self.e = None
+
+    def run(self):
+        try:
+            for i in range(10):
+                self.fn(i, i)
+        except Exception as e:
+            self.e = e
+
+    def join(self):
+        super().join()
+        if self.e:
+            raise self.e
+
+
+def test_implicit_conversion():
+    a = Thread(m.test)
+    b = Thread(m.test)
+    c = Thread(m.test)
+    for x in [a, b, c]:
+        x.start()
+    for x in [c, b, a]:
+        x.join()
+
+
+def test_implicit_conversion_no_gil():
+    a = Thread(m.test_no_gil)
+    b = Thread(m.test_no_gil)
+    c = Thread(m.test_no_gil)
+    for x in [a, b, c]:
+        x.start()
+    for x in [c, b, a]:
+        x.join()
```

## extern/pybind11/tests/test_type_caster_pyobject_ptr.py

 * *Ordering differences only*

```diff
@@ -1,104 +1,104 @@
-import pytest
-
-from pybind11_tests import type_caster_pyobject_ptr as m
-
-
-# For use as a temporary user-defined object, to maximize sensitivity of the tests below.
-class ValueHolder:
-    def __init__(self, value):
-        self.value = value
-
-
-def test_cast_from_pyobject_ptr():
-    assert m.cast_from_pyobject_ptr() == 6758
-
-
-def test_cast_handle_to_pyobject_ptr():
-    assert m.cast_handle_to_pyobject_ptr(ValueHolder(24)) == 76
-
-
-def test_cast_object_to_pyobject_ptr():
-    assert m.cast_object_to_pyobject_ptr(ValueHolder(43)) == 257
-
-
-def test_cast_list_to_pyobject_ptr():
-    assert m.cast_list_to_pyobject_ptr([1, 2, 3, 4, 5]) == 395
-
-
-def test_return_pyobject_ptr():
-    assert m.return_pyobject_ptr() == 2314
-
-
-def test_pass_pyobject_ptr():
-    assert m.pass_pyobject_ptr(ValueHolder(82)) == 118
-
-
-@pytest.mark.parametrize(
-    "call_callback",
-    [
-        m.call_callback_with_object_return,
-        m.call_callback_with_pyobject_ptr_return,
-    ],
-)
-def test_call_callback_with_object_return(call_callback):
-    def cb(value):
-        if value < 0:
-            raise ValueError("Raised from cb")
-        return ValueHolder(1000 - value)
-
-    assert call_callback(cb, 287).value == 713
-
-    with pytest.raises(ValueError, match="^Raised from cb$"):
-        call_callback(cb, -1)
-
-
-def test_call_callback_with_pyobject_ptr_arg():
-    def cb(obj):
-        return 300 - obj.value
-
-    assert m.call_callback_with_pyobject_ptr_arg(cb, ValueHolder(39)) == 261
-
-
-@pytest.mark.parametrize("set_error", [True, False])
-def test_cast_to_python_nullptr(set_error):
-    expected = {
-        True: r"^Reflective of healthy error handling\.$",
-        False: (
-            r"^Internal error: pybind11::error_already_set called "
-            r"while Python error indicator not set\.$"
-        ),
-    }[set_error]
-    with pytest.raises(RuntimeError, match=expected):
-        m.cast_to_pyobject_ptr_nullptr(set_error)
-
-
-def test_cast_to_python_non_nullptr_with_error_set():
-    with pytest.raises(SystemError) as excinfo:
-        m.cast_to_pyobject_ptr_non_nullptr_with_error_set()
-    assert str(excinfo.value) == "src != nullptr but PyErr_Occurred()"
-    assert str(excinfo.value.__cause__) == "Reflective of unhealthy error handling."
-
-
-def test_pass_list_pyobject_ptr():
-    acc = m.pass_list_pyobject_ptr([ValueHolder(842), ValueHolder(452)])
-    assert acc == 842452
-
-
-def test_return_list_pyobject_ptr_take_ownership():
-    vec_obj = m.return_list_pyobject_ptr_take_ownership(ValueHolder)
-    assert [e.value for e in vec_obj] == [93, 186]
-
-
-def test_return_list_pyobject_ptr_reference():
-    vec_obj = m.return_list_pyobject_ptr_reference(ValueHolder)
-    assert [e.value for e in vec_obj] == [93, 186]
-    # Commenting out the next `assert` will leak the Python references.
-    # An easy way to see evidence of the leaks:
-    # Insert `while True:` as the first line of this function and monitor the
-    # process RES (Resident Memory Size) with the Unix top command.
-    assert m.dec_ref_each_pyobject_ptr(vec_obj) == 2
-
-
-def test_type_caster_name_via_incompatible_function_arguments_type_error():
-    with pytest.raises(TypeError, match=r"1\. \(arg0: object, arg1: int\) -> None"):
-        m.pass_pyobject_ptr_and_int(ValueHolder(101), ValueHolder(202))
+import pytest
+
+from pybind11_tests import type_caster_pyobject_ptr as m
+
+
+# For use as a temporary user-defined object, to maximize sensitivity of the tests below.
+class ValueHolder:
+    def __init__(self, value):
+        self.value = value
+
+
+def test_cast_from_pyobject_ptr():
+    assert m.cast_from_pyobject_ptr() == 6758
+
+
+def test_cast_handle_to_pyobject_ptr():
+    assert m.cast_handle_to_pyobject_ptr(ValueHolder(24)) == 76
+
+
+def test_cast_object_to_pyobject_ptr():
+    assert m.cast_object_to_pyobject_ptr(ValueHolder(43)) == 257
+
+
+def test_cast_list_to_pyobject_ptr():
+    assert m.cast_list_to_pyobject_ptr([1, 2, 3, 4, 5]) == 395
+
+
+def test_return_pyobject_ptr():
+    assert m.return_pyobject_ptr() == 2314
+
+
+def test_pass_pyobject_ptr():
+    assert m.pass_pyobject_ptr(ValueHolder(82)) == 118
+
+
+@pytest.mark.parametrize(
+    "call_callback",
+    [
+        m.call_callback_with_object_return,
+        m.call_callback_with_pyobject_ptr_return,
+    ],
+)
+def test_call_callback_with_object_return(call_callback):
+    def cb(value):
+        if value < 0:
+            raise ValueError("Raised from cb")
+        return ValueHolder(1000 - value)
+
+    assert call_callback(cb, 287).value == 713
+
+    with pytest.raises(ValueError, match="^Raised from cb$"):
+        call_callback(cb, -1)
+
+
+def test_call_callback_with_pyobject_ptr_arg():
+    def cb(obj):
+        return 300 - obj.value
+
+    assert m.call_callback_with_pyobject_ptr_arg(cb, ValueHolder(39)) == 261
+
+
+@pytest.mark.parametrize("set_error", [True, False])
+def test_cast_to_python_nullptr(set_error):
+    expected = {
+        True: r"^Reflective of healthy error handling\.$",
+        False: (
+            r"^Internal error: pybind11::error_already_set called "
+            r"while Python error indicator not set\.$"
+        ),
+    }[set_error]
+    with pytest.raises(RuntimeError, match=expected):
+        m.cast_to_pyobject_ptr_nullptr(set_error)
+
+
+def test_cast_to_python_non_nullptr_with_error_set():
+    with pytest.raises(SystemError) as excinfo:
+        m.cast_to_pyobject_ptr_non_nullptr_with_error_set()
+    assert str(excinfo.value) == "src != nullptr but PyErr_Occurred()"
+    assert str(excinfo.value.__cause__) == "Reflective of unhealthy error handling."
+
+
+def test_pass_list_pyobject_ptr():
+    acc = m.pass_list_pyobject_ptr([ValueHolder(842), ValueHolder(452)])
+    assert acc == 842452
+
+
+def test_return_list_pyobject_ptr_take_ownership():
+    vec_obj = m.return_list_pyobject_ptr_take_ownership(ValueHolder)
+    assert [e.value for e in vec_obj] == [93, 186]
+
+
+def test_return_list_pyobject_ptr_reference():
+    vec_obj = m.return_list_pyobject_ptr_reference(ValueHolder)
+    assert [e.value for e in vec_obj] == [93, 186]
+    # Commenting out the next `assert` will leak the Python references.
+    # An easy way to see evidence of the leaks:
+    # Insert `while True:` as the first line of this function and monitor the
+    # process RES (Resident Memory Size) with the Unix top command.
+    assert m.dec_ref_each_pyobject_ptr(vec_obj) == 2
+
+
+def test_type_caster_name_via_incompatible_function_arguments_type_error():
+    with pytest.raises(TypeError, match=r"1\. \(arg0: object, arg1: int\) -> None"):
+        m.pass_pyobject_ptr_and_int(ValueHolder(101), ValueHolder(202))
```

## extern/pybind11/tests/test_union.py

 * *Ordering differences only*

```diff
@@ -1,8 +1,8 @@
-from pybind11_tests import union_ as m
-
-
-def test_union():
-    instance = m.TestUnion()
-
-    instance.as_uint = 10
-    assert instance.as_int == 10
+from pybind11_tests import union_ as m
+
+
+def test_union():
+    instance = m.TestUnion()
+
+    instance.as_uint = 10
+    assert instance.as_int == 10
```

## extern/pybind11/tests/test_unnamed_namespace_a.py

 * *Ordering differences only*

```diff
@@ -1,34 +1,34 @@
-import pytest
-
-from pybind11_tests import unnamed_namespace_a as m
-from pybind11_tests import unnamed_namespace_b as mb
-
-XFAIL_CONDITION = (
-    "(m.PYBIND11_INTERNALS_VERSION <= 4 and (m.defined___clang__ or not m.defined___GLIBCXX__))"
-    " or "
-    "(m.PYBIND11_INTERNALS_VERSION >= 5 and not m.defined_WIN32_or__WIN32"
-    " and "
-    "(m.defined___clang__ or m.defined__LIBCPP_VERSION))"
-)
-XFAIL_REASON = "Known issues: https://github.com/pybind/pybind11/pull/4319"
-
-
-@pytest.mark.xfail(XFAIL_CONDITION, reason=XFAIL_REASON, strict=False)
-@pytest.mark.parametrize(
-    "any_struct", [m.unnamed_namespace_a_any_struct, mb.unnamed_namespace_b_any_struct]
-)
-def test_have_class_any_struct(any_struct):
-    assert any_struct is not None
-
-
-def test_have_at_least_one_class_any_struct():
-    assert (
-        m.unnamed_namespace_a_any_struct is not None
-        or mb.unnamed_namespace_b_any_struct is not None
-    )
-
-
-@pytest.mark.xfail(XFAIL_CONDITION, reason=XFAIL_REASON, strict=True)
-def test_have_both_class_any_struct():
-    assert m.unnamed_namespace_a_any_struct is not None
-    assert mb.unnamed_namespace_b_any_struct is not None
+import pytest
+
+from pybind11_tests import unnamed_namespace_a as m
+from pybind11_tests import unnamed_namespace_b as mb
+
+XFAIL_CONDITION = (
+    "(m.PYBIND11_INTERNALS_VERSION <= 4 and (m.defined___clang__ or not m.defined___GLIBCXX__))"
+    " or "
+    "(m.PYBIND11_INTERNALS_VERSION >= 5 and not m.defined_WIN32_or__WIN32"
+    " and "
+    "(m.defined___clang__ or m.defined__LIBCPP_VERSION))"
+)
+XFAIL_REASON = "Known issues: https://github.com/pybind/pybind11/pull/4319"
+
+
+@pytest.mark.xfail(XFAIL_CONDITION, reason=XFAIL_REASON, strict=False)
+@pytest.mark.parametrize(
+    "any_struct", [m.unnamed_namespace_a_any_struct, mb.unnamed_namespace_b_any_struct]
+)
+def test_have_class_any_struct(any_struct):
+    assert any_struct is not None
+
+
+def test_have_at_least_one_class_any_struct():
+    assert (
+        m.unnamed_namespace_a_any_struct is not None
+        or mb.unnamed_namespace_b_any_struct is not None
+    )
+
+
+@pytest.mark.xfail(XFAIL_CONDITION, reason=XFAIL_REASON, strict=True)
+def test_have_both_class_any_struct():
+    assert m.unnamed_namespace_a_any_struct is not None
+    assert mb.unnamed_namespace_b_any_struct is not None
```

## extern/pybind11/tests/test_unnamed_namespace_b.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-from pybind11_tests import unnamed_namespace_b as m
-
-
-def test_have_attr_any_struct():
-    assert hasattr(m, "unnamed_namespace_b_any_struct")
+from pybind11_tests import unnamed_namespace_b as m
+
+
+def test_have_attr_any_struct():
+    assert hasattr(m, "unnamed_namespace_b_any_struct")
```

## extern/pybind11/tests/test_vector_unique_ptr_member.py

 * *Ordering differences only*

```diff
@@ -1,14 +1,14 @@
-import pytest
-
-from pybind11_tests import vector_unique_ptr_member as m
-
-
-@pytest.mark.parametrize("num_elems", range(3))
-def test_create(num_elems):
-    vo = m.VectorOwner.Create(num_elems)
-    assert vo.data_size() == num_elems
-
-
-def test_cast():
-    vo = m.VectorOwner.Create(0)
-    assert m.py_cast_VectorOwner_ptr(vo) is vo
+import pytest
+
+from pybind11_tests import vector_unique_ptr_member as m
+
+
+@pytest.mark.parametrize("num_elems", range(3))
+def test_create(num_elems):
+    vo = m.VectorOwner.Create(num_elems)
+    assert vo.data_size() == num_elems
+
+
+def test_cast():
+    vo = m.VectorOwner.Create(0)
+    assert m.py_cast_VectorOwner_ptr(vo) is vo
```

## extern/pybind11/tests/test_virtual_functions.py

 * *Ordering differences only*

```diff
@@ -1,458 +1,458 @@
-import pytest
-
-import env  # noqa: F401
-
-m = pytest.importorskip("pybind11_tests.virtual_functions")
-from pybind11_tests import ConstructorStats  # noqa: E402
-
-
-def test_override(capture, msg):
-    class ExtendedExampleVirt(m.ExampleVirt):
-        def __init__(self, state):
-            super().__init__(state + 1)
-            self.data = "Hello world"
-
-        def run(self, value):
-            print(f"ExtendedExampleVirt::run({value}), calling parent..")
-            return super().run(value + 1)
-
-        def run_bool(self):
-            print("ExtendedExampleVirt::run_bool()")
-            return False
-
-        def get_string1(self):
-            return "override1"
-
-        def pure_virtual(self):
-            print(f"ExtendedExampleVirt::pure_virtual(): {self.data}")
-
-    class ExtendedExampleVirt2(ExtendedExampleVirt):
-        def __init__(self, state):
-            super().__init__(state + 1)
-
-        def get_string2(self):
-            return "override2"
-
-    ex12 = m.ExampleVirt(10)
-    with capture:
-        assert m.runExampleVirt(ex12, 20) == 30
-    assert (
-        capture
-        == """
-        Original implementation of ExampleVirt::run(state=10, value=20, str1=default1, str2=default2)
-    """
-    )
-
-    with pytest.raises(RuntimeError) as excinfo:
-        m.runExampleVirtVirtual(ex12)
-    assert (
-        msg(excinfo.value)
-        == 'Tried to call pure virtual function "ExampleVirt::pure_virtual"'
-    )
-
-    ex12p = ExtendedExampleVirt(10)
-    with capture:
-        assert m.runExampleVirt(ex12p, 20) == 32
-    assert (
-        capture
-        == """
-        ExtendedExampleVirt::run(20), calling parent..
-        Original implementation of ExampleVirt::run(state=11, value=21, str1=override1, str2=default2)
-    """
-    )
-    with capture:
-        assert m.runExampleVirtBool(ex12p) is False
-    assert capture == "ExtendedExampleVirt::run_bool()"
-    with capture:
-        m.runExampleVirtVirtual(ex12p)
-    assert capture == "ExtendedExampleVirt::pure_virtual(): Hello world"
-
-    ex12p2 = ExtendedExampleVirt2(15)
-    with capture:
-        assert m.runExampleVirt(ex12p2, 50) == 68
-    assert (
-        capture
-        == """
-        ExtendedExampleVirt::run(50), calling parent..
-        Original implementation of ExampleVirt::run(state=17, value=51, str1=override1, str2=override2)
-    """
-    )
-
-    cstats = ConstructorStats.get(m.ExampleVirt)
-    assert cstats.alive() == 3
-    del ex12, ex12p, ex12p2
-    assert cstats.alive() == 0
-    assert cstats.values() == ["10", "11", "17"]
-    assert cstats.copy_constructions == 0
-    assert cstats.move_constructions >= 0
-
-
-def test_alias_delay_initialization1(capture):
-    """`A` only initializes its trampoline class when we inherit from it
-
-    If we just create and use an A instance directly, the trampoline initialization is
-    bypassed and we only initialize an A() instead (for performance reasons).
-    """
-
-    class B(m.A):
-        def __init__(self):
-            super().__init__()
-
-        def f(self):
-            print("In python f()")
-
-    # C++ version
-    with capture:
-        a = m.A()
-        m.call_f(a)
-        del a
-        pytest.gc_collect()
-    assert capture == "A.f()"
-
-    # Python version
-    with capture:
-        b = B()
-        m.call_f(b)
-        del b
-        pytest.gc_collect()
-    assert (
-        capture
-        == """
-        PyA.PyA()
-        PyA.f()
-        In python f()
-        PyA.~PyA()
-    """
-    )
-
-
-def test_alias_delay_initialization2(capture):
-    """`A2`, unlike the above, is configured to always initialize the alias
-
-    While the extra initialization and extra class layer has small virtual dispatch
-    performance penalty, it also allows us to do more things with the trampoline
-    class such as defining local variables and performing construction/destruction.
-    """
-
-    class B2(m.A2):
-        def __init__(self):
-            super().__init__()
-
-        def f(self):
-            print("In python B2.f()")
-
-    # No python subclass version
-    with capture:
-        a2 = m.A2()
-        m.call_f(a2)
-        del a2
-        pytest.gc_collect()
-        a3 = m.A2(1)
-        m.call_f(a3)
-        del a3
-        pytest.gc_collect()
-    assert (
-        capture
-        == """
-        PyA2.PyA2()
-        PyA2.f()
-        A2.f()
-        PyA2.~PyA2()
-        PyA2.PyA2()
-        PyA2.f()
-        A2.f()
-        PyA2.~PyA2()
-    """
-    )
-
-    # Python subclass version
-    with capture:
-        b2 = B2()
-        m.call_f(b2)
-        del b2
-        pytest.gc_collect()
-    assert (
-        capture
-        == """
-        PyA2.PyA2()
-        PyA2.f()
-        In python B2.f()
-        PyA2.~PyA2()
-    """
-    )
-
-
-# PyPy: Reference count > 1 causes call with noncopyable instance
-# to fail in ncv1.print_nc()
-@pytest.mark.xfail("env.PYPY")
-@pytest.mark.skipif(
-    not hasattr(m, "NCVirt"), reason="NCVirt does not work on Intel/PGI/NVCC compilers"
-)
-def test_move_support():
-    class NCVirtExt(m.NCVirt):
-        def get_noncopyable(self, a, b):
-            # Constructs and returns a new instance:
-            return m.NonCopyable(a * a, b * b)
-
-        def get_movable(self, a, b):
-            # Return a referenced copy
-            self.movable = m.Movable(a, b)
-            return self.movable
-
-    class NCVirtExt2(m.NCVirt):
-        def get_noncopyable(self, a, b):
-            # Keep a reference: this is going to throw an exception
-            self.nc = m.NonCopyable(a, b)
-            return self.nc
-
-        def get_movable(self, a, b):
-            # Return a new instance without storing it
-            return m.Movable(a, b)
-
-    ncv1 = NCVirtExt()
-    assert ncv1.print_nc(2, 3) == "36"
-    assert ncv1.print_movable(4, 5) == "9"
-    ncv2 = NCVirtExt2()
-    assert ncv2.print_movable(7, 7) == "14"
-    # Don't check the exception message here because it differs under debug/non-debug mode
-    with pytest.raises(RuntimeError):
-        ncv2.print_nc(9, 9)
-
-    nc_stats = ConstructorStats.get(m.NonCopyable)
-    mv_stats = ConstructorStats.get(m.Movable)
-    assert nc_stats.alive() == 1
-    assert mv_stats.alive() == 1
-    del ncv1, ncv2
-    assert nc_stats.alive() == 0
-    assert mv_stats.alive() == 0
-    assert nc_stats.values() == ["4", "9", "9", "9"]
-    assert mv_stats.values() == ["4", "5", "7", "7"]
-    assert nc_stats.copy_constructions == 0
-    assert mv_stats.copy_constructions == 1
-    assert nc_stats.move_constructions >= 0
-    assert mv_stats.move_constructions >= 0
-
-
-def test_dispatch_issue(msg):
-    """#159: virtual function dispatch has problems with similar-named functions"""
-
-    class PyClass1(m.DispatchIssue):
-        def dispatch(self):
-            return "Yay.."
-
-    class PyClass2(m.DispatchIssue):
-        def dispatch(self):
-            with pytest.raises(RuntimeError) as excinfo:
-                super().dispatch()
-            assert (
-                msg(excinfo.value)
-                == 'Tried to call pure virtual function "Base::dispatch"'
-            )
-
-            return m.dispatch_issue_go(PyClass1())
-
-    b = PyClass2()
-    assert m.dispatch_issue_go(b) == "Yay.."
-
-
-def test_recursive_dispatch_issue():
-    """#3357: Recursive dispatch fails to find python function override"""
-
-    class Data(m.Data):
-        def __init__(self, value):
-            super().__init__()
-            self.value = value
-
-    class Adder(m.Adder):
-        def __call__(self, first, second, visitor):
-            # lambda is a workaround, which adds extra frame to the
-            # current CPython thread. Removing lambda reveals the bug
-            # [https://github.com/pybind/pybind11/issues/3357]
-            (lambda: visitor(Data(first.value + second.value)))()  # noqa: PLC3002
-
-    class StoreResultVisitor:
-        def __init__(self):
-            self.result = None
-
-        def __call__(self, data):
-            self.result = data.value
-
-    store = StoreResultVisitor()
-
-    m.add2(Data(1), Data(2), Adder(), store)
-    assert store.result == 3
-
-    # without lambda in Adder class, this function fails with
-    # RuntimeError: Tried to call pure virtual function "AdderBase::__call__"
-    m.add3(Data(1), Data(2), Data(3), Adder(), store)
-    assert store.result == 6
-
-
-def test_override_ref():
-    """#392/397: overriding reference-returning functions"""
-    o = m.OverrideTest("asdf")
-
-    # Not allowed (see associated .cpp comment)
-    # i = o.str_ref()
-    # assert o.str_ref() == "asdf"
-    assert o.str_value() == "asdf"
-
-    assert o.A_value().value == "hi"
-    a = o.A_ref()
-    assert a.value == "hi"
-    a.value = "bye"
-    assert a.value == "bye"
-
-
-def test_inherited_virtuals():
-    class AR(m.A_Repeat):
-        def unlucky_number(self):
-            return 99
-
-    class AT(m.A_Tpl):
-        def unlucky_number(self):
-            return 999
-
-    obj = AR()
-    assert obj.say_something(3) == "hihihi"
-    assert obj.unlucky_number() == 99
-    assert obj.say_everything() == "hi 99"
-
-    obj = AT()
-    assert obj.say_something(3) == "hihihi"
-    assert obj.unlucky_number() == 999
-    assert obj.say_everything() == "hi 999"
-
-    for obj in [m.B_Repeat(), m.B_Tpl()]:
-        assert obj.say_something(3) == "B says hi 3 times"
-        assert obj.unlucky_number() == 13
-        assert obj.lucky_number() == 7.0
-        assert obj.say_everything() == "B says hi 1 times 13"
-
-    for obj in [m.C_Repeat(), m.C_Tpl()]:
-        assert obj.say_something(3) == "B says hi 3 times"
-        assert obj.unlucky_number() == 4444
-        assert obj.lucky_number() == 888.0
-        assert obj.say_everything() == "B says hi 1 times 4444"
-
-    class CR(m.C_Repeat):
-        def lucky_number(self):
-            return m.C_Repeat.lucky_number(self) + 1.25
-
-    obj = CR()
-    assert obj.say_something(3) == "B says hi 3 times"
-    assert obj.unlucky_number() == 4444
-    assert obj.lucky_number() == 889.25
-    assert obj.say_everything() == "B says hi 1 times 4444"
-
-    class CT(m.C_Tpl):
-        pass
-
-    obj = CT()
-    assert obj.say_something(3) == "B says hi 3 times"
-    assert obj.unlucky_number() == 4444
-    assert obj.lucky_number() == 888.0
-    assert obj.say_everything() == "B says hi 1 times 4444"
-
-    class CCR(CR):
-        def lucky_number(self):
-            return CR.lucky_number(self) * 10
-
-    obj = CCR()
-    assert obj.say_something(3) == "B says hi 3 times"
-    assert obj.unlucky_number() == 4444
-    assert obj.lucky_number() == 8892.5
-    assert obj.say_everything() == "B says hi 1 times 4444"
-
-    class CCT(CT):
-        def lucky_number(self):
-            return CT.lucky_number(self) * 1000
-
-    obj = CCT()
-    assert obj.say_something(3) == "B says hi 3 times"
-    assert obj.unlucky_number() == 4444
-    assert obj.lucky_number() == 888000.0
-    assert obj.say_everything() == "B says hi 1 times 4444"
-
-    class DR(m.D_Repeat):
-        def unlucky_number(self):
-            return 123
-
-        def lucky_number(self):
-            return 42.0
-
-    for obj in [m.D_Repeat(), m.D_Tpl()]:
-        assert obj.say_something(3) == "B says hi 3 times"
-        assert obj.unlucky_number() == 4444
-        assert obj.lucky_number() == 888.0
-        assert obj.say_everything() == "B says hi 1 times 4444"
-
-    obj = DR()
-    assert obj.say_something(3) == "B says hi 3 times"
-    assert obj.unlucky_number() == 123
-    assert obj.lucky_number() == 42.0
-    assert obj.say_everything() == "B says hi 1 times 123"
-
-    class DT(m.D_Tpl):
-        def say_something(self, times):
-            return "DT says:" + (" quack" * times)
-
-        def unlucky_number(self):
-            return 1234
-
-        def lucky_number(self):
-            return -4.25
-
-    obj = DT()
-    assert obj.say_something(3) == "DT says: quack quack quack"
-    assert obj.unlucky_number() == 1234
-    assert obj.lucky_number() == -4.25
-    assert obj.say_everything() == "DT says: quack 1234"
-
-    class DT2(DT):
-        def say_something(self, times):
-            return "DT2: " + ("QUACK" * times)
-
-        def unlucky_number(self):
-            return -3
-
-    class BT(m.B_Tpl):
-        def say_something(self, times):
-            return "BT" * times
-
-        def unlucky_number(self):
-            return -7
-
-        def lucky_number(self):
-            return -1.375
-
-    obj = BT()
-    assert obj.say_something(3) == "BTBTBT"
-    assert obj.unlucky_number() == -7
-    assert obj.lucky_number() == -1.375
-    assert obj.say_everything() == "BT -7"
-
-
-def test_issue_1454():
-    # Fix issue #1454 (crash when acquiring/releasing GIL on another thread in Python 2.7)
-    m.test_gil()
-    m.test_gil_from_thread()
-
-
-def test_python_override():
-    def func():
-        class Test(m.test_override_cache_helper):
-            def func(self):
-                return 42
-
-        return Test()
-
-    def func2():
-        class Test(m.test_override_cache_helper):
-            pass
-
-        return Test()
-
-    for _ in range(1500):
-        assert m.test_override_cache(func()) == 42
-        assert m.test_override_cache(func2()) == 0
+import pytest
+
+import env  # noqa: F401
+
+m = pytest.importorskip("pybind11_tests.virtual_functions")
+from pybind11_tests import ConstructorStats  # noqa: E402
+
+
+def test_override(capture, msg):
+    class ExtendedExampleVirt(m.ExampleVirt):
+        def __init__(self, state):
+            super().__init__(state + 1)
+            self.data = "Hello world"
+
+        def run(self, value):
+            print(f"ExtendedExampleVirt::run({value}), calling parent..")
+            return super().run(value + 1)
+
+        def run_bool(self):
+            print("ExtendedExampleVirt::run_bool()")
+            return False
+
+        def get_string1(self):
+            return "override1"
+
+        def pure_virtual(self):
+            print(f"ExtendedExampleVirt::pure_virtual(): {self.data}")
+
+    class ExtendedExampleVirt2(ExtendedExampleVirt):
+        def __init__(self, state):
+            super().__init__(state + 1)
+
+        def get_string2(self):
+            return "override2"
+
+    ex12 = m.ExampleVirt(10)
+    with capture:
+        assert m.runExampleVirt(ex12, 20) == 30
+    assert (
+        capture
+        == """
+        Original implementation of ExampleVirt::run(state=10, value=20, str1=default1, str2=default2)
+    """
+    )
+
+    with pytest.raises(RuntimeError) as excinfo:
+        m.runExampleVirtVirtual(ex12)
+    assert (
+        msg(excinfo.value)
+        == 'Tried to call pure virtual function "ExampleVirt::pure_virtual"'
+    )
+
+    ex12p = ExtendedExampleVirt(10)
+    with capture:
+        assert m.runExampleVirt(ex12p, 20) == 32
+    assert (
+        capture
+        == """
+        ExtendedExampleVirt::run(20), calling parent..
+        Original implementation of ExampleVirt::run(state=11, value=21, str1=override1, str2=default2)
+    """
+    )
+    with capture:
+        assert m.runExampleVirtBool(ex12p) is False
+    assert capture == "ExtendedExampleVirt::run_bool()"
+    with capture:
+        m.runExampleVirtVirtual(ex12p)
+    assert capture == "ExtendedExampleVirt::pure_virtual(): Hello world"
+
+    ex12p2 = ExtendedExampleVirt2(15)
+    with capture:
+        assert m.runExampleVirt(ex12p2, 50) == 68
+    assert (
+        capture
+        == """
+        ExtendedExampleVirt::run(50), calling parent..
+        Original implementation of ExampleVirt::run(state=17, value=51, str1=override1, str2=override2)
+    """
+    )
+
+    cstats = ConstructorStats.get(m.ExampleVirt)
+    assert cstats.alive() == 3
+    del ex12, ex12p, ex12p2
+    assert cstats.alive() == 0
+    assert cstats.values() == ["10", "11", "17"]
+    assert cstats.copy_constructions == 0
+    assert cstats.move_constructions >= 0
+
+
+def test_alias_delay_initialization1(capture):
+    """`A` only initializes its trampoline class when we inherit from it
+
+    If we just create and use an A instance directly, the trampoline initialization is
+    bypassed and we only initialize an A() instead (for performance reasons).
+    """
+
+    class B(m.A):
+        def __init__(self):
+            super().__init__()
+
+        def f(self):
+            print("In python f()")
+
+    # C++ version
+    with capture:
+        a = m.A()
+        m.call_f(a)
+        del a
+        pytest.gc_collect()
+    assert capture == "A.f()"
+
+    # Python version
+    with capture:
+        b = B()
+        m.call_f(b)
+        del b
+        pytest.gc_collect()
+    assert (
+        capture
+        == """
+        PyA.PyA()
+        PyA.f()
+        In python f()
+        PyA.~PyA()
+    """
+    )
+
+
+def test_alias_delay_initialization2(capture):
+    """`A2`, unlike the above, is configured to always initialize the alias
+
+    While the extra initialization and extra class layer has small virtual dispatch
+    performance penalty, it also allows us to do more things with the trampoline
+    class such as defining local variables and performing construction/destruction.
+    """
+
+    class B2(m.A2):
+        def __init__(self):
+            super().__init__()
+
+        def f(self):
+            print("In python B2.f()")
+
+    # No python subclass version
+    with capture:
+        a2 = m.A2()
+        m.call_f(a2)
+        del a2
+        pytest.gc_collect()
+        a3 = m.A2(1)
+        m.call_f(a3)
+        del a3
+        pytest.gc_collect()
+    assert (
+        capture
+        == """
+        PyA2.PyA2()
+        PyA2.f()
+        A2.f()
+        PyA2.~PyA2()
+        PyA2.PyA2()
+        PyA2.f()
+        A2.f()
+        PyA2.~PyA2()
+    """
+    )
+
+    # Python subclass version
+    with capture:
+        b2 = B2()
+        m.call_f(b2)
+        del b2
+        pytest.gc_collect()
+    assert (
+        capture
+        == """
+        PyA2.PyA2()
+        PyA2.f()
+        In python B2.f()
+        PyA2.~PyA2()
+    """
+    )
+
+
+# PyPy: Reference count > 1 causes call with noncopyable instance
+# to fail in ncv1.print_nc()
+@pytest.mark.xfail("env.PYPY")
+@pytest.mark.skipif(
+    not hasattr(m, "NCVirt"), reason="NCVirt does not work on Intel/PGI/NVCC compilers"
+)
+def test_move_support():
+    class NCVirtExt(m.NCVirt):
+        def get_noncopyable(self, a, b):
+            # Constructs and returns a new instance:
+            return m.NonCopyable(a * a, b * b)
+
+        def get_movable(self, a, b):
+            # Return a referenced copy
+            self.movable = m.Movable(a, b)
+            return self.movable
+
+    class NCVirtExt2(m.NCVirt):
+        def get_noncopyable(self, a, b):
+            # Keep a reference: this is going to throw an exception
+            self.nc = m.NonCopyable(a, b)
+            return self.nc
+
+        def get_movable(self, a, b):
+            # Return a new instance without storing it
+            return m.Movable(a, b)
+
+    ncv1 = NCVirtExt()
+    assert ncv1.print_nc(2, 3) == "36"
+    assert ncv1.print_movable(4, 5) == "9"
+    ncv2 = NCVirtExt2()
+    assert ncv2.print_movable(7, 7) == "14"
+    # Don't check the exception message here because it differs under debug/non-debug mode
+    with pytest.raises(RuntimeError):
+        ncv2.print_nc(9, 9)
+
+    nc_stats = ConstructorStats.get(m.NonCopyable)
+    mv_stats = ConstructorStats.get(m.Movable)
+    assert nc_stats.alive() == 1
+    assert mv_stats.alive() == 1
+    del ncv1, ncv2
+    assert nc_stats.alive() == 0
+    assert mv_stats.alive() == 0
+    assert nc_stats.values() == ["4", "9", "9", "9"]
+    assert mv_stats.values() == ["4", "5", "7", "7"]
+    assert nc_stats.copy_constructions == 0
+    assert mv_stats.copy_constructions == 1
+    assert nc_stats.move_constructions >= 0
+    assert mv_stats.move_constructions >= 0
+
+
+def test_dispatch_issue(msg):
+    """#159: virtual function dispatch has problems with similar-named functions"""
+
+    class PyClass1(m.DispatchIssue):
+        def dispatch(self):
+            return "Yay.."
+
+    class PyClass2(m.DispatchIssue):
+        def dispatch(self):
+            with pytest.raises(RuntimeError) as excinfo:
+                super().dispatch()
+            assert (
+                msg(excinfo.value)
+                == 'Tried to call pure virtual function "Base::dispatch"'
+            )
+
+            return m.dispatch_issue_go(PyClass1())
+
+    b = PyClass2()
+    assert m.dispatch_issue_go(b) == "Yay.."
+
+
+def test_recursive_dispatch_issue():
+    """#3357: Recursive dispatch fails to find python function override"""
+
+    class Data(m.Data):
+        def __init__(self, value):
+            super().__init__()
+            self.value = value
+
+    class Adder(m.Adder):
+        def __call__(self, first, second, visitor):
+            # lambda is a workaround, which adds extra frame to the
+            # current CPython thread. Removing lambda reveals the bug
+            # [https://github.com/pybind/pybind11/issues/3357]
+            (lambda: visitor(Data(first.value + second.value)))()  # noqa: PLC3002
+
+    class StoreResultVisitor:
+        def __init__(self):
+            self.result = None
+
+        def __call__(self, data):
+            self.result = data.value
+
+    store = StoreResultVisitor()
+
+    m.add2(Data(1), Data(2), Adder(), store)
+    assert store.result == 3
+
+    # without lambda in Adder class, this function fails with
+    # RuntimeError: Tried to call pure virtual function "AdderBase::__call__"
+    m.add3(Data(1), Data(2), Data(3), Adder(), store)
+    assert store.result == 6
+
+
+def test_override_ref():
+    """#392/397: overriding reference-returning functions"""
+    o = m.OverrideTest("asdf")
+
+    # Not allowed (see associated .cpp comment)
+    # i = o.str_ref()
+    # assert o.str_ref() == "asdf"
+    assert o.str_value() == "asdf"
+
+    assert o.A_value().value == "hi"
+    a = o.A_ref()
+    assert a.value == "hi"
+    a.value = "bye"
+    assert a.value == "bye"
+
+
+def test_inherited_virtuals():
+    class AR(m.A_Repeat):
+        def unlucky_number(self):
+            return 99
+
+    class AT(m.A_Tpl):
+        def unlucky_number(self):
+            return 999
+
+    obj = AR()
+    assert obj.say_something(3) == "hihihi"
+    assert obj.unlucky_number() == 99
+    assert obj.say_everything() == "hi 99"
+
+    obj = AT()
+    assert obj.say_something(3) == "hihihi"
+    assert obj.unlucky_number() == 999
+    assert obj.say_everything() == "hi 999"
+
+    for obj in [m.B_Repeat(), m.B_Tpl()]:
+        assert obj.say_something(3) == "B says hi 3 times"
+        assert obj.unlucky_number() == 13
+        assert obj.lucky_number() == 7.0
+        assert obj.say_everything() == "B says hi 1 times 13"
+
+    for obj in [m.C_Repeat(), m.C_Tpl()]:
+        assert obj.say_something(3) == "B says hi 3 times"
+        assert obj.unlucky_number() == 4444
+        assert obj.lucky_number() == 888.0
+        assert obj.say_everything() == "B says hi 1 times 4444"
+
+    class CR(m.C_Repeat):
+        def lucky_number(self):
+            return m.C_Repeat.lucky_number(self) + 1.25
+
+    obj = CR()
+    assert obj.say_something(3) == "B says hi 3 times"
+    assert obj.unlucky_number() == 4444
+    assert obj.lucky_number() == 889.25
+    assert obj.say_everything() == "B says hi 1 times 4444"
+
+    class CT(m.C_Tpl):
+        pass
+
+    obj = CT()
+    assert obj.say_something(3) == "B says hi 3 times"
+    assert obj.unlucky_number() == 4444
+    assert obj.lucky_number() == 888.0
+    assert obj.say_everything() == "B says hi 1 times 4444"
+
+    class CCR(CR):
+        def lucky_number(self):
+            return CR.lucky_number(self) * 10
+
+    obj = CCR()
+    assert obj.say_something(3) == "B says hi 3 times"
+    assert obj.unlucky_number() == 4444
+    assert obj.lucky_number() == 8892.5
+    assert obj.say_everything() == "B says hi 1 times 4444"
+
+    class CCT(CT):
+        def lucky_number(self):
+            return CT.lucky_number(self) * 1000
+
+    obj = CCT()
+    assert obj.say_something(3) == "B says hi 3 times"
+    assert obj.unlucky_number() == 4444
+    assert obj.lucky_number() == 888000.0
+    assert obj.say_everything() == "B says hi 1 times 4444"
+
+    class DR(m.D_Repeat):
+        def unlucky_number(self):
+            return 123
+
+        def lucky_number(self):
+            return 42.0
+
+    for obj in [m.D_Repeat(), m.D_Tpl()]:
+        assert obj.say_something(3) == "B says hi 3 times"
+        assert obj.unlucky_number() == 4444
+        assert obj.lucky_number() == 888.0
+        assert obj.say_everything() == "B says hi 1 times 4444"
+
+    obj = DR()
+    assert obj.say_something(3) == "B says hi 3 times"
+    assert obj.unlucky_number() == 123
+    assert obj.lucky_number() == 42.0
+    assert obj.say_everything() == "B says hi 1 times 123"
+
+    class DT(m.D_Tpl):
+        def say_something(self, times):
+            return "DT says:" + (" quack" * times)
+
+        def unlucky_number(self):
+            return 1234
+
+        def lucky_number(self):
+            return -4.25
+
+    obj = DT()
+    assert obj.say_something(3) == "DT says: quack quack quack"
+    assert obj.unlucky_number() == 1234
+    assert obj.lucky_number() == -4.25
+    assert obj.say_everything() == "DT says: quack 1234"
+
+    class DT2(DT):
+        def say_something(self, times):
+            return "DT2: " + ("QUACK" * times)
+
+        def unlucky_number(self):
+            return -3
+
+    class BT(m.B_Tpl):
+        def say_something(self, times):
+            return "BT" * times
+
+        def unlucky_number(self):
+            return -7
+
+        def lucky_number(self):
+            return -1.375
+
+    obj = BT()
+    assert obj.say_something(3) == "BTBTBT"
+    assert obj.unlucky_number() == -7
+    assert obj.lucky_number() == -1.375
+    assert obj.say_everything() == "BT -7"
+
+
+def test_issue_1454():
+    # Fix issue #1454 (crash when acquiring/releasing GIL on another thread in Python 2.7)
+    m.test_gil()
+    m.test_gil_from_thread()
+
+
+def test_python_override():
+    def func():
+        class Test(m.test_override_cache_helper):
+            def func(self):
+                return 42
+
+        return Test()
+
+    def func2():
+        class Test(m.test_override_cache_helper):
+            pass
+
+        return Test()
+
+    for _ in range(1500):
+        assert m.test_override_cache(func()) == 42
+        assert m.test_override_cache(func2()) == 0
```

## extern/pybind11/tests/extra_python_package/test_files.py

 * *Ordering differences only*

```diff
@@ -1,293 +1,293 @@
-import contextlib
-import os
-import string
-import subprocess
-import sys
-import tarfile
-import zipfile
-
-# These tests must be run explicitly
-# They require CMake 3.15+ (--install)
-
-DIR = os.path.abspath(os.path.dirname(__file__))
-MAIN_DIR = os.path.dirname(os.path.dirname(DIR))
-
-PKGCONFIG = """\
-prefix=${{pcfiledir}}/../../
-includedir=${{prefix}}/include
-
-Name: pybind11
-Description: Seamless operability between C++11 and Python
-Version: {VERSION}
-Cflags: -I${{includedir}}
-"""
-
-
-main_headers = {
-    "include/pybind11/attr.h",
-    "include/pybind11/buffer_info.h",
-    "include/pybind11/cast.h",
-    "include/pybind11/chrono.h",
-    "include/pybind11/common.h",
-    "include/pybind11/complex.h",
-    "include/pybind11/eigen.h",
-    "include/pybind11/embed.h",
-    "include/pybind11/eval.h",
-    "include/pybind11/functional.h",
-    "include/pybind11/gil.h",
-    "include/pybind11/gil_safe_call_once.h",
-    "include/pybind11/iostream.h",
-    "include/pybind11/numpy.h",
-    "include/pybind11/operators.h",
-    "include/pybind11/options.h",
-    "include/pybind11/pybind11.h",
-    "include/pybind11/pytypes.h",
-    "include/pybind11/stl.h",
-    "include/pybind11/stl_bind.h",
-    "include/pybind11/type_caster_pyobject_ptr.h",
-    "include/pybind11/typing.h",
-}
-
-detail_headers = {
-    "include/pybind11/detail/class.h",
-    "include/pybind11/detail/common.h",
-    "include/pybind11/detail/descr.h",
-    "include/pybind11/detail/init.h",
-    "include/pybind11/detail/internals.h",
-    "include/pybind11/detail/type_caster_base.h",
-    "include/pybind11/detail/typeid.h",
-}
-
-eigen_headers = {
-    "include/pybind11/eigen/common.h",
-    "include/pybind11/eigen/matrix.h",
-    "include/pybind11/eigen/tensor.h",
-}
-
-stl_headers = {
-    "include/pybind11/stl/filesystem.h",
-}
-
-cmake_files = {
-    "share/cmake/pybind11/FindPythonLibsNew.cmake",
-    "share/cmake/pybind11/pybind11Common.cmake",
-    "share/cmake/pybind11/pybind11Config.cmake",
-    "share/cmake/pybind11/pybind11ConfigVersion.cmake",
-    "share/cmake/pybind11/pybind11NewTools.cmake",
-    "share/cmake/pybind11/pybind11Targets.cmake",
-    "share/cmake/pybind11/pybind11Tools.cmake",
-}
-
-pkgconfig_files = {
-    "share/pkgconfig/pybind11.pc",
-}
-
-py_files = {
-    "__init__.py",
-    "__main__.py",
-    "_version.py",
-    "commands.py",
-    "py.typed",
-    "setup_helpers.py",
-}
-
-headers = main_headers | detail_headers | eigen_headers | stl_headers
-src_files = headers | cmake_files | pkgconfig_files
-all_files = src_files | py_files
-
-
-sdist_files = {
-    "pybind11",
-    "pybind11/include",
-    "pybind11/include/pybind11",
-    "pybind11/include/pybind11/detail",
-    "pybind11/include/pybind11/eigen",
-    "pybind11/include/pybind11/stl",
-    "pybind11/share",
-    "pybind11/share/cmake",
-    "pybind11/share/cmake/pybind11",
-    "pybind11/share/pkgconfig",
-    "pyproject.toml",
-    "setup.cfg",
-    "setup.py",
-    "LICENSE",
-    "MANIFEST.in",
-    "README.rst",
-    "PKG-INFO",
-    "SECURITY.md",
-}
-
-local_sdist_files = {
-    ".egg-info",
-    ".egg-info/PKG-INFO",
-    ".egg-info/SOURCES.txt",
-    ".egg-info/dependency_links.txt",
-    ".egg-info/not-zip-safe",
-    ".egg-info/top_level.txt",
-}
-
-
-def read_tz_file(tar: tarfile.TarFile, name: str) -> bytes:
-    start = tar.getnames()[0] + "/"
-    inner_file = tar.extractfile(tar.getmember(f"{start}{name}"))
-    assert inner_file
-    with contextlib.closing(inner_file) as f:
-        return f.read()
-
-
-def normalize_line_endings(value: bytes) -> bytes:
-    return value.replace(os.linesep.encode("utf-8"), b"\n")
-
-
-def test_build_sdist(monkeypatch, tmpdir):
-    monkeypatch.chdir(MAIN_DIR)
-
-    subprocess.run(
-        [sys.executable, "-m", "build", "--sdist", f"--outdir={tmpdir}"], check=True
-    )
-
-    (sdist,) = tmpdir.visit("*.tar.gz")
-
-    with tarfile.open(str(sdist), "r:gz") as tar:
-        start = tar.getnames()[0] + "/"
-        version = start[9:-1]
-        simpler = {n.split("/", 1)[-1] for n in tar.getnames()[1:]}
-
-        setup_py = read_tz_file(tar, "setup.py")
-        pyproject_toml = read_tz_file(tar, "pyproject.toml")
-        pkgconfig = read_tz_file(tar, "pybind11/share/pkgconfig/pybind11.pc")
-        cmake_cfg = read_tz_file(
-            tar, "pybind11/share/cmake/pybind11/pybind11Config.cmake"
-        )
-
-    assert (
-        'set(pybind11_INCLUDE_DIR "${PACKAGE_PREFIX_DIR}/include")'
-        in cmake_cfg.decode("utf-8")
-    )
-
-    files = {f"pybind11/{n}" for n in all_files}
-    files |= sdist_files
-    files |= {f"pybind11{n}" for n in local_sdist_files}
-    files.add("pybind11.egg-info/entry_points.txt")
-    files.add("pybind11.egg-info/requires.txt")
-    assert simpler == files
-
-    with open(os.path.join(MAIN_DIR, "tools", "setup_main.py.in"), "rb") as f:
-        contents = (
-            string.Template(f.read().decode("utf-8"))
-            .substitute(version=version, extra_cmd="")
-            .encode("utf-8")
-        )
-    assert setup_py == contents
-
-    with open(os.path.join(MAIN_DIR, "tools", "pyproject.toml"), "rb") as f:
-        contents = f.read()
-    assert pyproject_toml == contents
-
-    simple_version = ".".join(version.split(".")[:3])
-    pkgconfig_expected = PKGCONFIG.format(VERSION=simple_version).encode("utf-8")
-    assert normalize_line_endings(pkgconfig) == pkgconfig_expected
-
-
-def test_build_global_dist(monkeypatch, tmpdir):
-    monkeypatch.chdir(MAIN_DIR)
-    monkeypatch.setenv("PYBIND11_GLOBAL_SDIST", "1")
-    subprocess.run(
-        [sys.executable, "-m", "build", "--sdist", "--outdir", str(tmpdir)], check=True
-    )
-
-    (sdist,) = tmpdir.visit("*.tar.gz")
-
-    with tarfile.open(str(sdist), "r:gz") as tar:
-        start = tar.getnames()[0] + "/"
-        version = start[16:-1]
-        simpler = {n.split("/", 1)[-1] for n in tar.getnames()[1:]}
-
-        setup_py = read_tz_file(tar, "setup.py")
-        pyproject_toml = read_tz_file(tar, "pyproject.toml")
-        pkgconfig = read_tz_file(tar, "pybind11/share/pkgconfig/pybind11.pc")
-        cmake_cfg = read_tz_file(
-            tar, "pybind11/share/cmake/pybind11/pybind11Config.cmake"
-        )
-
-    assert (
-        'set(pybind11_INCLUDE_DIR "${PACKAGE_PREFIX_DIR}/include")'
-        in cmake_cfg.decode("utf-8")
-    )
-
-    files = {f"pybind11/{n}" for n in all_files}
-    files |= sdist_files
-    files |= {f"pybind11_global{n}" for n in local_sdist_files}
-    assert simpler == files
-
-    with open(os.path.join(MAIN_DIR, "tools", "setup_global.py.in"), "rb") as f:
-        contents = (
-            string.Template(f.read().decode())
-            .substitute(version=version, extra_cmd="")
-            .encode("utf-8")
-        )
-        assert setup_py == contents
-
-    with open(os.path.join(MAIN_DIR, "tools", "pyproject.toml"), "rb") as f:
-        contents = f.read()
-        assert pyproject_toml == contents
-
-    simple_version = ".".join(version.split(".")[:3])
-    pkgconfig_expected = PKGCONFIG.format(VERSION=simple_version).encode("utf-8")
-    assert normalize_line_endings(pkgconfig) == pkgconfig_expected
-
-
-def tests_build_wheel(monkeypatch, tmpdir):
-    monkeypatch.chdir(MAIN_DIR)
-
-    subprocess.run(
-        [sys.executable, "-m", "pip", "wheel", ".", "-w", str(tmpdir)], check=True
-    )
-
-    (wheel,) = tmpdir.visit("*.whl")
-
-    files = {f"pybind11/{n}" for n in all_files}
-    files |= {
-        "dist-info/LICENSE",
-        "dist-info/METADATA",
-        "dist-info/RECORD",
-        "dist-info/WHEEL",
-        "dist-info/entry_points.txt",
-        "dist-info/top_level.txt",
-    }
-
-    with zipfile.ZipFile(str(wheel)) as z:
-        names = z.namelist()
-
-    trimmed = {n for n in names if "dist-info" not in n}
-    trimmed |= {f"dist-info/{n.split('/', 1)[-1]}" for n in names if "dist-info" in n}
-    assert files == trimmed
-
-
-def tests_build_global_wheel(monkeypatch, tmpdir):
-    monkeypatch.chdir(MAIN_DIR)
-    monkeypatch.setenv("PYBIND11_GLOBAL_SDIST", "1")
-
-    subprocess.run(
-        [sys.executable, "-m", "pip", "wheel", ".", "-w", str(tmpdir)], check=True
-    )
-
-    (wheel,) = tmpdir.visit("*.whl")
-
-    files = {f"data/data/{n}" for n in src_files}
-    files |= {f"data/headers/{n[8:]}" for n in headers}
-    files |= {
-        "dist-info/LICENSE",
-        "dist-info/METADATA",
-        "dist-info/WHEEL",
-        "dist-info/top_level.txt",
-        "dist-info/RECORD",
-    }
-
-    with zipfile.ZipFile(str(wheel)) as z:
-        names = z.namelist()
-
-    beginning = names[0].split("/", 1)[0].rsplit(".", 1)[0]
-    trimmed = {n[len(beginning) + 1 :] for n in names}
-
-    assert files == trimmed
+import contextlib
+import os
+import string
+import subprocess
+import sys
+import tarfile
+import zipfile
+
+# These tests must be run explicitly
+# They require CMake 3.15+ (--install)
+
+DIR = os.path.abspath(os.path.dirname(__file__))
+MAIN_DIR = os.path.dirname(os.path.dirname(DIR))
+
+PKGCONFIG = """\
+prefix=${{pcfiledir}}/../../
+includedir=${{prefix}}/include
+
+Name: pybind11
+Description: Seamless operability between C++11 and Python
+Version: {VERSION}
+Cflags: -I${{includedir}}
+"""
+
+
+main_headers = {
+    "include/pybind11/attr.h",
+    "include/pybind11/buffer_info.h",
+    "include/pybind11/cast.h",
+    "include/pybind11/chrono.h",
+    "include/pybind11/common.h",
+    "include/pybind11/complex.h",
+    "include/pybind11/eigen.h",
+    "include/pybind11/embed.h",
+    "include/pybind11/eval.h",
+    "include/pybind11/functional.h",
+    "include/pybind11/gil.h",
+    "include/pybind11/gil_safe_call_once.h",
+    "include/pybind11/iostream.h",
+    "include/pybind11/numpy.h",
+    "include/pybind11/operators.h",
+    "include/pybind11/options.h",
+    "include/pybind11/pybind11.h",
+    "include/pybind11/pytypes.h",
+    "include/pybind11/stl.h",
+    "include/pybind11/stl_bind.h",
+    "include/pybind11/type_caster_pyobject_ptr.h",
+    "include/pybind11/typing.h",
+}
+
+detail_headers = {
+    "include/pybind11/detail/class.h",
+    "include/pybind11/detail/common.h",
+    "include/pybind11/detail/descr.h",
+    "include/pybind11/detail/init.h",
+    "include/pybind11/detail/internals.h",
+    "include/pybind11/detail/type_caster_base.h",
+    "include/pybind11/detail/typeid.h",
+}
+
+eigen_headers = {
+    "include/pybind11/eigen/common.h",
+    "include/pybind11/eigen/matrix.h",
+    "include/pybind11/eigen/tensor.h",
+}
+
+stl_headers = {
+    "include/pybind11/stl/filesystem.h",
+}
+
+cmake_files = {
+    "share/cmake/pybind11/FindPythonLibsNew.cmake",
+    "share/cmake/pybind11/pybind11Common.cmake",
+    "share/cmake/pybind11/pybind11Config.cmake",
+    "share/cmake/pybind11/pybind11ConfigVersion.cmake",
+    "share/cmake/pybind11/pybind11NewTools.cmake",
+    "share/cmake/pybind11/pybind11Targets.cmake",
+    "share/cmake/pybind11/pybind11Tools.cmake",
+}
+
+pkgconfig_files = {
+    "share/pkgconfig/pybind11.pc",
+}
+
+py_files = {
+    "__init__.py",
+    "__main__.py",
+    "_version.py",
+    "commands.py",
+    "py.typed",
+    "setup_helpers.py",
+}
+
+headers = main_headers | detail_headers | eigen_headers | stl_headers
+src_files = headers | cmake_files | pkgconfig_files
+all_files = src_files | py_files
+
+
+sdist_files = {
+    "pybind11",
+    "pybind11/include",
+    "pybind11/include/pybind11",
+    "pybind11/include/pybind11/detail",
+    "pybind11/include/pybind11/eigen",
+    "pybind11/include/pybind11/stl",
+    "pybind11/share",
+    "pybind11/share/cmake",
+    "pybind11/share/cmake/pybind11",
+    "pybind11/share/pkgconfig",
+    "pyproject.toml",
+    "setup.cfg",
+    "setup.py",
+    "LICENSE",
+    "MANIFEST.in",
+    "README.rst",
+    "PKG-INFO",
+    "SECURITY.md",
+}
+
+local_sdist_files = {
+    ".egg-info",
+    ".egg-info/PKG-INFO",
+    ".egg-info/SOURCES.txt",
+    ".egg-info/dependency_links.txt",
+    ".egg-info/not-zip-safe",
+    ".egg-info/top_level.txt",
+}
+
+
+def read_tz_file(tar: tarfile.TarFile, name: str) -> bytes:
+    start = tar.getnames()[0] + "/"
+    inner_file = tar.extractfile(tar.getmember(f"{start}{name}"))
+    assert inner_file
+    with contextlib.closing(inner_file) as f:
+        return f.read()
+
+
+def normalize_line_endings(value: bytes) -> bytes:
+    return value.replace(os.linesep.encode("utf-8"), b"\n")
+
+
+def test_build_sdist(monkeypatch, tmpdir):
+    monkeypatch.chdir(MAIN_DIR)
+
+    subprocess.run(
+        [sys.executable, "-m", "build", "--sdist", f"--outdir={tmpdir}"], check=True
+    )
+
+    (sdist,) = tmpdir.visit("*.tar.gz")
+
+    with tarfile.open(str(sdist), "r:gz") as tar:
+        start = tar.getnames()[0] + "/"
+        version = start[9:-1]
+        simpler = {n.split("/", 1)[-1] for n in tar.getnames()[1:]}
+
+        setup_py = read_tz_file(tar, "setup.py")
+        pyproject_toml = read_tz_file(tar, "pyproject.toml")
+        pkgconfig = read_tz_file(tar, "pybind11/share/pkgconfig/pybind11.pc")
+        cmake_cfg = read_tz_file(
+            tar, "pybind11/share/cmake/pybind11/pybind11Config.cmake"
+        )
+
+    assert (
+        'set(pybind11_INCLUDE_DIR "${PACKAGE_PREFIX_DIR}/include")'
+        in cmake_cfg.decode("utf-8")
+    )
+
+    files = {f"pybind11/{n}" for n in all_files}
+    files |= sdist_files
+    files |= {f"pybind11{n}" for n in local_sdist_files}
+    files.add("pybind11.egg-info/entry_points.txt")
+    files.add("pybind11.egg-info/requires.txt")
+    assert simpler == files
+
+    with open(os.path.join(MAIN_DIR, "tools", "setup_main.py.in"), "rb") as f:
+        contents = (
+            string.Template(f.read().decode("utf-8"))
+            .substitute(version=version, extra_cmd="")
+            .encode("utf-8")
+        )
+    assert setup_py == contents
+
+    with open(os.path.join(MAIN_DIR, "tools", "pyproject.toml"), "rb") as f:
+        contents = f.read()
+    assert pyproject_toml == contents
+
+    simple_version = ".".join(version.split(".")[:3])
+    pkgconfig_expected = PKGCONFIG.format(VERSION=simple_version).encode("utf-8")
+    assert normalize_line_endings(pkgconfig) == pkgconfig_expected
+
+
+def test_build_global_dist(monkeypatch, tmpdir):
+    monkeypatch.chdir(MAIN_DIR)
+    monkeypatch.setenv("PYBIND11_GLOBAL_SDIST", "1")
+    subprocess.run(
+        [sys.executable, "-m", "build", "--sdist", "--outdir", str(tmpdir)], check=True
+    )
+
+    (sdist,) = tmpdir.visit("*.tar.gz")
+
+    with tarfile.open(str(sdist), "r:gz") as tar:
+        start = tar.getnames()[0] + "/"
+        version = start[16:-1]
+        simpler = {n.split("/", 1)[-1] for n in tar.getnames()[1:]}
+
+        setup_py = read_tz_file(tar, "setup.py")
+        pyproject_toml = read_tz_file(tar, "pyproject.toml")
+        pkgconfig = read_tz_file(tar, "pybind11/share/pkgconfig/pybind11.pc")
+        cmake_cfg = read_tz_file(
+            tar, "pybind11/share/cmake/pybind11/pybind11Config.cmake"
+        )
+
+    assert (
+        'set(pybind11_INCLUDE_DIR "${PACKAGE_PREFIX_DIR}/include")'
+        in cmake_cfg.decode("utf-8")
+    )
+
+    files = {f"pybind11/{n}" for n in all_files}
+    files |= sdist_files
+    files |= {f"pybind11_global{n}" for n in local_sdist_files}
+    assert simpler == files
+
+    with open(os.path.join(MAIN_DIR, "tools", "setup_global.py.in"), "rb") as f:
+        contents = (
+            string.Template(f.read().decode())
+            .substitute(version=version, extra_cmd="")
+            .encode("utf-8")
+        )
+        assert setup_py == contents
+
+    with open(os.path.join(MAIN_DIR, "tools", "pyproject.toml"), "rb") as f:
+        contents = f.read()
+        assert pyproject_toml == contents
+
+    simple_version = ".".join(version.split(".")[:3])
+    pkgconfig_expected = PKGCONFIG.format(VERSION=simple_version).encode("utf-8")
+    assert normalize_line_endings(pkgconfig) == pkgconfig_expected
+
+
+def tests_build_wheel(monkeypatch, tmpdir):
+    monkeypatch.chdir(MAIN_DIR)
+
+    subprocess.run(
+        [sys.executable, "-m", "pip", "wheel", ".", "-w", str(tmpdir)], check=True
+    )
+
+    (wheel,) = tmpdir.visit("*.whl")
+
+    files = {f"pybind11/{n}" for n in all_files}
+    files |= {
+        "dist-info/LICENSE",
+        "dist-info/METADATA",
+        "dist-info/RECORD",
+        "dist-info/WHEEL",
+        "dist-info/entry_points.txt",
+        "dist-info/top_level.txt",
+    }
+
+    with zipfile.ZipFile(str(wheel)) as z:
+        names = z.namelist()
+
+    trimmed = {n for n in names if "dist-info" not in n}
+    trimmed |= {f"dist-info/{n.split('/', 1)[-1]}" for n in names if "dist-info" in n}
+    assert files == trimmed
+
+
+def tests_build_global_wheel(monkeypatch, tmpdir):
+    monkeypatch.chdir(MAIN_DIR)
+    monkeypatch.setenv("PYBIND11_GLOBAL_SDIST", "1")
+
+    subprocess.run(
+        [sys.executable, "-m", "pip", "wheel", ".", "-w", str(tmpdir)], check=True
+    )
+
+    (wheel,) = tmpdir.visit("*.whl")
+
+    files = {f"data/data/{n}" for n in src_files}
+    files |= {f"data/headers/{n[8:]}" for n in headers}
+    files |= {
+        "dist-info/LICENSE",
+        "dist-info/METADATA",
+        "dist-info/WHEEL",
+        "dist-info/top_level.txt",
+        "dist-info/RECORD",
+    }
+
+    with zipfile.ZipFile(str(wheel)) as z:
+        names = z.namelist()
+
+    beginning = names[0].split("/", 1)[0].rsplit(".", 1)[0]
+    trimmed = {n[len(beginning) + 1 :] for n in names}
+
+    assert files == trimmed
```

## extern/pybind11/tests/extra_setuptools/test_setuphelper.py

 * *Ordering differences only*

```diff
@@ -1,151 +1,151 @@
-import os
-import subprocess
-import sys
-from textwrap import dedent
-
-import pytest
-
-DIR = os.path.abspath(os.path.dirname(__file__))
-MAIN_DIR = os.path.dirname(os.path.dirname(DIR))
-WIN = sys.platform.startswith("win32") or sys.platform.startswith("cygwin")
-
-
-@pytest.mark.parametrize("parallel", [False, True])
-@pytest.mark.parametrize("std", [11, 0])
-def test_simple_setup_py(monkeypatch, tmpdir, parallel, std):
-    monkeypatch.chdir(tmpdir)
-    monkeypatch.syspath_prepend(MAIN_DIR)
-
-    (tmpdir / "setup.py").write_text(
-        dedent(
-            f"""\
-            import sys
-            sys.path.append({MAIN_DIR!r})
-
-            from setuptools import setup, Extension
-            from pybind11.setup_helpers import build_ext, Pybind11Extension
-
-            std = {std}
-
-            ext_modules = [
-                Pybind11Extension(
-                    "simple_setup",
-                    sorted(["main.cpp"]),
-                    cxx_std=std,
-                ),
-            ]
-
-            cmdclass = dict()
-            if std == 0:
-                cmdclass["build_ext"] = build_ext
-
-
-            parallel = {parallel}
-            if parallel:
-                from pybind11.setup_helpers import ParallelCompile
-                ParallelCompile().install()
-
-            setup(
-                name="simple_setup_package",
-                cmdclass=cmdclass,
-                ext_modules=ext_modules,
-            )
-            """
-        ),
-        encoding="ascii",
-    )
-
-    (tmpdir / "main.cpp").write_text(
-        dedent(
-            """\
-            #include <pybind11/pybind11.h>
-
-            int f(int x) {
-                return x * 3;
-            }
-            PYBIND11_MODULE(simple_setup, m) {
-                m.def("f", &f);
-            }
-            """
-        ),
-        encoding="ascii",
-    )
-
-    out = subprocess.check_output(
-        [sys.executable, "setup.py", "build_ext", "--inplace"],
-    )
-    if not WIN:
-        assert b"-g0" in out
-    out = subprocess.check_output(
-        [sys.executable, "setup.py", "build_ext", "--inplace", "--force"],
-        env=dict(os.environ, CFLAGS="-g"),
-    )
-    if not WIN:
-        assert b"-g0" not in out
-
-    # Debug helper printout, normally hidden
-    print(out)
-    for item in tmpdir.listdir():
-        print(item.basename)
-
-    assert (
-        len([f for f in tmpdir.listdir() if f.basename.startswith("simple_setup")]) == 1
-    )
-    assert len(list(tmpdir.listdir())) == 4  # two files + output + build_dir
-
-    (tmpdir / "test.py").write_text(
-        dedent(
-            """\
-            import simple_setup
-            assert simple_setup.f(3) == 9
-            """
-        ),
-        encoding="ascii",
-    )
-
-    subprocess.check_call(
-        [sys.executable, "test.py"], stdout=sys.stdout, stderr=sys.stderr
-    )
-
-
-def test_intree_extensions(monkeypatch, tmpdir):
-    monkeypatch.syspath_prepend(MAIN_DIR)
-
-    from pybind11.setup_helpers import intree_extensions
-
-    monkeypatch.chdir(tmpdir)
-    root = tmpdir
-    root.ensure_dir()
-    subdir = root / "dir"
-    subdir.ensure_dir()
-    src = subdir / "ext.cpp"
-    src.ensure()
-    relpath = src.relto(tmpdir)
-    (ext,) = intree_extensions([relpath])
-    assert ext.name == "ext"
-    subdir.ensure("__init__.py")
-    (ext,) = intree_extensions([relpath])
-    assert ext.name == "dir.ext"
-
-
-def test_intree_extensions_package_dir(monkeypatch, tmpdir):
-    monkeypatch.syspath_prepend(MAIN_DIR)
-
-    from pybind11.setup_helpers import intree_extensions
-
-    monkeypatch.chdir(tmpdir)
-    root = tmpdir / "src"
-    root.ensure_dir()
-    subdir = root / "dir"
-    subdir.ensure_dir()
-    src = subdir / "ext.cpp"
-    src.ensure()
-    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"": "src"})
-    assert ext.name == "dir.ext"
-    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"foo": "src"})
-    assert ext.name == "foo.dir.ext"
-    subdir.ensure("__init__.py")
-    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"": "src"})
-    assert ext.name == "dir.ext"
-    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"foo": "src"})
-    assert ext.name == "foo.dir.ext"
+import os
+import subprocess
+import sys
+from textwrap import dedent
+
+import pytest
+
+DIR = os.path.abspath(os.path.dirname(__file__))
+MAIN_DIR = os.path.dirname(os.path.dirname(DIR))
+WIN = sys.platform.startswith("win32") or sys.platform.startswith("cygwin")
+
+
+@pytest.mark.parametrize("parallel", [False, True])
+@pytest.mark.parametrize("std", [11, 0])
+def test_simple_setup_py(monkeypatch, tmpdir, parallel, std):
+    monkeypatch.chdir(tmpdir)
+    monkeypatch.syspath_prepend(MAIN_DIR)
+
+    (tmpdir / "setup.py").write_text(
+        dedent(
+            f"""\
+            import sys
+            sys.path.append({MAIN_DIR!r})
+
+            from setuptools import setup, Extension
+            from pybind11.setup_helpers import build_ext, Pybind11Extension
+
+            std = {std}
+
+            ext_modules = [
+                Pybind11Extension(
+                    "simple_setup",
+                    sorted(["main.cpp"]),
+                    cxx_std=std,
+                ),
+            ]
+
+            cmdclass = dict()
+            if std == 0:
+                cmdclass["build_ext"] = build_ext
+
+
+            parallel = {parallel}
+            if parallel:
+                from pybind11.setup_helpers import ParallelCompile
+                ParallelCompile().install()
+
+            setup(
+                name="simple_setup_package",
+                cmdclass=cmdclass,
+                ext_modules=ext_modules,
+            )
+            """
+        ),
+        encoding="ascii",
+    )
+
+    (tmpdir / "main.cpp").write_text(
+        dedent(
+            """\
+            #include <pybind11/pybind11.h>
+
+            int f(int x) {
+                return x * 3;
+            }
+            PYBIND11_MODULE(simple_setup, m) {
+                m.def("f", &f);
+            }
+            """
+        ),
+        encoding="ascii",
+    )
+
+    out = subprocess.check_output(
+        [sys.executable, "setup.py", "build_ext", "--inplace"],
+    )
+    if not WIN:
+        assert b"-g0" in out
+    out = subprocess.check_output(
+        [sys.executable, "setup.py", "build_ext", "--inplace", "--force"],
+        env=dict(os.environ, CFLAGS="-g"),
+    )
+    if not WIN:
+        assert b"-g0" not in out
+
+    # Debug helper printout, normally hidden
+    print(out)
+    for item in tmpdir.listdir():
+        print(item.basename)
+
+    assert (
+        len([f for f in tmpdir.listdir() if f.basename.startswith("simple_setup")]) == 1
+    )
+    assert len(list(tmpdir.listdir())) == 4  # two files + output + build_dir
+
+    (tmpdir / "test.py").write_text(
+        dedent(
+            """\
+            import simple_setup
+            assert simple_setup.f(3) == 9
+            """
+        ),
+        encoding="ascii",
+    )
+
+    subprocess.check_call(
+        [sys.executable, "test.py"], stdout=sys.stdout, stderr=sys.stderr
+    )
+
+
+def test_intree_extensions(monkeypatch, tmpdir):
+    monkeypatch.syspath_prepend(MAIN_DIR)
+
+    from pybind11.setup_helpers import intree_extensions
+
+    monkeypatch.chdir(tmpdir)
+    root = tmpdir
+    root.ensure_dir()
+    subdir = root / "dir"
+    subdir.ensure_dir()
+    src = subdir / "ext.cpp"
+    src.ensure()
+    relpath = src.relto(tmpdir)
+    (ext,) = intree_extensions([relpath])
+    assert ext.name == "ext"
+    subdir.ensure("__init__.py")
+    (ext,) = intree_extensions([relpath])
+    assert ext.name == "dir.ext"
+
+
+def test_intree_extensions_package_dir(monkeypatch, tmpdir):
+    monkeypatch.syspath_prepend(MAIN_DIR)
+
+    from pybind11.setup_helpers import intree_extensions
+
+    monkeypatch.chdir(tmpdir)
+    root = tmpdir / "src"
+    root.ensure_dir()
+    subdir = root / "dir"
+    subdir.ensure_dir()
+    src = subdir / "ext.cpp"
+    src.ensure()
+    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"": "src"})
+    assert ext.name == "dir.ext"
+    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"foo": "src"})
+    assert ext.name == "foo.dir.ext"
+    subdir.ensure("__init__.py")
+    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"": "src"})
+    assert ext.name == "dir.ext"
+    (ext,) = intree_extensions([src.relto(tmpdir)], package_dir={"foo": "src"})
+    assert ext.name == "foo.dir.ext"
```

## extern/pybind11/tests/test_cmake_build/test.py

 * *Ordering differences only*

```diff
@@ -1,8 +1,8 @@
-import sys
-
-import test_cmake_build
-
-assert isinstance(__file__, str)  # Test this is properly set
-
-assert test_cmake_build.add(1, 2) == 3
-print(f"{sys.argv[1]} imports, runs, and adds: 1 + 2 = 3")
+import sys
+
+import test_cmake_build
+
+assert isinstance(__file__, str)  # Test this is properly set
+
+assert test_cmake_build.add(1, 2) == 3
+print(f"{sys.argv[1]} imports, runs, and adds: 1 + 2 = 3")
```

## extern/pybind11/tests/test_embed/test_interpreter.py

 * *Ordering differences only*

```diff
@@ -1,14 +1,14 @@
-import sys
-
-from widget_module import Widget
-
-
-class DerivedWidget(Widget):
-    def __init__(self, message):
-        super().__init__(message)
-
-    def the_answer(self):
-        return 42
-
-    def argv0(self):
-        return sys.argv[0]
+import sys
+
+from widget_module import Widget
+
+
+class DerivedWidget(Widget):
+    def __init__(self, message):
+        super().__init__(message)
+
+    def the_answer(self):
+        return 42
+
+    def argv0(self):
+        return sys.argv[0]
```

## extern/pybind11/tests/test_embed/test_trampoline.py

 * *Ordering differences only*

```diff
@@ -1,16 +1,16 @@
-import trampoline_module
-
-
-def func():
-    class Test(trampoline_module.test_override_cache_helper):
-        def func(self):
-            return 42
-
-    return Test()
-
-
-def func2():
-    class Test(trampoline_module.test_override_cache_helper):
-        pass
-
-    return Test()
+import trampoline_module
+
+
+def func():
+    class Test(trampoline_module.test_override_cache_helper):
+        def func(self):
+            return 42
+
+    return Test()
+
+
+def func2():
+    class Test(trampoline_module.test_override_cache_helper):
+        pass
+
+    return Test()
```

## extern/pybind11/tools/codespell_ignore_lines_from_errors.py

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-"""Simple script for rebuilding .codespell-ignore-lines
-
-Usage:
-
-cat < /dev/null > .codespell-ignore-lines
-pre-commit run --all-files codespell >& /tmp/codespell_errors.txt
-python3 tools/codespell_ignore_lines_from_errors.py /tmp/codespell_errors.txt > .codespell-ignore-lines
-
-git diff to review changes, then commit, push.
-"""
-
-import sys
-from typing import List
-
-
-def run(args: List[str]) -> None:
-    assert len(args) == 1, "codespell_errors.txt"
-    cache = {}
-    done = set()
-    with open(args[0]) as f:
-        lines = f.read().splitlines()
-
-    for line in sorted(lines):
-        i = line.find(" ==> ")
-        if i > 0:
-            flds = line[:i].split(":")
-            if len(flds) >= 2:
-                filename, line_num = flds[:2]
-                if filename not in cache:
-                    with open(filename) as f:
-                        cache[filename] = f.read().splitlines()
-                supp = cache[filename][int(line_num) - 1]
-                if supp not in done:
-                    print(supp)
-                    done.add(supp)
-
-
-if __name__ == "__main__":
-    run(args=sys.argv[1:])
+"""Simple script for rebuilding .codespell-ignore-lines
+
+Usage:
+
+cat < /dev/null > .codespell-ignore-lines
+pre-commit run --all-files codespell >& /tmp/codespell_errors.txt
+python3 tools/codespell_ignore_lines_from_errors.py /tmp/codespell_errors.txt > .codespell-ignore-lines
+
+git diff to review changes, then commit, push.
+"""
+
+import sys
+from typing import List
+
+
+def run(args: List[str]) -> None:
+    assert len(args) == 1, "codespell_errors.txt"
+    cache = {}
+    done = set()
+    with open(args[0]) as f:
+        lines = f.read().splitlines()
+
+    for line in sorted(lines):
+        i = line.find(" ==> ")
+        if i > 0:
+            flds = line[:i].split(":")
+            if len(flds) >= 2:
+                filename, line_num = flds[:2]
+                if filename not in cache:
+                    with open(filename) as f:
+                        cache[filename] = f.read().splitlines()
+                supp = cache[filename][int(line_num) - 1]
+                if supp not in done:
+                    print(supp)
+                    done.add(supp)
+
+
+if __name__ == "__main__":
+    run(args=sys.argv[1:])
```

## extern/pybind11/tools/libsize.py

 * *Ordering differences only*

```diff
@@ -1,36 +1,36 @@
-import os
-import sys
-
-# Internal build script for generating debugging test .so size.
-# Usage:
-#     python libsize.py file.so save.txt -- displays the size of file.so and, if save.txt exists, compares it to the
-#                                           size in it, then overwrites save.txt with the new size for future runs.
-
-if len(sys.argv) != 3:
-    sys.exit("Invalid arguments: usage: python libsize.py file.so save.txt")
-
-lib = sys.argv[1]
-save = sys.argv[2]
-
-if not os.path.exists(lib):
-    sys.exit(f"Error: requested file ({lib}) does not exist")
-
-libsize = os.path.getsize(lib)
-
-print("------", os.path.basename(lib), "file size:", libsize, end="")
-
-if os.path.exists(save):
-    with open(save) as sf:
-        oldsize = int(sf.readline())
-
-    if oldsize > 0:
-        change = libsize - oldsize
-        if change == 0:
-            print(" (no change)")
-        else:
-            print(f" (change of {change:+} bytes = {change / oldsize:+.2%})")
-else:
-    print()
-
-with open(save, "w") as sf:
-    sf.write(str(libsize))
+import os
+import sys
+
+# Internal build script for generating debugging test .so size.
+# Usage:
+#     python libsize.py file.so save.txt -- displays the size of file.so and, if save.txt exists, compares it to the
+#                                           size in it, then overwrites save.txt with the new size for future runs.
+
+if len(sys.argv) != 3:
+    sys.exit("Invalid arguments: usage: python libsize.py file.so save.txt")
+
+lib = sys.argv[1]
+save = sys.argv[2]
+
+if not os.path.exists(lib):
+    sys.exit(f"Error: requested file ({lib}) does not exist")
+
+libsize = os.path.getsize(lib)
+
+print("------", os.path.basename(lib), "file size:", libsize, end="")
+
+if os.path.exists(save):
+    with open(save) as sf:
+        oldsize = int(sf.readline())
+
+    if oldsize > 0:
+        change = libsize - oldsize
+        if change == 0:
+            print(" (no change)")
+        else:
+            print(f" (change of {change:+} bytes = {change / oldsize:+.2%})")
+else:
+    print()
+
+with open(save, "w") as sf:
+    sf.write(str(libsize))
```

## extern/pybind11/tools/make_changelog.py

 * *Ordering differences only*

```diff
@@ -1,88 +1,88 @@
-#!/usr/bin/env python3
-from __future__ import annotations
-
-import re
-
-import ghapi.all
-from rich import print
-from rich.syntax import Syntax
-
-ENTRY = re.compile(
-    r"""
-    Suggested \s changelog \s entry:
-    .*
-    ```rst
-    \s*
-    (.*?)
-    \s*
-    ```
-""",
-    re.DOTALL | re.VERBOSE,
-)
-
-print()
-
-
-api = ghapi.all.GhApi(owner="pybind", repo="pybind11")
-
-issues_pages = ghapi.page.paged(
-    api.issues.list_for_repo, labels="needs changelog", state="closed"
-)
-issues = (issue for page in issues_pages for issue in page)
-missing = []
-cats_descr = {
-    "feat": "New Features",
-    "fix": "Bug fixes",
-    "fix(types)": "",
-    "fix(cmake)": "",
-    "docs": "Documentation",
-    "tests": "Tests",
-    "ci": "CI",
-    "chore": "Other",
-    "unknown": "Uncategorised",
-}
-cats: dict[str, list[str]] = {c: [] for c in cats_descr}
-
-for issue in issues:
-    changelog = ENTRY.findall(issue.body or "")
-    if not changelog or not changelog[0]:
-        missing.append(issue)
-    else:
-        (msg,) = changelog
-        if msg.startswith("- "):
-            msg = msg[2:]
-        if not msg.startswith("* "):
-            msg = "* " + msg
-        if not msg.endswith("."):
-            msg += "."
-
-        msg += f"\n  `#{issue.number} <{issue.html_url}>`_"
-        for cat in cats:
-            if issue.title.lower().startswith(f"{cat}:"):
-                cats[cat].append(msg)
-                break
-        else:
-            cats["unknown"].append(msg)
-
-for cat, msgs in cats.items():
-    if msgs:
-        desc = cats_descr[cat]
-        print(f"[bold]{desc}:\n" if desc else "")
-        for msg in msgs:
-            print(Syntax(msg, "rst", theme="ansi_light", word_wrap=True))
-        print()
-
-if missing:
-    print()
-    print("[blue]" + "-" * 30)
-    print()
-
-    for issue in missing:
-        print(f"[red bold]Missing:[/red bold][red] {issue.title}")
-        print(f"[red]  {issue.html_url}\n")
-
-    print("[bold]Template:\n")
-    msg = "## Suggested changelog entry:\n\n```rst\n\n```"
-    print(Syntax(msg, "md", theme="ansi_light"))
-
-print()
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import re
+
+import ghapi.all
+from rich import print
+from rich.syntax import Syntax
+
+ENTRY = re.compile(
+    r"""
+    Suggested \s changelog \s entry:
+    .*
+    ```rst
+    \s*
+    (.*?)
+    \s*
+    ```
+""",
+    re.DOTALL | re.VERBOSE,
+)
+
+print()
+
+
+api = ghapi.all.GhApi(owner="pybind", repo="pybind11")
+
+issues_pages = ghapi.page.paged(
+    api.issues.list_for_repo, labels="needs changelog", state="closed"
+)
+issues = (issue for page in issues_pages for issue in page)
+missing = []
+cats_descr = {
+    "feat": "New Features",
+    "fix": "Bug fixes",
+    "fix(types)": "",
+    "fix(cmake)": "",
+    "docs": "Documentation",
+    "tests": "Tests",
+    "ci": "CI",
+    "chore": "Other",
+    "unknown": "Uncategorised",
+}
+cats: dict[str, list[str]] = {c: [] for c in cats_descr}
+
+for issue in issues:
+    changelog = ENTRY.findall(issue.body or "")
+    if not changelog or not changelog[0]:
+        missing.append(issue)
+    else:
+        (msg,) = changelog
+        if msg.startswith("- "):
+            msg = msg[2:]
+        if not msg.startswith("* "):
+            msg = "* " + msg
+        if not msg.endswith("."):
+            msg += "."
+
+        msg += f"\n  `#{issue.number} <{issue.html_url}>`_"
+        for cat in cats:
+            if issue.title.lower().startswith(f"{cat}:"):
+                cats[cat].append(msg)
+                break
+        else:
+            cats["unknown"].append(msg)
+
+for cat, msgs in cats.items():
+    if msgs:
+        desc = cats_descr[cat]
+        print(f"[bold]{desc}:\n" if desc else "")
+        for msg in msgs:
+            print(Syntax(msg, "rst", theme="ansi_light", word_wrap=True))
+        print()
+
+if missing:
+    print()
+    print("[blue]" + "-" * 30)
+    print()
+
+    for issue in missing:
+        print(f"[red bold]Missing:[/red bold][red] {issue.title}")
+        print(f"[red]  {issue.html_url}\n")
+
+    print("[bold]Template:\n")
+    msg = "## Suggested changelog entry:\n\n```rst\n\n```"
+    print(Syntax(msg, "md", theme="ansi_light"))
+
+print()
```

## Comparing `SuPyMode-1.2.0.dist-info/LICENSE` & `SuPyMode-1.2.1.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-MIT License
-
-Copyright (c) 2020 Martin de Sivry
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2020 Martin de Sivry
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
```

## Comparing `SuPyMode-1.2.0.dist-info/METADATA` & `SuPyMode-1.2.1.dist-info/METADATA`

 * *Files 12% similar despite different names*

```diff
@@ -1,170 +1,171 @@
-Metadata-Version: 2.1
-Name: SuPyMode
-Version: 1.2.0
-Summary: A package for light propagation in fiber optics.
-Home-page: https://github.com/MartinPdeS/SuPyMode
-Author: Martin Poinsinet de Sivry
-Author-email: Martin.poinsinet.de.sivry@gmail.com
-License: MIT
-Platform: unix
-Platform: linux
-Platform: osx
-Platform: windows
-Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Programming Language :: Python :: 3.12
-Classifier: Programming Language :: Python :: Implementation :: CPython
-Classifier: Development Status :: 4 - Beta
-Classifier: Operating System :: OS Independent
-Classifier: Topic :: Scientific/Engineering :: Physics
-Classifier: Intended Audience :: Telecommunications Industry
-Classifier: Intended Audience :: Science/Research
-Description-Content-Type: text/x-rst
-License-File: LICENSE
-Requires-Dist: MPSPlots ==1.4.0
-Requires-Dist: PyFinitDiff ==1.1.2
-Requires-Dist: FiberFusing ==1.2.1
-Requires-Dist: scipy ==1.11.3
-Requires-Dist: matplotlib
-Requires-Dist: pathvalidate ==3.2.0
-Provides-Extra: documentation
-Requires-Dist: numpydoc ==1.6.0 ; extra == 'documentation'
-Requires-Dist: sphinx >=5.1.1 ; extra == 'documentation'
-Requires-Dist: sphinx-gallery ==0.15.0 ; extra == 'documentation'
-Requires-Dist: sphinx-rtd-theme ==2.0.0 ; extra == 'documentation'
-Requires-Dist: pydata-sphinx-theme ==0.14.1 ; extra == 'documentation'
-Requires-Dist: PyFiberModes ==0.2.39 ; extra == 'documentation'
-Provides-Extra: testing
-Requires-Dist: pytest >=0.6 ; extra == 'testing'
-Requires-Dist: pytest-cov >=2.0 ; extra == 'testing'
-Requires-Dist: pytest-json-report ==1.5.0 ; extra == 'testing'
-Requires-Dist: mypy >=0.910 ; extra == 'testing'
-Requires-Dist: flake8 >=3.9 ; extra == 'testing'
-Requires-Dist: tox >=3.24 ; extra == 'testing'
-Requires-Dist: coverage ==6.5.0 ; extra == 'testing'
-Requires-Dist: PyFiberModes ==0.2.39 ; extra == 'testing'
-
-SuPyMode
-========
-
-|python|
-|docs|
-|Citation|
-|Unittest|
-|PyPi|
-|PyPi_download|
-|colab|
-
-
-..  figure:: https://github.com/MartinPdeS/SuPyMode/blob/master/docs/images/mode_propagation.gif?raw=true
-   :alt: some image
-   :class: with-shadow float-left
-   :width: 800px
-
-   Propagation of mode in an adiabatic 2x1 modally-specific photonic lantern.
-
-
-
-
-This project aims to develop an useful tool design and optimize fiber optic tapered component.
-SuPyMode is a Python library linked to a c++ core allowing for a flexible interface and fast computing core.
-The library also aims to offer the end-user a great vizual tools for data analysis.
-To this day, SuPyMode as been proven a useful tool to develop very-short 2x1 and 3x1 modally specific photonic lantern with very low loss and cross-talk.
-
-----
-
-Documentation
-**************
-All the latest available documentation is available `here <https://supymodes.readthedocs.io/en/latest/>`_ or you can click the following badge:
-
-|docs|
-
-
-----
-
-
-Installation
-------------
-
-
-Pip installation
-****************
-
-The package have been uploaded as wheel for a few OS (Linux, MacOS) and need Python 3.10.
-As such, with the adequate configuration one can simply do
-
-.. code-block:: python
-
-   >>> pip3 install SuPyMode
-
-
-
-Manual installation
-*******************
-
-To install manually (os independent) you will need to install:
-
-1. cmake (3.16+)
-
-Then, download and install the SuPyMode package:
-
-.. code-block:: python
-
-    >>> git clone --recurse-submodules https://github.com/MartinPdeS/SuPyMode.git
-    >>> cd SuPyMode && mkdir build && cd build
-    >>> cmake ..
-    >>> cmake --build .
-    >>> cd ..
-    >>> pip3 install .
-
-----
-
-Testing
-*******
-
-Make sure to install both coverage and pytest using ``pip3 install coverage pytest``. To test locally (with cloning the GitHub repository) you'll need to install the dependencies and run the coverage command as
-
-.. code:: python
-
-   >>> git clone --recurse-submodules https://github.com/MartinPdeS/SuPyMode.git
-   >>> cd SuPyMode
-   >>> pip3 install PyFiberModes
-   >>> coverage run --source=SuPyMode --module pytest --verbose tests
-   >>> coverage report --show-missing
-
-----
-
-Contact Information
-*******************
-
-As of 2023 the project is still under development if you want to collaborate it would be a pleasure. I encourage you to contact me.
-
-SuPyMode was written by `Martin Poinsinet de Sivry-Houle <https://github.com/MartinPdS>`_  .
-
-Email:`martin.poinsinet-de-sivry@polymtl.ca <mailto:martin.poinsinet-de-sivry@polymtl.ca?subject=SuPyMode>`_ .
-
-
-.. |python| image:: https://img.shields.io/badge/Made%20with-Python-1f425f.svg
-   :target: https://www.python.org/
-
-.. |docs| image:: https://readthedocs.org/projects/supymodes/badge/?version=latest
-   :target: https://supymodes.readthedocs.io/en/latest/
-   :alt: Documentation Status
-
-.. |Citation| image:: https://zenodo.org/badge/366930899.svg
-   :target: https://zenodo.org/badge/latestdoi/366930899
-
-.. |Unittest| image:: https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/MartinPdeS/8e5ebf39ed694d3c90a790dffc0eff4f/raw
-
-.. |PyPi| image:: https://badge.fury.io/py/SuPyMode.svg
-   :target: https://pypi.org/project/SuPyMode/
-
-.. |PyPi_download| image:: https://img.shields.io/pypi/dm/supymode.svg
-   :target: https://pypistats.org/packages/supymode
-
-.. |colab| image:: https://colab.research.google.com/assets/colab-badge.svg
-   :target: https://colab.research.google.com/github/MartinPdeS/SuPyMode/blob/master/SuPyModes.ipynb
-
-
-
+Metadata-Version: 2.1
+Name: SuPyMode
+Version: 1.2.1
+Summary: A package for light propagation in fiber optics.
+Home-page: https://github.com/MartinPdeS/SuPyMode
+Author: Martin Poinsinet de Sivry
+Author-email: Martin.poinsinet.de.sivry@gmail.com
+License: MIT
+Platform: unix
+Platform: linux
+Platform: osx
+Platform: windows
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Development Status :: 4 - Beta
+Classifier: Operating System :: OS Independent
+Classifier: Topic :: Scientific/Engineering :: Physics
+Classifier: Intended Audience :: Telecommunications Industry
+Classifier: Intended Audience :: Science/Research
+Description-Content-Type: text/x-rst
+License-File: LICENSE
+Requires-Dist: MPSPlots ==1.4.0
+Requires-Dist: PyFinitDiff ==1.1.2
+Requires-Dist: FiberFusing ==1.2.1
+Requires-Dist: scipy ==1.11.3
+Requires-Dist: matplotlib
+Requires-Dist: pathvalidate ==3.2.0
+Requires-Dist: pydantic ==2.6.3
+Provides-Extra: documentation
+Requires-Dist: numpydoc ==1.6.0 ; extra == 'documentation'
+Requires-Dist: sphinx >=5.1.1 ; extra == 'documentation'
+Requires-Dist: sphinx-gallery ==0.15.0 ; extra == 'documentation'
+Requires-Dist: sphinx-rtd-theme ==2.0.0 ; extra == 'documentation'
+Requires-Dist: pydata-sphinx-theme ==0.14.1 ; extra == 'documentation'
+Requires-Dist: PyFiberModes ==0.2.39 ; extra == 'documentation'
+Provides-Extra: testing
+Requires-Dist: pytest >=0.6 ; extra == 'testing'
+Requires-Dist: pytest-cov >=2.0 ; extra == 'testing'
+Requires-Dist: pytest-json-report ==1.5.0 ; extra == 'testing'
+Requires-Dist: mypy >=0.910 ; extra == 'testing'
+Requires-Dist: flake8 >=3.9 ; extra == 'testing'
+Requires-Dist: tox >=3.24 ; extra == 'testing'
+Requires-Dist: coverage ==6.5.0 ; extra == 'testing'
+Requires-Dist: PyFiberModes ==0.2.39 ; extra == 'testing'
+
+SuPyMode
+========
+
+|python|
+|docs|
+|Citation|
+|Unittest|
+|PyPi|
+|PyPi_download|
+|colab|
+
+
+..  figure:: https://github.com/MartinPdeS/SuPyMode/blob/master/docs/images/mode_propagation.gif?raw=true
+   :alt: some image
+   :class: with-shadow float-left
+   :width: 800px
+
+   Propagation of mode in an adiabatic 2x1 modally-specific photonic lantern.
+
+
+
+
+This project aims to develop an useful tool design and optimize fiber optic tapered component.
+SuPyMode is a Python library linked to a c++ core allowing for a flexible interface and fast computing core.
+The library also aims to offer the end-user a great vizual tools for data analysis.
+To this day, SuPyMode as been proven a useful tool to develop very-short 2x1 and 3x1 modally specific photonic lantern with very low loss and cross-talk.
+
+----
+
+Documentation
+**************
+All the latest available documentation is available `here <https://supymodes.readthedocs.io/en/latest/>`_ or you can click the following badge:
+
+|docs|
+
+
+----
+
+
+Installation
+------------
+
+
+Pip installation
+****************
+
+The package have been uploaded as wheel for a few OS (Linux, MacOS) and need Python 3.10.
+As such, with the adequate configuration one can simply do
+
+.. code-block:: python
+
+   >>> pip3 install SuPyMode
+
+
+
+Manual installation
+*******************
+
+To install manually (os independent) you will need to install:
+
+1. cmake (3.16+)
+
+Then, download and install the SuPyMode package:
+
+.. code-block:: python
+
+    >>> git clone --recurse-submodules https://github.com/MartinPdeS/SuPyMode.git
+    >>> cd SuPyMode && mkdir build && cd build
+    >>> cmake ..
+    >>> cmake --build .
+    >>> cd ..
+    >>> pip3 install .
+
+----
+
+Testing
+*******
+
+Make sure to install both coverage and pytest using ``pip3 install coverage pytest``. To test locally (with cloning the GitHub repository) you'll need to install the dependencies and run the coverage command as
+
+.. code:: python
+
+   >>> git clone --recurse-submodules https://github.com/MartinPdeS/SuPyMode.git
+   >>> cd SuPyMode
+   >>> pip3 install PyFiberModes
+   >>> coverage run --source=SuPyMode --module pytest --verbose tests
+   >>> coverage report --show-missing
+
+----
+
+Contact Information
+*******************
+
+As of 2023 the project is still under development if you want to collaborate it would be a pleasure. I encourage you to contact me.
+
+SuPyMode was written by `Martin Poinsinet de Sivry-Houle <https://github.com/MartinPdS>`_  .
+
+Email:`martin.poinsinet-de-sivry@polymtl.ca <mailto:martin.poinsinet-de-sivry@polymtl.ca?subject=SuPyMode>`_ .
+
+
+.. |python| image:: https://img.shields.io/badge/Made%20with-Python-1f425f.svg
+   :target: https://www.python.org/
+
+.. |docs| image:: https://readthedocs.org/projects/supymodes/badge/?version=latest
+   :target: https://supymodes.readthedocs.io/en/latest/
+   :alt: Documentation Status
+
+.. |Citation| image:: https://zenodo.org/badge/366930899.svg
+   :target: https://zenodo.org/badge/latestdoi/366930899
+
+.. |Unittest| image:: https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/MartinPdeS/8e5ebf39ed694d3c90a790dffc0eff4f/raw
+
+.. |PyPi| image:: https://badge.fury.io/py/SuPyMode.svg
+   :target: https://pypi.org/project/SuPyMode/
+
+.. |PyPi_download| image:: https://img.shields.io/pypi/dm/supymode.svg
+   :target: https://pypistats.org/packages/supymode
+
+.. |colab| image:: https://colab.research.google.com/assets/colab-badge.svg
+   :target: https://colab.research.google.com/github/MartinPdeS/SuPyMode/blob/master/SuPyModes.ipynb
+
+
+
```

## Comparing `SuPyMode-1.2.0.dist-info/RECORD` & `SuPyMode-1.2.1.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,142 +1,143 @@
-SuPyMode/VERSION,sha256=pkcIsBDivPYoFU3cIF7UloimNH75OmakJJJDD2PwIbE,7
-SuPyMode/__init__.py,sha256=Bpg3W59JPi806tYYi-UFH3IGlbeb-VzedVpo8WevbaI,52
-SuPyMode/directories.py,sha256=nWDOBTB-chyHBHUTOkOy-wJHylLX3yHlFmT4rzYCUVs,1165
-SuPyMode/mode_label.py,sha256=SczeSYwK1A2m7xxJ-KJPCEIaHtvPi35uvYLny06qzUs,5219
-SuPyMode/profiles.py,sha256=PjOTV7Kg1UxbGaBLwwQ4Fb7QYtrP3mAdHy9NQWjNgTQ,31102
-SuPyMode/solver.py,sha256=XNEnOGhIjONuhrv10ZNZcVJRe5uxubDSTVbgaBqL2PI,9049
-SuPyMode/special.py,sha256=cwuVcMrxtRbbM60gByR5bfEgsoJF1pTYwU9TNYvyr1M,4775
-SuPyMode/supermode.py,sha256=ZIE31qqm8M60Pn3xD7LO_xhi6m6flODh_wNzXEsLylw,10578
-SuPyMode/superset.py,sha256=tBS1AtAkvGi0nw-_0UtZfmJhJDKediKHTQWFAGA6aPE,41698
-SuPyMode/utils.py,sha256=Q5IWsy8q_l3PYv23HTsNpdrJ1mzbmCVmA66qglxzRIo,9808
-SuPyMode/workflow.py,sha256=iIuBOEXqx-SikJurTq4NHozqnGMNfSttFbXFXA8oESw,14653
-SuPyMode/binary/CppSolver.cp311-win_amd64.pyd,sha256=B6XJlp80opMoXllMOCbzZnoa2Uds-lbHi60WMi2XFoU,1485312
-SuPyMode/binary/CppSolver.cp312-win_amd64.pyd,sha256=shLsBUQPexYqrS8mnGWmPbM1FvKDVWDE5NbOLZitUB4,1483776
-SuPyMode/binary/Example.cp311-win_amd64.pyd,sha256=L7ysHfxVGIz_6gyRcL-IzOx-0_KsN5z3mGz2xQ42Qc8,1078272
-SuPyMode/binary/Example.cp312-win_amd64.pyd,sha256=SKLhVGSspPpI5yVDjpEaI0l7sUtZj0R-4t1mO4P7PlQ,1078272
-SuPyMode/binary/ModelParameters.cp311-win_amd64.pyd,sha256=xcMcWDw37tsa4PHFvs0QNwsgcm60q3tV1tqRf-XTRnY,1122816
-SuPyMode/binary/ModelParameters.cp312-win_amd64.pyd,sha256=qghPuN4lGa23DCOyQO8dc1Gs0CWLjeNObZvvqOGi7nY,1123328
-SuPyMode/binary/SuperMode.cp311-win_amd64.pyd,sha256=9E5Ez9NQicQcmk8X3RGXvz4zFnClJQEK0vjj7lCV1qA,1157120
-SuPyMode/binary/SuperMode.cp312-win_amd64.pyd,sha256=mU33CUUgtVrr6SQSQOepYP9_OSXU1QVqTW3tcDd3694,1156608
-SuPyMode/binary/__init__.py,sha256=frcCV1k9oG9oKj3dpUqdJg1PxRT2RSN_XKdLCPjaYaY,2
-SuPyMode/representation/__init__.py,sha256=CIPkjhqrdVAaV92WfRaYrBAhmRREfQV-0FudypEKmNs,253
-SuPyMode/representation/adiabatic.py,sha256=lwmnWLkSCqSVuD1BR5WUWkHyBVnkcFG9BdWocbOR5_Y,3964
-SuPyMode/representation/base.py,sha256=2-eRL956PcsYuhWKCzza_CBG5xLfutHOd6EKJ3LC-58,4205
-SuPyMode/representation/beating_length.py,sha256=_XKlJeyJtthqfIMyRBxP8sEQaS30XU56THKMENnECbw,3473
-SuPyMode/representation/beta.py,sha256=8sX-4ok5_7QFGGY0M4-6BeYfGJxq6rytrfk3S0J__Sw,2762
-SuPyMode/representation/eigen_value.py,sha256=3Qy2JEv5QdwSR_jr1URxWJgF_62G4CBsQ2HLslKdZc8,2501
-SuPyMode/representation/field.py,sha256=3Ga0Xg2_ZJtLutT6yfESww7id9bHy8BenDVZE0Td7ww,12984
-SuPyMode/representation/index.py,sha256=GD0NBAoo3UROAxVbmle_6JKUAjXMY3btApgDiHCaxIw,2667
-SuPyMode/representation/normalized_coupling.py,sha256=zQUP3x8krrhv04WUQ2eXkYjWe7BLldMAt8wmVWUx8ew,3831
-SuPyMode/tools/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-SuPyMode/tools/special.py,sha256=cwuVcMrxtRbbM60gByR5bfEgsoJF1pTYwU9TNYvyr1M,4775
-SuPyMode/tools/utils.py,sha256=pcd_Sqab0IeB0KjiewwAp1QBEueF0m-zRkZQrIe3fH8,8943
-SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP02.csv,sha256=j0ybGVc3SmFcwrsK8MGyW1TY0QHRuXaNoiSNEQUbmYY,4073
-SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP21.csv,sha256=E6AshwC1Fu87mg2e9TkLC4-HZUmWSqha7Ext-TiVh7s,3640
-SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP41.csv,sha256=E9DXjgBQTUKnOP_DbUq2iwZy_lzD6MamUQR5MLWkYD8,3552
-SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP12.csv,sha256=ra1S20zmBTXZ8HU0SqRR_Ms_5fhPNCppTRA2mEz-vXo,3435
-SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP31.csv,sha256=KlOx0xrVh02eklLTjxSvJe6NBv4Qjopm85J9GSJTVDk,3871
-SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP51.csv,sha256=EZ1sv0B5--UCImPpknu669oyKtPNLUJTuNfG_h7KpIc,3351
-SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP02.csv,sha256=dVTY2BJANQL8IOV_VHOclnDoSQpCJTJklBfh8SQS1s8,11801
-SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP21.csv,sha256=oOWGCwlufEzh2CsJz4z2HIhP8O2IX7L04LkHXXlWDig,3180
-SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP41.csv,sha256=YiLbzJqQ-kwEQc2Xq_XMqdYpXyV6AREh4tKFM4KNFKQ,9766
-SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP12.csv,sha256=f1EgCIevVz9dggpXWIZBVj15KiGdeVnbGXAGjUQi8ts,5278
-SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP31.csv,sha256=VvIhe6OE5OfHbTuc30yUPoyzWB7B5hRk1IgnwAfTgkc,6584
-SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP51.csv,sha256=eRUF3mav8mN9wmV-sSLC6yh-jK4eSVhW39-hvd1cPig,9280
-developments/gradient_tests_2.py,sha256=eM3DbTFmRUByCeon3FYTrSiyrrRjErW7bIF_avAcJnA,1129
-developments/validation.py,sha256=9ocXrQ-0ljVVqo_OiE37rkkpZ33icUZcFL1vpdLp64I,4038
-developments/validation_2.py,sha256=ErN6LjFoNzQ4K5hOX9pIPAKGarxJGNlqldGuGBk-ibg,4045
-docs/examples/basic/plot_alpha_profile_0.py,sha256=V12fCuK-DeZiPFw3-hE2YvdF0z9VKWQJk3fgbq1pSc8,718
-docs/examples/basic/plot_alpha_profile_1.py,sha256=rABdmTUGeTrkSB7rX8XFkI-JPo1uwzRko-bGPC4spao,757
-docs/examples/basic/plot_workflow_01.py,sha256=ZdAMr3N3mOUOdl_NxoQ_q07tkoPixwr7PGv90A07EVg,3117
-docs/examples/basic/plot_workflow_02.py,sha256=3iUYM2sqEUI8hHw7b_EDcx8MeA_JUE2Qg2uLpMrsO0Q,3195
-docs/examples/basic/plot_workflow_03.py,sha256=gdCPpuaENvSA_DMfEAC402qbL0LNh1N-geTbHsOSc80,3644
-docs/examples/basic/plot_workflow_04.py,sha256=RjVxgEyfYjFsqaCIAtj_oUueQ23djGjHa0-tqie3vWk,3244
-docs/examples/basic/plot_workflow_05.py,sha256=onH24k4cRXYbBi25FqAS84EP7f4o_yvQsKtICbreAOQ,3615
-docs/examples/basic/plot_workflow_06.py,sha256=5-gQWZHIApZjDVWwH2ZE8cWQKV3dLM6vv4U1JtAl0EM,3699
-docs/examples/basic/plot_workflow_07.py,sha256=cB_mZefe0MMcAYDIN90rha8KF4fiu7GCj6n0bBsw0YY,3321
-docs/examples/basic/plot_workflow_08.py,sha256=jOA_07ED7ACweQpLTLddsYsi6fhoh4_n9gCerYsvTco,3300
-docs/examples/validation/plot_beta_DCF.py,sha256=Y_TEg_57HxRfyO5Yvbu6hpqRZ_RNQyU7Fgk4ST5ps4w,3580
-docs/examples/validation/plot_beta_SMF28.py,sha256=l5wtRnI_5uf3oWTpzd5pXEMQjkbZQfykvkbvYtiRZPQ,3573
-docs/examples/validation/plot_normalized_coupling_DCF.py,sha256=UDDhaRpzlwSA2r8aRgsy1j1U3oFLXZc0o6vAO3fm5eo,3743
-docs/examples/validation/plot_normalized_coupling_SMF28.py,sha256=J1bm-AfTgmXcFE3iws-_4vi0PnFZoZu5vtZOax8Dpwo,3912
-docs/examples/validation/plot_validation.py,sha256=Y52CW_WLfYX6k5l06lR9ezHn8XuQpUCgABxgvreJ51c,5878
-docs/legacy/__debug__.py,sha256=lyiUh90a4Pi3j-OhYO9yp2teHML8IlJxZxpaQJ9w3Js,1726
-docs/legacy/python_debuging/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-docs/legacy/python_debuging/eigen_solver.py,sha256=jKWwtV6KS3pwRpy35n-aU5w_xajE9qs02wNUQpL0b8E,11485
-docs/legacy/python_debuging/mode_solver.py,sha256=z2sfLwh147ZjrQYGw9nmoJI5Im3VaL-2L5ibm-m3CO0,13021
-docs/source/conf.py,sha256=NA0sdw-U6RnmowK_94ncHRDRpAJu9C7yZBFJ3B2Mfig,4479
-extern/eigen/debug/gdb/__init__.py,sha256=Zm25_g-Pu7xBYyUqKD4MgNKVDKx1dkzPUr99Wh4ptAg,23
-extern/eigen/debug/gdb/printers.py,sha256=Z6BPQsF75qJmbJ2Xl-UBUiO6rloj1Qop00t5Q2Ch3GA,9931
-extern/eigen/scripts/relicense.py,sha256=9bC_4t-_u2cyzKL3-iKk7bDNUNYnXO0EvQUcASfpCUM,2437
-extern/pybind11/noxfile.py,sha256=PdQfwsFP_cW_Oe0V0hyamFVvPOFSTxJPkKB8-IniyAQ,2853
-extern/pybind11/setup.py,sha256=6y7BV5FX9E3xt0JHbLOFo65lp9xMEuKw8GDaPCDKFck,5005
-extern/pybind11/docs/benchmark.py,sha256=xGe51SxzhQEqBC4uVlj9U4uqXtkTPW4geLfrlu2-2dA,2940
-extern/pybind11/docs/conf.py,sha256=0QNgwuj4TUvnRT8cVh-prR0QFsZWVdYYGI1xEhjME5k,11942
-extern/pybind11/pybind11/__init__.py,sha256=dksfY3nzoZ03AJcx_f2hcVJM3ux4iRtkFEQIOUav3GQ,446
-extern/pybind11/pybind11/__main__.py,sha256=14R-y51seeb0de65x1CZt2picXBvL-N96jdtzUCC5CU,1606
-extern/pybind11/pybind11/_version.py,sha256=baz8zXhXiq5xRnu7-Hc8rSoNdnqdh5UJuH6mN0kl4Mk,245
-extern/pybind11/pybind11/commands.py,sha256=hyYsANrDUOF0XUe7vNu6jnslBu8JA7IjWLRzt8aujYI,1244
-extern/pybind11/pybind11/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-extern/pybind11/pybind11/setup_helpers.py,sha256=2HvR1iefibmaJHZeJSZsiqzUeVgSKueiF0hm-24En-M,17992
-extern/pybind11/tests/conftest.py,sha256=ht-r2-RRVyFIPSK7WcaIrZDnKwX0cd_FfgApfaCYoJ8,5840
-extern/pybind11/tests/env.py,sha256=rlhsR46zq6hWxjckIdq2wU4qYCRW-XLg_OD5eYbigaE,953
-extern/pybind11/tests/test_async.py,sha256=LMpCIiMyta3ATovOt0BJpARJhW6eRlnG9mVmBGbzLPQ,560
-extern/pybind11/tests/test_buffers.py,sha256=t1VbhqduXTI69mUVWFhTQ435ZvMxE7w0Kub0Y8BRLBU,7352
-extern/pybind11/tests/test_builtin_casters.py,sha256=EVR_8ZOVv9MX5BXytKl8MtRyvFbHz8Dba7huvPxZFFU,17771
-extern/pybind11/tests/test_call_policies.py,sha256=Thh9Q_wck4D9tvvP7wl1S_rLXsKijl8mkfq6RQ0AwR8,6796
-extern/pybind11/tests/test_callbacks.py,sha256=Dv9AJvI_UzzedSQJkdr1gbGbE9tPCWoQ0KnvFazJORM,7180
-extern/pybind11/tests/test_chrono.py,sha256=mLKoPUYSSuEwgcUVZz-fZwR_xEj80SZVAZpEPChNgWM,5896
-extern/pybind11/tests/test_class.py,sha256=AkC7uXmcViRggpqu2ytQYI-qr3dG9xNmGDgZEYii14M,15686
-extern/pybind11/tests/test_const_name.py,sha256=fjcJk1OfS-rX_fe0kW3xa_rhugRSq-d_36Y8-gGt98Q,622
-extern/pybind11/tests/test_constants_and_functions.py,sha256=zuHPrzAS4LjiSKA_qLqQk4XUi50hIjeFGGEd0N1O21o,1607
-extern/pybind11/tests/test_copy_move.py,sha256=uMh4eQn7oDQl-PHaWzq-SLKaQvyNEaZjeMtIoqie5ek,4928
-extern/pybind11/tests/test_custom_type_casters.py,sha256=I391JdDY5jAnYYoyvDJWllUOt5s5F0pvt5JK5XS7yzg,4114
-extern/pybind11/tests/test_custom_type_setup.py,sha256=jVuY5CRB6iGJ4S_p6ug1b7b_yPzs-wnq_GjB44Xz3dM,1139
-extern/pybind11/tests/test_docstring_options.py,sha256=e2p8DRsIXyR9_1yeONGV3oVOeeYhTASsiIQQJEr1_dk,2487
-extern/pybind11/tests/test_eigen_matrix.py,sha256=Bx_qhR2OUVdaceQWtDcO-xE411VuaY1glsOA4Am77Eg,29962
-extern/pybind11/tests/test_eigen_tensor.py,sha256=h5aqhHcrGSe3itJb3iD1x9J3UR-nDjPGJvyfEMQRBtE,9702
-extern/pybind11/tests/test_enum.py,sha256=RmbCpgeu6-ZMoQTro2CNdJX3PTgyADYn9iVVo78MGD4,9338
-extern/pybind11/tests/test_eval.py,sha256=uhk8ZP_UXyXbFVhTuISqhvDI9GTSu0cGfNuucdQcheE,1193
-extern/pybind11/tests/test_eval_call.py,sha256=u7UlNV-aeggzw6AKA3847r6EWmPXTV9v17DJXJRGY0U,123
-extern/pybind11/tests/test_exceptions.py,sha256=2UX6QeEjUY18bYB_xx370kcbzegUEOcUvaeD8jFT8bw,14586
-extern/pybind11/tests/test_factory_constructors.py,sha256=SSF2f3wl1IjZcIpaBcGPssNWEWffRfPhZlzQp9p-rkI,17007
-extern/pybind11/tests/test_gil_scoped.py,sha256=Joqyyn1Bzj7c3O4rrt6hKbPssV-CT89CxxPx1-B5H5Q,8749
-extern/pybind11/tests/test_iostream.py,sha256=n0Vx0ExVCpfaal49VBDrWJBUosOemnzlRDGAo1DCxG0,7435
-extern/pybind11/tests/test_kwargs_and_defaults.py,sha256=6P6lhOjkE98TFM_WFc_yF7KY7hjbBXWJ5scMWJrp_pk,15281
-extern/pybind11/tests/test_local_bindings.py,sha256=H-grO_Kz_byDZL34o2m_GSUkxxWgAQN8HJ-T6UgU0tc,8311
-extern/pybind11/tests/test_methods_and_attributes.py,sha256=sROpAHvquy0hYQ5doltCORjj0gKMzbp85400_LJIG7k,18963
-extern/pybind11/tests/test_modules.py,sha256=1RhI2YP1uu4dRhjnYVv6zOKrlq_eCrsmwR3Ado4RD94,4079
-extern/pybind11/tests/test_multiple_inheritance.py,sha256=aidGjgyDdHlLIpyBXt-KKG8fSHDdQczuz-di4i8q34o,12367
-extern/pybind11/tests/test_numpy_array.py,sha256=nUv3ZhJMt1Zi4tVjfy4D1lyRuMDm2QxuxRL5arvx68E,23560
-extern/pybind11/tests/test_numpy_dtypes.py,sha256=doEjvSiIwjFSLtyQdHUXyLfAYF-2DDp_-9hkfOdChHs,14712
-extern/pybind11/tests/test_numpy_vectorize.py,sha256=Aww_lfMh436PJeLFdee32l_ReSvpab46eCOLKgdXJSY,9924
-extern/pybind11/tests/test_opaque_types.py,sha256=VQkfjmjOQrIAqGohE0Jc82Q3nyWOt1OMahw9RHlJ7VQ,1905
-extern/pybind11/tests/test_operator_overloading.py,sha256=8fX_td5nXACSzh-B5BUA8H7pO4WSjd-hWKrjwioId9I,4483
-extern/pybind11/tests/test_pickling.py,sha256=ak4g7rDTDrUaK0JZ__f_FTn54GR9tNPV1yY3njnNaDM,2813
-extern/pybind11/tests/test_python_multiple_inheritance.py,sha256=k4R6VIo0qILyISwlLgSmtOiTtIRDKgIAMN27bsuL5B8,894
-extern/pybind11/tests/test_pytypes.py,sha256=frQ1rkOBZ4OVN3RpwQIrPK4ESygylTZVsg6hxLhgQww,26013
-extern/pybind11/tests/test_sequences_and_iterators.py,sha256=aa9nLfH8tv8PAGn0WQIBe55FsgwRKxhQlx64BkNoFcc,8924
-extern/pybind11/tests/test_smart_ptr.py,sha256=1HLW1_YNMdMPYrxYOavNlqu2ymDt5AjFYoC9pZPiqxY,9845
-extern/pybind11/tests/test_stl.py,sha256=HXPe4f9bV4B3JRFDxmM-pHsILMC9BMRknw8eUePWrT0,12688
-extern/pybind11/tests/test_stl_binders.py,sha256=4w1GAzqe2LGG4uk30aLYrQu_nFGlNZt3aMmJXq77ATk,10150
-extern/pybind11/tests/test_tagbased_polymorphic.py,sha256=hAqyR1IXoNmJUUZ-H0Ot2hteaex9VGE1QymWDTN3tJ4,769
-extern/pybind11/tests/test_thread.py,sha256=xpgsriDrcCnLpsRud873ktQL7RZWB3nTvTxTWEOoBI8,868
-extern/pybind11/tests/test_type_caster_pyobject_ptr.py,sha256=-5P_7QAdTExLNf-OeDPVM9JlPfp6TwpZte6B6_wW-jA,3364
-extern/pybind11/tests/test_union.py,sha256=BLIsmhBn9GX2LDn9hBhjDD03vE_9m7FdFIrhai_opL8,156
-extern/pybind11/tests/test_unnamed_namespace_a.py,sha256=7TXqvmlaNgxao1YG7HmfxAKpfKNr7CXl1vCzUwLncRc,1175
-extern/pybind11/tests/test_unnamed_namespace_b.py,sha256=fvLE_vjSnrEu6-dXDSbe19hUSpSw3F_jE1QCqk7W5tA,148
-extern/pybind11/tests/test_vector_unique_ptr_member.py,sha256=jAUMq-GSYm1ei7x5c0AD1MMp1AT7w0SP35kUV4gRgyY,343
-extern/pybind11/tests/test_virtual_functions.py,sha256=b3WAkKcbg7LnKxoA72JMNC7btiyeISjeKZtv_-GQqKk,13371
-extern/pybind11/tests/extra_python_package/test_files.py,sha256=YJirJRqG0RwTW26lcBcLdLQOuhcxNQKh4FEd00HUfZI,8774
-extern/pybind11/tests/extra_setuptools/test_setuphelper.py,sha256=wkDPeVFCh0UYxKQqr5g4917_15SzbFvmgDMbX0fN_3A,4304
-extern/pybind11/tests/test_cmake_build/test.py,sha256=FIAyjOQkxy8mScsPccANS8lIkxEHMXucr2D0IzjxY2Q,206
-extern/pybind11/tests/test_embed/test_interpreter.py,sha256=unuIU5dE-Ie8L2l6UkUuFfE2s_dTyboWkITp2TrjzuA,251
-extern/pybind11/tests/test_embed/test_trampoline.py,sha256=fa6Pm_kP3TZFriK4zGkJT98JF6GDWFoFGZ5fUAoP9zw,291
-extern/pybind11/tools/codespell_ignore_lines_from_errors.py,sha256=-uOBDpMzC32MQ-TtfYpWtBjb-9PzXcFNOIqCHuLcqgM,1156
-extern/pybind11/tools/libsize.py,sha256=xp1nJIl4vHGMbSpYOydVV9kzcraSNRXNS52eImM7a94,1067
-extern/pybind11/tools/make_changelog.py,sha256=gFxp0WanqGCaF2KVvkjPehnqBlNxfcWihlTgBmdBJWE,2135
-SuPyMode-1.2.0.dist-info/LICENSE,sha256=_Xcqg6btgIHBE66SoLrThK_k6I8az305mCNRWdWThVE,1093
-SuPyMode-1.2.0.dist-info/METADATA,sha256=9c6Uz50EF5OLde_IQYzrBZmVcWkelKAT_sTk_NUlwMQ,5624
-SuPyMode-1.2.0.dist-info/WHEEL,sha256=fZWyj_84lK0cA-ZNCsdwhbJl0OTrpWkxInEn424qrSs,102
-SuPyMode-1.2.0.dist-info/top_level.txt,sha256=4wDFcf5kyQU2nrrrdYayxkcXY96Uwq9KEL1aJ6R7jns,73
-SuPyMode-1.2.0.dist-info/RECORD,,
+developments/gradient_tests_2.py,sha256=EaEgg805nYo6nlXr5cGwt5S90MeMPZmNB6U1P9pXw-0,1083
+developments/validation_2.py,sha256=BFcMSixioeaxPm1YgmLD-aUJimw_Vj0b5UQUben5cF0,3920
+developments/pydantic_test.py,sha256=QDNo6Ekwnjn5V0R_N-jC-dm17f80N3p6Z265mYBzx4E,112
+developments/validation.py,sha256=AG2cwgSrXkpSiCJHy-PHGLNNrE8yyBWThL7OVBFHn_M,3913
+docs/source/conf.py,sha256=9GiPhWIINIdV93EDYAHpAGs5CpHC5mJluHL86eVD8mg,4292
+docs/legacy/__debug__.py,sha256=Q3OSlyKkbYSwImswPusbGZiic2ibPi4NN5WJgnIchhg,1659
+docs/legacy/python_debuging/eigen_solver.py,sha256=55aV-EtbfRPl9Pj454pBsEsdUFOVoiqbYZGX3yeNltw,11163
+docs/legacy/python_debuging/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+docs/legacy/python_debuging/mode_solver.py,sha256=BJRMmktHkC5LJOQ8bUM_3dwAH7iS4DnGkoiPrwuDnus,12623
+docs/examples/basic/plot_workflow_06.py,sha256=zBYa1BbNYb72h1Bbs8c7Ju0uShQI9oQg1x6XueEfdC8,3608
+docs/examples/basic/plot_workflow_02.py,sha256=N2iEPgxBq_hnEq0tzWUXIPDLuv9Zd_gB4N3L0g3Cb2M,3118
+docs/examples/basic/plot_workflow_03.py,sha256=iXlCQXLfYcpVAqIf-NUEel44L1n7IjUJciagNp3C5dQ,3550
+docs/examples/basic/plot_workflow_07.py,sha256=FLNU4o6OC3u3YcGJIdxHk564m-ZIKM0B-ZP7RDhAcOA,3242
+docs/examples/basic/plot_workflow_08.py,sha256=8QSKJrPnGqo7QSyoQmKL5n-xTD1yFBhoKK8L9fZpIo8,3224
+docs/examples/basic/plot_alpha_profile_1.py,sha256=1O4F0ICsU43STA84pF7mFsjEEQTh_F8MYqA3iI1rE5k,722
+docs/examples/basic/plot_workflow_04.py,sha256=ZFHAauExF5tdwOHXWcLvXKa4AMv0aXmrU_X1qXd9Yno,3167
+docs/examples/basic/plot_workflow_05.py,sha256=jHQw5qaQL997ttocBs1ogE6ruUEx3rYER6_yiPC4rEg,3529
+docs/examples/basic/plot_workflow_01.py,sha256=cXgYpOPbHTKQqu5heeMzR9dq56FzJUMilNPRNrc-6pU,3041
+docs/examples/basic/plot_alpha_profile_0.py,sha256=jcTskCcenSg6RvuxuB1wCMtkIs8qxUDsx8pe6FjyGrM,685
+docs/examples/validation/plot_beta_SMF28.py,sha256=fjLhW6Namv_TpastzHBq5uGsZor090YGfxnpMSyQS1s,3477
+docs/examples/validation/plot_beta_DCF.py,sha256=OuKPidrGG-ygdRSB58TKv11rdD4FIDYgaGXUxaeKWn8,3484
+docs/examples/validation/plot_validation.py,sha256=f_GA97taoxnNyVi_PJwnWRpiL76bgqkgC44zvFNMy_M,5713
+SuPyMode-1.2.1.dist-info/RECORD,,
+SuPyMode-1.2.1.dist-info/LICENSE,sha256=U6YG4UEW9XJzHa53oijR0qw6JNN_SZ38WOBmYn3NPd0,1072
+SuPyMode-1.2.1.dist-info/WHEEL,sha256=Vo9YTsjXxZ5SWdH4n69oS5jU3YTIi3eHk0n-aUcTtlw,110
+SuPyMode-1.2.1.dist-info/top_level.txt,sha256=b7JIWmXo0XfSchh5fC60FpjoDaSTibp8qH4Bf4SHxjY,61
+SuPyMode-1.2.1.dist-info/METADATA,sha256=b4DddCCKp_NL3dsPidh9eZnl8DJZ7x7AKi1YgGlXYls,5486
+SuPyMode/superset.py,sha256=cMEGDXluY5eC25-1XtFyTGEU4e32_Js-EciEhrCo_XE,39705
+SuPyMode/solver.py,sha256=PpZALz-hJcpXbK7lubhIAUMxdCMadlOkZ2jQF2EqEUs,8867
+SuPyMode/directories.py,sha256=Lg6S5wzjxqbHDquVd2QcmDNbyi4S87MeoVsIIvRZTKo,1113
+SuPyMode/__init__.py,sha256=Bpg3W59JPi806tYYi-UFH3IGlbeb-VzedVpo8WevbaI,52
+SuPyMode/mode_label.py,sha256=UGrUKCxqCb1tFTyuTTV_tPfbYsfFAuayaBmBMzJVWYA,5091
+SuPyMode/VERSION,sha256=bPTghLR_M8mwLveSedFXgzho-PcFFBaadovjU-4yj-o,6
+SuPyMode/utils.py,sha256=-n0U837GpHBJu3xsyTw8fhOSdGO9O3qJKW0SUQYwPz0,9562
+SuPyMode/supermode.py,sha256=Tn0YhIrJEfEYLi5TC6A3HI--_iZFGMAh8S_trIRLvtY,10304
+SuPyMode/workflow.py,sha256=3xHigckPhaWFSaOpjgbVvntwbh40cHrzEtbebjgijKw,15735
+SuPyMode/special.py,sha256=BVp8op7tN5X-AX0nBn1I3Hqb14OpHYb3pBYBZqpRNpg,4612
+SuPyMode/profiles.py,sha256=s7_TIuF-mFjMC5QbDOVicbuhD4vM88l41Tp-InaGaUo,30289
+SuPyMode/tools/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+SuPyMode/tools/utils.py,sha256=5tzXF5902GNhr5MQ9orzZj7sLsDYGTL0QPXjbwtPnO0,8688
+SuPyMode/tools/special.py,sha256=BVp8op7tN5X-AX0nBn1I3Hqb14OpHYb3pBYBZqpRNpg,4612
+SuPyMode/.dylibs/libstdc++.6.dylib,sha256=GwdT6U8R1Zq30c17tDdpQa4y-0FissfP7hqTF8glHJM,4016064
+SuPyMode/.dylibs/libgcc_s.1.1.dylib,sha256=eIOzJTTpzQxquBem8bXQNfjiKwyV4mwnkobejomu82U,205680
+SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP02.csv,sha256=TBU5P4wX2PIGhTDMXH30G2vcKfRbkjq8dzRnSGa8_tg,3975
+SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP12.csv,sha256=eVdSBUcsy3NbRI2CZN3gYhIBS8VtR1hUG7968H2xwCo,3353
+SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP41.csv,sha256=5NMi0Kus0g0T2vRHt3IRSj95pr0_EikB6-YRfW7mXdE,3466
+SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP31.csv,sha256=ivEqwB0p9OOZBIlgOn3dA4bqU4kyobfndbKcV4e1H4U,3776
+SuPyMode/validation_data/SBB_figure_4_16_a/LP01-LP21.csv,sha256=YkUklj4_aIaxOfxkPPwqhIFSKDD-VF05upSl5AHOGDo,3552
+SuPyMode/validation_data/SBB_figure_4_16_a/LP11-LP51.csv,sha256=dgzjH8bd-TJ52sFIQt1gmJ69aPYkjhynZOgVFXcSqLE,3270
+SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP02.csv,sha256=-GCu5mF0GSIhOho2tviAh7LJCmjraypJHROEznnTat8,11516
+SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP12.csv,sha256=C7eKhCeOdq_9yfjhzLQIwXFQwG02VHswoFa4yDMz5Mg,5152
+SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP41.csv,sha256=PxHu2bPrOsL-Am6IkZYTn3OHbNvAKillcwNIg7SUAAk,9529
+SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP31.csv,sha256=K0pV3owu-i3lPgkpT8je1XP-x9lamUF7DC62yLNLUro,6428
+SuPyMode/validation_data/SBB_figure_4_16_b/LP01-LP21.csv,sha256=dT2ihBQglYVkA2VyHNHYgDop9grRDbDy-ZwvxVnQ1Pc,3105
+SuPyMode/validation_data/SBB_figure_4_16_b/LP11-LP51.csv,sha256=qasmwgeN6UPOhO7xEkMTGUdF3DnJU9iMzl18dV01QI0,9056
+SuPyMode/representation/field.py,sha256=UWtLORgHRRKbblPVsb2JmynwJ-GR7Bfii2GKWUHBkbU,12613
+SuPyMode/representation/index.py,sha256=LIePm5hweeE7Ks10DqCJ9NOIkG9bNkfgClTE0m3DAkQ,2584
+SuPyMode/representation/beta.py,sha256=hn5fecXN0F7gXkeyYXncyOiHYSOrji51bSFoW9XBIjw,2677
+SuPyMode/representation/adiabatic.py,sha256=cjpmTD8FJCZdPskaCMu0Yj7OLMTYCqT7fGtfQVQZ30w,3857
+SuPyMode/representation/normalized_coupling.py,sha256=U8tCqlBkCcA4I4M7pUpTvY6yqPPIhrnqZ0UwZhi5A9U,3727
+SuPyMode/representation/__init__.py,sha256=p4BQykbK_Y6pgyBnN_BMaYbn1YQd4TTogcsprfzvXvY,241
+SuPyMode/representation/beating_length.py,sha256=bMK_wOu7JUmVgPfHCvQvuZihu5BrCMt2FRuqeOWBzAg,3379
+SuPyMode/representation/eigen_value.py,sha256=om6Q2dqJHsMEgwMJlpVlPP2bTjlV3pvtSm_iye5v8fU,2423
+SuPyMode/representation/base.py,sha256=Deyotql8A2Dn2xG9ulBmyisYtSUNTnceprGg4IhHrxE,4060
+SuPyMode/binary/ModelParameters.cpython-312-darwin.so,sha256=fd24azWt6r43QUxvyNt39fVv9n2Dxnzff5djyUr8yDA,241216
+SuPyMode/binary/CppSolver.cpython-312-darwin.so,sha256=mfCguHStJLsfl92UXsBr9eq9O6LwqWICXkq87cDOLWs,562992
+SuPyMode/binary/SuperMode.cpython-312-darwin.so,sha256=pveZZAhpIokJk25Wv1G_N031jDx_Sgmxdk77vYlgjYc,274512
+SuPyMode/binary/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+SuPyMode/binary/Example.cpython-312-darwin.so,sha256=NnMUDrwpiyRZuCje_AZmUz--hZjj0HYm3tbQEDdJTIs,190064
+SuPyMode/binary/CppSolver.cpython-311-darwin.so,sha256=Gn6s6po7w8ZTgwS3b_nLrf2G4EvcPsNpXc9IPJpSvJs,563792
+SuPyMode/binary/SuperMode.cpython-311-darwin.so,sha256=j-yb7kqVTXJ8_o1ik0zHiEyFggeIT2PFv5RhJQXG4PE,275152
+SuPyMode/binary/Example.cpython-311-darwin.so,sha256=lyDeRVhkvmRCo58JTCUvK-6KoGO8cpETHr6-K4HZMls,190592
+SuPyMode/binary/ModelParameters.cpython-311-darwin.so,sha256=JmTP3hK7h5ehf3uGJi5PsIVHM0NBv7s2Ef2ndpg4t3k,241968
+extern/pybind11/setup.py,sha256=SEax08lv9WHfsRYR6NBd-kGc4ZE3XPAaE4-L0CoTXXg,4855
+extern/pybind11/noxfile.py,sha256=BU4j6Sx17oqNWTkvbkAEH1vEUVDVku7NvkFjJn5rljc,2746
+extern/pybind11/tools/libsize.py,sha256=3MBZDCi0-kdKei_6RcTbmVJgtmT4udB-WIF-mOPLBD4,1031
+extern/pybind11/tools/make_changelog.py,sha256=9nCsnW20rWzR974X-6QlCbVKeQY9WJNUr-_B-jV6iHs,2047
+extern/pybind11/tools/codespell_ignore_lines_from_errors.py,sha256=bTs7QS1-reWL04cS6C-Fh4F-TTXBgLIhemO4gfRaIgo,1117
+extern/pybind11/pybind11/setup_helpers.py,sha256=DZfrJeCTrHZDUpYVui7BDntZYtIp65UUQiVg8__Xd3Q,17492
+extern/pybind11/pybind11/_version.py,sha256=-l6BQjKBARiB1P1qV_b0C9NJ0VGw_td0SdwDct7xI1w,233
+extern/pybind11/pybind11/__init__.py,sha256=4-WhH9Ac6P8D_FqnflpOch8XlaZrkXbe95FspbMvwu0,429
+extern/pybind11/pybind11/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+extern/pybind11/pybind11/commands.py,sha256=iJBFWhXHqlC_JMAgMjMIn6H_hizvorS572upGU1roGA,1207
+extern/pybind11/pybind11/__main__.py,sha256=ATLlhFlhBxDXxxXEfnf2F1RcRhuWN1ziMwbmrGuhif0,1544
+extern/pybind11/tests/test_stl_binders.py,sha256=LCSbWxzHOvVGVYZ8CHb8qZEv_VtwBmWjWaWbs-HORh4,9795
+extern/pybind11/tests/test_methods_and_attributes.py,sha256=eeKv_KTT7AGh5xx__l--5ipDIWo2se7IIl6hZAujRA8,18426
+extern/pybind11/tests/test_sequences_and_iterators.py,sha256=lEmcoEAs4BRF56_nW4s4VBajQpwbDyKFP6tlghh6mRU,8659
+extern/pybind11/tests/test_vector_unique_ptr_member.py,sha256=GH3W9XCjs-4ZGVbPSwL6tWMuwH3lo2jWTIy_5ErolIM,329
+extern/pybind11/tests/test_numpy_vectorize.py,sha256=TiaL_Of3IV54EL02dxSQHxQiaRPfXE2Io_rcNMRbSkk,9658
+extern/pybind11/tests/test_chrono.py,sha256=wWRj4tub996ztvM47I32U3V4Zh4Fyrsts12NWVC6KfE,5691
+extern/pybind11/tests/conftest.py,sha256=apNK2IWTJJrO2iRZ-gKQfMVazRKalssfNC6W_T1HOqo,5619
+extern/pybind11/tests/test_python_multiple_inheritance.py,sha256=u4danQMnaWvONH3meU1CSCBMJKO6HWNJOCuDezLW7wY,859
+extern/pybind11/tests/test_callbacks.py,sha256=eOsVfPfniwFACqJ_75eYndXaro4ORFWdjE_1G9BKtCE,6955
+extern/pybind11/tests/test_pytypes.py,sha256=J_lTuIpT6UXnyJ_TNnp2nw9nxiPEGRpml2AUE8wf2p4,25066
+extern/pybind11/tests/test_class.py,sha256=jk7nEmUICabpdYDAOvJn0qu0xHJWqzepORt228b2cwU,15187
+extern/pybind11/tests/env.py,sha256=mBvy4nBuYARGq4e0WFiqRHi2lFfm-Muil2hPImp77QU,926
+extern/pybind11/tests/test_eigen_tensor.py,sha256=1DpHD-tDI_dSRiQu5yeN3mHZ5JX5OlumnEdbVxIYHuE,9414
+extern/pybind11/tests/test_docstring_options.py,sha256=9SIyCr1g7mRKCpL5Y1op_Wvo2Wnyfs1eVDdQjvo2V64,2423
+extern/pybind11/tests/test_async.py,sha256=uYMOvTRUXaP5xNAyaBV6dQ-M1BmiNLsaUek5Ov6Te6g,536
+extern/pybind11/tests/test_unnamed_namespace_a.py,sha256=yWaoqrOYoWHMkmoHYzfWcrGMhNcoZpBVFxezJZ0jbmI,1141
+extern/pybind11/tests/test_local_bindings.py,sha256=Z4aupdd8VqwEL_YtqauPisMGDQ96Wq2u0WX7Tlgs3Po,8054
+extern/pybind11/tests/test_smart_ptr.py,sha256=Pg4squkdWXLQbzkPpW_uJwCD8t3C--tXRhkrQaOV6Lo,9530
+extern/pybind11/tests/test_numpy_array.py,sha256=CsADQJNUuCluZTqUGIYGVRT7WvPp6ljL1VmyV1OIM9I,22892
+extern/pybind11/tests/test_builtin_casters.py,sha256=85lKGmZ9MVPeOAVGqZ6PChTh0czr6fDAynMp_IkUsv0,17243
+extern/pybind11/tests/test_constants_and_functions.py,sha256=2wOq0KNZWeEVOcsZFv24m_ZT2QQmHjA0pc2CJu_nNuA,1551
+extern/pybind11/tests/test_exceptions.py,sha256=tFTpuzeIYKObN20nrET0TXI0F5Sm3D0L5Br9__bCIOA,14165
+extern/pybind11/tests/test_factory_constructors.py,sha256=QPZGHcuhknyk7DXEiQB7tlndBizJTW99FbFwfd4VzBI,16491
+extern/pybind11/tests/test_iostream.py,sha256=xGeQwxjGz1GKSWBBxi1XZS6lE2GBP8VtPR_7SqDTyJI,7144
+extern/pybind11/tests/test_operator_overloading.py,sha256=EXYVO-xVcZ7JGqtbf9kr_jSr4z9vWPp9WlzkWdXMLxQ,4332
+extern/pybind11/tests/test_union.py,sha256=k80v8rRTygvDKJ1glA8Pptl1_JWxn2hHSIZUnzJ_M-4,148
+extern/pybind11/tests/test_kwargs_and_defaults.py,sha256=Y85X7POZCrIOGgpHBAT1DY8hmvKjChYikWPVRuIUQfA,14856
+extern/pybind11/tests/test_type_caster_pyobject_ptr.py,sha256=OZ8WD3Yfa_ryXT7WHqp9TaY034itiDxls43I_AT6ibQ,3260
+extern/pybind11/tests/test_thread.py,sha256=0UOYRTgU4Cn2NyMqKXTCRPvLPV2VZp1tv5g_GCiJVRI,826
+extern/pybind11/tests/test_pickling.py,sha256=YdQB55beQ2jM3chdltDDdDgDFTgafB2p_C-kYRfeyNE,2720
+extern/pybind11/tests/test_unnamed_namespace_b.py,sha256=7NSpWeCZ8gDj6gR_NCEyE3VgUrN_PjzOoqddCo7ZxvQ,143
+extern/pybind11/tests/test_copy_move.py,sha256=g3Ko_liPXH1HoGMRF18rK5uCPmZ3VmRM4NZ4NFlzr50,4796
+extern/pybind11/tests/test_eval_call.py,sha256=Sv6xRg8O6PFz9bu4E-SngKmKAJDR-zoraB4DJxiIwsQ,119
+extern/pybind11/tests/test_custom_type_casters.py,sha256=u_Lej31fx61mPzol7U4Xr3WGSyD4aYKAKpm-njYbR5s,3992
+extern/pybind11/tests/test_stl.py,sha256=nxOVBwvOXkc0kvUovEW11QBCvQfyD_FudMagYmqNfb8,12307
+extern/pybind11/tests/test_numpy_dtypes.py,sha256=N_oX2PbgvOe0cjiXSOS39X4TR1bY3QlzsDrjTQCZKtU,14272
+extern/pybind11/tests/test_eigen_matrix.py,sha256=m4qNtxwV2zhKbqigZjkPyrduMKVUkeyJbJYWRwR89qA,29150
+extern/pybind11/tests/test_opaque_types.py,sha256=9NC9CVbTICcgHROPDELwp8cAODmEhiAJZorhXJVOsFw,1847
+extern/pybind11/tests/test_virtual_functions.py,sha256=k_lqTAulKG64S2H4JUSurCs6R0eCD5aWgBnLiqQdlI4,12913
+extern/pybind11/tests/test_const_name.py,sha256=4m2BHzRPio31JdIvLNNyI5sooL9SjPLx2mPECXsD2y4,593
+extern/pybind11/tests/test_call_policies.py,sha256=Sh6W8mZl_6WES3wl0Xg37wDRKtwvfTYN4KVrbMjgGCg,6549
+extern/pybind11/tests/test_custom_type_setup.py,sha256=ZvxJFhL1VJ-KMCSaoidCs-7gJJPT7_rT8dsKuyuireU,1091
+extern/pybind11/tests/test_buffers.py,sha256=1FtPBCl1ENZLm8BprdB6Bqvr2lF0ocSMnCpUHYPMnDs,7124
+extern/pybind11/tests/test_modules.py,sha256=_bRNXlAMaP0AJ1g1PC45XGlaFZizaWJ2t7H9-QNtv44,3963
+extern/pybind11/tests/test_gil_scoped.py,sha256=izUGwxoBnOmgPbTLV3Ncr7nzdHOU7GsT5krJwMykdzw,8507
+extern/pybind11/tests/test_multiple_inheritance.py,sha256=TMfFciBKCWT_HMEiJd4rsM5UAah0vwDO2ce80gmajCU,11874
+extern/pybind11/tests/test_tagbased_polymorphic.py,sha256=SOZRvD7dO-d8yN0rdwdNwuierZ_QSGBxGdHyr8jAg5I,741
+extern/pybind11/tests/test_eval.py,sha256=OWASlmDmIp_YVBWdfJWqQsVnXNNXAf9bbTrbYfXnkts,1143
+extern/pybind11/tests/test_enum.py,sha256=N2MuJS_THhinHJRJjMThlR4Ad_bfG22w5ZnBeNuf0uY,9069
+extern/pybind11/tests/test_embed/test_trampoline.py,sha256=Imweq5_SBMVAHq3Z2Zk2BBhdsU051vlQCDTPCN_VHFM,275
+extern/pybind11/tests/test_embed/test_interpreter.py,sha256=9IOkq9zAEvHwSfYphifX44hic0IxULirsSxpOYylePk,237
+extern/pybind11/tests/test_cmake_build/test.py,sha256=U_GX_6p4JTzq-zPzmopNAoD_MuPfE0MLiiJf4-u24O8,198
+extern/pybind11/tests/extra_setuptools/test_setuphelper.py,sha256=msgUx7ZS651vGZ9Jg_f4LBdQ2otkdOb61dLBBpmvC6k,4153
+extern/pybind11/tests/extra_python_package/test_files.py,sha256=0eKZ9cOOzqfwTm9nuPTyJ6eut-jvzTkKOeOgtoKaB-c,8481
+extern/pybind11/docs/benchmark.py,sha256=tO_QYZdRU4osvuDvstboRUYJKzL5gkmbbTdArlRDvlg,2853
+extern/pybind11/docs/conf.py,sha256=AC4NU6pdI96eKTIRvbV_04LIiKLYtCYy84RCbY2B7OU,11574
+extern/eigen/scripts/relicense.py,sha256=ZE1K4NL09B7psBh5P9bA9avIoTgUmsTIL-zMhUjhjts,2368
+extern/eigen/debug/gdb/__init__.py,sha256=j5vg_XYSXQiKXbLJ-c-1U8w9pwzfTyP1aK3_2CFHczc,22
+extern/eigen/debug/gdb/printers.py,sha256=LX2DRZRnR-tTzH3ZkK8-ajvfwvKC68FzfXLF0PmffAg,9617
```

